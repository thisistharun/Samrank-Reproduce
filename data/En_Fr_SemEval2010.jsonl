{"file_name": "C-38", "text": "Un cadre pour l'architecture de superpositions pilot\u00e9es par des r\u00e9cepteurs peer-to-peer R\u00c9SUM\u00c9 Cet article pr\u00e9sente un cadre simple et \u00e9volutif pour l'architecture de superpositions peer-to-peer appel\u00e9 Overlay pilot\u00e9 par des r\u00e9cepteurs peer-to-peer -LRB- ou PRO -RRB-. PRO est con\u00e7u pour les applications de streaming non interactives et son objectif principal de conception est de maximiser la bande passante d\u00e9livr\u00e9e -LRB- et ainsi de fournir une qualit\u00e9 -RRB- aux pairs dot\u00e9s d'une bande passante h\u00e9t\u00e9rog\u00e8ne et asym\u00e9trique. Pour atteindre cet objectif, PRO adopte une approche ax\u00e9e sur le r\u00e9cepteur dans laquelle chaque r\u00e9cepteur -LRB- ou homologue participant -RRB- -LRB- i -RRB- d\u00e9couvre ind\u00e9pendamment d'autres pairs dans la superposition par le biais de comm\u00e9rages, et -LRB- ii -RRB- de mani\u00e8re \u00e9go\u00efste. d\u00e9termine le meilleur sous-ensemble de pairs parents via lequel se connecter \u00e0 la superposition afin de maximiser sa propre bande passante fournie. Les pairs participants forment une superposition non structur\u00e9e qui est intrins\u00e8quement robuste face \u00e0 un taux de d\u00e9sabonnement \u00e9lev\u00e9. De plus, chaque r\u00e9cepteur exploite la bande passante contr\u00f4l\u00e9e par l'encombrement de ses parents comme signal implicite pour d\u00e9tecter et r\u00e9agir aux changements \u00e0 long terme de l'\u00e9tat du r\u00e9seau ou de la superposition sans aucune coordination explicite avec les autres pairs participants. La s\u00e9lection ind\u00e9pendante des parents par des pairs individuels converge dynamiquement vers une structure de superposition efficace. 1. INTRODUCTION l'h\u00e9t\u00e9rog\u00e9n\u00e9it\u00e9 et l'asym\u00e9trie de la connectivit\u00e9 de la bande passante parmi les pairs participants -LSB- 19 -RSB-. Faire face aux variations, \u00e0 l'h\u00e9t\u00e9rog\u00e9n\u00e9it\u00e9 et \u00e0 l'asym\u00e9trie de la bande passante est particuli\u00e8rement important dans la conception de superpositions peer-to-peer pour les applications de streaming, car la qualit\u00e9 fournie \u00e0 chaque homologue est directement d\u00e9termin\u00e9e par sa connectivit\u00e9 de bande passante \u00e0 -LRB- un autre homologue -LRB- s -RRB- sur -RRB- la superposition. Cet article pr\u00e9sente un cadre simple pour l'architecture d'une superposition pilot\u00e9e par un r\u00e9cepteur peer-to-peer, appel\u00e9 PRO. La principale philosophie de conception de PRO est que chaque homologue doit \u00eatre autoris\u00e9 \u00e0 d\u00e9terminer de mani\u00e8re ind\u00e9pendante et \u00e9go\u00efste la meilleure fa\u00e7on de se connecter \u00e0 la superposition afin de maximiser sa propre qualit\u00e9 fournie. \u00c0 cette fin, chaque homologue peut se connecter \u00e0 la topologie de superposition en plusieurs points -LRB-, c'est-\u00e0-dire recevoir du contenu via plusieurs homologues parents -RRB-. Par cons\u00e9quent, les pairs participants forment une superposition non structur\u00e9e qui peut faire face avec \u00e9l\u00e9gance \u00e0 un taux de d\u00e9sabonnement \u00e9lev\u00e9 -LSB- 5 -RSB-. De plus, le fait d\u2019avoir plusieurs pairs parents s\u2019adapte \u00e0 l\u2019h\u00e9t\u00e9rog\u00e9n\u00e9it\u00e9 et \u00e0 l\u2019asym\u00e9trie de la bande passante tout en am\u00e9liorant la r\u00e9silience face \u00e0 la dynamique de participation des pairs. PRO se compose de deux composants cl\u00e9s\u00a0: -LRB- i -RRB- D\u00e9couverte des pairs bas\u00e9e sur les potins\u00a0: chaque pair \u00e9change p\u00e9riodiquement un message -LRB-, c'est-\u00e0-dire des potins -RRB- avec d'autres pairs connus pour en apprendre progressivement sur un sous-ensemble de pairs participants dans la superposition. qui sont susceptibles d'\u00eatre de bons parents. -LRB- ii -RRB- S\u00e9lection des parents pilot\u00e9e par le r\u00e9cepteur\u00a0: \u00e9tant donn\u00e9 les informations collect\u00e9es sur les autres pairs participants par le m\u00e9canisme de potins,chaque homologue -LRB- ou r\u00e9cepteur -RRB- am\u00e9liore progressivement sa propre qualit\u00e9 d\u00e9livr\u00e9e en s\u00e9lectionnant dynamiquement un sous-ensemble appropri\u00e9 de pairs parents qui maximisent collectivement la bande passante fournie au r\u00e9cepteur. \u00c9tant donn\u00e9 que la bande passante disponible des diff\u00e9rents pairs participants vers un r\u00e9cepteur -LRB- et la corr\u00e9lation possible entre eux -RRB- peuvent \u00eatre mesur\u00e9es uniquement au niveau de ce r\u00e9cepteur, une approche pilot\u00e9e par le r\u00e9cepteur est la solution naturelle pour maximiser la bande passante disponible pour des pairs h\u00e9t\u00e9rog\u00e8nes. De plus, la bande passante disponible des homologues parents sert de signal implicite permettant \u00e0 un r\u00e9cepteur de d\u00e9tecter et de r\u00e9agir aux changements dans l'\u00e9tat du r\u00e9seau ou de la superposition sans aucune coordination explicite avec les autres homologues participants. La s\u00e9lection ind\u00e9pendante des parents par des pairs individuels conduit \u00e0 une superposition efficace qui maximise la qualit\u00e9 fournie \u00e0 chaque pair. PRO int\u00e8gre plusieurs fonctions d'amortissement pour assurer la stabilit\u00e9 de la superposition malgr\u00e9 les actions non coordonn\u00e9es de diff\u00e9rents pairs. PRO fait partie d'une architecture plus large que nous avons d\u00e9velopp\u00e9e pour le streaming peer-to-peer. Ainsi, PRO et PALS sont tous deux pilot\u00e9s par le r\u00e9cepteur mais se compl\u00e8tent. Plus sp\u00e9cifiquement, PRO d\u00e9termine un sous-ensemble appropri\u00e9 de pairs parents qui maximisent collectivement la bande passante d\u00e9livr\u00e9e \u00e0 chaque r\u00e9cepteur tandis que PALS coordonne le streaming \u00ab\u00a0dans le temps\u00a0\u00bb de diff\u00e9rents segments de contenu multim\u00e9dia de ces parents malgr\u00e9 des variations impr\u00e9visibles de leur bande passante disponible. Cette division des fonctionnalit\u00e9s offre une grande flexibilit\u00e9 car elle dissocie la construction de superposition du m\u00e9canisme de livraison. Dans cet article, nous nous concentrons principalement sur le m\u00e9canisme de construction de superposition, ou PRO. Le reste de cet article est organis\u00e9 comme suit\u00a0: Dans la section 2, nous revisitons le probl\u00e8me de la construction de superpositions pour le streaming peer-to-peer, identifions ses deux composants cl\u00e9s et explorons leur espace de conception. Nous pr\u00e9sentons notre cadre propos\u00e9 dans la section 3. Dans les sections 4 et 5, les \u00e9l\u00e9ments cl\u00e9s de notre cadre sont d\u00e9crits plus en d\u00e9tail. Enfin, la section 6 conclut le document et pr\u00e9sente nos projets futurs. 6. CONCLUSIONS ET TRAVAUX FUTURS Dans cet article, nous avons pr\u00e9sent\u00e9 un cadre simple pilot\u00e9 par un r\u00e9cepteur pour l'architecture de structures de superposition peer-to-pee appel\u00e9 PRO. PRO permet \u00e0 chaque homologue de d\u00e9terminer de mani\u00e8re \u00e9go\u00efste et ind\u00e9pendante la meilleure fa\u00e7on de se connecter \u00e0 la superposition pour maximiser ses performances. Par cons\u00e9quent, PRO devrait \u00eatre en mesure de maximiser la qualit\u00e9 fournie aux pairs avec une connectivit\u00e9 \u00e0 bande passante h\u00e9t\u00e9rog\u00e8ne et asym\u00e9trique. La d\u00e9couverte et la s\u00e9lection des pairs dans ce cadre sont \u00e9volutives. De plus, PRO utilise une bande passante contr\u00f4l\u00e9e par la congestion comme signal implicite pour d\u00e9tecter les goulots d'\u00e9tranglement partag\u00e9s entre les parents existants ainsi que les changements dans les conditions du r\u00e9seau ou de superposition pour remodeler correctement la structure. Nous avons d\u00e9crit le cadre de base et ses composants cl\u00e9s, et esquiss\u00e9 nos solutions de paille. C'est un point de d\u00e9part pour notre travail sur PRO. Nous \u00e9valuons actuellement divers aspects de ce cadre via la simulation,et explorer l'espace de conception des composants cl\u00e9s. Nous prototypons \u00e9galement ce cadre pour mener des exp\u00e9riences r\u00e9elles sur le Planet-Lab dans un avenir proche.", "keyphrases": ["flux peer-to-peer", "contr\u00f4le des embouteillages", "approche ax\u00e9e sur la r\u00e9ception", "superposition bas\u00e9e sur la r\u00e9ception", "syst\u00e8me de distribution", "conception", "mesurer", "structure superpos\u00e9e efficace", "pro", "sous-ensemble appropri\u00e9 du pair parent", "d\u00e9couverte par les pairs bas\u00e9e sur les potins", "s\u00e9lection du parent bas\u00e9e sur la r\u00e9ception"]}
{"file_name": "H-17", "text": "Politiques d'\u00e9lagage pour les index invers\u00e9s \u00e0 deux niveaux avec garantie d'exactitude R\u00c9SUM\u00c9 Les moteurs de recherche Web maintiennent des index invers\u00e9s \u00e0 grande \u00e9chelle qui sont interrog\u00e9s des milliers de fois par seconde par les utilisateurs avides d'informations. Afin de faire face aux grandes quantit\u00e9s de charges de requ\u00eates, les moteurs de recherche \u00e9laguent leur index pour conserver les documents susceptibles d'\u00eatre renvoy\u00e9s comme premiers r\u00e9sultats, et utilisent cet index \u00e9lagu\u00e9 pour calculer les premiers lots de r\u00e9sultats. Bien que cette approche puisse am\u00e9liorer les performances en r\u00e9duisant la taille de l'index, si nous calculons les meilleurs r\u00e9sultats uniquement \u00e0 partir de l'index \u00e9lagu\u00e9, nous pouvons remarquer une d\u00e9gradation significative de la qualit\u00e9 des r\u00e9sultats : si un document devrait figurer dans les premiers r\u00e9sultats mais n'a pas \u00e9t\u00e9 inclus dans l'index \u00e9lagu\u00e9, il sera plac\u00e9 derri\u00e8re les r\u00e9sultats calcul\u00e9s \u00e0 partir de l'index \u00e9lagu\u00e9. Compte tenu de la concurrence f\u00e9roce sur le march\u00e9 de la recherche en ligne, ce ph\u00e9nom\u00e8ne est clairement ind\u00e9sirable. Dans cet article, nous \u00e9tudions comment \u00e9viter toute d\u00e9gradation de la qualit\u00e9 des r\u00e9sultats due \u00e0 l\u2019optimisation des performances bas\u00e9e sur l\u2019\u00e9lagage, tout en r\u00e9alisant la plupart de ses avantages. Notre contribution consiste en un certain nombre de modifications dans les techniques d'\u00e9lagage pour cr\u00e9er l'index \u00e9lagu\u00e9 et un nouvel algorithme de calcul des r\u00e9sultats qui garantit que les pages les plus correspondantes sont toujours plac\u00e9es en haut des r\u00e9sultats de recherche, m\u00eame si nous calculons le premier lot \u00e0 partir de l'index \u00e9lagu\u00e9. index la plupart du temps. Nous montrons \u00e9galement comment d\u00e9terminer la taille optimale d'un index \u00e9lagu\u00e9 et nous \u00e9valuons exp\u00e9rimentalement nos algorithmes sur une collection de 130 millions de pages Web. 1. INTRODUCTION Selon une \u00e9tude r\u00e9cente -LSB- 13 -RSB-, on estime que le \u2217 Travail effectu\u00e9 alors que l'auteur \u00e9tait au d\u00e9partement d'informatique de l'UCLA. \u2020 Ce travail est partiellement soutenu par les subventions NSF, IIS-0534784, IIS0347993 et \u200b\u200bCNS-0626702. En raison de cette immense quantit\u00e9 d'informations disponibles, les utilisateurs deviennent de plus en plus d\u00e9pendants des moteurs de recherche Web pour localiser les informations pertinentes sur le Web. G\u00e9n\u00e9ralement, les moteurs de recherche Web, \u00e0 l'instar d'autres applications de recherche d'informations, utilisent une structure de donn\u00e9es appel\u00e9e index invers\u00e9. Un index invers\u00e9 permet une r\u00e9cup\u00e9ration efficace des documents -LRB- ou des pages Web -RRB- qui contiennent un mot-cl\u00e9 particulier. Dans la plupart des cas, une requ\u00eate \u00e9mise par l'utilisateur peut contenir des milliers, voire des millions de documents correspondants. Afin d'\u00e9viter de submerger les utilisateurs avec une quantit\u00e9 \u00e9norme de r\u00e9sultats, les moteurs de recherche pr\u00e9sentent les r\u00e9sultats par lots de 10 \u00e0 20 documents pertinents. L'utilisateur parcourt ensuite le premier lot de r\u00e9sultats et, s'il ne trouve pas la r\u00e9ponse qu'il cherche, il peut \u00e9ventuellement demander \u00e0 consulter le lot suivant ou d\u00e9cider d'\u00e9mettre une nouvelle requ\u00eate. Une \u00e9tude r\u00e9cente -LSB-16-RSB- a indiqu\u00e9 qu'environ 80 % des utilisateurs examinent au maximum les 3 premiers lots de r\u00e9sultats. Autrement dit, 80 % des utilisateurs affichent g\u00e9n\u00e9ralement au maximum 30 \u00e0 60 r\u00e9sultats pour chaque requ\u00eate qu'ils envoient \u00e0 un moteur de recherche. En m\u00eame temps, compte tenu de la taille du Web,l'index invers\u00e9 maintenu par les moteurs de recherche peut devenir tr\u00e8s volumineux. Une solution naturelle \u00e0 ce probl\u00e8me consiste \u00e0 cr\u00e9er un petit index sur un sous-ensemble de documents susceptibles d'\u00eatre renvoy\u00e9s comme premiers r\u00e9sultats -LRB- en utilisant, par exemple, les techniques d'\u00e9lagage de -LSB- 7, 20 -RSB-. -RRB- et calculez le premier lot de r\u00e9ponses en utilisant l'index \u00e9lagu\u00e9. Bien qu'il ait \u00e9t\u00e9 d\u00e9montr\u00e9 que cette approche apporte une am\u00e9lioration significative des performances, elle conduit \u00e9galement \u00e0 une d\u00e9gradation notable de la qualit\u00e9 des r\u00e9sultats de recherche, car les meilleures r\u00e9ponses sont calcul\u00e9es uniquement \u00e0 partir de l'index \u00e9lagu\u00e9 -LSB- 7, 20 -RSB-. Autrement dit, m\u00eame si une page doit \u00eatre plac\u00e9e comme page la plus correspondante selon la m\u00e9trique de classement d'un moteur de recherche, la page peut \u00eatre plac\u00e9e derri\u00e8re celles contenues dans l'index \u00e9lagu\u00e9 si la page ne fait pas partie de l'index \u00e9lagu\u00e9. pour diverses raisons -LSB- 7, 20 -RSB-. Compte tenu de la concurrence f\u00e9roce entre les moteurs de recherche, cette d\u00e9gradation est clairement ind\u00e9sirable et doit \u00eatre corrig\u00e9e si possible. Dans cet article, nous \u00e9tudions comment \u00e9viter toute d\u00e9gradation de la qualit\u00e9 de la recherche due \u00e0 l\u2019optimisation des performances ci-dessus tout en profitant de la plupart de ses avantages. Autrement dit, nous pr\u00e9sentons un certain nombre de changements simples -LRB- mais importants -RRB- dans les techniques d'\u00e9lagage pour cr\u00e9er l'index \u00e9lagu\u00e9. Notre principale contribution est un nouvel algorithme de calcul de r\u00e9ponse qui garantit que les pages les plus correspondantes -LRB- selon la m\u00e9trique de classement du moteur de recherche -RRB- sont toujours plac\u00e9es en haut des r\u00e9sultats de recherche, m\u00eame si nous calculons la premi\u00e8re. lot de r\u00e9ponses de l'index \u00e9lagu\u00e9 la plupart du temps. Ces techniques d'\u00e9lagage am\u00e9lior\u00e9es et ces algorithmes de calcul de r\u00e9ponse sont explor\u00e9s dans le context de l'architecture de cluster couramment utilis\u00e9e par les moteurs de recherche d'aujourd'hui. Enfin, nous \u00e9tudions et pr\u00e9sentons comment les moteurs de recherche peuvent minimiser le co\u00fbt op\u00e9rationnel li\u00e9 aux r\u00e9ponses aux requ\u00eates tout en fournissant des r\u00e9sultats de recherche de haute qualit\u00e9. Figure 1 : -LRB- a -RRB- Le moteur de recherche r\u00e9plique son index IF complet pour augmenter la capacit\u00e9 de r\u00e9ponse aux requ\u00eates. -LRB- b -RRB- Au 1er niveau, les petits pindex IP g\u00e8rent la plupart des requ\u00eates. Lorsque l'IP ne peut pas r\u00e9pondre \u00e0 une requ\u00eate, elle est redirig\u00e9e vers le 2\u00e8me niveau, o\u00f9 l'index complet IF est utilis\u00e9 pour calculer la r\u00e9ponse. 6. TRAVAUX CONNEXES -LSB- 3, 30 -RSB- fournissent un bon aper\u00e7u de l'indexation invers\u00e9e dans les moteurs de recherche Web et les syst\u00e8mes IR. Des \u00e9tudes exp\u00e9rimentales et des analyses de divers sch\u00e9mas de partitionnement pour un indice invers\u00e9 sont pr\u00e9sent\u00e9es dans -LSB- 6, 23, 33 -RSB-. Les algorithmes d'\u00e9lagage que nous avons pr\u00e9sent\u00e9s dans cet article sont ind\u00e9pendants du sch\u00e9ma de partitionnement utilis\u00e9. Cependant, -LSB- 1, 5, 7, 27 -RSB- ne prennent en compte aucune qualit\u00e9 ind\u00e9pendante de la requ\u00eate -LRB- telle que le PageRank -RRB- dans la fonction de classement. -LSB- 32 -RSB- pr\u00e9sente un cadre g\u00e9n\u00e9rique pour calculer les r\u00e9ponses approximatives top-k avec certaines limites probabilistes sur la qualit\u00e9 des r\u00e9sultats. Notre travail \u00e9tend essentiellement -LSB- 1, 2, 4, 7, 20, 27,31 -RSB- en proposant des m\u00e9canismes pour fournir la garantie d'exactitude des r\u00e9sultats top-k calcul\u00e9s. Les moteurs de recherche utilisent diverses m\u00e9thodes de mise en cache pour r\u00e9duire le co\u00fbt associ\u00e9 aux requ\u00eates -LSB- 18, 19, 21, 31 -RSB-. Ce fil de travail est \u00e9galement orthogonal au n\u00f4tre car un sch\u00e9ma de mise en cache peut fonctionner au-dessus de notre p-index afin de minimiser le co\u00fbt de calcul de la r\u00e9ponse. Les fonctions de classement exactes utilis\u00e9es par les moteurs de recherche actuels sont des secrets jalousement gard\u00e9s. En g\u00e9n\u00e9ral, cependant, les classements sont bas\u00e9s sur la pertinence d\u00e9pendante de la requ\u00eate et sur la qualit\u00e9 du document, ind\u00e9pendante de la requ\u00eate. '' De m\u00eame, il existe un certain nombre de travaux qui mesurent la `` qualit\u00e9 '' des documents, g\u00e9n\u00e9ralement telle que captur\u00e9e par l'analyse bas\u00e9e sur les liens -LSB- 17, 28, 26 -RSB-. Puisque notre travail n\u2019assume pas une forme particuli\u00e8re de fonction de classement, il est compl\u00e9mentaire \u00e0 ce corpus de travaux. De nombreux travaux ont \u00e9t\u00e9 r\u00e9alis\u00e9s sur le calcul des r\u00e9sultats top-k. 7. REMARQUES CONCLUSIVES Les moteurs de recherche Web \u00e9laguent g\u00e9n\u00e9ralement leurs index invers\u00e9s \u00e0 grande \u00e9chelle afin de s'adapter \u00e0 d'\u00e9normes charges de requ\u00eates. Bien que cette approche puisse am\u00e9liorer les performances, en calculant les meilleurs r\u00e9sultats \u00e0 partir d'un index \u00e9lagu\u00e9, nous pouvons remarquer une d\u00e9gradation significative de la qualit\u00e9 des r\u00e9sultats. Dans cet article, nous avons fourni un cadre pour de nouvelles techniques d'\u00e9lagage et des algorithmes de calcul de r\u00e9ponses qui garantissent que les pages les plus correspondantes sont toujours plac\u00e9es en haut des r\u00e9sultats de recherche dans le bon ordre. Nous avons \u00e9tudi\u00e9 deux techniques d'\u00e9lagage, \u00e0 savoir l'\u00e9lagage bas\u00e9 sur des mots cl\u00e9s et bas\u00e9 sur des documents, ainsi que leur combinaison. Nos r\u00e9sultats exp\u00e9rimentaux ont d\u00e9montr\u00e9 que nos algorithmes peuvent \u00eatre utilis\u00e9s efficacement pour \u00e9laguer un index invers\u00e9 sans d\u00e9gradation de la qualit\u00e9 des r\u00e9sultats. En particulier, un index \u00e9lagu\u00e9 par mot cl\u00e9 peut garantir 73 % des requ\u00eates avec une taille de 30 % de l'index complet, tandis qu'un index \u00e9lagu\u00e9 par document peut garantir 68 % des requ\u00eates avec la m\u00eame taille. Lorsque nous combinons les deux algorithmes d'\u00e9lagage, nous pouvons garantir 60 % des requ\u00eates avec une taille d'index de 16 %. Nous esp\u00e9rons que nos travaux aideront les moteurs de recherche \u00e0 d\u00e9velopper des index meilleurs, plus rapides et plus efficaces et offriront ainsi une meilleure exp\u00e9rience de recherche aux utilisateurs sur le Web.il est compl\u00e9mentaire \u00e0 ce corpus de travail. De nombreux travaux ont \u00e9t\u00e9 r\u00e9alis\u00e9s sur le calcul des r\u00e9sultats top-k. 7. REMARQUES CONCLUSIVES Les moteurs de recherche Web \u00e9laguent g\u00e9n\u00e9ralement leurs index invers\u00e9s \u00e0 grande \u00e9chelle afin de s'adapter \u00e0 d'\u00e9normes charges de requ\u00eates. Bien que cette approche puisse am\u00e9liorer les performances, en calculant les meilleurs r\u00e9sultats \u00e0 partir d'un index \u00e9lagu\u00e9, nous pouvons remarquer une d\u00e9gradation significative de la qualit\u00e9 des r\u00e9sultats. Dans cet article, nous avons fourni un cadre pour de nouvelles techniques d'\u00e9lagage et des algorithmes de calcul de r\u00e9ponses qui garantissent que les pages les plus correspondantes sont toujours plac\u00e9es en haut des r\u00e9sultats de recherche dans le bon ordre. Nous avons \u00e9tudi\u00e9 deux techniques d'\u00e9lagage, \u00e0 savoir l'\u00e9lagage bas\u00e9 sur des mots cl\u00e9s et bas\u00e9 sur des documents, ainsi que leur combinaison. Nos r\u00e9sultats exp\u00e9rimentaux ont d\u00e9montr\u00e9 que nos algorithmes peuvent \u00eatre utilis\u00e9s efficacement pour \u00e9laguer un index invers\u00e9 sans d\u00e9gradation de la qualit\u00e9 des r\u00e9sultats. En particulier, un index \u00e9lagu\u00e9 par mot cl\u00e9 peut garantir 73 % des requ\u00eates avec une taille de 30 % de l'index complet, tandis qu'un index \u00e9lagu\u00e9 par document peut garantir 68 % des requ\u00eates avec la m\u00eame taille. Lorsque nous combinons les deux algorithmes d'\u00e9lagage, nous pouvons garantir 60 % des requ\u00eates avec une taille d'index de 16 %. Nous esp\u00e9rons que nos travaux aideront les moteurs de recherche \u00e0 d\u00e9velopper des index meilleurs, plus rapides et plus efficaces et offriront ainsi une meilleure exp\u00e9rience de recherche aux utilisateurs sur le Web.il est compl\u00e9mentaire \u00e0 ce corpus de travail. De nombreux travaux ont \u00e9t\u00e9 r\u00e9alis\u00e9s sur le calcul des r\u00e9sultats top-k. 7. REMARQUES CONCLUSIVES Les moteurs de recherche Web \u00e9laguent g\u00e9n\u00e9ralement leurs index invers\u00e9s \u00e0 grande \u00e9chelle afin de s'adapter \u00e0 d'\u00e9normes charges de requ\u00eates. Bien que cette approche puisse am\u00e9liorer les performances, en calculant les meilleurs r\u00e9sultats \u00e0 partir d'un index \u00e9lagu\u00e9, nous pouvons remarquer une d\u00e9gradation significative de la qualit\u00e9 des r\u00e9sultats. Dans cet article, nous avons fourni un cadre pour de nouvelles techniques d'\u00e9lagage et des algorithmes de calcul de r\u00e9ponses qui garantissent que les pages les plus correspondantes sont toujours plac\u00e9es en haut des r\u00e9sultats de recherche dans le bon ordre. Nous avons \u00e9tudi\u00e9 deux techniques d'\u00e9lagage, \u00e0 savoir l'\u00e9lagage bas\u00e9 sur des mots cl\u00e9s et bas\u00e9 sur des documents, ainsi que leur combinaison. Nos r\u00e9sultats exp\u00e9rimentaux ont d\u00e9montr\u00e9 que nos algorithmes peuvent \u00eatre utilis\u00e9s efficacement pour \u00e9laguer un index invers\u00e9 sans d\u00e9gradation de la qualit\u00e9 des r\u00e9sultats. En particulier, un index \u00e9lagu\u00e9 par mot cl\u00e9 peut garantir 73 % des requ\u00eates avec une taille de 30 % de l'index complet, tandis qu'un index \u00e9lagu\u00e9 par document peut garantir 68 % des requ\u00eates avec la m\u00eame taille. Lorsque nous combinons les deux algorithmes d'\u00e9lagage, nous pouvons garantir 60 % des requ\u00eates avec une taille d'index de 16 %. Nous esp\u00e9rons que nos travaux aideront les moteurs de recherche \u00e0 d\u00e9velopper des index meilleurs, plus rapides et plus efficaces et offriront ainsi une meilleure exp\u00e9rience de recherche aux utilisateurs sur le Web.", "keyphrases": ["moteur de recherche web", "indice invers\u00e9 \u00e0 grande \u00e9chelle", "charge de requ\u00eate", "indice de pruneau", "march\u00e9 de recherche en ligne", "d\u00e9gradation de la qualit\u00e9 des r\u00e9sultats", "prune-base perform optim", "technique de pruneau", "algorithme de calcul des r\u00e9sultats", "page la plus adapt\u00e9e", "meilleur r\u00e9sultat de recherche", "taille optimale"]}
{"file_name": "J-25", "text": "Paris de style bool\u00e9en\u00a0: un cadre pour la n\u00e9gociation de titres bas\u00e9s sur des formules logiques R\u00c9SUM\u00c9 Nous d\u00e9veloppons un cadre pour la n\u00e9gociation de titres compos\u00e9s\u00a0: des instruments financiers qui rapportent en fonction des r\u00e9sultats d'\u00e9nonc\u00e9s arbitraires dans la logique propositionnelle. L'achat ou la vente de titres -- qui peuvent \u00eatre consid\u00e9r\u00e9s comme un pari sur ou contre un r\u00e9sultat futur particulier -- permet aux agents \u00e0 la fois de couvrir le risque et de profiter -LRB- dans l'attente -RRB- de pr\u00e9dictions subjectives. Un march\u00e9 de valeurs mobili\u00e8res compos\u00e9 permet aux agents de parier sur des combinaisons bool\u00e9ennes arbitraires d'\u00e9v\u00e9nements, leur permettant ainsi d'atteindre plus \u00e9troitement leur exposition optimale au risque et permettant au march\u00e9 dans son ensemble d'atteindre plus \u00e9troitement l'optimum social. Le compromis pour permettre une telle expressivit\u00e9 r\u00e9side dans la complexit\u00e9 des probl\u00e8mes d'optimisation des agents et du commissaire-priseur. Nous d\u00e9veloppons et motivons le concept d'un march\u00e9 de titres compos\u00e9, en pr\u00e9sentant le cadre \u00e0 travers une s\u00e9rie de d\u00e9finitions formelles et d'exemples. Nous analysons ensuite en d\u00e9tail le probl\u00e8me d'appariement du commissaire-priseur. Nous montrons que, avec n \u00e9v\u00e9nements, le probl\u00e8me d\u2019appariement est co-NP-complet dans le cas divisible et \u03a3p2-complet dans le cas indivisible. Nous montrons que ce dernier r\u00e9sultat de duret\u00e9 reste valable m\u00eame sous de s\u00e9v\u00e8res restrictions linguistiques sur les offres. Avec log n \u00e9v\u00e9nements, le probl\u00e8me est polynomial dans le cas divisible et NP-complet dans le cas indivisible. Nous discutons bri\u00e8vement des algorithmes d\u2019appariement et des cas particuliers traitables. 1. INTRODUCTION Les march\u00e9s de valeurs mobili\u00e8res permettent effectivement aux traders de parier sur les r\u00e9sultats de propositions futures incertaines. La valeur \u00e9conomique des march\u00e9s de valeurs mobili\u00e8res est double. Premi\u00e8rement, ils permettent aux traders de couvrir les risques ou de s\u2019assurer contre des r\u00e9sultats ind\u00e9sirables. Par exemple, le propri\u00e9taire d'une action peut acheter une option de vente -LRB- le droit de vendre l'action \u00e0 un prix particulier -RRB- afin de s'assurer contre une baisse des actions. Deuxi\u00e8mement, les march\u00e9s de valeurs mobili\u00e8res permettent aux traders de sp\u00e9culer ou d\u2019obtenir un profit esp\u00e9r\u00e9 subjectif lorsque les prix du march\u00e9 ne refl\u00e8tent pas leur \u00e9valuation de la probabilit\u00e9 des r\u00e9sultats futurs. Par exemple, un trader peut acheter une option d'achat s'il estime que la probabilit\u00e9 que le prix de l'action sous-jacente augmente est \u00e9lev\u00e9e, quelle que soit l'exposition au risque li\u00e9 aux variations du prix de l'action. Parce que les traders peuvent r\u00e9aliser des b\u00e9n\u00e9fices s'ils peuvent proc\u00e9der \u00e0 des \u00e9valuations de probabilit\u00e9 efficaces, les prix sur les march\u00e9s financiers donnent souvent des pr\u00e9visions globales tr\u00e8s pr\u00e9cises d'\u00e9v\u00e9nements futurs -LSB- 10, 29, 27, 28 -RSB-. Les march\u00e9s de titres r\u00e9els ont des structures de gains complexes avec divers d\u00e9clencheurs. Cependant, ceux-ci peuvent tous \u00eatre mod\u00e9lis\u00e9s comme des collections de titres Arrow-Debreu plus basiques ou atomiques -LSB- 1, 8, 20 -RSB-. Une unit\u00e9 d'un titre Arrow-Debreu rapporte un dollar si et seulement si -LRB- iff -RRB- un \u00e9v\u00e9nement binaire correspondant se produit ; cela ne paie rien si l\u2019\u00e9v\u00e9nement ne se produit pas. Ainsi, par exemple, une unit\u00e9 d'un titre not\u00e9 -LRB- Acme100 -RRB- pourrait rapporter 1 $ si l'action d'Acme est sup\u00e9rieure \u00e0 100 $ le 4 janvier.2004. Une option d\u2019achat d\u2019actions Acme telle qu\u2019elle serait d\u00e9finie sur une bourse financi\u00e8re peut \u00eatre consid\u00e9r\u00e9e comme un portefeuille de ces titres atomiques.1 Dans cet article, nous d\u00e9veloppons et analysons un cadre pour la n\u00e9gociation sur des march\u00e9s de titres compos\u00e9s avec des gains conditionn\u00e9s \u00e0 des d\u00e9cisions arbitraires. combinaisons logiques d\u2019\u00e9v\u00e9nements, y compris les conditionnels. Par exemple, \u00e9tant donn\u00e9 les \u00e9v\u00e9nements binaires A, B et C, un trader pourrait ench\u00e9rir pour acheter trois unit\u00e9s d'un titre not\u00e9 -LRB- A n B \u00af VC -RRB- qui rapporte 1 $ si l'\u00e9v\u00e9nement compos\u00e9 A n B \u00af VC se produit pour trente cents chacun. Face \u00e0 un ensemble de telles offres, le commissaire-priseur est confront\u00e9 \u00e0 un probl\u00e8me d'appariement complexe pour d\u00e9cider quelles offres sont accept\u00e9es pour combien d'unit\u00e9s et \u00e0 quel prix. En r\u00e8gle g\u00e9n\u00e9rale, le commissaire-priseur ne cherche \u00e0 prendre aucun risque, se contentant de faire correspondre les transactions agr\u00e9ables entre les ench\u00e9risseurs, mais nous envisageons \u00e9galement des formulations alternatives dans lesquelles le commissaire-priseur agit comme un teneur de march\u00e9 dispos\u00e9 \u00e0 accepter certains risques. Nous examinons la complexit\u00e9 informatique du probl\u00e8me d'appariement du commissaire-priseur. Soit la longueur de la description de tous les titres disponibles O -LRB- n -RRB-. Avec n \u00e9v\u00e9nements, le probl\u00e8me d\u2019appariement est co-NP-complet dans le cas divisible et Ep2-complet dans le cas indivisible. Cette duret\u00e9 Ep2-compl\u00e8te reste valable m\u00eame lorsque le langage des ench\u00e8res est consid\u00e9rablement restreint. Avec log n \u00e9v\u00e9nements, le probl\u00e8me est polynomial dans le cas divisible et NP-complet dans le cas indivisible. La section 2 pr\u00e9sente certaines informations g\u00e9n\u00e9rales n\u00e9cessaires, la motivation et les travaux connexes. La section 3 d\u00e9crit formellement notre cadre pour les titres compos\u00e9s et d\u00e9finit le probl\u00e8me d'appariement du commissaire-priseur. La section 4 discute bri\u00e8vement des algorithmes naturels pour r\u00e9soudre le probl\u00e8me d'appariement. La section 5 prouve nos r\u00e9sultats centraux en mati\u00e8re de complexit\u00e9 informatique. La section 6 discute de la possibilit\u00e9 de cas particuliers traitables. La section 7 se termine par un r\u00e9sum\u00e9 et quelques id\u00e9es d'orientations futures. 2. PR\u00c9LIMINAIRES 2.1 Context et notation Dans ce monde simple, il y a quatre \u00e9tats futurs possibles -- toutes les combinaisons possibles des r\u00e9sultats des \u00e9v\u00e9nements binaires : frapp\u00e9 n acme100, frapp\u00e9 n acme100, frapp\u00e9 n acme100, frapp\u00e9 n acme100. La couverture du risque peut \u00eatre consid\u00e9r\u00e9e comme une action consistant \u00e0 d\u00e9placer de l\u2019argent entre diff\u00e9rents \u00e9tats futurs possibles. Par exemple, insur1 Techniquement, une option est un portefeuille d'une infinit\u00e9 de titres atomiques, bien qu'elle puisse \u00eatre mod\u00e9lis\u00e9e approximativement avec un nombre fini. Le fait de transf\u00e9rer de l'argent dans sa maison depuis les futurs \u00c9tats o\u00f9 il a \u00e9t\u00e9 frapp\u00e9 n'est pas fid\u00e8le aux \u00c9tats o\u00f9 il se trouve. La vente d'un titre not\u00e9 -LRB- acme100 -RRB- -- qui rapporte 1 $ si l'\u00e9v\u00e9nement acme100 se produit -- transf\u00e8re de l'argent des futurs \u00c9tats o\u00f9 le prix d'Acme est sup\u00e9rieur \u00e0 100 $ le 4 janvier vers les \u00c9tats o\u00f9 ce n'est pas le cas. La sp\u00e9culation est \u00e9galement un acte de transfert d\u2019argent entre des \u00c9tats futurs, bien que g\u00e9n\u00e9ralement associ\u00e9 \u00e0 la maximisation du rendement attendu plut\u00f4t qu\u2019\u00e0 la r\u00e9duction des risques. Par exemple, parier sur une \u00e9quipe de football d\u00e9place l'argent de l'\u00e9tat \u00ab\u00a0l'\u00e9quipe perd\u00a0\u00bb vers l'\u00e9tat \u00ab\u00a0l'\u00e9quipe gagne\u00a0\u00bb.Tous les r\u00e9sultats futurs possibles forment un espace d\u2019\u00e9tats \u03a9, constitu\u00e9 d\u2019\u00e9tats mutuellement exclusifs et exhaustifs \u03c9 E \u03a9. Souvent, une fa\u00e7on plus naturelle de penser aux r\u00e9sultats futurs possibles consiste \u00e0 consid\u00e9rer un espace d\u2019\u00e9v\u00e9nements A d\u2019\u00e9v\u00e9nements AEA lin\u00e9airement ind\u00e9pendants qui peuvent se chevaucher arbitrairement. Ainsi, dans notre exemple de jouet, frapp\u00e9 n acme100 est l'un des quatre \u00e9tats disjoints, tandis que frapp\u00e9 est l'un des deux \u00e9v\u00e9nements. Notez qu'un ensemble de n \u00e9v\u00e9nements lin\u00e9airement ind\u00e9pendants d\u00e9finit un espace d'\u00e9tat \u03a9 de taille 2'' compos\u00e9 de toutes les combinaisons possibles de r\u00e9sultats d'\u00e9v\u00e9nements. \u00c0 l\u2019inverse, tout espace d\u2019\u00e9tat \u03a9 peut \u00eatre pris en compte dans les \u00e9v\u00e9nements -LSB- log l\u03a9ll. Supposons que A couvre de mani\u00e8re exhaustive tous les r\u00e9sultats futurs significatifs -LRB-, c'est-\u00e0-dire couvre toutes les \u00e9ventualit\u00e9s contre lesquelles les agents pourraient souhaiter se couvrir et/ou sp\u00e9culer sur -RRB-. Ensuite, l'existence de 2 titres lin\u00e9airement ind\u00e9pendants \u2013 appel\u00e9s march\u00e9 complet \u2013 permet aux agents de r\u00e9partir arbitrairement leur richesse entre les \u00c9tats futurs.2 Un agent peut cr\u00e9er toute couverture ou sp\u00e9culation qu'il d\u00e9sire. Dans des conditions classiques, les agents n\u00e9gociant sur un march\u00e9 complet forment un \u00e9quilibre dans lequel le risque est r\u00e9parti de mani\u00e8re Pareto optimale. Si le march\u00e9 est incomplet, c'est-\u00e0-dire qu'il est constitu\u00e9 de moins de 2'' de titres lin\u00e9airement ind\u00e9pendants, alors en g\u00e9n\u00e9ral les agents ne peuvent pas construire de couvertures arbitraires et les allocations d'\u00e9quilibre peuvent \u00eatre non optimales -LSB- 1, 8, 19, 20 -RSB-. Dans des contexts r\u00e9els, le nombre d\u2019\u00e9v\u00e9nements significatifs n est grand et le nombre de titres requis pour l\u2019exhaustivit\u00e9 est donc insoluble. Aucun march\u00e9 v\u00e9ritablement complet n\u2019existe ni n\u2019existera jamais. L\u2019une des motivations derri\u00e8re les march\u00e9s de titres compos\u00e9s est de fournir un m\u00e9canisme qui prend en charge le plus grand transfert de risque en utilisant le moins de transactions possible. Les titres compos\u00e9s permettent un haut degr\u00e9 d'expressivit\u00e9 dans la construction des offres. Le compromis pour une expressivit\u00e9 accrue est une complexit\u00e9 informatique accrue, tant du point de vue de l'ench\u00e9risseur que du commissaire-priseur. 2.2 Travaux connexes La qu\u00eate visant \u00e0 r\u00e9duire le nombre d'instruments financiers requis pour soutenir une allocation optimale des risques date du travail original d'Arrow -LSB- 1 -RSB-. L'exigence \u00e9nonc\u00e9e ci-dessus de \u00ab seulement \u00ab 2 \u00bb titres lin\u00e9airement ind\u00e9pendants est en soi une r\u00e9duction de la formulation la plus simple. Dans une \u00e9conomie avec k biens standards, le march\u00e9 complet le plus simple contient k \u2022 2 titres, chacun rapportant un bien sous une seule r\u00e9alisation d'\u00c9tat. Arrow -LSB- 1 -RSB- a montr\u00e9 qu'un march\u00e9 o\u00f9 les titres et les biens sont essentiellement s\u00e9par\u00e9s, avec des titres de 2 pouces payants en un seul bien num\u00e9raire plus k march\u00e9s au comptant pour les biens standard, est \u00e9galement complet. Pour nos besoins, nous devons consid\u00e9rer uniquement le march\u00e9 des valeurs mobili\u00e8res. 2Par titres lin\u00e9airement ind\u00e9pendants, nous entendons que les vecteurs de gains dans tous les \u00e9tats futurs de ces titres sont lin\u00e9airement ind\u00e9pendants. Varian -LSB- 34 -RSB- montre qu'un march\u00e9 complet peut \u00eatre construit en utilisant moins de 2n titres,remplacer les titres manquants par des options. N\u00e9anmoins, le nombre d\u2019instruments financiers lin\u00e9airement ind\u00e9pendants \u2013 titres plus options \u2013 doit \u00eatre de 2n pour garantir l\u2019exhaustivit\u00e9. Les auteurs montrent que dans certains cas, le march\u00e9 peut \u00eatre structur\u00e9 et \u00ab compact\u00e9 \u00bb par analogie avec les repr\u00e9sentations en r\u00e9seau bay\u00e9sien des distributions de probabilit\u00e9 conjointes -LSB- 23 -RSB-. Ils montrent que si les ind\u00e9pendances neutres au risque de tous les agents concordent avec les ind\u00e9pendances cod\u00e9es dans la structure du march\u00e9, alors le march\u00e9 est op\u00e9rationnel sur le plan op\u00e9rationnel. Pour des ensembles d\u2019agents ayant tous une aversion absolue au risque constante, un accord sur les ind\u00e9pendances de Markov est suffisant. Bossaerts, Fine et Ledyard -LSB- 2 -RSB- d\u00e9veloppent un m\u00e9canisme qu'ils appellent trading \u00e0 valeur combin\u00e9e -LRB-CVT-RRB- qui permet aux traders d'ordonner un portefeuille arbitraire de titres en une seule offre, plut\u00f4t que de diviser l'ordre en une s\u00e9quence d'offres sur des titres individuels. Si l'ordre de portefeuille est accept\u00e9, toutes les transactions implicites sur des titres individuels sont ex\u00e9cut\u00e9es simultan\u00e9ment, \u00e9liminant ainsi le risque d'ex\u00e9cution que les prix changent au milieu d'une s\u00e9quence d'ordres planifi\u00e9e. Les auteurs m\u00e8nent des exp\u00e9riences en laboratoire montrant que, m\u00eame sur des march\u00e9s restreints o\u00f9 les \u00e9changes s\u00e9quentiels ordinaires \u00e9chouent, la CVT permet une tarification et une allocation efficaces. Notez que la CVT diff\u00e8re consid\u00e9rablement du trading de titres compos\u00e9s. CVT permet la n\u00e9gociation instantan\u00e9e de toute combinaison lin\u00e9aire de titres, tandis que les titres compos\u00e9s permettent des titres plus expressifs pouvant coder des combinaisons bool\u00e9ennes d'\u00e9v\u00e9nements non lin\u00e9aires. Par exemple, CVT peut permettre \u00e0 un agent d'ordonner des titres -LRB- A -RRB- et -LRB- B -RRB- dans un lot qui rapporte comme une combinaison lin\u00e9aire de A et B,3 mais CVT ne permettra pas construction d'un titre compos\u00e9 -LRB- A n B -RRB- qui rapporte 1 $ si A et B se produisent \u00e0 la fois, ou d'un titre compos\u00e9 -LRB- AIB -RRB-. Les ench\u00e8res combinatoires permettent aux ench\u00e9risseurs d'attribuer des valeurs distinctes \u00e0 tous les lots de biens possibles plut\u00f4t qu'\u00e0 des biens individuels. Les titres compos\u00e9s diff\u00e8rent des ench\u00e8res combinatoires par leur concept et leur complexit\u00e9. Les titres compos\u00e9s permettent aux ench\u00e9risseurs de construire un pari arbitraire sur l'un des 22n \u00e9v\u00e9nements compos\u00e9s possibles, exprimables comme fonctions logiques des n \u00e9v\u00e9nements de base, conditionnels \u00e0 tout autre des 22n \u00e9v\u00e9nements compos\u00e9s. Les agents optimisent en fonction de leurs propres probabilit\u00e9s subjectives et de leur attitude face au risque -LRB- et en g\u00e9n\u00e9ral, de leurs croyances sur les croyances et utilit\u00e9s des autres agents, \u00e0 l'infini -RRB-. Le probl\u00e8me central du commissaire-priseur est d'identifier les opportunit\u00e9s d'arbitrage : c'est-\u00e0-dire d'associer les paris sans prendre de risque. Les ench\u00e8res combinatoires, quant \u00e0 elles, permettent d\u2019ench\u00e9rir sur n\u2019importe lequel des 2n lots de n biens. l\u2019incertitude \u2013 et donc le risque \u2013 n\u2019est pas prise en compte. Le probl\u00e8me central du commissaire-priseur est de maximiser le bien-\u00eatre social. Notez \u00e9galement que les probl\u00e8mes se situent dans diff\u00e9rentes classes de complexit\u00e9.Alors que la validation d'une ench\u00e8re combinatoire est polynomiale dans le cas divisible et NP-compl\u00e8te dans le cas indivisible, l'appariement dans un march\u00e9 de titres compos\u00e9 est NP-complet dans le cas divisible et Ep2-complet dans le cas indivisible. En fait, m\u00eame le probl\u00e8me de d\u00e9cider si deux offres sur des titres compos\u00e9s correspondent, m\u00eame dans le cas divisible, est NP-complet -LRB- voir Section 5.2 -RRB-. Il y a un sens dans lequel il est possible de traduire notre probl\u00e8me d\u2019appariement pour les titres compos\u00e9s en un probl\u00e8me analogue pour la compensation d\u2019\u00e9changes combinatoires bilat\u00e9raux -LSB-31-RSB- de taille exponentielle. Plus pr\u00e9cis\u00e9ment, si nous consid\u00e9rons le paiement dans un \u00e9tat particulier comme un bien, alors les titres compos\u00e9s peuvent \u00eatre consid\u00e9r\u00e9s comme des paquets de -LRB- quantit\u00e9s fractionnaires de -RRB- de tels biens. La contrainte de bilan mati\u00e8re \u00e0 laquelle est confront\u00e9 le commissaire-priseur combinatoire correspond \u00e0 une restriction selon laquelle le commissaire-priseur \u00e0 s\u00e9curit\u00e9 compos\u00e9e ne peut assumer aucun risque. Notez que cette traduction n\u2019est pas du tout utile pour r\u00e9soudre le probl\u00e8me d\u2019appariement de s\u00e9curit\u00e9 compos\u00e9e, car l\u2019\u00e9change combinatoire r\u00e9sultant a un nombre exponentiel de biens. Hanson -LSB- 15 -RSB- d\u00e9veloppe un m\u00e9canisme de march\u00e9 appel\u00e9 r\u00e8gle de notation du march\u00e9 qui est particuli\u00e8rement bien adapt\u00e9 pour permettre des paris sur un nombre combinatoire de r\u00e9sultats. Le m\u00e9canisme maintient une distribution de probabilit\u00e9 conjointe sur tous les 2n \u00e9tats, soit explicitement, soit implicitement en utilisant un r\u00e9seau bay\u00e9sien ou une autre repr\u00e9sentation compacte. Dans la limite d\u2019un seul trader, le m\u00e9canisme se comporte comme une r\u00e8gle de notation, adapt\u00e9e pour interroger un seul agent sur sa distribution de probabilit\u00e9. Dans la limite de nombreux traders, il produit une estimation combin\u00e9e. \u00c9tant donn\u00e9 que le march\u00e9 dispose toujours d\u2019un ensemble complet de prix affich\u00e9s pour tous les r\u00e9sultats possibles, le m\u00e9canisme \u00e9vite le probl\u00e8me des march\u00e9s \u00e9troits, ou d\u2019illiquidit\u00e9, qui affecte n\u00e9cessairement tout march\u00e9 contenant un nombre exponentiel d\u2019investissements alternatifs. Les offres sur des titres compos\u00e9s peuvent \u00eatre consid\u00e9r\u00e9es comme des expressions d'in\u00e9galit\u00e9s probabilistes : par exemple, une offre d'achat de -LRB- A n B -RRB- au prix 0,3 est une affirmation selon laquelle la probabilit\u00e9 de A n B est sup\u00e9rieure \u00e0 0,3. Si un ensemble d\u2019offres unitaires correspond \u00e0 un ensemble d\u2019in\u00e9galit\u00e9s probabilistes incoh\u00e9rentes, alors il y a une correspondance. Nous abordons ces probl\u00e8mes ci-dessous.La contrainte de bilan mati\u00e8re \u00e0 laquelle est confront\u00e9 le commissaire-priseur combinatoire correspond \u00e0 une restriction selon laquelle le commissaire-priseur \u00e0 s\u00e9curit\u00e9 compos\u00e9e ne peut assumer aucun risque. Notez que cette traduction n\u2019est pas du tout utile pour r\u00e9soudre le probl\u00e8me d\u2019appariement de s\u00e9curit\u00e9 compos\u00e9e, car l\u2019\u00e9change combinatoire r\u00e9sultant a un nombre exponentiel de biens. Hanson -LSB- 15 -RSB- d\u00e9veloppe un m\u00e9canisme de march\u00e9 appel\u00e9 r\u00e8gle de notation du march\u00e9 qui est particuli\u00e8rement bien adapt\u00e9 pour permettre des paris sur un nombre combinatoire de r\u00e9sultats. Le m\u00e9canisme maintient une distribution de probabilit\u00e9 conjointe sur tous les 2n \u00e9tats, soit explicitement, soit implicitement en utilisant un r\u00e9seau bay\u00e9sien ou une autre repr\u00e9sentation compacte. Dans la limite d\u2019un seul trader, le m\u00e9canisme se comporte comme une r\u00e8gle de notation, adapt\u00e9e pour interroger un seul agent sur sa distribution de probabilit\u00e9. Dans la limite de nombreux traders, il produit une estimation combin\u00e9e. \u00c9tant donn\u00e9 que le march\u00e9 dispose toujours d\u2019un ensemble complet de prix affich\u00e9s pour tous les r\u00e9sultats possibles, le m\u00e9canisme \u00e9vite le probl\u00e8me des march\u00e9s \u00e9troits, ou d\u2019illiquidit\u00e9, qui affecte n\u00e9cessairement tout march\u00e9 contenant un nombre exponentiel d\u2019investissements alternatifs. Les offres sur des titres compos\u00e9s peuvent \u00eatre consid\u00e9r\u00e9es comme des expressions d'in\u00e9galit\u00e9s probabilistes : par exemple, une offre d'achat de -LRB- A n B -RRB- au prix 0,3 est une affirmation selon laquelle la probabilit\u00e9 de A n B est sup\u00e9rieure \u00e0 0,3. Si un ensemble d\u2019offres unitaires correspond \u00e0 un ensemble d\u2019in\u00e9galit\u00e9s probabilistes incoh\u00e9rentes, alors il y a une correspondance. Nous abordons ces probl\u00e8mes ci-dessous.La contrainte de bilan mati\u00e8re \u00e0 laquelle est confront\u00e9 le commissaire-priseur combinatoire correspond \u00e0 une restriction selon laquelle le commissaire-priseur \u00e0 s\u00e9curit\u00e9 compos\u00e9e ne peut assumer aucun risque. Notez que cette traduction n\u2019est pas du tout utile pour r\u00e9soudre le probl\u00e8me d\u2019appariement de s\u00e9curit\u00e9 compos\u00e9e, car l\u2019\u00e9change combinatoire r\u00e9sultant a un nombre exponentiel de biens. Hanson -LSB- 15 -RSB- d\u00e9veloppe un m\u00e9canisme de march\u00e9 appel\u00e9 r\u00e8gle de notation du march\u00e9 qui est particuli\u00e8rement bien adapt\u00e9 pour permettre des paris sur un nombre combinatoire de r\u00e9sultats. Le m\u00e9canisme maintient une distribution de probabilit\u00e9 conjointe sur tous les 2n \u00e9tats, soit explicitement, soit implicitement en utilisant un r\u00e9seau bay\u00e9sien ou une autre repr\u00e9sentation compacte. Dans la limite d\u2019un seul trader, le m\u00e9canisme se comporte comme une r\u00e8gle de notation, adapt\u00e9e pour interroger un seul agent sur sa distribution de probabilit\u00e9. Dans la limite de nombreux traders, il produit une estimation combin\u00e9e. \u00c9tant donn\u00e9 que le march\u00e9 dispose toujours d\u2019un ensemble complet de prix affich\u00e9s pour tous les r\u00e9sultats possibles, le m\u00e9canisme \u00e9vite le probl\u00e8me des march\u00e9s \u00e9troits, ou d\u2019illiquidit\u00e9, qui affecte n\u00e9cessairement tout march\u00e9 contenant un nombre exponentiel d\u2019investissements alternatifs. Les offres sur des titres compos\u00e9s peuvent \u00eatre consid\u00e9r\u00e9es comme des expressions d'in\u00e9galit\u00e9s probabilistes : par exemple, une offre d'achat de -LRB- A n B -RRB- au prix 0,3 est une affirmation selon laquelle la probabilit\u00e9 de A n B est sup\u00e9rieure \u00e0 0,3. Si un ensemble d\u2019offres unitaires correspond \u00e0 un ensemble d\u2019in\u00e9galit\u00e9s probabilistes incoh\u00e9rentes, alors il y a une correspondance. Nous abordons ces probl\u00e8mes ci-dessous.Nous abordons ces probl\u00e8mes ci-dessous.Nous abordons ces probl\u00e8mes ci-dessous.", "keyphrases": ["pari combinatoire", "effet probable \u00e9valuer", "combinaison logique arbitraire", "s\u00e9curit\u00e9 compos\u00e9e", "r\u00e9seau bay\u00e9sien", "commerce \u00e0 valeur combin\u00e9e", "algorithme approximatif", "vecteur de paiement", "cas traitable", "base s\u00e9curis\u00e9e"]}
{"file_name": "J-15", "text": "D\u00e9composition g\u00e9n\u00e9ralis\u00e9e de la valeur et ench\u00e8res multi-attributs structur\u00e9es R\u00c9SUM\u00c9 Les m\u00e9canismes d'ench\u00e8res multi-attributs restent g\u00e9n\u00e9ralement agnostiques quant aux pr\u00e9f\u00e9rences des traders, ou pr\u00e9supposent des formes tr\u00e8s restrictives, telles que l'additivit\u00e9 totale. Les pr\u00e9f\u00e9rences r\u00e9elles pr\u00e9sentent souvent des d\u00e9pendances entre les attributs, mais peuvent poss\u00e9der une certaine structure qui peut \u00eatre utilement exploit\u00e9e pour rationaliser la communication et simplifier le fonctionnement d'une ench\u00e8re multi-attributs. Nous d\u00e9veloppons une telle structure en utilisant la th\u00e9orie des fonctions de valeur mesurables, une repr\u00e9sentation cardinale d'utilit\u00e9 bas\u00e9e sur un ordre sous-jacent sur les diff\u00e9rences de pr\u00e9f\u00e9rences. Un ensemble de relations d'ind\u00e9pendance conditionnelle locale sur de telles diff\u00e9rences prend en charge une repr\u00e9sentation de pr\u00e9f\u00e9rence additive g\u00e9n\u00e9ralis\u00e9e, qui d\u00e9compose l'utilit\u00e9 en groupes superpos\u00e9s d'attributs associ\u00e9s. Nous introduisons un m\u00e9canisme d'ench\u00e8res it\u00e9ratif qui maintient les prix sur des groupes locaux d'attributs plut\u00f4t que sur l'espace complet des configurations conjointes. Lorsque les pr\u00e9f\u00e9rences des traders sont coh\u00e9rentes avec la structure additive g\u00e9n\u00e9ralis\u00e9e des ench\u00e8res, le m\u00e9canisme produit des allocations approximativement optimales, \u00e0 des prix VCG approximatifs. 1. INTRODUCTION Les m\u00e9canismes commerciaux multi-attributs \u00e9tendent les m\u00e9canismes traditionnels ax\u00e9s uniquement sur le prix en facilitant la n\u00e9gociation sur un ensemble d'attributs pr\u00e9d\u00e9finis repr\u00e9sentant divers aspects non li\u00e9s au prix de la transaction. Plut\u00f4t que de n\u00e9gocier un bien ou un service enti\u00e8rement d\u00e9fini, un m\u00e9canisme multi-attributs retarde l\u2019engagement sur des configurations sp\u00e9cifiques jusqu\u2019\u00e0 ce que les candidats les plus prometteurs soient identifi\u00e9s. Par exemple, le service des achats d'une entreprise peut utiliser une vente aux ench\u00e8res multi-attributs pour s\u00e9lectionner un fournisseur de disques durs. Afin de prendre en compte les pr\u00e9f\u00e9rences des traders, le m\u00e9canisme d'ench\u00e8res doit extraire des informations \u00e9valuatives sur un domaine complexe de configurations multidimensionnelles. Construire et communiquer une sp\u00e9cification de pr\u00e9f\u00e9rence compl\u00e8te peut repr\u00e9senter une lourde charge, m\u00eame pour un nombre mod\u00e9r\u00e9 d'attributs. Par cons\u00e9quent, les ench\u00e8res multi-attributs pratiques doivent soit s'adapter \u00e0 des sp\u00e9cifications partielles, soit prendre en charge une expression compacte des pr\u00e9f\u00e9rences sous une forme simplifi\u00e9e. La forme multi-attributs la plus populaire \u00e0 adopter est de loin la plus simple : une repr\u00e9sentation additive o\u00f9 la valeur globale est une combinaison lin\u00e9aire de valeurs associ\u00e9es \u00e0 chaque attribut. Par exemple, plusieurs propositions r\u00e9centes d'ench\u00e8res it\u00e9ratives multi-attributs -LSB- 2, 3, 8, 19 -RSB- n\u00e9cessitent des repr\u00e9sentations de pr\u00e9f\u00e9rences additives. Une telle additivit\u00e9 r\u00e9duit exponentiellement la complexit\u00e9 de la sp\u00e9cification des pr\u00e9f\u00e9rences -LRB- par rapport au cas discret g\u00e9n\u00e9ral -RRB-, mais exclut l'expression de toute interd\u00e9pendance entre les attributs. Toutefois, dans la pratique, les interd\u00e9pendances entre attributs naturels sont assez courantes. Dans de tels cas, une fonction de valeur additive peut ne pas \u00eatre en mesure de fournir m\u00eame une approximation raisonnable des pr\u00e9f\u00e9rences r\u00e9elles. En revanche, les mod\u00e8les enti\u00e8rement g\u00e9n\u00e9raux sont insolubles,et il est raisonnable de s\u2019attendre \u00e0 ce que les pr\u00e9f\u00e9rences multiattributs pr\u00e9sentent une certaine structure. Notre objectif est donc d\u2019identifier les repr\u00e9sentations structur\u00e9es les plus subtiles mais les plus largement applicables, et d\u2019exploiter ces propri\u00e9t\u00e9s des pr\u00e9f\u00e9rences dans les m\u00e9canismes commerciaux. Nous proposons un m\u00e9canisme d\u2019ench\u00e8res it\u00e9ratif bas\u00e9 sur une telle structure de pr\u00e9f\u00e9rence flexible. Notre approche s\u2019inspire de la conception d\u2019une ench\u00e8re it\u00e9rative d\u2019approvisionnement multi-attributs pour les pr\u00e9f\u00e9rences additives, due \u00e0 Parkes et Kalagnanam -LRB- PK -RRB- -LSB- 19 -RSB-. PK propose deux types d'ench\u00e8res it\u00e9ratives : la premi\u00e8re -LRB-NLD-RRB- ne fait aucune hypoth\u00e8se sur les pr\u00e9f\u00e9rences des traders, et permet aux vendeurs d'ench\u00e9rir sur l'ensemble de l'espace d'attributs multidimensionnel. \u00c9tant donn\u00e9 que NLD maintient une structure de prix exponentielle, il ne convient qu'aux petits domaines. L'autre ench\u00e8re -LRB- AD -RRB- suppose des fonctions additives d'\u00e9valuation de l'acheteur et de co\u00fbt du vendeur. Il collecte les offres de vente par niveau d'attribut et pour une seule dur\u00e9e de remise. Le prix d'une configuration est d\u00e9fini comme la somme des prix des niveaux d'attributs choisis moins la remise. L'ench\u00e8re que nous proposons prend \u00e9galement en charge des espaces de prix compacts, mais pour des niveaux de groupes d'attributs plut\u00f4t que des singletons. Compte tenu de ses racines dans la th\u00e9orie de l'utilit\u00e9 multiattribute -LSB- 13 -RSB-, la condition GAI est d\u00e9finie par rapport \u00e0 la fonction d'utilit\u00e9 attendue. Son application pour mod\u00e9liser les valeurs de certains r\u00e9sultats n\u00e9cessite donc une r\u00e9interpr\u00e9tation de la pr\u00e9f\u00e9rence dans des conditions de certitude. \u00c0 cette fin, nous exploitons le fait que les r\u00e9sultats des ench\u00e8res sont associ\u00e9s \u00e0 des prix continus, qui fournissent une \u00e9chelle naturelle pour \u00e9valuer l\u2019ampleur des pr\u00e9f\u00e9rences. Nous pr\u00e9sentons d'abord un cadre de repr\u00e9sentation des pr\u00e9f\u00e9rences qui capture, en plus des simples classements parmi les valeurs de configuration des attributs, la diff\u00e9rence dans la volont\u00e9 de payer -LRB- wtp -RRB- pour chacune. Ensuite, nous construisons un lien direct et formellement justifi\u00e9 entre les d\u00e9clarations de pr\u00e9f\u00e9rences sur les r\u00e9sultats tarif\u00e9s et une d\u00e9composition additive g\u00e9n\u00e9ralis\u00e9e de la fonction wtp. Apr\u00e8s avoir d\u00e9fini cette infrastructure, nous utilisons cet outil de repr\u00e9sentation pour le d\u00e9veloppement d'un m\u00e9canisme d'ench\u00e8res it\u00e9ratives multi-attributs qui permet aux traders d'exprimer leurs pr\u00e9f\u00e9rences complexes au format GAI. Nous \u00e9tudions ensuite les propri\u00e9t\u00e9s d'allocation, de calcul et pratiques de l'ench\u00e8re. Dans la section 2, nous pr\u00e9sentons les informations essentielles sur notre cadre de repr\u00e9sentation, la fonction de valeur mesurable -LRB-MVF-RRB-. La section 3 d\u00e9veloppe de nouvelles structures multiattributs pour MVF, prenant en charge les d\u00e9compositions additives g\u00e9n\u00e9ralis\u00e9es. Nous montrons ensuite l\u2019applicabilit\u00e9 du cadre th\u00e9orique aux pr\u00e9f\u00e9rences en mati\u00e8re de trading. Le reste de l\u2019article est consacr\u00e9 au m\u00e9canisme d\u2019ench\u00e8res propos\u00e9.Notre approche s\u2019inspire de la conception d\u2019une ench\u00e8re it\u00e9rative d\u2019approvisionnement multi-attributs pour les pr\u00e9f\u00e9rences additives, due \u00e0 Parkes et Kalagnanam -LRB- PK -RRB- -LSB- 19 -RSB-. PK propose deux types d'ench\u00e8res it\u00e9ratives : la premi\u00e8re -LRB-NLD-RRB- ne fait aucune hypoth\u00e8se sur les pr\u00e9f\u00e9rences des traders, et permet aux vendeurs d'ench\u00e9rir sur l'ensemble de l'espace d'attributs multidimensionnel. \u00c9tant donn\u00e9 que NLD maintient une structure de prix exponentielle, il ne convient qu'aux petits domaines. L'autre ench\u00e8re -LRB- AD -RRB- suppose des fonctions additives d'\u00e9valuation de l'acheteur et de co\u00fbt du vendeur. Il collecte les offres de vente par niveau d'attribut et pour une seule dur\u00e9e de remise. Le prix d'une configuration est d\u00e9fini comme la somme des prix des niveaux d'attributs choisis moins la remise. L'ench\u00e8re que nous proposons prend \u00e9galement en charge des espaces de prix compacts, mais pour des niveaux de groupes d'attributs plut\u00f4t que des singletons. Compte tenu de ses racines dans la th\u00e9orie de l'utilit\u00e9 multiattribute -LSB- 13 -RSB-, la condition GAI est d\u00e9finie par rapport \u00e0 la fonction d'utilit\u00e9 attendue. Son application pour mod\u00e9liser les valeurs de certains r\u00e9sultats n\u00e9cessite donc une r\u00e9interpr\u00e9tation de la pr\u00e9f\u00e9rence dans des conditions de certitude. \u00c0 cette fin, nous exploitons le fait que les r\u00e9sultats des ench\u00e8res sont associ\u00e9s \u00e0 des prix continus, qui fournissent une \u00e9chelle naturelle pour \u00e9valuer l\u2019ampleur des pr\u00e9f\u00e9rences. Nous pr\u00e9sentons d'abord un cadre de repr\u00e9sentation des pr\u00e9f\u00e9rences qui capture, en plus des simples classements parmi les valeurs de configuration des attributs, la diff\u00e9rence dans la volont\u00e9 de payer -LRB- wtp -RRB- pour chacune. Ensuite, nous construisons un lien direct et formellement justifi\u00e9 entre les d\u00e9clarations de pr\u00e9f\u00e9rences sur les r\u00e9sultats tarif\u00e9s et une d\u00e9composition additive g\u00e9n\u00e9ralis\u00e9e de la fonction wtp. Apr\u00e8s avoir d\u00e9fini cette infrastructure, nous utilisons cet outil de repr\u00e9sentation pour le d\u00e9veloppement d'un m\u00e9canisme d'ench\u00e8res it\u00e9ratives multi-attributs qui permet aux traders d'exprimer leurs pr\u00e9f\u00e9rences complexes au format GAI. Nous \u00e9tudions ensuite les propri\u00e9t\u00e9s d'allocation, de calcul et pratiques de l'ench\u00e8re. Dans la section 2, nous pr\u00e9sentons les informations essentielles sur notre cadre de repr\u00e9sentation, la fonction de valeur mesurable -LRB-MVF-RRB-. La section 3 d\u00e9veloppe de nouvelles structures multiattributs pour MVF, prenant en charge les d\u00e9compositions additives g\u00e9n\u00e9ralis\u00e9es. Nous montrons ensuite l\u2019applicabilit\u00e9 du cadre th\u00e9orique aux pr\u00e9f\u00e9rences en mati\u00e8re de trading. Le reste de l\u2019article est consacr\u00e9 au m\u00e9canisme d\u2019ench\u00e8res propos\u00e9.Notre approche s\u2019inspire de la conception d\u2019une ench\u00e8re it\u00e9rative d\u2019approvisionnement multi-attributs pour les pr\u00e9f\u00e9rences additives, due \u00e0 Parkes et Kalagnanam -LRB- PK -RRB- -LSB- 19 -RSB-. PK propose deux types d'ench\u00e8res it\u00e9ratives : la premi\u00e8re -LRB-NLD-RRB- ne fait aucune hypoth\u00e8se sur les pr\u00e9f\u00e9rences des traders, et permet aux vendeurs d'ench\u00e9rir sur l'ensemble de l'espace d'attributs multidimensionnel. \u00c9tant donn\u00e9 que NLD maintient une structure de prix exponentielle, il ne convient qu'aux petits domaines. L'autre ench\u00e8re -LRB- AD -RRB- suppose des fonctions additives d'\u00e9valuation de l'acheteur et de co\u00fbt du vendeur. Il collecte les offres de vente par niveau d'attribut et pour une seule dur\u00e9e de remise. Le prix d'une configuration est d\u00e9fini comme la somme des prix des niveaux d'attributs choisis moins la remise. L'ench\u00e8re que nous proposons prend \u00e9galement en charge des espaces de prix compacts, mais pour des niveaux de groupes d'attributs plut\u00f4t que des singletons. Compte tenu de ses racines dans la th\u00e9orie de l'utilit\u00e9 multiattribute -LSB- 13 -RSB-, la condition GAI est d\u00e9finie par rapport \u00e0 la fonction d'utilit\u00e9 attendue. Son application pour mod\u00e9liser les valeurs de certains r\u00e9sultats n\u00e9cessite donc une r\u00e9interpr\u00e9tation de la pr\u00e9f\u00e9rence dans des conditions de certitude. \u00c0 cette fin, nous exploitons le fait que les r\u00e9sultats des ench\u00e8res sont associ\u00e9s \u00e0 des prix continus, qui fournissent une \u00e9chelle naturelle pour \u00e9valuer l\u2019ampleur des pr\u00e9f\u00e9rences. Nous pr\u00e9sentons d'abord un cadre de repr\u00e9sentation des pr\u00e9f\u00e9rences qui capture, en plus des simples classements parmi les valeurs de configuration des attributs, la diff\u00e9rence dans la volont\u00e9 de payer -LRB- wtp -RRB- pour chacune. Ensuite, nous construisons un lien direct et formellement justifi\u00e9 entre les d\u00e9clarations de pr\u00e9f\u00e9rences sur les r\u00e9sultats tarif\u00e9s et une d\u00e9composition additive g\u00e9n\u00e9ralis\u00e9e de la fonction wtp. Apr\u00e8s avoir d\u00e9fini cette infrastructure, nous utilisons cet outil de repr\u00e9sentation pour le d\u00e9veloppement d'un m\u00e9canisme d'ench\u00e8res it\u00e9ratives multi-attributs qui permet aux traders d'exprimer leurs pr\u00e9f\u00e9rences complexes au format GAI. Nous \u00e9tudions ensuite les propri\u00e9t\u00e9s d'allocation, de calcul et pratiques de l'ench\u00e8re. Dans la section 2, nous pr\u00e9sentons les informations essentielles sur notre cadre de repr\u00e9sentation, la fonction de valeur mesurable -LRB-MVF-RRB-. La section 3 d\u00e9veloppe de nouvelles structures multiattributs pour MVF, prenant en charge les d\u00e9compositions additives g\u00e9n\u00e9ralis\u00e9es. Nous montrons ensuite l\u2019applicabilit\u00e9 du cadre th\u00e9orique aux pr\u00e9f\u00e9rences en mati\u00e8re de trading. Le reste de l\u2019article est consacr\u00e9 au m\u00e9canisme d\u2019ench\u00e8res propos\u00e9.Le prix d'une configuration est d\u00e9fini comme la somme des prix des niveaux d'attributs choisis moins la remise. L'ench\u00e8re que nous proposons prend \u00e9galement en charge des espaces de prix compacts, mais pour des niveaux de groupes d'attributs plut\u00f4t que des singletons. Compte tenu de ses racines dans la th\u00e9orie de l'utilit\u00e9 multiattribute -LSB- 13 -RSB-, la condition GAI est d\u00e9finie par rapport \u00e0 la fonction d'utilit\u00e9 attendue. Son application pour mod\u00e9liser les valeurs de certains r\u00e9sultats n\u00e9cessite donc une r\u00e9interpr\u00e9tation de la pr\u00e9f\u00e9rence dans des conditions de certitude. \u00c0 cette fin, nous exploitons le fait que les r\u00e9sultats des ench\u00e8res sont associ\u00e9s \u00e0 des prix continus, qui fournissent une \u00e9chelle naturelle pour \u00e9valuer l\u2019ampleur des pr\u00e9f\u00e9rences. Nous pr\u00e9sentons d'abord un cadre de repr\u00e9sentation des pr\u00e9f\u00e9rences qui capture, en plus des simples classements parmi les valeurs de configuration des attributs, la diff\u00e9rence dans la volont\u00e9 de payer -LRB- wtp -RRB- pour chacune. Ensuite, nous construisons un lien direct et formellement justifi\u00e9 entre les d\u00e9clarations de pr\u00e9f\u00e9rences sur les r\u00e9sultats tarif\u00e9s et une d\u00e9composition additive g\u00e9n\u00e9ralis\u00e9e de la fonction wtp. Apr\u00e8s avoir d\u00e9fini cette infrastructure, nous utilisons cet outil de repr\u00e9sentation pour le d\u00e9veloppement d'un m\u00e9canisme d'ench\u00e8res it\u00e9ratives multi-attributs qui permet aux traders d'exprimer leurs pr\u00e9f\u00e9rences complexes au format GAI. Nous \u00e9tudions ensuite les propri\u00e9t\u00e9s d'allocation, de calcul et pratiques de l'ench\u00e8re. Dans la section 2, nous pr\u00e9sentons les informations essentielles sur notre cadre de repr\u00e9sentation, la fonction de valeur mesurable -LRB-MVF-RRB-. La section 3 d\u00e9veloppe de nouvelles structures multiattributs pour MVF, prenant en charge les d\u00e9compositions additives g\u00e9n\u00e9ralis\u00e9es. Nous montrons ensuite l\u2019applicabilit\u00e9 du cadre th\u00e9orique aux pr\u00e9f\u00e9rences en mati\u00e8re de trading. Le reste de l\u2019article est consacr\u00e9 au m\u00e9canisme d\u2019ench\u00e8res propos\u00e9.Le prix d'une configuration est d\u00e9fini comme la somme des prix des niveaux d'attributs choisis moins la remise. L'ench\u00e8re que nous proposons prend \u00e9galement en charge des espaces de prix compacts, mais pour des niveaux de groupes d'attributs plut\u00f4t que des singletons. Compte tenu de ses racines dans la th\u00e9orie de l'utilit\u00e9 multiattribute -LSB- 13 -RSB-, la condition GAI est d\u00e9finie par rapport \u00e0 la fonction d'utilit\u00e9 attendue. Son application pour mod\u00e9liser les valeurs de certains r\u00e9sultats n\u00e9cessite donc une r\u00e9interpr\u00e9tation de la pr\u00e9f\u00e9rence dans des conditions de certitude. \u00c0 cette fin, nous exploitons le fait que les r\u00e9sultats des ench\u00e8res sont associ\u00e9s \u00e0 des prix continus, qui fournissent une \u00e9chelle naturelle pour \u00e9valuer l\u2019ampleur des pr\u00e9f\u00e9rences. Nous pr\u00e9sentons d'abord un cadre de repr\u00e9sentation des pr\u00e9f\u00e9rences qui capture, en plus des simples classements parmi les valeurs de configuration des attributs, la diff\u00e9rence dans la volont\u00e9 de payer -LRB- wtp -RRB- pour chacune. Ensuite, nous construisons un lien direct et formellement justifi\u00e9 entre les d\u00e9clarations de pr\u00e9f\u00e9rences sur les r\u00e9sultats tarif\u00e9s et une d\u00e9composition additive g\u00e9n\u00e9ralis\u00e9e de la fonction wtp. Apr\u00e8s avoir d\u00e9fini cette infrastructure, nous utilisons cet outil de repr\u00e9sentation pour le d\u00e9veloppement d'un m\u00e9canisme d'ench\u00e8res it\u00e9ratives multi-attributs qui permet aux traders d'exprimer leurs pr\u00e9f\u00e9rences complexes au format GAI. Nous \u00e9tudions ensuite les propri\u00e9t\u00e9s d'allocation, de calcul et pratiques de l'ench\u00e8re. Dans la section 2, nous pr\u00e9sentons les informations essentielles sur notre cadre de repr\u00e9sentation, la fonction de valeur mesurable -LRB-MVF-RRB-. La section 3 d\u00e9veloppe de nouvelles structures multiattributs pour MVF, prenant en charge les d\u00e9compositions additives g\u00e9n\u00e9ralis\u00e9es. Nous montrons ensuite l\u2019applicabilit\u00e9 du cadre th\u00e9orique aux pr\u00e9f\u00e9rences en mati\u00e8re de trading. Le reste de l\u2019article est consacr\u00e9 au m\u00e9canisme d\u2019ench\u00e8res propos\u00e9.Nous \u00e9tudions ensuite les propri\u00e9t\u00e9s d'allocation, de calcul et pratiques de l'ench\u00e8re. Dans la section 2, nous pr\u00e9sentons les informations essentielles sur notre cadre de repr\u00e9sentation, la fonction de valeur mesurable -LRB-MVF-RRB-. La section 3 d\u00e9veloppe de nouvelles structures multiattributs pour MVF, prenant en charge les d\u00e9compositions additives g\u00e9n\u00e9ralis\u00e9es. Nous montrons ensuite l\u2019applicabilit\u00e9 du cadre th\u00e9orique aux pr\u00e9f\u00e9rences en mati\u00e8re de trading. Le reste de l\u2019article est consacr\u00e9 au m\u00e9canisme d\u2019ench\u00e8res propos\u00e9.Nous \u00e9tudions ensuite les propri\u00e9t\u00e9s d'allocation, de calcul et pratiques de l'ench\u00e8re. Dans la section 2, nous pr\u00e9sentons les informations essentielles sur notre cadre de repr\u00e9sentation, la fonction de valeur mesurable -LRB-MVF-RRB-. La section 3 d\u00e9veloppe de nouvelles structures multiattributs pour MVF, prenant en charge les d\u00e9compositions additives g\u00e9n\u00e9ralis\u00e9es. Nous montrons ensuite l\u2019applicabilit\u00e9 du cadre th\u00e9orique aux pr\u00e9f\u00e9rences en mati\u00e8re de trading. Le reste de l\u2019article est consacr\u00e9 au m\u00e9canisme d\u2019ench\u00e8res propos\u00e9.", "keyphrases": ["ench\u00e8res", "ench\u00e8res multi-attributs", "pr\u00e9f\u00e8re la poign\u00e9e", "th\u00e9orie de la fonction mesure-valeur", "m\u00e9canisme d'ench\u00e8res iter", "mvf", "gau", "ench\u00e8res de base gai"]}
{"file_name": "I-7", "text": "Engagement et extorsion * R\u00c9SUM\u00c9 Prendre des engagements, par exemple par le biais de promesses et de menaces, permet \u00e0 un joueur d'exploiter les forces de sa propre position strat\u00e9gique ainsi que les faiblesses de celle de ses adversaires. Les engagements qu\u2019un acteur peut prendre avec cr\u00e9dibilit\u00e9 d\u00e9pendent des circonstances. Dans certains cas, un joueur ne peut s'engager que sur l'ex\u00e9cution d'une action, dans d'autres, il peut s'engager conditionnellement aux actions des autres joueurs. Certaines situations permettent m\u00eame des engagements sur engagements ou des engagements sur des actions al\u00e9atoires. Nous explorons les propri\u00e9t\u00e9s formelles de ces types d\u2019engagement -LRB- conditionnel -RRB- et leurs interrelations. Afin d'\u00e9viter les incoh\u00e9rences entre les engagements conditionnels, nous supposons un ordre dans lequel les acteurs prennent leurs engagements. Au centre de nos analyses se trouve la notion d'extorsion, que nous d\u00e9finissons, pour un ordre donn\u00e9 d'acteurs, comme un profil qui contient, pour chaque acteur, un engagement optimal compte tenu des engagements des acteurs qui se sont engag\u00e9s pr\u00e9c\u00e9demment. Sur cette base, nous \u00e9tudions, pour diff\u00e9rents types d'engagement, s'il est avantageux de s'engager plus t\u00f4t que plus tard, et comment les r\u00e9sultats obtenus gr\u00e2ce aux extorsions sont li\u00e9s \u00e0 l'induction en amont et \u00e0 l'efficacit\u00e9 de Pareto. 1. INTRODUCTION D'un certain point de vue, le moins que l'on puisse attendre de la th\u00e9orie des jeux est qu'elle fournisse une r\u00e9ponse \u00e0 la question de savoir quelles actions maximisent l'utilit\u00e9 attendue d'un agent dans des situations de prise de d\u00e9cision interactive. Dans cette perspective, le mod\u00e8le formel d\u2019un jeu sous forme strat\u00e9gique ne fait qu\u2019esquisser les caract\u00e9ristiques strat\u00e9giques d\u2019une situation interactive. Outre le simple choix et l\u2019ex\u00e9cution d\u2019une action parmi un ensemble d\u2019actions, il peut \u00e9galement y avoir d\u2019autres parcours ouverts \u00e0 un agent. Par exemple, la situation strat\u00e9gique du terrain peut \u00eatre telle qu'une promesse, une menace, ou une combinaison des deux, serait plus propice \u00e0 l'atteinte de ses objectifs. De m\u00eame, une menace ne r\u00e9ussit \u00e0 dissuader un agent que si l\u2019on peut lui faire croire que le mena\u00e7ant est tenu d\u2019ex\u00e9cuter la menace, au cas o\u00f9 elle serait ignor\u00e9e. En ce sens, les promesses et les menaces impliquent essentiellement un engagement de la part de celui qui les fait, restreignant ainsi volontairement sa libert\u00e9 de choix. Les promesses et les menaces r\u00e9sument l'un des ph\u00e9nom\u00e8nes fondamentaux et peut-\u00eatre \u00e0 premi\u00e8re vue les plus surprenants de la th\u00e9orie des jeux : il peut arriver qu'un joueur puisse am\u00e9liorer sa position strat\u00e9gique en limitant sa propre libert\u00e9 d'action. Par engagements, nous entendrons de telles limitations de l'espace d'action de chacun. L\u2019action elle-m\u00eame pourrait \u00eatre consid\u00e9r\u00e9e comme l\u2019engagement ultime. Effectuer une action particuli\u00e8re signifie le faire \u00e0 l\u2019exclusion de toute autre action. Les engagements prennent diff\u00e9rentes formes et peuvent d\u00e9pendre des circonstances : ceux qui peuvent ou ne peuvent pas \u00eatre pris de mani\u00e8re cr\u00e9dible. En plus de simplement s'engager dans l'accomplissement d'une action, un agent peut subordonner son engagement aux actions d'autres agents, comme le fait par exemple le kidnappeur lorsqu'il promet de lib\u00e9rer un otage contre une ran\u00e7on,tout en mena\u00e7ant de couper un autre orteil, sinon. Certaines situations permettent m\u00eame des engagements sur engagements ou des engagements sur des actions al\u00e9atoires. En se concentrant sur la s\u00e9lection des actions plut\u00f4t que sur les engagements, il peut sembler que la conception de la th\u00e9orie des jeux comme une simple th\u00e9orie de la d\u00e9cision interactive est trop \u00e9troite. \u00c0 cet \u00e9gard, le point de vue de Schelling pourrait sembler t\u00e9moigner d\u2019une compr\u00e9hension plus globale de ce que la th\u00e9orie des jeux tente d\u2019accomplir. On pourrait objecter que les engagements pourraient \u00eatre consid\u00e9r\u00e9s comme les actions d\u2019un jeu plus vaste. -LSB-... -RSB- Ce que nous voulons, c'est une th\u00e9orie qui syst\u00e9matise l'\u00e9tude des diff\u00e9rents ingr\u00e9dients universels qui composent la structure des mouvements des jeux ; un mod\u00e8le trop abstrait les manquera. -LSB- 9, pp. 156-7 -RSB- Notre pr\u00e9occupation concerne ces tactiques d'engagement, soit que notre analyse se cantonne aux situations dans lesquelles les acteurs peuvent s'engager dans un ordre donn\u00e9 et o\u00f9 nous assumons les engagements que les acteurs peuvent prendre sont donn\u00e9s. Malgr\u00e9 la mise en garde de Schelling concernant un cadre trop abstrait, notre approche sera bas\u00e9e sur la notion formelle d'extorsion, que nous proposerons dans la section 4 comme tactique uniforme pour une classe compl\u00e8te de situations dans lesquelles des engagements peuvent \u00eatre pris s\u00e9quentiellement. Sur cette base, nous abordons des questions telles que l'utilit\u00e9 de certains types d'engagement dans diff\u00e9rentes situations - LRB - les jeux strat\u00e9giques - RRB - ou s'il est pr\u00e9f\u00e9rable de s'engager t\u00f4t plut\u00f4t que tard. Nous fournissons \u00e9galement un cadre pour l'\u00e9valuation de questions plus g\u00e9n\u00e9rales li\u00e9es \u00e0 la th\u00e9orie des jeux, telles que la relation entre les extorsions et l'induction vers l'arri\u00e8re ou l'efficacit\u00e9 de Pareto. Par exemple, les engagements ont \u00e9t\u00e9 consid\u00e9r\u00e9s comme importants pour les agents logiciels en interaction ainsi que pour la conception des m\u00e9canismes. Dans le premier cas, l\u2019incapacit\u00e9 de reprogrammer un agent logiciel \u00e0 la vol\u00e9e peut \u00eatre consid\u00e9r\u00e9e comme un engagement envers sa sp\u00e9cification et ainsi exploit\u00e9e pour renforcer sa position strat\u00e9gique dans un context multi-agent. Un m\u00e9canisme, en revanche, pourrait \u00eatre vu comme un ensemble d'engagements qui orientent le comportement des joueurs d'une certaine mani\u00e8re souhait\u00e9e -LRB- voir, par exemple, -LSB- 2 -RSB- -RRB-. Ces jeux analysent des situations dans lesquelles un leader s'engage dans une strat\u00e9gie pure ou mixte, et plusieurs suiveurs, qui agissent alors simultan\u00e9ment. Apr\u00e8s avoir bri\u00e8vement discut\u00e9 des travaux connexes dans la section 2, nous pr\u00e9sentons le cadre formel de la th\u00e9orie des jeux, dans lequel nous d\u00e9finissons les notions de type d'engagement ainsi que d'engagements conditionnels et inconditionnels -LRB- Section 3 -RRB-. Dans la section 4, nous proposons le concept g\u00e9n\u00e9rique d'extorsion, qui pour chaque type d'engagement capture l'id\u00e9e d'un profil d'engagement optimal. La section 5 passe bri\u00e8vement en revue certains autres types d\u2019engagements, tels que les engagements inductifs, mixtes et conditionnels mixtes. 2. TRAVAUX CONNEXES L'engagement est un concept central en th\u00e9orie des jeux. La possibilit\u00e9 de prendre des engagements distingue la th\u00e9orie des jeux coop\u00e9rative de la th\u00e9orie des jeux non coop\u00e9rative -LSB- 4, 6 -RSB-. Les jeux de leadership, comme \u00e9voqu\u00e9 en introduction,analyser les engagements en faveur de strat\u00e9gies pures ou mixtes dans ce qui est essentiellement un cadre \u00e0 deux acteurs -LSB- 15, 16 -RSB-. De mani\u00e8re informelle, Schelling -LSB-9-RSB- a soulign\u00e9 l'importance des promesses, des menaces, etc. pour une bonne compr\u00e9hension de l'interaction sociale. \u00c0 un niveau plus formel, les menaces ont \u00e9galement figur\u00e9 dans la th\u00e9orie des n\u00e9gociations. Le jeu de menace de Nash -LSB- 5 -RSB- et les menaces rationnelles de Harsanyi -LSB- 3 -RSB- en sont deux premiers exemples importants. En outre, les engagements ont jou\u00e9 un r\u00f4le important dans la th\u00e9orie de la s\u00e9lection \u00e0 l'\u00e9quilibre -LRB- voir, par exemple, -LSB- 13 -RSB-. Au cours des derni\u00e8res ann\u00e9es, la th\u00e9orie des jeux est devenue presque indispensable en tant qu\u2019outil de recherche en informatique et dans la recherche sur les agents -LRB-multi-RRB-. Les engagements ne sont en aucun cas pass\u00e9s inaper\u00e7us -LRB- voir Figure 1 : S'engager dans une strat\u00e9gie domin\u00e9e peut \u00eatre avantageux. par exemple, -LSB- 1, 11 -RSB- -RRB-. R\u00e9cemment, les aspects strat\u00e9giques des engagements ont \u00e9galement attir\u00e9 l'attention des informaticiens. Ainsi, Conitzer et Sandholm -LSB- 2 -RSB- ont \u00e9tudi\u00e9 la complexit\u00e9 informatique du calcul de la strat\u00e9gie optimale \u00e0 adopter dans la forme normale et dans les jeux bay\u00e9siens. Sandholm et Lesser -LSB- 8 -RSB- emploient des engagements nivel\u00e9s pour la conception de syst\u00e8mes multiagents dans lesquels les accords contractuels ne sont pas enti\u00e8rement contraignants. Un autre lien entre engagements et informatique a \u00e9t\u00e9 soulign\u00e9 par Samet -LSB- 7 -RSB- et Tennenholtz -LSB- 12 -RSB-. Leur point de d\u00e9part est le constat que les programmes peuvent \u00eatre utilis\u00e9s pour formuler des engagements conditionn\u00e9s aux programmes d'autres syst\u00e8mes. Notre approche est similaire au cadre de Stackleberg dans la mesure o\u00f9 nous supposons un ordre dans lequel les joueurs s'engagent. Nous consid\u00e9rons cependant un certain nombre de types d'engagement diff\u00e9rents, parmi lesquels les engagements conditionnels, et proposons un concept de solution g\u00e9n\u00e9rique. 6. R\u00c9SUM\u00c9 ET CONCLUSION Dans certaines situations, les agents peuvent renforcer leur position strat\u00e9gique en s'engageant dans une ligne d'action particuli\u00e8re. Il existe diff\u00e9rents types d'engagement, par exemple purs, mixtes et conditionnels. Le type d\u2019engagement qu\u2019un agent est en mesure de prendre d\u00e9pend essentiellement de la situation consid\u00e9r\u00e9e. Si les agents s'engagent dans un ordre particulier, il existe une tactique commune \u00e0 la prise d'engagements de tout type, que nous avons formalis\u00e9e par la notion d'extorsion. Ce concept g\u00e9n\u00e9rique d\u2019extorsion peut \u00eatre analys\u00e9 in abstracto. En outre, sur cette base, les diff\u00e9rents types d'engagement peuvent \u00eatre compar\u00e9s de mani\u00e8re formelle et syst\u00e9matique. Nous avons vu que le type d\u2019engagement qu\u2019un agent peut prendre a un impact profond sur ce qu\u2019un agent peut accomplir dans une situation de jeu. Dans certaines situations, un joueur est grandement aid\u00e9 s'il est en mesure de s'engager sous conditions, alors que dans d'autres, des engagements mixtes seraient plus rentables. Cela pose la question des traits formels caract\u00e9ristiques des situations dans lesquelles il est avantageux pour un acteur de pouvoir prendre un type particulier d'engagements.Un autre probl\u00e8me que nous laissons aux recherches futures est la complexit\u00e9 informatique n\u00e9cessaire \u00e0 la recherche d'une extorsion pour les diff\u00e9rents types d'engagement.", "keyphrases": ["commettre", "cr\u00e9dible", "th\u00e9orie des jeux", "prendre des d\u00e9cisions", "position strat\u00e9gique", "libert\u00e9 d'action", "syst\u00e8me multiag", "distribuer l'informatique", "march\u00e9 des \u00e9lectrons", "extorquer", "ensemble stackleberg", "validation de conditions optimales", "type de validation s\u00e9quentielle", "formuler une hypoth\u00e8se", "pareto efficace", "pareto effici condition extorquer"]}
{"file_name": "J-10", "text": "Comprendre le comportement des utilisateurs dans les rapports de commentaires en ligne R\u00c9SUM\u00c9 Les avis en ligne sont devenus de plus en plus populaires comme moyen de juger de la qualit\u00e9 de divers produits et services. Des travaux ant\u00e9rieurs ont d\u00e9montr\u00e9 que les rapports contradictoires et les pr\u00e9jug\u00e9s sous-jacents des utilisateurs rendent difficile l\u2019\u00e9valuation de la v\u00e9ritable valeur d\u2019un service. Dans cet article, nous \u00e9tudions les facteurs sous-jacents qui influencent le comportement des utilisateurs lors de la communication de commentaires. Nous examinons deux sources d'information outre les \u00e9valuations num\u00e9riques : les preuves linguistiques provenant du commentaire textuel accompagnant une \u00e9valuation et les tendances dans la s\u00e9quence temporelle des rapports. Nous montrons d\u2019abord que les groupes d\u2019utilisateurs qui discutent amplement d\u2019une certaine fonctionnalit\u00e9 sont plus susceptibles de s\u2019entendre sur une note commune pour cette fonctionnalit\u00e9. Deuxi\u00e8mement, nous montrons que l'\u00e9valuation d'un utilisateur refl\u00e8te en partie la diff\u00e9rence entre la qualit\u00e9 r\u00e9elle et les attentes ant\u00e9rieures en mati\u00e8re de qualit\u00e9, telles que d\u00e9duites des avis pr\u00e9c\u00e9dents. Les deux nous offrent un moyen moins bruyant de produire des estimations de notation et r\u00e9v\u00e8lent les raisons des biais des utilisateurs. Nos hypoth\u00e8ses ont \u00e9t\u00e9 valid\u00e9es par des preuves statistiques provenant des avis d'h\u00f4tels sur le site TripAdvisor. 1. MOTIVATIONS Tenir compte s\u00e9rieusement des commentaires en ligne lors de la prise de d\u00e9cisions d'achat et \u00eatre pr\u00eat \u00e0 payer des primes de r\u00e9putation pour des produits ou des services jouissant d'une bonne r\u00e9putation. Une analyse r\u00e9cente soul\u00e8ve cependant d'importantes questions quant \u00e0 la capacit\u00e9 des forums existants \u00e0 refl\u00e9ter la qualit\u00e9 r\u00e9elle d'un produit. En l\u2019absence d\u2019incitations claires, les utilisateurs ayant une opinion mod\u00e9r\u00e9e ne prendront pas la peine d\u2019exprimer leurs opinions, ce qui conduit \u00e0 un \u00e9chantillon d\u2019avis non repr\u00e9sentatif. Dans ces circonstances, utiliser la moyenne arithm\u00e9tique pour pr\u00e9dire la qualit\u00e9 -LRB- comme le font la plupart des forums -RRB- donne \u00e0 l'utilisateur type un estimateur avec une variance \u00e9lev\u00e9e qui est souvent fausse. Am\u00e9liorer la mani\u00e8re dont nous regroupons les informations disponibles \u00e0 partir des avis en ligne n\u00e9cessite une compr\u00e9hension approfondie des facteurs sous-jacents qui biaisent le comportement d'\u00e9valuation des utilisateurs. Hu et coll. -LSB- 12 -RSB- proposent le `` Mod\u00e8le Brag-and-Moan '' o\u00f9 les utilisateurs \u00e9valuent uniquement si leur utilit\u00e9 du produit -LRB- tir\u00e9 d'une distribution normale -RRB- se situe en dehors d'un intervalle m\u00e9dian. Les auteurs concluent que le mod\u00e8le explique la distribution empirique des rapports et offre un aper\u00e7u de moyens plus intelligents d'estimer la v\u00e9ritable qualit\u00e9 du produit. Dans le pr\u00e9sent article, nous \u00e9largissons cette ligne de recherche et tentons d'expliquer davantage de faits sur le comportement des utilisateurs lorsqu'ils signalent des commentaires en ligne. En utilisant les avis r\u00e9els sur les h\u00f4tels du site Web TripAdvisor2, nous consid\u00e9rons deux sources d'informations suppl\u00e9mentaires en plus des notes num\u00e9riques de base soumises par les utilisateurs. La premi\u00e8re est une simple preuve linguistique issue de l\u2019examen textuel qui accompagne g\u00e9n\u00e9ralement les \u00e9valuations num\u00e9riques. Nous constatons que les utilisateurs qui commentent davantage la m\u00eame fonctionnalit\u00e9 sont plus susceptibles de s'entendre sur une note num\u00e9rique commune pour cette fonctionnalit\u00e9 particuli\u00e8re. Intuitivement, de longs commentaires r\u00e9v\u00e8lent l\u2019importance de la fonctionnalit\u00e9 pour l\u2019utilisateur.\u00c9tant donn\u00e9 que les gens ont tendance \u00e0 mieux conna\u00eetre les aspects qu\u2019ils consid\u00e8rent comme importants, les utilisateurs qui discutent plus en d\u00e9tail d\u2019une fonctionnalit\u00e9 donn\u00e9e peuvent \u00eatre suppos\u00e9s avoir plus d\u2019autorit\u00e9 dans l\u2019\u00e9valuation de cette fonctionnalit\u00e9. Deuxi\u00e8mement, nous \u00e9tudions la relation entre un avis. Figure 1 : La page TripAdvisor affichant les avis d'un h\u00f4tel populaire de Boston. Le nom de l\u2019h\u00f4tel et les publicit\u00e9s ont \u00e9t\u00e9 d\u00e9lib\u00e9r\u00e9ment effac\u00e9s. et les critiques qui l'ont pr\u00e9c\u00e9d\u00e9. La lecture des avis en ligne montre que les \u00e9valuations font souvent partie de fils de discussion, o\u00f9 un message n'est pas n\u00e9cessairement ind\u00e9pendant des autres messages. On peut voir, par exemple, des utilisateurs qui s'efforcent de contredire, ou d'approuver avec v\u00e9h\u00e9mence, les remarques des utilisateurs pr\u00e9c\u00e9dents. En analysant la s\u00e9quence temporelle des rapports, nous concluons que les \u00e9valuations pass\u00e9es influencent les rapports futurs, car elles cr\u00e9ent des attentes pr\u00e9alables concernant la qualit\u00e9 du service. La perception subjective de l'utilisateur est influenc\u00e9e par l'\u00e9cart entre les attentes pr\u00e9alables et la performance r\u00e9elle du service -LSB- 17, 18, 16, 21 -RSB- qui se refl\u00e9tera plus tard dans l'\u00e9valuation de l'utilisateur. Nous proposons un mod\u00e8le qui capture la d\u00e9pendance des notes aux attentes ant\u00e9rieures et le validons \u00e0 l'aide des donn\u00e9es empiriques que nous avons collect\u00e9es. Les deux r\u00e9sultats peuvent \u00eatre utilis\u00e9s pour am\u00e9liorer la mani\u00e8re dont les m\u00e9canismes de r\u00e9putation regroupent les informations provenant des avis individuels. Notre premier r\u00e9sultat peut \u00eatre utilis\u00e9 pour d\u00e9terminer une estimation de la qualit\u00e9 fonctionnalit\u00e9 par fonctionnalit\u00e9, o\u00f9 pour chaque fonctionnalit\u00e9, un sous-ensemble diff\u00e9rent de critiques -LRB-, c'est-\u00e0-dire ceux avec de longs commentaires sur cette fonctionnalit\u00e9 -RRB-, est pris en compte. La seconde conduit \u00e0 un algorithme qui produit une estimation plus pr\u00e9cise de la qualit\u00e9 r\u00e9elle.Notre premier r\u00e9sultat peut \u00eatre utilis\u00e9 pour d\u00e9terminer une estimation de la qualit\u00e9 fonctionnalit\u00e9 par fonctionnalit\u00e9, o\u00f9 pour chaque fonctionnalit\u00e9, un sous-ensemble diff\u00e9rent de critiques -LRB-, c'est-\u00e0-dire ceux avec de longs commentaires sur cette fonctionnalit\u00e9 -RRB-, est pris en compte. La seconde conduit \u00e0 un algorithme qui produit une estimation plus pr\u00e9cise de la qualit\u00e9 r\u00e9elle.Notre premier r\u00e9sultat peut \u00eatre utilis\u00e9 pour d\u00e9terminer une estimation de la qualit\u00e9 fonctionnalit\u00e9 par fonctionnalit\u00e9, o\u00f9 pour chaque fonctionnalit\u00e9, un sous-ensemble diff\u00e9rent de critiques -LRB-, c'est-\u00e0-dire ceux avec de longs commentaires sur cette fonctionnalit\u00e9 -RRB-, est pris en compte. La seconde conduit \u00e0 un algorithme qui produit une estimation plus pr\u00e9cise de la qualit\u00e9 r\u00e9elle.", "keyphrases": ["revue en ligne", "m\u00e9canisme de r\u00e9putation", "estimation de la qualit\u00e9 caract\u00e9ristique par caract\u00e9ristique", "absence d'incitation claire", "utilisation du produit", "mod\u00e8le qui se vante et se plaint", "taux", "tr\u00e8s probablement bi-modal", "distribution en forme de U", "orientation s\u00e9mantante de l'\u00e9valuation du produit", "corr\u00e9ler", "une longue p\u00e9riode"]}
{"file_name": "C-1", "text": "D\u00e9couverte de services de grille \u00e9volutive bas\u00e9e sur UDDI * R\u00c9SUM\u00c9 Une d\u00e9couverte efficace des services de grille est essentielle au succ\u00e8s du calcul en grille. La standardisation des grilles bas\u00e9es sur les services Web a entra\u00een\u00e9 la n\u00e9cessit\u00e9 de d\u00e9ployer des m\u00e9canismes de d\u00e9couverte de services Web \u00e9volutifs dans les grilles. M\u00eame si UDDI a \u00e9t\u00e9 la norme de facto de l'industrie pour la d\u00e9couverte de services Web, des exigences impos\u00e9es de r\u00e9plication \u00e9troite entre les registres et le manque Le contr\u00f4le autonome a gravement entrav\u00e9 son d\u00e9ploiement et son utilisation \u00e0 grande \u00e9chelle. Avec l'av\u00e8nement du calcul en grille, le probl\u00e8me d'\u00e9volutivit\u00e9 d'UDDI deviendra un obstacle qui emp\u00eachera son d\u00e9ploiement dans les grilles. Dans cet article, nous pr\u00e9sentons notre architecture de d\u00e9couverte de services Web distribu\u00e9e, appel\u00e9e DUDE -LRB- Distributed UDDI Deployment Engine -RRB-. DUDE exploite les tables de hachage distribu\u00e9es DHT -LRB- -RRB- comme m\u00e9canisme de rendez-vous entre plusieurs registres UDDI. DUDE permet aux consommateurs d'interroger plusieurs registres, tout en permettant aux organisations d'avoir un contr\u00f4le autonome sur leurs registres. . Sur la base d'un prototype pr\u00e9liminaire sur PlanetLab, nous pensons que l'architecture DUDE peut prendre en charge une distribution efficace des registres UDDI, rendant ainsi UDDI plus robuste et r\u00e9solvant \u00e9galement ses probl\u00e8mes de mise \u00e0 l'\u00e9chelle. De plus, l'architecture DUDE pour une distribution \u00e9volutive peut \u00eatre appliqu\u00e9e au-del\u00e0 d'UDDI \u00e0 n'importe quel m\u00e9canisme de d\u00e9couverte de services de grille. 1. INTRODUCTION Une d\u00e9couverte efficace des services de grille est essentielle au succ\u00e8s du calcul en grille. m\u00e9canismes de d\u00e9couverte \u00e0 d\u00e9ployer dans les grilles. Les services de d\u00e9couverte de grille offrent la possibilit\u00e9 de surveiller et de d\u00e9couvrir des ressources et des services sur les grilles. Ils offrent la possibilit\u00e9 d'interroger et de s'abonner \u00e0 des informations sur les ressources/services. L'\u00e9tat des donn\u00e9es doit \u00eatre maintenu dans un \u00e9tat souple afin que les informations les plus r\u00e9centes soient toujours disponibles. Les informations recueillies doivent \u00eatre fournies \u00e0 divers syst\u00e8mes dans le but soit d'utiliser la grille, soit de prouver des informations r\u00e9capitulatives. Cependant, le probl\u00e8me fondamental r\u00e9side dans la n\u00e9cessit\u00e9 d\u2019\u00eatre \u00e9volutif pour g\u00e9rer d\u2019\u00e9normes quantit\u00e9s de donn\u00e9es provenant de sources multiples. La communaut\u00e9 des services Web a r\u00e9pondu au besoin de d\u00e9couverte de services, avant que les grilles ne soient envisag\u00e9es, via une norme industrielle appel\u00e9e UDDI. Cependant, m\u00eame si UDDI est devenu la norme de facto de l'industrie pour la d\u00e9couverte de services Web, les exigences impos\u00e9es en mati\u00e8re de r\u00e9plication stricte entre les registres et le manque de contr\u00f4le autonome ont, entre autres, gravement entrav\u00e9 son d\u00e9ploiement et son utilisation \u00e0 grande \u00e9chelle -LSB- 7 -RSB- . Avec l'av\u00e8nement du calcul en grille, le probl\u00e8me d'\u00e9volutivit\u00e9 d'UDDI deviendra un obstacle qui emp\u00eachera son d\u00e9ploiement dans les grilles. Cet article aborde le probl\u00e8me de l'\u00e9volutivit\u00e9 et un moyen de trouver des services dans plusieurs registres dans UDDI en d\u00e9veloppant une architecture de d\u00e9couverte de services Web distribu\u00e9s. La distribution des fonctionnalit\u00e9s UDDI peut \u00eatre r\u00e9alis\u00e9e de plusieurs mani\u00e8res et peut-\u00eatre en utilisant diff\u00e9rentes infrastructures/plates-formes informatiques distribu\u00e9es -LRB-, par exemple CORBA, DCE, etc. -RRB-.Dans cet article, nous explorons comment la technologie des tables de hachage distribu\u00e9es -LRB-DHT-RRB- peut \u00eatre exploit\u00e9e pour d\u00e9velopper une architecture de d\u00e9couverte de services Web distribu\u00e9s \u00e9volutive. Un DHT est un syst\u00e8me distribu\u00e9 peer-to-peer -LRB-P2P-RRB- qui forme une superposition structur\u00e9e permettant un routage plus efficace que le r\u00e9seau sous-jacent. Le premier facteur de motivation est la simplicit\u00e9 inh\u00e9rente de l\u2019abstraction put/get fournie par les DHT, qui facilite la cr\u00e9ation rapide d\u2019applications sur les DHT. D'autres plates-formes/middlewares informatiques distribu\u00e9s, tout en offrant plus de fonctionnalit\u00e9s, ont une surcharge et une complexit\u00e9 beaucoup plus \u00e9lev\u00e9es. Le deuxi\u00e8me facteur de motivation vient du fait que les DHT sont un outil relativement nouveau pour cr\u00e9er des applications distribu\u00e9es et nous aimerions tester son potentiel en l'appliquant au probl\u00e8me de la distribution d'UDDI. Dans la section suivante, nous fournissons un bref aper\u00e7u des services d'informations sur la grille, d'UDDI et de ses limites, suivi d'un aper\u00e7u des DHT dans la section 3. La section 4 d\u00e9crit notre architecture propos\u00e9e avec des d\u00e9tails sur les cas d'utilisation. Dans la section 5, l'article 2 d\u00e9crit notre mise en \u0153uvre actuelle, suivi de nos conclusions dans la section 6. La section 7 discute des travaux connexes dans ce domaine et la section 8 contient nos remarques finales. 2. CONtext 2.1 D\u00e9couverte des services de grille L'informatique en grille est bas\u00e9e sur des normes qui utilisent la technologie des services Web. Dans l'architecture pr\u00e9sent\u00e9e dans -LSB- 6 -RSB-, la fonction de d\u00e9couverte de services est affect\u00e9e \u00e0 un service Grid sp\u00e9cialis\u00e9 appel\u00e9 Registry. Sa fonction de base le rend similaire au registre UDDI. Pour atteindre l'\u00e9volutivit\u00e9, les services d'index de diff\u00e9rents conteneurs Globus peuvent s'enregistrer les uns avec les autres de mani\u00e8re hi\u00e9rarchique pour agr\u00e9ger les donn\u00e9es. Plus pr\u00e9cis\u00e9ment, cette approche n'est pas adapt\u00e9e aux syst\u00e8mes qui tentent d'exploiter la convergence de l'informatique en grille et de l'informatique peer-to-peer -LSB-5-RSB-. 2.2 UDDI Au-del\u00e0 du calcul en grille, le probl\u00e8me de la d\u00e9couverte de services doit \u00eatre abord\u00e9 de mani\u00e8re plus g\u00e9n\u00e9rale dans la communaut\u00e9 des services Web. Encore une fois, l'\u00e9volutivit\u00e9 est une pr\u00e9occupation majeure puisque des millions d'acheteurs \u00e0 la recherche de services sp\u00e9cifiques doivent trouver tous les vendeurs potentiels du service qui peuvent r\u00e9pondre \u00e0 leurs besoins. Bien qu'il existe diff\u00e9rentes mani\u00e8res de proc\u00e9der, les comit\u00e9s de normalisation des services Web r\u00e9pondent \u00e0 cette exigence via une sp\u00e9cification appel\u00e9e UDDI -LRB- Universal Description, Discovery, and Integration -RRB-. Un registre UDDI permet \u00e0 une entreprise de saisir trois types d'informations dans un registre UDDI\u00a0: pages blanches, pages jaunes et pages vertes. L'objectif de l'UDDI est de fonctionner comme un registre de services, tout comme les pages jaunes sont un registre d'entreprises. Tout comme dans les pages jaunes, les entreprises s'inscrivent ainsi que leurs services dans diff\u00e9rentes cat\u00e9gories. Dans UDDI, les pages blanches sont une liste des entit\u00e9s commerciales. Les pages vertes repr\u00e9sentent les informations techniques n\u00e9cessaires pour appeler un service donn\u00e9. Ainsi, en parcourant un registre UDDI,un d\u00e9veloppeur doit \u00eatre capable de localiser un service et une entreprise et de d\u00e9couvrir comment invoquer le service. Lorsque UDDI a \u00e9t\u00e9 initialement propos\u00e9, il offrait beaucoup de potentiel. Cependant, nous constatons aujourd\u2019hui qu\u2019UDDI n\u2019a pas \u00e9t\u00e9 largement d\u00e9ploy\u00e9 sur Internet. En fait, les seules utilisations connues d'UDDI sont ce que l'on appelle les registres UDDI priv\u00e9s au sein des limites d'une entreprise. Les lecteurs peuvent se r\u00e9f\u00e9rer \u00e0 -LSB- 7 -RSB- pour un article r\u00e9cent qui traite des lacunes d'UDDI et des propri\u00e9t\u00e9s d'un registre de services id\u00e9al. L'am\u00e9lioration de la norme UDDI se poursuit \u00e0 plein r\u00e9gime et la version UDDI 3 -LRB-V3-RRB- a r\u00e9cemment \u00e9t\u00e9 approuv\u00e9e en tant que norme OASIS. Cependant, UDDI a aujourd'hui des probl\u00e8mes qui n'ont pas \u00e9t\u00e9 r\u00e9solus, tels que l'\u00e9volutivit\u00e9 et l'autonomie des registres individuels. UDDI V3 offre une prise en charge plus large des environnements multi-registres bas\u00e9s sur la portabilit\u00e9 des cl\u00e9s. En permettant aux cl\u00e9s d'\u00eatre r\u00e9enregistr\u00e9es dans plusieurs registres, la possibilit\u00e9 de lier des registres dans diverses topologies est effectivement activ\u00e9e. Cependant, aucune description normative de ces topologies n\u2019est fournie \u00e0 ce stade dans la sp\u00e9cification UDDI. Les am\u00e9liorations apport\u00e9es \u00e0 UDDI V3 qui permettent la prise en charge des environnements multi-registres sont significatives et ouvrent la possibilit\u00e9 de recherches suppl\u00e9mentaires sur la mani\u00e8re dont les environnements multi-registres peuvent \u00eatre d\u00e9ploy\u00e9s. Un sc\u00e9nario de d\u00e9ploiement recommand\u00e9 propos\u00e9 par la sp\u00e9cification UDDI V3.0.2 consiste \u00e0 utiliser les registres d'entreprise UDDI comme registres racine, et il est possible d'activer cela \u00e0 l'aide de notre solution. 2.3 Tables de hachage distribu\u00e9es Une table de hachage distribu\u00e9e -LRB-DHT-RRB- est un syst\u00e8me distribu\u00e9 peer-to-peer -LRB-P2P-RRB- qui forme une superposition structur\u00e9e permettant un routage plus efficace que le r\u00e9seau sous-jacent. Il maintient une collection de paires cl\u00e9-valeur sur les n\u0153uds participant \u00e0 cette structure graphique. Pour notre d\u00e9ploiement, une cl\u00e9 est le hachage d'un mot-cl\u00e9 issu d'un nom ou d'une description de service. Il y aura plusieurs valeurs pour cette cl\u00e9, une pour chaque service contenant le mot-cl\u00e9. Comme toute autre structure de donn\u00e9es de table de hachage, elle fournit une interface simple compos\u00e9e des op\u00e9rations put -LRB- -RRB- et get -LRB- -RRB-. Cela doit \u00eatre fait avec robustesse en raison de la nature transitoire des n\u0153uds dans les syst\u00e8mes P2P. Les cl\u00e9s DHT sont obtenues \u00e0 partir d'un grand espace d'identifiant. Une fonction de hachage, telle que MD5 ou SHA-1, est appliqu\u00e9e \u00e0 un nom d'objet pour obtenir sa cl\u00e9 DHT. Les n\u0153uds d'un DHT sont \u00e9galement mapp\u00e9s dans le m\u00eame espace d'identifiant en appliquant la fonction de hachage \u00e0 leur identifiant, tel que l'adresse IP et le num\u00e9ro de port, ou la cl\u00e9 publique. L'espace d'identifiant est attribu\u00e9 aux n\u0153uds de mani\u00e8re distribu\u00e9e et d\u00e9terministe, de sorte que le routage et la recherche puissent \u00eatre effectu\u00e9s efficacement. Les n\u0153uds d'un DHT maintiennent des liens avec certains des autres n\u0153uds du DHT. Le mod\u00e8le de ces liens est connu sous le nom de g\u00e9om\u00e9trie du DHT. Par exemple, dans le Bamboo DHT -LSB- 11 -RSB-, et dans le Pastry DHT -LSB- 8 -RSB- sur lequel Bamboo est bas\u00e9,les n\u0153uds maintiennent des liens vers les n\u0153uds voisins et vers d'autres n\u0153uds distants trouv\u00e9s dans une table de routage. La table de routage permet un routage par superposition efficace. Pour obtenir un routage ou une recherche coh\u00e9rent, une cl\u00e9 DHT doit \u00eatre achemin\u00e9e vers le n\u0153ud avec l\u2019identifiant num\u00e9riquement le plus proche. Pour plus de d\u00e9tails sur la fa\u00e7on dont les tables de routage sont construites et maintenues, le lecteur peut se r\u00e9f\u00e9rer \u00e0 -LSB- 8, 11 -RSB-. 5. TRAVAUX CONNEXES Un cadre pour la d\u00e9couverte de services bas\u00e9s sur la QoS dans les grilles a \u00e9t\u00e9 propos\u00e9 dans -LSB-18-RSB-. UDDIe, un registre UDDI \u00e9tendu pour la publication et la d\u00e9couverte de services bas\u00e9s sur des param\u00e8tres de QoS, est propos\u00e9 dans -LSB-19-RSB-. Notre travail est compl\u00e9mentaire puisque nous nous concentrons sur la mani\u00e8re de f\u00e9d\u00e9rer les registres UDDI et de r\u00e9soudre le probl\u00e8me de scalabilit\u00e9 avec UDDI. Le proxy DUDE peut publier les propri\u00e9t\u00e9s de service prises en charge par UDDIe dans le DHT et prendre en charge les requ\u00eates de plage \u00e0 l'aide des techniques propos\u00e9es pour de telles requ\u00eates sur les DHT. Nous pourrons alors offrir les avantages d\u2019\u00e9volutivit\u00e9 de notre solution actuelle aux registres UDDI et UDDIe. La d\u00e9couverte de services r\u00e9pondant aux exigences de qualit\u00e9 de service et de prix a \u00e9t\u00e9 \u00e9tudi\u00e9e dans le context d'une \u00e9conomie de r\u00e9seau, afin que les planificateurs de r\u00e9seau puissent utiliser divers mod\u00e8les de march\u00e9 tels que les march\u00e9s de mati\u00e8res premi\u00e8res et les ench\u00e8res. Le Grid Market Directory -LSB-20-RSB- a \u00e9t\u00e9 propos\u00e9 \u00e0 cet effet. Les descriptions des ressources et des demandes sont exprim\u00e9es dans RDF Schema, un langage de balisage s\u00e9mantique. Les r\u00e8gles de matchmaking sont exprim\u00e9es dans TRIPLE, un langage bas\u00e9 sur Horn Logic. Bien que notre impl\u00e9mentation actuelle se concentre sur UDDI version 2, nous envisagerons \u00e0 l'avenir des extensions s\u00e9mantiques \u00e0 UDDI, WS-Discovery -LSB- 16 -RSB- et d'autres normes de calcul en grille telles que Monitoring and Discovery Service -LRB- MDS -RRB- -LSB. - 10 -RSB-. Ainsi, l'extension la plus simple de notre travail pourrait impliquer d'utiliser le DHT pour effectuer une premi\u00e8re recherche bas\u00e9e sur la syntaxe afin d'identifier les registres locaux qui doivent \u00eatre contact\u00e9s. La convergence du calcul en grille et du calcul P2P a \u00e9t\u00e9 explor\u00e9e dans -LSB- 5 -RSB-. Un service UDDI f\u00e9d\u00e9r\u00e9 -LSB- 4 -RSB- a \u00e9t\u00e9 construit au-dessus du syst\u00e8me de publication-abonnement PlanetP -LSB- 3 -RSB- pour les communaut\u00e9s P2P non structur\u00e9es. Ce travail s'est concentr\u00e9 sur la g\u00e9rabilit\u00e9 du service f\u00e9d\u00e9r\u00e9. Le service UDDI est trait\u00e9 comme un service d'application Article 2 \u00e0 g\u00e9rer dans leur cadre. Ils ne traitent donc pas le probl\u00e8me de l\u2019\u00e9volutivit\u00e9 dans UDDI et utilisent plut\u00f4t une simple r\u00e9plication. Dans -LSB- 21 -RSB-, les auteurs d\u00e9crivent un syst\u00e8me d'extension UDDI -LRB- UX -RRB- qui lance une requ\u00eate f\u00e9d\u00e9r\u00e9e uniquement si les r\u00e9sultats trouv\u00e9s localement ne sont pas ad\u00e9quats. Bien que le serveur UX se positionne comme un interm\u00e9diaire \u00e0 l'instar du proxy UDDI d\u00e9crit dans notre framework DUDE, il se concentre davantage sur le framework QoS et ne tente pas d'impl\u00e9menter un m\u00e9canisme de f\u00e9d\u00e9ration transparent tel que notre approche bas\u00e9e sur DHT. Dans -LSB- 22 -RSB- D2HT d\u00e9crit un cadre de d\u00e9couverte construit sur DHT. Cependant, nous avons choisi d'utiliser UDDI en plus de DHT. 6. CONCLUSIONS ET TRAVAUX FUTURS Dans cet article,nous avons d\u00e9crit une architecture distribu\u00e9e pour prendre en charge la d\u00e9couverte \u00e0 grande \u00e9chelle de services Web. Notre architecture permettra aux organisations de maintenir un contr\u00f4le autonome sur leurs registres UDDI tout en permettant aux clients d'interroger plusieurs registres simultan\u00e9ment. Sur la base des tests de prototype initiaux, nous pensons que l'architecture DUDE peut prendre en charge une distribution efficace des registres UDDI, rendant ainsi UDDI plus robuste et r\u00e9solvant \u00e9galement ses probl\u00e8mes de mise \u00e0 l'\u00e9chelle. L'article a r\u00e9solu les probl\u00e8mes d'\u00e9volutivit\u00e9 avec UDDI mais n'exclut pas l'application de cette approche \u00e0 d'autres m\u00e9canismes de d\u00e9couverte de services. Un exemple d'un autre m\u00e9canisme de d\u00e9couverte de services qui pourrait b\u00e9n\u00e9ficier d'une telle approche est le MDS de Globus Toolkit. De plus, nous pr\u00e9voyons d\u2019\u00e9tudier d\u2019autres aspects de la d\u00e9couverte de services de r\u00e9seau qui \u00e9tendent ce travail. De plus, nous pr\u00e9voyons de revoir les API de service pour une solution Grid Service Discovery en tirant parti des solutions et sp\u00e9cifications disponibles ainsi que des travaux pr\u00e9sent\u00e9s dans cet article.", "keyphrases": ["d\u00e9couverte des services de r\u00e9seau", "oudi", "architecture de d\u00e9couverte de services Web distribu\u00e9s", "base dht uddi registre hi\u00e9rarchie", "d\u00e9ployer le probl\u00e8me", "code dht en bambou", "recherche insensible \u00e0 la casse", "requ\u00eate", "pr\u00e9fixe de disponibilit\u00e9 la plus longue", "d\u00e9couverte du service qo-base", "contr\u00f4le autonome", "uddi registre", "probl\u00e8me \u00e9volutif", "\u00e9tat mou"]}
{"file_name": "J-22", "text": "Parier sur les permutations R\u00c9SUM\u00c9 Nous consid\u00e9rons un sc\u00e9nario de pari sur les permutations, dans lequel des personnes parient sur l'ordre final de n candidats : par exemple, le r\u00e9sultat d'une course de chevaux. Nous examinons le probl\u00e8me du commissaire-priseur consistant \u00e0 faire correspondre les paris sans risque ou, de mani\u00e8re \u00e9quivalente, \u00e0 trouver des opportunit\u00e9s d'arbitrage entre les paris propos\u00e9s. Exiger des ench\u00e9risseurs qu'ils r\u00e9pertorient explicitement les commandes sur lesquelles ils souhaitent parier est \u00e0 la fois contre nature et insoluble, car le nombre de commandes est n\u00a0! et le nombre de sous-ensembles de commandes est 2n\u00a0! . Nous proposons deux langages de paris expressifs qui semblent naturels pour les ench\u00e9risseurs, et examinons la complexit\u00e9 informatique du probl\u00e8me du commissaire-priseur dans chaque cas. Les paris sur sous-ensembles permettent aux traders de parier soit qu'un candidat finira par \u00eatre class\u00e9 parmi un sous-ensemble de positions dans l'ordre final, par exemple, \"le cheval A finira aux positions 4, 9 ou 13-21\", soit qu'une position sera remport\u00e9 par un sous-ensemble de candidats, par exemple `` le cheval A, B ou D terminera en position 2 ''. Pour les paris sur sous-ensembles, nous montrons que le probl\u00e8me du commissaire-priseur peut \u00eatre r\u00e9solu en temps polynomial si les ordres sont divisibles. Les paris en paire permettent aux traders de parier sur le fait qu'un candidat finira par \u00eatre mieux class\u00e9 qu'un autre candidat, par exemple \u00ab\u00a0le cheval A battra le cheval B\u00a0\u00bb. Nous prouvons que le probl\u00e8me du commissaire-priseur devient NP-difficile pour les paris en paire. Nous identifions une condition suffisante pour l\u2019existence d\u2019un match de pari en paire qui peut \u00eatre v\u00e9rifi\u00e9e en temps polynomial. Nous montrons \u00e9galement qu\u2019un algorithme glouton naturel donne une mauvaise approximation des ordres indivisibles. 1. INTRODUCTION Acheter ou vendre un titre financier est en effet un pari sur la valeur du titre. Par exemple, acheter une action, c'est parier que la valeur de l'action est sup\u00e9rieure \u00e0 son prix actuel. Chaque commer\u00e7ant \u00e9value son profit attendu pour d\u00e9cider de la quantit\u00e9 \u00e0 acheter ou \u00e0 vendre en fonction de ses propres informations et de son \u00e9valuation subjective de la probabilit\u00e9. L'interaction collective de tous les paris conduit \u00e0 un \u00e9quilibre qui refl\u00e8te une agr\u00e9gation de toutes les informations et croyances des traders. Pensez \u00e0 acheter un titre au prix de cinquante-deux cents, qui rapporte 1 dollar si et seulement si un d\u00e9mocrate remporte l'\u00e9lection pr\u00e9sidentielle am\u00e9ricaine de 2008. Dans le cas d'un titre contingent \u00e0 un \u00e9v\u00e9nement, le prix - la valeur marchande du titre - correspond directement \u00e0 la probabilit\u00e9 estim\u00e9e de l'\u00e9v\u00e9nement. Presque toutes les bourses financi\u00e8res et de paris existantes associent des partenaires commerciaux bilat\u00e9raux. Par exemple, un trader pr\u00eat \u00e0 accepter une perte de x dollars si un d\u00e9mocrate ne gagne pas, en \u00e9change d'un profit d'un dollar si un d\u00e9mocrate gagne, est confront\u00e9 \u00e0 un deuxi\u00e8me trader pr\u00eat \u00e0 accepter le contraire. Cependant, dans de nombreux sc\u00e9narios, m\u00eame s\u2019il n\u2019existe aucun accord bilat\u00e9ral entre commer\u00e7ants, des accords multilat\u00e9raux peuvent \u00eatre possibles. Nous proposons un \u00e9change o\u00f9 les traders disposent d'une flexibilit\u00e9 consid\u00e9rable pour exprimer naturellement et succinctement leurs paris,et examiner la complexit\u00e9 informatique du probl\u00e8me de correspondance qui en r\u00e9sulte pour le commissaire-priseur, \u00e0 savoir l'identification des accords bilat\u00e9raux et multilat\u00e9raux. En particulier, nous nous concentrons sur un context dans lequel les traders parient sur le r\u00e9sultat d\u2019une comp\u00e9tition entre n candidats. Par exemple, supposons qu'il y ait n candidats \u00e0 une \u00e9lection -LRB- ou n chevaux dans une course, etc. -RRB- et donc n ! classement \u00e9ventuel des candidats apr\u00e8s le d\u00e9compte final des votes. Comme nous le verrons, le probl\u00e8me d'appariement peut \u00eatre formul\u00e9 sous la forme d'un programme lin\u00e9aire ou entier, selon que les ordres sont respectivement divisibles ou indivisibles. Tenter de r\u00e9duire le probl\u00e8me \u00e0 un probl\u00e8me d'appariement bilat\u00e9ral en cr\u00e9ant explicitement n! des titres, un pour chaque ordre final possible, est \u00e0 la fois fastidieux pour les traders et irr\u00e9alisable sur le plan informatique, m\u00eame pour des n de taille modeste. De plus, l'attention des traders serait r\u00e9partie entre n ! des choix ind\u00e9pendants, ce qui rend la probabilit\u00e9 que deux commer\u00e7ants convergent en m\u00eame temps et au m\u00eame endroit semble faible. Il existe un compromis entre l'expressivit\u00e9 du langage d'appel d'offres et la complexit\u00e9 informatique du probl\u00e8me d'appariement. Nous souhaitons offrir aux traders le langage d\u2019ench\u00e8res le plus expressif possible tout en conservant la faisabilit\u00e9 informatique. Nous explorons deux langages d'ench\u00e8res qui semblent naturels du point de vue d'un commer\u00e7ant. Les paris sur sous-ensembles, d\u00e9crits dans la section 3.2, permettent aux traders de parier sur les positions dans le classement qu'un candidat perdra, par exemple \u00ab le candidat D finira en position 1, 3-5 ou 10 \u00bb. Sym\u00e9triquement, les traders peuvent \u00e9galement parier sur les candidats qui occuperont une position particuli\u00e8re. Dans la section 4, nous d\u00e9rivons un algorithme en temps polynomial pour faire correspondre les paris du sous-ensemble -LRB- divisible -RRB-. Les paris en paires, d\u00e9crits dans la section 3.3, permettent aux traders de parier sur le classement final de deux candidats quelconques, par exemple \u00ab\u00a0le candidat D battra le candidat R\u00a0\u00bb. Dans la section 5, nous montrons que l'appariement optimal des paris de paires -LRB- divisibles ou indivisibles -RRB- est NP-difficile, via une r\u00e9duction du probl\u00e8me d'ensemble d'arc de r\u00e9troaction minimum non pond\u00e9r\u00e9. Nous fournissons \u00e9galement une condition suffisante polynomialement v\u00e9rifiable pour l'existence d'un pari en paire et montrons qu'un algorithme glouton offre une mauvaise approximation pour les paris en paire indivisibles. 2. CONtext ET TRAVAUX CONNEXES Nous consid\u00e9rons les paris de permutation, ou les paris sur le r\u00e9sultat d'une comp\u00e9tition entre n candidats. Le r\u00e9sultat final ou ES de l'\u00e9tat est un classement ordinal des n candidats. Par exemple, les candidats pourraient \u00eatre des chevaux participant \u00e0 une course et le r\u00e9sultat serait la liste des chevaux par ordre croissant de leurs temps d'arriv\u00e9e. L'espace d'\u00e9tat S contient tous les n\u00a0! permutations mutuellement exclusives et exhaustives de candidats. Dans la pratique sur les hippodromes, chacun de ces diff\u00e9rents types de paris est trait\u00e9 dans des pools ou groupes distincts. Au lieu de cela, nous d\u00e9crivons un \u00e9change central o\u00f9 tous les paris sur le r\u00e9sultat sont trait\u00e9s ensemble, agr\u00e9geant ainsi la liquidit\u00e9 et garantissant que l'inf\u00e9rence informationnelle se produit automatiquement. Id\u00e9alement,nous aimerions permettre aux traders de parier sur n'importe quelle propri\u00e9t\u00e9 de l'ordre final qu'ils souhaitent, indiqu\u00e9 exactement dans la langue qu'ils pr\u00e9f\u00e8rent. En pratique, autoriser un langage trop flexible cr\u00e9e une charge de calcul pour le commissaire-priseur qui tente de mettre en relation les commer\u00e7ants consentants. Nous explorons le compromis entre l'expressivit\u00e9 du langage d'appel d'offres et la complexit\u00e9 informatique du probl\u00e8me d'appariement. Nous consid\u00e9rons un cadre dans lequel les gens proposent d'acheter des titres qui paient 1 $ si et seulement si certaines propri\u00e9t\u00e9s de l'ordre final sont vraies. Les traders indiquent le prix qu'ils sont pr\u00eats \u00e0 payer par action et le nombre d'actions qu'ils souhaitent acheter. Un ordre divisible permet au trader de recevoir moins d'actions que demand\u00e9, tant que la contrainte de prix est respect\u00e9e ; un ordre indivisible est un ordre tout ou rien. titres, un pour chaque ES -LRB- de chaque \u00c9tat ou en fait n'importe quel ensemble de n! titres lin\u00e9airement ind\u00e9pendants -RRB-. Il s\u2019agit dans notre context du march\u00e9 des valeurs mobili\u00e8res Arrow-Debreu complet -LSB-1-RSB-. En pratique, les traders ne veulent pas s'occuper de sp\u00e9cifications de bas niveau d'ordres complets : les gens pensent plus naturellement en termes de propri\u00e9t\u00e9s de haut niveau des ordres. De plus, l'exploitation n! les valeurs mobili\u00e8res sont irr\u00e9alisables en pratique d\u2019un point de vue informatique \u00e0 mesure que n grandit. Un langage d'ench\u00e8res tr\u00e8s simple pourrait permettre aux traders de parier uniquement sur le vainqueur de la comp\u00e9tition, comme cela se fait dans le pool \u00ab gagnant \u00bb sur les hippodromes. Le probl\u00e8me d\u2019appariement correspondant est polynomial, cependant le langage est peu expressif. Un trader qui croit que A va vaincre B, mais qu\u2019aucun des deux ne gagnera purement et simplement, ne peut pas communiquer utilement ses informations au march\u00e9. L\u2019espace des prix du march\u00e9 r\u00e9v\u00e8le les estimations collectives des probabilit\u00e9s de gain mais rien d\u2019autre. Notre objectif est de trouver des langages aussi expressifs et intuitifs que possible et de r\u00e9v\u00e9ler autant d'informations que possible, tout en maintenant la faisabilit\u00e9 informatique. Notre travail est en analogie directe avec les travaux de Fortnow et. Alors que nous explorons la combinatoire de permutation, Fortnow et. Al. explorer la combinatoire bool\u00e9enne. Les auteurs consid\u00e8rent un espace d\u2019\u00e9tats des 2n r\u00e9sultats possibles de n variables binaires. Les traders expriment leurs paris selon la logique bool\u00e9enne. Les auteurs montrent que l\u2019appariement divisible est co-NP-complet et que l\u2019appariement indivisible est p2-complet. Hanson -LSB- 9 -RSB- d\u00e9crit un m\u00e9canisme de r\u00e8gle de notation du march\u00e9 qui peut permettre de parier sur un nombre combinatoire de r\u00e9sultats. Le march\u00e9 commence par une distribution de probabilit\u00e9 commune sur tous les r\u00e9sultats. Cela fonctionne comme une version s\u00e9quentielle d\u2019une r\u00e8gle de notation. Tout trader peut modifier la distribution de probabilit\u00e9 \u00e0 condition qu'il accepte de payer le trader le plus r\u00e9cent conform\u00e9ment \u00e0 la r\u00e8gle de notation. Le teneur de march\u00e9 paie le dernier trader. Il supporte donc des risques et peut subir des pertes. Les m\u00e9canismes de r\u00e8gles de notation de march\u00e9 ont la propri\u00e9t\u00e9 int\u00e9ressante de limiter la perte du teneur de march\u00e9 dans le pire des cas. Cependant, les aspects informatiques du fonctionnement du m\u00e9canisme n\u2019ont pas \u00e9t\u00e9 enti\u00e8rement explor\u00e9s.Nos m\u00e9canismes disposent d'un commissaire-priseur qui ne supporte aucun risque et ne fait qu'apparier les commandes. Les ench\u00e8res combinatoires permettent aux ench\u00e9risseurs d'attribuer des valeurs distinctes \u00e0 des lots de biens plut\u00f4t qu'\u00e0 des biens individuels. L'incertitude et le risque ne sont g\u00e9n\u00e9ralement pas pris en compte et le probl\u00e8me central du commissaire-priseur est de maximiser le bien-\u00eatre social. Nos m\u00e9canismes permettent aux traders de construire des paris sur un \u00e9v\u00e9nement avec n\u00a0! r\u00e9sultats. L'incertitude et le risque sont pris en compte et le probl\u00e8me du commissaire-priseur est d'explorer les opportunit\u00e9s d'arbitrage et de faire correspondre les paris sans risque. 6. CONCLUSION Nous consid\u00e9rons un sc\u00e9nario de pari de permutation, dans lequel les traders parient sur l'ordre final de n candidats. Bien qu'il soit contre nature et insoluble de permettre aux traders de parier directement sur le n! diff\u00e9rents ordres finaux, nous proposons deux langages de paris expressifs, les paris sur sous-ensembles et les paris en paires. Dans un march\u00e9 de paris sur sous-ensembles, les traders peuvent parier soit sur un sous-ensemble de positions occup\u00e9es par un candidat, soit sur un sous-ensemble de candidats qui occupent une position sp\u00e9cifique dans l'ordre final. Les paris en paire permettent aux traders de parier sur le fait qu'un candidat donn\u00e9 soit mieux class\u00e9 qu'un autre candidat donn\u00e9. Nous examinons le probl\u00e8me du commissaire-priseur consistant \u00e0 faire correspondre les commandes sans encourir de risque. Nous constatons que dans un march\u00e9 de paris sous-ensemble, un commissaire-priseur peut trouver l'ensemble et la quantit\u00e9 optimaux d'ordres \u00e0 accepter de telle sorte que son profit dans le pire des cas soit maximis\u00e9 en temps polynomial si les ordres sont divisibles. La complexit\u00e9 change radicalement pour les paris en paire. Nous prouvons que le probl\u00e8me d'appariement optimal pour le commissaire-priseur est NP-difficile pour les paris par paires avec des ordres indivisibles et divisibles via des r\u00e9ductions au probl\u00e8me d'ensemble d'arc de r\u00e9troaction minimum. Nous identifions une condition suffisante pour l\u2019existence d\u2019une correspondance, qui peut \u00eatre v\u00e9rifi\u00e9e en temps polynomial. Il a \u00e9t\u00e9 d\u00e9montr\u00e9 qu\u2019un algorithme glouton naturel donne une mauvaise approximation pour les paris sur paires indivisibles. Des questions ouvertes int\u00e9ressantes pour nos paris par permutation incluent la complexit\u00e9 informatique de la correspondance indivisible optimale pour les paris sur sous-ensembles et la condition n\u00e9cessaire \u00e0 l'existence d'une correspondance sur les march\u00e9s des paris par paires. Nous souhaitons explorer davantage de meilleurs algorithmes d\u2019approximation pour les march\u00e9s de paris en paire.Dans un march\u00e9 de paris sur sous-ensembles, les traders peuvent parier soit sur un sous-ensemble de positions occup\u00e9es par un candidat, soit sur un sous-ensemble de candidats qui occupent une position sp\u00e9cifique dans l'ordre final. Les paris en paire permettent aux traders de parier sur le fait qu'un candidat donn\u00e9 soit mieux class\u00e9 qu'un autre candidat donn\u00e9. Nous examinons le probl\u00e8me du commissaire-priseur consistant \u00e0 faire correspondre les commandes sans encourir de risque. Nous constatons que dans un march\u00e9 de paris sous-ensemble, un commissaire-priseur peut trouver l'ensemble et la quantit\u00e9 optimaux d'ordres \u00e0 accepter de telle sorte que son profit dans le pire des cas soit maximis\u00e9 en temps polynomial si les ordres sont divisibles. La complexit\u00e9 change radicalement pour les paris en paire. Nous prouvons que le probl\u00e8me d'appariement optimal pour le commissaire-priseur est NP-difficile pour les paris par paires avec des ordres indivisibles et divisibles via des r\u00e9ductions au probl\u00e8me d'ensemble d'arc de r\u00e9troaction minimum. Nous identifions une condition suffisante pour l\u2019existence d\u2019une correspondance, qui peut \u00eatre v\u00e9rifi\u00e9e en temps polynomial. Il a \u00e9t\u00e9 d\u00e9montr\u00e9 qu\u2019un algorithme glouton naturel donne une mauvaise approximation pour les paris sur paires indivisibles. Des questions ouvertes int\u00e9ressantes pour nos paris par permutation incluent la complexit\u00e9 informatique de la correspondance indivisible optimale pour les paris sur sous-ensembles et la condition n\u00e9cessaire \u00e0 l'existence d'une correspondance sur les march\u00e9s des paris par paires. Nous souhaitons explorer davantage de meilleurs algorithmes d\u2019approximation pour les march\u00e9s de paris en paire.Dans un march\u00e9 de paris sur sous-ensembles, les traders peuvent parier soit sur un sous-ensemble de positions occup\u00e9es par un candidat, soit sur un sous-ensemble de candidats qui occupent une position sp\u00e9cifique dans l'ordre final. Les paris en paire permettent aux traders de parier sur le fait qu'un candidat donn\u00e9 soit mieux class\u00e9 qu'un autre candidat donn\u00e9. Nous examinons le probl\u00e8me du commissaire-priseur consistant \u00e0 faire correspondre les commandes sans encourir de risque. Nous constatons que dans un march\u00e9 de paris sous-ensemble, un commissaire-priseur peut trouver l'ensemble et la quantit\u00e9 optimaux d'ordres \u00e0 accepter de telle sorte que son profit dans le pire des cas soit maximis\u00e9 en temps polynomial si les ordres sont divisibles. La complexit\u00e9 change radicalement pour les paris en paire. Nous prouvons que le probl\u00e8me d'appariement optimal pour le commissaire-priseur est NP-difficile pour les paris par paires avec des ordres indivisibles et divisibles via des r\u00e9ductions au probl\u00e8me d'ensemble d'arc de r\u00e9troaction minimum. Nous identifions une condition suffisante pour l\u2019existence d\u2019une correspondance, qui peut \u00eatre v\u00e9rifi\u00e9e en temps polynomial. Il a \u00e9t\u00e9 d\u00e9montr\u00e9 qu\u2019un algorithme glouton naturel donne une mauvaise approximation pour les paris sur paires indivisibles. Des questions ouvertes int\u00e9ressantes pour nos paris par permutation incluent la complexit\u00e9 informatique de la correspondance indivisible optimale pour les paris sur sous-ensembles et la condition n\u00e9cessaire \u00e0 l'existence d'une correspondance sur les march\u00e9s des paris par paires. Nous souhaitons explorer davantage de meilleurs algorithmes d\u2019approximation pour les march\u00e9s de paris en paire.", "keyphrases": ["pari permut\u00e9", "pari de sous-ensemble", "partenaire commercial bilat\u00e9ral", "algorithme polynomi-temporel", "informer l'agr\u00e9gat", "combinateur permutateur", "march\u00e9 des paris en paire", "graphe biparti", "r\u00e9troaction minimale", "algorithme glouton", "transform\u00e9e en polyn\u00f4me complexe"]}
{"file_name": "I-31", "text": "Raisonnement sur le jugement et l'agr\u00e9gation des pr\u00e9f\u00e9rences \u25e6 R\u00c9SUM\u00c9 Les agents qui doivent parvenir \u00e0 des accords avec d'autres agents doivent raisonner sur la mani\u00e8re dont leurs pr\u00e9f\u00e9rences, jugements et croyances pourraient \u00eatre agr\u00e9g\u00e9s avec ceux des autres par les m\u00e9canismes de choix sociaux qui r\u00e9gissent leurs interactions. Le domaine r\u00e9cemment \u00e9mergent de l'agr\u00e9gation de jugement \u00e9tudie l'agr\u00e9gation d'un point de vue logique et consid\u00e8re comment plusieurs ensembles de formules logiques peuvent \u00eatre agr\u00e9g\u00e9s en un seul ensemble coh\u00e9rent. Comme cas particulier, l\u2019agr\u00e9gation de jugements peut \u00eatre consid\u00e9r\u00e9e comme englobant l\u2019agr\u00e9gation de pr\u00e9f\u00e9rences classique. Nous pr\u00e9sentons une logique modale destin\u00e9e \u00e0 soutenir le raisonnement sur les sc\u00e9narios d'agr\u00e9gation de jugements -LRB- et donc, comme cas particulier, sur l'agr\u00e9gation de pr\u00e9f\u00e9rences -RRB- : le langage logique est interpr\u00e9t\u00e9 directement dans les r\u00e8gles d'agr\u00e9gation de jugements. Nous pr\u00e9sentons une axiomatisation solide et compl\u00e8te de ces r\u00e8gles. Nous montrons que la logique peut exprimer des r\u00e8gles d'agr\u00e9gation telles que le vote majoritaire ; propri\u00e9t\u00e9s de r\u00e8gle telles que l'ind\u00e9pendance ; et des r\u00e9sultats tels que le paradoxe discursif, le th\u00e9or\u00e8me d'Arrow et le paradoxe de Condorcet -- qui peuvent \u00eatre d\u00e9riv\u00e9s en tant que th\u00e9or\u00e8mes formels de la logique. La logique est param\u00e9tr\u00e9e de telle mani\u00e8re qu'elle peut \u00eatre utilis\u00e9e comme cadre g\u00e9n\u00e9ral pour comparer les propri\u00e9t\u00e9s logiques de diff\u00e9rents types d'agr\u00e9gation, y compris l'agr\u00e9gation de pr\u00e9f\u00e9rences classique. 1. INTRODUCTION Dans cet article, nous nous int\u00e9ressons aux formalismes de repr\u00e9sentation des connaissances pour les syst\u00e8mes dans lesquels les agents doivent agr\u00e9ger leurs pr\u00e9f\u00e9rences, jugements, croyances, etc.. Par exemple, un agent peut avoir besoin de raisonner sur le vote majoritaire dans un groupe auquel il appartient. un membre de. L'agr\u00e9gation des pr\u00e9f\u00e9rences -- combinant les relations de pr\u00e9f\u00e9rence des individus sur un ensemble d'alternatives en une relation de pr\u00e9f\u00e9rence qui repr\u00e9sente les pr\u00e9f\u00e9rences communes du groupe par ce que l'on appelle les fonctions de bien-\u00eatre social -- a \u00e9t\u00e9 largement \u00e9tudi\u00e9e dans la th\u00e9orie du choix social -LSB- 2 -RSB- . Le domaine r\u00e9cemment \u00e9mergent de l'agr\u00e9gation de jugements \u00e9tudie l'agr\u00e9gation d'un point de vue logique et explique comment, \u00e9tant donn\u00e9 un ensemble coh\u00e9rent de formules logiques pour chaque agent, repr\u00e9sentant les croyances ou les jugements de l'agent, nous pouvons les agr\u00e9ger en un seul ensemble coh\u00e9rent de formules. Diverses r\u00e8gles d'agr\u00e9gation de jugement ont \u00e9t\u00e9 d\u00e9velopp\u00e9es \u00e0 cette fin. Comme cas particulier, l\u2019agr\u00e9gation de jugement peut \u00eatre consid\u00e9r\u00e9e comme englobant l\u2019agr\u00e9gation de pr\u00e9f\u00e9rences -LSB-5-RSB-. Dans cet article, nous pr\u00e9sentons une logique, appel\u00e9e Logique d'agr\u00e9gation de jugement -LRB-jal-RRB-, pour raisonner sur l'agr\u00e9gation de jugement. Les formules de la logique sont interpr\u00e9t\u00e9es comme des d\u00e9clarations sur les r\u00e8gles d'agr\u00e9gation des jugements, et nous donnons une axiomatisation solide et compl\u00e8te de toutes ces r\u00e8gles. L'axiomatisation est param\u00e9tr\u00e9e de telle mani\u00e8re que nous pouvons l'instancier pour obtenir une gamme de logiques d'agr\u00e9gation de jugement diff\u00e9rentes. Par exemple, un exemple est une axiomatisation, dans notre langage, de toutes les fonctions de protection sociale \u2013 nous obtenons ainsi \u00e9galement une logique d\u2019agr\u00e9gation classique des pr\u00e9f\u00e9rences.Et c'est l'une des principales contributions de cet article : nous identifions les propri\u00e9t\u00e9s logiques de l'agr\u00e9gation de jugement, et nous pouvons comparer les propri\u00e9t\u00e9s logiques de diff\u00e9rentes classes d'agr\u00e9gation de jugement -- et de l'agr\u00e9gation de jugement g\u00e9n\u00e9rale et de l'agr\u00e9gation de pr\u00e9f\u00e9rences en particulier. Bien entendu, une logique n\u2019est int\u00e9ressante que dans la mesure o\u00f9 elle est expressive. L'un des objectifs de cet article est d'\u00e9tudier les capacit\u00e9s repr\u00e9sentationnelles et logiques dont un agent a besoin pour son jugement et son agr\u00e9gation de pr\u00e9f\u00e9rences ; c'est-\u00e0-dire, quel type de langage logique pourrait \u00eatre utilis\u00e9 pour repr\u00e9senter et raisonner sur l'agr\u00e9gation des jugements\u00a0? Le langage de repr\u00e9sentation des connaissances d'un agent doit \u00eatre capable d'exprimer : des r\u00e8gles d'agr\u00e9gation communes telles que le vote \u00e0 la majorit\u00e9 ; les propri\u00e9t\u00e9s couramment discut\u00e9es des r\u00e8gles d'agr\u00e9gation des jugements et des fonctions de protection sociale telles que l'ind\u00e9pendance ; paradoxes couramment utilis\u00e9s pour illustrer l'agr\u00e9gation de jugements et l'agr\u00e9gation de pr\u00e9f\u00e9rences, \u00e0 savoir. respectivement le paradoxe discursif et le paradoxe de Condorcet ; et d'autres propri\u00e9t\u00e9s importantes telles que le th\u00e9or\u00e8me d'Arrow. A partir de cet exemple, il semble qu'un langage formel pour les fonds souverains devrait \u00eatre capable d'exprimer : \u2022 Les propri\u00e9t\u00e9s des relations de pr\u00e9f\u00e9rence pour diff\u00e9rents agents, et les propri\u00e9t\u00e9s de plusieurs relations de pr\u00e9f\u00e9rence diff\u00e9rentes pour le m\u00eame agent dans la m\u00eame formule. \u2022 Comparaison de diff\u00e9rentes relations de pr\u00e9f\u00e9rence. \u2022 La relation de pr\u00e9f\u00e9rence r\u00e9sultant de l'application d'un SWF \u00e0 d'autres relations de pr\u00e9f\u00e9rence. A partir de ces points, il pourrait sembler qu'un tel langage serait plut\u00f4t complexe -LRB- en particulier, ces exigences semblent exclure une logique modale propositionnelle standard -RRB-. Dans la section suivante, nous passons en revue les bases de l'agr\u00e9gation de jugement ainsi que de l'agr\u00e9gation de pr\u00e9f\u00e9rences, et mentionnons certaines propri\u00e9t\u00e9s couramment discut\u00e9es des r\u00e8gles d'agr\u00e9gation de jugement et des fonctions de protection sociale. Les formules de JAL sont interpr\u00e9t\u00e9es directement par les r\u00e8gles d'agr\u00e9gation de jugement et repr\u00e9sentent donc leurs propri\u00e9t\u00e9s. Dans la section 4, nous d\u00e9montrons que la logique peut exprimer des propri\u00e9t\u00e9s commun\u00e9ment discut\u00e9es des r\u00e8gles d'agr\u00e9gation de jugement, telles que le paradoxe discursif. Nous donnons une axiomatisation solide et compl\u00e8te de la logique dans la section 5, sous l\u2019hypoth\u00e8se que l\u2019agenda sur lequel les agents portent des jugements est fini. Comme mentionn\u00e9 ci-dessus, l\u2019agr\u00e9gation des pr\u00e9f\u00e9rences peut \u00eatre consid\u00e9r\u00e9e comme un cas particulier d\u2019agr\u00e9gation des jugements, et dans la section 6, nous introduisons une interpr\u00e9tation alternative des formules JAL directement dans les fonctions de protection sociale. Nous obtenons \u00e9galement une axiomatisation solide et compl\u00e8te de la logique d\u2019agr\u00e9gation des pr\u00e9f\u00e9rences. Les sections 7 et 8 traitent des travaux connexes et concluent. 7. TRAVAUX CONNEXES Les logiques formelles li\u00e9es au choix social se sont principalement concentr\u00e9es sur la repr\u00e9sentation logique des pr\u00e9f\u00e9rences lorsque l'ensemble des alternatives est large et sur les propri\u00e9t\u00e9s de calcul du calcul des pr\u00e9f\u00e9rences agr\u00e9g\u00e9es pour une repr\u00e9sentation donn\u00e9e -LSB- 6, 7, 8 -RSB- . Une exception notable et r\u00e9cente est un cadre logique pour l'agr\u00e9gation de jugement d\u00e9velopp\u00e9 par Marc Pauly dans -LSB- 10 -RSB-,afin de pouvoir caract\u00e9riser les relations logiques entre diff\u00e9rentes r\u00e8gles d'agr\u00e9gation de jugement. La logique de fl\u00e8che de logique modale -LSB- 11 -RSB- est con\u00e7ue pour raisonner sur tout objet pouvant \u00eatre repr\u00e9sent\u00e9 graphiquement sous forme de fl\u00e8che, et poss\u00e8de divers op\u00e9rateurs modaux pour exprimer les propri\u00e9t\u00e9s et les relations entre ces fl\u00e8ches. Dans la logique d'agr\u00e9gation des pr\u00e9f\u00e9rences jal -LRB- LK -RRB-, nous avons interpr\u00e9t\u00e9 les formules par paires d'alternatives -- qui peuvent \u00eatre vues comme des fl\u00e8ches. Ainsi, -LRB- au moins -RRB- la variante d'agr\u00e9gation des pr\u00e9f\u00e9rences de notre logique est li\u00e9e \u00e0 la logique des fl\u00e8ches. Cependant, bien que les op\u00e9rateurs modaux de la logique des fl\u00e8ches puissent exprimer des propri\u00e9t\u00e9s de relations de pr\u00e9f\u00e9rence telles que la transitivit\u00e9, ils ne peuvent pas exprimer directement la plupart des propri\u00e9t\u00e9s dont nous avons discut\u00e9 dans cet article. N\u00e9anmoins, la relation avec la logique des fl\u00e8ches pourrait \u00eatre \u00e9tudi\u00e9e plus en d\u00e9tail dans des travaux futurs. En particulier, les logiques de fl\u00e8ches se r\u00e9v\u00e8lent g\u00e9n\u00e9ralement compl\u00e8tes. une alg\u00e8bre. Cela pourrait signifier qu\u2019il serait possible d\u2019utiliser de telles alg\u00e8bres comme structure sous-jacente pour repr\u00e9senter les pr\u00e9f\u00e9rences individuelles et collectives. Ensuite, changer le profil de pr\u00e9f\u00e9rence nous fait passer d'une alg\u00e8bre \u00e0 une autre, et un SWF d\u00e9termine la pr\u00e9f\u00e9rence collective, dans chacune des alg\u00e8bres. 8. DISCUSSION Nous avons pr\u00e9sent\u00e9 un jal logique solide et complet pour repr\u00e9senter et raisonner sur l'agr\u00e9gation des jugements. jal est expressif : il peut exprimer des r\u00e8gles d'agr\u00e9gation de jugements telles que le vote majoritaire ; propri\u00e9t\u00e9s compliqu\u00e9es telles que l'ind\u00e9pendance ; et des r\u00e9sultats importants tels que le paradoxe discursif, le th\u00e9or\u00e8me d'Arrow et le paradoxe de Condorcet. Nous soutenons que ces r\u00e9sultats montrent exactement de quelles capacit\u00e9s logiques un agent a besoin pour pouvoir raisonner sur l'agr\u00e9gation de jugements. Il est peut-\u00eatre surprenant qu'un langage relativement simple offre ces capacit\u00e9s. L'axiomatisation d\u00e9crit les principes logiques de l'agr\u00e9gation de jugements et peut \u00e9galement \u00eatre instanci\u00e9e pour raisonner sur des instances sp\u00e9cifiques d'agr\u00e9gation de jugements, telles que l'agr\u00e9gation de pr\u00e9f\u00e9rences arrovienne classique. Ainsi, notre cadre met en lumi\u00e8re les diff\u00e9rences entre les principes logiques derri\u00e8re l\u2019agr\u00e9gation g\u00e9n\u00e9rale des jugements, d\u2019une part, et l\u2019agr\u00e9gation classique des pr\u00e9f\u00e9rences, d\u2019autre part. Dans les travaux futurs, il serait int\u00e9ressant d'assouplir les exigences d'exhaustivit\u00e9 et de coh\u00e9rence des ensembles de jugement, et d'essayer de les caract\u00e9riser dans le langage logique, en tant que propri\u00e9t\u00e9s des ensembles de jugement g\u00e9n\u00e9raux.-LRB- au moins -RRB- la variante d'agr\u00e9gation des pr\u00e9f\u00e9rences de notre logique est li\u00e9e \u00e0 la logique des fl\u00e8ches. Cependant, bien que les op\u00e9rateurs modaux de la logique des fl\u00e8ches puissent exprimer des propri\u00e9t\u00e9s de relations de pr\u00e9f\u00e9rence telles que la transitivit\u00e9, ils ne peuvent pas exprimer directement la plupart des propri\u00e9t\u00e9s dont nous avons discut\u00e9 dans cet article. N\u00e9anmoins, la relation avec la logique des fl\u00e8ches pourrait \u00eatre \u00e9tudi\u00e9e plus en d\u00e9tail dans des travaux futurs. En particulier, les logiques de fl\u00e8ches se r\u00e9v\u00e8lent g\u00e9n\u00e9ralement compl\u00e8tes. une alg\u00e8bre. Cela pourrait signifier qu\u2019il serait possible d\u2019utiliser de telles alg\u00e8bres comme structure sous-jacente pour repr\u00e9senter les pr\u00e9f\u00e9rences individuelles et collectives. Ensuite, changer le profil de pr\u00e9f\u00e9rence nous fait passer d'une alg\u00e8bre \u00e0 une autre, et un SWF d\u00e9termine la pr\u00e9f\u00e9rence collective, dans chacune des alg\u00e8bres. 8. DISCUSSION Nous avons pr\u00e9sent\u00e9 un jal logique solide et complet pour repr\u00e9senter et raisonner sur l'agr\u00e9gation des jugements. jal est expressif : il peut exprimer des r\u00e8gles d'agr\u00e9gation de jugements telles que le vote majoritaire ; propri\u00e9t\u00e9s compliqu\u00e9es telles que l'ind\u00e9pendance ; et des r\u00e9sultats importants tels que le paradoxe discursif, le th\u00e9or\u00e8me d'Arrow et le paradoxe de Condorcet. Nous soutenons que ces r\u00e9sultats montrent exactement de quelles capacit\u00e9s logiques un agent a besoin pour pouvoir raisonner sur l'agr\u00e9gation de jugements. Il est peut-\u00eatre surprenant qu'un langage relativement simple offre ces capacit\u00e9s. L'axiomatisation d\u00e9crit les principes logiques de l'agr\u00e9gation de jugements et peut \u00e9galement \u00eatre instanci\u00e9e pour raisonner sur des instances sp\u00e9cifiques d'agr\u00e9gation de jugements, telles que l'agr\u00e9gation de pr\u00e9f\u00e9rences arrovienne classique. Ainsi, notre cadre met en lumi\u00e8re les diff\u00e9rences entre les principes logiques derri\u00e8re l\u2019agr\u00e9gation g\u00e9n\u00e9rale des jugements, d\u2019une part, et l\u2019agr\u00e9gation classique des pr\u00e9f\u00e9rences, d\u2019autre part. Dans les travaux futurs, il serait int\u00e9ressant d'assouplir les exigences d'exhaustivit\u00e9 et de coh\u00e9rence des ensembles de jugement, et d'essayer de les caract\u00e9riser dans le langage logique, en tant que propri\u00e9t\u00e9s des ensembles de jugement g\u00e9n\u00e9raux.-LRB- au moins -RRB- la variante d'agr\u00e9gation des pr\u00e9f\u00e9rences de notre logique est li\u00e9e \u00e0 la logique des fl\u00e8ches. Cependant, bien que les op\u00e9rateurs modaux de la logique des fl\u00e8ches puissent exprimer des propri\u00e9t\u00e9s de relations de pr\u00e9f\u00e9rence telles que la transitivit\u00e9, ils ne peuvent pas exprimer directement la plupart des propri\u00e9t\u00e9s dont nous avons discut\u00e9 dans cet article. N\u00e9anmoins, la relation avec la logique des fl\u00e8ches pourrait \u00eatre \u00e9tudi\u00e9e plus en d\u00e9tail dans des travaux futurs. En particulier, les logiques de fl\u00e8ches se r\u00e9v\u00e8lent g\u00e9n\u00e9ralement compl\u00e8tes. une alg\u00e8bre. Cela pourrait signifier qu\u2019il serait possible d\u2019utiliser de telles alg\u00e8bres comme structure sous-jacente pour repr\u00e9senter les pr\u00e9f\u00e9rences individuelles et collectives. Ensuite, changer le profil de pr\u00e9f\u00e9rence nous fait passer d'une alg\u00e8bre \u00e0 une autre, et un SWF d\u00e9termine la pr\u00e9f\u00e9rence collective, dans chacune des alg\u00e8bres. 8. DISCUSSION Nous avons pr\u00e9sent\u00e9 un jal logique solide et complet pour repr\u00e9senter et raisonner sur l'agr\u00e9gation des jugements. jal est expressif : il peut exprimer des r\u00e8gles d'agr\u00e9gation de jugements telles que le vote majoritaire ; propri\u00e9t\u00e9s compliqu\u00e9es telles que l'ind\u00e9pendance ; et des r\u00e9sultats importants tels que le paradoxe discursif, le th\u00e9or\u00e8me d'Arrow et le paradoxe de Condorcet. Nous soutenons que ces r\u00e9sultats montrent exactement de quelles capacit\u00e9s logiques un agent a besoin pour pouvoir raisonner sur l'agr\u00e9gation de jugements. Il est peut-\u00eatre surprenant qu'un langage relativement simple offre ces capacit\u00e9s. L'axiomatisation d\u00e9crit les principes logiques de l'agr\u00e9gation de jugements et peut \u00e9galement \u00eatre instanci\u00e9e pour raisonner sur des instances sp\u00e9cifiques d'agr\u00e9gation de jugements, telles que l'agr\u00e9gation de pr\u00e9f\u00e9rences arrovienne classique. Ainsi, notre cadre met en lumi\u00e8re les diff\u00e9rences entre les principes logiques derri\u00e8re l\u2019agr\u00e9gation g\u00e9n\u00e9rale des jugements, d\u2019une part, et l\u2019agr\u00e9gation classique des pr\u00e9f\u00e9rences, d\u2019autre part. Dans les travaux futurs, il serait int\u00e9ressant d'assouplir les exigences d'exhaustivit\u00e9 et de coh\u00e9rence des ensembles de jugement, et d'essayer de les caract\u00e9riser dans le langage logique, en tant que propri\u00e9t\u00e9s des ensembles de jugement g\u00e9n\u00e9raux.Th\u00e9or\u00e8me de Arrow et paradoxe de Condorcet. Nous soutenons que ces r\u00e9sultats montrent exactement de quelles capacit\u00e9s logiques un agent a besoin pour pouvoir raisonner sur l'agr\u00e9gation de jugements. Il est peut-\u00eatre surprenant qu'un langage relativement simple offre ces capacit\u00e9s. L'axiomatisation d\u00e9crit les principes logiques de l'agr\u00e9gation de jugements et peut \u00e9galement \u00eatre instanci\u00e9e pour raisonner sur des instances sp\u00e9cifiques d'agr\u00e9gation de jugements, telles que l'agr\u00e9gation de pr\u00e9f\u00e9rences arrovienne classique. Ainsi, notre cadre met en lumi\u00e8re les diff\u00e9rences entre les principes logiques derri\u00e8re l\u2019agr\u00e9gation g\u00e9n\u00e9rale des jugements, d\u2019une part, et l\u2019agr\u00e9gation classique des pr\u00e9f\u00e9rences, d\u2019autre part. Dans les travaux futurs, il serait int\u00e9ressant d'assouplir les exigences d'exhaustivit\u00e9 et de coh\u00e9rence des ensembles de jugement, et d'essayer de les caract\u00e9riser dans le langage logique, en tant que propri\u00e9t\u00e9s des ensembles de jugement g\u00e9n\u00e9raux.Th\u00e9or\u00e8me de Arrow et paradoxe de Condorcet. Nous soutenons que ces r\u00e9sultats montrent exactement de quelles capacit\u00e9s logiques un agent a besoin pour pouvoir raisonner sur l'agr\u00e9gation de jugements. Il est peut-\u00eatre surprenant qu'un langage relativement simple offre ces capacit\u00e9s. L'axiomatisation d\u00e9crit les principes logiques de l'agr\u00e9gation de jugements et peut \u00e9galement \u00eatre instanci\u00e9e pour raisonner sur des instances sp\u00e9cifiques d'agr\u00e9gation de jugements, telles que l'agr\u00e9gation de pr\u00e9f\u00e9rences arrovienne classique. Ainsi, notre cadre met en lumi\u00e8re les diff\u00e9rences entre les principes logiques derri\u00e8re l\u2019agr\u00e9gation g\u00e9n\u00e9rale des jugements, d\u2019une part, et l\u2019agr\u00e9gation classique des pr\u00e9f\u00e9rences, d\u2019autre part. Dans les travaux futurs, il serait int\u00e9ressant d'assouplir les exigences d'exhaustivit\u00e9 et de coh\u00e9rence des ensembles de jugement, et d'essayer de les caract\u00e9riser dans le langage logique, en tant que propri\u00e9t\u00e9s des ensembles de jugement g\u00e9n\u00e9raux.", "keyphrases": ["la connaissance repr\u00e9sente le formel", "fonction de protection sociale", "axiomatis complet", "syntaxe et s\u00e9mant de jal", "discute du paradoxe", "r\u00e8gle globale de jugement", "th\u00e9or\u00e8me de la fl\u00e8che", "exprimer", "non-dictature", "unanimit\u00e9", "pr\u00e9f\u00e9rer l'agr\u00e9gat", "logique de la fl\u00e8che", "Jal"]}
{"file_name": "C-27", "text": "Un syst\u00e8me de localisation de haute pr\u00e9cision et \u00e0 faible co\u00fbt pour les r\u00e9seaux de capteurs sans fil R\u00c9SUM\u00c9 Le probl\u00e8me de la localisation des n\u0153uds de capteurs sans fil a longtemps \u00e9t\u00e9 consid\u00e9r\u00e9 comme tr\u00e8s difficile \u00e0 r\u00e9soudre, compte tenu des r\u00e9alit\u00e9s des environnements du monde r\u00e9el. Dans cet article, nous d\u00e9crivons, concevons, impl\u00e9mentons et \u00e9valuons formellement un nouveau syst\u00e8me de localisation, appel\u00e9 Spotlight. Notre syst\u00e8me utilise les propri\u00e9t\u00e9s spatio-temporelles d'\u00e9v\u00e9nements bien contr\u00f4l\u00e9s dans le r\u00e9seau -LRB-, par exemple la lumi\u00e8re -RRB-, pour obtenir les emplacements des n\u0153uds de capteurs. Nous d\u00e9montrons qu'une grande pr\u00e9cision de localisation peut \u00eatre obtenue sans l'aide de mat\u00e9riel co\u00fbteux sur les n\u0153uds de capteurs, comme l'exigent d'autres syst\u00e8mes de localisation. Nous \u00e9valuons les performances de notre syst\u00e8me dans les d\u00e9ploiements de motes Mica2 et XSM. Gr\u00e2ce \u00e0 des \u00e9valuations des performances d'un syst\u00e8me r\u00e9el d\u00e9ploy\u00e9 en ext\u00e9rieur, nous obtenons une erreur de localisation de 20 cm. Un r\u00e9seau de capteurs, comportant un nombre quelconque de n\u0153uds, d\u00e9ploy\u00e9 dans une zone de 2 500 m2, peut \u00eatre localis\u00e9 en moins de 10 minutes, \u00e0 l'aide d'un appareil qui co\u00fbte moins de 1 000 dollars. \u00c0 notre connaissance, il s'agit du premier rapport d'un sous-r\u00e9seau de capteurs. erreur de localisation du compteur, obtenue dans un environnement ext\u00e9rieur, sans \u00e9quiper les n\u0153uds de capteurs sans fil d'un mat\u00e9riel de t\u00e9l\u00e9m\u00e9trie sp\u00e9cialis\u00e9. 1. INTRODUCTION R\u00e9cemment, les syst\u00e8mes de r\u00e9seaux de capteurs sans fil ont \u00e9t\u00e9 utilis\u00e9s dans de nombreuses applications prometteuses, notamment la surveillance militaire, la surveillance de l'habitat, le suivi de la faune, etc. -LSB- 12 -RSB- -LSB- 22 -RSB- -LSB- 33 -RSB- -LSB - 36 -RSB-. M\u00eame si de nombreux services middleware destin\u00e9s \u00e0 prendre en charge ces applications ont \u00e9t\u00e9 con\u00e7us et mis en \u0153uvre avec succ\u00e8s, la localisation (trouver la position des n\u0153uds de capteurs) reste l'un des d\u00e9fis de recherche les plus difficiles \u00e0 r\u00e9soudre en pratique. Un GPS embarqu\u00e9 -LSB- 23 -RSB- est une solution haut de gamme typique, qui n\u00e9cessite un mat\u00e9riel sophistiqu\u00e9 pour obtenir une synchronisation temporelle haute r\u00e9solution avec les satellites. Les contraintes de puissance et de co\u00fbt des minuscules n\u0153uds de capteurs excluent cette solution viable. D'autres solutions n\u00e9cessitent des p\u00e9riph\u00e9riques par n\u0153ud capables d'effectuer des op\u00e9rations entre les n\u0153uds voisins. Les difficult\u00e9s de ces approches sont doubles. Premi\u00e8rement, sous les contraintes de facteur de forme et d\u2019alimentation \u00e9lectrique, les port\u00e9es efficaces de tels dispositifs sont tr\u00e8s limit\u00e9es. Par exemple, la port\u00e9e effective des transducteurs ultrasoniques utilis\u00e9s dans le syst\u00e8me Cricket est inf\u00e9rieure \u00e0 2 m\u00e8tres lorsque l'\u00e9metteur et le r\u00e9cepteur ne se font pas face -LSB- 26 -RSB-. Deuxi\u00e8mement, \u00e9tant donn\u00e9 que la plupart des n\u0153uds de capteurs sont statiques, c'est-\u00e0-dire que leur emplacement ne devrait pas changer, il n'est pas rentable d'\u00e9quiper ces capteurs de circuits sp\u00e9ciaux uniquement pour une localisation ponctuelle. Pour surmonter ces limitations, de nombreux sch\u00e9mas de localisation sans port\u00e9e ont \u00e9t\u00e9 propos\u00e9s. La plupart de ces sch\u00e9mas estiment l'emplacement des n\u0153uds de capteurs en exploitant les informations de connectivit\u00e9 radio entre les n\u0153uds voisins. Ces approches \u00e9liminent le besoin de mat\u00e9riel sp\u00e9cialis\u00e9 co\u00fbteux, au prix d\u2019une localisation moins pr\u00e9cise. En outre,les caract\u00e9ristiques de propagation radio varient dans le temps et d\u00e9pendent de l'environnement, imposant ainsi des co\u00fbts d'\u00e9talonnage \u00e9lev\u00e9s pour les sch\u00e9mas de localisation sans port\u00e9e. Notre r\u00e9ponse \u00e0 ce d\u00e9fi est un syst\u00e8me de localisation appel\u00e9 Spotlight. Ce syst\u00e8me utilise une architecture asym\u00e9trique, dans laquelle les n\u0153uds de capteurs n'ont besoin d'aucun mat\u00e9riel suppl\u00e9mentaire, autre que celui dont ils disposent actuellement. Tout le mat\u00e9riel et les calculs sophistiqu\u00e9s r\u00e9sident sur un seul appareil Spotlight. Le dispositif Spotlight utilise une source de lumi\u00e8re laser orientable, \u00e9clairant les n\u0153uds de capteurs plac\u00e9s dans un terrain connu. Dans le m\u00eame temps, \u00e9tant donn\u00e9 qu\u2019un seul appareil sophistiqu\u00e9 est n\u00e9cessaire pour localiser l\u2019ensemble du r\u00e9seau, le co\u00fbt amorti est bien inf\u00e9rieur au co\u00fbt d\u2019ajout de composants mat\u00e9riels aux capteurs individuels. 2. TRAVAUX CONNEXES Le probl\u00e8me de la localisation est un probl\u00e8me de recherche fondamental dans de nombreux domaines. Les erreurs de localisation signal\u00e9es sont de l'ordre de plusieurs dizaines de centim\u00e8tres, lorsqu'on utilise du mat\u00e9riel de t\u00e9l\u00e9m\u00e9trie sp\u00e9cialis\u00e9, par exemple un t\u00e9l\u00e9m\u00e8tre laser ou des ultrasons. En raison du co\u00fbt \u00e9lev\u00e9 et du facteur de forme non n\u00e9gligeable du mat\u00e9riel de t\u00e9l\u00e9m\u00e9trie, ces solutions ne peuvent pas \u00eatre simplement appliqu\u00e9es aux r\u00e9seaux de capteurs. Le RSSI s'est av\u00e9r\u00e9 une solution int\u00e9ressante pour estimer la distance entre l'\u00e9metteur et le destinataire. Le syst\u00e8me RADAR -LSB- 2 -RSB- utilise le RSSI pour cr\u00e9er un r\u00e9f\u00e9rentiel centralis\u00e9 de l'intensit\u00e9 des signaux \u00e0 diverses positions par rapport \u00e0 un ensemble de n\u0153uds de balise. La localisation d'un utilisateur mobile est estim\u00e9e \u00e0 quelques m\u00e8tres pr\u00e8s. Dans une approche similaire, MoteTrack -LSB- 17 -RSB- distribue les valeurs RSSI de r\u00e9f\u00e9rence aux n\u0153uds de balise. Des solutions qui utilisent RSSI et ne n\u00e9cessitent pas de n\u0153uds de balise ont \u00e9galement \u00e9t\u00e9 propos\u00e9es -LSB- 5 -RSB- -LSB- 14 -RSB- -LSB- 24 -RSB- -LSB- 26 -RSB- -LSB- 29 -RSB-. Ils partagent tous l\u2019id\u00e9e d\u2019utiliser une balise mobile. Les n\u0153uds de capteurs qui re\u00e7oivent les balises appliquent diff\u00e9rents algorithmes pour d\u00e9duire leur emplacement. Dans -LSB- 29 -RSB-, Sichitiu propose une solution dans laquelle les n\u0153uds qui re\u00e7oivent la balise construisent, sur la base de la valeur RSSI, une contrainte sur leur estimation de position. Dans -LSB-24-RSB-, Pathirana et al. formule le probl\u00e8me de localisation sous la forme d'une estimation en ligne dans un syst\u00e8me dynamique non lin\u00e9aire et propose un filtre de Kalman \u00e9tendu robuste pour le r\u00e9soudre. Elnahrawy -LSB-8-RSB- fournit des preuves solides des limites inh\u00e9rentes \u00e0 la pr\u00e9cision de la localisation \u00e0 l'aide du RSSI, dans des environnements int\u00e9rieurs. Une technique de t\u00e9l\u00e9m\u00e9trie plus pr\u00e9cise utilise la diff\u00e9rence de temps entre un signal radio et une onde acoustique pour obtenir des distances par paires entre les n\u0153uds de capteurs. Cette approche produit des erreurs de localisation plus petites, au prix de mat\u00e9riel suppl\u00e9mentaire. Le syst\u00e8me d'aide \u00e0 la localisation Cricket -LSB-25-RSB- peut atteindre une granularit\u00e9 de localisation de plusieurs dizaines de centim\u00e8tres avec des \u00e9metteurs-r\u00e9cepteurs \u00e0 ultrasons \u00e0 courte port\u00e9e. AHLoS, propos\u00e9 par Savvides et al. -LSB- 27 -RSB-, utilise des techniques de t\u00e9l\u00e9m\u00e9trie de l'heure d'arriv\u00e9e -LRB- ToA -RRB- qui n\u00e9cessitent un mat\u00e9riel \u00e9tendu et la r\u00e9solution de syst\u00e8mes d'\u00e9quations non lin\u00e9aires relativement grands.Dans -LSB-30-RSB-, Simon et al. mettre en \u0153uvre un syst\u00e8me distribu\u00e9 -LRB- utilisant la t\u00e9l\u00e9m\u00e9trie acoustique -RRB- qui localise un tireur d'\u00e9lite en terrain urbain. La t\u00e9l\u00e9m\u00e9trie acoustique pour la localisation est \u00e9galement utilis\u00e9e par Kwon et al. -LSB- 15 -RSB-. Les erreurs de localisation signal\u00e9es varient de 2,2 m \u00e0 9,5 m, selon le type -LRB- centralis\u00e9 ou distribu\u00e9 -RRB- de l'algorithme de mise \u00e0 l'\u00e9chelle des moindres carr\u00e9s utilis\u00e9. Pour les r\u00e9seaux de capteurs sans fil, la t\u00e9l\u00e9m\u00e9trie est une option difficile. Cependant, la grande pr\u00e9cision de localisation obtenue par ces sch\u00e9mas est tr\u00e8s souhaitable. Pour surmonter les d\u00e9fis pos\u00e9s par les sch\u00e9mas de localisation bas\u00e9s sur la port\u00e9e, lorsqu'ils sont appliqu\u00e9s aux r\u00e9seaux de capteurs, une approche diff\u00e9rente a \u00e9t\u00e9 propos\u00e9e et \u00e9valu\u00e9e dans le pass\u00e9. Cette approche est appel\u00e9e sans port\u00e9e et tente d'obtenir des informations de localisation \u00e0 partir de la proximit\u00e9 d'un ensemble de n\u0153uds de balise connus. Bulusu et coll. proposent dans -LSB- 4 -RSB- un sch\u00e9ma de localisation, appel\u00e9 Centroid, dans lequel chaque n\u0153ud se localise au centro\u00efde de ses n\u0153uds balises proches. Le syst\u00e8me de coordonn\u00e9es globales -LSB-20-RSB-, d\u00e9velopp\u00e9 au MIT, utilise la connaissance a priori de la densit\u00e9 des n\u0153uds dans le r\u00e9seau, pour estimer la distance moyenne des sauts. La famille DV - * de sch\u00e9mas de localisation -LSB- 21 -RSB- utilise le nombre de sauts depuis les n\u0153uds de balise connus jusqu'aux n\u0153uds du r\u00e9seau pour d\u00e9duire la distance. La majorit\u00e9 des sch\u00e9mas de localisation sans port\u00e9e ont \u00e9t\u00e9 \u00e9valu\u00e9s dans des simulations ou dans des environnements contr\u00f4l\u00e9s. Langendoen et Reijers pr\u00e9sentent une \u00e9tude comparative d\u00e9taill\u00e9e de plusieurs sch\u00e9mas de localisation dans -LSB-16-RSB-. \u00c0 notre connaissance, Spotlight est le premier syst\u00e8me de localisation sans port\u00e9e qui fonctionne tr\u00e8s bien dans un environnement ext\u00e9rieur. Notre syst\u00e8me n\u00e9cessite une ligne de vue entre un seul appareil et les n\u0153uds de capteurs, ainsi qu'une carte du terrain o\u00f9 se trouve le champ du capteur. Le syst\u00e8me Spotlight a une longue port\u00e9e effective -LRB- de 1 000 m\u00e8tres -RRB- et ne n\u00e9cessite aucune infrastructure ni mat\u00e9riel suppl\u00e9mentaire pour les n\u0153uds de capteurs. Le syst\u00e8me Spotlight combine les avantages et ne souffre pas des inconv\u00e9nients des deux classes de localisation. 7. CONCLUSIONS ET TRAVAUX FUTURS Dans cet article, nous avons pr\u00e9sent\u00e9 la conception, la mise en \u0153uvre et l'\u00e9valuation d'un syst\u00e8me de localisation pour les r\u00e9seaux de capteurs sans fil, appel\u00e9 Spotlight. Notre solution de localisation ne n\u00e9cessite aucun mat\u00e9riel suppl\u00e9mentaire pour les n\u0153uds capteurs, autre que ce qui existe d\u00e9j\u00e0. Toute la complexit\u00e9 du syst\u00e8me est regroup\u00e9e dans un seul appareil Spotlight. Notre syst\u00e8me de localisation est r\u00e9utilisable, c'est-\u00e0-dire que les co\u00fbts peuvent \u00eatre amortis sur plusieurs d\u00e9ploiements, et ses performances ne sont pas affect\u00e9es par le nombre de n\u0153uds capteurs dans le r\u00e9seau. Nos r\u00e9sultats exp\u00e9rimentaux, obtenus \u00e0 partir d'un syst\u00e8me r\u00e9el d\u00e9ploy\u00e9 en ext\u00e9rieur, montrent que l'erreur de localisation est inf\u00e9rieure \u00e0 20 cm. Cette erreur est actuellement l'\u00e9tat de l'art,m\u00eame pour les syst\u00e8mes de localisation bas\u00e9s sur la distance et elle est 75 % inf\u00e9rieure \u00e0 l'erreur obtenue lors de l'utilisation d'appareils GPS ou lorsque le d\u00e9ploiement manuel de n\u0153uds de capteurs est une option r\u00e9alisable -LSB- 31 -RSB-. Dans le cadre de travaux futurs, nous aimerions explorer l'auto-calibrage et l'auto-r\u00e9glage du syst\u00e8me Spotlight. La pr\u00e9cision du syst\u00e8me peut \u00eatre encore am\u00e9lior\u00e9e si la distribution de l'\u00e9v\u00e9nement, au lieu d'un horodatage unique, est signal\u00e9e. Une g\u00e9n\u00e9ralisation pourrait \u00eatre obtenue en reformulant le probl\u00e8me comme un probl\u00e8me d\u2019estimation angulaire qui fournit les \u00e9l\u00e9ments de base pour des techniques de localisation plus g\u00e9n\u00e9rales.", "keyphrases": ["r\u00e9seau de capteurs sans fil", "locale", "local de base de rang", "syst\u00e8me sans sonnerie", "transmis", "effectuer", "pr\u00e9cision", "erreur locale", "r\u00e9seau de capteurs", "syst\u00e8me de projecteurs", "technique locale", "distribuer"]}
{"file_name": "C-17", "text": "Probl\u00e8mes de d\u00e9ploiement d'un syst\u00e8me de conf\u00e9rence VoIP dans un environnement de conf\u00e9rence virtuelle R\u00c9SUM\u00c9 Les services en temps r\u00e9el ont \u00e9t\u00e9 largement pris en charge sur les r\u00e9seaux \u00e0 commutation de circuits. Les tendances r\u00e9centes favorisent les services port\u00e9s sur les r\u00e9seaux \u00e0 commutation de paquets. Pour l'audioconf\u00e9rence, nous devons prendre en compte de nombreux probl\u00e8mes\u00a0: \u00e9volutivit\u00e9, qualit\u00e9 de l'application de conf\u00e9rence, contr\u00f4le de l'\u00e9tage et charge sur les clients/serveurs, pour n'en nommer que quelques-uns. Dans cet article, nous d\u00e9crivons un cadre de service audio con\u00e7u pour fournir un environnement de conf\u00e9rence virtuelle -LRB-VCE-RRB-. Le syst\u00e8me est con\u00e7u pour accueillir un grand nombre d\u2019utilisateurs finaux parlant en m\u00eame temps et r\u00e9partis sur Internet. Le framework est bas\u00e9 sur les serveurs de conf\u00e9rence -LSB-14-RSB-, qui facilitent la gestion audio, tandis que nous exploitons les capacit\u00e9s SIP \u00e0 des fins de signalisation. La s\u00e9lection des clients est bas\u00e9e sur un quantificateur r\u00e9cent appel\u00e9 \u00ab Loudness Number \u00bb qui permet d'imiter une conf\u00e9rence physique en face \u00e0 face. Nous abordons les probl\u00e9matiques de d\u00e9ploiement de la solution propos\u00e9e tant en termes d'\u00e9volutivit\u00e9 que d'interactivit\u00e9, tout en expliquant les techniques que nous utilisons pour r\u00e9duire le trafic. Nous avons impl\u00e9ment\u00e9 une application Conference Server -LRB-CS-RRB- sur un r\u00e9seau \u00e0 l'\u00e9chelle du campus de notre Institut. 1. INTRODUCTION L'Internet d'aujourd'hui utilise la suite de protocoles IP qui a \u00e9t\u00e9 principalement con\u00e7ue pour le transport de donn\u00e9es et qui permet une livraison de donn\u00e9es au mieux. Les contraintes et caract\u00e9ristiques de d\u00e9lai s\u00e9parent les donn\u00e9es traditionnelles d'une part des applications voix et vid\u00e9o d'autre part. Par cons\u00e9quent, \u00e0 mesure que des applications voix et vid\u00e9o sensibles au facteur temps sont d\u00e9ploy\u00e9es sur Internet, l\u2019insuffisance d\u2019Internet est r\u00e9v\u00e9l\u00e9e. De plus, nous cherchons \u00e0 porter les services t\u00e9l\u00e9phoniques sur Internet. Parmi eux, la conf\u00e9rence virtuelle -LRB- t\u00e9l\u00e9conf\u00e9rence -RRB- est \u00e0 la pointe. Les conf\u00e9rences audio et vid\u00e9o sur Internet sont populaires -LSB- 25 -RSB- pour les nombreux avantages qu'elles pr\u00e9sentent -LSB- 3,6 -RSB-. De toute \u00e9vidence, la bande passante requise pour une t\u00e9l\u00e9conf\u00e9rence sur Internet augmente rapidement avec le nombre de participants ; r\u00e9duire la bande passante sans compromettre la qualit\u00e9 audio est un d\u00e9fi en t\u00e9l\u00e9phonie Internet. Il y a de nombreuses discussions au sein de la communaut\u00e9 HCI et CSCW sur l'utilisation de l'ethnom\u00e9thodologie pour la conception d'applications CSCW. L\u2019approche de base consiste \u00e0 fournir une bande passante plus large, davantage de fonctionnalit\u00e9s et des m\u00e9canismes de contr\u00f4le plus avanc\u00e9s, dans l\u2019attente d\u2019une meilleure qualit\u00e9 d\u2019interaction. Cette approche ignore l'utilit\u00e9 fonctionnelle de l'environnement utilis\u00e9 pour la collaboration. Il est donc n\u00e9cessaire d\u2019adopter une approche qui tienne compte des deux aspects : le technique et le fonctionnel. Dans ce travail, nous n'abordons pas la vid\u00e9oconf\u00e9rence ; son inclusion ne profite pas de mani\u00e8re significative \u00e0 la qualit\u00e9 de la conf\u00e9rence -LSB- 4 -RSB-. Nous nous concentrons sur les environnements audio virtuels. Nous d\u00e9crivons d\u2019abord les d\u00e9fis rencontr\u00e9s dans les audioconf\u00e9rences virtuelles. Nous examinons ensuite les motivations suivies par la litt\u00e9rature pertinente. Dans la section 5,nous expliquons l'architecture de notre syst\u00e8me. La section 6 comprend la description des diff\u00e9rents algorithmes utilis\u00e9s dans notre configuration. Nous r\u00e9solvons les probl\u00e8mes de d\u00e9ploiement. S'ensuit une discussion sur la performance. Nous concluons en abordant quelques probl\u00e8mes de mise en \u0153uvre. 4. TRAVAUX CONNEXES La norme SIP d\u00e9finie dans la RFC 3261 -LSB- 22 -RSB- et dans les extensions ult\u00e9rieures telles que -LSB- 21 -RSB- n'offre pas de services de contr\u00f4le de conf\u00e9rence tels que le contr\u00f4le d'\u00e9tage ou le vote et ne prescrit pas comment un Fig. 1. Exemple de conf\u00e9rence -- 3 domaines contenant les entit\u00e9s n\u00e9cessaires pour que la conf\u00e9rence puisse avoir lieu. la conf\u00e9rence doit \u00eatre g\u00e9r\u00e9e. Cependant, SIP peut \u00eatre utilis\u00e9 pour lancer une session utilisant un autre protocole de contr\u00f4le de conf\u00e9rence. La sp\u00e9cification SIP principale prend en charge de nombreux mod\u00e8les de conf\u00e9rence -LSB- 26, 23 -RSB-. Dans les mod\u00e8les bas\u00e9s sur serveur, un serveur m\u00e9lange les flux multim\u00e9dias, tandis que dans une conf\u00e9rence sans serveur, le m\u00e9lange est effectu\u00e9 au niveau des syst\u00e8mes finaux. SDP -LSB- 7 -RSB- peut \u00eatre utilis\u00e9 pour d\u00e9finir les capacit\u00e9s multim\u00e9dias et fournir d'autres informations sur la conf\u00e9rence. Nous allons maintenant consid\u00e9rer quelques mod\u00e8les de conf\u00e9rence en SIP qui ont \u00e9t\u00e9 propos\u00e9s r\u00e9cemment -LSB-23-RSB-. Tout d\u2019abord, examinons les mod\u00e8les sans serveur. Dans End-System Mixing, un seul client -LRB-SIP UA -RRB- g\u00e8re la signalisation et le mixage multim\u00e9dia pour tous les autres, ce qui n'est clairement pas \u00e9volutif et pose des probl\u00e8mes lorsque ce client particulier quitte la conf\u00e9rence. Cela conduit \u00e0 un nombre croissant de sauts pour les feuilles distantes et n'est pas \u00e9volutif. Une autre option consisterait \u00e0 utiliser la multidiffusion pour les conf\u00e9rences, mais la multidiffusion n'est pas activ\u00e9e sur Internet et n'est actuellement possible que sur un r\u00e9seau local. Parmi les mod\u00e8les bas\u00e9s sur serveur, dans une conf\u00e9rence Dial-In, les UA se connectent \u00e0 un serveur central qui g\u00e8re tout le mixage. Ce mod\u00e8le n'est pas \u00e9volutif car il est limit\u00e9 par la puissance de traitement du serveur et la bande passante du r\u00e9seau. Les conf\u00e9rences centralis\u00e9es ad hoc et les serveurs de conf\u00e9rence par num\u00e9rotation sortante pr\u00e9sentent des m\u00e9canismes et des probl\u00e8mes similaires. Les mod\u00e8les hybrides impliquant une signalisation centralis\u00e9e et des m\u00e9dias distribu\u00e9s, ces derniers utilisant la monodiffusion ou la multidiffusion, posent comme auparavant des probl\u00e8mes d'\u00e9volutivit\u00e9. Cependant, l'avantage est que le contr\u00f4le de conf\u00e9rence peut \u00eatre une solution tierce. La perte de spatialisme lorsqu'ils se m\u00e9langent et l'augmentation de la bande passante lorsqu'ils ne se m\u00e9langent pas sont des probl\u00e8mes ouverts. Une \u00e9tude connexe -LSB- 19 -RSB- du m\u00eame auteur propose une architecture de conf\u00e9rence pour les environnements virtuels collaboratifs -LRB-CVEs-RRB- mais ne fournit pas l'angle d'\u00e9volutivit\u00e9 sans la disponibilit\u00e9 de la multidiffusion. En gardant \u00e0 l\u2019esprit les limites des syst\u00e8mes de conf\u00e9rence propos\u00e9s, nous allons maintenant d\u00e9tailler notre proposition. 9. CONCLUSION Dans cet article, nous avons pr\u00e9sent\u00e9 une discussion sur un environnement de conf\u00e9rence virtuelle uniquement vocale. Nous avons soutenu que la nature distribu\u00e9e du d\u00e9ploiement le rend ici \u00e9volutif. L'interactivit\u00e9 est obtenue en adaptant un sch\u00e9ma de s\u00e9lection de flux r\u00e9cent bas\u00e9 sur le Loudness Number. Ainsi, il existe une utilisation consid\u00e9rablement efficace de la bande passante.Ceux-ci font de la parole impromptue lors d\u2019une t\u00e9l\u00e9conf\u00e9rence virtuelle sur VoIP une r\u00e9alit\u00e9, comme dans une v\u00e9ritable conf\u00e9rence en face \u00e0 face. Le trafic dans le WAN -LRB-Internet -RRB- est limit\u00e9 au carr\u00e9 du nombre de domaines -- encore r\u00e9duit gr\u00e2ce \u00e0 l'utilisation d'algorithmes heuristiques -- ce qui est bien inf\u00e9rieur au nombre total de clients participant \u00e0 la conf\u00e9rence. Cela est d\u00fb \u00e0 l'utilisation d'un serveur de conf\u00e9rence local \u00e0 chaque domaine. Les techniques VAD contribuent \u00e0 r\u00e9duire davantage le trafic. L'utilisation du standard SIP pour la signalisation rend cette solution hautement interop\u00e9rable. Nous avons impl\u00e9ment\u00e9 une application CS sur un r\u00e9seau \u00e0 l'\u00e9chelle du campus. Nous pensons que cette nouvelle g\u00e9n\u00e9ration d'environnements de conf\u00e9rence virtuelle gagnera en popularit\u00e9 \u00e0 l'avenir car sa facilit\u00e9 de d\u00e9ploiement est assur\u00e9e gr\u00e2ce \u00e0 des technologies facilement disponibles et des cadres \u00e9volutifs.", "keyphrases": ["syst\u00e8me de conf\u00e9rence VoIP", "r\u00e9seau \u00e0 commutation de paquets", "cadre de service audio", "environnement de conf\u00e9rence virtuelle", "Conf\u00e9rer le serveur", "num\u00e9ro fort", "m\u00e9lange partiel", "d\u00e9tection d'activation vocale", "suffisant de trois locuteurs simultan\u00e9s", "vad technique"]}
{"file_name": "H-30", "text": "Expansion de concepts latents \u00e0 l'aide de champs al\u00e9atoires de Markov R\u00c9SUM\u00c9 L'expansion des requ\u00eates, sous la forme de commentaires de pseudo-pertinence ou de commentaires de pertinence, est une technique courante utilis\u00e9e pour am\u00e9liorer l'efficacit\u00e9 de la r\u00e9cup\u00e9ration. La plupart des approches pr\u00e9c\u00e9dentes ont ignor\u00e9 des questions importantes, telles que le r\u00f4le des fonctionnalit\u00e9s et l\u2019importance de la mod\u00e9lisation des d\u00e9pendances des termes. Dans cet article, nous proposons une technique robuste d'expansion de requ\u00eates bas\u00e9e sur le mod\u00e8le de champ al\u00e9atoire de Markov pour la recherche d'informations. La technique, appel\u00e9e expansion de concepts latents, fournit un m\u00e9canisme permettant de mod\u00e9liser les d\u00e9pendances des termes au cours de l'expansion. De plus, l\u2019utilisation de caract\u00e9ristiques arbitraires dans le mod\u00e8le fournit un cadre puissant pour aller au-del\u00e0 des simples caract\u00e9ristiques d\u2019occurrence de termes qui sont implicitement utilis\u00e9es par la plupart des autres techniques d\u2019expansion. Nous \u00e9valuons notre technique par rapport aux mod\u00e8les de pertinence, une technique d'expansion de requ\u00eates de mod\u00e9lisation de langage de pointe. Notre mod\u00e8le d\u00e9montre des am\u00e9liorations coh\u00e9rentes et significatives de l\u2019efficacit\u00e9 de la r\u00e9cup\u00e9ration sur plusieurs ensembles de donn\u00e9es TREC. Nous d\u00e9crivons \u00e9galement comment notre technique peut \u00eatre utilis\u00e9e pour g\u00e9n\u00e9rer des concepts multitermes significatifs pour des t\u00e2ches telles que la suggestion/reformulation de requ\u00eates. 1. INTRODUCTION \u00e9ventuellement un r\u00e9cit plus long. Une grande quantit\u00e9 d\u2019informations est perdue au cours du processus de traduction du besoin d\u2019information \u00e0 la requ\u00eate r\u00e9elle. Pour cette raison, les techniques d\u2019expansion des requ\u00eates suscitent un vif int\u00e9r\u00eat. De telles techniques sont utilis\u00e9es pour augmenter la requ\u00eate originale afin de produire une repr\u00e9sentation qui refl\u00e8te mieux le besoin d'information sous-jacent. Les techniques d'expansion des requ\u00eates ont \u00e9t\u00e9 bien \u00e9tudi\u00e9es pour divers mod\u00e8les dans le pass\u00e9 et ont montr\u00e9 qu'elles am\u00e9lioraient consid\u00e9rablement l'efficacit\u00e9 \u00e0 la fois dans le cadre du feedback de pertinence et du feedback de pseudo-pertinence -LSB- 12, 21, 28, 29 -RSB-. Le mod\u00e8le MRF g\u00e9n\u00e9ralise l'unigramme, le bigramme et d'autres mod\u00e8les de d\u00e9pendance -LSB- 14 -RSB-. La plupart des mod\u00e8les de d\u00e9pendance \u00e0 terme ant\u00e9rieurs n'ont pas r\u00e9ussi \u00e0 montrer des am\u00e9liorations coh\u00e9rentes et significatives par rapport aux lignes de base de l'unigramme, \u00e0 quelques exceptions pr\u00e8s -LSB-8-RSB-. Jusqu\u2019\u00e0 pr\u00e9sent, le mod\u00e8le \u00e9tait uniquement utilis\u00e9 pour classer des documents en r\u00e9ponse \u00e0 une requ\u00eate donn\u00e9e. Dans ce travail, nous montrons comment le mod\u00e8le peut \u00eatre \u00e9tendu et utilis\u00e9 pour l'expansion de requ\u00eates en utilisant une technique que nous appelons expansion de concept latent -LRB-LCE-RRB-. Il y a trois contributions principales \u00e0 notre travail. Premi\u00e8rement, LCE fournit un m\u00e9canisme permettant de combiner la d\u00e9pendance des termes avec l'expansion des requ\u00eates. Les techniques d\u2019expansion de requ\u00eates pr\u00e9c\u00e9dentes sont bas\u00e9es sur des mod\u00e8les de sacs de mots. Par cons\u00e9quent, en effectuant une expansion des requ\u00eates \u00e0 l\u2019aide du mod\u00e8le MRF, nous sommes en mesure d\u2019\u00e9tudier la dynamique entre la d\u00e9pendance des termes et l\u2019expansion des requ\u00eates. Ensuite, comme nous le montrerons, le mod\u00e8le MRF permet d'utiliser des fonctionnalit\u00e9s arbitraires dans le mod\u00e8le. Dans le pass\u00e9, les techniques d\u2019expansion des requ\u00eates utilisaient implicitement uniquement les fonctionnalit\u00e9s d\u2019occurrence de termes. En utilisant des ensembles de fonctionnalit\u00e9s plus robustes, il est possible de produire de meilleurs termes d'expansion qui font une meilleure distinction entre les documents pertinents et non pertinents. Enfin,notre approche propos\u00e9e fournit de mani\u00e8re transparente un m\u00e9canisme permettant de g\u00e9n\u00e9rer des concepts \u00e0 la fois uniques et multitermes. La plupart des techniques pr\u00e9c\u00e9dentes g\u00e9n\u00e8rent par d\u00e9faut des termes ind\u00e9pendamment. Il y a eu plusieurs approches qui utilisent des concepts g\u00e9n\u00e9ralis\u00e9s, mais ces approches \u00e9taient quelque peu heuristiques et r\u00e9alis\u00e9es en dehors du mod\u00e8le -LSB- 19, 28 -RSB-. Notre approche est \u00e0 la fois formellement motiv\u00e9e et constitue une extension naturelle du mod\u00e8le sous-jacent. Dans la section 2, nous d\u00e9crivons les approches associ\u00e9es d\u2019expansion des requ\u00eates. La section 3 donne un aper\u00e7u du mod\u00e8le MRF et d\u00e9taille notre technique d'expansion de concept latent propos\u00e9e. Dans la section 4, nous \u00e9valuons notre mod\u00e8le propos\u00e9 et analysons les r\u00e9sultats. 2. TRAVAUX CONNEXES L'une des approches classiques et les plus largement utilis\u00e9es pour l'expansion des requ\u00eates est l'algorithme de Rocchio -LSB-21-RSB-. L'approche de Rocchio, qui a \u00e9t\u00e9 d\u00e9velopp\u00e9e dans le mod\u00e8le d'espace vectoriel, repond\u00e8re le vecteur de requ\u00eate original en d\u00e9pla\u00e7ant les pond\u00e9rations vers l'ensemble des documents pertinents ou pseudo-pertinents et en les \u00e9loignant des documents non pertinents. Malheureusement, il n'est pas possible d'appliquer formellement l'approche de Rocchio \u00e0 un mod\u00e8le de recherche statistique, tel que la mod\u00e9lisation linguistique pour la recherche d'informations. Un certain nombre de techniques formalis\u00e9es d'expansion de requ\u00eates ont \u00e9t\u00e9 d\u00e9velopp\u00e9es pour le cadre de mod\u00e9lisation du langage, notamment la r\u00e9troaction bas\u00e9e sur un mod\u00e8le de Zhai et Lafferty et les mod\u00e8les de pertinence de Lavrenko et Croft -LSB- 12, 29 -RSB-. Les deux approches tentent d'utiliser des documents pseudo-pertinents ou pertinents pour estimer un meilleur mod\u00e8le de requ\u00eate. Le feedback bas\u00e9 sur un mod\u00e8le trouve le mod\u00e8le qui d\u00e9crit le mieux les documents pertinents tout en prenant en compte un mod\u00e8le de bruit de fond -LRB-RRB-. Cela s\u00e9pare le mod\u00e8le de contenu du mod\u00e8le d'arri\u00e8re-plan. Le mod\u00e8le de contenu est ensuite interpol\u00e9 avec le mod\u00e8le de requ\u00eate d'origine pour former la requ\u00eate d\u00e9velopp\u00e9e. L\u2019autre technique, les mod\u00e8les de pertinence, est plus \u00e9troitement li\u00e9e \u00e0 nos travaux. Nous entrons donc dans les d\u00e9tails du mod\u00e8le. Tout comme les commentaires bas\u00e9s sur un mod\u00e8le, les mod\u00e8les de pertinence estiment un mod\u00e8le de requ\u00eate am\u00e9lior\u00e9. La seule diff\u00e9rence entre les deux approches est que les mod\u00e8les de pertinence ne mod\u00e9lisent pas explicitement les documents pertinents ou pseudo-pertinents. Au lieu de cela, ils mod\u00e9lisent une notion plus g\u00e9n\u00e9ralis\u00e9e de pertinence, comme nous le montrons maintenant. \u00c9tant donn\u00e9 une requ\u00eate Q, un mod\u00e8le de pertinence est une distribution multinomiale, P -LRB- \u00b7 | Q -RRB-, qui code la probabilit\u00e9 de chaque terme \u00e9tant donn\u00e9 la requ\u00eate comme preuve. Il est calcul\u00e9 comme suit\u00a0: o\u00f9 RQ est l'ensemble des documents pertinents ou pseudo-pertinents pour interroger Q. Ces hypoth\u00e8ses douces rendent le calcul du post\u00e9rieur bay\u00e9sien plus pratique. Une fois le mod\u00e8le estim\u00e9, les documents sont class\u00e9s en d\u00e9coupant le mod\u00e8le de pertinence en choisissant les k termes les plus probables parmi P -LRB- \u00b7 | Q -RRB-. Cette distribution \u00e9cr\u00eat\u00e9e est ensuite interpol\u00e9e avec le mod\u00e8le de requ\u00eate original \u00e0 maximum de vraisemblance -LSB-1-RSB-. Cela peut \u00eatre consid\u00e9r\u00e9 comme une extension de la requ\u00eate d'origine par k termes pond\u00e9r\u00e9s. Dans la suite de ce travail,nous appelons cette instanciation de mod\u00e8les de pertinence RM3. Il y a eu relativement peu de travaux r\u00e9alis\u00e9s dans le domaine de l'expansion des requ\u00eates dans le context des mod\u00e8les de d\u00e9pendance -LSB-9-RSB-. Cependant, il y a eu plusieurs tentatives d'expansion en utilisant des concepts multitermes. La m\u00e9thode d'analyse du context local -LRB- LCA -RRB- de Xu et Croft combinait la r\u00e9cup\u00e9ration au niveau des passages avec l'expansion des concepts, o\u00f9 les concepts \u00e9taient des termes et des expressions uniques -LSB- 28 -RSB-. Les concepts d'expansion ont \u00e9t\u00e9 choisis et pond\u00e9r\u00e9s \u00e0 l'aide d'une m\u00e9trique bas\u00e9e sur des statistiques de cooccurrence. Papka et Allan \u00e9tudient l'utilisation du retour d'information sur la pertinence pour effectuer une expansion de concepts multitermes pour le routage de documents -LSB-19-RSB-. Les r\u00e9sultats ont montr\u00e9 que la combinaison de concepts \u00e0 terme unique et de concepts multitermes \u00e0 grande fen\u00eatre am\u00e9liorait consid\u00e9rablement l\u2019efficacit\u00e9. 5. CONCLUSIONS Dans cet article, nous avons propos\u00e9 une technique robuste d'expansion de requ\u00eates appel\u00e9e expansion de concept latent. La technique s'est av\u00e9r\u00e9e \u00eatre une extension naturelle du mod\u00e8le de champ al\u00e9atoire de Markov pour la recherche d'informations et une g\u00e9n\u00e9ralisation des mod\u00e8les de pertinence. Nous avons montr\u00e9 que la technique peut \u00eatre utilis\u00e9e pour produire des concepts d\u2019expansion multitermes de haute qualit\u00e9, bien form\u00e9s et pertinents sur le plan th\u00e9matique. Les concepts g\u00e9n\u00e9r\u00e9s peuvent \u00eatre utilis\u00e9s dans un module alternatif de suggestion de requ\u00eates. Nous avons \u00e9galement montr\u00e9 que le mod\u00e8le est tr\u00e8s efficace. En fait, il permet d\u2019obtenir des am\u00e9liorations significatives de la pr\u00e9cision moyenne par rapport aux mod\u00e8les de pertinence sur une s\u00e9lection d\u2019ensembles de donn\u00e9es TREC. Il a \u00e9galement \u00e9t\u00e9 d\u00e9montr\u00e9 que le mod\u00e8le MRF lui-m\u00eame, sans aucune extension de requ\u00eate, surpasse les mod\u00e8les de pertinence sur de grands ensembles de donn\u00e9es Web. Enfin, nous avons r\u00e9it\u00e9r\u00e9 l\u2019importance de choisir des termes d\u2019expansion qui mod\u00e9lisent la pertinence, plut\u00f4t que les documents pertinents, et avons montr\u00e9 comment LCE capture \u00e0 la fois les d\u00e9pendances syntaxiques et s\u00e9mantiques c\u00f4t\u00e9 requ\u00eate. Les travaux futurs porteront \u00e9galement sur l'int\u00e9gration des d\u00e9pendances c\u00f4t\u00e9 document.Les concepts g\u00e9n\u00e9r\u00e9s peuvent \u00eatre utilis\u00e9s dans un module alternatif de suggestion de requ\u00eates. Nous avons \u00e9galement montr\u00e9 que le mod\u00e8le est tr\u00e8s efficace. En fait, il permet d\u2019obtenir des am\u00e9liorations significatives de la pr\u00e9cision moyenne par rapport aux mod\u00e8les de pertinence sur une s\u00e9lection d\u2019ensembles de donn\u00e9es TREC. Il a \u00e9galement \u00e9t\u00e9 d\u00e9montr\u00e9 que le mod\u00e8le MRF lui-m\u00eame, sans aucune extension de requ\u00eate, surpasse les mod\u00e8les de pertinence sur de grands ensembles de donn\u00e9es Web. Enfin, nous avons r\u00e9it\u00e9r\u00e9 l\u2019importance de choisir des termes d\u2019expansion qui mod\u00e9lisent la pertinence, plut\u00f4t que les documents pertinents, et avons montr\u00e9 comment LCE capture \u00e0 la fois les d\u00e9pendances syntaxiques et s\u00e9mantiques c\u00f4t\u00e9 requ\u00eate. Les travaux futurs porteront \u00e9galement sur l'int\u00e9gration des d\u00e9pendances c\u00f4t\u00e9 document.Les concepts g\u00e9n\u00e9r\u00e9s peuvent \u00eatre utilis\u00e9s dans un module alternatif de suggestion de requ\u00eates. Nous avons \u00e9galement montr\u00e9 que le mod\u00e8le est tr\u00e8s efficace. En fait, il permet d\u2019obtenir des am\u00e9liorations significatives de la pr\u00e9cision moyenne par rapport aux mod\u00e8les de pertinence sur une s\u00e9lection d\u2019ensembles de donn\u00e9es TREC. Il a \u00e9galement \u00e9t\u00e9 d\u00e9montr\u00e9 que le mod\u00e8le MRF lui-m\u00eame, sans aucune extension de requ\u00eate, surpasse les mod\u00e8les de pertinence sur de grands ensembles de donn\u00e9es Web. Enfin, nous avons r\u00e9it\u00e9r\u00e9 l\u2019importance de choisir des termes d\u2019expansion qui mod\u00e9lisent la pertinence, plut\u00f4t que les documents pertinents, et avons montr\u00e9 comment LCE capture \u00e0 la fois les d\u00e9pendances syntaxiques et s\u00e9mantiques c\u00f4t\u00e9 requ\u00eate. Les travaux futurs porteront \u00e9galement sur l'int\u00e9gration des d\u00e9pendances c\u00f4t\u00e9 document.", "keyphrases": ["queri robuste \u00e9tend la technique", "mod\u00e8le de langue queri d\u00e9veloppe la technique", "commentaires pertinents", "feedback pseudo-pertinent", "informer la r\u00e9cup\u00e9ration", "approche du mod\u00e8le linguistique", "recherche Internet", "requ\u00eate s'\u00e9tend", "mrf", "algorithme de Rocchio", "cadre de mod\u00e8le linguistique", "RM3", "acheminement des documents", "r\u00e9cup\u00e9ration ad hoc", "mod\u00e8le mrf", "distribution pertinente"]}
{"file_name": "I-10", "text": "SMILE : Sound Multi-agent Incremental LEarning ;--RRB- * R\u00c9SUM\u00c9 Cet article traite de la probl\u00e9matique de l'apprentissage collaboratif dans un syst\u00e8me multi-agents. Ici, chaque agent peut mettre \u00e0 jour progressivement ses croyances B -LRB- la repr\u00e9sentation conceptuelle -RRB- afin qu'elle soit d'une mani\u00e8re maintenue coh\u00e9rente avec l'ensemble des informations K -LRB- les exemples -RRB- qu'il a re\u00e7us de l'environnement ou d'autres agents. Nous \u00e9tendons cette notion de coh\u00e9rence -LRB- ou de solidit\u00e9 -RRB- \u00e0 l'ensemble du SMA et discutons de la mani\u00e8re d'obtenir qu'\u00e0 tout instant, une m\u00eame repr\u00e9sentation conceptuelle coh\u00e9rente soit pr\u00e9sente dans chaque agent. Le protocole correspondant est appliqu\u00e9 \u00e0 l\u2019apprentissage supervis\u00e9 de concepts. La m\u00e9thode r\u00e9sultante SMILE -LRB- pour Sound Multiagent Incremental LEarning -RRB- est d\u00e9crite et exp\u00e9riment\u00e9e ici. \u00c9tonnamment, certaines formules bool\u00e9ennes difficiles sont mieux apprises, avec le m\u00eame ensemble d'apprentissage, par un syst\u00e8me multi-agents que par un seul agent. 1. INTRODUCTION Cet article traite du probl\u00e8me de l'apprentissage collaboratif de concepts dans un syst\u00e8me multi-agents. -LSB- 6 -RSB- introduit une caract\u00e9risation de l'apprentissage en syst\u00e8me multi-agents en fonction du niveau de conscience des agents. Au niveau 1, les agents apprennent * L'auteur principal de cet article est un \u00e9tudiant. dans le syst\u00e8me sans tenir compte de la pr\u00e9sence d'autres agents, sauf \u00e0 travers la modification apport\u00e9e au milieu par leur action. Le niveau 2 implique une interaction directe entre les agents car ils peuvent \u00e9changer des messages pour am\u00e9liorer leur apprentissage. Nous nous concentrons dans cet article sur le niveau 2, \u00e9tudiant l'interaction directe entre les agents impliqu\u00e9s dans un processus d'apprentissage. Chaque agent est suppos\u00e9 \u00eatre capable d'apprendre progressivement \u00e0 partir des donn\u00e9es qu'il re\u00e7oit, ce qui signifie que chaque agent peut mettre \u00e0 jour son ensemble de croyances B pour le maintenir coh\u00e9rent avec l'ensemble des informations K qu'il a re\u00e7ues de l'environnement ou d'autres agents. De plus, nous supposons qu'au moins une partie Bc des croyances de chaque agent est commune \u00e0 tous les agents et doit le rester. Ainsi, une mise \u00e0 jour de cet ensemble commun Bc par l\u2019agent r doit provoquer une mise \u00e0 jour de Bc pour l\u2019ensemble de la communaut\u00e9 d\u2019agents. Cela nous am\u00e8ne \u00e0 d\u00e9finir quelle est la mas-coh\u00e9rence d'un agent par rapport \u00e0 la communaut\u00e9. Le processus de mise \u00e0 jour des croyances de la communaut\u00e9 lorsqu'un de ses membres obtient de nouvelles informations peut alors \u00eatre d\u00e9fini comme le processus de maintien de la coh\u00e9rence garantissant que chaque agent de la communaut\u00e9 restera coh\u00e9rent. Ce processus de maintien de la coh\u00e9rence par rapport \u00e0 l'obtention de nouvelles informations par un agent lui conf\u00e8re le r\u00f4le d'apprenant et implique une communication avec d'autres agents agissant en tant que critiques. Cependant, les agents ne sont pas sp\u00e9cialis\u00e9s et peuvent tour \u00e0 tour \u00eatre des apprenants ou des critiques, aucun d\u2019entre eux n\u2019\u00e9tant cantonn\u00e9 \u00e0 un r\u00f4le pr\u00e9cis. Les informations sont r\u00e9parties entre les agents, mais peuvent \u00eatre redondantes. Il n'y a pas de m\u00e9moire centrale. Le travail d\u00e9crit ici trouve son origine dans un travail ant\u00e9rieur concernant l'apprentissage dans un syst\u00e8me multi-agent intentionnel utilisant un formalisme BDI -LSB- 6 -RSB-. Dans ce travail,les agents avaient des plans, chacun d'eux \u00e9tant associ\u00e9 \u00e0 un context d\u00e9finissant dans quelles conditions il peut \u00eatre d\u00e9clench\u00e9. Les plans -LRB- ayant chacun son propre context -RRB- \u00e9taient communs \u00e0 l'ensemble des agents de la communaut\u00e9. Les agents devaient adapter les contexts de leurs plans en fonction de l'\u00e9chec ou du succ\u00e8s des plans ex\u00e9cut\u00e9s, en utilisant un m\u00e9canisme d'apprentissage et en demandant \u00e0 d'autres agents des exemples de r\u00e9ussites ou d'\u00e9checs de plans -LRB- -RRB-. Il manquait cependant \u00e0 ces travaux un protocole d'apprentissage collectif permettant une r\u00e9elle autonomie du syst\u00e8me multi-agents. L\u2019\u00e9tude d\u2019un tel protocole fait l\u2019objet du pr\u00e9sent article. Dans la section 2, nous d\u00e9finissons formellement la plus grande coh\u00e9rence d'un m\u00e9canisme de mise \u00e0 jour pour l'ensemble du MAS et nous proposons un m\u00e9canisme de mise \u00e0 jour g\u00e9n\u00e9rique qui s'est av\u00e9r\u00e9 le plus coh\u00e9rent. Dans la section 3, nous d\u00e9crivons SMILE, un apprenant de concepts multi-agents incr\u00e9mentiel appliquant notre m\u00e9canisme de mise \u00e0 jour coh\u00e9rente mas \u00e0 l'apprentissage de concepts collaboratif. La section 4 d\u00e9crit diverses exp\u00e9riences sur SMILE et aborde diverses questions, notamment la fa\u00e7on dont l'exactitude et la simplicit\u00e9 de l'hypoth\u00e8se actuelle varient lorsque l'on compare l'apprentissage mono-agent et l'apprentissage mas. Dans la section 5, nous pr\u00e9sentons bri\u00e8vement quelques travaux connexes, puis concluons dans la section 6 en discutant d'investigations plus approfondies sur l'apprentissage coh\u00e9rent. 5. TRAVAUX CONNEXES Depuis 96 -LSB- 15 -RSB-, divers travaux ont \u00e9t\u00e9 r\u00e9alis\u00e9s sur l'apprentissage en MAS, mais assez peu sur l'apprentissage de concepts. Dans -LSB- 11 -RSB- le MAS effectue une forme d'apprentissage d'ensemble dans lequel les agents sont des apprenants paresseux -LRB- aucune repr\u00e9sentation explicite n'est maintenue -RRB- et vendent des exemples inutiles \u00e0 d'autres agents. Dans -LSB- 10 -RSB- chaque agent observe tous les exemples mais ne per\u00e7oit qu'une partie de leur repr\u00e9sentation. Dans l'apprentissage mutuel de concepts en ligne -LSB-14-RSB-, les agents convergent vers une hypoth\u00e8se unique, mais chaque agent produit des exemples \u00e0 partir de sa propre repr\u00e9sentation de concept, ce qui entra\u00eene une sorte de synchronisation plut\u00f4t qu'un pur apprentissage de concepts. 6. CONCLUSION Nous avons pr\u00e9sent\u00e9 ici et exp\u00e9riment\u00e9 un protocole pour l'apprentissage des concepts en ligne MAS. N\u00e9anmoins, notre cadre est ouvert, c'est \u00e0 dire que les agents peuvent quitter le syst\u00e8me ou y entrer tout en pr\u00e9servant le m\u00e9canisme de coh\u00e9rence. Par exemple, si nous introduisons un m\u00e9canisme de timeout, m\u00eame lorsqu'un agent critique plante ou omet de r\u00e9pondre, la coh\u00e9rence avec les autres critiques -LRB- au sein des agents -RRB- restants est impliqu\u00e9e. D'autres travaux portent d'abord sur le couplage de l'induction et de l'abduction afin d'effectuer un apprentissage collaboratif de concepts lorsque les exemples ne sont que partiellement observ\u00e9s par chaque agent, et deuxi\u00e8mement, sur l'apprentissage partiel de la m\u00e9moire : comment l'apprentissage est pr\u00e9serv\u00e9 lorsqu'un agent ou l'ensemble du MAS oublie certains exemples s\u00e9lectionn\u00e9s.Les agents devaient adapter les contexts de leurs plans en fonction de l'\u00e9chec ou du succ\u00e8s des plans ex\u00e9cut\u00e9s, en utilisant un m\u00e9canisme d'apprentissage et en demandant \u00e0 d'autres agents des exemples de r\u00e9ussites ou d'\u00e9checs de plans -LRB- -RRB-. Il manquait cependant \u00e0 ces travaux un protocole d'apprentissage collectif permettant une r\u00e9elle autonomie du syst\u00e8me multi-agents. L\u2019\u00e9tude d\u2019un tel protocole fait l\u2019objet du pr\u00e9sent article. Dans la section 2, nous d\u00e9finissons formellement la plus grande coh\u00e9rence d'un m\u00e9canisme de mise \u00e0 jour pour l'ensemble du MAS et nous proposons un m\u00e9canisme de mise \u00e0 jour g\u00e9n\u00e9rique qui s'est av\u00e9r\u00e9 le plus coh\u00e9rent. Dans la section 3, nous d\u00e9crivons SMILE, un apprenant de concepts multi-agents incr\u00e9mentiel appliquant notre m\u00e9canisme de mise \u00e0 jour coh\u00e9rente mas \u00e0 l'apprentissage de concepts collaboratif. La section 4 d\u00e9crit diverses exp\u00e9riences sur SMILE et aborde diverses questions, notamment la fa\u00e7on dont l'exactitude et la simplicit\u00e9 de l'hypoth\u00e8se actuelle varient lorsque l'on compare l'apprentissage mono-agent et l'apprentissage mas. Dans la section 5, nous pr\u00e9sentons bri\u00e8vement quelques travaux connexes, puis concluons dans la section 6 en discutant d'investigations plus approfondies sur l'apprentissage coh\u00e9rent. 5. TRAVAUX CONNEXES Depuis 96 -LSB- 15 -RSB-, divers travaux ont \u00e9t\u00e9 r\u00e9alis\u00e9s sur l'apprentissage en MAS, mais assez peu sur l'apprentissage de concepts. Dans -LSB- 11 -RSB- le MAS effectue une forme d'apprentissage d'ensemble dans lequel les agents sont des apprenants paresseux -LRB- aucune repr\u00e9sentation explicite n'est maintenue -RRB- et vendent des exemples inutiles \u00e0 d'autres agents. Dans -LSB- 10 -RSB- chaque agent observe tous les exemples mais ne per\u00e7oit qu'une partie de leur repr\u00e9sentation. Dans l'apprentissage mutuel de concepts en ligne -LSB-14-RSB-, les agents convergent vers une hypoth\u00e8se unique, mais chaque agent produit des exemples \u00e0 partir de sa propre repr\u00e9sentation de concept, ce qui entra\u00eene une sorte de synchronisation plut\u00f4t qu'un pur apprentissage de concepts. 6. CONCLUSION Nous avons pr\u00e9sent\u00e9 ici et exp\u00e9riment\u00e9 un protocole pour l'apprentissage des concepts en ligne MAS. N\u00e9anmoins, notre cadre est ouvert, c'est \u00e0 dire que les agents peuvent quitter le syst\u00e8me ou y entrer tout en pr\u00e9servant le m\u00e9canisme de coh\u00e9rence. Par exemple, si nous introduisons un m\u00e9canisme de timeout, m\u00eame lorsqu'un agent critique plante ou omet de r\u00e9pondre, la coh\u00e9rence avec les autres critiques -LRB- au sein des agents -RRB- restants est impliqu\u00e9e. D'autres travaux portent d'abord sur le couplage de l'induction et de l'abduction afin d'effectuer un apprentissage collaboratif de concepts lorsque les exemples ne sont que partiellement observ\u00e9s par chaque agent, et deuxi\u00e8mement, sur l'apprentissage partiel de la m\u00e9moire : comment l'apprentissage est pr\u00e9serv\u00e9 lorsqu'un agent ou l'ensemble du MAS oublie certains exemples s\u00e9lectionn\u00e9s.Les agents devaient adapter les contexts de leurs plans en fonction de l'\u00e9chec ou du succ\u00e8s des plans ex\u00e9cut\u00e9s, en utilisant un m\u00e9canisme d'apprentissage et en demandant \u00e0 d'autres agents des exemples de r\u00e9ussites ou d'\u00e9checs de plans -LRB- -RRB-. Il manquait cependant \u00e0 ces travaux un protocole d'apprentissage collectif permettant une r\u00e9elle autonomie du syst\u00e8me multi-agents. L\u2019\u00e9tude d\u2019un tel protocole fait l\u2019objet du pr\u00e9sent article. Dans la section 2, nous d\u00e9finissons formellement la plus grande coh\u00e9rence d'un m\u00e9canisme de mise \u00e0 jour pour l'ensemble du MAS et nous proposons un m\u00e9canisme de mise \u00e0 jour g\u00e9n\u00e9rique qui s'est av\u00e9r\u00e9 le plus coh\u00e9rent. Dans la section 3, nous d\u00e9crivons SMILE, un apprenant de concepts multi-agents incr\u00e9mentiel appliquant notre m\u00e9canisme de mise \u00e0 jour coh\u00e9rente mas \u00e0 l'apprentissage de concepts collaboratif. La section 4 d\u00e9crit diverses exp\u00e9riences sur SMILE et aborde diverses questions, notamment la fa\u00e7on dont l'exactitude et la simplicit\u00e9 de l'hypoth\u00e8se actuelle varient lorsque l'on compare l'apprentissage mono-agent et l'apprentissage mas. Dans la section 5, nous pr\u00e9sentons bri\u00e8vement quelques travaux connexes, puis concluons dans la section 6 en discutant d'investigations plus approfondies sur l'apprentissage coh\u00e9rent. 5. TRAVAUX CONNEXES Depuis 96 -LSB- 15 -RSB-, divers travaux ont \u00e9t\u00e9 r\u00e9alis\u00e9s sur l'apprentissage en MAS, mais assez peu sur l'apprentissage de concepts. Dans -LSB- 11 -RSB- le MAS effectue une forme d'apprentissage d'ensemble dans lequel les agents sont des apprenants paresseux -LRB- aucune repr\u00e9sentation explicite n'est maintenue -RRB- et vendent des exemples inutiles \u00e0 d'autres agents. Dans -LSB- 10 -RSB- chaque agent observe tous les exemples mais ne per\u00e7oit qu'une partie de leur repr\u00e9sentation. Dans l'apprentissage mutuel de concepts en ligne -LSB-14-RSB-, les agents convergent vers une hypoth\u00e8se unique, mais chaque agent produit des exemples \u00e0 partir de sa propre repr\u00e9sentation de concept, ce qui entra\u00eene une sorte de synchronisation plut\u00f4t qu'un pur apprentissage de concepts. 6. CONCLUSION Nous avons pr\u00e9sent\u00e9 ici et exp\u00e9riment\u00e9 un protocole pour l'apprentissage des concepts en ligne MAS. N\u00e9anmoins, notre cadre est ouvert, c'est-\u00e0-dire que les agents peuvent quitter le syst\u00e8me ou y entrer tout en pr\u00e9servant le m\u00e9canisme de coh\u00e9rence. Par exemple, si nous introduisons un m\u00e9canisme de timeout, m\u00eame lorsqu'un agent critique plante ou omet de r\u00e9pondre, la coh\u00e9rence avec les autres critiques -LRB- au sein des agents -RRB- restants est impliqu\u00e9e. D'autres travaux portent d'abord sur le couplage de l'induction et de l'abduction afin d'effectuer un apprentissage collaboratif de concepts lorsque les exemples ne sont que partiellement observ\u00e9s par chaque agent, et deuxi\u00e8mement, sur l'apprentissage partiel de la m\u00e9moire : comment l'apprentissage est pr\u00e9serv\u00e9 lorsqu'un agent ou l'ensemble du MAS oublie certains exemples s\u00e9lectionn\u00e9s.un apprenant de concept multi-agents incr\u00e9mentiel appliquant notre m\u00e9canisme de mise \u00e0 jour coh\u00e9rent mas \u00e0 l'apprentissage de concepts collaboratif. La section 4 d\u00e9crit diverses exp\u00e9riences sur SMILE et aborde diverses questions, notamment la fa\u00e7on dont l'exactitude et la simplicit\u00e9 de l'hypoth\u00e8se actuelle varient lorsque l'on compare l'apprentissage mono-agent et l'apprentissage mas. Dans la section 5, nous pr\u00e9sentons bri\u00e8vement quelques travaux connexes, puis concluons dans la section 6 en discutant d'investigations plus approfondies sur l'apprentissage coh\u00e9rent. 5. TRAVAUX CONNEXES Depuis 96 -LSB- 15 -RSB-, divers travaux ont \u00e9t\u00e9 r\u00e9alis\u00e9s sur l'apprentissage en MAS, mais assez peu sur l'apprentissage de concepts. Dans -LSB- 11 -RSB- le MAS effectue une forme d'apprentissage d'ensemble dans lequel les agents sont des apprenants paresseux -LRB- aucune repr\u00e9sentation explicite n'est maintenue -RRB- et vendent des exemples inutiles \u00e0 d'autres agents. Dans -LSB- 10 -RSB- chaque agent observe tous les exemples mais ne per\u00e7oit qu'une partie de leur repr\u00e9sentation. Dans l'apprentissage mutuel de concepts en ligne -LSB-14-RSB-, les agents convergent vers une hypoth\u00e8se unique, mais chaque agent produit des exemples \u00e0 partir de sa propre repr\u00e9sentation de concept, ce qui entra\u00eene une sorte de synchronisation plut\u00f4t qu'un pur apprentissage de concepts. 6. CONCLUSION Nous avons pr\u00e9sent\u00e9 ici et exp\u00e9riment\u00e9 un protocole pour l'apprentissage des concepts en ligne MAS. N\u00e9anmoins, notre cadre est ouvert, c'est \u00e0 dire que les agents peuvent quitter le syst\u00e8me ou y entrer tout en pr\u00e9servant le m\u00e9canisme de coh\u00e9rence. Par exemple, si nous introduisons un m\u00e9canisme de timeout, m\u00eame lorsqu'un agent critique plante ou omet de r\u00e9pondre, la coh\u00e9rence avec les autres critiques -LRB- au sein des agents -RRB- restants est impliqu\u00e9e. D'autres travaux portent d'abord sur le couplage de l'induction et de l'abduction afin d'effectuer un apprentissage collaboratif de concepts lorsque les exemples ne sont que partiellement observ\u00e9s par chaque agent, et deuxi\u00e8mement, sur l'apprentissage partiel de la m\u00e9moire : comment l'apprentissage est pr\u00e9serv\u00e9 lorsqu'un agent ou l'ensemble du MAS oublie certains exemples s\u00e9lectionn\u00e9s.un apprenant de concept multi-agents incr\u00e9mentiel appliquant notre m\u00e9canisme de mise \u00e0 jour coh\u00e9rent mas \u00e0 l'apprentissage de concepts collaboratif. La section 4 d\u00e9crit diverses exp\u00e9riences sur SMILE et aborde diverses questions, notamment la fa\u00e7on dont l'exactitude et la simplicit\u00e9 de l'hypoth\u00e8se actuelle varient lorsque l'on compare l'apprentissage mono-agent et l'apprentissage mas. Dans la section 5, nous pr\u00e9sentons bri\u00e8vement quelques travaux connexes, puis concluons dans la section 6 en discutant d'investigations plus approfondies sur l'apprentissage coh\u00e9rent. 5. TRAVAUX CONNEXES Depuis 96 -LSB- 15 -RSB-, divers travaux ont \u00e9t\u00e9 r\u00e9alis\u00e9s sur l'apprentissage en MAS, mais assez peu sur l'apprentissage de concepts. Dans -LSB- 11 -RSB- le MAS effectue une forme d'apprentissage d'ensemble dans lequel les agents sont des apprenants paresseux -LRB- aucune repr\u00e9sentation explicite n'est maintenue -RRB- et vendent des exemples inutiles \u00e0 d'autres agents. Dans -LSB- 10 -RSB- chaque agent observe tous les exemples mais ne per\u00e7oit qu'une partie de leur repr\u00e9sentation. Dans l'apprentissage mutuel de concepts en ligne -LSB-14-RSB-, les agents convergent vers une hypoth\u00e8se unique, mais chaque agent produit des exemples \u00e0 partir de sa propre repr\u00e9sentation de concept, ce qui entra\u00eene une sorte de synchronisation plut\u00f4t qu'un pur apprentissage de concepts. 6. CONCLUSION Nous avons pr\u00e9sent\u00e9 ici et exp\u00e9riment\u00e9 un protocole pour l'apprentissage des concepts en ligne MAS. N\u00e9anmoins, notre cadre est ouvert, c'est \u00e0 dire que les agents peuvent quitter le syst\u00e8me ou y entrer tout en pr\u00e9servant le m\u00e9canisme de coh\u00e9rence. Par exemple, si nous introduisons un m\u00e9canisme de timeout, m\u00eame lorsqu'un agent critique plante ou omet de r\u00e9pondre, la coh\u00e9rence avec les autres critiques -LRB- au sein des agents -RRB- restants est impliqu\u00e9e. D'autres travaux portent d'abord sur le couplage de l'induction et de l'abduction afin d'effectuer un apprentissage collaboratif de concepts lorsque les exemples ne sont que partiellement observ\u00e9s par chaque agent, et deuxi\u00e8mement, sur l'apprentissage partiel de la m\u00e9moire : comment l'apprentissage est pr\u00e9serv\u00e9 lorsqu'un agent ou l'ensemble du MAS oublie certains exemples s\u00e9lectionn\u00e9s.aboutissant ainsi \u00e0 une sorte de synchronisation plut\u00f4t qu\u2019\u00e0 un pur apprentissage de concepts. 6. CONCLUSION Nous avons pr\u00e9sent\u00e9 ici et exp\u00e9riment\u00e9 un protocole pour l'apprentissage des concepts en ligne MAS. N\u00e9anmoins, notre cadre est ouvert, c'est \u00e0 dire que les agents peuvent quitter le syst\u00e8me ou y entrer tout en pr\u00e9servant le m\u00e9canisme de coh\u00e9rence. Par exemple, si nous introduisons un m\u00e9canisme de timeout, m\u00eame lorsqu'un agent critique plante ou omet de r\u00e9pondre, la coh\u00e9rence avec les autres critiques -LRB- au sein des agents -RRB- restants est impliqu\u00e9e. D'autres travaux portent d'abord sur le couplage de l'induction et de l'abduction afin d'effectuer un apprentissage collaboratif de concepts lorsque les exemples ne sont que partiellement observ\u00e9s par chaque agent, et deuxi\u00e8mement, sur l'apprentissage partiel de la m\u00e9moire : comment l'apprentissage est pr\u00e9serv\u00e9 lorsqu'un agent ou l'ensemble du MAS oublie certains exemples s\u00e9lectionn\u00e9s.aboutissant ainsi \u00e0 une sorte de synchronisation plut\u00f4t qu\u2019\u00e0 un pur apprentissage de concepts. 6. CONCLUSION Nous avons pr\u00e9sent\u00e9 ici et exp\u00e9riment\u00e9 un protocole pour l'apprentissage des concepts en ligne MAS. N\u00e9anmoins, notre cadre est ouvert, c'est \u00e0 dire que les agents peuvent quitter le syst\u00e8me ou y entrer tout en pr\u00e9servant le m\u00e9canisme de coh\u00e9rence. Par exemple, si nous introduisons un m\u00e9canisme de timeout, m\u00eame lorsqu'un agent critique plante ou omet de r\u00e9pondre, la coh\u00e9rence avec les autres critiques -LRB- au sein des agents -RRB- restants est impliqu\u00e9e. D'autres travaux portent d'abord sur le couplage de l'induction et de l'abduction afin d'effectuer un apprentissage collaboratif de concepts lorsque les exemples ne sont que partiellement observ\u00e9s par chaque agent, et deuxi\u00e8mement, sur l'apprentissage partiel de la m\u00e9moire : comment l'apprentissage est pr\u00e9serv\u00e9 lorsqu'un agent ou l'ensemble du MAS oublie certains exemples s\u00e9lectionn\u00e9s.", "keyphrases": ["apprentissage multi-agents", "apprendre le concept de collaboration", "apprendre le processus", "connaissance", "ma-consiste", "incr\u00e9menter apprendre", "agent", "m\u00e9canisme de mise \u00e0 jour", "synchronis\u00e9"]}
{"file_name": "H-31", "text": "Une \u00e9tude du mod\u00e8le de g\u00e9n\u00e9ration de requ\u00eates de Poisson pour la recherche d'informations R\u00c9SUM\u00c9 De nombreuses variantes de mod\u00e8les de langage ont \u00e9t\u00e9 propos\u00e9es pour la recherche d'informations. La plupart des mod\u00e8les existants sont bas\u00e9s sur une distribution multinomiale et attribueraient une note aux documents en fonction de la probabilit\u00e9 de requ\u00eate calcul\u00e9e sur la base d'un mod\u00e8le probabiliste de g\u00e9n\u00e9ration de requ\u00eates. Dans cet article, nous proposons et \u00e9tudions une nouvelle famille de mod\u00e8les de g\u00e9n\u00e9ration de requ\u00eates bas\u00e9s sur la distribution de Poisson. Nous montrons que m\u00eame si dans leurs formes les plus simples, la nouvelle famille de mod\u00e8les et les mod\u00e8les multinomiaux existants sont \u00e9quivalents, ils se comportent diff\u00e9remment pour de nombreuses m\u00e9thodes de lissage. Nous montrons que le mod\u00e8le de Poisson pr\u00e9sente plusieurs avantages par rapport au mod\u00e8le multinomial, notamment celui de s'adapter naturellement au lissage par terme et de permettre une mod\u00e9lisation d'arri\u00e8re-plan plus pr\u00e9cise. Nous pr\u00e9sentons plusieurs variantes du nouveau mod\u00e8le correspondant \u00e0 diff\u00e9rentes m\u00e9thodes de lissage, et les \u00e9valuons sur quatre collections de tests TREC repr\u00e9sentatives. Les r\u00e9sultats montrent que m\u00eame si leurs mod\u00e8les de base fonctionnent de mani\u00e8re comparable, le mod\u00e8le de Poisson peut surpasser le mod\u00e8le multinomial avec un lissage par terme. Les performances peuvent \u00eatre encore am\u00e9lior\u00e9es avec un lissage en deux \u00e9tapes. 1. INTRODUCTION En tant que nouveau type de mod\u00e8les de r\u00e9cup\u00e9ration probabilistes, les mod\u00e8les de langage se sont r\u00e9v\u00e9l\u00e9s efficaces pour de nombreuses t\u00e2ches de r\u00e9cup\u00e9ration -LSB- 21, 28, 14, 4 -RSB-. Nous pouvons ensuite classer les documents en fonction de la probabilit\u00e9 de g\u00e9n\u00e9rer la requ\u00eate. Pratiquement tous les mod\u00e8les de langage de g\u00e9n\u00e9ration de requ\u00eates existants sont bas\u00e9s soit sur la distribution multinomiale -LSB- 19, 6, 28 -RSB-, soit sur la distribution multivari\u00e9e de Bernoulli -LSB- 21, 18 -RSB-. La distribution multinomiale est particuli\u00e8rement populaire et s'est \u00e9galement r\u00e9v\u00e9l\u00e9e tr\u00e8s efficace. Notez que l'absence de terme est \u00e9galement indirectement captur\u00e9e dans un mod\u00e8le multinomial via la contrainte selon laquelle toutes les probabilit\u00e9s de terme doivent totaliser 1. Dans cet article, nous proposons et \u00e9tudions une nouvelle famille de mod\u00e8les de g\u00e9n\u00e9ration de requ\u00eates bas\u00e9s sur la distribution de Poisson. Dans cette nouvelle famille de mod\u00e8les, nous mod\u00e9lisons la fr\u00e9quence de chaque terme ind\u00e9pendamment avec une distribution de Poisson. Pour \u00e9valuer un document, nous devrions d'abord estimer un mod\u00e8le de Poisson multivari\u00e9 bas\u00e9 sur le document, puis le noter en fonction de la vraisemblance de la requ\u00eate donn\u00e9e par le mod\u00e8le de Poisson estim\u00e9. Dans un certain sens, le mod\u00e8le de Poisson combine l'avantage du multinomial dans la mod\u00e9lisation de la fr\u00e9quence des termes et l'avantage du mod\u00e8le de Bernoulli multivari\u00e9 dans la prise en charge du lissage par terme. Comme dans les travaux existants sur les mod\u00e8les de langage multinomial, le lissage est essentiel pour cette nouvelle famille de mod\u00e8les. Nous d\u00e9rivons plusieurs m\u00e9thodes de lissage pour le mod\u00e8le de Poisson parall\u00e8lement \u00e0 celles utilis\u00e9es pour les distributions multinomiales, et comparons les mod\u00e8les de r\u00e9cup\u00e9ration correspondants avec ceux bas\u00e9s sur des distributions multinomiales. Nous constatons que m\u00eame si avec certaines m\u00e9thodes de lissage, le nouveau mod\u00e8le et le mod\u00e8le multinomial conduisent exactement \u00e0 la m\u00eame formule, avec d'autres m\u00e9thodes de lissage, ils divergent et le mod\u00e8le de Poisson apporte plus de flexibilit\u00e9 pour le lissage. En particulier,une diff\u00e9rence cl\u00e9 est que le mod\u00e8le de Poisson peut naturellement s'adapter au lissage perterm, ce qui est difficile \u00e0 r\u00e9aliser avec un mod\u00e8le multinomial sans torsion heuristique de la s\u00e9mantique d'un mod\u00e8le g\u00e9n\u00e9ratif. Nous exploitons cet avantage potentiel pour d\u00e9velopper un nouvel algorithme de lissage d\u00e9pendant des termes pour le mod\u00e8le de Poisson et montrons que ce nouvel algorithme de lissage peut am\u00e9liorer les performances par rapport aux algorithmes de lissage ind\u00e9pendants des termes utilisant soit un mod\u00e8le de Poisson, soit un mod\u00e8le multinomial. Cet avantage est visible \u00e0 la fois pour le lissage en une \u00e9tape et en deux \u00e9tapes. Un autre avantage potentiel du mod\u00e8le de Poisson est que son mod\u00e8le de fond correspondant pour le lissage peut \u00eatre am\u00e9lior\u00e9 gr\u00e2ce \u00e0 l'utilisation d'un mod\u00e8le de m\u00e9lange dot\u00e9 d'une formule ferm\u00e9e. Il est d\u00e9montr\u00e9 que ce nouveau mod\u00e8le d'arri\u00e8re-plan surpasse le mod\u00e8le d'arri\u00e8re-plan standard et r\u00e9duit la sensibilit\u00e9 des performances de r\u00e9cup\u00e9ration au param\u00e8tre de lissage. Dans la section 2, nous introduisons la nouvelle famille de mod\u00e8les de g\u00e9n\u00e9ration de requ\u00eates avec distribution de Poisson, et pr\u00e9sentons diverses m\u00e9thodes de lissage qui conduisent \u00e0 diff\u00e9rentes fonctions de r\u00e9cup\u00e9ration. Dans la section 3, nous comparons analytiquement le mod\u00e8le de langage de Poisson avec le mod\u00e8le de langage multinomial, du point de vue de la r\u00e9cup\u00e9ration. Nous concevons ensuite des exp\u00e9riences empiriques pour comparer les deux familles de mod\u00e8les de langage dans la section 4. Nous discutons des travaux associ\u00e9s en 5 et concluons en 6. 5. TRAVAUX CONNEXES \u00c0 notre connaissance, il n'y a pas eu d'\u00e9tude de mod\u00e8les de g\u00e9n\u00e9ration de requ\u00eates bas\u00e9s sur sur la distribution de Poisson. Les mod\u00e8les de langage se sont r\u00e9v\u00e9l\u00e9s efficaces pour de nombreuses t\u00e2ches de r\u00e9cup\u00e9ration -LSB- 21, 28, 14, 4 -RSB-. Le plus populaire et le plus fondamental est le mod\u00e8le de langage de g\u00e9n\u00e9ration de requ\u00eates -LSB- 21, 13 -RSB-. Tous les mod\u00e8les de langage de g\u00e9n\u00e9ration de requ\u00eates existants sont bas\u00e9s soit sur la distribution multinomiale -LSB- 19, 6, 28, 13 -RSB-, soit sur la distribution multivari\u00e9e de Bernoulli -LSB- 21, 17, 18 -RSB-. Nous introduisons une nouvelle famille de mod\u00e8les de langage, bas\u00e9s sur la distribution de Poisson. La distribution de Poisson a d\u00e9j\u00e0 \u00e9t\u00e9 \u00e9tudi\u00e9e dans les mod\u00e8les de g\u00e9n\u00e9ration de documents -LSB- 16, 22, 3, 24 -RSB-, conduisant au d\u00e9veloppement de l'une des formules de r\u00e9cup\u00e9ration les plus efficaces BM25 -LSB- 23 -RSB-. -LSB- 24 -RSB- \u00e9tudie la d\u00e9rivation parall\u00e8le de trois mod\u00e8les de r\u00e9cup\u00e9ration diff\u00e9rents qui est li\u00e9e \u00e0 notre comparaison de Poisson et multinomial. Cependant, le mod\u00e8le de Poisson pr\u00e9sent\u00e9 dans leur article rel\u00e8ve toujours du cadre de g\u00e9n\u00e9ration de documents et ne tient pas non plus compte de la variation de la longueur du document. -LSB- 26 -RSB- introduit un moyen de recherche empirique d'un mod\u00e8le exponentiel pour les documents. Les m\u00e9langes de Poisson -LSB- 3 -RSB- tels que le 2-Poisson -LSB- 22 -RSB-, le multin\u00f4me n\u00e9gatif et le KMixture de Katz -LSB- 9 -RSB- se sont r\u00e9v\u00e9l\u00e9s efficaces pour mod\u00e9liser et r\u00e9cup\u00e9rer des documents. Encore une fois, aucun de ces travaux n\u2019explore la distribution de Poisson dans le cadre de g\u00e9n\u00e9ration de requ\u00eates. Le lissage des mod\u00e8les de langage -LSB- 2, 28, 29 -RSB- et les structures d'arri\u00e8re-plan -LSB- 15, 10, 25, 27 -RSB- ont \u00e9t\u00e9 \u00e9tudi\u00e9s avec des mod\u00e8les de langage multinomiaux.-LSB- 7 -RSB- montre analytiquement qu'un lissage sp\u00e9cifique \u00e0 un terme pourrait \u00eatre utile. Nous montrons que le mod\u00e8le de langage de Poisson est naturel pour s'adapter au lissage par terme sans torsion heuristique de la s\u00e9mantique d'un mod\u00e8le g\u00e9n\u00e9ratif, et qu'il est capable de mieux mod\u00e9liser efficacement l'arri\u00e8re-plan du m\u00e9lange, \u00e0 la fois analytiquement et empiriquement. 6. CONCLUSIONS Nous pr\u00e9sentons une nouvelle famille de mod\u00e8les de langage de g\u00e9n\u00e9ration de requ\u00eates pour la r\u00e9cup\u00e9ration bas\u00e9e sur la distribution de Poisson. Nous d\u00e9rivons plusieurs m\u00e9thodes de lissage pour cette famille de mod\u00e8les, notamment le lissage en une \u00e9tape et le lissage en deux \u00e9tapes. Nous comparons les nouveaux mod\u00e8les avec les mod\u00e8les de recherche multinomiaux populaires, \u00e0 la fois analytiquement et exp\u00e9rimentalement. Notre analyse montre que m\u00eame si nos nouveaux mod\u00e8les et mod\u00e8les multinomiaux sont \u00e9quivalents sous certaines hypoth\u00e8ses, ils sont g\u00e9n\u00e9ralement diff\u00e9rents avec quelques diff\u00e9rences importantes. En particulier, nous montrons que Poisson a un avantage sur les multinomiaux en ce qu\u2019il s\u2019adapte naturellement au lissage par terme. Nous exploitons cette propri\u00e9t\u00e9 pour d\u00e9velopper un nouvel algorithme de lissage par terme pour les mod\u00e8les de langage de Poisson, qui surpasse le lissage ind\u00e9pendant des termes pour les mod\u00e8les de Poisson et multinomiaux. De plus, nous montrons qu\u2019un mod\u00e8le de fond de m\u00e9lange pour Poisson peut \u00eatre utilis\u00e9 pour am\u00e9liorer les performances et la robustesse par rapport au mod\u00e8le de fond de Poisson standard. Notre travail ouvre de nombreuses directions int\u00e9ressantes pour une exploration plus approfondie de cette nouvelle famille de mod\u00e8les. Une exploration plus approfondie des flexibilit\u00e9s des mod\u00e8les de langage multinomiaux, telles que la normalisation de la longueur et le pseudo-feedback, pourrait \u00eatre un bon travail futur.Une exploration plus approfondie des flexibilit\u00e9s des mod\u00e8les de langage multinomiaux, telles que la normalisation de la longueur et le pseudo-feedback, pourrait \u00eatre un bon travail futur.Une exploration plus approfondie des flexibilit\u00e9s des mod\u00e8les de langage multinomiaux, telles que la normalisation de la longueur et le pseudo-feedback, pourrait \u00eatre un bon travail futur.", "keyphrases": ["distribution multinomi", "mod\u00e8le probabiliste queri gener", "poisson distribu\u00e9", "lisse en deux \u00e9tapes", "multivari\u00e9 bernoullu distribution", "reconnaissance vocale", "terme fr\u00e9quence", "lisse \u00e0 terme", "nouvel algorithme de lissage d\u00e9pendant du terme", "ensemble de vocabulaire", "processus de poisson homog\u00e8ne", "pseudo terme unique"]}
{"file_name": "I-35", "text": "Gestion distribu\u00e9e des normes dans les syst\u00e8mes multi-agents r\u00e9glement\u00e9s * R\u00c9SUM\u00c9 Les normes sont largement reconnues comme un moyen de coordonner les syst\u00e8mes multi-agents. La gestion distribu\u00e9e des normes est une question difficile et nous observons un manque de r\u00e9alisations informatiques v\u00e9ritablement distribu\u00e9es des mod\u00e8les normatifs. Afin de r\u00e9guler le comportement des agents autonomes qui participent \u00e0 des activit\u00e9s multiples et li\u00e9es, nous proposons un mod\u00e8le normatif, la Structure Normative -LRB-NS-RRB-, un artefact bas\u00e9 sur la propagation de positions normatives -LRB- et d'obligations. , interdictions, autorisations -RRB-, comme cons\u00e9quences des actions des agents. Au sein d'un SN, des conflits peuvent survenir en raison de la nature dynamique du MAS et de la concurrence des actions des agents. Cependant, garantir l'absence de conflit d'un NS au moment de la conception est difficile \u00e0 r\u00e9soudre du point de vue informatique. Nous montrons cela en formalisant la notion de conflit, en fournissant une cartographie des NS dans des r\u00e9seaux de Petri color\u00e9s et en empruntant des r\u00e9sultats th\u00e9oriques bien connus dans ce domaine. Puisque la r\u00e9solution des conflits en ligne est n\u00e9cessaire, nous pr\u00e9sentons un algorithme traitable \u00e0 utiliser de mani\u00e8re distribu\u00e9e. Nous d\u00e9montrons ensuite que cet algorithme est primordial pour la mise en \u0153uvre distribu\u00e9e d\u2019un NS. 1. INTRODUCTION Une caract\u00e9ristique fondamentale des syst\u00e8mes multi-agents ouverts et r\u00e9glement\u00e9s dans lesquels des agents autonomes interagissent est que les agents participants sont cens\u00e9s se conformer aux conventions du syst\u00e8me. Les normes peuvent \u00eatre utilis\u00e9es pour mod\u00e9liser de telles conventions et donc comme moyen de r\u00e9guler le comportement observable des agents -LSB- 6, 29 -RSB-. Il existe de nombreuses contributions sur le th\u00e8me des normes de la part de sociologues, philosophes et logiciens -LRB- par exemple, -LSB- 15, 28 -RSB- -RRB-. Cependant, il existe tr\u00e8s peu de propositions concernant la r\u00e9alisation informatique de mod\u00e8les normatifs \u2013 la mani\u00e8re dont les normes peuvent \u00eatre int\u00e9gr\u00e9es dans la conception et l\u2019ex\u00e9cution des SMA. \u00c0 notre connaissance, aucune proposition ne soutient v\u00e9ritablement la mise en \u0153uvre distribu\u00e9e d\u2019environnements normatifs. Dans notre article, nous abordons ce probl\u00e8me et proposons des moyens pour g\u00e9rer les engagements conflictuels dans des syst\u00e8mes multi-agents ouverts, r\u00e9glement\u00e9s, de mani\u00e8re distribu\u00e9e. Le type de MAS r\u00e9glement\u00e9 que nous envisageons consiste en des activit\u00e9s multiples, simultan\u00e9es et li\u00e9es o\u00f9 les agents interagissent. Chaque agent peut participer simultan\u00e9ment \u00e0 plusieurs activit\u00e9s et passer d'une activit\u00e9 \u00e0 l'autre. Les actions d'un agent au sein d'une activit\u00e9 peuvent avoir des cons\u00e9quences sous la forme de positions normatives -LRB- c'est-\u00e0-dire d'obligations, de permissions et d'interdictions -RRB- -LSB- 26 -RSB- qui peuvent contraindre son comportement futur. Nous supposons que les agents peuvent choisir de ne pas remplir toutes leurs obligations et peuvent donc \u00eatre sanctionn\u00e9s par le MAS. Notons que, lorsque les activit\u00e9s sont distribu\u00e9es, les positions normatives doivent d\u00e9couler des activit\u00e9s dans lesquelles elles sont g\u00e9n\u00e9r\u00e9es vers celles dans lesquelles elles prennent effet. Puisque dans un SMA ouvert et r\u00e9glement\u00e9, on ne peut pas int\u00e9grer des aspects normatifs dans la conception des agents,nous estimons que le MAS devrait \u00eatre compl\u00e9t\u00e9 par un ensemble distinct de normes qui r\u00e9glementent davantage le comportement des agents participants. Afin de mod\u00e9liser la s\u00e9paration des pr\u00e9occupations entre le niveau de coordination -LRB- interactions des agents -RRB- et le niveau normatif -LRB- propagation des positions normatives -RRB-, nous proposons un artefact appel\u00e9 Structure Normative -LRB- NS -RRB. -. Au sein d'une SN, des conflits peuvent survenir en raison de la nature dynamique du SMA et de la concurrence des actions des agents. Par exemple, un agent peut \u00eatre oblig\u00e9 et interdit de faire exactement la m\u00eame action dans le cadre d\u2019une activit\u00e9. Cependant, garantir l'absence de conflit d'un NS au moment de la conception est difficile \u00e0 r\u00e9soudre du point de vue informatique. Nous montrons cela en formalisant la notion de conflit, en fournissant une cartographie des NS en r\u00e9seaux de Petri color\u00e9s -LRB-CPNs-RRB- et en empruntant des r\u00e9sultats th\u00e9oriques bien connus au domaine des CPN. Nous pensons que la d\u00e9tection et la r\u00e9solution des conflits en ligne sont n\u00e9cessaires. Par cons\u00e9quent, nous pr\u00e9sentons un algorithme traitable pour la r\u00e9solution des conflits. Cet algorithme est primordial pour la mise en \u0153uvre distribu\u00e9e d'un NS. Le document est organis\u00e9 comme suit. Dans la section 2, nous d\u00e9taillons un sc\u00e9nario pour servir d\u2019exemple tout au long du document. Ensuite, dans la section 3, nous d\u00e9finissons formellement l\u2019artefact de structure normative. Plus loin, dans la section 4, nous formalisons la notion de conflit pour ensuite analyser la complexit\u00e9 de la d\u00e9tection des conflits en termes de CPN dans la section 5. La section 6 d\u00e9crit la gestion informatique des NS en d\u00e9crivant leur mise en \u0153uvre et en pr\u00e9sentant un algorithme de r\u00e9solution des conflits. Enfin, nous commentons les travaux connexes, tirons des conclusions et rendons compte des travaux futurs dans la section 7. 7. TRAVAUX CONNEXES ET CONCLUSIONS Nos contributions dans cet article sont triples. Premi\u00e8rement, nous introduisons une approche de gestion et de raisonnement sur les normes de mani\u00e8re distribu\u00e9e. A notre connaissance, il existe peu de travaux publi\u00e9s dans ce sens. Dans -LSB- 8, 21 -RSB-, deux langages sont pr\u00e9sent\u00e9s pour l'application distribu\u00e9e des normes dans MAS. Cependant, dans les deux cas, chaque agent dispose d\u2019une interface de message locale qui transmet les messages l\u00e9gaux selon un ensemble de normes. Puisque ces interfaces sont locales \u00e0 chaque agent, les normes ne peuvent \u00eatre exprim\u00e9es qu\u2019en termes d\u2019actions de cet agent. Ceci constitue un s\u00e9rieux inconv\u00e9nient, par exemple lorsqu'il faut activer une obligation envers un agent en raison d'un certain message d'un autre. La deuxi\u00e8me contribution est la proposition d\u2019une structure normative. Cette notion est f\u00e9conde car elle permet de s\u00e9parer les pr\u00e9occupations normatives et proc\u00e9durales. La structure normative que nous proposons met en \u00e9vidence la similitude entre la propagation des positions normatives et la propagation des positions normatives. sur les agents autonomes et les syst\u00e8mes multi-agents -LRB- AAMAS 07 -RRB- de jetons dans les r\u00e9seaux de Petri color\u00e9s. Cette similitude sugg\u00e8re facilement une cartographie entre les deux et donne lieu \u00e0 un traitement analytique pratique de la structure normative en g\u00e9n\u00e9ral.et la complexit\u00e9 de la d\u00e9tection des conflits, en particulier. Dans -LSB- 5 -RSB-, les conversations sont d'abord con\u00e7ues et analys\u00e9es au niveau des CPN puis traduites en protocoles. Lin et coll. -LSB- 20 -RSB- mappe les sch\u00e9mas de conversation aux CPN. \u00c0 notre connaissance, l\u2019utilisation de cette repr\u00e9sentation dans le support de la d\u00e9tection de conflits dans les MAS r\u00e9glement\u00e9s n\u2019a pas \u00e9t\u00e9 rapport\u00e9e ailleurs. Enfin, nous pr\u00e9sentons un m\u00e9canisme distribu\u00e9 pour r\u00e9soudre les conflits normatifs. Sartor -LSB- 25 -RSB- traite les conflits normatifs du point de vue de la th\u00e9orie juridique et sugg\u00e8re une mani\u00e8re d'ordonner les normes en cause. Son id\u00e9e est impl\u00e9ment\u00e9e dans -LSB- 12 -RSB- mais n\u00e9cessite une ressource centrale pour la maintenance des normes. L'approche de d\u00e9tection et de r\u00e9solution des conflits est une adaptation et une extension des travaux sur les graphes d'instanciation rapport\u00e9s dans -LSB- 17 -RSB- et d'un algorithme associ\u00e9 dans -LSB- 27 -RSB-. Ces trois contributions que nous pr\u00e9sentons dans cet article ouvrent de nombreuses possibilit\u00e9s de travaux futurs. Nous esp\u00e9rons qu\u2019un tel couplage dotera les institutions \u00e9lectroniques d\u2019un environnement normatif plus flexible \u2013 et plus expressif. Sur le plan th\u00e9orique, nous avons l'intention d'utiliser des techniques d'analyse des CPN afin de caract\u00e9riser des classes de CPN -LRB- par exemple, acycliques, sym\u00e9triques, etc. -RRB- correspondant \u00e0 des familles de structures normatives susceptibles d'\u00eatre trait\u00e9es hors ligne. La combinaison de ces techniques avec nos m\u00e9canismes de r\u00e9solution de conflits en ligne vise \u00e0 doter les concepteurs MAS de la capacit\u00e9 d'incorporer des normes dans leurs syst\u00e8mes de mani\u00e8re fond\u00e9e.La combinaison de ces techniques avec nos m\u00e9canismes de r\u00e9solution de conflits en ligne vise \u00e0 doter les concepteurs MAS de la capacit\u00e9 d'incorporer des normes dans leurs syst\u00e8mes de mani\u00e8re fond\u00e9e.La combinaison de ces techniques avec nos m\u00e9canismes de r\u00e9solution de conflits en ligne vise \u00e0 doter les concepteurs MAS de la capacit\u00e9 d'incorporer des normes dans leurs syst\u00e8mes de mani\u00e8re fond\u00e9e.", "keyphrases": ["algorithme", "actif", "sc\u00e9nario", "position normative", "protocole", "sc\u00e8ne de norme", "r\u00e8gle de transit de norme", "structure normative", "graphe biparti", "interdire", "chevauchement des autorisations", "jeton", "conflit"]}
{"file_name": "I-33", "text": "Une voie formelle des normes institutionnelles aux structures organisationnelles R\u00c9SUM\u00c9 Jusqu'\u00e0 pr\u00e9sent, la mani\u00e8re dont les institutions et les organisations ont \u00e9t\u00e9 utilis\u00e9es dans le d\u00e9veloppement de syst\u00e8mes ouverts n'est souvent pas all\u00e9e plus loin qu'une heuristique utile. Afin de d\u00e9velopper des syst\u00e8mes mettant r\u00e9ellement en \u0153uvre des institutions et des organisations, les m\u00e9thodes formelles devraient remplacer les m\u00e9thodes heuristiques. L'article pr\u00e9sente une s\u00e9mantique formelle pour la notion d'institution et ses composantes -LRB- normes abstraites et concr\u00e8tes, autonomisation des agents, r\u00f4les -RRB- et d\u00e9finit une relation formelle entre les institutions et les structures organisationnelles. En cons\u00e9quence, nous montrons comment les normes institutionnelles peuvent \u00eatre affin\u00e9es pour devenir des constructions \u2013 des structures organisationnelles \u2013 qui sont plus proches d'un syst\u00e8me mis en \u0153uvre. Nous montrons \u00e9galement comment un tel processus de raffinement peut \u00eatre enti\u00e8rement formalis\u00e9 et se pr\u00eate donc \u00e0 une v\u00e9rification rigoureuse. 1. INTRODUCTION L'opportunit\u00e9 d'un \u00ab\u00a0transfert de technologie\u00a0\u00bb du domaine de la th\u00e9orie organisationnelle et sociale vers l'IA distribu\u00e9e et les syst\u00e8mes multiagents -LRB- MASs -RRB- a longtemps \u00e9t\u00e9 pr\u00e9conis\u00e9e -LRB- -LSB- 8 -RSB- -RRB -. Dans les MAS, l'application des m\u00e9taphores organisationnelles et institutionnelles \u00e0 la conception de syst\u00e8mes s'est av\u00e9r\u00e9e utile pour le d\u00e9veloppement de m\u00e9thodologies et d'outils. Dans de nombreux cas, cependant, l\u2019application de ces appareils conceptuels se r\u00e9sume \u00e0 de simples heuristiques guidant la conception de haut niveau des syst\u00e8mes. trait\u00e9 formellement, c'est-\u00e0-dire une fois que des notions telles que norme, r\u00f4le, structure, etc. obtiennent une s\u00e9mantique formelle. Le but du pr\u00e9sent article est de combler cette lacune en ce qui concerne la notion d'institution en fournissant des fondements formels pour l'application de la m\u00e9taphore institutionnelle et pour sa relation avec la m\u00e9taphore organisationnelle. Le r\u00e9sultat principal de l'article consiste \u00e0 montrer comment les contraintes abstraites -LRB- institutions -RRB- peuvent \u00eatre affin\u00e9es \u00e9tape par \u00e9tape en descriptions structurelles concr\u00e8tes -LRB- structures organisationnelles -RRB- du syst\u00e8me \u00e0 mettre en \u0153uvre, comblant ainsi le foss\u00e9 entre normes abstraites et sp\u00e9cifications concr\u00e8tes du syst\u00e8me. Concr\u00e8tement, dans la section 2, un cadre logique est pr\u00e9sent\u00e9 qui fournit une s\u00e9mantique formelle pour les notions d'institution, de norme, de r\u00f4le, et qui soutient la prise en compte des caract\u00e9ristiques cl\u00e9s des institutions telles que la traduction de normes abstraites en normes concr\u00e8tes et applicables, la l'autonomisation institutionnelle des agents et certains aspects de la conception de l'application des normes. Dans la section 3, le cadre est \u00e9tendu pour traiter de la notion d'infrastructure d'une institution. Le cadre \u00e9tendu est ensuite \u00e9tudi\u00e9 en relation avec le formalisme de repr\u00e9sentation des structures organisationnelles pr\u00e9sent\u00e9 dans -LSB- 11 -RSB-. Dans la section 4, quelques conclusions suivent. 4. CONCLUSIONS L'article visait \u00e0 fournir une analyse formelle compl\u00e8te de la m\u00e9taphore institutionnelle et de sa relation avec la m\u00e9taphore organisationnelle. L\u2019outil formel pr\u00e9dominant a \u00e9t\u00e9 la logique de description.Les TBoxes ont \u00e9t\u00e9 utilis\u00e9es pour repr\u00e9senter les sp\u00e9cifications des institutions -LRB- D\u00e9finition 3 -RRB- et de leurs infrastructures -LRB- D\u00e9finition 6 -RRB-, fournissant ainsi une s\u00e9mantique de syst\u00e8me de transition pour un certain nombre de notions institutionnelles -LRB- Exemples 1-7 - RRB-. Des multi-graphes ont ensuite \u00e9t\u00e9 utilis\u00e9s pour repr\u00e9senter la sp\u00e9cification des structures organisationnelles -LRB- D\u00e9finition 6 -RRB-. Le dernier r\u00e9sultat pr\u00e9sent\u00e9 concernait la d\u00e9finition d'une correspondance formelle entre les sp\u00e9cifications de l'institution et de l'organisation -LRB- D\u00e9finition 7 -RRB-, qui fournit un moyen formel de basculer entre les deux paradigmes. Dans l'ensemble, ces r\u00e9sultats fournissent un moyen de relier les sp\u00e9cifications abstraites d'un syst\u00e8me -LRB-, c'est-\u00e0-dire les institutions en tant qu'ensembles de normes -RRB-, \u00e0 des sp\u00e9cifications plus proches d'un syst\u00e8me mis en \u0153uvre -LRB-, c'est-\u00e0-dire les structures organisationnelles -RRB-.", "keyphrases": ["m\u00e9thode formelle", "norme de l'institut", "contrainte abstraite", "formel pour la structure de l'organisation des repr\u00e9sentants", "entiti", "propri\u00e9t\u00e9", "d\u00e9crire la logique", "logique dynamique", "axiome terminologique", "r\u00f4le", "infrastructure"]}
{"file_name": "C-36", "text": "Contr\u00f4le d'acc\u00e8s forc\u00e9 par cryptage dans les r\u00e9seaux de publication/abonnement dynamiques multi-domaines R\u00c9SUM\u00c9 Les syst\u00e8mes de publication/abonnement fournissent une infrastructure de communications distribu\u00e9es efficace, bas\u00e9e sur les \u00e9v\u00e9nements et \u00e0 grande \u00e9chelle. Les syst\u00e8mes de publication/abonnement \u00e0 grande \u00e9chelle utiliseront probablement des composants du r\u00e9seau de transport d\u2019\u00e9v\u00e9nements appartenant \u00e0 des organisations coop\u00e9rantes mais ind\u00e9pendantes. \u00c0 mesure que le nombre de participants au r\u00e9seau augmente, la s\u00e9curit\u00e9 devient une pr\u00e9occupation croissante. Cet article \u00e9tend les travaux ant\u00e9rieurs pour pr\u00e9senter et \u00e9valuer une infrastructure de publication/abonnement multi-domaine s\u00e9curis\u00e9e qui prend en charge et applique un contr\u00f4le d'acc\u00e8s pr\u00e9cis sur les attributs individuels des types d'\u00e9v\u00e9nements. L'actualisation des cl\u00e9s nous permet d'assurer la s\u00e9curit\u00e9 avant et arri\u00e8re lorsque les courtiers d'\u00e9v\u00e9nements rejoignent et quittent le r\u00e9seau. Nous d\u00e9montrons que les co\u00fbts de temps et d'espace peuvent \u00eatre minimis\u00e9s par un examen attentif des techniques de chiffrement et par l'utilisation de la mise en cache pour r\u00e9duire les d\u00e9cryptages inutiles. Nous montrons que notre approche n\u00e9cessite une surcharge de communication globale inf\u00e9rieure \u00e0 celle des approches existantes pour atteindre le m\u00eame degr\u00e9 de contr\u00f4le sur la s\u00e9curit\u00e9 dans les r\u00e9seaux de publication/abonnement. 1. INTRODUCTION La publication/abonnement est un m\u00e9canisme de communication bien adapt\u00e9 pour cr\u00e9er des applications \u00e9v\u00e9nementielles distribu\u00e9es \u00e0 l'\u00e9chelle Internet. des participants vient de son d\u00e9couplage des \u00e9diteurs et des abonn\u00e9s en pla\u00e7ant un service de diffusion d'\u00e9v\u00e9nements asynchrone entre eux. Dans les syst\u00e8mes de publication/abonnement v\u00e9ritablement \u00e0 l'\u00e9chelle Internet, le service de livraison d'\u00e9v\u00e9nements comprendra un large ensemble de n\u0153uds de courtier interconnect\u00e9s couvrant une vaste zone g\u00e9ographique -LRB- et donc un r\u00e9seau -RRB-. Bien que les capacit\u00e9s de communication des syst\u00e8mes de publication/abonnement soient bien prouv\u00e9es, la couverture de plusieurs domaines administratifs n\u00e9cessitera probablement de prendre en compte des consid\u00e9rations de s\u00e9curit\u00e9. La s\u00e9curit\u00e9 et le contr\u00f4le d\u2019acc\u00e8s \u00e9tant presque l\u2019antith\u00e8se du d\u00e9couplage, relativement peu de recherches sur la publication/l\u2019abonnement se sont jusqu\u2019\u00e0 pr\u00e9sent concentr\u00e9es sur la s\u00e9curit\u00e9. Notre objectif global de recherche est de d\u00e9velopper des r\u00e9seaux de publication/abonnement \u00e0 l'\u00e9chelle Internet qui assurent une diffusion s\u00e9curis\u00e9e et efficace des \u00e9v\u00e9nements, une tol\u00e9rance aux pannes et une auto-r\u00e9paration dans l'infrastructure de diffusion, ainsi qu'une interface d'\u00e9v\u00e9nement pratique. Dans -LSB-12-RSB-Pesonen et al. proposer une architecture de contr\u00f4le d'acc\u00e8s multidomaine bas\u00e9e sur les capacit\u00e9s pour les syst\u00e8mes de publication/abonnement. L'architecture fournit un m\u00e9canisme permettant d'autoriser les clients d'\u00e9v\u00e9nements \u00e0 publier et \u00e0 s'abonner \u00e0 des types d'\u00e9v\u00e9nements. Les privil\u00e8ges du client sont v\u00e9rifi\u00e9s par le courtier local auquel le client se connecte afin d'acc\u00e9der au syst\u00e8me de publication/abonnement. L'approche met en \u0153uvre le contr\u00f4le d'acc\u00e8s \u00e0 la p\u00e9riph\u00e9rie du r\u00e9seau de courtiers et suppose que tous les courtiers peuvent \u00eatre fiables pour appliquer correctement les politiques de contr\u00f4le d'acc\u00e8s. Tout courtier malveillant, compromis ou non autoris\u00e9 est libre de lire et d'\u00e9crire tous les \u00e9v\u00e9nements qui le traversent entre les \u00e9diteurs et les abonn\u00e9s. Nous proposons d'appliquer le contr\u00f4le d'acc\u00e8s au sein du r\u00e9seau de courtiers en chiffrant le contenu des \u00e9v\u00e9nements,et cette politique dicte le contr\u00f4le des cl\u00e9s de chiffrement n\u00e9cessaires. Avec le contenu d'\u00e9v\u00e9nement chiffr\u00e9, seuls les courtiers autoris\u00e9s \u00e0 acc\u00e9der aux cl\u00e9s de chiffrement peuvent acc\u00e9der au contenu d'\u00e9v\u00e9nement -LRB-, c'est-\u00e0-dire publier, s'abonner ou filtrer -RRB-. Nous d\u00e9pla\u00e7ons efficacement l'application du contr\u00f4le d'acc\u00e8s des courtiers vers les gestionnaires de cl\u00e9s de chiffrement. Nous pensons que le contr\u00f4le d'acc\u00e8s devra \u00eatre appliqu\u00e9 dans un syst\u00e8me de publication/abonnement multidomaine lorsque plusieurs organisations forment un syst\u00e8me de publication/abonnement partag\u00e9 tout en ex\u00e9cutant plusieurs applications ind\u00e9pendantes. Le contr\u00f4le d'acc\u00e8s peut \u00e9galement \u00eatre n\u00e9cessaire lorsqu'une seule organisation se compose de plusieurs sous-domaines qui fournissent des donn\u00e9es confidentielles via le syst\u00e8me de publication/abonnement \u00e0 l'\u00e9chelle de l'organisation. Les deux cas n\u00e9cessitent un contr\u00f4le d'acc\u00e8s, car la diffusion d'\u00e9v\u00e9nements dans une infrastructure de publication/abonnement dynamique bas\u00e9e sur un r\u00e9seau de courtiers partag\u00e9 peut tr\u00e8s bien conduire \u00e0 l'acheminement des \u00e9v\u00e9nements via des domaines non autoris\u00e9s tout au long de leur chemin depuis les \u00e9diteurs vers les abonn\u00e9s. Le partage de l'infrastructure de publication/abonnement pr\u00e9sente deux avantages particuliers, tous deux li\u00e9s au r\u00e9seau de courtiers. Premi\u00e8rement, les courtiers de partage cr\u00e9eront un r\u00e9seau physiquement plus vaste qui offrira une plus grande port\u00e9e g\u00e9ographique. Deuxi\u00e8mement, l\u2019augmentation de l\u2019interconnectivit\u00e9 des courtiers permettra au syst\u00e8me de publication/abonnement d\u2019offrir une plus grande tol\u00e9rance aux pannes. La figure 1 montre le r\u00e9seau de publication/abonnement multidomaine que nous utilisons comme exemple tout au long de cet article. Ce domaine contient un ensemble de cam\u00e9ras de vid\u00e9osurveillance qui publient des informations sur les mouvements des v\u00e9hicules dans la r\u00e9gion de Londres. Nous avons inclus le d\u00e9tective Smith comme abonn\u00e9 dans ce domaine. Domaine du service de p\u00e9age urbain. Les taxes pr\u00e9lev\u00e9es sur les v\u00e9hicules qui traversent chaque jour la zone de p\u00e9age urbain de Londres sont \u00e9mises par des syst\u00e8mes relevant de ce domaine. Les donn\u00e9es sources de reconnaissance des plaques d'immatriculation proviennent des cam\u00e9ras du domaine de la police m\u00e9tropolitaine. Le fait que les CCS ne soient autoris\u00e9s \u00e0 lire qu'un sous-ensemble des donn\u00e9es d'\u00e9v\u00e9nements du v\u00e9hicule exercera certaines des caract\u00e9ristiques cl\u00e9s du contr\u00f4le d'acc\u00e8s ex\u00e9cutoire du syst\u00e8me de publication/abonnement pr\u00e9sent\u00e9 dans cet article. Domaine PITO. Il s'agit du propri\u00e9taire du type d'\u00e9v\u00e9nement dans ce sc\u00e9nario particulier. Le cryptage prot\u00e8ge la confidentialit\u00e9 des \u00e9v\u00e9nements s'ils sont transport\u00e9s via des domaines non autoris\u00e9s. Cependant, le chiffrement d\u2019\u00e9v\u00e9nements entiers emp\u00eache les courtiers non autoris\u00e9s de prendre des d\u00e9cisions de routage efficaces. Notre approche consiste \u00e0 appliquer le chiffrement aux attributs individuels des \u00e9v\u00e9nements. De cette fa\u00e7on, notre politique de contr\u00f4le d'acc\u00e8s multi-domaines fonctionne avec une granularit\u00e9 plus fine\u00a0: les \u00e9diteurs et les abonn\u00e9s peuvent \u00eatre autoris\u00e9s \u00e0 acc\u00e9der \u00e0 un sous-ensemble des attributs disponibles. Dans les cas o\u00f9 des \u00e9v\u00e9nements non crypt\u00e9s sont utilis\u00e9s pour le routage, nous pouvons r\u00e9duire le nombre total d'\u00e9v\u00e9nements envoy\u00e9s via le syst\u00e8me sans r\u00e9v\u00e9ler les valeurs des attributs sensibles. Nous pr\u00e9servons ainsi la vie priv\u00e9e des automobilistes tout en permettant au CCS de faire son travail en utilisant l'infrastructure de publication/abonnement partag\u00e9e.La d\u00e9tective obtient une ordonnance du tribunal qui l'autorise \u00e0 s'abonner aux \u00e9v\u00e9nements de plaque d'immatriculation sp\u00e9cifique li\u00e9s \u00e0 son cas. Les syst\u00e8mes actuels de contr\u00f4le d'acc\u00e8s de publication/abonnement appliquent la s\u00e9curit\u00e9 \u00e0 la p\u00e9riph\u00e9rie du r\u00e9seau de courtiers, l\u00e0 o\u00f9 les clients s'y connectent. Cependant, cette approche n'est souvent pas acceptable dans les syst\u00e8mes \u00e0 l'\u00e9chelle d'Internet. Nous proposons de renforcer la s\u00e9curit\u00e9 au sein du r\u00e9seau de courtiers ainsi qu'aux p\u00e9riph\u00e9ries auxquelles les clients d'\u00e9v\u00e9nements se connectent, en chiffrant le contenu des \u00e9v\u00e9nements. Les publications seront crypt\u00e9es avec leurs cl\u00e9s de cryptage sp\u00e9cifiques au type d'\u00e9v\u00e9nement. En contr\u00f4lant l'acc\u00e8s aux cl\u00e9s de chiffrement, nous pouvons contr\u00f4ler l'acc\u00e8s aux types d'\u00e9v\u00e9nements. L'approche propos\u00e9e permet aux courtiers d'\u00e9v\u00e9nements d'acheminer les \u00e9v\u00e9nements m\u00eame lorsqu'ils n'ont acc\u00e8s qu'\u00e0 un sous-ensemble des cl\u00e9s de chiffrement potentielles. Nous introduisons les syst\u00e8mes de publication/abonnement d\u00e9centralis\u00e9s et la cryptographie pertinente dans la section 2. Dans la section 3, nous pr\u00e9sentons notre mod\u00e8le de chiffrement du contenu des \u00e9v\u00e9nements au niveau de l'\u00e9v\u00e9nement et de l'attribut. La section 4 traite de la gestion des cl\u00e9s de chiffrement dans les syst\u00e8mes de publication/abonnement multi-domaines. Enfin, la section 6 traite des travaux connexes visant \u00e0 s\u00e9curiser les syst\u00e8mes de publication/abonnement et la section 7 fournit des remarques finales. 2. CONtext Dans cette section, nous fournissons une br\u00e8ve introduction aux syst\u00e8mes de publication/abonnement d\u00e9centralis\u00e9s. Nous indiquons nos hypoth\u00e8ses sur les syst\u00e8mes de publication/abonnement multi-domaines et d\u00e9crivons comment ces hypoth\u00e8ses influencent les d\u00e9veloppements que nous avons r\u00e9alis\u00e9s \u00e0 partir de nos travaux pr\u00e9c\u00e9demment publi\u00e9s. 2.1 Syst\u00e8mes de publication/abonnement d\u00e9centralis\u00e9s Un syst\u00e8me de publication/abonnement comprend des \u00e9diteurs, des abonn\u00e9s et un service d'\u00e9v\u00e9nements. Les \u00e9diteurs publient des \u00e9v\u00e9nements, les abonn\u00e9s s'abonnent aux \u00e9v\u00e9nements qui les int\u00e9ressent et le service d'\u00e9v\u00e9nements est charg\u00e9 de diffuser les \u00e9v\u00e9nements publi\u00e9s \u00e0 tous les abonn\u00e9s dont les int\u00e9r\u00eats correspondent \u00e0 l'\u00e9v\u00e9nement donn\u00e9. Le service d'\u00e9v\u00e9nements dans un syst\u00e8me de publication/abonnement d\u00e9centralis\u00e9 est distribu\u00e9 sur un certain nombre de n\u0153uds de courtier. Ensemble, ces courtiers forment un r\u00e9seau charg\u00e9 de maintenir les chemins de routage n\u00e9cessaires des \u00e9diteurs aux abonn\u00e9s. Clients -LRB- \u00e9diteurs et abonn\u00e9s -RRB- se connectent \u00e0 un courtier local, en qui le client a enti\u00e8rement confiance. Dans notre discussion, nous d\u00e9signons les h\u00e9bergeurs clients par les noms d'h\u00e9bergeurs \u00e9diteurs -LRB- PHB -RRB- ou d'h\u00e9bergeurs abonn\u00e9s -LRB- SHB -RRB- selon que le client connect\u00e9 est un \u00e9diteur ou un \u00e9diteur. d\u00e9ploiement de publication/abonnement multi-domaine sur un abonn\u00e9, respectivement. Un courtier local fait g\u00e9n\u00e9ralement partie du m\u00eame domaine que le client ou appartient \u00e0 un fournisseur de services approuv\u00e9 par le client. Un r\u00e9seau de courtiers peut avoir une topologie statique -LRB- par exemple Siena -LSB- 3 -RSB- et Gryphon -LSB- 14 -RSB- -RRB- ou une topologie dynamique -LRB- par exemple Scribe -LSB- 4 -RSB- et Hermes -LSB- 13 -RSB- -RRB-. L\u2019approche que nous proposons fonctionnera dans les deux cas.Une topologie statique permet \u00e0 l'administrateur syst\u00e8me de cr\u00e9er des domaines de confiance et d'am\u00e9liorer ainsi l'efficacit\u00e9 du routage en \u00e9vitant les cryptages inutiles -LRB- voir Sect. Notre travail est bas\u00e9 sur le syst\u00e8me Herm\u00e8s. Hermes est un middleware de publication/abonnement bas\u00e9 sur le contenu qui inclut une solide prise en charge des types d'\u00e9v\u00e9nements. En d\u2019autres termes, chaque publication est une instance d\u2019un type d\u2019\u00e9v\u00e9nement pr\u00e9d\u00e9fini particulier. Les publications sont v\u00e9rifi\u00e9es chez le courtier local de chaque \u00e9diteur. Notre sch\u00e9ma de chiffrement au niveau des attributs suppose que les \u00e9v\u00e9nements sont typ\u00e9s. Hermes utilise un r\u00e9seau superpos\u00e9 structur\u00e9 comme transport et poss\u00e8de donc une topologie dynamique. Une publication Hermes se compose d'un identifiant de type d'\u00e9v\u00e9nement et d'un ensemble de paires de valeurs d'attribut. L'identifiant de type est le hachage SHA-1 du nom du type d'\u00e9v\u00e9nement. Il est utilis\u00e9 pour acheminer la publication via le r\u00e9seau de courtiers d'\u00e9v\u00e9nements. Il masque commod\u00e9ment le type de publication, c'est-\u00e0-dire que les courtiers ne peuvent pas voir quels \u00e9v\u00e9nements les traversent \u00e0 moins qu'ils ne connaissent le nom et l'identifiant sp\u00e9cifiques du type d'\u00e9v\u00e9nement. 2.2 Types d'\u00e9v\u00e9nements s\u00e9curis\u00e9s Pesonen et al. introduit des types d'\u00e9v\u00e9nements s\u00e9curis\u00e9s dans -LSB- 11 -RSB-, dont l'int\u00e9grit\u00e9 et l'authenticit\u00e9 peuvent \u00eatre confirm\u00e9es en v\u00e9rifiant leurs signatures num\u00e9riques. Un effet secondaire utile des types d\u2019\u00e9v\u00e9nements s\u00e9curis\u00e9s est leur type d\u2019\u00e9v\u00e9nement et leurs noms d\u2019attributs uniques au monde. Ces noms peuvent \u00eatre r\u00e9f\u00e9renc\u00e9s par les politiques de contr\u00f4le d\u2019acc\u00e8s. Dans cet article, nous utilisons le nom s\u00e9curis\u00e9 du type d'\u00e9v\u00e9nement ou de l'attribut pour faire r\u00e9f\u00e9rence \u00e0 la cl\u00e9 de chiffrement utilis\u00e9e pour chiffrer l'\u00e9v\u00e9nement ou l'attribut. 2.3 Contr\u00f4le d'acc\u00e8s bas\u00e9 sur les capacit\u00e9s Pesonen et al. a propos\u00e9 une architecture de contr\u00f4le d'acc\u00e8s bas\u00e9e sur les capacit\u00e9s pour les syst\u00e8mes de publication/abonnement multi-domaines dans -LSB-12-RSB-. Le mod\u00e8le traite les types d'\u00e9v\u00e9nements comme des ressources auxquelles les \u00e9diteurs, les abonn\u00e9s et les courtiers d'\u00e9v\u00e9nements souhaitent acc\u00e9der. Le propri\u00e9taire du type d'\u00e9v\u00e9nement est responsable de la gestion du contr\u00f4le d'acc\u00e8s pour un type d'\u00e9v\u00e9nement en \u00e9mettant des certificats d'autorisation Simple Public Key Infrastructure -LRB- SPKI -RRB- qui accordent au titulaire l'acc\u00e8s au type d'\u00e9v\u00e9nement sp\u00e9cifi\u00e9. Par exemple, les \u00e9diteurs autoris\u00e9s auront re\u00e7u un certificat d'autorisation sp\u00e9cifiant que l'\u00e9diteur, identifi\u00e9 par une cl\u00e9 publique, est autoris\u00e9 \u00e0 publier des instances du type d'\u00e9v\u00e9nement sp\u00e9cifi\u00e9 dans le certificat. Nous exploitons le m\u00e9canisme de contr\u00f4le d'acc\u00e8s mentionn\u00e9 ci-dessus dans cet article en contr\u00f4lant l'acc\u00e8s aux cl\u00e9s de chiffrement \u00e0 l'aide des m\u00eames certificats d'autorisation. Autrement dit, un \u00e9diteur autoris\u00e9 \u00e0 publier un type d'\u00e9v\u00e9nement donn\u00e9 est \u00e9galement autoris\u00e9 \u00e0 acc\u00e9der aux cl\u00e9s de chiffrement utilis\u00e9es pour prot\u00e9ger les \u00e9v\u00e9nements de ce type. 4. 2.4 Mod\u00e8le de menace L'objectif du m\u00e9canisme propos\u00e9 est d'appliquer le contr\u00f4le d'acc\u00e8s pour les participants autoris\u00e9s au syst\u00e8me. Dans notre cas, le premier niveau de contr\u00f4le d'acc\u00e8s est appliqu\u00e9 lorsque le participant tente de rejoindre le r\u00e9seau de publication/abonnement. Les courtiers d'\u00e9v\u00e9nements non autoris\u00e9s ne sont pas autoris\u00e9s \u00e0 rejoindre le r\u00e9seau de courtiers. De m\u00eame, les clients d'\u00e9v\u00e9nements non autoris\u00e9s ne sont pas autoris\u00e9s \u00e0 se connecter \u00e0 un courtier d'\u00e9v\u00e9nements.Toutes les connexions du r\u00e9seau de courtiers entre les courtiers d'\u00e9v\u00e9nements et les clients d'\u00e9v\u00e9nements utilisent Transport Layer Security -LRB-TLS-RRB- -LSB- 5 -RSB- afin d'emp\u00eacher tout acc\u00e8s non autoris\u00e9 sur la couche de transport. L'architecture du syst\u00e8me de publication/abonnement signifie que les clients d'\u00e9v\u00e9nements doivent se connecter aux courtiers d'\u00e9v\u00e9nements afin de pouvoir acc\u00e9der au syst\u00e8me de publication/abonnement. Nous supposons donc que ces clients ne constituent pas une menace. Le client d'\u00e9v\u00e9nements s'appuie enti\u00e8rement sur le courtier d'\u00e9v\u00e9nements local pour acc\u00e9der au r\u00e9seau de courtiers. Par cons\u00e9quent, le client d'\u00e9v\u00e9nement ne peut acc\u00e9der \u00e0 aucun \u00e9v\u00e9nement sans l'aide du courtier local. Les courtiers, quant \u00e0 eux, sont capables d'analyser tous les \u00e9v\u00e9nements du syst\u00e8me qui les traversent. Un courtier peut analyser \u00e0 la fois le trafic d'\u00e9v\u00e9nements ainsi que le nombre et les noms des attributs renseign\u00e9s dans un \u00e9v\u00e9nement -LRB- dans le cas du chiffrement au niveau des attributs -RRB-. Il existe des approches viables pour emp\u00eacher l'analyse du trafic en ins\u00e9rant des \u00e9v\u00e9nements al\u00e9atoires dans le flux d'\u00e9v\u00e9nements afin de produire un mod\u00e8le de trafic uniforme. 6. TRAVAUX CONNEXES Wang et al. ont cat\u00e9goris\u00e9 les diff\u00e9rents probl\u00e8mes de s\u00e9curit\u00e9 qui doivent \u00eatre r\u00e9solus dans les syst\u00e8mes de publication/abonnement \u00e0 l'avenir dans -LSB- 20 -RSB-. Le document constitue un aper\u00e7u complet des probl\u00e8mes de s\u00e9curit\u00e9 dans les syst\u00e8mes de publication/abonnement et, en tant que tel, tente d'attirer l'attention sur ces probl\u00e8mes plut\u00f4t que de proposer des solutions. Bacon et coll. dans -LSB- 1 -RSB- examine l'utilisation du contr\u00f4le d'acc\u00e8s bas\u00e9 sur les r\u00f4les dans les syst\u00e8mes de publication/abonnement distribu\u00e9s multi-domaines. Opychal et Prakash abordent le probl\u00e8me de la confidentialit\u00e9 des \u00e9v\u00e9nements au niveau du dernier lien entre l'abonn\u00e9 et le SHB dans -LSB-10-RSB-. Ils d\u00e9clarent \u00e0 juste titre qu'une approche de communication de groupe s\u00e9curis\u00e9e est irr\u00e9alisable dans un environnement tel que la publication/abonnement qui comporte des adh\u00e9sions \u00e0 des groupes tr\u00e8s dynamiques. Nous supposons dans notre travail que le SHB est suffisamment puissant pour g\u00e9rer une connexion s\u00e9curis\u00e9e TLS pour chaque abonn\u00e9 local. Srivatsa et al. -LSB-19-RSB- et Raiciu et al. -LSB- 16 -RSB- pr\u00e9sentent des m\u00e9canismes de protection de la confidentialit\u00e9 des messages dans les infrastructures de publication/abonnement d\u00e9centralis\u00e9es. Par rapport \u00e0 notre travail, les deux articles visent \u00e0 fournir les moyens de prot\u00e9ger l'int\u00e9grit\u00e9 et la confidentialit\u00e9 des messages, tandis que l'objectif de notre travail est d'appliquer le contr\u00f4le d'acc\u00e8s au sein du r\u00e9seau de courtiers. Raiciu et coll. supposent dans leur travail qu'aucun des courtiers du r\u00e9seau n'est fiable et que, par cons\u00e9quent, tous les \u00e9v\u00e9nements sont crypt\u00e9s de l'\u00e9diteur \u00e0 l'abonn\u00e9 et que toute correspondance est bas\u00e9e sur des \u00e9v\u00e9nements crypt\u00e9s. En revanche, nous supposons que certains des courtiers sur le chemin d'une publication sont autoris\u00e9s \u00e0 acc\u00e9der \u00e0 cette publication et sont donc capables de mettre en \u0153uvre la mise en correspondance d'\u00e9v\u00e9nements. Nous supposons \u00e9galement que les courtiers d\u2019h\u00e9bergement des \u00e9diteurs et des abonn\u00e9s sont toujours fiables pour acc\u00e9der \u00e0 la publication. Enfin, Fi\u00e8ge et al. aborde le sujet connexe de la visibilit\u00e9 des \u00e9v\u00e9nements dans -LSB- 6 -RSB-.Alors que les travaux se sont concentr\u00e9s sur l\u2019utilisation des scopes comme m\u00e9canisme pour structurer des syst\u00e8mes bas\u00e9s sur des \u00e9v\u00e9nements \u00e0 grande \u00e9chelle, la notion de visibilit\u00e9 des \u00e9v\u00e9nements r\u00e9sonne dans une certaine mesure avec le contr\u00f4le d\u2019acc\u00e8s. 7. CONCLUSIONS Le chiffrement du contenu des \u00e9v\u00e9nements peut \u00eatre utilis\u00e9 pour appliquer une politique de contr\u00f4le d'acc\u00e8s pendant que les \u00e9v\u00e9nements sont en transit dans le r\u00e9seau de courtiers d'un syst\u00e8me de publication/abonnement multidomaine. Le chiffrement au niveau des attributs peut \u00eatre mis en \u0153uvre afin d\u2019appliquer des politiques de contr\u00f4le d\u2019acc\u00e8s plus pr\u00e9cises. En plus de fournir un contr\u00f4le d'acc\u00e8s au niveau des attributs, le chiffrement des attributs permet aux courtiers partiellement autoris\u00e9s de mettre en \u0153uvre un routage bas\u00e9 sur le contenu en fonction des attributs qui leur sont accessibles.", "keyphrases": ["syst\u00e8me de publication/abonnement s\u00e9curis\u00e9", "distribuer le contr\u00f4le d'acc\u00e8s", "domaine d'administration multiple", "chiffrement d'attribut", "multi-domaine", "frais g\u00e9n\u00e9raux communs globaux", "syst\u00e8me de distribution-application de distribution", "effectuer", "Crypter", "service de facturation des embouteillages"]}
{"file_name": "C-29", "text": "Impl\u00e9mentation et \u00e9valuation des performances de CONFLEX-G\u00a0: programme de recherche spatiale conformationnelle mol\u00e9culaire activ\u00e9 par une grille avec OmniRPC ABSTRACT CONFLEX-G est la version activ\u00e9e par une grille d'un programme de recherche spatiale conformationnelle mol\u00e9culaire appel\u00e9 CONFLEX. Nous avons impl\u00e9ment\u00e9 CONFLEX-G en utilisant un syst\u00e8me RPC de grille appel\u00e9 OmniRPC. Dans cet article, nous rapportons les performances de CONFLEX-G dans un banc d'essai en grille de plusieurs clusters de PC g\u00e9ographiquement r\u00e9partis. Afin d'explorer de nombreuses conformations de grandes biomol\u00e9cules, CONFLEX-G g\u00e9n\u00e8re des structures d'essai des mol\u00e9cules et attribue des t\u00e2ches pour optimiser une structure d'essai avec une m\u00e9thode de m\u00e9canique mol\u00e9culaire fiable dans la grille. OmniRPC fournit un mod\u00e8le de persistance restreint pour prendre en charge les applications de recherche param\u00e9trique. Dans ce mod\u00e8le, lorsque la proc\u00e9dure d'initialisation est d\u00e9finie dans le module RPC, le module est automatiquement initialis\u00e9 au moment de l'invocation en appelant la proc\u00e9dure d'initialisation. Cela peut \u00e9liminer les communications et initialisations inutiles \u00e0 chaque appel dans CONFLEX-G. CONFLEXG peut atteindre des performances comparables \u00e0 CONFLEX MPI et peut exploiter davantage de ressources informatiques en permettant l'utilisation d'un cluster de plusieurs clusters dans la grille. Le r\u00e9sultat exp\u00e9rimental montre que CONFLEX-G a atteint une acc\u00e9l\u00e9ration de 56,5 fois dans le cas de la mol\u00e9cule 1BL1, o\u00f9 la mol\u00e9cule est constitu\u00e9e d'un grand nombre d'atomes, et chaque essai d'optimisation de la structure n\u00e9cessite un temps consid\u00e9rable. Le d\u00e9s\u00e9quilibre de charge du temps d'optimisation de la structure d'essai peut \u00e9galement entra\u00eener une d\u00e9gradation des performances. 1. INTRODUCTION R\u00e9cemment, le concept de grille de calcul a commenc\u00e9 \u00e0 susciter un int\u00e9r\u00eat significatif dans le domaine du calcul en r\u00e9seau haute performance. CONFLEX est l'un des programmes de recherche spatiale conformationnelle les plus efficaces et les plus fiables -LSB- 1 -RSB-. Nous avons appliqu\u00e9 ce programme \u00e0 la parall\u00e9lisation utilisant l'informatique globale. Les performances du CONFLEX parall\u00e9lis\u00e9 permettent l'exploration de la r\u00e9gion de basse \u00e9nergie de l'espace conformationnel de petits peptides dans un temps \u00e9coul\u00e9 disponible \u00e0 l'aide d'un cluster PC local. \u00c9tant donn\u00e9 que l\u2019optimisation de la structure d\u2019essai dans CONFLEX est calcul\u00e9e via la m\u00e9canique mol\u00e9culaire, la recherche spatiale conformationnelle peut \u00eatre effectu\u00e9e rapidement par rapport \u00e0 celle utilisant le calcul orbital mol\u00e9culaire. Bien que la version parall\u00e9lis\u00e9e de CONFLEX ait \u00e9t\u00e9 utilis\u00e9e pour calculer en parall\u00e8le l'optimisation de la structure, qui repr\u00e9sente plus de 90 % du traitement dans la recherche de conformation mol\u00e9culaire, une am\u00e9lioration suffisante de l'acc\u00e9l\u00e9ration n'a pas pu \u00eatre obtenue par cette m\u00e9thode seule. Cela n\u00e9cessite les vastes ressources informatiques d\u2019un environnement informatique en grille. Dans cet article, nous d\u00e9crivons CONFLEX-G, un programme de recherche conformationnelle mol\u00e9culaire bas\u00e9 sur une grille, utilisant OmniRPC et rapportons ses performances dans une grille de plusieurs clusters de PC g\u00e9ographiquement r\u00e9partis. Le prototype CONFLEX-G alloue l'optimisation des structures d'essai de calcul, t\u00e2che tr\u00e8s chronophage, aux n\u0153uds de travail dans l'environnement grille afin d'obtenir un d\u00e9bit \u00e9lev\u00e9.De plus, nous comparons les performances de CONFLEX-G dans un cluster de PC local \u00e0 celles d'un banc d'essai en grille. OmniRPC -LSB- 2, 3, 4 -RSB- est une impl\u00e9mentation thread-safe de Ninf RPC -LSB- 5, 6 -RSB- qui est une fonctionnalit\u00e9 Grid RPC pour le calcul en environnement de grille. Plusieurs syst\u00e8mes adoptent le concept du RPC comme mod\u00e8le de base pour le calcul en environnement de grille, notamment Ninf-G -LSB- 7 -RSB-, NetSolve -LSB- 8 -RSB- et CORBA -LSB- 9 -RSB-. Le syst\u00e8me RPCstyle fournit une interface de programmation intuitive et facile \u00e0 utiliser, permettant aux utilisateurs du syst\u00e8me de grille de cr\u00e9er facilement des applications compatibles avec la grille. Afin de prendre en charge la programmation parall\u00e8le, un client RPC peut \u00e9mettre des demandes d'appel asynchrones vers un autre ordinateur distant pour exploiter le parall\u00e9lisme \u00e0 l'\u00e9chelle du r\u00e9seau via OmniRPC. Dans cet article, nous proposons le mod\u00e8le de persistance OmniRPC \u00e0 un syst\u00e8me Grid RPC et d\u00e9montrons son efficacit\u00e9. Afin de prendre en charge une application typique pour un environnement de grille, telle qu'une application de recherche param\u00e9trique, dans laquelle la m\u00eame fonction est ex\u00e9cut\u00e9e avec diff\u00e9rents param\u00e8tres d'entr\u00e9e sur le m\u00eame ensemble de donn\u00e9es. Dans le syst\u00e8me GridRPC actuel -LSB-10-RSB-, les donn\u00e9es d\u00e9finies par l'appel pr\u00e9c\u00e9dent ne peuvent pas \u00eatre utilis\u00e9es par les appels suivants. Cet article d\u00e9montre que CONFLEX-G est capable d'exploiter les \u00e9normes ressources informatiques d'un environnement de grille et de rechercher des conform\u00e8res mol\u00e9culaires \u00e0 grande \u00e9chelle. Nous d\u00e9montrons CONFLEX-G sur notre banc d'essai en grille en utilisant la prot\u00e9ine r\u00e9elle comme mol\u00e9cule \u00e9chantillon. La fonction OmniRPC du module d'initialisation automatique -LRB-AIM-RRB- permet au syst\u00e8me de calculer efficacement de nombreux conformateurs. De plus, en utilisant OmniRPC, l'utilisateur peut parall\u00e9liser l'application existante sur une grille et passer du cluster \u00e0 l'environnement de grille sans modifier le code du programme ni compiler le programme. De plus, l'utilisateur peut facilement cr\u00e9er un environnement de r\u00e9seau priv\u00e9. Un aper\u00e7u Figure 1 : Algorithme de recherche d'espace conformationnel dans le CONFLEX original. du syst\u00e8me CONFLEX est pr\u00e9sent\u00e9 dans la section 2, et la mise en \u0153uvre et la conception de CONFLEX-G sont d\u00e9crites dans la section 3. Nous rapportons les r\u00e9sultats exp\u00e9rimentaux obtenus en utilisant CONFLEX-G et discutons de ses performances dans la section 4. Dans la section 6, nous pr\u00e9sentons les conclusions et discutons sujets d\u2019\u00e9tudes futures. 5. TRAVAUX CONNEXES R\u00e9cemment, un algorithme a \u00e9t\u00e9 d\u00e9velopp\u00e9 pour r\u00e9soudre les probl\u00e8mes de parall\u00e9lisation et de communication dans des processeurs mal connect\u00e9s destin\u00e9s \u00e0 \u00eatre utilis\u00e9s pour la simulation. Cela nous a permis de simuler le pliage pour la premi\u00e8re fois et d'examiner directement les maladies li\u00e9es au pliage. SETI@home[14] est un programme permettant de rechercher la vie extraterrestre en analysant les signaux des radiot\u00e9lescopes \u00e0 l'aide des donn\u00e9es des radiot\u00e9lescopes \u00e0 transform\u00e9e de Fourier provenant de t\u00e9lescopes de diff\u00e9rents sites. SETI@home aborde des probl\u00e8mes extr\u00eamement parall\u00e8les, dans lesquels le calcul peut facilement \u00eatre r\u00e9parti sur plusieurs ordinateurs. Les blocs de donn\u00e9es du radiot\u00e9lescope peuvent facilement \u00eatre attribu\u00e9s \u00e0 diff\u00e9rents ordinateurs. Cependant, les comp\u00e9tences et les efforts requis pour d\u00e9velopper une application de grille peuvent ne pas \u00eatre requis pour OmniRPC.Nimrod/G -LSB- 15 -RSB- est un outil de mod\u00e9lisation param\u00e9trique distribu\u00e9e et impl\u00e9mente une ferme de t\u00e2ches parall\u00e8les pour les simulations qui n\u00e9cessitent plusieurs param\u00e8tres d'entr\u00e9e variables. Nimrod a \u00e9t\u00e9 appliqu\u00e9 \u00e0 des applications telles que la bioinformatique, la recherche op\u00e9rationnelle et la mod\u00e9lisation mol\u00e9culaire pour la conception de m\u00e9dicaments. NetSolve -LSB- 8 -RSB- est une fonctionnalit\u00e9 RPC similaire \u00e0 OmniRPC et Ninf, fournissant une interface de programmation similaire et un m\u00e9canisme d'\u00e9quilibrage automatique de charge. Matsuoka et coll. -LSB- 16 -RSB- a \u00e9galement discut\u00e9 de plusieurs probl\u00e8mes de conception li\u00e9s aux syst\u00e8mes RPC en grille. 6. CONCLUSIONS ET TRAVAUX FUTURS Nous avons con\u00e7u et impl\u00e9ment\u00e9 CONFLEX-G en utilisant OmniRPC. Nous avons rapport\u00e9 ses performances dans un banc d'essai en grille de plusieurs clusters de PC g\u00e9ographiquement r\u00e9partis. Afin d'explorer la conformation de grandes biomol\u00e9cules, CONFLEXG a \u00e9t\u00e9 utilis\u00e9 pour g\u00e9n\u00e9rer des structures d'essai des mol\u00e9cules et attribuer des t\u00e2ches pour les optimiser par la m\u00e9canique mol\u00e9culaire dans la grille. OmniRPC fournit un mod\u00e8le de persistance restreint afin que le module soit automatiquement initialis\u00e9 lors de l'appel en appelant la proc\u00e9dure d'initialisation. Cela peut \u00e9liminer les communications inutiles et l'initialisation \u00e0 chaque appel dans CONFLEX-G. CONFLEX-G peut atteindre des performances comparables \u00e0 CONFLEX MPI et exploite davantage de ressources informatiques en permettant l'utilisation de plusieurs clusters de PC dans la grille. Le r\u00e9sultat exp\u00e9rimental montre que CONFLEX-G a atteint une acc\u00e9l\u00e9ration de 56,5 fois pour la mol\u00e9cule 1BL1, o\u00f9 la mol\u00e9cule est constitu\u00e9e d'un grand nombre d'atomes et o\u00f9 chaque essai d'optimisation de structure n\u00e9cessite beaucoup de temps. Le d\u00e9s\u00e9quilibre de charge des optimisations de la structure d'essai peut entra\u00eener une d\u00e9gradation des performances. Nous devons affiner l'algorithme utilis\u00e9 pour g\u00e9n\u00e9rer la structure d'essai afin d'am\u00e9liorer l'optimisation de l'\u00e9quilibre de charge pour les structures d'essai dans CONFLEX. Les \u00e9tudes futures comprendront le d\u00e9veloppement d'outils de d\u00e9ploiement et un examen de la tol\u00e9rance aux pannes. Dans l'OmniRPC actuel, l'enregistrement d'un programme d'ex\u00e9cution sur des h\u00f4tes distants et les d\u00e9ploiements de programmes de travail sont d\u00e9finis manuellement. Des outils de d\u00e9ploiement seront n\u00e9cessaires \u00e0 mesure que le nombre d\u2019h\u00f4tes distants augmentera. Dans les environnements de grille dans lesquels l'environnement change de mani\u00e8re dynamique, il est \u00e9galement n\u00e9cessaire de prendre en charge la tol\u00e9rance aux pannes. Cette fonctionnalit\u00e9 est particuli\u00e8rement importante dans les applications \u00e0 grande \u00e9chelle qui n\u00e9cessitent de longs calculs dans un environnement de grille. Nous pr\u00e9voyons d'affiner l'algorithme d'optimisation conformationnelle dans CONFLEX pour explorer la recherche spatiale de conformation de biomol\u00e9cules plus grandes telles que la prot\u00e9ase du VIH en utilisant jusqu'\u00e0 1 000 travailleurs dans un environnement de grille.-LSB- 16 -RSB- a \u00e9galement discut\u00e9 de plusieurs probl\u00e8mes de conception li\u00e9s aux syst\u00e8mes RPC en grille. 6. CONCLUSIONS ET TRAVAUX FUTURS Nous avons con\u00e7u et impl\u00e9ment\u00e9 CONFLEX-G en utilisant OmniRPC. Nous avons rapport\u00e9 ses performances dans un banc d'essai en grille de plusieurs clusters de PC g\u00e9ographiquement r\u00e9partis. Afin d'explorer la conformation de grandes biomol\u00e9cules, CONFLEXG a \u00e9t\u00e9 utilis\u00e9 pour g\u00e9n\u00e9rer des structures d'essai des mol\u00e9cules et attribuer des t\u00e2ches pour les optimiser par la m\u00e9canique mol\u00e9culaire dans la grille. OmniRPC fournit un mod\u00e8le de persistance restreint afin que le module soit automatiquement initialis\u00e9 lors de l'appel en appelant la proc\u00e9dure d'initialisation. Cela peut \u00e9liminer les communications inutiles et l'initialisation \u00e0 chaque appel dans CONFLEX-G. CONFLEX-G peut atteindre des performances comparables \u00e0 CONFLEX MPI et exploite davantage de ressources informatiques en permettant l'utilisation de plusieurs clusters de PC dans la grille. Le r\u00e9sultat exp\u00e9rimental montre que CONFLEX-G a atteint une acc\u00e9l\u00e9ration de 56,5 fois pour la mol\u00e9cule 1BL1, o\u00f9 la mol\u00e9cule est constitu\u00e9e d'un grand nombre d'atomes et o\u00f9 chaque essai d'optimisation de structure n\u00e9cessite beaucoup de temps. Le d\u00e9s\u00e9quilibre de charge des optimisations de la structure d'essai peut entra\u00eener une d\u00e9gradation des performances. Nous devons affiner l'algorithme utilis\u00e9 pour g\u00e9n\u00e9rer la structure d'essai afin d'am\u00e9liorer l'optimisation de l'\u00e9quilibre de charge pour les structures d'essai dans CONFLEX. Les \u00e9tudes futures comprendront le d\u00e9veloppement d'outils de d\u00e9ploiement et un examen de la tol\u00e9rance aux pannes. Dans l'OmniRPC actuel, l'enregistrement d'un programme d'ex\u00e9cution sur des h\u00f4tes distants et les d\u00e9ploiements de programmes de travail sont d\u00e9finis manuellement. Des outils de d\u00e9ploiement seront n\u00e9cessaires \u00e0 mesure que le nombre d\u2019h\u00f4tes distants augmentera. Dans les environnements de grille dans lesquels l'environnement change de mani\u00e8re dynamique, il est \u00e9galement n\u00e9cessaire de prendre en charge la tol\u00e9rance aux pannes. Cette fonctionnalit\u00e9 est particuli\u00e8rement importante dans les applications \u00e0 grande \u00e9chelle qui n\u00e9cessitent de longs calculs dans un environnement de grille. Nous pr\u00e9voyons d'affiner l'algorithme d'optimisation conformationnelle dans CONFLEX pour explorer la recherche spatiale de conformation de biomol\u00e9cules plus grandes telles que la prot\u00e9ase du VIH en utilisant jusqu'\u00e0 1 000 travailleurs dans un environnement de grille.-LSB- 16 -RSB- a \u00e9galement discut\u00e9 de plusieurs probl\u00e8mes de conception li\u00e9s aux syst\u00e8mes RPC en grille. 6. CONCLUSIONS ET TRAVAUX FUTURS Nous avons con\u00e7u et impl\u00e9ment\u00e9 CONFLEX-G en utilisant OmniRPC. Nous avons rapport\u00e9 ses performances dans un banc d'essai en grille de plusieurs clusters de PC g\u00e9ographiquement r\u00e9partis. Afin d'explorer la conformation de grandes biomol\u00e9cules, CONFLEXG a \u00e9t\u00e9 utilis\u00e9 pour g\u00e9n\u00e9rer des structures d'essai des mol\u00e9cules et attribuer des t\u00e2ches pour les optimiser par la m\u00e9canique mol\u00e9culaire dans la grille. OmniRPC fournit un mod\u00e8le de persistance restreint afin que le module soit automatiquement initialis\u00e9 lors de l'appel en appelant la proc\u00e9dure d'initialisation. Cela peut \u00e9liminer les communications inutiles et l'initialisation \u00e0 chaque appel dans CONFLEX-G. CONFLEX-G peut atteindre des performances comparables \u00e0 CONFLEX MPI et exploite davantage de ressources informatiques en permettant l'utilisation de plusieurs clusters de PC dans la grille. Le r\u00e9sultat exp\u00e9rimental montre que CONFLEX-G a atteint une acc\u00e9l\u00e9ration de 56,5 fois pour la mol\u00e9cule 1BL1, o\u00f9 la mol\u00e9cule est constitu\u00e9e d'un grand nombre d'atomes et o\u00f9 chaque essai d'optimisation de structure n\u00e9cessite beaucoup de temps. Le d\u00e9s\u00e9quilibre de charge des optimisations de la structure d'essai peut entra\u00eener une d\u00e9gradation des performances. Nous devons affiner l'algorithme utilis\u00e9 pour g\u00e9n\u00e9rer la structure d'essai afin d'am\u00e9liorer l'optimisation de l'\u00e9quilibre de charge pour les structures d'essai dans CONFLEX. Les \u00e9tudes futures comprendront le d\u00e9veloppement d'outils de d\u00e9ploiement et un examen de la tol\u00e9rance aux pannes. Dans l'OmniRPC actuel, l'enregistrement d'un programme d'ex\u00e9cution sur des h\u00f4tes distants et les d\u00e9ploiements de programmes de travail sont d\u00e9finis manuellement. Des outils de d\u00e9ploiement seront n\u00e9cessaires \u00e0 mesure que le nombre d\u2019h\u00f4tes distants augmentera. Dans les environnements de grille dans lesquels l'environnement change de mani\u00e8re dynamique, il est \u00e9galement n\u00e9cessaire de prendre en charge la tol\u00e9rance aux pannes. Cette fonctionnalit\u00e9 est particuli\u00e8rement importante dans les applications \u00e0 grande \u00e9chelle qui n\u00e9cessitent de longs calculs dans un environnement de grille. Nous pr\u00e9voyons d'affiner l'algorithme d'optimisation conformationnelle dans CONFLEX pour explorer la recherche spatiale de conformation de biomol\u00e9cules plus grandes telles que la prot\u00e9ase du VIH en utilisant jusqu'\u00e0 1 000 travailleurs dans un environnement de grille.Le r\u00e9sultat exp\u00e9rimental montre que CONFLEX-G a atteint une acc\u00e9l\u00e9ration de 56,5 fois pour la mol\u00e9cule 1BL1, o\u00f9 la mol\u00e9cule est constitu\u00e9e d'un grand nombre d'atomes et o\u00f9 chaque essai d'optimisation de structure n\u00e9cessite beaucoup de temps. Le d\u00e9s\u00e9quilibre de charge des optimisations de la structure d'essai peut entra\u00eener une d\u00e9gradation des performances. Nous devons affiner l'algorithme utilis\u00e9 pour g\u00e9n\u00e9rer la structure d'essai afin d'am\u00e9liorer l'optimisation de l'\u00e9quilibre de charge pour les structures d'essai dans CONFLEX. Les \u00e9tudes futures comprendront le d\u00e9veloppement d'outils de d\u00e9ploiement et un examen de la tol\u00e9rance aux pannes. Dans l'OmniRPC actuel, l'enregistrement d'un programme d'ex\u00e9cution sur des h\u00f4tes distants et les d\u00e9ploiements de programmes de travail sont d\u00e9finis manuellement. Des outils de d\u00e9ploiement seront n\u00e9cessaires \u00e0 mesure que le nombre d\u2019h\u00f4tes distants augmentera. Dans les environnements de grille dans lesquels l'environnement change de mani\u00e8re dynamique, il est \u00e9galement n\u00e9cessaire de prendre en charge la tol\u00e9rance aux pannes. Cette fonctionnalit\u00e9 est particuli\u00e8rement importante dans les applications \u00e0 grande \u00e9chelle qui n\u00e9cessitent de longs calculs dans un environnement de grille. Nous pr\u00e9voyons d'affiner l'algorithme d'optimisation conformationnelle dans CONFLEX pour explorer la recherche spatiale de conformation de biomol\u00e9cules plus grandes telles que la prot\u00e9ase du VIH en utilisant jusqu'\u00e0 1 000 travailleurs dans un environnement de grille.Le r\u00e9sultat exp\u00e9rimental montre que CONFLEX-G a atteint une acc\u00e9l\u00e9ration de 56,5 fois pour la mol\u00e9cule 1BL1, o\u00f9 la mol\u00e9cule est constitu\u00e9e d'un grand nombre d'atomes et o\u00f9 chaque essai d'optimisation de structure n\u00e9cessite beaucoup de temps. Le d\u00e9s\u00e9quilibre de charge des optimisations de la structure d'essai peut entra\u00eener une d\u00e9gradation des performances. Nous devons affiner l'algorithme utilis\u00e9 pour g\u00e9n\u00e9rer la structure d'essai afin d'am\u00e9liorer l'optimisation de l'\u00e9quilibre de charge pour les structures d'essai dans CONFLEX. Les \u00e9tudes futures comprendront le d\u00e9veloppement d'outils de d\u00e9ploiement et un examen de la tol\u00e9rance aux pannes. Dans l'OmniRPC actuel, l'enregistrement d'un programme d'ex\u00e9cution sur des h\u00f4tes distants et les d\u00e9ploiements de programmes de travail sont d\u00e9finis manuellement. Des outils de d\u00e9ploiement seront n\u00e9cessaires \u00e0 mesure que le nombre d\u2019h\u00f4tes distants augmentera. Dans les environnements de grille dans lesquels l'environnement change de mani\u00e8re dynamique, il est \u00e9galement n\u00e9cessaire de prendre en charge la tol\u00e9rance aux pannes. Cette fonctionnalit\u00e9 est particuli\u00e8rement importante dans les applications \u00e0 grande \u00e9chelle qui n\u00e9cessitent de longs calculs dans un environnement de grille. Nous pr\u00e9voyons d'affiner l'algorithme d'optimisation conformationnelle dans CONFLEX pour explorer la recherche spatiale de conformation de biomol\u00e9cules plus grandes telles que la prot\u00e9ase du VIH en utilisant jusqu'\u00e0 1 000 travailleurs dans un environnement de grille.", "keyphrases": ["conflex-g", "omnirpc", "recherche d'espace conforme", "biomol\u00e9cule", "module rpc", "proc\u00e9dure de lancement", "mpu", "cluster d'ordinateurs", "calcul en grille", "syst\u00e8me RPC en grille", "m\u00e9canique mol\u00e9culaire", "module d'initialisation automatique"]}
{"file_name": "C-9", "text": "EDAS : Fournir un environnement pour les services adaptatifs d\u00e9centralis\u00e9s R\u00c9SUM\u00c9 \u00c0 mesure que l'id\u00e9e de virtualisation de la puissance de calcul, du stockage et de la bande passante devient de plus en plus importante, le calcul en grille \u00e9volue et est appliqu\u00e9 \u00e0 un nombre croissant d'applications. L'environnement pour les services adaptatifs d\u00e9centralis\u00e9s -LRB- EDAS -RRB- fournit une infrastructure de type grille pour les services \u00e0 long terme accessibles aux utilisateurs -LRB-, par exemple un serveur Web, un r\u00e9f\u00e9rentiel de code source, etc. -RRB-. Il vise \u00e0 soutenir l\u2019ex\u00e9cution autonome et l\u2019\u00e9volution des services en termes d\u2019\u00e9volutivit\u00e9 et de distribution sensible aux ressources. EDAS propose des mod\u00e8les de services flexibles bas\u00e9s sur des objets mobiles distribu\u00e9s, allant d'un sc\u00e9nario client-serveur traditionnel \u00e0 une approche enti\u00e8rement peer-to-peer. La gestion automatique et dynamique des ressources permet une utilisation optimis\u00e9e des ressources disponibles tout en minimisant la complexit\u00e9 administrative. 1. INTRODUCTION Les infrastructures de calcul en grille visent \u00e0 virtualiser un groupe d'ordinateurs, de serveurs et de stockage en un seul grand syst\u00e8me informatique. La gestion des ressources est un probl\u00e8me cl\u00e9 dans de tels syst\u00e8mes, n\u00e9cessaire \u00e0 une r\u00e9partition efficace et automatis\u00e9e des t\u00e2ches sur la grille. De telles infrastructures de r\u00e9seau sont souvent d\u00e9ploy\u00e9es au niveau de l'entreprise, mais des projets comme SETI@home -LSB-1-RSB- ont \u00e9galement d\u00e9montr\u00e9 la faisabilit\u00e9 de r\u00e9seaux plus d\u00e9centralis\u00e9s. Les infrastructures de calcul en grille actuelles ne fournissent pas un support suffisant pour l'ex\u00e9cution de services distribu\u00e9s, accessibles aux utilisateurs et \u00e0 long terme, car elles sont con\u00e7ues pour r\u00e9soudre des t\u00e2ches de calcul ou de donn\u00e9es intensives avec un ensemble de param\u00e8tres plus ou moins fixes. Au lieu de cela, une infrastructure pour les services \u00e0 long terme doit placer les services en fonction de leur demande actuelle et de leurs besoins futurs estim\u00e9s. Cependant, la migration est co\u00fbteuse car l'\u00e9tat complet d'un service doit \u00eatre transf\u00e9r\u00e9. De plus, un service non r\u00e9pliqu\u00e9 n'est pas accessible pendant la migration. Par cons\u00e9quent, la gestion des ressources doit \u00e9viter la migration si possible. En outre, un concept de service doit \u00eatre fourni qui \u00e9vite la surcharge en premier lieu, et en second lieu inhibe l'indisponibilit\u00e9 du service si la migration ne peut \u00eatre \u00e9vit\u00e9e. EDAS -LSB- 2 -RSB- vise \u00e0 fournir une infrastructure de type grille pour les services \u00e0 long terme accessibles aux utilisateurs qui permet l'adaptation dynamique au moment de l'ex\u00e9cution, fournit une infrastructure de gestion et offre une prise en charge au niveau du syst\u00e8me pour l'\u00e9volutivit\u00e9 et les pannes. tol\u00e9rance. Les n\u0153uds peuvent rejoindre et quitter l'infrastructure de mani\u00e8re dynamique, et toutes les t\u00e2ches de gestion, en particulier la gestion des ressources, sont d\u00e9centralis\u00e9es. L'environnement est construit sur notre infrastructure middleware AspectIX -LSB- 3 -RSB-, qui prend directement en charge la reconfiguration dynamique des services bas\u00e9e sur la QoS. La gestion des ressources se concentre sur l\u2019ex\u00e9cution de services qui ont une dur\u00e9e de fonctionnement longue, potentiellement infinie. Ces services sont organis\u00e9s en projets. Chaque projet a une port\u00e9e d'ex\u00e9cution distribu\u00e9e appel\u00e9e environnement de service. Un tel environnement peut s\u2019\u00e9tendre \u00e0 plusieurs institutions.Chaque institution repr\u00e9sente un domaine administratif capable de soutenir un projet avec un ensemble fixe de ressources. Notre approche prend en charge la gestion adaptative des ressources de tous les projets relevant du p\u00e9rim\u00e8tre d'une institution bas\u00e9e sur un algorithme inspir\u00e9 des algorithmes diffusifs d'\u00e9quilibrage de charge d\u00e9centralis\u00e9 -LSB- 4 -RSB-. On ne sait pas comment subdiviser de mani\u00e8re optimale ces ressources pour les services, car la demande en ressources des services peut changer au fil du temps ou m\u00eame fluctuer fr\u00e9quemment. Pour fournir les ressources selon les besoins, notre approche r\u00e9affecte automatiquement les ressources libres ou inutiles entre les instances de service, les projets et les n\u0153uds. Dans les cas o\u00f9 la r\u00e9affectation n'est pas possible, la migration du service demandeur est initi\u00e9e. Dans une infrastructure de grille de service \u00e0 long terme, la r\u00e9plication active pr\u00e9sente divers avantages : les r\u00e9pliques peuvent rejoindre et quitter le groupe d'objets et donc les r\u00e9pliques peuvent \u00eatre migr\u00e9es sans indisponibilit\u00e9 du service. Enfin, un certain nombre de crashs de n\u0153uds peuvent \u00eatre tol\u00e9r\u00e9s. La section 4 explique les concepts d'autogestion et de red\u00e9ploiement de la gestion adaptative distribu\u00e9e des ressources. La section 5 d\u00e9crit le cadre des services adaptatifs d\u00e9centralis\u00e9s. La section 6 d\u00e9crit les travaux connexes et enfin la section 7 conclut le document. 6. TRAVAUX CONNEXES Les infrastructures de grille telles que Globus-Toolkit -LSB-11-RSB- fournissent des services et des m\u00e9canismes pour les environnements h\u00e9t\u00e9rog\u00e8nes distribu\u00e9s afin de combiner des ressources \u00e0 la demande pour r\u00e9soudre des t\u00e2ches gourmandes en ressources et gourmandes en calcul. En raison de cette orientation, ils se concentrent sur diff\u00e9rents mod\u00e8les de service et ne fournissent aucun support pour la mobilit\u00e9 des objets, voire m\u00eame une approche objet distribu\u00e9e. Mais surtout, ils suivent une approche diff\u00e9rente de gestion des ressources car ils ciblent l\u2019ex\u00e9cution parall\u00e8le d\u2019un grand nombre de t\u00e2ches \u00e0 court et moyen terme. Les objets activement r\u00e9pliqu\u00e9s sont fournis par Jgroup -LSB- 14 -RSB- bas\u00e9 sur RMI. En plus de ce middleware de base, une couche de gestion de r\u00e9plication a \u00e9t\u00e9 impl\u00e9ment\u00e9e appel\u00e9e ARM -LSB-15-RSB-. JGroup se concentre sur la r\u00e9plication active d'objets mais ne prend pas en charge des services plus flexibles comme le fait EDAS. ARM peut \u00eatre compar\u00e9 \u00e0 EDAS mais ne prend en charge aucune distribution prenant en charge les ressources. Fog -LSB- 16 -RSB- et Globe -LSB- 17 -RSB- sont des environnements middleware de base qui prennent en charge l'approche objet fragment\u00e9. Globe prend en compte la r\u00e9plication et la mise en cache. Les deux syst\u00e8mes ne prennent pas en charge la distribution tenant compte des ressources. 7. CONCLUSION ET TRAVAUX EN COURS Bas\u00e9s sur le mod\u00e8le objet fragment\u00e9 et l'architecture de l'environnement EDAS, les services adaptatifs d\u00e9centralis\u00e9s peuvent \u00eatre facilement con\u00e7us, mis en \u0153uvre et ex\u00e9cut\u00e9s. Comme d\u00e9crit, la gestion des ressources peut \u00eatre d\u00e9compos\u00e9e en deux probl\u00e8mes principaux qui doivent \u00eatre r\u00e9solus. Contr\u00f4ler et g\u00e9rer les limites des ressources, notamment s'assurer que les ressources attribu\u00e9es sont disponibles -LRB- m\u00eame dans le context de pannes de n\u0153uds -RRB- et le placement autonome des services. Pour les deux probl\u00e8mes, nous proposons une solution,un environnement de simulation actuellement mis en \u0153uvre v\u00e9rifiera leur faisabilit\u00e9. Dans une prochaine \u00e9tape, la gestion des ressources sera int\u00e9gr\u00e9e dans un prototype d\u00e9j\u00e0 impl\u00e9ment\u00e9 de l'architecture EDAS. Comme d\u00e9crit, nous avons d\u00e9j\u00e0 une premi\u00e8re mise en \u0153uvre du cadre pour les services adaptatifs d\u00e9centralis\u00e9s. Ce cadre doit \u00eatre \u00e9tendu pour interagir en douceur avec la gestion des ressources et l'architecture EDAS. Dans une derni\u00e8re \u00e9tape, nous devons impl\u00e9menter certains services qui v\u00e9rifient la convivialit\u00e9 de l'ensemble du projet EDAS.", "keyphrases": ["service d'adaptation d\u00e9centr\u00e9", "gestion des ressources", "environnement domestique", "infrastructure", "client", "service \u00e0 long terme", "eda", "limite locale", "limite globale", "ressource", "n\u0153ud"]}
{"file_name": "H-14", "text": "\u00c9tudier l'utilisation de destinations populaires pour am\u00e9liorer l'interaction de recherche sur le Web R\u00c9SUM\u00c9 Nous pr\u00e9sentons une nouvelle fonctionnalit\u00e9 d'interaction de recherche sur le Web qui, pour une requ\u00eate donn\u00e9e, fournit des liens vers des sites Web fr\u00e9quemment visit\u00e9s par d'autres utilisateurs ayant des besoins d'information similaires. Ces destinations populaires compl\u00e8tent les r\u00e9sultats de recherche traditionnels, permettant une navigation directe vers des ressources faisant autorit\u00e9 pour le sujet de la requ\u00eate. Les destinations sont identifi\u00e9es \u00e0 l'aide de l'historique du comportement de recherche et de navigation de nombreux utilisateurs sur une p\u00e9riode de temps prolong\u00e9e, dont le comportement collectif constitue une base pour l'autorit\u00e9 de source informatique. Nous d\u00e9crivons une \u00e9tude utilisateur qui a compar\u00e9 la suggestion de destinations avec la suggestion de requ\u00eates associ\u00e9es pr\u00e9c\u00e9demment propos\u00e9e, ainsi qu'avec la recherche Web traditionnelle et sans aide. Les r\u00e9sultats montrent que la recherche am\u00e9lior\u00e9e par les suggestions de destination surpasse les autres syst\u00e8mes pour les t\u00e2ches exploratoires, les meilleures performances \u00e9tant obtenues en explorant le comportement pass\u00e9 des utilisateurs avec une granularit\u00e9 au niveau de la requ\u00eate. 1. INTRODUCTION Le probl\u00e8me de l'am\u00e9lioration des requ\u00eates envoy\u00e9es aux syst\u00e8mes de recherche d'informations -LRB- IR -RRB- a \u00e9t\u00e9 \u00e9tudi\u00e9 de mani\u00e8re approfondie dans la recherche IR -LSB- 4 -RSB- -LSB- 11 -RSB-. Des formulations de requ\u00eates alternatives, appel\u00e9es suggestions de requ\u00eates, peuvent \u00eatre propos\u00e9es aux utilisateurs \u00e0 la suite d'une requ\u00eate initiale, leur permettant de modifier la sp\u00e9cification de leurs besoins fournie au syst\u00e8me, conduisant ainsi \u00e0 des performances de r\u00e9cup\u00e9ration am\u00e9lior\u00e9es. La popularit\u00e9 r\u00e9cente des moteurs de recherche Web a permis des suggestions de requ\u00eates qui s'appuient sur le comportement de reformulation des requ\u00eates de nombreux utilisateurs pour formuler des recommandations de requ\u00eates bas\u00e9es sur les interactions utilisateur pr\u00e9c\u00e9dentes -LSB-10-RSB-. L'exploitation des processus d\u00e9cisionnels de nombreux utilisateurs pour la reformulation des requ\u00eates trouve ses racines dans l'indexation adaptative -LSB-8-RSB-. Cependant, les approches de suggestion de requ\u00eates bas\u00e9es sur l'interaction peuvent \u00eatre moins efficaces lorsque le besoin d'information est exploratoire, puisqu'une grande partie de l'activit\u00e9 des utilisateurs pour de tels besoins d'information peut se produire au-del\u00e0 des interactions avec les moteurs de recherche. Dans les cas o\u00f9 la recherche dirig\u00e9e ne repr\u00e9sente qu'une fraction du comportement de recherche d'informations des utilisateurs, l'utilit\u00e9 des clics des autres utilisateurs sur l'espace des r\u00e9sultats les mieux class\u00e9s peut \u00eatre limit\u00e9e, car elle ne couvre pas le comportement de navigation ult\u00e9rieur. Dans le m\u00eame temps, la navigation des utilisateurs qui suit les interactions des moteurs de recherche fournit une approbation implicite des ressources Web pr\u00e9f\u00e9r\u00e9es par les utilisateurs, ce qui peut \u00eatre particuli\u00e8rement utile pour les t\u00e2ches de recherche exploratoire. Ainsi, nous proposons d'exploiter une combinaison de comportements de recherche et de navigation ant\u00e9rieurs des utilisateurs pour am\u00e9liorer les interactions de recherche sur le Web des utilisateurs. Les plugins de navigateur et les journaux du serveur proxy permettent d'acc\u00e9der aux mod\u00e8les de navigation des utilisateurs qui transcendent les interactions des moteurs de recherche. Dans des travaux ant\u00e9rieurs, ces donn\u00e9es ont \u00e9t\u00e9 utilis\u00e9es pour am\u00e9liorer le classement des r\u00e9sultats de recherche par Agichtein et al. -LSB- 1 -RSB-. Radlinski et Joachims -LSB- 13 -RSB- ont utilis\u00e9 une telle intelligence collective des utilisateurs pour am\u00e9liorer la pr\u00e9cision de la r\u00e9cup\u00e9ration en utilisant des s\u00e9quences de reformulations de requ\u00eates cons\u00e9cutives,pourtant, leur approche ne prend pas en compte les interactions des utilisateurs au-del\u00e0 de la page de r\u00e9sultats de recherche. Dans cet article, nous pr\u00e9sentons une \u00e9tude utilisateur d'une technique qui exploite le comportement de recherche et de navigation de nombreux utilisateurs pour sugg\u00e9rer des pages Web populaires, d\u00e9sormais appel\u00e9es destinations, en plus des r\u00e9sultats de recherche habituels. Les destinations peuvent ne pas figurer parmi les meilleurs r\u00e9sultats, ne pas contenir les termes recherch\u00e9s ou m\u00eame ne pas \u00eatre index\u00e9es par le moteur de recherche. Au lieu de cela, il s\u2019agit de pages sur lesquelles d\u2019autres utilisateurs se retrouvent fr\u00e9quemment apr\u00e8s avoir soumis des requ\u00eates identiques ou similaires, puis parcouru les r\u00e9sultats de recherche initialement cliqu\u00e9s. Nous supposons que les destinations populaires aupr\u00e8s d'un grand nombre d'utilisateurs peuvent capturer l'exp\u00e9rience utilisateur collective pour les besoins d'information, et nos r\u00e9sultats soutiennent cette hypoth\u00e8se. Dans -LSB-19-RSB-, Wexelblat et Maes d\u00e9crivent un syst\u00e8me permettant de prendre en charge la navigation au sein d'un domaine bas\u00e9e sur les parcours de navigation d'autres utilisateurs. Cependant, nous ne savons pas si de tels principes sont appliqu\u00e9s \u00e0 la recherche sur le Web. L'instanciation la plus proche de la t\u00e9l\u00e9portation est peut-\u00eatre l'offre par les moteurs de recherche de plusieurs raccourcis au sein du domaine sous le titre d'un r\u00e9sultat de recherche. Bien que ceux-ci puissent \u00eatre bas\u00e9s sur le comportement de l'utilisateur et \u00e9ventuellement sur la structure du site, l'utilisateur enregistre au maximum un clic gr\u00e2ce \u00e0 cette fonctionnalit\u00e9. En revanche, l'approche propos\u00e9e peut transporter les utilisateurs vers des emplacements situ\u00e9s plusieurs fois au-del\u00e0 du r\u00e9sultat de la recherche, ce qui leur permet de gagner du temps et de leur donner une perspective plus large sur les informations associ\u00e9es disponibles. L'\u00e9tude men\u00e9e aupr\u00e8s des utilisateurs examine l'efficacit\u00e9 de l'inclusion de liens vers des destinations populaires en tant que fonctionnalit\u00e9 d'interface suppl\u00e9mentaire sur les pages de r\u00e9sultats des moteurs de recherche. Nous comparons deux variantes de cette approche \u00e0 la suggestion de requ\u00eates associ\u00e9es et de recherche Web non assist\u00e9e, et cherchons des r\u00e9ponses aux questions sur : -LRB- i -RRB- la pr\u00e9f\u00e9rence de l'utilisateur et l'efficacit\u00e9 de la recherche pour les t\u00e2ches de recherche d'\u00e9l\u00e9ments connus et exploratoires, et -LRB- ii -RRB- la distance pr\u00e9f\u00e9r\u00e9e entre la requ\u00eate et la destination utilis\u00e9e pour identifier les destinations populaires \u00e0 partir des journaux de comportement pass\u00e9s. Les r\u00e9sultats indiquent que sugg\u00e9rer des destinations populaires aux utilisateurs tentant des t\u00e2ches exploratoires fournit de meilleurs r\u00e9sultats dans des aspects cl\u00e9s de l'exp\u00e9rience de recherche d'informations, tandis que fournir des suggestions d'affinement des requ\u00eates est plus souhaitable pour les t\u00e2ches \u00e0 \u00e9l\u00e9ments connus. Dans la section 2, nous d\u00e9crivons l'extraction des pistes de recherche et de navigation \u00e0 partir des journaux d'activit\u00e9 des utilisateurs, et leur utilisation pour identifier les principales destinations pour les nouvelles requ\u00eates. La section 3 d\u00e9crit la conception de l'\u00e9tude sur les utilisateurs, tandis que les sections 4 et 5 pr\u00e9sentent respectivement les r\u00e9sultats de l'\u00e9tude et leur discussion. 6. CONCLUSIONS Nous avons pr\u00e9sent\u00e9 une nouvelle approche pour am\u00e9liorer l'interaction des utilisateurs dans la recherche sur le Web en fournissant des liens vers des sites Web fr\u00e9quemment visit\u00e9s par d'anciens chercheurs ayant des besoins d'information similaires. Une \u00e9tude utilisateur a \u00e9t\u00e9 men\u00e9e dans laquelle nous avons \u00e9valu\u00e9 l'efficacit\u00e9 de la technique propos\u00e9e par rapport \u00e0 un syst\u00e8me de raffinement des requ\u00eates et \u00e0 une recherche Web automatis\u00e9e. Les r\u00e9sultats de notre \u00e9tude ont r\u00e9v\u00e9l\u00e9 que\u00a0:Les syst\u00e8mes -LRB- i -RRB- sugg\u00e9rant des affinements de requ\u00eates ont \u00e9t\u00e9 pr\u00e9f\u00e9r\u00e9s pour les t\u00e2ches d'\u00e9l\u00e9ments connus, les syst\u00e8mes -LRB- ii -RRB- offrant des destinations populaires ont \u00e9t\u00e9 pr\u00e9f\u00e9r\u00e9s pour les t\u00e2ches de recherche exploratoire, et les destinations -LRB- iii -RRB- doivent \u00eatre extraites de la fin des pistes de requ\u00eates, pas les pistes de session. Dans l'ensemble, les suggestions de destinations populaires ont influenc\u00e9 strat\u00e9giquement les recherches d'une mani\u00e8re impossible \u00e0 r\u00e9aliser par les approches de suggestion de requ\u00eates en offrant une nouvelle fa\u00e7on de r\u00e9soudre les probl\u00e8mes d'information et en am\u00e9liorant l'exp\u00e9rience de recherche d'informations pour de nombreux chercheurs sur le Web.", "keyphrases": ["destin populaire", "recherche sur le Web interagir", "question d'improvisation", "r\u00e9cup\u00e9rer effectuer", "relative \u00e0 la question", "exp\u00e9rience d'information et de recherche", "sentier des requ\u00eates", "parcours de s\u00e9ance", "approche bas\u00e9e sur la recherche", "\u00e9valuation de base de journal"]}
{"file_name": "I-20", "text": "Calcul de l'indice de puissance de Banzhaf dans les jeux de flux r\u00e9seau R\u00c9SUM\u00c9 L'agr\u00e9gation des pr\u00e9f\u00e9rences est utilis\u00e9e dans diverses applications multi-agents et, par cons\u00e9quent, la th\u00e9orie du vote est devenue un sujet important dans la recherche sur les syst\u00e8mes multi-agents. Cependant, les indices de pouvoir -LRB- qui refl\u00e8tent le \u00ab pouvoir r\u00e9el \u00bb d'un \u00e9lecteur dans un syst\u00e8me de vote pond\u00e9r\u00e9 -RRB- ont re\u00e7u relativement peu d'attention, bien qu'ils aient \u00e9t\u00e9 \u00e9tudi\u00e9s depuis longtemps en sciences politiques et en \u00e9conomie. L'indice de pouvoir Banzhaf est l'un des plus populaires ; il est \u00e9galement bien d\u00e9fini pour tout jeu de coalition simple. Dans cet article, nous examinons la complexit\u00e9 informatique du calcul de l\u2019indice de puissance de Banzhaf dans un domaine multiagent particulier, un jeu de flux de r\u00e9seau. Les agents contr\u00f4lent les bords d'un graphique ; une coalition gagne si elle peut envoyer un flux d'une taille donn\u00e9e d'un sommet source \u00e0 un sommet cible. La puissance relative de chaque p\u00e9riph\u00e9rie/agent refl\u00e8te son importance pour permettre un tel flux et, dans les r\u00e9seaux du monde r\u00e9el, elle pourrait \u00eatre utilis\u00e9e, par exemple, pour allouer des ressources pour maintenir des parties du r\u00e9seau. Nous montrons que le calcul de l'indice de puissance Banzhaf de chaque agent dans ce domaine de flux r\u00e9seau est #P - complet. Nous montrons \u00e9galement que pour certains domaines de flux de r\u00e9seau restreints, il existe un algorithme polynomial pour calculer les indices de puissance de Banzhaf des agents. 1. INTRODUCTION Quelle est la complexit\u00e9 du processus ? La complexit\u00e9 peut-elle \u00eatre utilis\u00e9e pour se pr\u00e9munir contre des ph\u00e9nom\u00e8nes ind\u00e9sirables ? La complexit\u00e9 du calcul emp\u00eache-t-elle la mise en \u0153uvre r\u00e9aliste d\u2019une technique ? Les applications pratiques du vote parmi les agents automatis\u00e9s sont d\u00e9j\u00e0 largement r\u00e9pandues. En fait, pour voir la g\u00e9n\u00e9ralit\u00e9 du sc\u00e9nario de vote -LRB- automatis\u00e9 -RRB-, consid\u00e9rons la recherche moderne sur le Web. Dans cet article, nous consid\u00e9rons un sujet moins \u00e9tudi\u00e9 dans le context du vote automatis\u00e9 des agents, \u00e0 savoir les indices de pouvoir. Un indice de pouvoir est une mesure du pouvoir qu'un sous-groupe, ou de mani\u00e8re \u00e9quivalente un \u00e9lecteur dans un environnement de vote pond\u00e9r\u00e9, poss\u00e8de sur les d\u00e9cisions d'un groupe plus large. L\u2019indice de pouvoir de Banzhaf est l\u2019une des mesures les plus populaires du pouvoir de vote et, bien qu\u2019il ait \u00e9t\u00e9 principalement utilis\u00e9 pour mesurer le pouvoir dans les jeux de vote pond\u00e9r\u00e9s, il est bien d\u00e9fini pour tout jeu de coalition simple. Nous examinons certains aspects informatiques de l'indice de puissance de Banzhaf dans un environnement sp\u00e9cifique, \u00e0 savoir un jeu de flux en r\u00e9seau. Dans ce jeu, une coalition d\u2019agents gagne si elle peut envoyer un flux de taille k d\u2019un sommet source s \u00e0 un sommet cible t, la puissance relative de chaque ar\u00eate refl\u00e9tant son importance pour permettre un tel flux. Nous montrons que le calcul de l'indice de puissance Banzhaf de chaque agent dans ce domaine g\u00e9n\u00e9ral de flux de r\u00e9seau est #P - complet. Dans les jeux de nectivit\u00e9 sur graphes \u00e0 couches born\u00e9es -RRB-, il existe un algorithme polynomial pour calculer l'indice de puissance de Banzhaf d'un agent. Le document proc\u00e8de comme suit. Dans la section 2, nous donnons quelques informations g\u00e9n\u00e9rales sur les jeux de coalition et l'indice de pouvoir de Banzhaf, et dans la section 3, nous introduisons notre jeu de flux de r\u00e9seau sp\u00e9cifique.Dans la section 4, nous discutons de l'indice de puissance de Banzhaf dans les jeux de flux en r\u00e9seau, en pr\u00e9sentant notre r\u00e9sultat de complexit\u00e9 dans le cas g\u00e9n\u00e9ral. Dans la section 5, nous consid\u00e9rons un cas restreint du jeu de flux r\u00e9seau et pr\u00e9sentons les r\u00e9sultats. Dans la section 6, nous discutons des travaux connexes et nous concluons dans la section 7. 6. TRAVAUX CONNEXES La mesure de la puissance des joueurs individuels dans les jeux de coalition est \u00e9tudi\u00e9e depuis de nombreuses ann\u00e9es. Les indices les plus populaires sugg\u00e9r\u00e9s pour une telle mesure sont l'indice de Banzhaf -LSB- 1 -RSB- et l'indice de Shapley-Shubik -LSB- 19 -RSB-. Dans son article fondateur, Shapley -LSB-18-RSB- a examin\u00e9 les jeux de coalition et l'allocation \u00e9quitable de l'utilit\u00e9 acquise par la grande coalition -LRB-, la coalition de tous les agents -RRB- \u00e0 ses membres. L'indice de Shapley-Shubik -LSB- 19 -RSB- est l'application directe de la valeur de Shapley \u00e0 des jeux coalitionnels simples. L\u2019indice Banzhaf est directement issu de l\u2019\u00e9tude du vote dans les instances d\u00e9cisionnelles. L'indice Banzhaf normalis\u00e9 mesure la proportion de coalitions dans lesquelles un joueur est \u00e9changiste, parmi toutes les coalitions gagnantes. Cet indice est similaire \u00e0 l'indice de Banzhaf discut\u00e9 dans la section 1 et est d\u00e9fini comme\u00a0: L'indice de Banzhaf a \u00e9t\u00e9 analys\u00e9 math\u00e9matiquement dans -LSB- 3 -RSB-, o\u00f9 il a \u00e9t\u00e9 montr\u00e9 que cette normalisation manque de certaines propri\u00e9t\u00e9s souhaitables, et le Banzhaf plus naturel l'index est introduit. Les indices de Shapley-Shubik et de Banzhaf ont \u00e9t\u00e9 largement \u00e9tudi\u00e9s, et Straffin -LSB-20-RSB- a montr\u00e9 que chaque indice refl\u00e8te les conditions sp\u00e9cifiques d'un corps \u00e9lectoral. -LSB- 11 -RSB- consid\u00e8re ces deux indices avec plusieurs autres, et d\u00e9crit les axiomes qui caract\u00e9risent les diff\u00e9rents indices. L'impl\u00e9mentation na\u00efve d'un algorithme de calcul de l'indice de Banzhaf d'un agent i \u00e9num\u00e8re toutes les coalitions contenant i. Il existe 2n \u2212 1 de telles coalitions, donc la performance est exponentielle en nombre d\u2019agents. -LSB- 12 -RSB- contient une \u00e9tude des algorithmes permettant de calculer les indices de puissance des jeux \u00e0 majorit\u00e9 pond\u00e9r\u00e9e. Deng et Papadimitriou -LSB- 2 -RSB- montrent que le calcul de la valeur de Shapley dans les jeux \u00e0 majorit\u00e9 pond\u00e9r\u00e9e est #P - complet, en utilisant une r\u00e9duction de KNAPSACK. Puisque la valeur de Shapley de tout jeu simple a la m\u00eame valeur que son indice de Shapley-Shubik, cela montre que le calcul de l'indice de Shapley-Shubik dans les jeux \u00e0 majorit\u00e9 pond\u00e9r\u00e9e est #Pcomplete. Matsui et Matsui -LSB- 13 -RSB- ont montr\u00e9 que le calcul des indices Banzhaf et Shapley-Shubik dans les jeux de vote pond\u00e9r\u00e9s est NP-complet. Le probl\u00e8me des indices de puissance de calcul dans les jeux simples d\u00e9pend de la repr\u00e9sentation choisie du jeu. Puisque le nombre de coalitions possibles est exponentiel par rapport au nombre d\u2019agents, le calcul d\u2019indices de pouvoir en temps polynomial en nombre d\u2019agents ne peut \u00eatre r\u00e9alis\u00e9 que dans des domaines sp\u00e9cifiques. Dans cet article, nous avons consid\u00e9r\u00e9 le domaine des flux de r\u00e9seau, o\u00f9 une coalition d'agents doit atteindre un flux au-del\u00e0 d'une certaine valeur. Le jeu de flux r\u00e9seau que nous avons d\u00e9fini est un jeu simple. -LSB- 10,9 -RSB- ont consid\u00e9r\u00e9 un domaine de flux r\u00e9seau similaire, o\u00f9 chaque agent contr\u00f4le un bord d'un graphe de flux r\u00e9seau. Cependant, ils ont introduit un jeu non simple, dans lequel la valeur atteinte par une coalition d\u2019agents est le flux total maximal. Ils ont montr\u00e9 que certaines familles de jeux \u00e0 flux r\u00e9seau et jeux similaires poss\u00e8dent des c\u0153urs non vides. 7. CONCLUSIONS ET ORIENTATIONS FUTURES Nous avons consid\u00e9r\u00e9 des jeux de flux en r\u00e9seau, dans lesquels une coalition d'agents gagne si elle parvient \u00e0 envoyer un flux sup\u00e9rieur \u00e0 une certaine valeur k entre deux sommets. Nous avons \u00e9valu\u00e9 le pouvoir relatif de chaque agent dans ce sc\u00e9nario \u00e0 l\u2019aide de l\u2019indice Banzhaf. Cet indice de puissance peut \u00eatre utilis\u00e9 pour d\u00e9cider comment allouer les ressources de maintenance dans les r\u00e9seaux du monde r\u00e9el, afin de maximiser notre capacit\u00e9 \u00e0 maintenir un certain flux d'informations entre deux sites. Bien que l'indice de Banzhaf permette th\u00e9oriquement de mesurer la puissance des agents dans le jeu de flux r\u00e9seau, nous avons montr\u00e9 que le probl\u00e8me du calcul de l'indice de Banzhaf dans ce domaine en #P - complet. Malgr\u00e9 ce r\u00e9sultat d\u00e9courageant pour le domaine g\u00e9n\u00e9ral des flux r\u00e9seau, nous avons \u00e9galement fourni un r\u00e9sultat plus encourageant pour un domaine restreint. Dans le cas des jeux de connectivit\u00e9 -LRB- o\u00f9 il suffit qu'une coalition contienne un chemin de la source \u00e0 la destination -RRB- jou\u00e9 sur des graphes \u00e0 couches born\u00e9es, il est possible de calculer l'indice de Banzhaf d'un agent en temps polynomial . Trouver des moyens d'approcher de mani\u00e8re traitable l'indice de Banzhaf dans le domaine g\u00e9n\u00e9ral des flux de r\u00e9seau reste un probl\u00e8me ouvert. Il pourrait \u00e9galement \u00eatre possible de trouver d'autres domaines restreints utiles o\u00f9 il est possible de calculer exactement l'indice Banzhaf. Nous n'avons consid\u00e9r\u00e9 que la complexit\u00e9 du calcul de l'indice Banzhaf ; il reste un probl\u00e8me ouvert de trouver la complexit\u00e9 du calcul de Shapley-Shubik ou d'autres indices dans le domaine des flux de r\u00e9seau. Enfin, nous pensons qu\u2019il existe de nombreux autres domaines int\u00e9ressants autres que les jeux de vote pond\u00e9r\u00e9 et les jeux de flux de r\u00e9seau, et il serait int\u00e9ressant d\u2019\u00e9tudier la complexit\u00e9 du calcul de l\u2019indice de Banzhaf ou d\u2019autres indices de pouvoir dans ces domaines.nous avons montr\u00e9 que le probl\u00e8me du calcul de l'indice de Banzhaf dans ce domaine en #P - est termin\u00e9. Malgr\u00e9 ce r\u00e9sultat d\u00e9courageant pour le domaine g\u00e9n\u00e9ral des flux r\u00e9seau, nous avons \u00e9galement fourni un r\u00e9sultat plus encourageant pour un domaine restreint. Dans le cas des jeux de connectivit\u00e9 -LRB- o\u00f9 il suffit qu'une coalition contienne un chemin de la source \u00e0 la destination -RRB- jou\u00e9 sur des graphes \u00e0 couches born\u00e9es, il est possible de calculer l'indice de Banzhaf d'un agent en temps polynomial . Trouver des moyens d'approcher de mani\u00e8re traitable l'indice de Banzhaf dans le domaine g\u00e9n\u00e9ral des flux de r\u00e9seau reste un probl\u00e8me ouvert. Il pourrait \u00e9galement \u00eatre possible de trouver d'autres domaines restreints utiles o\u00f9 il est possible de calculer exactement l'indice Banzhaf. Nous n'avons consid\u00e9r\u00e9 que la complexit\u00e9 du calcul de l'indice Banzhaf ; il reste un probl\u00e8me ouvert de trouver la complexit\u00e9 du calcul de Shapley-Shubik ou d'autres indices dans le domaine des flux de r\u00e9seau. Enfin, nous pensons qu\u2019il existe de nombreux autres domaines int\u00e9ressants autres que les jeux de vote pond\u00e9r\u00e9 et les jeux de flux de r\u00e9seau, et il serait int\u00e9ressant d\u2019\u00e9tudier la complexit\u00e9 du calcul de l\u2019indice de Banzhaf ou d\u2019autres indices de pouvoir dans ces domaines.nous avons montr\u00e9 que le probl\u00e8me du calcul de l'indice de Banzhaf dans ce domaine en #P - est termin\u00e9. Malgr\u00e9 ce r\u00e9sultat d\u00e9courageant pour le domaine g\u00e9n\u00e9ral des flux r\u00e9seau, nous avons \u00e9galement fourni un r\u00e9sultat plus encourageant pour un domaine restreint. Dans le cas des jeux de connectivit\u00e9 -LRB- o\u00f9 il suffit qu'une coalition contienne un chemin de la source \u00e0 la destination -RRB- jou\u00e9 sur des graphes \u00e0 couches born\u00e9es, il est possible de calculer l'indice de Banzhaf d'un agent en temps polynomial . Trouver des moyens d'approcher de mani\u00e8re traitable l'indice de Banzhaf dans le domaine g\u00e9n\u00e9ral des flux de r\u00e9seau reste un probl\u00e8me ouvert. Il pourrait \u00e9galement \u00eatre possible de trouver d'autres domaines restreints utiles o\u00f9 il est possible de calculer exactement l'indice Banzhaf. Nous n'avons consid\u00e9r\u00e9 que la complexit\u00e9 du calcul de l'indice Banzhaf ; il reste un probl\u00e8me ouvert de trouver la complexit\u00e9 du calcul de Shapley-Shubik ou d'autres indices dans le domaine des flux de r\u00e9seau. Enfin, nous pensons qu\u2019il existe de nombreux autres domaines int\u00e9ressants autres que les jeux de vote pond\u00e9r\u00e9 et les jeux de flux de r\u00e9seau, et il serait int\u00e9ressant d\u2019\u00e9tudier la complexit\u00e9 du calcul de l\u2019indice de Banzhaf ou d\u2019autres indices de pouvoir dans ces domaines.", "keyphrases": ["pr\u00e9f\u00e9rer l'agr\u00e9gat", "application multiag", "th\u00e9orie du vote", "indice de puissance banzhaf", "analyse de l'algorithme et du probl\u00e8me complexe", "th\u00e9orie du choix social", "vote des agents automatiques", "jeu de flux de r\u00e9seau", "mod\u00e8le probabiliste", "connecter le jeu"]}
{"file_name": "J-7", "text": "Le r\u00f4le de la compatibilit\u00e9 dans la diffusion des technologies \u00e0 travers les r\u00e9seaux sociaux R\u00c9SUM\u00c9 Dans de nombreux contexts, des technologies concurrentes -- par exemple, les syst\u00e8mes d'exploitation, les syst\u00e8mes de messagerie instantan\u00e9e ou les formats de documents -- peuvent adopter un degr\u00e9 limit\u00e9 de compatibilit\u00e9 les unes avec les autres ; en d\u2019autres termes, la difficult\u00e9 d\u2019utiliser plusieurs technologies se situe quelque part entre les deux extr\u00eames de l\u2019impossibilit\u00e9 et de l\u2019interop\u00e9rabilit\u00e9 sans effort. Il existe toute une s\u00e9rie de raisons pour lesquelles ce ph\u00e9nom\u00e8ne se produit, dont beaucoup \u2013 fond\u00e9es sur des consid\u00e9rations juridiques, sociales ou commerciales \u2013 semblent d\u00e9fier les mod\u00e8les math\u00e9matiques concis. Malgr\u00e9 cela, nous montrons que les avantages d\u2019une compatibilit\u00e9 limit\u00e9e peuvent appara\u00eetre dans un mod\u00e8le tr\u00e8s simple de diffusion dans les r\u00e9seaux sociaux, offrant ainsi une explication fondamentale de ce ph\u00e9nom\u00e8ne en termes purement strat\u00e9giques. Notre approche s'appuie sur des travaux sur la diffusion des innovations dans la litt\u00e9rature \u00e9conomique, qui cherchent \u00e0 mod\u00e9liser la fa\u00e7on dont une nouvelle technologie A pourrait se propager \u00e0 travers un r\u00e9seau social d'individus qui sont actuellement utilisateurs de la technologie B. Nous envisageons plusieurs mani\u00e8res de capturer la compatibilit\u00e9 de A. et B, en se concentrant principalement sur un mod\u00e8le dans lequel les utilisateurs peuvent choisir d'adopter A, d'adopter B ou -- moyennant un co\u00fbt suppl\u00e9mentaire -- d'adopter \u00e0 la fois A et B. Nous caract\u00e9risons comment la capacit\u00e9 de A \u00e0 se propager d\u00e9pend \u00e0 la fois de sa qualit\u00e9 relative \u00e0 B, ainsi que ce co\u00fbt suppl\u00e9mentaire li\u00e9 \u00e0 l'adoption des deux, et trouvent des propri\u00e9t\u00e9s surprenantes de non-monotonicit\u00e9 dans la d\u00e9pendance \u00e0 l'\u00e9gard de ces param\u00e8tres : dans certains cas, pour qu'une technologie survive \u00e0 l'introduction d'une autre, le co\u00fbt de l'adoption des deux technologies doit \u00eatre \u00e9quilibr\u00e9 dans une fourchette \u00e9troite et interm\u00e9diaire. Nous \u00e9tendons \u00e9galement le cadre au cas de technologies multiples, o\u00f9 nous constatons qu'un simple Ce travail a \u00e9t\u00e9 soutenu en partie par les subventions NSF CCF0325453, IIS-0329064, CNS-0403340 et BCS-0537606, une subvention de recherche Google, une subvention Yahoo ! Research Alliance Grant, l'Institut des sciences sociales de Cornell et la Fondation John D. et Catherine T. MacArthur. Le mod\u00e8le capture le ph\u00e9nom\u00e8ne de deux entreprises adoptant une \u00ab alliance strat\u00e9gique \u00bb limit\u00e9e pour se d\u00e9fendre contre une nouvelle troisi\u00e8me technologie. 1. INTRODUCTION Jeux de diffusion et de coordination en r\u00e9seau. De tels probl\u00e8mes se posent, par exemple, lors de l'adoption de nouvelles technologies, de l'\u00e9mergence de nouvelles normes sociales ou conventions organisationnelles, ou de la diffusion des langages humains -LSB- 2, 14, 15, 16, 17 -RSB-. Une ligne de recherche active en \u00e9conomie et en sociologie math\u00e9matique s'int\u00e9resse \u00e0 la mod\u00e9lisation de ces types de processus de diffusion comme un jeu de coordination jou\u00e9 sur un r\u00e9seau social -LSB- 1, 5, 7, 13, 19 -RSB-. Nous commen\u00e7ons par discuter de l'un des mod\u00e8les de diffusion de la th\u00e9orie des jeux les plus fondamentaux, propos\u00e9 dans un article influent de Morris -LSB-13-RSB-, qui constituera le point de d\u00e9part de notre travail ici. Nous le d\u00e9crivons en termes du sc\u00e9nario d\u2019adoption technologique suivant, bien qu\u2019il existe de nombreux autres exemples qui pourraient servir le m\u00eame objectif.Notez que A est la \u00ab meilleure \u00bb technologie si q < 21, dans le sens o\u00f9 les gains AA d\u00e9passeraient alors les gains BB, tandis que A est la pire technologie si q > 21. Un certain nombre d'informations qualitatives peuvent \u00eatre d\u00e9riv\u00e9es d'une analyse de diffusion. mod\u00e8le m\u00eame \u00e0 ce niveau de simplicit\u00e9. Plus pr\u00e9cis\u00e9ment, consid\u00e9rons un r\u00e9seau G et laissez tous les n\u0153uds jouer initialement B. Supposons maintenant qu'un petit nombre de n\u0153uds commencent \u00e0 adopter la strat\u00e9gie A \u00e0 la place. Compatibilit\u00e9, interop\u00e9rabilit\u00e9 et bilinguisme. Cependant, un \u00e9l\u00e9ment important qui manque sans doute dans les mod\u00e8les de diffusion de base de la th\u00e9orie des jeux est une image plus d\u00e9taill\u00e9e de ce qui se passe \u00e0 la fronti\u00e8re de coexistence, o\u00f9 la forme de base du mod\u00e8le postule que les n\u0153uds qui adoptent A sont li\u00e9s aux n\u0153uds qui adoptent A. B. Dans ces contexts motivants pour les mod\u00e8les, on voit bien s\u00fbr tr\u00e8s souvent des r\u00e9gions d'interface dans lesquelles les individus deviennent essentiellement \u00ab bilingues \u00bb. \u00ab Dans le cas de la diffusion des langues humaines, cette bilinguisme s'entend litt\u00e9ralement : les r\u00e9gions g\u00e9ographiques o\u00f9 il y a une interaction substantielle avec des locuteurs de deux langues diff\u00e9rentes ont tendance \u00e0 avoir des habitants qui parlent les deux. Dans cette perspective, il est naturel de se demander comment les mod\u00e8les de diffusion se comportent lorsqu\u2019ils sont \u00e9tendus pour que certains n\u0153uds puissent \u00eatre bilingues dans ce sens tr\u00e8s g\u00e9n\u00e9ral, adoptant les deux strat\u00e9gies \u00e0 un certain prix pour eux-m\u00eames. Que pourrions-nous apprendre d\u2019une telle extension ? Tout d\u2019abord, elle a le potentiel de fournir une perspective pr\u00e9cieuse sur la question de la compatibilit\u00e9 et de l\u2019incompatibilit\u00e9 qui sous-tend la concurrence entre les entreprises technologiques. Il existe une abondante litt\u00e9rature sur la mani\u00e8re dont la compatibilit\u00e9 entre technologies affecte la concurrence entre entreprises, et en particulier sur la mani\u00e8re dont l'incompatibilit\u00e9 peut \u00eatre une d\u00e9cision strat\u00e9gique b\u00e9n\u00e9fique pour certains acteurs d'un march\u00e9 -LSB- 3, 4, 8, 9, 12 -RSB-. Bien que ces mod\u00e8les de compatibilit\u00e9 existants capturent les effets de r\u00e9seau dans le sens o\u00f9 les utilisateurs du march\u00e9 pr\u00e9f\u00e8rent utiliser une technologie plus r\u00e9pandue, ils ne capturent pas le ph\u00e9nom\u00e8ne de r\u00e9seau plus fin repr\u00e9sent\u00e9 par la diffusion - dans lequel chaque utilisateur inclut sa vision locale dans la d\u00e9cision, bas\u00e9e sur ce que font ses propres voisins des r\u00e9seaux sociaux. Un mod\u00e8le de diffusion int\u00e9grant de telles extensions pourrait donner un aper\u00e7u de la structure des fronti\u00e8res du r\u00e9seau entre les technologies ; cela pourrait potentiellement offrir une base th\u00e9orique des graphes sur la mani\u00e8re dont l'incompatibilit\u00e9 peut b\u00e9n\u00e9ficier \u00e0 une technologie existante, en renfor\u00e7ant ces fronti\u00e8res et en emp\u00eachant l'incursion d'une nouvelle technologie meilleure. Le pr\u00e9sent travail : Diffusion avec comportement bilingue. Dans cet article, nous d\u00e9veloppons un ensemble de mod\u00e8les de diffusion qui int\u00e8grent les notions de compatibilit\u00e9 et de bilinguisme, et nous constatons que certains ph\u00e9nom\u00e8nes inattendus \u00e9mergent m\u00eame \u00e0 partir de versions tr\u00e8s simples des mod\u00e8les. Nous commen\u00e7ons par la mani\u00e8re peut-\u00eatre la plus simple d'\u00e9tendre le mod\u00e8le de Morris \u00e9voqu\u00e9 ci-dessus pour incorporer le comportement bilingue. Prenons \u00e0 nouveau l'exemple des syst\u00e8mes de messagerie instantan\u00e9e A et B, avec la structure de paiement comme pr\u00e9c\u00e9demment,mais supposons maintenant que chaque n\u0153ud puisse adopter une troisi\u00e8me strat\u00e9gie, not\u00e9e AB, dans laquelle il d\u00e9cide d'utiliser \u00e0 la fois A et B. Enfin, celui qui adopte AB paie une p\u00e9nalit\u00e9 de co\u00fbt fixe de c -LRB-, c'est-\u00e0-dire -- c est ajout\u00e9 \u00e0 son gain total -RRB- pour repr\u00e9senter le co\u00fbt de la maintenance des deux technologies. Ainsi, dans ce mod\u00e8le, il y a deux param\u00e8tres que l'on peut faire varier : les qualit\u00e9s relatives des deux technologies -LRB- cod\u00e9es par q -RRB-, et le co\u00fbt du bilinguisme, qui refl\u00e8te un type d'incompatibilit\u00e9 -LRB- cod\u00e9 par q -RRB-. c -RRB-. Nous introduisons \u00e9galement un bit de notation suppl\u00e9mentaire qui sera utile dans les sections suivantes : nous d\u00e9finissons r = c / \u0394, la p\u00e9nalit\u00e9 fixe pour l'adoption de AB, mise \u00e0 l'\u00e9chelle de mani\u00e8re \u00e0 ce qu'il s'agisse d'un co\u00fbt par ar\u00eate. Dans le mod\u00e8le de Morris, o\u00f9 les seules options strat\u00e9giques sont A et B, un param\u00e8tre cl\u00e9 est le seuil de contagion de G, not\u00e9 q \u2217 -LRB- G -RRB- : c'est le supremum de q pour lequel A peut devenir \u00e9pid\u00e9mique dans G avec le param\u00e8tre q dans la structure de paiement. Un r\u00e9sultat central de -LSB- 13 -RSB- est que 21 est le seuil de contagion maximum possible pour tout graphe : supG q \u2217 -LRB- G -RRB- = 21. En effet, il existe des graphes dans lesquels le seuil de contagion est aussi grand que comme 21 -LRB- incluant la ligne infinie -- l'unique graphe 2-r\u00e9gulier connect\u00e9 infini -RRB- ; en revanche, on peut montrer qu'il n'existe aucun graphe avec un seuil de contagion sup\u00e9rieur \u00e0 Figure 1 : La r\u00e9gion du plan -LRB- q, r -RRB- pour laquelle la technologie A peut devenir \u00e9pid\u00e9mique sur la ligne infinie. Nos r\u00e9sultats. -LRB- On retrouve des formes analogues qui deviennent encore plus complexes pour d'autres structures de graphes infinis simples ; voir par exemple les figures 3 et 4. -RRB- En particulier, cela signifie que pour des valeurs de q proches mais inf\u00e9rieures \u00e0 21, la strat\u00e9gie A peut devenir \u00e9pid\u00e9mique sur la ligne infinie si r est suffisamment petit ou suffisamment grand, mais pas si r prend des valeurs dans un intervalle interm\u00e9diaire. En d\u2019autres termes, la strat\u00e9gie B -LRB- qui repr\u00e9sente la pire technologie, puisque q < 21 -RRB- survivra si et seulement si le co\u00fbt du bilinguisme est calibr\u00e9 pour se situer dans cet intervalle m\u00e9dian. Cela refl\u00e8te une compatibilit\u00e9 limit\u00e9e -- il peut \u00eatre dans l'int\u00e9r\u00eat d'une technologie en place de rendre difficile, mais pas trop difficile, l'utilisation d'une nouvelle technologie -- et nous trouvons surprenant qu'elle \u00e9merge d'un mod\u00e8le de base sur une telle une structure de r\u00e9seau simple. Il est naturel de se demander s\u2019il existe une interpr\u00e9tation qualitative de la fa\u00e7on dont cela d\u00e9coule du mod\u00e8le, et en fait il n\u2019est pas difficile de donner une telle interpr\u00e9tation, comme suit. Lorsque r est tr\u00e8s petit, il est peu co\u00fbteux pour les n\u0153uds d\u2019adopter AB comme strat\u00e9gie, et AB se propage donc \u00e0 travers l\u2019ensemble du r\u00e9seau. Une fois que AB est partout, les mises \u00e0 jour offrant la meilleure r\u00e9ponse font basculer tous les n\u0153uds vers A, car ils b\u00e9n\u00e9ficient des m\u00eames avantages d'interaction sans payer la p\u00e9nalit\u00e9 de r. Lorsque r est tr\u00e8s grand, les n\u0153uds \u00e0 l'interface, avec un voisin A et un voisin B, trouveront trop co\u00fbteux de choisir AB, ils choisiront donc A -LRB- la meilleure technologie -RRB-,et donc A se propagera \u00e9tape par \u00e9tape \u00e0 travers le r\u00e9seau. Lorsque r prend une valeur interm\u00e9diaire, un n\u0153ud v \u00e0 l\u2019interface, avec un voisin A et un voisin B, trouvera plus avantageux d\u2019adopter AB comme strat\u00e9gie. Par cons\u00e9quent, cette valeur interm\u00e9diaire de r permet \u00e0 une \u00ab fronti\u00e8re \u00bb de AB de se former entre les adoptants de A et les adoptants de B. Mais si elle a le bon \u00e9quilibre dans la valeur de r, alors les adoptions de A aboutissent \u00e0 un arr\u00eatez-vous \u00e0 une fronti\u00e8re bilingue o\u00f9 les n\u0153uds adoptent AB. Au-del\u00e0 des graphiques G sp\u00e9cifiques, nous constatons que cette non-convexit\u00e9 se v\u00e9rifie \u00e9galement dans un sens beaucoup plus g\u00e9n\u00e9ral, en consid\u00e9rant la r\u00e9gion \u00e9pid\u00e9mique g\u00e9n\u00e9rale \u03a9 = UG\u03a9 -LRB- G -RRB-. Pour toute valeur donn\u00e9e de \u0394, la r\u00e9gion \u03a9 est une union compliqu\u00e9e de polygones limit\u00e9s et non limit\u00e9s, et nous n\u2019avons pas de description simple et ferm\u00e9e pour cela. Cependant, nous pouvons montrer via un argument de fonction potentielle qu'aucun point -LRB- q, r -RRB- avec q > 21 n'appartient \u00e0 \u03a9. De plus, on peut montrer l'existence d'un point -LRB- q, r -RRB- E ~ \u03a9 pour lequel q < 21. En revanche, la consid\u00e9ration de la r\u00e9gion \u00e9pid\u00e9mique pour la droite infinie montre que -LRB- 21, r -RRB- E \u03a9 pour r = 0 et pour r suffisamment grand. Par cons\u00e9quent, ni \u03a9 ni son compl\u00e9mentaire ne sont convexes dans le quadrant positif. Enfin, nous \u00e9tendons \u00e9galement une caract\u00e9risation donn\u00e9e par Morris pour le seuil de contagion -LSB- 13 -RSB-, produisant une caract\u00e9risation un peu plus complexe de la r\u00e9gion \u03a9 -LRB- G -RRB-. Dans le cadre de Morris, sans strat\u00e9gie AB, il a montr\u00e9 que A ne peut pas devenir \u00e9pid\u00e9mique avec le param\u00e8tre q si et seulement si chaque ensemble cofini de n\u0153uds contient un sous-ensemble S qui fonctionne comme une \u00ab communaut\u00e9 \u00bb bien connect\u00e9e : chaque n\u0153ud dans S a au moins une fraction -LRB- 1 -- q -RRB- de ses voisins dans S. En d'autres termes, les communaut\u00e9s \u00e9troitement li\u00e9es sont les obstacles naturels \u00e0 la diffusion dans son environnement. Avec la strat\u00e9gie AB comme option suppl\u00e9mentaire, une structure plus complexe devient l'obstacle : nous montrons que A ne peut pas devenir \u00e9pid\u00e9mique avec les param\u00e8tres -LRB- q, r -RRB- si et seulement si chaque ensemble cofini contient une structure constitu\u00e9e d'un ensemble \u00e9troitement -communaut\u00e9 tricot\u00e9e avec un type particulier d'\"interface\" de n\u0153uds voisins. Nous montrons qu'une telle structure permet aux n\u0153uds d'adopter AB \u00e0 l'interface et B \u00e0 l'int\u00e9rieur de la communaut\u00e9 elle-m\u00eame, emp\u00eachant ainsi la propagation de A ; et inversement, c\u2019est le seul moyen de bloquer la propagation de A. Extensions suppl\u00e9mentaires. Une autre fa\u00e7on de mod\u00e9liser la compatibilit\u00e9 et l'interop\u00e9rabilit\u00e9 dans les mod\u00e8les de diffusion consiste \u00e0 utiliser les termes \u00ab hors diagonale \u00bb repr\u00e9sentant le gain pour les interactions entre un n\u0153ud adoptant A et un n\u0153ud adoptant B. Plut\u00f4t que de les d\u00e9finir sur 0, nous pouvons envisager de les d\u00e9finir sur une valeur x < min -LRB- q, 1 -- q -RRB-. Nous constatons que pour le cas de deux technologies, le mod\u00e8le ne devient pas plus g\u00e9n\u00e9ral, dans la mesure o\u00f9 tout cas de ce type est \u00e9quivalent, par une nouvelle \u00e9chelle de q et r, \u00e0 celui o\u00f9 x = 0. De plus,en utilisant notre caract\u00e9risation de la r\u00e9gion \u03a9 -LRB- G -RRB- en termes de communaut\u00e9s et d'interfaces, nous montrons un r\u00e9sultat de monotonie : si A peut devenir \u00e9pid\u00e9mique sur un graphe G de param\u00e8tres -LRB- q, r, x -RRB-, et puis x est augment\u00e9, alors A peut encore devenir \u00e9pid\u00e9mique avec les nouveaux param\u00e8tres. Nous consid\u00e9rons \u00e9galement l'effet de ces termes hors diagonale dans une extension \u00e0 k > 2 technologies concurrentes ; pour les technologies X et Y, soit qX d\u00e9signe le gain d'une interaction XX sur un bord et qXY d\u00e9signe le gain d'une interaction XY sur un bord. Nous consid\u00e9rons un context dans lequel deux technologies B et C, qui coexistent initialement avec qBC = 0, sont confront\u00e9es \u00e0 l\u2019introduction d\u2019une troisi\u00e8me technologie A, meilleure, au niveau d\u2019un ensemble fini de n\u0153uds. Nous montrons un exemple dans lequel B et C survivent tous deux \u00e0 l'\u00e9quilibre s'ils fixent qBC dans une plage de valeurs particuli\u00e8re, mais pas s'ils fixent qBC trop bas ou trop haut pour se situer dans cette plage. Ainsi, m\u00eame dans un mod\u00e8le de diffusion de base comportant trois technologies, on trouve des cas dans lesquels deux entreprises sont incit\u00e9es \u00e0 adopter une \u00ab\u00a0alliance strat\u00e9gique\u00a0\u00bb limit\u00e9e, augmentant partiellement leur interop\u00e9rabilit\u00e9 pour se d\u00e9fendre contre un nouvel entrant sur le march\u00e9. 6. COMPATIBILIT\u00c9 LIMIT\u00c9E Nous examinons maintenant d'autres moyens de mod\u00e9liser la compatibilit\u00e9 et l'interop\u00e9rabilit\u00e9. Nous consid\u00e9rons d'abord deux technologies, comme dans les sections pr\u00e9c\u00e9dentes, et introduisons des gains \u00ab hors diagonale \u00bb pour capturer un b\u00e9n\u00e9fice positif dans les interactions AB directes. Nous constatons que ce n\u2019est en fait pas plus g\u00e9n\u00e9ral que le mod\u00e8le avec des gains nuls pour les interactions AB. Nous envisageons ensuite des extensions \u00e0 trois technologies, en identifiant les situations dans lesquelles deux technologies historiques coexistantes peuvent ou non vouloir accro\u00eetre leur compatibilit\u00e9 mutuelle face \u00e0 une nouvelle troisi\u00e8me technologie. Deux technologies. Un assouplissement naturel du mod\u00e8le \u00e0 deux technologies consiste \u00e0 introduire des gains positifs -LRB-petits-RRB- pour l'interaction AB ; c\u2019est-\u00e0-dire que la communication inter-technologique apporte une valeur moindre aux deux agents. Nous pouvons mod\u00e9liser cela en utilisant une variable xAB repr\u00e9sentant le gain collect\u00e9 par un agent avec la technologie A lorsque son voisin a la technologie B, et de m\u00eame, une variable xBA repr\u00e9sentant le gain collect\u00e9 par un agent avec B lorsque son voisin a la technologie A. Nous consid\u00e9rons ici le cas particulier dans lequel ces entr\u00e9es \u00ab hors diagonale \u00bb sont sym\u00e9triques, c'est-\u00e0-dire xAB = xBA = x. Nous supposons \u00e9galement que x < q < 1 -- q. Nous montrons d\u2019abord que le jeu avec des entr\u00e9es hors diagonale est \u00e9quivalent \u00e0 un jeu sans ces entr\u00e9es, sous une simple remise \u00e0 l\u2019\u00e9chelle de q et r. Notez que si nous redimensionnons tous les gains par une constante additive ou multiplicative, le comportement du jeu n'est pas affect\u00e9. \u00c9tant donn\u00e9 un jeu avec des entr\u00e9es hors diagonale param\u00e9tr\u00e9es par q, r et x, envisagez de soustraire x de tous les gains et d'augmenter par un facteur de 1 / -LRB- 1 -- 2x -RRB-. Comme on peut le constater en examinant le tableau 1, les gains qui en r\u00e9sultent sont exactement ceux d'un jeu sans entr\u00e9es hors diagonale,param\u00e9tr\u00e9 par q' = -LRB- q -- x -RRB- / -LRB- 1 -- 2x -RRB- et r' = r / -LRB- 1 -- 2x -RRB-. Ainsi, l\u2019ajout d\u2019entr\u00e9es sym\u00e9triques hors diagonale n\u2019\u00e9largit pas la classe de jeux consid\u00e9r\u00e9e. Le tableau 1 repr\u00e9sente les gains du jeu de coordination en termes de ces param\u00e8tres. N\u00e9anmoins, nous pouvons toujours nous demander comment l\u2019ajout d\u2019une entr\u00e9e hors diagonale pourrait affecter le r\u00e9sultat d\u2019un jeu particulier. Comme le montre l\u2019exemple suivant, une compatibilit\u00e9 croissante entre deux technologies peut permettre \u00e0 une technologie qui n\u2019\u00e9tait pas initialement \u00e9pid\u00e9mique de le devenir. EXEMPLE 6.1. Consid\u00e9rons le jeu de contagion jou\u00e9 sur un graphique \u00e0 lignes \u00e9paisses -LRB- voir Section 3 -RRB- avec r = 5/32 et q = 3/8. Dans ce cas, A n\u2019est pas \u00e9pid\u00e9mique, comme le montre la figure 1, puisque 2r < q et q + r > 1/2. Cependant, si nous ins\u00e9rons des gains sym\u00e9triques hors diagonale x = 1/4, nous avons un nouveau jeu, \u00e9quivalent \u00e0 un jeu param\u00e9tr\u00e9 par r ' = 5/16 et q ' = 1/4. Puisque q ' < 1/2 et q ' < 2r ', A est \u00e9pid\u00e9mique dans ce jeu, et donc aussi dans le jeu \u00e0 compatibilit\u00e9 limit\u00e9e. Nous montrons maintenant que g\u00e9n\u00e9ralement, si A est la technologie sup\u00e9rieure -LRB- c'est-\u00e0-dire q < 1/2 -RRB-, l'ajout d'un terme de compatibilit\u00e9 x ne peut qu'aider A \u00e0 se propager. TH\u00c9OR\u00c8ME 6.2. Soit G un jeu sans compatibilit\u00e9, param\u00e9tr\u00e9 par r et q sur un r\u00e9seau particulier. Soit G ' le m\u00eame jeu, mais avec un terme de compatibilit\u00e9 sym\u00e9trique ajout\u00e9 x. Si A est \u00e9pid\u00e9mique pour G, alors A est \u00e9pid\u00e9mique pour G'. PREUVE. Nous allons montrer que toute structure bloquante dans G' est aussi une structure bloquante dans G. D'apr\u00e8s notre th\u00e9or\u00e8me de caract\u00e9risation, le th\u00e9or\u00e8me 4.6, cela implique le r\u00e9sultat souhait\u00e9. On a que G' est \u00e9quivalent \u00e0 un jeu sans compatibilit\u00e9 param\u00e9tr\u00e9 par q' = -LRB- q -- x -RRB- / -LRB- 1 -- 2x -RRB- et r' = r / -LRB- 1 -- 2x -RRB-. Consid\u00e9rons une structure bloquante -LRB- SB, SAB -RRB- pour G'. Donc plus de deux technologies. Compte tenu de la structure complexe inh\u00e9rente aux jeux de contagion \u00e0 deux technologies, la compr\u00e9hension des jeux de contagion \u00e0 trois technologies ou plus est largement ouverte. Nous indiquons ici certains des probl\u00e8mes techniques qui surviennent avec plusieurs technologies, \u00e0 travers une s\u00e9rie de premiers r\u00e9sultats. La configuration de base que nous \u00e9tudions est celle dans laquelle deux technologies existantes B et C coexistent initialement, et une troisi\u00e8me technologie A, sup\u00e9rieure aux deux, est introduite initialement au niveau d\u2019un ensemble fini de n\u0153uds. Nous pr\u00e9sentons d'abord un th\u00e9or\u00e8me affirmant que pour tout \u0394 pair, il existe un jeu de contagion sur un \u0394 -- graphe r\u00e9gulier dans lequel les deux technologies en place, B et C, pourraient trouver avantageux d'augmenter leur compatibilit\u00e9 afin d'\u00e9viter d'\u00eatre an\u00e9anties par le nouvelle technologie sup\u00e9rieure A. En particulier, nous consid\u00e9rons une situation dans laquelle initialement, deux technologies B et C avec une compatibilit\u00e9 nulle sont dans un \u00e9tat stable. Par \u00e9tat stable, nous entendons qu'aucune perturbation finie des \u00e9tats actuels ne peut conduire \u00e0 une \u00e9pid\u00e9mie pour B ou C. Nous avons \u00e9galement une technologie A qui est sup\u00e9rieure \u00e0 la fois \u00e0 B et \u00e0 C,et peut devenir \u00e9pid\u00e9mique en for\u00e7ant un seul n\u0153ud \u00e0 choisir A. Cependant, en augmentant leur compatibilit\u00e9, B et C peuvent maintenir leur stabilit\u00e9 et r\u00e9sister \u00e0 une \u00e9pid\u00e9mie de A. Soit qA d\u00e9signant les gains pour deux n\u0153uds adjacents qui choisissent tous deux la technologie A, et d\u00e9finir qB et qC de mani\u00e8re analogue. Nous supposerons qA > qB > qC. Nous supposons \u00e9galement que r, le co\u00fbt de s\u00e9lection de technologies suppl\u00e9mentaires, est suffisamment \u00e9lev\u00e9 pour garantir que les n\u0153uds n'adoptent jamais plus d'une technologie. Enfin, nous consid\u00e9rons un param\u00e8tre de compatibilit\u00e9 qBC qui repr\u00e9sente les gains de deux n\u0153uds adjacents lorsque l'un s\u00e9lectionne B et l'autre s\u00e9lectionne C. Ainsi notre jeu de contagion est maintenant d\u00e9crit par cinq param\u00e8tres -LRB- G, qA, qB, qC, qBC -RRB. -. PREUVE. -LRB- Croquis. -RRB- \u00c9tant donn\u00e9 \u0394, d\u00e9finissez G en commen\u00e7ant par une grille infinie et en connectant chaque n\u0153ud \u00e0 son \u0394 le plus proche -- 2 voisins qui sont dans la m\u00eame rang\u00e9e. L'\u00e9tat initial s attribue la strat\u00e9gie B aux lignes paires et la strat\u00e9gie C aux lignes impaires. Les premi\u00e8re, troisi\u00e8me et quatri\u00e8me affirmations du th\u00e9or\u00e8me peuvent \u00eatre v\u00e9rifi\u00e9es en v\u00e9rifiant les in\u00e9galit\u00e9s correspondantes. La deuxi\u00e8me affirmation d\u00e9coule de la premi\u00e8re et de l\u2019observation selon laquelle les rang\u00e9es altern\u00e9es contiennent toute \u00e9pid\u00e9mie plausible provenant d\u2019une croissance verticale. Le th\u00e9or\u00e8me ci-dessus montre que deux technologies peuvent toutes deux \u00eatre capables de survivre \u00e0 l\u2019introduction d\u2019une nouvelle technologie en augmentant leur niveau de compatibilit\u00e9 l\u2019une avec l\u2019autre. Comme on pouvait s'y attendre, Tableau 1 : Les gains dans le jeu de coordination. L'entr\u00e9e -LRB- x, y -RRB- dans la ligne i, colonne j indique que le joueur de ligne obtient un gain de x et que le joueur de colonne obtient un gain de y lorsque le joueur de ligne joue la strat\u00e9gie i et que le joueur de colonne joue la strat\u00e9gie j. il existe des cas o\u00f9 une compatibilit\u00e9 accrue entre deux technologies favorise l\u2019une au d\u00e9triment de l\u2019autre. Il est toutefois surprenant de constater qu\u2019il existe \u00e9galement des cas dans lesquels la compatibilit\u00e9 est en fait pr\u00e9judiciable aux deux parties ; l'exemple suivant consid\u00e8re une configuration initiale fixe avec les technologies A, B et C qui est \u00e0 l'\u00e9quilibre lorsque qBC = 0. Cependant, si ce terme de compatibilit\u00e9 est suffisamment augment\u00e9, l'\u00e9quilibre est perdu et A devient \u00e9pid\u00e9mique. EXEMPLE 6.4. Consid\u00e9rons l'union d'un graphe quadrill\u00e9 bidimensionnel infini avec des n\u0153uds u -LRB- x, y -RRB- et un graphe lin\u00e9aire infini avec des n\u0153uds v -LRB- y -RRB-. Ajoutez une ar\u00eate entre u -LRB- 1, y -RRB- et v -LRB- y -RRB- pour tout y. Pour ce r\u00e9seau, nous consid\u00e9rons la configuration initiale dans laquelle tous les n\u0153uds v -LRB- y -RRB- s\u00e9lectionnent A, et le n\u0153ud u -LRB- x, y -RRB- s\u00e9lectionne B si x < 0 et s\u00e9lectionne C sinon. Nous d\u00e9finissons maintenant les param\u00e8tres de ce jeu comme suit. On v\u00e9rifie facilement que pour ces valeurs, la configuration initiale donn\u00e9e ci-dessus est un \u00e9quilibre. Cependant, supposons maintenant que nous augmentions le terme de coordination, en d\u00e9finissant qBC = 0,9. Ce n'est pas un \u00e9quilibre, puisque chaque n\u0153ud de la forme u -LRB- 0, y -RRB- est d\u00e9sormais incit\u00e9 \u00e0 passer de C -LRB- g\u00e9n\u00e9rant un gain de 3,9 -RRB- \u00e0 B -LRB- g\u00e9n\u00e9rant ainsi un gain de 3,95 -RRB-. Cependant,une fois que ces n\u0153uds ont adopt\u00e9 B, la meilleure r\u00e9ponse pour chaque n\u0153ud de la forme u -LRB- 1, y -RRB- est A -LRB- A g\u00e9n\u00e8re un gain de 4 alors que B ne g\u00e9n\u00e8re qu'un gain de 3,95 -RRB- . \u00c0 partir de l\u00e0, il n\u2019est pas difficile de montrer que A se propage directement dans l\u2019ensemble du r\u00e9seau.", "keyphrases": ["processus diffus", "mod\u00e8le diffus de la th\u00e9orie des jeux", "strat\u00e9gie incompatible", "bilingue", "limite de compatibilit\u00e9", "interop\u00e9rer", "propri\u00e9t\u00e9s non convexes", "personnage", "th\u00e9or\u00e8me de Morri", "seuil de contagion", "jeu de contagion", "fonction de potentiel"]}
{"file_name": "I-34", "text": "R\u00e9soudre les conflits et les incoh\u00e9rences dans les organisations virtuelles r\u00e9glement\u00e9es par des normes R\u00c9SUM\u00c9 Les organisations virtuelles r\u00e9gies par des normes d\u00e9finissent, gouvernent et facilitent le partage coordonn\u00e9 des ressources et la r\u00e9solution de probl\u00e8mes dans les soci\u00e9t\u00e9s d'agents. Avec une explication explicite des normes, l'ouverture dans les organisations virtuelles peut \u00eatre atteinte : de nouveaux composants, con\u00e7us par diverses parties, peuvent \u00eatre int\u00e9gr\u00e9s de mani\u00e8re transparente. Nous nous concentrons sur les organisations virtuelles r\u00e9alis\u00e9es sous forme de syst\u00e8mes multi-agents, dans lesquels les agents humains et logiciels interagissent pour atteindre des objectifs individuels et globaux. Cependant, toute explication r\u00e9aliste des normes doit tenir compte de leur nature dynamique : les normes changeront \u00e0 mesure que les agents interagissent les uns avec les autres et avec leur environnement. En raison de la nature changeante des normes ou des normes \u00e9manant de diff\u00e9rentes organisations virtuelles, il y aura des situations o\u00f9 une action sera simultan\u00e9ment autoris\u00e9e et interdite, c'est-\u00e0-dire qu'un conflit surviendra. De m\u00eame, il y aura des situations o\u00f9 une action est \u00e0 la fois obligatoire et interdite, c'est-\u00e0-dire qu'une incoh\u00e9rence surviendra. Nous introduisons une approche, bas\u00e9e sur l'unification de premier ordre, pour d\u00e9tecter et r\u00e9soudre de tels conflits et incoh\u00e9rences. Dans notre solution propos\u00e9e, nous annotons une norme avec l\u2019ensemble des valeurs que ses variables ne devraient pas avoir afin d\u2019\u00e9viter un conflit ou une incoh\u00e9rence avec une autre norme. Notre approche s\u2019adapte parfaitement aux interrelations d\u00e9pendant du domaine entre les actions et aux conflits/incoh\u00e9rences indirectes qu\u2019elles peuvent provoquer. Plus g\u00e9n\u00e9ralement, nous pouvons capturer une notion utile de d\u00e9l\u00e9gation inter-agents -LRB- et inter-r\u00f4les -RRB- des actions et des normes qui leur sont associ\u00e9es, et l'utiliser pour r\u00e9soudre les conflits/incoh\u00e9rences caus\u00e9s par la d\u00e9l\u00e9gation d'actions. Nous illustrons notre approche avec un exemple e-Science dans lequel des agents supportent les services Grid. 1. INTRODUCTION Les organisations virtuelles -LRB- VOs -RRB- facilitent le partage coordonn\u00e9 de ressources et la r\u00e9solution de probl\u00e8mes impliquant diverses parties g\u00e9ographiquement \u00e9loign\u00e9es -LSB- 9 -RSB-. Les VO d\u00e9finissent et r\u00e9gulent les interactions -LRB- facilitant ainsi la coordination -RRB- entre les logiciels et/ou les agents humains qui communiquent pour atteindre des objectifs individuels et globaux -LSB- 16 -RSB-. Les VO sont r\u00e9alis\u00e9s sous forme de syst\u00e8mes multi-agents et une caract\u00e9ristique la plus souhaitable de ces syst\u00e8mes est l'ouverture gr\u00e2ce \u00e0 laquelle les nouveaux composants con\u00e7us par d'autres parties sont int\u00e9gr\u00e9s de mani\u00e8re transparente. Les normes r\u00e9gulent le comportement observable d'agents logiciels h\u00e9t\u00e9rog\u00e8nes et int\u00e9ress\u00e9s, con\u00e7us par diverses parties qui ne se font pas enti\u00e8rement confiance -LSB- 3, 24 -RSB-. Cependant, les VO r\u00e9glement\u00e9s par des normes peuvent rencontrer des probl\u00e8mes lorsque les normes assign\u00e9es \u00e0 leurs agents sont en conflit -LRB- c'est-\u00e0-dire qu'une action est simultan\u00e9ment interdite et autoris\u00e9e -RRB- ou incoh\u00e9rentes -LRB- c'est-\u00e0-dire qu'une action est simultan\u00e9ment interdite et oblig\u00e9e -RRB-. . Nous proposons un moyen de d\u00e9tecter et de r\u00e9soudre automatiquement les conflits et les incoh\u00e9rences dans les VO r\u00e9glement\u00e9s par des normes. Nous utilisons l'unification des termes de premier ordre -LSB- 8 -RSB- pour d\u00e9couvrir si et comment les normes se chevauchent dans leur influence -LRB-, c'est-\u00e0-dire,les agents et les valeurs des param\u00e8tres dans les actions des agents que les normes peuvent affecter -RRB-. Cela permet d\u2019aboutir \u00e0 une solution fine gr\u00e2ce \u00e0 laquelle l\u2019influence de normes contradictoires ou incoh\u00e9rentes est r\u00e9duite pour des ensembles de valeurs particuliers. Par exemple, les normes `` l'agent x est autoris\u00e9 \u00e0 envoyer une offre -LRB- ag1, 20 -RRB- '' et `` l'agent ag2 n'a pas le droit d'envoyer une offre -LRB- y, z -RRB- '' -LRB- o\u00f9 x, y, z sont des variables et ag1, ag2, 20 sont des constantes -RRB- sont en conflit car leurs agents, actions et termes -LRB- au sein des actions -RRB- s'unifient. Nous r\u00e9solvons le conflit en annotant les normes avec des ensembles de valeurs que leurs variables ne peuvent pas avoir, r\u00e9duisant ainsi leur influence. Dans notre exemple, le conflit est \u00e9vit\u00e9 si nous exigeons que la variable y ne puisse pas \u00eatre ag1 et que z ne puisse pas \u00eatre 20. Dans la section suivante, nous fournissons une d\u00e9finition minimaliste des VO r\u00e9gul\u00e9s par des normes. Dans la section 3, nous d\u00e9finissons formellement les conflits de normes et expliquons comment ils sont d\u00e9tect\u00e9s et r\u00e9solus. Dans la section 4, nous d\u00e9crivons comment les m\u00e9canismes de la section pr\u00e9c\u00e9dente peuvent \u00eatre adapt\u00e9s pour d\u00e9tecter et r\u00e9soudre les incoh\u00e9rences des normes. Dans la section 5, nous d\u00e9crivons comment nos normes restreintes sont utilis\u00e9es dans les soci\u00e9t\u00e9s d\u2019agents conscients des normes. Dans la section 6, nous expliquons comment nos m\u00e9canismes peuvent \u00eatre utilis\u00e9s pour d\u00e9tecter et r\u00e9soudre les conflits/incoh\u00e9rences indirects, c'est-\u00e0-dire ceux provoqu\u00e9s par les relations entre les actions ; nous \u00e9largissons et adaptons les m\u00e9canismes pour accueillir la d\u00e9l\u00e9gation de normes. Dans la section 7, nous illustrons notre approche avec un exemple d'agents logiciels r\u00e9glement\u00e9s par des normes au service de la Grille.Dans la section 7, nous illustrons notre approche avec un exemple d'agents logiciels r\u00e9glement\u00e9s par des normes au service de la Grille.Dans la section 7, nous illustrons notre approche avec un exemple d'agents logiciels r\u00e9glement\u00e9s par des normes au service de la Grille.", "keyphrases": ["orgue virtuel", "syst\u00e8me multi-agents", "norme-r\u00e9gul vo", "agent", "conflit de normes", "conflit interdire", "la norme est incompatible", "agent externe", "agent du gouverneur"]}
{"file_name": "J-31", "text": "Calculer la strat\u00e9gie optimale \u00e0 adopter \u2217 R\u00c9SUM\u00c9 Dans les syst\u00e8mes multi-agents, les param\u00e8tres strat\u00e9giques sont souvent analys\u00e9s en supposant que les acteurs choisissent leurs strat\u00e9gies simultan\u00e9ment. Toutefois, ce mod\u00e8le n\u2019est pas toujours r\u00e9aliste. Dans de nombreux contexts, un joueur est capable de s\u2019engager dans une strat\u00e9gie avant que l\u2019autre joueur ne prenne une d\u00e9cision. De tels mod\u00e8les sont \u00e9galement appel\u00e9s mod\u00e8les de leadership, d'engagement ou de Stackelberg, et le jeu optimal dans de tels mod\u00e8les est souvent tr\u00e8s diff\u00e9rent du jeu optimal dans le mod\u00e8le o\u00f9 les strat\u00e9gies sont s\u00e9lectionn\u00e9es simultan\u00e9ment. Le r\u00e9cent regain d'int\u00e9r\u00eat pour les solutions informatiques de la th\u00e9orie des jeux a jusqu'\u00e0 pr\u00e9sent ignor\u00e9 les mod\u00e8les de leadership -LRB- \u00e0 l'exception de l'int\u00e9r\u00eat pour la conception de m\u00e9canismes, o\u00f9 le concepteur est implicitement dans une position de leadership -RRB-. Dans cet article, nous \u00e9tudions comment calculer les strat\u00e9gies optimales dans lesquelles s'engager \u00e0 la fois dans le cadre d'un engagement dans des strat\u00e9gies pures et dans un engagement dans des strat\u00e9gies mixtes, \u00e0 la fois dans des jeux de forme normale et bay\u00e9siens. Nous donnons \u00e0 la fois des r\u00e9sultats positifs -LRB- pour des algorithmes efficaces -RRB- et des r\u00e9sultats n\u00e9gatifs -LRB- pour des r\u00e9sultats de duret\u00e9 NP -RRB-. 1. INTRODUCTION Dans les syst\u00e8mes multi-agents avec des agents int\u00e9ress\u00e9s -LRB-, y compris la plupart des contexts \u00e9conomiques -RRB-, l'action optimale qu'un agent doit entreprendre d\u00e9pend des actions entreprises par les autres agents. Pour analyser comment un agent doit se comporter dans de tels contexts, les outils de la th\u00e9orie des jeux doivent \u00eatre appliqu\u00e9s. G\u00e9n\u00e9ralement, lorsqu\u2019un context strat\u00e9gique est mod\u00e9lis\u00e9 dans le cadre de la th\u00e9orie des jeux, on suppose que les joueurs choisissent leurs strat\u00e9gies simultan\u00e9ment. Cela est particuli\u00e8rement vrai lorsque le context est mod\u00e9lis\u00e9 comme un jeu de forme normale, qui sp\u00e9cifie uniquement l'utilit\u00e9 de chaque agent en fonction du vecteur de strat\u00e9gies choisi par les agents, et ne fournit aucune information sur l'ordre dans lequel les agents agissent. leurs d\u00e9cisions et ce que les agents observent \u00e0 propos des d\u00e9cisions ant\u00e9rieures des autres agents. \u00c9tant donn\u00e9 que le jeu est mod\u00e9lis\u00e9 sous forme normale, il est g\u00e9n\u00e9ralement analys\u00e9 en utilisant le concept d\u2019\u00e9quilibre de Nash. Un \u00e9quilibre de Nash sp\u00e9cifie une strat\u00e9gie pour chaque joueur, de telle sorte qu'aucun joueur n'est incit\u00e9 \u00e0 s'\u00e9carter individuellement de ce profil de strat\u00e9gies. -LRB- G\u00e9n\u00e9ralement, les strat\u00e9gies peuvent \u00eatre mixtes, c'est-\u00e0-dire des distributions de probabilit\u00e9 sur les strat\u00e9gies -LRB- pures -RRB- originales. -RRB- Un -LRB- strat\u00e9gie mixte -RRB- L'\u00e9quilibre de Nash est garanti d'exister dans les jeux finis -LSB- 18 -RSB-, mais un probl\u00e8me est qu'il peut y avoir plusieurs \u00e9quilibres de Nash. Cela conduit au probl\u00e8me de s\u00e9lection d\u2019\u00e9quilibre : comment un agent peut savoir quelle strat\u00e9gie jouer s\u2019il ne sait pas quel \u00e9quilibre doit \u00eatre jou\u00e9. Lorsque le context est mod\u00e9lis\u00e9 comme un jeu de forme \u00e9tendue, il est possible de sp\u00e9cifier que certains joueurs re\u00e7oivent des informations sur les actions entreprises par d'autres plus t\u00f4t dans la partie avant de d\u00e9cider de leur action. N\u00e9anmoins, en g\u00e9n\u00e9ral, les joueurs ne savent pas tout ce qui s\u2019est pass\u00e9 plus t\u00f4t dans la partie. \u00c0 cause de \u00e7a,ces jeux sont g\u00e9n\u00e9ralement encore analys\u00e9s en utilisant un concept d'\u00e9quilibre, o\u00f9 l'on sp\u00e9cifie une strat\u00e9gie mixte pour chaque joueur et exige que la strat\u00e9gie de chaque joueur soit la meilleure r\u00e9ponse aux strat\u00e9gies des autres. -LRB- G\u00e9n\u00e9ralement, une contrainte suppl\u00e9mentaire sur les strat\u00e9gies est d\u00e9sormais impos\u00e9e pour garantir que les joueurs ne jouent pas d'une mani\u00e8re irrationnelle par rapport aux informations qu'ils ont re\u00e7ues jusqu'\u00e0 pr\u00e9sent. Cela conduit \u00e0 des raffinements de l\u2019\u00e9quilibre de Nash tels que l\u2019\u00e9quilibre parfait et s\u00e9quentiel des sous-jeux. -RRB- Cependant, dans de nombreux contexts du monde r\u00e9el, les strat\u00e9gies ne sont pas s\u00e9lectionn\u00e9es de mani\u00e8re aussi simultan\u00e9e. Souvent, un joueur -LRB- le leader -RRB- est capable de s'engager dans une strat\u00e9gie avant un autre joueur -LRB- le suiveur -RRB-. Cela peut \u00eatre d\u00fb \u00e0 diverses raisons. Par exemple, l'un des joueurs peut arriver sur le site o\u00f9 le jeu doit \u00eatre jou\u00e9 avant un autre agent -LRB-. Par exemple, dans un context \u00e9conomique, un joueur peut entrer sur un march\u00e9 plus t\u00f4t et s'engager sur une mani\u00e8re de faire des affaires -RRB. -. Un tel pouvoir d\u2019engagement a un impact profond sur la mani\u00e8re dont le jeu doit \u00eatre jou\u00e9. Par exemple, il serait peut-\u00eatre pr\u00e9f\u00e9rable pour le leader de jouer une strat\u00e9gie domin\u00e9e par la repr\u00e9sentation normale du jeu. En g\u00e9n\u00e9ral, si l'engagement dans des strat\u00e9gies mixtes est possible, alors -LRB- sous des hypoth\u00e8ses mineures -RRB- cela ne fait jamais de mal, et souvent aide, de s'engager dans une strat\u00e9gie -LSB- 26 -RSB-. \u00catre oblig\u00e9 de s'engager dans une strat\u00e9gie pure aide parfois, et parfois fait mal -LRB- par exemple, s'engager dans une strat\u00e9gie pure \u00e0 pierre-feuille-ciseaux avant que la d\u00e9cision de l'autre joueur entra\u00eenera naturellement une perte -RRB-. Dans cet article, nous supposerons que l'engagement est toujours forc\u00e9 ; si ce n'est pas le cas, le joueur qui a le choix de s'engager peut simplement comparer le r\u00e9sultat de l'engagement au r\u00e9sultat du non-engagement -LRB-mouvement simultan\u00e9 -RRB-. Les mod\u00e8les de leadership sont particuli\u00e8rement importants dans les environnements comportant plusieurs agents logiciels int\u00e9ress\u00e9s. Une fois que le code pour un agent -LRB- ou pour une \u00e9quipe d'agents -RRB- est finalis\u00e9 et que l'agent est d\u00e9ploy\u00e9, l'agent s'engage \u00e0 jouer la strat\u00e9gie -LRB- \u00e9ventuellement al\u00e9atoire -RRB- que prescrit le code. Enfin, il existe \u00e9galement une situation de leadership implicite dans le domaine de la conception de m\u00e9canismes, dans laquelle un joueur -LRB- et le concepteur -RRB- choisissent les r\u00e8gles du jeu auxquelles les autres joueurs jouent ensuite. En effet, le concepteur du m\u00e9canisme peut gagner \u00e0 s'engager sur un choix qui, si les actions des -LRB-restants-RRB-agents \u00e9taient corrig\u00e9es, serait sous-optimal. Cependant, le calcul de la strat\u00e9gie optimale \u00e0 adopter dans une situation de leadership a \u00e9t\u00e9 ignor\u00e9. Th\u00e9oriquement, les situations de leadership peuvent simplement \u00eatre consid\u00e9r\u00e9es comme un jeu de forme \u00e9tendue dans lequel un joueur choisit d'abord une strat\u00e9gie -LRB- pour le jeu original -RRB-. Le nombre de strat\u00e9gies dans ce jeu \u00e9tendu peut cependant \u00eatre extr\u00eamement important. Par exemple, si le leader est capable de s'engager dans une strat\u00e9gie mixte dans le jeu original,alors chacune des strat\u00e9gies mixtes -LRB- du continuum -RRB- constitue une pure strat\u00e9gie dans la repr\u00e9sentation sous forme extensive de la situation de leadership. -LRB- On remarque qu'un engagement sur une r\u00e9partition n'est pas la m\u00eame chose qu'une r\u00e9partition sur engagements. -RRB- De plus, si le jeu original est lui-m\u00eame un jeu de forme extensive, le nombre de strat\u00e9gies dans la repr\u00e9sentation de forme extensive de la situation de leadership -LRB- qui est un jeu de forme extensive diff\u00e9rent -RRB- devient encore plus grand. Pour cette raison, il n'est g\u00e9n\u00e9ralement pas r\u00e9alisable informatiquement de simplement transformer le jeu original en une repr\u00e9sentation \u00e9tendue de la situation de leadership ; nous devons plut\u00f4t analyser le jeu dans sa repr\u00e9sentation originale. Dans cet article, nous \u00e9tudions comment calculer la strat\u00e9gie optimale dans laquelle s'engager, \u00e0 la fois dans les jeux de forme normale -LRB- Section 2 -RRB- et dans les jeux bay\u00e9siens, qui sont un cas particulier des jeux de forme extensive -LRB- Section 3 -RRB -. 4. CONCLUSIONS ET RECHERCHES FUTURES Dans les syst\u00e8mes multi-agents, les param\u00e8tres strat\u00e9giques sont souvent analys\u00e9s en supposant que les acteurs choisissent leurs strat\u00e9gies simultan\u00e9ment. Cela n\u00e9cessite une certaine notion d'\u00e9quilibre -LRB-, l'\u00e9quilibre de Nash et ses raffinements -RRB-, et conduit souvent au probl\u00e8me de s\u00e9lection d'\u00e9quilibre : il n'est pas clair pour chaque joueur individuel selon quel \u00e9quilibre il doit jouer. Toutefois, ce mod\u00e8le n\u2019est pas toujours r\u00e9aliste. Dans de nombreux contexts, un joueur est capable de s\u2019engager dans une strat\u00e9gie avant que l\u2019autre joueur ne prenne une d\u00e9cision. Par exemple, un agent peut arriver sur le site -LRB- r\u00e9el ou virtuel -RRB- du jeu avant l'autre, ou, dans le cas sp\u00e9cifique des agents logiciels, le code d'un agent peut \u00eatre compl\u00e9t\u00e9 et valid\u00e9 avant celui d'un autre. agent. De tels mod\u00e8les sont \u00e9galement appel\u00e9s mod\u00e8les de leadership, d'engagement ou de Stackelberg, et le jeu optimal dans de tels mod\u00e8les est souvent tr\u00e8s diff\u00e9rent du jeu optimal dans le mod\u00e8le o\u00f9 les strat\u00e9gies sont s\u00e9lectionn\u00e9es simultan\u00e9ment. Plus pr\u00e9cis\u00e9ment, si l\u2019engagement dans des strat\u00e9gies mixtes est possible, alors l\u2019engagement -LRB- optimal -RRB- ne nuit jamais au leader et l\u2019aide souvent. Le r\u00e9cent regain d'int\u00e9r\u00eat pour les solutions informatiques de la th\u00e9orie des jeux a jusqu'\u00e0 pr\u00e9sent ignor\u00e9 les mod\u00e8les de leadership -LRB- \u00e0 l'exception de l'int\u00e9r\u00eat pour la conception de m\u00e9canismes, o\u00f9 le concepteur est implicitement dans une position de leadership -RRB-. Dans cet article, nous avons \u00e9tudi\u00e9 comment calculer les strat\u00e9gies optimales dans lesquelles s'engager \u00e0 la fois dans le cadre d'un engagement dans des strat\u00e9gies pures et dans un engagement dans des strat\u00e9gies mixtes, \u00e0 la fois dans des jeux de forme normale et bay\u00e9siens. Pour les jeux de forme normale, nous avons montr\u00e9 que la strat\u00e9gie pure optimale dans laquelle s\u2019engager peut \u00eatre trouv\u00e9e efficacement pour n\u2019importe quel nombre de joueurs. Une strat\u00e9gie mixte optimale dans laquelle s'engager dans un jeu de forme normale peut \u00eatre trouv\u00e9e efficacement pour deux joueurs en utilisant la programmation lin\u00e9aire -LRB- et pas plus efficacement que cela, dans le sens o\u00f9 tout programme lin\u00e9aire avec une contrainte de probabilit\u00e9 peut \u00eatre cod\u00e9 comme tel. probl\u00e8me -RRB-.-LRB- Il s'agit d'une g\u00e9n\u00e9ralisation de la calculabilit\u00e9 en temps polynomial des strat\u00e9gies minimax dans les jeux de forme normale. -RRB- Le probl\u00e8me devient NP-difficile pour trois joueurs -LRB- ou plus -RRB-. Dans les jeux bay\u00e9siens, le probl\u00e8me de trouver une strat\u00e9gie pure optimale dans laquelle s'engager est NP-difficile m\u00eame dans les jeux \u00e0 deux joueurs dans lesquels le suiveur n'a qu'un seul type, bien que les jeux \u00e0 deux joueurs dans lesquels le leader n'a qu'un seul type peuvent \u00eatre r\u00e9solu efficacement. Le probl\u00e8me de trouver une strat\u00e9gie mixte optimale dans laquelle s'engager dans un jeu bay\u00e9sien est NP-difficile m\u00eame dans les jeux \u00e0 deux joueurs dans lesquels le leader n'a qu'un seul type, bien que les jeux \u00e0 deux joueurs dans lesquels le suiveur n'a qu'un seul type peuvent \u00eatre r\u00e9solu efficacement en utilisant une g\u00e9n\u00e9ralisation de l'approche de programmation lin\u00e9aire pour les jeux de forme normale. Les deux tableaux suivants r\u00e9sument ces r\u00e9sultats. R\u00e9sultats pour l\u2019engagement dans des strat\u00e9gies mixtes. -LRB- A plus de 2 joueurs, le \"suiveur\" est le dernier joueur \u00e0 s'engager, le \"leader\" est le premier. -RRB- Les recherches futures peuvent prendre plusieurs directions. Nous pouvons \u00e9galement \u00e9tudier le calcul de strat\u00e9gies optimales dans lesquelles s'engager dans d'autres1 repr\u00e9sentations concises de jeux de forme normale -- par exemple, dans les jeux graphiques -LSB- 10 -RSB- ou les jeux de graphes d'action/effet local -LSB- 14, 1 -RSB-. Pour les cas o\u00f9 le calcul d'une strat\u00e9gie optimale dans laquelle s'engager est NP-difficile, nous pouvons \u00e9galement \u00e9tudier le calcul de strat\u00e9gies approximativement optimales dans lesquelles s'engager. On peut \u00e9galement \u00e9tudier des mod\u00e8les dans lesquels plusieurs acteurs -LRB- mais pas tous -RRB- s'engagent en m\u00eame temps. Une autre direction int\u00e9ressante \u00e0 poursuivre est de voir si le calcul de strat\u00e9gies mixtes optimales dans lesquelles s\u2019engager peut nous aider, ou autrement \u00e9clairer, le calcul des \u00e9quilibres de Nash. Souvent, les strat\u00e9gies mixtes optimales dans lesquelles s'engager sont \u00e9galement des strat\u00e9gies d'\u00e9quilibre de Nash -LRB- par exemple, dans les jeux \u00e0 somme nulle \u00e0 deux joueurs, cela est toujours vrai -RRB-, bien que ce ne soit pas toujours le cas -LRB- par exemple, comme nous Comme nous l'avons d\u00e9j\u00e0 soulign\u00e9, parfois la strat\u00e9gie optimale dans laquelle s'engager est une strat\u00e9gie strictement domin\u00e9e, qui ne peut jamais \u00eatre une strat\u00e9gie d'\u00e9quilibre de Nash -RRB-.le \u00ab leader \u00bb est le premier. -RRB- Les recherches futures peuvent prendre plusieurs directions. Nous pouvons \u00e9galement \u00e9tudier le calcul de strat\u00e9gies optimales dans lesquelles s'engager dans d'autres1 repr\u00e9sentations concises de jeux de forme normale -- par exemple, dans les jeux graphiques -LSB- 10 -RSB- ou les jeux de graphes d'action/effet local -LSB- 14, 1 -RSB-. Pour les cas o\u00f9 le calcul d'une strat\u00e9gie optimale dans laquelle s'engager est NP-difficile, nous pouvons \u00e9galement \u00e9tudier le calcul de strat\u00e9gies approximativement optimales dans lesquelles s'engager. On peut \u00e9galement \u00e9tudier des mod\u00e8les dans lesquels plusieurs acteurs -LRB- mais pas tous -RRB- s'engagent en m\u00eame temps. Une autre direction int\u00e9ressante \u00e0 poursuivre est de voir si le calcul de strat\u00e9gies mixtes optimales dans lesquelles s\u2019engager peut nous aider, ou autrement \u00e9clairer, le calcul des \u00e9quilibres de Nash. Souvent, les strat\u00e9gies mixtes optimales dans lesquelles s'engager sont \u00e9galement des strat\u00e9gies d'\u00e9quilibre de Nash -LRB- par exemple, dans les jeux \u00e0 somme nulle \u00e0 deux joueurs, cela est toujours vrai -RRB-, bien que ce ne soit pas toujours le cas -LRB- par exemple, comme nous Comme nous l'avons d\u00e9j\u00e0 soulign\u00e9, parfois la strat\u00e9gie optimale dans laquelle s'engager est une strat\u00e9gie strictement domin\u00e9e, qui ne peut jamais \u00eatre une strat\u00e9gie d'\u00e9quilibre de Nash -RRB-.le \u00ab leader \u00bb est le premier. -RRB- Les recherches futures peuvent prendre plusieurs directions. Nous pouvons \u00e9galement \u00e9tudier le calcul de strat\u00e9gies optimales dans lesquelles s'engager dans d'autres1 repr\u00e9sentations concises de jeux de forme normale -- par exemple, dans les jeux graphiques -LSB- 10 -RSB- ou les jeux de graphes d'action/effet local -LSB- 14, 1 -RSB-. Pour les cas o\u00f9 le calcul d'une strat\u00e9gie optimale dans laquelle s'engager est NP-difficile, nous pouvons \u00e9galement \u00e9tudier le calcul de strat\u00e9gies approximativement optimales dans lesquelles s'engager. On peut \u00e9galement \u00e9tudier des mod\u00e8les dans lesquels plusieurs acteurs -LRB- mais pas tous -RRB- s'engagent en m\u00eame temps. Une autre direction int\u00e9ressante \u00e0 poursuivre est de voir si le calcul de strat\u00e9gies mixtes optimales dans lesquelles s\u2019engager peut nous aider, ou autrement \u00e9clairer, le calcul des \u00e9quilibres de Nash. Souvent, les strat\u00e9gies mixtes optimales dans lesquelles s'engager sont \u00e9galement des strat\u00e9gies d'\u00e9quilibre de Nash -LRB- par exemple, dans les jeux \u00e0 somme nulle \u00e0 deux joueurs, cela est toujours vrai -RRB-, bien que ce ne soit pas toujours le cas -LRB- par exemple, comme nous Comme nous l'avons d\u00e9j\u00e0 soulign\u00e9, parfois la strat\u00e9gie optimale dans laquelle s'engager est une strat\u00e9gie strictement domin\u00e9e, qui ne peut jamais \u00eatre une strat\u00e9gie d'\u00e9quilibre de Nash -RRB-.", "keyphrases": ["strat\u00e9gie optimale", "syst\u00e8me multiag", "mani\u00e8re simultan\u00e9e", "mod\u00e8le Stackelberg", "mod\u00e8le de leadership", "strat\u00e9gie pure", "m\u00e9langer les strat\u00e9gies", "jeu de forme normale", "jeu bay\u00e9sien", "\u00e9quilibre de Nash", "np-dur"]}
{"file_name": "H-13", "text": "L'influence des fonctionnalit\u00e9s de sous-titres sur les mod\u00e8les de clics dans la recherche sur le Web R\u00c9SUM\u00c9 Les moteurs de recherche sur le Web pr\u00e9sentent des listes de l\u00e9gendes, comprenant le titre, l'extrait de code et l'URL, pour aider les utilisateurs \u00e0 d\u00e9cider quels r\u00e9sultats de recherche consulter. Comprendre l'influence des caract\u00e9ristiques de ces sous-titres sur le comportement de recherche sur le Web peut aider \u00e0 valider les algorithmes et les lignes directrices pour leur g\u00e9n\u00e9ration am\u00e9lior\u00e9e. Dans cet article, nous d\u00e9veloppons une m\u00e9thodologie pour utiliser les journaux de clics d'un moteur de recherche commercial pour \u00e9tudier le comportement des utilisateurs lors de leurs interactions avec les l\u00e9gendes des r\u00e9sultats de recherche. Les r\u00e9sultats de notre \u00e9tude sugg\u00e8rent que des fonctionnalit\u00e9s de l\u00e9gende relativement simples, telles que la pr\u00e9sence de tous les termes de requ\u00eate, la lisibilit\u00e9 de l'extrait et la longueur de l'URL affich\u00e9e dans la l\u00e9gende, peuvent influencer consid\u00e9rablement le comportement de recherche des utilisateurs sur le Web. 1. INTRODUCTION Les principaux moteurs de recherche commerciaux sur le Web pr\u00e9sentent tous leurs r\u00e9sultats \u00e0 peu pr\u00e8s de la m\u00eame mani\u00e8re. Chaque r\u00e9sultat de recherche est d\u00e9crit par une br\u00e8ve l\u00e9gende, comprenant l'URL de la page Web associ\u00e9e, un titre et un bref r\u00e9sum\u00e9 -LRB- ou `` snippet '' -RRB- d\u00e9crivant le contenu de la page. Souvent, l'extrait est extrait de la page Web elle-m\u00eame, mais il peut \u00e9galement provenir de sources externes, telles que les r\u00e9sum\u00e9s g\u00e9n\u00e9r\u00e9s par l'homme et trouv\u00e9s dans les annuaires Web. La figure 1 montre une recherche Web typique, avec des l\u00e9gendes pour les trois premiers r\u00e9sultats. Alors que les trois l\u00e9gendes partagent la m\u00eame chose, l'extrait de la troisi\u00e8me l\u00e9gende est presque deux fois plus long que celui de la premi\u00e8re, tandis que l'extrait est enti\u00e8rement absent de la deuxi\u00e8me l\u00e9gende. Le titre de la troisi\u00e8me l\u00e9gende contient tous les termes de la requ\u00eate dans l'ordre, tandis que les titres des premi\u00e8re et deuxi\u00e8me l\u00e9gendes ne contiennent que deux des trois termes. L'un des termes de la requ\u00eate est r\u00e9p\u00e9t\u00e9 dans la premi\u00e8re l\u00e9gende. Tous les termes de requ\u00eate apparaissent dans l\u2019URL de la troisi\u00e8me l\u00e9gende, alors qu\u2019aucun n\u2019appara\u00eet dans l\u2019URL de la premi\u00e8re l\u00e9gende. Si ces diff\u00e9rences peuvent para\u00eetre mineures, elles peuvent \u00e9galement avoir un impact substantiel sur le comportement des utilisateurs. L'une des principales motivations pour fournir une l\u00e9gende est d'aider l'utilisateur \u00e0 d\u00e9terminer la pertinence de la page associ\u00e9e sans avoir \u00e0 cliquer pour acc\u00e9der au r\u00e9sultat. Dans le cas d'une requ\u00eate de navigation -- notamment lorsque la destination est bien connue -- l'URL seule peut suffire \u00e0 identifier la page souhait\u00e9e. Mais dans le cas d'une requ\u00eate informative, le titre et l'extrait peuvent \u00eatre n\u00e9cessaires pour guider l'utilisateur dans la s\u00e9lection d'une page pour une \u00e9tude plus approfondie, et il peut juger de la pertinence d'une page sur la seule base de la l\u00e9gende. Lorsque ce jugement est correct, il peut acc\u00e9l\u00e9rer le processus de recherche en permettant \u00e0 l'utilisateur d'\u00e9viter les \u00e9l\u00e9ments ind\u00e9sirables. En cas d'\u00e9chec, l'utilisateur peut perdre son temps \u00e0 cliquer sur un r\u00e9sultat inappropri\u00e9 et \u00e0 num\u00e9riser une page contenant peu ou rien d'int\u00e9ressant. Pire encore, l'utilisateur peut \u00eatre induit en erreur et ignorer une page contenant les informations souhait\u00e9es. Les trois r\u00e9sultats de la figure 1 sont pertinents, avec certaines limites. Le premier r\u00e9sultat renvoie au principal Yahoo Kids! page d'accueil,mais il faut alors suivre un lien dans un menu pour retrouver la page principale des jeux. Malgr\u00e9 les apparences, le deuxi\u00e8me r\u00e9sultat renvoie \u00e0 une collection \u00e9tonnamment grande de jeux en ligne, principalement sur des th\u00e8mes environnementaux. Malheureusement, ces caract\u00e9ristiques des pages ne sont pas enti\u00e8rement refl\u00e9t\u00e9es dans les l\u00e9gendes. Dans cet article, nous examinons l'influence des fonctionnalit\u00e9s de sous-titres sur le comportement de recherche des utilisateurs sur le Web, en utilisant les clics extraits des journaux des moteurs de recherche comme principal outil d'enqu\u00eate. Comprendre cette influence peut aider \u00e0 valider les algorithmes et les lignes directrices pour la g\u00e9n\u00e9ration am\u00e9lior\u00e9e du Figure 1 : Trois principaux r\u00e9sultats pour la requ\u00eate : jeux en ligne pour enfants. l\u00e9gendes elles-m\u00eames. De plus, ces fonctionnalit\u00e9s peuvent jouer un r\u00f4le dans le processus de d\u00e9duction de jugements de pertinence \u00e0 partir du comportement de l'utilisateur -LSB- 1 -RSB-. En comprenant mieux leur influence, de meilleurs jugements peuvent en r\u00e9sulter. Diff\u00e9rents algorithmes de g\u00e9n\u00e9ration de l\u00e9gendes peuvent s\u00e9lectionner des extraits de diff\u00e9rentes longueurs dans diff\u00e9rentes zones d'une page. Les extraits de code peuvent \u00eatre g\u00e9n\u00e9r\u00e9s ind\u00e9pendamment de la requ\u00eate, fournissant un r\u00e9sum\u00e9 de la page dans son ensemble, ou de mani\u00e8re d\u00e9pendante de la requ\u00eate, fournissant un r\u00e9sum\u00e9 de la mani\u00e8re dont la page se rapporte aux termes de la requ\u00eate. Le choix correct de l'extrait peut d\u00e9pendre d'aspects \u00e0 la fois de la requ\u00eate et de la page de r\u00e9sultats. Pour les liens qui redirigent, il peut \u00eatre possible d'afficher des URL alternatives. De plus, pour les pages r\u00e9pertori\u00e9es dans des r\u00e9pertoires Web \u00e9dit\u00e9s par des humains tels que l'Open Directory Project ', il peut \u00eatre possible d'afficher des titres alternatifs et des extraits d\u00e9riv\u00e9s de ces listes. Lorsque ces extraits de code, titres et URL alternatifs sont disponibles, la s\u00e9lection d'une combinaison appropri\u00e9e \u00e0 afficher peut \u00eatre guid\u00e9e par leurs caract\u00e9ristiques. Un extrait d'un annuaire Web peut \u00eatre constitu\u00e9 de phrases compl\u00e8tes et \u00eatre moins fragmentaire qu'un extrait extrait. Un titre extrait du corps peut fournir une plus grande couverture des termes de la requ\u00eate. Les travaux rapport\u00e9s dans cet article ont \u00e9t\u00e9 entrepris dans le context du moteur de recherche Windows Live. Les exp\u00e9riences rapport\u00e9es dans les sections suivantes sont bas\u00e9es sur les journaux de requ\u00eates Windows Live, les pages de r\u00e9sultats et les jugements de pertinence collect\u00e9s dans le cadre de recherches en cours sur les performances des moteurs de recherche -LSB- 1, 2 -RSB-. N\u00e9anmoins, \u00e9tant donn\u00e9 la similitude des formats de sous-titres entre les principaux moteurs de recherche Web, nous pensons que les r\u00e9sultats sont applicables \u00e0 ces autres moteurs. La requ\u00eate dans la figure 1 de www.dmoz.org produit des r\u00e9sultats avec une pertinence similaire sur les autres principaux moteurs de recherche. Cette requ\u00eate et d\u2019autres produisent des l\u00e9gendes pr\u00e9sentant des variations similaires. En outre, nous pensons que notre m\u00e9thodologie pourra \u00eatre g\u00e9n\u00e9ralis\u00e9e \u00e0 d'autres applications de recherche lorsque suffisamment de donn\u00e9es sur les clics seront disponibles. 2. TRAVAUX CONNEXES Bien que les moteurs de recherche Web commerciaux aient suivi des approches similaires en mati\u00e8re d'affichage de sous-titres depuis leur gen\u00e8se, relativement peu de recherches ont \u00e9t\u00e9 publi\u00e9es sur les m\u00e9thodes permettant de g\u00e9n\u00e9rer ces sous-titres et d'\u00e9valuer leur impact sur le comportement des utilisateurs.La plupart des recherches sur l'affichage des r\u00e9sultats Web ont propos\u00e9 des modifications substantielles de l'interface, plut\u00f4t que d'aborder les d\u00e9tails des interfaces existantes. 2.1 Affichage des r\u00e9sultats Web Varadarajan et Hristidis -LSB-16-RSB- sont parmi les rares \u00e0 avoir tent\u00e9 d'am\u00e9liorer directement les extraits g\u00e9n\u00e9r\u00e9s par les syst\u00e8mes de recherche commerciaux, sans introduire de modifications suppl\u00e9mentaires dans l'interface. Ils ont g\u00e9n\u00e9r\u00e9 des extraits \u00e0 partir d'arbres couvrants de graphiques de documents et ont compar\u00e9 exp\u00e9rimentalement ces extraits avec les extraits g\u00e9n\u00e9r\u00e9s pour les m\u00eames documents par le syst\u00e8me de recherche de bureau Google et le syst\u00e8me de recherche de bureau MSN. Ils ont \u00e9valu\u00e9 leur m\u00e9thode en demandant aux utilisateurs de comparer des extraits de diff\u00e9rentes sources. 6. CONCLUSIONS Les inversions de clics constituent un outil appropri\u00e9 pour \u00e9valuer l'influence des fonctionnalit\u00e9s de l\u00e9gende. En utilisant les inversions de clics, nous avons d\u00e9montr\u00e9 que des fonctionnalit\u00e9s de sous-titres relativement simples peuvent influencer consid\u00e9rablement le comportement des utilisateurs. \u00c0 notre connaissance, il s\u2019agit de la premi\u00e8re m\u00e9thodologie valid\u00e9e pour \u00e9valuer la qualit\u00e9 des sous-titres Web par feedback implicite. Nous esp\u00e9rons \u00e9galement r\u00e9pondre directement \u00e0 l'objectif de pr\u00e9dire la pertinence des clics et d'autres informations pr\u00e9sentes dans les journaux des moteurs de recherche.", "keyphrases": ["mod\u00e8le de clic", "fonction de l\u00e9gende", "comportement de recherche sur le Web", "facteur humain", "extrait du r\u00e9sum\u00e9", "fragment", "journal des requ\u00eates", "demander une reformulation", "mot significatif", "inverseurs de clics", "correspondance des termes recherch\u00e9s"]}
{"file_name": "I-5", "text": "Vers une allocation de ressources auto-organis\u00e9e bas\u00e9e sur des agents dans un environnement multi-serveur R\u00c9SUM\u00c9 Les applications distribu\u00e9es n\u00e9cessitent des techniques distribu\u00e9es pour une allocation efficace des ressources. Ces techniques doivent prendre en compte l'h\u00e9t\u00e9rog\u00e9n\u00e9it\u00e9 et le manque de fiabilit\u00e9 potentiel des ressources et des consommateurs de ressources dans un environnement distribu\u00e9. Dans cet article, nous proposons un algorithme distribu\u00e9 qui r\u00e9sout le probl\u00e8me d'allocation de ressources dans les syst\u00e8mes multiagents distribu\u00e9s. Notre solution repose sur l\u2019auto-organisation des agents, qui ne n\u00e9cessite aucun facilitateur ni niveau de gestion. L'allocation des ressources dans le syst\u00e8me est un effet purement \u00e9mergent. Nous pr\u00e9sentons les r\u00e9sultats du m\u00e9canisme d'allocation de ressources propos\u00e9 dans l'environnement multi-serveur statique et dynamique simul\u00e9. 1. INTRODUCTION En ce sens, chaque agent est un consommateur de ressources qui acquiert une certaine quantit\u00e9 de ressources pour l'ex\u00e9cution de ses t\u00e2ches. Il est difficile pour un m\u00e9canisme central d'allocation des ressources de collecter et de g\u00e9rer les informations sur toutes les ressources partag\u00e9es et les consommateurs de ressources afin d'effectuer efficacement l'allocation des ressources. Par cons\u00e9quent, des solutions distribu\u00e9es au probl\u00e8me d\u2019allocation des ressources sont n\u00e9cessaires. Les chercheurs ont reconnu ces exigences -LSB-10-RSB- et ont propos\u00e9 des techniques d'allocation distribu\u00e9e des ressources. Un type prometteur de ces approches distribu\u00e9es est bas\u00e9 sur des mod\u00e8les de march\u00e9 \u00e9conomiques -LSB-4-RSB-, inspir\u00e9s des principes des march\u00e9s boursiers r\u00e9els. M\u00eame si ces approches sont distribu\u00e9es, elles n\u00e9cessitent g\u00e9n\u00e9ralement un facilitateur pour la tarification, la d\u00e9couverte des ressources et la r\u00e9partition des t\u00e2ches vers les ressources -LSB- 5, 9 -RSB-. Un autre probl\u00e8me essentiellement non r\u00e9solu de ces approches est le r\u00e9glage fin des contraintes de prix, de temps et de budget pour permettre une allocation efficace des ressources dans de grands syst\u00e8mes dynamiques -LSB- 22 -RSB-. Dans cet article, nous proposons une solution distribu\u00e9e au probl\u00e8me d'allocation des ressources bas\u00e9e sur l'auto-organisation des consommateurs de ressources dans un syst\u00e8me aux ressources limit\u00e9es. Dans notre approche, les agents allouent dynamiquement des t\u00e2ches aux serveurs qui fournissent une quantit\u00e9 limit\u00e9e de ressources. Dans notre approche, les agents s\u00e9lectionnent de mani\u00e8re autonome la plateforme d'ex\u00e9cution de la t\u00e2che plut\u00f4t que de demander \u00e0 un courtier de ressources de faire l'allocation. Tout le contr\u00f4le n\u00e9cessaire \u00e0 notre algorithme est r\u00e9parti entre les agents du syst\u00e8me. Ils optimisent continuellement le processus d'allocation des ressources tout au long de leur dur\u00e9e de vie en fonction des changements dans la disponibilit\u00e9 des ressources partag\u00e9es, en tirant les le\u00e7ons des d\u00e9cisions d'allocation pass\u00e9es. Les seules informations disponibles pour tous les agents sont les informations sur la charge des ressources et la r\u00e9ussite des allocations issues des allocations de ressources pass\u00e9es. Les informations suppl\u00e9mentaires sur la charge des ressources sur les serveurs ne sont pas diffus\u00e9es. Le m\u00e9canisme propos\u00e9 ne n\u00e9cessite pas d'autorit\u00e9 de contr\u00f4le centrale, de couche de gestion des ressources ni d'introduction de communication suppl\u00e9mentaire entre les agents pour d\u00e9cider quelle t\u00e2che est allou\u00e9e sur quel serveur.Nous d\u00e9montrons que ce m\u00e9canisme fonctionne bien sur les syst\u00e8mes dynamiques comportant un grand nombre de t\u00e2ches et peut facilement \u00eatre adapt\u00e9 \u00e0 diff\u00e9rentes tailles de syst\u00e8mes. De plus, les performances globales du syst\u00e8me ne sont pas affect\u00e9es en cas de panne ou d'indisponibilit\u00e9 des agents ou des serveurs. L'approche propos\u00e9e fournit un moyen simple de mettre en \u0153uvre une allocation distribu\u00e9e des ressources et prend en compte les tendances des syst\u00e8mes multi-agents vers l'autonomie, l'h\u00e9t\u00e9rog\u00e9n\u00e9it\u00e9 et le manque de fiabilit\u00e9 des ressources et des agents. Cette technique propos\u00e9e peut \u00eatre facilement compl\u00e9t\u00e9e par des techniques de mise en file d'attente ou de rejet des demandes d'allocation de ressources des agents -LSB-11-RSB-. De telles capacit\u00e9s d'autogestion des agents logiciels permettent une allocation fiable des ressources m\u00eame dans un environnement avec des fournisseurs de ressources peu fiables. Ceci peut \u00eatre r\u00e9alis\u00e9 par les interactions mutuelles entre agents en appliquant des techniques issues de la th\u00e9orie des syst\u00e8mes complexes. L'auto-organisation de tous les agents conduit \u00e0 une auto-organisation des agents. 2. TRAVAUX CONNEXES L'allocation des ressources est un probl\u00e8me important dans le domaine de l'informatique. D'une mani\u00e8re g\u00e9n\u00e9rale, l'allocation de ressources est un m\u00e9canisme ou une politique pour la gestion efficiente et efficace de l'acc\u00e8s \u00e0 une ressource limit\u00e9e ou \u00e0 un ensemble de ressources par ses consommateurs. Dans le cas le plus simple, les consommateurs de ressources demandent \u00e0 un courtier central ou \u00e0 un r\u00e9partiteur les ressources disponibles auxquelles le consommateur de ressources sera allou\u00e9. Le courtier a g\u00e9n\u00e9ralement une connaissance compl\u00e8te de toutes les ressources du syst\u00e8me. Dans ces approches, le consommateur de ressources ne peut pas influencer le processus de d\u00e9cision d'allocation. L'\u00e9quilibrage de charge -LSB- 3 -RSB- est un cas particulier de probl\u00e8me d'allocation de ressources utilisant un courtier qui tente d'\u00eatre \u00e9quitable envers toutes les ressources en \u00e9quilibrant la charge du syst\u00e8me de mani\u00e8re \u00e9gale entre tous les fournisseurs de ressources. Ce m\u00e9canisme fonctionne mieux dans un syst\u00e8me homog\u00e8ne. Une technique distribu\u00e9e simple pour la gestion des ressources est la planification de la capacit\u00e9 en refusant ou en mettant en file d'attente les agents entrants pour \u00e9viter la surcharge des ressources -LSB-11-RSB-. Du point de vue du propri\u00e9taire de la ressource, cette technique est importante pour \u00e9viter une surcharge de la ressource, mais elle n'est pas suffisante pour une allocation efficace des ressources. Cette technique ne peut que constituer un bon compl\u00e9ment aux m\u00e9canismes d\u2019allocation de ressources distribu\u00e9es. Ces coordinateurs doivent g\u00e9n\u00e9ralement disposer d\u2019une connaissance globale de l\u2019\u00e9tat de toutes les ressources du syst\u00e8me. Un exemple d'algorithme d'allocation dynamique de ressources est le projet Cactus -LSB- 1 -RSB- pour l'allocation de t\u00e2ches de calcul tr\u00e8s co\u00fbteuses. La valeur des solutions distribu\u00e9es pour le probl\u00e8me d'allocation des ressources a \u00e9t\u00e9 reconnue par la recherche -LSB-10-RSB-. Inspir\u00e9s par les principes des march\u00e9s boursiers, des mod\u00e8les de march\u00e9 \u00e9conomiques ont \u00e9t\u00e9 d\u00e9velopp\u00e9s pour \u00e9changer des ressources afin de r\u00e9guler l'offre et la demande sur le r\u00e9seau. Les utilisateurs essaient d'acheter les ressources bon march\u00e9 n\u00e9cessaires \u00e0 l'ex\u00e9cution du travail, tandis que les fournisseurs tentent de r\u00e9aliser le plus de b\u00e9n\u00e9fices possible et d'exploiter les ressources disponibles \u00e0 pleine capacit\u00e9.Une collection de diff\u00e9rentes techniques d'allocation de ressources distribu\u00e9es bas\u00e9es sur des mod\u00e8les de march\u00e9 est pr\u00e9sent\u00e9e dans Clearwater -LSB-10-RSB-. Buyya et coll. a d\u00e9velopp\u00e9 un cadre d'allocation de ressources bas\u00e9 sur la r\u00e9gulation de l'offre et de la demande -LSB- 4 -RSB- pour Nimrod-G -LSB- 6 -RSB- en mettant l'accent principalement sur les d\u00e9lais de travail et les contraintes budg\u00e9taires. Le mod\u00e8le d'allocation de ressources bas\u00e9 sur des agents -LRB-ARAM-RRB- pour les grilles est con\u00e7u pour planifier des t\u00e2ches de calcul co\u00fbteuses \u00e0 l'aide d'agents. L'inconv\u00e9nient de ce mod\u00e8le est l'utilisation intensive de l'\u00e9change de messages entre agents pour une surveillance p\u00e9riodique et l'\u00e9change d'informations au sein de la structure hi\u00e9rarchique. Les sous-t\u00e2ches d'un travail migrent \u00e0 travers le r\u00e9seau jusqu'\u00e0 ce qu'elles trouvent une ressource r\u00e9pondant aux contraintes de prix. L'itin\u00e9raire de migration du travail est d\u00e9termin\u00e9 par les ressources en les connectant dans diff\u00e9rentes topologies -LSB- 17 -RSB-. Le m\u00e9canisme propos\u00e9 dans cet article \u00e9limine le besoin d\u2019\u00e9change p\u00e9riodique d\u2019informations sur les charges de ressources et ne n\u00e9cessite pas de topologie de connexion entre les ressources. De nombreux travaux ont \u00e9t\u00e9 publi\u00e9s ces derni\u00e8res ann\u00e9es sur les techniques d\u2019allocation d\u00e9centralis\u00e9e des ressources utilisant la th\u00e9orie des jeux. Il s\u2019agit d\u2019un probl\u00e8me de d\u00e9cision mal d\u00e9fini qui suppose et mod\u00e9lise un raisonnement inductif. Dans ce jeu de d\u00e9cision r\u00e9p\u00e9titif, un nombre impair d'agents doivent choisir entre deux ressources en fonction des informations de r\u00e9ussite pass\u00e9e, essayant de s'attribuer la ressource avec la minorit\u00e9. Galstyan et coll. -LSB- 14 -RSB- a \u00e9tudi\u00e9 une variation avec plus de deux ressources, changeant les capacit\u00e9s des ressources et les informations des agents voisins. Ils ont montr\u00e9 que les agents peuvent s'adapter efficacement aux capacit\u00e9s changeantes de cet environnement en utilisant un ensemble de tables de recherche simples -LRB-strat\u00e9gies -RRB- par agent. Une autre technique distribu\u00e9e utilis\u00e9e pour r\u00e9soudre le probl\u00e8me d\u2019allocation des ressources est bas\u00e9e sur l\u2019apprentissage par renforcement -LSB-18-RSB-. Semblable \u00e0 notre approche, un ensemble d\u2019agents se disputent un nombre limit\u00e9 de ressources sur la base uniquement de leur exp\u00e9rience individuelle ant\u00e9rieure. Dans ce document, l'objectif du syst\u00e8me est de maximiser le d\u00e9bit du syst\u00e8me tout en garantissant l'\u00e9quit\u00e9 des ressources, mesur\u00e9es par le temps de traitement moyen par unit\u00e9 de travail. Une approche d'allocation de ressources pour les r\u00e9seaux de capteurs bas\u00e9e sur des techniques d'auto-organisation et d'apprentissage par renforcement est pr\u00e9sent\u00e9e dans -LSB-16-RSB- avec un accent principal sur l'optimisation de la consommation d'\u00e9nergie des n\u0153uds du r\u00e9seau. Nous -LSB- 19 -RSB- avons propos\u00e9 une approche d'\u00e9quilibrage de charge auto-organis\u00e9e pour un serveur unique en mettant l'accent sur l'optimisation des co\u00fbts de communication des agents mobiles. Un agent mobile rejettera une migration vers un serveur d'agent distant s'il s'attend \u00e0 ce que le serveur de destination soit d\u00e9j\u00e0 surcharg\u00e9 par d'autres agents ou t\u00e2ches serveur. Les agents prennent eux-m\u00eames leurs d\u00e9cisions sur la base des pr\u00e9visions d'utilisation du serveur. Dans cet article, une solution pour un environnement multi-serveurs est pr\u00e9sent\u00e9e sans tenir compte des co\u00fbts de communication ou de migration. 6.CONCLUSIONS ET TRAVAUX FUTURS Dans cet article, une technique d'allocation de ressources distribu\u00e9e et auto-organis\u00e9e pour les syst\u00e8mes multi-agents a \u00e9t\u00e9 pr\u00e9sent\u00e9e. Nous permettons aux agents de s\u00e9lectionner eux-m\u00eames la plateforme d'ex\u00e9cution pour leurs t\u00e2ches avant chaque ex\u00e9cution au moment de l'ex\u00e9cution. Dans notre approche, les agents sont en comp\u00e9tition pour une allocation \u00e0 l'un des niveaux. Figure 5 : R\u00e9sultats de l'exp\u00e9rience 2 dans un environnement de serveur dynamique en moyenne sur 100 r\u00e9p\u00e9titions. ressource partag\u00e9e disponible. Les agents d\u00e9tectent leur environnement serveur et adoptent leurs actions pour rivaliser plus efficacement dans le nouvel environnement cr\u00e9\u00e9. Ce processus est adaptatif et a une forte r\u00e9troaction car les d\u00e9cisions d'allocation influencent indirectement les d\u00e9cisions des autres agents. L'allocation des ressources est un effet purement \u00e9mergent. Notre m\u00e9canisme d\u00e9montre que l\u2019allocation des ressources peut se faire par la concurrence efficace d\u2019agents individuels et autonomes. Ils n\u2019ont pas non plus besoin de coordination ou d\u2019informations provenant d\u2019une autorit\u00e9 sup\u00e9rieure, ni d\u2019une communication directe suppl\u00e9mentaire entre les agents. Ce m\u00e9canisme s'inspire des principes de raisonnement inductif et de rationalit\u00e9 limit\u00e9e qui permettent aux agents d'adapter leurs strat\u00e9gies pour rivaliser efficacement dans un environnement dynamique. Dans le cas o\u00f9 un serveur devient indisponible, les agents peuvent s'adapter rapidement \u00e0 cette nouvelle situation en explorant de nouvelles ressources ou rester sur le serveur domestique si une allocation n'est pas possible. En particulier dans les environnements dynamiques et \u00e9volutifs tels que les syst\u00e8mes de grille, un m\u00e9canisme robuste et distribu\u00e9 d'allocation des ressources est n\u00e9cessaire. Notre approche d'allocation de ressources auto-organis\u00e9e a \u00e9t\u00e9 \u00e9valu\u00e9e \u00e0 l'aide d'un certain nombre d'exp\u00e9riences de simulation dans un environnement dynamique d'agents et de ressources de serveur. Les r\u00e9sultats pr\u00e9sent\u00e9s pour cette nouvelle approche d\u2019optimisation strat\u00e9gique de la migration sont tr\u00e8s prometteurs et justifient des recherches plus approfondies dans un environnement syst\u00e8me multi-agent r\u00e9el. Il s\u2019agit d\u2019une politique distribu\u00e9e, \u00e9volutive et facile \u00e0 comprendre pour la r\u00e9gulation de l\u2019offre et de la demande de ressources. Tout contr\u00f4le est impl\u00e9ment\u00e9 dans les agents. Un m\u00e9canisme de d\u00e9cision simple bas\u00e9 sur diff\u00e9rentes croyances de l\u2019agent cr\u00e9e un comportement \u00e9mergent qui conduit \u00e0 une allocation efficace des ressources. Cette approche peut \u00eatre facilement \u00e9tendue ou prise en charge par des m\u00e9canismes d\u2019\u00e9quilibrage/file d\u2019attente des ressources fournis par les ressources. Notre approche s'adapte aux changements de l'environnement mais elle n'est pas \u00e9volutive. Il n\u2019y a pas de d\u00e9couverte de nouvelles strat\u00e9gies par les agents. \u00e9tudi\u00e9 \u00e0 l\u2019avenir. Dans un avenir proche, nous \u00e9tudierons si une adaptation automatique du taux de d\u00e9gradation des informations historiques de notre algorithme est possible et peut am\u00e9liorer les performances d'allocation des ressources. Un grand nombre de ressources partag\u00e9es n\u00e9cessite des informations historiques plus anciennes pour \u00e9viter une exploration trop fr\u00e9quente des ressources. En revanche, un environnement dynamique avec des capacit\u00e9s variables n\u00e9cessite des informations plus r\u00e9centes pour pouvoir faire des pr\u00e9visions plus fiables.Nous sommes conscients de la longue phase d\u2019apprentissage dans les environnements comportant un grand nombre de ressources partag\u00e9es connues par chaque agent. Dans le cas o\u00f9 plus de ressources sont demand\u00e9es par les agents que de ressources partag\u00e9es n'en sont fournies par tous les serveurs, tous les agents exploreront de mani\u00e8re al\u00e9atoire tous les serveurs connus. Ce processus d'acquisition d'informations sur la charge des ressources sur tous les serveurs peut prendre beaucoup de temps dans le cas o\u00f9 il n'y a pas suffisamment de ressources partag\u00e9es pour toutes les t\u00e2ches. Dans cette situation, il est difficile pour un agent de collecter efficacement des informations historiques sur tous les serveurs distants. Cette question n\u00e9cessite une enqu\u00eate plus approfondie \u00e0 l\u2019avenir.", "keyphrases": ["syst\u00e8me multi-agents", "agent", "allocation de ressources", "algorithme de distribution", "t\u00e2che d'allocation dynamique", "r\u00e9seau de serveur", "utilisation du serveur", "adapter le processus", "concourir", "pr\u00e9dicteur"]}
{"file_name": "J-14", "text": "Calcul des bons \u00e9quilibres de Nash dans les jeux graphiques * R\u00c9SUM\u00c9 Cet article aborde le probl\u00e8me de la s\u00e9lection d'\u00e9quilibre \u00e9quitable dans les jeux graphiques. Notre approche est bas\u00e9e sur la structure de donn\u00e9es appel\u00e9e politique de meilleure r\u00e9ponse, propos\u00e9e par Kearns et al. -LSB- 13 -RSB- comme moyen de repr\u00e9senter tous les \u00e9quilibres de Nash d'un jeu graphique. Dans -LSB-9-RSB-, il a \u00e9t\u00e9 montr\u00e9 que la meilleure politique de r\u00e9ponse a une taille polynomiale tant que le graphe sous-jacent est un chemin. Dans cet article, nous montrons que si le graphe sous-jacent est un arbre \u00e0 degr\u00e9s born\u00e9s et que la meilleure politique de r\u00e9ponse a une taille polynomiale, alors il existe un algorithme efficace qui construit un \u00e9quilibre de Nash qui garantit certains gains \u00e0 tous les participants. Un autre concept de solution int\u00e9ressant est un \u00e9quilibre de Nash qui maximise le bien-\u00eatre social. Nous montrons que, bien que le calcul exact de ce dernier soit irr\u00e9alisable -LRB-, nous prouvons que la r\u00e9solution de ce probl\u00e8me peut impliquer des nombres alg\u00e9briques d'un degr\u00e9 arbitrairement \u00e9lev\u00e9 -RRB-, il existe un FPTAS pour trouver un tel \u00e9quilibre tant que la meilleure politique de r\u00e9ponse a taille polynomiale. Ces deux algorithmes peuvent \u00eatre combin\u00e9s pour produire des \u00e9quilibres de Nash satisfaisant divers crit\u00e8res d\u2019\u00e9quit\u00e9. 1. INTRODUCTION C'est l'intuition derri\u00e8re les jeux graphiques, qui ont \u00e9t\u00e9 introduits par Kearns, Littman et Singh dans -LSB- 13 -RSB- comme un sch\u00e9ma de repr\u00e9sentation compact pour les jeux avec de nombreux joueurs. Dans un jeu graphique \u00e0 n joueurs, chaque joueur est associ\u00e9 \u00e0 un sommet d'un graphe sous-jacent G, et les gains de chaque joueur d\u00e9pendent de son action ainsi que des actions de ses voisins dans le graphe. Si le degr\u00e9 maximum de G est \u0394 et que chaque joueur dispose de deux actions, alors le jeu peut \u00eatre repr\u00e9sent\u00e9 en utilisant n2\u0394 +1 nombres. En revanche, nous avons besoin de n2n nombres pour repr\u00e9senter un jeu g\u00e9n\u00e9ral \u00e0 2 actions \u00e0 n joueurs, ce qui n\u2019est pratique que pour de petites valeurs de n. Pour les jeux graphiques \u00e0 \u0394 constant, la taille du jeu est lin\u00e9aire en n. L'un des probl\u00e8mes les plus naturels pour un jeu graphique est celui de trouver un \u00e9quilibre de Nash, dont l'existence d\u00e9coule du c\u00e9l\u00e8bre th\u00e9or\u00e8me de Nash -LRB- car les jeux graphiques ne sont qu'un cas particulier des jeux \u00e0 n joueurs -RRB-. La premi\u00e8re tentative pour r\u00e9soudre ce probl\u00e8me a \u00e9t\u00e9 faite dans -LSB- 13 -RSB-, o\u00f9 les auteurs consid\u00e8rent des jeux graphiques avec deux actions par joueur dans lesquels le graphe sous-jacent est un arbre \u00e0 degr\u00e9s born\u00e9. Ils proposent un algorithme g\u00e9n\u00e9rique pour trouver les \u00e9quilibres de Nash qui peut \u00eatre sp\u00e9cialis\u00e9 de deux mani\u00e8res\u00a0: un algorithme en temps exponentiel pour trouver un \u00e9quilibre -LRB- exact -RRB- de Nash, et un sch\u00e9ma d'approximation temporelle enti\u00e8rement polynomial -LRB- FPTAS -RRB- pour trouver une approximation d'un \u00e9quilibre de Nash. Pour tout e > 0, cet algorithme g\u00e9n\u00e8re un \u00e9quilibre e-Nash, qui est un profil strat\u00e9gique dans lequel aucun joueur ne peut am\u00e9liorer son gain de plus de e en changeant unilat\u00e9ralement sa strat\u00e9gie. Bien que les \u00e9quilibres e-Nash soient souvent plus faciles \u00e0 calculer que les \u00e9quilibres de Nash exacts, ce concept de solution pr\u00e9sente plusieurs inconv\u00e9nients. D'abord,les joueurs peuvent \u00eatre sensibles \u00e0 une petite perte de gains, donc le profil strat\u00e9gique qui est un \u00e9quilibre e-Nash ne sera pas stable. Deuxi\u00e8mement, les profils de strat\u00e9gie proches des \u00e9quilibres de Nash peuvent \u00eatre bien meilleurs en ce qui concerne les propri\u00e9t\u00e9s consid\u00e9r\u00e9es que les \u00e9quilibres de Nash exacts. Par cons\u00e9quent, l'approximation -LRB- de la valeur -RRB- de la meilleure solution qui correspond \u00e0 un \u00e9quilibre e-Nash peut ne pas \u00eatre indicative de ce qui peut \u00eatre obtenu dans un \u00e9quilibre de Nash exact. Ceci est particuli\u00e8rement important si le but de la solution approch\u00e9e est de fournir un bon point de r\u00e9f\u00e9rence pour un syst\u00e8me d\u2019agents \u00e9go\u00efstes, car le point de r\u00e9f\u00e9rence impliqu\u00e9 par un \u00e9quilibre e-Nash peut s\u2019av\u00e9rer irr\u00e9aliste. Pour ces raisons, dans cet article, nous nous concentrons sur le probl\u00e8me du calcul des \u00e9quilibres de Nash exacts. S'appuyant sur les id\u00e9es de -LSB- 14 -RSB-, Elkind et al. -LSB- 9 -RSB- a montr\u00e9 comment trouver un \u00e9quilibre de Nash -LRB- exact -RRB- en temps polynomial lorsque le sous-jacent. En revanche, trouver un \u00e9quilibre de Nash dans un graphe g\u00e9n\u00e9ral born\u00e9 par des degr\u00e9s semble \u00eatre une t\u00e2che difficile \u00e0 r\u00e9soudre : cela a \u00e9t\u00e9 montr\u00e9 -LRB- voir -LSB- 5, 12, 7 -RSB- -RRB- pour \u00eatre complet pour la classe de complexit\u00e9 PPAD. -LSB- 9 -RSB- \u00e9tend ce r\u00e9sultat de duret\u00e9 au cas dans lequel le graphe sous-jacent a une largeur de trajet limit\u00e9e. Un jeu graphique peut ne pas avoir d\u2019\u00e9quilibre de Nash unique, il peut m\u00eame en avoir un nombre exponentiel. De plus, certains \u00e9quilibres de Nash sont plus souhaitables que d\u2019autres. Plut\u00f4t que d'avoir un algorithme qui trouve simplement un \u00e9quilibre de Nash, nous aimerions avoir des algorithmes pour trouver des \u00e9quilibres de Nash avec diverses propri\u00e9t\u00e9s socialement souhaitables, telles que la maximisation du gain global ou la r\u00e9partition \u00e9quitable des b\u00e9n\u00e9fices. Une propri\u00e9t\u00e9 utile de la structure de donn\u00e9es de -LSB- 13 -RSB- est qu'elle repr\u00e9sente simultan\u00e9ment l'ensemble de tous les \u00e9quilibres de Nash du jeu sous-jacent. Si cette repr\u00e9sentation a une taille polynomiale -LRB- comme c'est le cas pour les chemins, comme le montre -LSB- 9 -RSB- -RRB-, on peut esp\u00e9rer en extraire un \u00e9quilibre de Nash avec les propri\u00e9t\u00e9s souhait\u00e9es. En fait, dans -LSB- 13 -RSB-, les auteurs mentionnent que cela est effectivement possible si l'on souhaite trouver un \u00e9quilibre -LRB- approximatif -RRB-a-Nash. Le but de cet article est d\u2019\u00e9tendre cela aux \u00e9quilibres de Nash exacts. 1.1 Nos r\u00e9sultats Dans cet article, nous \u00e9tudions des jeux graphiques \u00e0 2 actions \u00e0 n joueurs sur des arbres \u00e0 degr\u00e9s born\u00e9s pour lesquels la structure de donn\u00e9es de -LSB- 13 -RSB- a une taille poly -LRB- n -RRB-. Nous nous concentrons sur le probl\u00e8me de trouver des \u00e9quilibres de Nash exacts avec certaines propri\u00e9t\u00e9s socialement d\u00e9sirables. En particulier, nous montrons comment trouver un \u00e9quilibre de Nash qui -LRB- presque -RRB- maximise le bien-\u00eatre social, c'est-\u00e0-dire la somme des gains des joueurs, et nous montrons comment trouver un \u00e9quilibre de Nash qui -LRB- presque -RRB - satisfait aux limites de gains prescrites pour tous les joueurs. Les jeux graphiques sur arbres \u00e0 degr\u00e9s born\u00e9s ont une structure alg\u00e9brique simple. Une caract\u00e9ristique int\u00e9ressante, qui d\u00e9coule de -LSB- 13 -RSB-,est que chacun de ces jeux a un \u00e9quilibre de Nash dans lequel la strat\u00e9gie de chaque joueur est un nombre rationnel. La section 3 \u00e9tudie la structure alg\u00e9brique des \u00e9quilibres de Nash qui maximisent le bien-\u00eatre social. Nous montrons -LRB- Th\u00e9or\u00e8mes 1 et 2 -RRB- que, de mani\u00e8re surprenante, l'ensemble des \u00e9quilibres de Nash qui maximisent le bien-\u00eatre social est plus complexe. Il semble que ce soit une caract\u00e9ristique nouvelle du context que nous consid\u00e9rons ici, qu\u2019un \u00e9quilibre de Nash optimal soit difficile \u00e0 repr\u00e9senter, dans une situation o\u00f9 il est facile de trouver et de repr\u00e9senter un \u00e9quilibre de Nash. Comme l\u2019\u00e9quilibre de Nash maximisant le bien-\u00eatre social peut \u00eatre difficile \u00e0 repr\u00e9senter efficacement, nous devons nous contenter d\u2019une approximation. Cependant, la diff\u00e9rence cruciale entre notre approche et celle des articles pr\u00e9c\u00e9dents -LSB- 13, 16, 19 -RSB- est que nous exigeons que notre algorithme produise un \u00e9quilibre de Nash exact, mais pas n\u00e9cessairement optimal par rapport \u00e0 nos crit\u00e8res. Dans la section 4, nous d\u00e9crivons un algorithme qui satisfait \u00e0 cette exigence. Nous proposons notamment un algorithme qui, pour tout e > 0, trouve un \u00e9quilibre de Nash dont le gain total se situe dans les limites de a de l'optimal. Des r\u00e9sultats plus proches de Pre1A dans un context diff\u00e9rent ont \u00e9t\u00e9 obtenus par Datta -LSB- 8 -RSB-, qui montre que les jeux d'action \u00e0 n joueurs et \u00e0 2 sont universels dans le sens o\u00f9 toute vari\u00e9t\u00e9 alg\u00e9brique r\u00e9elle peut \u00eatre repr\u00e9sent\u00e9e comme l'ensemble de Nash totalement mixtes. \u00e9quilibres de tels jeux. Nous montrons -LRB- Section 4.1 -RRB- que sous certaines restrictions sur les matrices de gains, l'algorithme peut \u00eatre transform\u00e9 en un -LRB- v\u00e9ritablement -RRB- algorithme en temps polynomial qui produit un \u00e9quilibre de Nash dont le gain total est compris dans un 1 \u2212 e facteur de l\u2019optimal. Dans la section 5, nous consid\u00e9rons le probl\u00e8me de trouver un \u00e9quilibre de Nash dans lequel le gain attendu de chaque joueur Vi d\u00e9passe un seuil Ti prescrit. En utilisant l'id\u00e9e de la section 4, nous donnons -LRB- Th\u00e9or\u00e8me 5 -RRB- un sch\u00e9ma d'approximation temporelle enti\u00e8rement polynomiale pour ce probl\u00e8me. Le temps d'ex\u00e9cution de l'algorithme est limit\u00e9 par un polyn\u00f4me en n, Pmax et E. Si l'instance a un \u00e9quilibre de Nash satisfaisant les seuils prescrits, alors l'algorithme construit un \u00e9quilibre de Nash dans lequel le gain attendu de chaque joueur Vi est d'au moins Ti. \u2212 E. Dans la section 6, nous introduisons d'autres crit\u00e8res naturels pour s\u00e9lectionner un \u00ab\u00a0bon\u00a0\u00bb \u00e9quilibre de Nash et nous montrons que les algorithmes d\u00e9crits dans les deux sections pr\u00e9c\u00e9dentes peuvent \u00eatre utilis\u00e9s comme \u00e9l\u00e9ments de base pour trouver des \u00e9quilibres de Nash qui satisfont \u00e0 ces crit\u00e8res. En particulier, dans la section 6.1, nous montrons comment trouver un \u00e9quilibre de Nash qui se rapproche du bien-\u00eatre social maximum, tout en garantissant que chaque gain individuel est proche d'un seuil prescrit. Dans la section 6.2, nous montrons comment trouver un \u00e9quilibre de Nash qui -LRB- presque -RRB- maximise le gain individuel minimum. Enfin, dans la section 6.3, nous montrons comment trouver un \u00e9quilibre de Nash dans lequel les gains individuels des joueurs sont proches les uns des autres. 1.2 Travaux connexes Notre sch\u00e9ma d'approximation -LRB- Th\u00e9or\u00e8me 3 et Th\u00e9or\u00e8me 4 -RRB- montre un contraste entre les jeux que nous \u00e9tudions et les jeux n-action \u00e0 deux joueurs, pour lesquels les probl\u00e8mes correspondants sont g\u00e9n\u00e9ralement insolubles. Pour les jeux n-action \u00e0 deux joueurs, le probl\u00e8me de la recherche d\u2019\u00e9quilibres de Nash avec des propri\u00e9t\u00e9s sp\u00e9ciales est g\u00e9n\u00e9ralement NP-difficile. C'est notamment le cas des \u00e9quilibres de Nash qui maximisent le bien-\u00eatre social -LSB- 11, 6 -RSB-. De plus, il sera probablement difficile m\u00eame de se rapprocher de tels \u00e9quilibres. En particulier, Chen, Deng et Teng -LSB- 4 -RSB- montrent qu'il existe un e, polyn\u00f4me inverse en n, pour lequel le calcul d'un \u00e9quilibre e-Nash dans des jeux \u00e0 2 joueurs avec n actions par joueur est PPAD-complet. Lipton et Markakis -LSB- 15 -RSB- \u00e9tudient les propri\u00e9t\u00e9s alg\u00e9briques des \u00e9quilibres de Nash et soulignent que des algorithmes standard d'\u00e9limination de quantificateurs peuvent \u00eatre utilis\u00e9s pour les r\u00e9soudre. Notez que ces algorithmes ne sont pas en temps polynomial en g\u00e9n\u00e9ral. Les jeux que nous \u00e9tudions dans cet article ont des \u00e9quilibres de Nash calculables en temps polynomial dans lesquels toutes les strat\u00e9gies mixtes sont des nombres rationnels, mais un \u00e9quilibre de Nash optimal peut n\u00e9cessairement inclure des strat\u00e9gies mixtes avec un degr\u00e9 alg\u00e9brique \u00e9lev\u00e9. Tout \u00e9quilibre de Nash est un CE mais l\u2019inverse n\u2019est pas vrai en g\u00e9n\u00e9ral. Contrairement aux \u00e9quilibres de Nash, des \u00e9quilibres corr\u00e9l\u00e9s peuvent \u00eatre trouv\u00e9s pour les jeux graphiques de bas degr\u00e9 -LRB- ainsi que pour d'autres classes de jeux multijoueurs repr\u00e9sent\u00e9s de mani\u00e8re concise -RRB- en temps polynomial -LSB- 17 -RSB-. Mais, pour les jeux graphiques, il est NP-difficile de trouver un \u00e9quilibre corr\u00e9l\u00e9 qui maximise le gain total -LSB-18-RSB-. Cependant, les r\u00e9sultats NP-duret\u00e9 s\u2019appliquent \u00e0 des jeux plus g\u00e9n\u00e9raux que celui que nous consid\u00e9rons ici, en particulier les graphes ne sont pas des arbres. D'apr\u00e8s -LSB- 2 -RSB-, on sait \u00e9galement qu'il existe des jeux \u00e0 2 joueurs et 2 actions pour lesquels le gain total attendu du meilleur \u00e9quilibre corr\u00e9l\u00e9 est sup\u00e9rieur au meilleur \u00e9quilibre de Nash, et nous discutons de cette question plus en d\u00e9tail dans la section 7. 7. CONCLUSIONS Nous avons \u00e9tudi\u00e9 le probl\u00e8me de la s\u00e9lection d'\u00e9quilibre dans les jeux graphiques sur arbres \u00e0 degr\u00e9s born\u00e9s. Nous avons consid\u00e9r\u00e9 plusieurs crit\u00e8res pour s\u00e9lectionner un \u00e9quilibre de Nash, tels que maximiser le bien-\u00eatre social, garantir une limite inf\u00e9rieure sur le gain attendu de chaque joueur, etc. Premi\u00e8rement, nous nous sommes concentr\u00e9s sur la complexit\u00e9 alg\u00e9brique d'un \u00e9quilibre de Nash maximisant le bien-\u00eatre social, et se sont r\u00e9v\u00e9l\u00e9s tr\u00e8s n\u00e9gatifs pour ce probl\u00e8me. En particulier, nous avons montr\u00e9 que m\u00eame pour les jeux graphiques sur les chemins, tout nombre alg\u00e9brique \u03b1 E -LSB- 0, 1 -RSB- peut \u00eatre la seule strat\u00e9gie disponible pour certains joueurs dans tous les \u00e9quilibres de Nash maximisant le bien-\u00eatre social. Cela contraste fortement avec le fait que les jeux graphiques sur les arbres poss\u00e8dent toujours un \u00e9quilibre de Nash dans lequel les strat\u00e9gies de tous les joueurs sont des nombres rationnels. Nous avons ensuite fourni des algorithmes d'approximation pour s\u00e9lectionner des \u00e9quilibres de Nash dot\u00e9s de propri\u00e9t\u00e9s sp\u00e9ciales. Bien que le probl\u00e8me de la recherche d'\u00e9quilibres de Nash approximatifs pour diverses classes de jeux ait re\u00e7u beaucoup d'attention ces derni\u00e8res ann\u00e9es,la plupart des travaux existants visent \u00e0 trouver des \u00e9quilibres E-Nash qui satisfont -LRB- ou sont E-proches de satisfaire -RRB- certaines propri\u00e9t\u00e9s. Notre approche est diff\u00e9rente dans la mesure o\u00f9 nous insistons sur la production d\u2019un \u00e9quilibre de Nash exact, qui est E-proche de satisfaire une exigence donn\u00e9e. Comme indiqu\u00e9 dans l\u2019introduction, il existe plusieurs raisons de pr\u00e9f\u00e9rer une solution qui constitue un \u00e9quilibre de Nash exact. Bien que nous prouvions nos r\u00e9sultats pour les jeux sur un chemin, ils peuvent \u00eatre g\u00e9n\u00e9ralis\u00e9s \u00e0 tout arbre pour lequel les meilleures politiques de r\u00e9ponse ont des repr\u00e9sentations compactes sous forme d\u2019unions de rectangles. Dans la version compl\u00e8te de l'article, nous d\u00e9crivons nos algorithmes pour le cas g\u00e9n\u00e9ral. Des travaux suppl\u00e9mentaires dans ce sens pourraient inclure des extensions aux types de garanties recherch\u00e9es pour les \u00e9quilibres de Nash, telles que la garantie de gains totaux pour des sous-ensembles d'acteurs, la s\u00e9lection d'\u00e9quilibres dans lesquels certains acteurs re\u00e7oivent des gains significativement plus \u00e9lev\u00e9s que leurs pairs, etc. , il est peut-\u00eatre plus important de rechercher si les \u00e9quilibres de Nash des jeux graphiques peuvent \u00eatre calcul\u00e9s de mani\u00e8re d\u00e9centralis\u00e9e, contrairement aux algorithmes que nous avons introduits ici. Il est naturel de se demander si nos r\u00e9sultats ou ceux de -LSB- 9 -RSB- peuvent \u00eatre g\u00e9n\u00e9ralis\u00e9s aux jeux \u00e0 trois actions ou plus. Il semble toutefois que cela rendra l\u2019analyse beaucoup plus difficile. En particulier, notons que l\u2019on peut consid\u00e9rer les jeux \u00e0 gains limit\u00e9s comme un cas particulier tr\u00e8s limit\u00e9 de jeux avec trois actions par joueur. \u00c0 savoir, \u00e9tant donn\u00e9 un jeu \u00e0 deux actions avec des limites de gain, consid\u00e9rons un jeu dans lequel chaque joueur Vi a une troisi\u00e8me action qui lui garantit un gain de Ti, peu importe ce que font les autres. Ensuite, v\u00e9rifier s'il existe un \u00e9quilibre de Nash dans lequel aucun des joueurs n'attribue une probabilit\u00e9 non nulle \u00e0 sa troisi\u00e8me action \u00e9quivaut \u00e0 v\u00e9rifier s'il existe un \u00e9quilibre de Nash qui satisfait les limites de gain dans le jeu original, et la section 5.1 montre que trouver un \u00e9quilibre de Nash qui satisfait les limites de gain dans le jeu original, et la section 5.1 montre que trouver un \u00e9quilibre de Nash qui satisfait les limites de gain dans le jeu original. la solution \u00e0 ce probl\u00e8me n\u00e9cessite de nouvelles id\u00e9es. Alternativement, il peut \u00eatre int\u00e9ressant de rechercher des r\u00e9sultats similaires dans le context d'\u00e9quilibres corr\u00e9l\u00e9s -LRB- CE -RRB-, d'autant plus que le meilleur CE peut avoir une valeur -LRB- de gain total attendu -RRB- plus \u00e9lev\u00e9e que le meilleur NE. On sait d'apr\u00e8s -LSB- 1 -RSB- que la valeur de m\u00e9diation des jeux \u00e0 2 joueurs et 2 actions avec des gains non n\u00e9gatifs est d'au plus 43, et ils pr\u00e9sentent un jeu \u00e0 3 joueurs pour lequel elle est infinie.Dans la version compl\u00e8te de l'article, nous d\u00e9crivons nos algorithmes pour le cas g\u00e9n\u00e9ral. Des travaux suppl\u00e9mentaires dans ce sens pourraient inclure des extensions aux types de garanties recherch\u00e9es pour les \u00e9quilibres de Nash, telles que la garantie de gains totaux pour des sous-ensembles d'acteurs, la s\u00e9lection d'\u00e9quilibres dans lesquels certains acteurs re\u00e7oivent des gains significativement plus \u00e9lev\u00e9s que leurs pairs, etc. , il est peut-\u00eatre plus important de rechercher si les \u00e9quilibres de Nash des jeux graphiques peuvent \u00eatre calcul\u00e9s de mani\u00e8re d\u00e9centralis\u00e9e, contrairement aux algorithmes que nous avons introduits ici. Il est naturel de se demander si nos r\u00e9sultats ou ceux de -LSB- 9 -RSB- peuvent \u00eatre g\u00e9n\u00e9ralis\u00e9s aux jeux \u00e0 trois actions ou plus. Il semble toutefois que cela rendra l\u2019analyse beaucoup plus difficile. En particulier, notons que l\u2019on peut consid\u00e9rer les jeux \u00e0 gains limit\u00e9s comme un cas particulier tr\u00e8s limit\u00e9 de jeux avec trois actions par joueur. \u00c0 savoir, \u00e9tant donn\u00e9 un jeu \u00e0 deux actions avec des limites de gain, consid\u00e9rons un jeu dans lequel chaque joueur Vi a une troisi\u00e8me action qui lui garantit un gain de Ti, peu importe ce que font les autres. Ensuite, v\u00e9rifier s'il existe un \u00e9quilibre de Nash dans lequel aucun des joueurs n'attribue une probabilit\u00e9 non nulle \u00e0 sa troisi\u00e8me action \u00e9quivaut \u00e0 v\u00e9rifier s'il existe un \u00e9quilibre de Nash qui satisfait les limites de gain dans le jeu original, et la section 5.1 montre que trouver un \u00e9quilibre de Nash qui satisfait les limites de gain dans le jeu original, et la section 5.1 montre que trouver un \u00e9quilibre de Nash qui satisfait les limites de gain dans le jeu original. la solution \u00e0 ce probl\u00e8me n\u00e9cessite de nouvelles id\u00e9es. Alternativement, il peut \u00eatre int\u00e9ressant de rechercher des r\u00e9sultats similaires dans le context d'\u00e9quilibres corr\u00e9l\u00e9s -LRB- CE -RRB-, d'autant plus que le meilleur CE peut avoir une valeur -LRB- de gain total attendu -RRB- plus \u00e9lev\u00e9e que le meilleur NE. On sait d'apr\u00e8s -LSB- 1 -RSB- que la valeur de m\u00e9diation des jeux \u00e0 2 joueurs et 2 actions avec des gains non n\u00e9gatifs est d'au plus 43, et ils pr\u00e9sentent un jeu \u00e0 3 joueurs pour lequel elle est infinie.Dans la version compl\u00e8te de l'article, nous d\u00e9crivons nos algorithmes pour le cas g\u00e9n\u00e9ral. Des travaux suppl\u00e9mentaires dans ce sens pourraient inclure des extensions aux types de garanties recherch\u00e9es pour les \u00e9quilibres de Nash, telles que la garantie de gains totaux pour des sous-ensembles d'acteurs, la s\u00e9lection d'\u00e9quilibres dans lesquels certains acteurs re\u00e7oivent des gains significativement plus \u00e9lev\u00e9s que leurs pairs, etc. , il est peut-\u00eatre plus important de rechercher si les \u00e9quilibres de Nash des jeux graphiques peuvent \u00eatre calcul\u00e9s de mani\u00e8re d\u00e9centralis\u00e9e, contrairement aux algorithmes que nous avons introduits ici. Il est naturel de se demander si nos r\u00e9sultats ou ceux de -LSB- 9 -RSB- peuvent \u00eatre g\u00e9n\u00e9ralis\u00e9s aux jeux \u00e0 trois actions ou plus. Il semble toutefois que cela rendra l\u2019analyse beaucoup plus difficile. En particulier, notons que l\u2019on peut consid\u00e9rer les jeux \u00e0 gains limit\u00e9s comme un cas particulier tr\u00e8s limit\u00e9 de jeux avec trois actions par joueur. \u00c0 savoir, \u00e9tant donn\u00e9 un jeu \u00e0 deux actions avec des limites de gain, consid\u00e9rons un jeu dans lequel chaque joueur Vi a une troisi\u00e8me action qui lui garantit un gain de Ti, peu importe ce que font les autres. Ensuite, v\u00e9rifier s'il existe un \u00e9quilibre de Nash dans lequel aucun des joueurs n'attribue une probabilit\u00e9 non nulle \u00e0 sa troisi\u00e8me action \u00e9quivaut \u00e0 v\u00e9rifier s'il existe un \u00e9quilibre de Nash qui satisfait les limites de gain dans le jeu original, et la section 5.1 montre que trouver un \u00e9quilibre de Nash qui satisfait les limites de gain dans le jeu original, et la section 5.1 montre que trouver un \u00e9quilibre de Nash qui satisfait les limites de gain dans le jeu original. la solution \u00e0 ce probl\u00e8me n\u00e9cessite de nouvelles id\u00e9es. Alternativement, il peut \u00eatre int\u00e9ressant de rechercher des r\u00e9sultats similaires dans le context d'\u00e9quilibres corr\u00e9l\u00e9s -LRB- CE -RRB-, d'autant plus que le meilleur CE peut avoir une valeur -LRB- de gain total attendu -RRB- plus \u00e9lev\u00e9e que le meilleur NE. On sait d'apr\u00e8s -LSB- 1 -RSB- que la valeur de m\u00e9diation des jeux \u00e0 2 joueurs et 2 actions avec des gains non n\u00e9gatifs est d'au plus 43, et ils pr\u00e9sentent un jeu \u00e0 3 joueurs pour lequel elle est infinie.Ensuite, v\u00e9rifier s'il existe un \u00e9quilibre de Nash dans lequel aucun des joueurs n'attribue une probabilit\u00e9 non nulle \u00e0 sa troisi\u00e8me action \u00e9quivaut \u00e0 v\u00e9rifier s'il existe un \u00e9quilibre de Nash qui satisfait les limites de gain dans le jeu original, et la section 5.1 montre que trouver un \u00e9quilibre de Nash qui satisfait les limites de gain dans le jeu original, et la section 5.1 montre que trouver un \u00e9quilibre de Nash qui satisfait les limites de gain dans le jeu original. la solution \u00e0 ce probl\u00e8me n\u00e9cessite de nouvelles id\u00e9es. Alternativement, il peut \u00eatre int\u00e9ressant de rechercher des r\u00e9sultats similaires dans le context d'\u00e9quilibres corr\u00e9l\u00e9s -LRB- CE -RRB-, d'autant plus que le meilleur CE peut avoir une valeur -LRB- de gain total attendu -RRB- plus \u00e9lev\u00e9e que le meilleur NE. On sait d'apr\u00e8s -LSB- 1 -RSB- que la valeur de m\u00e9diation des jeux \u00e0 2 joueurs et 2 actions avec des gains non n\u00e9gatifs est d'au plus 43, et ils pr\u00e9sentent un jeu \u00e0 3 joueurs pour lequel elle est infinie.Ensuite, v\u00e9rifier s'il existe un \u00e9quilibre de Nash dans lequel aucun des joueurs n'attribue une probabilit\u00e9 non nulle \u00e0 sa troisi\u00e8me action \u00e9quivaut \u00e0 v\u00e9rifier s'il existe un \u00e9quilibre de Nash qui satisfait les limites de gain dans le jeu original, et la section 5.1 montre que trouver un \u00e9quilibre de Nash qui satisfait les limites de gain dans le jeu original, et la section 5.1 montre que trouver un \u00e9quilibre de Nash qui satisfait les limites de gain dans le jeu original. la solution \u00e0 ce probl\u00e8me n\u00e9cessite de nouvelles id\u00e9es. Alternativement, il peut \u00eatre int\u00e9ressant de rechercher des r\u00e9sultats similaires dans le context d'\u00e9quilibres corr\u00e9l\u00e9s -LRB- CE -RRB-, d'autant plus que le meilleur CE peut avoir une valeur -LRB- de gain total attendu -RRB- plus \u00e9lev\u00e9e que le meilleur NE. On sait d'apr\u00e8s -LSB- 1 -RSB- que la valeur de m\u00e9diation des jeux \u00e0 2 joueurs et 2 actions avec des gains non n\u00e9gatifs est d'au plus 43, et ils pr\u00e9sentent un jeu \u00e0 3 joueurs pour lequel elle est infinie.", "keyphrases": ["jeu graphique", "\u00e9quilibre de Nash", "sch\u00e9ma approximatif", "algorithme \u00e0 temps exponenti", "approximatif", "diverses propri\u00e9t\u00e9s socialement d\u00e9sir\u00e9es", "gain global", "distribuer les b\u00e9n\u00e9fices", "protection sociale", "jeu graphique \u00e0 gain int\u00e9gral g", "grave inconv\u00e9nient", "profil strat\u00e9gique", "graphique li\u00e9 aux degr\u00e9s"]}
{"file_name": "I-22", "text": "Mod\u00e9lisation r\u00e9aliste de la charge cognitive pour am\u00e9liorer les mod\u00e8les mentaux partag\u00e9s dans la collaboration homme-agent R\u00c9SUM\u00c9 Les membres d'une \u00e9quipe humaine d\u00e9veloppent souvent des attentes communes pour pr\u00e9dire les besoins de chacun et coordonner leurs comportements. Dans cet article, le concept \u00ab\u00a0Carte de croyances partag\u00e9es\u00a0\u00bb est propos\u00e9 comme base pour d\u00e9velopper des attentes partag\u00e9es r\u00e9alistes au sein d'une \u00e9quipe de paires homme-agent -LRB-HAPs-RRB-. L'\u00e9tablissement de cartes de croyances partag\u00e9es repose sur le partage d'informations entre agents, dont l'efficacit\u00e9 d\u00e9pend fortement des charges de traitement des agents et des charges cognitives instantan\u00e9es de leurs partenaires humains. Nous \u00e9tudions des mod\u00e8les de charge cognitive bas\u00e9s sur HMM pour aider les membres de l'\u00e9quipe \u00e0 \u00ab partager la bonne information avec la bonne partie au bon moment \u00bb. Le concept de carte de croyance partag\u00e9e et les mod\u00e8les de charge cognitive/de traitement ont \u00e9t\u00e9 impl\u00e9ment\u00e9s dans une architecture d'agent cognitif -- SMMall. Une s\u00e9rie d'exp\u00e9riences ont \u00e9t\u00e9 men\u00e9es pour \u00e9valuer le concept, les mod\u00e8les et leurs impacts sur l'\u00e9volution des mod\u00e8les mentaux partag\u00e9s des \u00e9quipes HAP. 1. INTRODUCTION Le travail d'\u00e9quipe multi-agents centr\u00e9 sur l'humain a ainsi attir\u00e9 une attention croissante dans le domaine des syst\u00e8mes multi-agents -LSB- 2, 10, 4 -RSB-. Humains et autonomes En bref, les humains et les agents peuvent faire \u00e9quipe pour obtenir de meilleures performances, \u00e9tant donn\u00e9 qu'ils pourraient \u00e9tablir une certaine conscience mutuelle pour coordonner leurs activit\u00e9s d'initiative mixte. Cependant, les fondements de la collaboration homme-agent continuent d\u2019\u00eatre remis en question en raison d\u2019une mod\u00e9lisation non r\u00e9aliste de la conscience mutuelle de l\u2019\u00e9tat des choses. En particulier, peu de chercheurs vont au-del\u00e0 pour \u00e9valuer les principes de mod\u00e9lisation des constructions mentales partag\u00e9es entre un humain et son agent qui l'assiste. De plus, les relations homme-agent peuvent aller du simple partenaire \u00e0 l\u2019\u00e9quipe. Par cons\u00e9quent, il existe une demande claire d\u2019enqu\u00eates pour \u00e9largir et approfondir notre compr\u00e9hension des principes de mod\u00e9lisation mentale partag\u00e9e entre les membres d\u2019une \u00e9quipe mixte humain-agent. Il existe des axes de recherche sur le travail en \u00e9quipe multi-agents, tant sur le plan th\u00e9orique qu'empirique. Par exemple, Joint Intention -LSB- 3 -RSB- et SharedPlans -LSB- 5 -RSB- sont deux cadres th\u00e9oriques pour sp\u00e9cifier les collaborations d'agents. L\u2019un des inconv\u00e9nients est que, bien que tous deux aient une profonde racine philosophique et cognitive, ils ne permettent pas de mod\u00e9liser les membres humains d\u2019une \u00e9quipe. Des \u00e9tudes cognitives sugg\u00e8rent que les \u00e9quipes qui ont partag\u00e9 des mod\u00e8les mentaux devraient avoir des attentes communes \u00e0 l'\u00e9gard de la t\u00e2che et de l'\u00e9quipe, ce qui leur permet de pr\u00e9dire plus pr\u00e9cis\u00e9ment le comportement et les besoins en ressources des membres de l'\u00e9quipe -LSB- 14, 6 -RSB-. Cannon-Bowers et coll. -LSB- 14 -RSB- soutiennent explicitement que les membres de l'\u00e9quipe devraient avoir des mod\u00e8les compatibles qui conduisent \u00e0 des \u00ab\u00a0attentes\u00a0\u00bb communes. Nous sommes d\u2019accord sur ce point et pensons que l\u2019\u00e9tablissement d\u2019attentes partag\u00e9es entre les membres de l\u2019\u00e9quipe humains et agents est une \u00e9tape cruciale pour faire progresser la recherche sur le travail d\u2019\u00e9quipe centr\u00e9e sur l\u2019humain.Il convient de noter que le concept d'attente partag\u00e9e peut largement inclure l'attribution de r\u00f4les et sa dynamique, les sch\u00e9mas et progr\u00e8s du travail d'\u00e9quipe, les mod\u00e8les et intentions de communication, etc. Alors que l'objectif \u00e0 long terme de notre recherche est de comprendre comment les structures cognitives partag\u00e9es peuvent am\u00e9liorer les performances de l'\u00e9quipe homme-agent, l'objectif sp\u00e9cifique des travaux rapport\u00e9s ici est de d\u00e9velopper une approche cognitive computationnelle 6. CONCLUSION L'attention r\u00e9cente des recherches sur le travail d'\u00e9quipe centr\u00e9 sur l'humain exige fortement la conception de syst\u00e8mes d'agents comme des aides cognitives capables de mod\u00e9liser et d'exploiter les partenaires humains. capacit\u00e9s cognitives pour offrir de l\u2019aide de mani\u00e8re discr\u00e8te. Dans cet article, nous avons \u00e9tudi\u00e9 plusieurs facteurs entourant le probl\u00e8me difficile de l\u2019\u00e9volution de mod\u00e8les mentaux partag\u00e9s d\u2019\u00e9quipes compos\u00e9es de paires homme-agent. La contribution majeure de cette recherche inclut la proposition de mod\u00e8les de charge bas\u00e9s sur -LRB-1-RRB-HMM pour un agent afin d'estimer la charge cognitive de son partenaire humain et les charges de traitement d'autres co\u00e9quipiers HAP ; -LRB- 2 -RRB- Le concept de carte de croyances partag\u00e9es a \u00e9t\u00e9 introduit et mis en \u0153uvre. Il permet aux membres du groupe de repr\u00e9senter et de raisonner efficacement sur des mod\u00e8les mentaux partag\u00e9s ; -LRB- 3 -RRB- Des exp\u00e9riences ont \u00e9t\u00e9 men\u00e9es pour \u00e9valuer les mod\u00e8les de charge cognitive/de traitement bas\u00e9s sur HMM et les impacts de la communication multipartite sur l'\u00e9volution des SMM d'\u00e9quipe. L\u2019utilit\u00e9 des cartes de croyances partag\u00e9es a \u00e9galement \u00e9t\u00e9 d\u00e9montr\u00e9e au cours des exp\u00e9rimentations.", "keyphrases": ["partager la carte des croyances", "travail d'\u00e9quipe multiag", "heuriste", "raison", "r\u00e9solution de probl\u00e8mes", "collaborer", "travail en \u00e9quipe", "attendre", "sch\u00e9ma de travail d'\u00e9quipe", "l'\u00e9quipe humain-agent effectue", "th\u00e9orie de la charge cognitive", "performance humaine", "allocation de ressources", "t\u00e2che effectuer", "partage d'informations", "commune multipartite"]}
{"file_name": "J-23", "text": "Ratios de frugalit\u00e9 et m\u00e9canismes de v\u00e9rit\u00e9 am\u00e9lior\u00e9s pour la couverture des sommets * Dans les ench\u00e8res \u00e0 syst\u00e8me d'ensemble, il existe plusieurs \u00e9quipes d'agents qui se chevauchent et une t\u00e2che qui peut \u00eatre accomplie par n'importe laquelle de ces \u00e9quipes. L'objectif du commissaire-priseur est d'embaucher une \u00e9quipe et de payer le moins possible. Des exemples de ce param\u00e8tre incluent les ench\u00e8res sur le chemin le plus court et les ench\u00e8res sur la couverture des sommets. R\u00e9cemment, Karlin, Kempe et Tamir ont introduit une nouvelle d\u00e9finition du ratio d'offrugalit\u00e9 pour ce probl\u00e8me. De mani\u00e8re informelle, le \u00ab ratio de frugalit\u00e9 \u00bb est le rapport entre le paiement total d'un m\u00e9canisme et une limite de paiement souhait\u00e9e. Le ratio refl\u00e8te la mesure dans laquelle le m\u00e9canisme surpaye, par rapport au juste co\u00fbt per\u00e7u dans une ench\u00e8re v\u00e9ridique. Dans cet article, nous proposons une nouvelle ench\u00e8re v\u00e9ridique en temps polynomial pour le probl\u00e8me de couverture des sommets et limitons son ratio de frugalit\u00e9. Nous montrons que la qualit\u00e9 de la solution est \u00e0 facteur constant d'optimal et que le rapport de frugalit\u00e9 est \u00e0 facteur constant de la meilleure borne du pire cas possible ; c'est la premi\u00e8re vente aux ench\u00e8res pour ce probl\u00e8me \u00e0 avoir ces propri\u00e9t\u00e9s. De plus, nous montrons comment transformer toute vente aux ench\u00e8res v\u00e9ridique en une vente frugale tout en pr\u00e9servant le rapport d\u2019approximation. Nous consid\u00e9rons \u00e9galement deux modifications naturelles de la d\u00e9finition de Karlin et al., et analysons les propri\u00e9t\u00e9s des limites de paiement r\u00e9sultantes, telles que la monotonie, la duret\u00e9 des calculs et la robustesse par rapport \u00e0 la r\u00e8gle de r\u00e9solution de tirage. Nous \u00e9tudions les relations entre les diff\u00e9rentes limites de paiement, \u00e0 la fois pour les syst\u00e8mes d'ensembles g\u00e9n\u00e9raux et pour les ench\u00e8res de syst\u00e8mes d'ensembles sp\u00e9cifiques, telles que les ench\u00e8res de chemin et les ench\u00e8res de couverture de sommets. Nous utilisons ces nouvelles d\u00e9finitions dans la preuve de notre r\u00e9sultat principal pour les ench\u00e8res de couverture de vertex via une technique de bootstrapping, qui peut pr\u00e9senter un int\u00e9r\u00eat ind\u00e9pendant. 1. INTRODUCTION Dans un syst\u00e8me d'ench\u00e8res d\u00e9fini, il y a un seul acheteur et de nombreux vendeurs qui peuvent fournir divers services. On suppose que les exigences de l'acheteur peuvent \u00eatre satisfaites par divers sous-ensembles de vendeurs ; ces sous-ensembles sont appel\u00e9s les ensembles r\u00e9alisables. Nous supposons que chaque vendeur supporte un co\u00fbt pour fournir ses services, mais soumet une offre \u00e9ventuellement plus \u00e9lev\u00e9e au commissaire-priseur. Sur la base de ces offres, le commissaire-priseur s\u00e9lectionne un sous-ensemble r\u00e9alisable de vendeurs et effectue les paiements aux vendeurs de ce sous-ensemble. Chaque fournisseur s\u00e9lectionn\u00e9 b\u00e9n\u00e9ficie d'un b\u00e9n\u00e9fice de paiement moins le co\u00fbt. Les vendeurs veulent maximiser leurs profits, tandis que l\u2019acheteur souhaite minimiser le montant qu\u2019il paie. Un objectif naturel dans ce context est de concevoir une vente aux ench\u00e8res v\u00e9ridique, dans laquelle les vendeurs sont incit\u00e9s \u00e0 ench\u00e9rir \u00e0 leur v\u00e9ritable prix. Ceci peut \u00eatre r\u00e9alis\u00e9 en payant \u00e0 chaque fournisseur s\u00e9lectionn\u00e9 une prime sup\u00e9rieure \u00e0 son offre, de telle sorte que le vendeur ne soit pas incit\u00e9 \u00e0 surench\u00e9rir. Une question int\u00e9ressante dans la conception du m\u00e9canisme est de savoir quel montant le commissaire-priseur devra payer en trop pour garantir la v\u00e9racit\u00e9 des offres. Dans le context des ench\u00e8res de chemins, ce sujet a \u00e9t\u00e9 abord\u00e9 pour la premi\u00e8re fois par Archer et Tardos -LSB-1-RSB-.Ils d\u00e9finissent le ratio de frugalit\u00e9 d'un m\u00e9canisme comme le rapport entre son paiement total et le co\u00fbt du chemin le moins cher disjoint du chemin s\u00e9lectionn\u00e9 par le m\u00e9canisme. Ils montrent que, pour une large classe de m\u00e9canismes v\u00e9ridiques pour ce probl\u00e8me, le rapport de frugalit\u00e9 est aussi grand que le nombre d\u2019ar\u00eates sur le chemin le plus court. Talwar -LSB- 21 -RSB- \u00e9tend cette d\u00e9finition du rapport de frugalit\u00e9 aux syst\u00e8mes d'ensembles g\u00e9n\u00e9raux et \u00e9tudie le rapport de frugalit\u00e9 du m\u00e9canisme VCG classique -LSB- 22, 4, 14 -RSB- pour de nombreux syst\u00e8mes d'ensembles sp\u00e9cifiques, tels que l'\u00e9tendue minimale arbres et couvertures de d\u00e9cors. Bien que la d\u00e9finition du rapport de frugalit\u00e9 propos\u00e9e par -LSB- 1 -RSB- soit bien motiv\u00e9e et ait jou\u00e9 un r\u00f4le d\u00e9terminant dans l'\u00e9tude des m\u00e9canismes v\u00e9ridiques pour les syst\u00e8mes d\u00e9finis, elle n'est pas compl\u00e8tement satisfaisante. Consid\u00e9rons par exemple le graphe de la Figure 1 avec les co\u00fbts CAB = CBC = Figure 1 : Le graphe du diamant Ce graphe est 2-connexe et le paiement VCG au chemin gagnant ABCD est born\u00e9. Cependant, le graphique ne contient aucun chemin A - D disjoint de ABCD et, par cons\u00e9quent, le rapport de frugalit\u00e9 de VCG sur ce graphique reste ind\u00e9fini. En m\u00eame temps, il n\u2019existe pas de monopole, c\u2019est-\u00e0-dire qu\u2019il n\u2019existe aucun fournisseur qui apparaisse dans tous les ensembles possibles. Pour r\u00e9soudre ce probl\u00e8me, Karlin et al. -LSB- 16 -RSB- sugg\u00e8rent une meilleure r\u00e9f\u00e9rence, d\u00e9finie pour tout syst\u00e8me d'ensemble sans monopole. Sur la base de cette nouvelle d\u00e9finition, les auteurs construisent de nouveaux m\u00e9canismes pour le probl\u00e8me du chemin le plus court et montrent que le trop-pay\u00e9 de ces m\u00e9canismes se situe dans un facteur constant d'optimum. 1.1 Nos r\u00e9sultats Ench\u00e8res de couverture de sommets Nous proposons une ench\u00e8re v\u00e9ridique en temps polynomial pour la couverture de sommets qui produit une solution dont le co\u00fbt est dans un facteur 2 de l'optimal, et dont le rapport de frugalit\u00e9 est d'au plus 2\u0394, o\u00f9 \u0394 est le degr\u00e9 maximum du graphe. -LRB- Th\u00e9or\u00e8me 4 -RRB-. Nous compl\u00e9tons ce r\u00e9sultat en prouvant -LRB- Th\u00e9or\u00e8me 5 -RRB- que pour tout \u0394 et n, il existe des graphes de degr\u00e9 maximum \u0394 et de taille \u0398 -LRB- n -RRB- pour lesquels tout m\u00e9canisme v\u00e9ridique a un rapport de frugalit\u00e9 d'au moins \u0394 / 2. Cela signifie que la qualit\u00e9 de la solution de notre ench\u00e8re est d'un facteur 2 optimale et que le ratio de frugalit\u00e9 se situe dans un facteur 4 de la meilleure limite possible pour les entr\u00e9es les plus d\u00e9favorables. \u00c0 notre connaissance, il s'agit de la premi\u00e8re vente aux ench\u00e8res pour ce probl\u00e8me dont b\u00e9n\u00e9ficient ces propri\u00e9t\u00e9s. De plus, nous montrons comment transformer tout m\u00e9canisme v\u00e9ridique pour le probl\u00e8me de couverture de sommets en un m\u00e9canisme frugal tout en pr\u00e9servant le rapport d'approximation. Rapports de frugalit\u00e9 Nos r\u00e9sultats de couverture de sommets sugg\u00e8rent naturellement deux modifications de la d\u00e9finition de \u03bd dans -LSB- 16 -RSB-. Ces modifications peuvent \u00eatre apport\u00e9es ind\u00e9pendamment les unes des autres, ce qui donne lieu \u00e0 quatre limites de paiement diff\u00e9rentes TUmax, TUmin, NTUmax et NTUmin, o\u00f9 NTUmin est \u00e9gal \u00e0 la limite de paiement initiale \u03bd de dans -LSB- 16 -RSB-. Alors que notre r\u00e9sultat principal sur les ench\u00e8res de couverture de vertex -LRB- Th\u00e9or\u00e8me 4 -RRB- concerne NTUmin = \u03bd, nous utilisons les nouvelles d\u00e9finitions en comparant d'abord le paiement de notre m\u00e9canisme \u00e0 une limite plus faible NTUmax,puis amorcer \u00e0 partir de ce r\u00e9sultat pour obtenir la limite souhait\u00e9e. Inspir\u00e9s par cette application, nous nous lan\u00e7ons dans une \u00e9tude plus approfondie de ces limites de paiement. Nos r\u00e9sultats ici sont les suivants : 1. Nous observons -LRB- Proposition 1 -RRB- que les quatre bornes de paiement ob\u00e9issent toujours \u00e0 un ordre particulier ind\u00e9pendant du choix du syst\u00e8me d'ensemble et du vecteur de co\u00fbt, \u00e0 savoir, TUmin < NTUmin < NTUmax <TUmax. Nous fournissons les exemples -LRB- Proposition 5 et les Corollaires 1 et 2 -RRB- montrant que pour le probl\u00e8me de couverture de sommets, deux limites cons\u00e9cutives peuvent diff\u00e9rer d'un facteur n \u2212 2, o\u00f9 n est le nombre d'agents. Nous montrons ensuite -LRB- Th\u00e9or\u00e8me 2 -RRB- que cette s\u00e9paration est presque la meilleure possible pour les syst\u00e8mes d'ensembles g\u00e9n\u00e9raux en prouvant que pour tout syst\u00e8me d'ensembles TUmax/TUmin < n. En revanche, nous d\u00e9montrons le -LRB- Th\u00e9or\u00e8me 3 -RRB- que pour les ench\u00e8res de chemin TUmax/TUmin < 2. Nous fournissons des exemples -LRB- Propositions 2, 3 et 4 -RRB- montrant que cette borne est \u00e9troite. Nous voyons cela comme un argument en faveur de l'\u00e9tude des ench\u00e8res de vertexcover, car elles semblent \u00eatre plus repr\u00e9sentatives du probl\u00e8me g\u00e9n\u00e9ral de s\u00e9lection d'\u00e9quipe que les ench\u00e8res de chemin largement \u00e9tudi\u00e9es. 2. Cette observation sugg\u00e8re que les quatre bornes de paiement devraient \u00eatre \u00e9tudi\u00e9es dans un cadre unifi\u00e9 ; de plus, cela nous laisse penser que la technique de bootstrapping du th\u00e9or\u00e8me 4 pourrait avoir d\u2019autres applications. 3. Nous \u00e9valuons les limites de paiement introduites ici par rapport \u00e0 une liste de contr\u00f4le des caract\u00e9ristiques souhaitables. Cela peut \u00eatre consid\u00e9r\u00e9 comme un argument en faveur de l\u2019utilisation de limites NTUmax et TUmax plus faibles mais calculables efficacement. Travaux connexes Les ench\u00e8res de couverture de sommet ont \u00e9t\u00e9 \u00e9tudi\u00e9es dans le pass\u00e9 par Talwar -LSB- 21 -RSB- et Calinescu -LSB- 5 -RSB-. Ces deux articles sont bas\u00e9s sur la d\u00e9finition du ratio de frugalit\u00e9 utilis\u00e9e dans -LSB- 1 -RSB-\u00a0; comme mentionn\u00e9 pr\u00e9c\u00e9demment, cela signifie que leurs r\u00e9sultats ne s'appliquent qu'aux graphes bipartis. Talwar -LSB- 21 -RSB- montre que le rapport de frugalit\u00e9 du VCG est au plus \u0394. Cependant, comme trouver la couverture de sommet la moins ch\u00e8re est un probl\u00e8me NP-difficile, le m\u00e9canisme VCG est informatiquement irr\u00e9alisable. Le premier -LRB- et, \u00e0 notre connaissance, le seul -RRB- article \u00e0 \u00e9tudier les m\u00e9canismes v\u00e9ridiques en temps polynomial pour la couverture des sommets est -LSB- 5 -RSB-. Cet article \u00e9tudie une vente aux ench\u00e8res bas\u00e9e sur l'algorithme d'allocation glouton, qui a un rapport d'approximation de log n. Alors que l'objectif principal de -LSB- 5 -RSB- est le probl\u00e8me plus g\u00e9n\u00e9ral de la couverture d'ensembles, les r\u00e9sultats de -LSB- 5 -RSB- impliquent un rapport de frugalit\u00e9 de 2\u03942 pour la couverture des sommets. 2. PR\u00c9LIMINAIRES Dans la majeure partie de cet article, nous discutons des ench\u00e8res pour les syst\u00e8mes d'ensembles. Dans les ench\u00e8res du syst\u00e8me d'ensembles, chaque \u00e9l\u00e9ment e de l'ensemble de base appartient \u00e0 un agent ind\u00e9pendant et a un co\u00fbt associ\u00e9 non n\u00e9gatif ce. Le but du centre est de s\u00e9lectionner -LRB- acheter -RRB- un ensemble r\u00e9alisable. Chaque \u00e9l\u00e9ment e de l\u2019ensemble s\u00e9lectionn\u00e9 entra\u00eene un co\u00fbt de ce. Les \u00e9l\u00e9ments non s\u00e9lectionn\u00e9s n'entra\u00eenent aucun frais. Les ench\u00e8res se d\u00e9roulent de la mani\u00e8re suivante : tous les \u00e9l\u00e9ments du terrain font leurs ench\u00e8res,le centre s\u00e9lectionne un ensemble r\u00e9alisable sur la base des offres et effectue les paiements aux agents. Formellement, une ench\u00e8re est d\u00e9finie par une r\u00e8gle d'allocation A : R''_, F et une r\u00e8gle de paiement P : R''_, R''. La r\u00e8gle d'allocation prend en entr\u00e9e un vecteur d'offres et d\u00e9cide lequel des ensembles de F doit \u00eatre s\u00e9lectionn\u00e9. La r\u00e8gle de paiement prend \u00e9galement en entr\u00e9e un vecteur d'offres et d\u00e9cide du montant \u00e0 payer \u00e0 chaque agent. Les exigences standard sont la rationalit\u00e9 individuelle, c'est-\u00e0-dire que le paiement \u00e0 chaque agent doit \u00eatre au moins aussi \u00e9lev\u00e9 que son co\u00fbt encouru -LRB- 0 pour les agents ne faisant pas partie de l'ensemble s\u00e9lectionn\u00e9 et ce pour les agents dans l'ensemble s\u00e9lectionn\u00e9 -RRB- et la compatibilit\u00e9 des incitations, ou la v\u00e9racit\u00e9, c'est-\u00e0-dire que la strat\u00e9gie dominante de chaque agent est de proposer son v\u00e9ritable prix. Une r\u00e8gle d'attribution est monotone si un agent ne peut pas augmenter ses chances d'\u00eatre s\u00e9lectionn\u00e9 en augmentant son ench\u00e8re. \u00c9tant donn\u00e9 une r\u00e8gle d'allocation monotone A et un vecteur d'ench\u00e8re b, l'ench\u00e8re seuil te d'un agent e EA -LRB- b -RRB- est l'ench\u00e8re la plus \u00e9lev\u00e9e de cet agent qui remporte encore l'ench\u00e8re, \u00e9tant donn\u00e9 que les offres des autres participants restent les m\u00eame. Il est bien connu -LRB- voir, par exemple -LSB- 19, 13 -RSB- -RRB- que toute ench\u00e8re qui a une r\u00e8gle d'allocation monotone et paie \u00e0 chaque agent son ench\u00e8re de seuil est v\u00e9ridique ; \u00e0 l\u2019inverse, toute vente aux ench\u00e8res v\u00e9ridique ob\u00e9it \u00e0 une r\u00e8gle d\u2019attribution monotone. Le m\u00e9canisme VCG est un m\u00e9canisme v\u00e9ridique qui maximise le \u00ab\u00a0bien-\u00eatre social\u00a0\u00bb et paie 0 aux agents perdants. Pour les ench\u00e8res du syst\u00e8me d'ensembles, cela signifie simplement choisir l'ensemble le moins cher possible, payer \u00e0 chaque agent de l'ensemble s\u00e9lectionn\u00e9 son ench\u00e8re seuil et payer 0 \u00e0 tous les autres agents. Notez cependant que le m\u00e9canisme VCG peut \u00eatre difficile \u00e0 mettre en \u0153uvre, car trouver un ensemble r\u00e9alisable le moins cher peut s'av\u00e9rer difficile. Si U est un ensemble d\u2019agents, c -LRB- U -RRB- d\u00e9signe Ew \u2208 U cw. De m\u00eame, b -LRB- U -RRB- d\u00e9signe Ew \u2208 U bw.13 -RSB- -RRB- que toute ench\u00e8re qui a une r\u00e8gle d'allocation monotone et paie \u00e0 chaque agent son ench\u00e8re de seuil est v\u00e9ridique ; \u00e0 l\u2019inverse, toute vente aux ench\u00e8res v\u00e9ridique ob\u00e9it \u00e0 une r\u00e8gle d\u2019attribution monotone. Le m\u00e9canisme VCG est un m\u00e9canisme v\u00e9ridique qui maximise le \u00ab\u00a0bien-\u00eatre social\u00a0\u00bb et paie 0 aux agents perdants. Pour les ench\u00e8res du syst\u00e8me d'ensembles, cela signifie simplement choisir l'ensemble le moins cher possible, payer \u00e0 chaque agent de l'ensemble s\u00e9lectionn\u00e9 son ench\u00e8re seuil et payer 0 \u00e0 tous les autres agents. Notez cependant que le m\u00e9canisme VCG peut \u00eatre difficile \u00e0 mettre en \u0153uvre, car trouver un ensemble r\u00e9alisable le moins cher peut s'av\u00e9rer difficile. Si U est un ensemble d\u2019agents, c -LRB- U -RRB- d\u00e9signe Ew \u2208 U cw. De m\u00eame, b -LRB- U -RRB- d\u00e9signe Ew \u2208 U bw.13 -RSB- -RRB- que toute ench\u00e8re qui a une r\u00e8gle d'allocation monotone et paie \u00e0 chaque agent son ench\u00e8re de seuil est v\u00e9ridique ; \u00e0 l\u2019inverse, toute vente aux ench\u00e8res v\u00e9ridique ob\u00e9it \u00e0 une r\u00e8gle d\u2019attribution monotone. Le m\u00e9canisme VCG est un m\u00e9canisme v\u00e9ridique qui maximise le \u00ab\u00a0bien-\u00eatre social\u00a0\u00bb et paie 0 aux agents perdants. Pour les ench\u00e8res du syst\u00e8me d'ensembles, cela signifie simplement choisir l'ensemble le moins cher possible, payer \u00e0 chaque agent de l'ensemble s\u00e9lectionn\u00e9 son ench\u00e8re seuil et payer 0 \u00e0 tous les autres agents. Notez cependant que le m\u00e9canisme VCG peut \u00eatre difficile \u00e0 mettre en \u0153uvre, car trouver un ensemble r\u00e9alisable le moins cher peut s'av\u00e9rer difficile. Si U est un ensemble d\u2019agents, c -LRB- U -RRB- d\u00e9signe Ew \u2208 U cw. De m\u00eame, b -LRB- U -RRB- d\u00e9signe Ew \u2208 U bw.", "keyphrases": ["rapport frugal", "technique d'amor\u00e7age", "ench\u00e8res de couverture de sommet", "utilitaire de transfert", "effectuer le paiement li\u00e9", "r\u00e8gle d'allocation monotone", "tonnelier", "temps polynomi", "non monotone"]}
{"file_name": "I-11", "text": "Caract\u00e9risation et pr\u00e9diction des agents en temps r\u00e9el R\u00c9SUM\u00c9 Raisonner sur les agents que nous observons dans le monde est un d\u00e9fi. Nos informations disponibles se limitent souvent aux observations du comportement externe de l'agent dans le pass\u00e9 et le pr\u00e9sent. Pour comprendre ces actions, il faut d\u00e9duire l'\u00e9tat interne de l'agent, qui comprend non seulement des \u00e9l\u00e9ments rationnels -LRB- comme les intentions et les plans -RRB-, mais aussi des \u00e9l\u00e9ments \u00e9motifs -LRB- comme la peur -RRB-. De plus, nous souhaitons souvent pr\u00e9dire les actions futures de l'agent, qui sont contraintes non seulement par ces caract\u00e9ristiques int\u00e9rieures, mais \u00e9galement par la dynamique de l'interaction de l'agent avec son environnement. BEE -LRB- Evolution du comportement et extrapolation -RRB- utilise un mod\u00e8le de l'environnement bas\u00e9 sur des agents plus rapide que le temps r\u00e9el pour caract\u00e9riser l'\u00e9tat interne des agents par \u00e9volution par rapport au comportement observ\u00e9, puis pr\u00e9dire leur comportement futur, en tenant compte de la dynamique de leur interaction avec l'environnement. 1. INTRODUCTION Le raisonnement sur les agents que l'on observe dans le monde doit int\u00e9grer deux niveaux disparates. Nos observations se limitent souvent au comportement ext\u00e9rieur de l'agent, qui peut fr\u00e9quemment se r\u00e9sumer num\u00e9riquement \u00e0 une trajectoire dans l'espace-temps -LRB- ponctu\u00e9e peut-\u00eatre par des actions issues d'un vocabulaire assez restreint -RRB-. Cependant, ce comportement est d\u00e9termin\u00e9 par l'\u00e9tat interne de l'agent, qui -LRB- dans le cas d'un humain -RRB- peut impliquer des concepts psychologiques et cognitifs de haut niveau tels que les intentions et les \u00e9motions. Un d\u00e9fi central dans de nombreux domaines d\u2019application consiste \u00e0 raisonner \u00e0 partir d\u2019observations externes du comportement des agents jusqu\u2019\u00e0 une estimation de leur \u00e9tat interne. Un tel raisonnement est motiv\u00e9 par le d\u00e9sir de pr\u00e9dire le comportement de l'agent. Ce probl\u00e8me a traditionnellement \u00e9t\u00e9 abord\u00e9 sous la rubrique de \u00ab reconnaissance de plan \u00bb ou \u00ab d'inf\u00e9rence de plan \u00bb. \" De nombreux probl\u00e8mes r\u00e9alistes s'\u00e9cartent de ces conditions. \u2022 L'augmentation du nombre d'agents conduit \u00e0 une explosion combinatoire qui peut submerger l'analyse conventionnelle. \u2022 La dynamique environnementale peut contrecarrer les intentions des agents. \u2022 Les agents tentent souvent de cacher leurs intentions -LRB- et m\u00eame leur pr\u00e9sence -RRB-, plut\u00f4t que de partager intentionnellement des informations. \u2022 L'\u00e9tat \u00e9motionnel d'un agent peut \u00eatre au moins aussi important que son \u00e9tat rationnel pour d\u00e9terminer son comportement. BEE -LRB- Evolution comportementale et extrapolation -RRB- est une nouvelle approche pour reconna\u00eetre l'\u00e9tat rationnel et \u00e9motionnel de plusieurs agents en interaction sur la base uniquement de leur comportement, sans recourir \u00e0 des communications intentionnelles de leur part. Il s'inspire des techniques utilis\u00e9es pour pr\u00e9dire le comportement des syst\u00e8mes dynamiques non lin\u00e9aires, dans lesquelles une repr\u00e9sentation du syst\u00e8me est continuellement adapt\u00e9e \u00e0 son comportement pass\u00e9 r\u00e9cent. Pour les syst\u00e8mes dynamiques non lin\u00e9aires, la repr\u00e9sentation est une \u00e9quation math\u00e9matique de forme ferm\u00e9e. Dans BEE, il s'agit d'un ensemble de param\u00e8tres r\u00e9gissant le comportement des agents logiciels repr\u00e9sentant les individus analys\u00e9s.La version actuelle de BEE caract\u00e9rise et pr\u00e9dit le comportement des agents repr\u00e9sentant les militaires engag\u00e9s dans des combats urbains -LSB- 8 -RSB-. La section 2 passe en revue les travaux ant\u00e9rieurs pertinents. La section 3 d\u00e9crit l'architecture de BEE. La section 4 rapporte les r\u00e9sultats des exp\u00e9riences avec le syst\u00e8me. La section 5 se termine. 2. LES TRAVAUX PR\u00c9C\u00c9DENTS BEE sont comparables aux recherches ant\u00e9rieures sur la reconnaissance de plans AI -LRB -RRB-, les mod\u00e8les de Markov cach\u00e9s et les syst\u00e8mes de dynamique non lin\u00e9aire -LRB- pr\u00e9diction de trajectoire -RRB-. 2.1 Reconnaissance de plans dans l'IA La th\u00e9orie des agents d\u00e9crit commun\u00e9ment l'\u00e9tat cognitif d'un agent en termes de ses croyances, d\u00e9sirs et intentions -LRB- le mod\u00e8le dit \u00ab BDI \u00bb -LSB- 5, 20 -RSB- -RRB- . Les croyances d'un agent sont des propositions sur l'\u00e9tat du monde qu'il consid\u00e8re comme vraies, sur la base de ses perceptions. Ses d\u00e9sirs sont des propositions sur le monde qu'il aimerait voir vraies. Les d\u00e9sirs ne sont pas forc\u00e9ment coh\u00e9rents les uns avec les autres : un agent peut d\u00e9sirer \u00e0 la fois \u00eatre riche et ne pas travailler. Les intentions, ou objectifs, d'un agent sont un sous-ensemble de ses d\u00e9sirs qu'il a s\u00e9lectionn\u00e9s, sur la base de ses croyances, pour guider ses actions futures. Contrairement aux d\u00e9sirs, les objectifs doivent \u00eatre coh\u00e9rents les uns avec les autres -LRB- ou du moins consid\u00e9r\u00e9s comme coh\u00e9rents par l'agent -RRB-. Les objectifs d'un agent guident ses actions. Ainsi, on devrait \u00eatre capable d'apprendre quelque chose sur les objectifs d'un agent en observant ses actions pass\u00e9es, et la connaissance des objectifs de l'agent permet \u00e0 son tour de tirer des conclusions sur ce que l'agent pourrait faire dans le futur. Ce processus de raisonnement \u00e0 partir des actions d'un agent jusqu'\u00e0 ses objectifs est connu sous le nom de \u00ab reconnaissance de plan \u00bb ou \u00ab inf\u00e9rence de plan \u00bb. \u00ab La reconnaissance des r\u00e9gimes est rarement recherch\u00e9e pour le plaisir en soi. Il prend g\u00e9n\u00e9ralement en charge une fonction de niveau sup\u00e9rieur. Par exemple, dans les interfaces homme-machine, la reconnaissance du plan d'un utilisateur peut permettre au syst\u00e8me de fournir des informations et des options plus appropri\u00e9es pour l'action de l'utilisateur. Dans un syst\u00e8me de tutorat, d\u00e9duire le plan de l'\u00e9l\u00e8ve est une premi\u00e8re \u00e9tape pour identifier les plans bugg\u00e9s et fournir des mesures correctives appropri\u00e9es. Dans de nombreux cas, la fonction de niveau sup\u00e9rieur pr\u00e9dit les actions futures probables de l'entit\u00e9 dont le plan est d\u00e9duit. Nous nous concentrons sur la reconnaissance des plans \u00e0 l\u2019appui de la pr\u00e9diction. Le plan d'un agent est un \u00e9l\u00e9ment n\u00e9cessaire \u00e0 la pr\u00e9diction de son comportement futur, mais il est loin d'\u00eatre suffisant. Au moins deux autres influences, une interne et une externe, doivent \u00eatre prises en compte. L'influence externe est la dynamique de l'environnement, qui peut inclure d'autres agents. La dynamique du monde r\u00e9el impose des contraintes importantes. \u2022 L'environnement peut interf\u00e9rer avec les d\u00e9sirs de l'agent -LSB- 4, 10 -RSB-. \u2022 La plupart des interactions entre les agents, et entre les agents et le monde, sont non lin\u00e9aires. Une analyse rationnelle des objectifs d'un agent peut nous permettre de pr\u00e9dire ce qu'il tentera, mais tout plan non trivial comportant plusieurs \u00e9tapes d\u00e9pendra de mani\u00e8re sensible, \u00e0 chaque \u00e9tape, de la r\u00e9action de l'environnement.et notre pr\u00e9diction doit \u00e9galement prendre en compte cette r\u00e9action. La simulation r\u00e9elle des futurs est une mani\u00e8re -LRB- la seule que nous connaissons actuellement -RRB- de g\u00e9rer l'impact de la dynamique environnementale sur les actions d'un agent. Les agents humains sont \u00e9galement soumis \u00e0 une influence interne. L'\u00e9tat \u00e9motionnel de l'agent peut moduler son processus de d\u00e9cision et son centre d'attention -LRB- et donc sa perception de l'environnement -RRB-. Dans des cas extr\u00eames, l\u2019\u00e9motion peut conduire un agent \u00e0 choisir des actions qui, du point de vue d\u2019une analyse logique, peuvent para\u00eetre irrationnelles. Les travaux actuels sur la reconnaissance des plans \u00e0 des fins de pr\u00e9diction se concentrent sur le plan rationnel et ne prennent en compte ni les influences environnementales externes ni les pr\u00e9jug\u00e9s \u00e9motionnels internes. BEE int\u00e8gre les trois \u00e9l\u00e9ments dans ses pr\u00e9dictions. 2.2 Mod\u00e8les de Markov cach\u00e9s BEE est superficiellement similaire aux mod\u00e8les de Markov cach\u00e9s -LRB- HMM -LSB- 19 -RSB- -RRB-. BEE offre deux avantages importants par rapport aux HMM. Premi\u00e8rement, les variables cach\u00e9es d'un seul agent ne satisfont pas \u00e0 la propri\u00e9t\u00e9 de Markov. Autrement dit, leurs valeurs \u00e0 t + 1 d\u00e9pendent non seulement de leurs valeurs \u00e0 t, mais aussi des variables cach\u00e9es des autres agents. On pourrait \u00e9viter cette limitation en construisant un seul HMM sur l\u2019espace d\u2019\u00e9tat commun de tous les agents, mais cette approche est combinatoirement prohibitive. BEE combine l\u2019efficacit\u00e9 de la mod\u00e9lisation ind\u00e9pendante d\u2019agents individuels avec la r\u00e9alit\u00e9 de la prise en compte des interactions entre eux. Deuxi\u00e8mement, les mod\u00e8les markoviens supposent que les probabilit\u00e9s de transition sont stationnaires. Le processus \u00e9volutif de BEE met continuellement \u00e0 jour la personnalit\u00e9 des agents sur la base d'observations r\u00e9elles, et tient ainsi automatiquement compte des changements dans la personnalit\u00e9 des agents. 2.3 Ajustement des syst\u00e8mes non lin\u00e9aires en temps r\u00e9el De nombreux syst\u00e8mes d'int\u00e9r\u00eat peuvent \u00eatre d\u00e9crits par un vecteur de nombres r\u00e9els qui change en fonction du temps. Les dimensions du vecteur d\u00e9finissent l'espace d'\u00e9tat du syst\u00e8me. La pr\u00e9vision \u00e0 long terme d\u2019un tel syst\u00e8me est impossible. Cependant, il est souvent utile d'anticiper le comportement du syst\u00e8me \u00e0 courte distance. Ce processus est r\u00e9p\u00e9t\u00e9 constamment, offrant \u00e0 l\u2019utilisateur une pr\u00e9vision limit\u00e9e. Cette approche est robuste et largement appliqu\u00e9e, mais n\u00e9cessite des syst\u00e8mes pouvant \u00eatre d\u00e9crits efficacement avec des \u00e9quations math\u00e9matiques. BEE \u00e9tend cette approche aux comportements des agents, qu'il adapte aux comportements observ\u00e9s \u00e0 l'aide d'un algorithme g\u00e9n\u00e9tique. 5. CONCLUSIONS Dans de nombreux domaines, il est important de raisonner \u00e0 partir du comportement observ\u00e9 d'une entit\u00e9 jusqu'\u00e0 une estimation de son \u00e9tat interne, puis d'extrapoler cette estimation pour pr\u00e9dire le comportement futur de l'entit\u00e9. BEE accomplit cette t\u00e2che en utilisant une simulation d\u2019agents d\u2019essaimage plus rapide qu\u2019en temps r\u00e9el, coordonn\u00e9e via des ph\u00e9romones num\u00e9riques. Cette simulation int\u00e8gre la connaissance des r\u00e9gions menac\u00e9es, une analyse cognitive des croyances, des d\u00e9sirs et des intentions de l'agent, un mod\u00e8le de la disposition et de l'\u00e9tat \u00e9motionnel de l'agent,et la dynamique des interactions avec l'environnement. En faisant \u00e9voluer les agents dans cet environnement riche, nous pouvons adapter leur \u00e9tat interne \u00e0 leur comportement observ\u00e9. Dans les wargames r\u00e9alistes, le syst\u00e8me d\u00e9tecte avec succ\u00e8s les \u00e9motions d\u00e9lib\u00e9r\u00e9ment jou\u00e9es et fait des pr\u00e9dictions raisonnables sur les comportements futurs des entit\u00e9s. BEE ne peut mod\u00e9liser que les variables d'\u00e9tat internes qui ont un impact sur le comportement externe de l'agent. Il ne peut pas s'adapter \u00e0 des variables que l'agent ne manifeste pas ext\u00e9rieurement, puisque la base du cycle \u00e9volutif est une comparaison du comportement ext\u00e9rieur de l'agent simul\u00e9 avec celui de l'entit\u00e9 r\u00e9elle. Cette limitation est s\u00e9rieuse si notre objectif est de comprendre l'\u00e9tat interne de l'entit\u00e9 pour lui-m\u00eame. Si notre objectif en mati\u00e8re d\u2019ajustement des agents est de pr\u00e9dire leur comportement ult\u00e9rieur, la limitation est beaucoup moins s\u00e9rieuse. Les variables d\u2019\u00e9tat qui n\u2019ont pas d\u2019impact sur le comportement, bien qu\u2019invisibles pour une analyse bas\u00e9e sur le comportement, ne sont pas pertinentes pour une pr\u00e9diction comportementale. \u2022 Notre r\u00e9pertoire initial limit\u00e9 d'\u00e9motions est un petit sous-ensemble de celles qui ont \u00e9t\u00e9 distingu\u00e9es par les psychologues et qui pourraient \u00eatre utiles pour comprendre et projeter le comportement. Nous esp\u00e9rons \u00e9tendre l\u2019ensemble des \u00e9motions et des dispositions de soutien que BEE peut d\u00e9tecter. \u2022 La cartographie entre l'\u00e9tat psychologique -LRB- cognitif et \u00e9motionnel -RRB- d'un agent et son comportement ext\u00e9rieur n'est pas univoque. Plusieurs \u00e9tats internes diff\u00e9rents peuvent \u00eatre coh\u00e9rents avec un comportement observ\u00e9 donn\u00e9 dans un ensemble de conditions environnementales, mais peuvent donner lieu \u00e0 des comportements distincts dans d'autres conditions. Si l\u2019environnement du pass\u00e9 r\u00e9cent confond des \u00e9tats internes aussi distincts, nous serons incapables de les distinguer. Tant que l\u2019environnement reste dans cet \u00e9tat, nos pr\u00e9dictions seront exactes, quel que soit l\u2019\u00e9tat interne que nous attribuons \u00e0 l\u2019agent. Si l\u2019environnement \u00e9volue ensuite vers un environnement dans lequel les diff\u00e9rents \u00e9tats internes conduisent \u00e0 des comportements diff\u00e9rents, l\u2019utilisation de l\u2019\u00e9tat interne pr\u00e9c\u00e9demment choisi produira des pr\u00e9dictions inexactes. Une fa\u00e7on de r\u00e9pondre \u00e0 ces pr\u00e9occupations consiste \u00e0 sonder le monde r\u00e9el, en le perturbant de mani\u00e8re \u00e0 stimuler des comportements distincts de la part d\u2019entit\u00e9s dont l\u2019\u00e9tat psychologique serait autrement impossible \u00e0 distinguer. De telles enqu\u00eates constituent une technique de renseignement importante. La simulation plus rapide que le temps r\u00e9el de BEE pourrait nous permettre d'identifier les actions de sondage appropri\u00e9es, augmentant ainsi consid\u00e9rablement l'efficacit\u00e9 des efforts de renseignement.puisque la base du cycle \u00e9volutif est une comparaison du comportement ext\u00e9rieur de l\u2019agent simul\u00e9 avec celui de l\u2019entit\u00e9 r\u00e9elle. Cette limitation est s\u00e9rieuse si notre objectif est de comprendre l'\u00e9tat interne de l'entit\u00e9 pour lui-m\u00eame. Si notre objectif en mati\u00e8re d\u2019ajustement des agents est de pr\u00e9dire leur comportement ult\u00e9rieur, la limitation est beaucoup moins s\u00e9rieuse. Les variables d\u2019\u00e9tat qui n\u2019ont pas d\u2019impact sur le comportement, bien qu\u2019invisibles pour une analyse bas\u00e9e sur le comportement, ne sont pas pertinentes pour une pr\u00e9diction comportementale. \u2022 Notre r\u00e9pertoire initial limit\u00e9 d'\u00e9motions est un petit sous-ensemble de celles qui ont \u00e9t\u00e9 distingu\u00e9es par les psychologues et qui pourraient \u00eatre utiles pour comprendre et projeter le comportement. Nous esp\u00e9rons \u00e9tendre l\u2019ensemble des \u00e9motions et des dispositions de soutien que BEE peut d\u00e9tecter. \u2022 La cartographie entre l'\u00e9tat psychologique -LRB- cognitif et \u00e9motionnel -RRB- d'un agent et son comportement ext\u00e9rieur n'est pas univoque. Plusieurs \u00e9tats internes diff\u00e9rents peuvent \u00eatre coh\u00e9rents avec un comportement observ\u00e9 donn\u00e9 dans un ensemble de conditions environnementales, mais peuvent donner lieu \u00e0 des comportements distincts dans d'autres conditions. Si l\u2019environnement du pass\u00e9 r\u00e9cent confond des \u00e9tats internes aussi distincts, nous serons incapables de les distinguer. Tant que l\u2019environnement reste dans cet \u00e9tat, nos pr\u00e9dictions seront exactes, quel que soit l\u2019\u00e9tat interne que nous attribuons \u00e0 l\u2019agent. Si l\u2019environnement \u00e9volue ensuite vers un environnement dans lequel les diff\u00e9rents \u00e9tats internes conduisent \u00e0 des comportements diff\u00e9rents, l\u2019utilisation de l\u2019\u00e9tat interne pr\u00e9c\u00e9demment choisi produira des pr\u00e9dictions inexactes. Une fa\u00e7on de r\u00e9pondre \u00e0 ces pr\u00e9occupations consiste \u00e0 sonder le monde r\u00e9el, en le perturbant de mani\u00e8re \u00e0 stimuler des comportements distincts de la part d\u2019entit\u00e9s dont l\u2019\u00e9tat psychologique serait autrement impossible \u00e0 distinguer. De telles enqu\u00eates constituent une technique de renseignement importante. La simulation plus rapide que le temps r\u00e9el de BEE pourrait nous permettre d'identifier les actions de sondage appropri\u00e9es, augmentant ainsi consid\u00e9rablement l'efficacit\u00e9 des efforts de renseignement.puisque la base du cycle \u00e9volutif est une comparaison du comportement ext\u00e9rieur de l\u2019agent simul\u00e9 avec celui de l\u2019entit\u00e9 r\u00e9elle. Cette limitation est s\u00e9rieuse si notre objectif est de comprendre l'\u00e9tat interne de l'entit\u00e9 pour lui-m\u00eame. Si notre objectif en mati\u00e8re d\u2019ajustement des agents est de pr\u00e9dire leur comportement ult\u00e9rieur, la limitation est beaucoup moins s\u00e9rieuse. Les variables d\u2019\u00e9tat qui n\u2019ont pas d\u2019impact sur le comportement, bien qu\u2019invisibles pour une analyse bas\u00e9e sur le comportement, ne sont pas pertinentes pour une pr\u00e9diction comportementale. \u2022 Notre r\u00e9pertoire initial limit\u00e9 d'\u00e9motions est un petit sous-ensemble de celles qui ont \u00e9t\u00e9 distingu\u00e9es par les psychologues et qui pourraient \u00eatre utiles pour comprendre et projeter le comportement. Nous esp\u00e9rons \u00e9tendre l\u2019ensemble des \u00e9motions et des dispositions de soutien que BEE peut d\u00e9tecter. \u2022 La cartographie entre l'\u00e9tat psychologique -LRB- cognitif et \u00e9motionnel -RRB- d'un agent et son comportement ext\u00e9rieur n'est pas univoque. Plusieurs \u00e9tats internes diff\u00e9rents peuvent \u00eatre coh\u00e9rents avec un comportement observ\u00e9 donn\u00e9 dans un ensemble de conditions environnementales, mais peuvent donner lieu \u00e0 des comportements distincts dans d'autres conditions. Si l\u2019environnement du pass\u00e9 r\u00e9cent confond des \u00e9tats internes aussi distincts, nous serons incapables de les distinguer. Tant que l\u2019environnement reste dans cet \u00e9tat, nos pr\u00e9dictions seront exactes, quel que soit l\u2019\u00e9tat interne que nous attribuons \u00e0 l\u2019agent. Si l\u2019environnement \u00e9volue ensuite vers un environnement dans lequel les diff\u00e9rents \u00e9tats internes conduisent \u00e0 des comportements diff\u00e9rents, l\u2019utilisation de l\u2019\u00e9tat interne pr\u00e9c\u00e9demment choisi produira des pr\u00e9dictions inexactes. Une fa\u00e7on de r\u00e9pondre \u00e0 ces pr\u00e9occupations consiste \u00e0 sonder le monde r\u00e9el, en le perturbant de mani\u00e8re \u00e0 stimuler des comportements distincts de la part d\u2019entit\u00e9s dont l\u2019\u00e9tat psychologique serait autrement impossible \u00e0 distinguer. De telles enqu\u00eates constituent une technique de renseignement importante. La simulation plus rapide que le temps r\u00e9el de BEE pourrait nous permettre d'identifier les actions de sondage appropri\u00e9es, augmentant ainsi consid\u00e9rablement l'efficacit\u00e9 des efforts de renseignement.Si l\u2019environnement du pass\u00e9 r\u00e9cent confond des \u00e9tats internes aussi distincts, nous serons incapables de les distinguer. Tant que l\u2019environnement reste dans cet \u00e9tat, nos pr\u00e9dictions seront exactes, quel que soit l\u2019\u00e9tat interne que nous attribuons \u00e0 l\u2019agent. Si l\u2019environnement \u00e9volue ensuite vers un environnement dans lequel les diff\u00e9rents \u00e9tats internes conduisent \u00e0 des comportements diff\u00e9rents, l\u2019utilisation de l\u2019\u00e9tat interne pr\u00e9c\u00e9demment choisi produira des pr\u00e9dictions inexactes. Une fa\u00e7on de r\u00e9pondre \u00e0 ces pr\u00e9occupations consiste \u00e0 sonder le monde r\u00e9el, en le perturbant de mani\u00e8re \u00e0 stimuler des comportements distincts de la part d\u2019entit\u00e9s dont l\u2019\u00e9tat psychologique serait autrement impossible \u00e0 distinguer. De telles enqu\u00eates constituent une technique de renseignement importante. La simulation plus rapide que le temps r\u00e9el de BEE pourrait nous permettre d'identifier les actions de sondage appropri\u00e9es, augmentant ainsi consid\u00e9rablement l'efficacit\u00e9 des efforts de renseignement.Si l\u2019environnement du pass\u00e9 r\u00e9cent confond des \u00e9tats internes aussi distincts, nous serons incapables de les distinguer. Tant que l\u2019environnement reste dans cet \u00e9tat, nos pr\u00e9dictions seront exactes, quel que soit l\u2019\u00e9tat interne que nous attribuons \u00e0 l\u2019agent. Si l\u2019environnement \u00e9volue ensuite vers un environnement dans lequel les diff\u00e9rents \u00e9tats internes conduisent \u00e0 des comportements diff\u00e9rents, l\u2019utilisation de l\u2019\u00e9tat interne pr\u00e9c\u00e9demment choisi produira des pr\u00e9dictions inexactes. Une fa\u00e7on de r\u00e9pondre \u00e0 ces pr\u00e9occupations consiste \u00e0 sonder le monde r\u00e9el, en le perturbant de mani\u00e8re \u00e0 stimuler des comportements distincts de la part d\u2019entit\u00e9s dont l\u2019\u00e9tat psychologique serait autrement impossible \u00e0 distinguer. De telles enqu\u00eates constituent une technique de renseignement importante. La simulation plus rapide que le temps r\u00e9el de BEE pourrait nous permettre d'identifier les actions de sondage appropri\u00e9es, augmentant ainsi consid\u00e9rablement l'efficacit\u00e9 des efforts de renseignement.", "keyphrases": ["raison de l'agent", "comportement externe", "\u00e9tat interne", "comportement des agents pr\u00e9dire", "\u00e9volution du comportement et extrapol", "syst\u00e8me dynamique non lin\u00e9aire", "objectif de l'agent", "\u00e9motic\u00f4ne", "saveur de ph\u00e9romone", "disposer", "comportement futur"]}
{"file_name": "J-9", "text": "Calcul dans un march\u00e9 d'information distribu\u00e9 \u2217 R\u00c9SUM\u00c9 Selon la th\u00e9orie \u00e9conomique -- \u00e9tay\u00e9e par des preuves empiriques et de laboratoire -- le prix d'\u00e9quilibre d'un titre financier refl\u00e8te toutes les informations concernant la valeur du titre. Nous \u00e9tudions le processus informatique sur la voie vers l'\u00e9quilibre, o\u00f9 les informations distribu\u00e9es entre les commer\u00e7ants sont r\u00e9v\u00e9l\u00e9es \u00e9tape par \u00e9tape au fil du temps et incorpor\u00e9es dans le prix du march\u00e9. Nous d\u00e9veloppons un mod\u00e8le simplifi\u00e9 d'un march\u00e9 de l'information, ainsi que des strat\u00e9gies de trading, afin de formaliser les propri\u00e9t\u00e9s computationnelles du processus. Nous montrons que les titres dont les gains ne peuvent pas \u00eatre exprim\u00e9s sous forme de fonctions de seuil pond\u00e9r\u00e9es de bits d'entr\u00e9e distribu\u00e9s ne sont pas garantis de converger vers le bon \u00e9quilibre pr\u00e9dit par la th\u00e9orie \u00e9conomique. En revanche, les titres dont les gains sont des fonctions de seuil sont garantis de converger, pour toutes les distributions de probabilit\u00e9 ant\u00e9rieures. De plus, ces s\u00e9curit\u00e9s \u00e0 seuil convergent en au plus n tours, o\u00f9 n est le nombre de bits d'information distribu\u00e9s. Nous prouvons \u00e9galement une limite inf\u00e9rieure, montrant un type de seuil de s\u00e9curit\u00e9 qui n\u00e9cessite au moins n/2 tours pour converger dans le pire des cas. \u2217 Ce travail a \u00e9t\u00e9 soutenu par l'Initiative de recherche universitaire du DoD -LRB-URI-RRB- administr\u00e9e par l'Office of Naval Research sous la subvention N00014-01-1-0795. \u2020 Soutenu en partie par la subvention ONR N00014-01-0795 et les subventions NSF CCR-0105337, CCR-TC-0208972, ANI-0207399 et ITR-0219018. \u2021 Ce travail a \u00e9t\u00e9 r\u00e9alis\u00e9 chez NEC Laboratories America, Princeton, NJ. 1. INTRODUCTION La forme forte de l'hypoth\u00e8se des march\u00e9s efficaces stipule que les prix du march\u00e9 int\u00e8grent presque instantan\u00e9ment toutes les informations disponibles pour tous les commer\u00e7ants. En cons\u00e9quence, les prix du march\u00e9 codent les meilleures pr\u00e9visions de r\u00e9sultats futurs compte tenu de toutes les informations, m\u00eame si ces informations sont r\u00e9parties sur de nombreuses sources. Le processus d\u2019incorporation d\u2019informations est, par essence, un calcul distribu\u00e9. Chaque commer\u00e7ant commence avec ses propres informations. Au fur et \u00e0 mesure que les transactions sont effectu\u00e9es, des informations r\u00e9capitulatives sont r\u00e9v\u00e9l\u00e9es \u00e0 travers les prix du march\u00e9. Les traders apprennent ou d\u00e9duisent quelles informations les autres sont susceptibles de d\u00e9tenir en observant les prix, puis mettent \u00e0 jour leurs propres convictions en fonction de leurs observations. Au fil du temps, si le processus fonctionne comme annonc\u00e9, toutes les informations sont r\u00e9v\u00e9l\u00e9es et tous les traders convergent vers le m\u00eame \u00e9tat d'information. \u00c0 ce stade, le march\u00e9 se trouve dans ce qu\u2019on appelle un \u00e9quilibre d\u2019anticipations rationnelles -LSB- 11, 16, 19 -RSB-. Toutes les informations disponibles pour tous les traders se refl\u00e8tent d\u00e9sormais dans les prix en vigueur, et aucune autre transaction n'est souhaitable jusqu'\u00e0 ce que de nouvelles informations soient disponibles. Bien que la plupart des march\u00e9s ne soient pas con\u00e7us avec l'agr\u00e9gation d'informations comme motivation principale -- par exemple, les produits d\u00e9riv\u00e9s. Dans cet article, nous \u00e9tudions la nature du processus informatique par lequel les informations distribu\u00e9es sont r\u00e9v\u00e9l\u00e9es et combin\u00e9es au fil du temps dans les prix sur les march\u00e9s de l'information. Pour ce faire, dans la section 3,Nous proposons un mod\u00e8le de march\u00e9 de l'information qui se pr\u00eate \u00e0 une analyse th\u00e9orique et qui, selon nous, capture une grande partie de l'essence importante des march\u00e9s de l'information r\u00e9els. Nous prouvons que seuls les titres bool\u00e9ens dont les gains peuvent \u00eatre exprim\u00e9s sous forme de fonctions de seuil des bits d'information d'entr\u00e9e distribu\u00e9s sont garantis de converger comme le pr\u00e9dit la th\u00e9orie des attentes rationnelles. Les titres bool\u00e9ens avec des gains plus complexes peuvent ne pas converger sous certaines distributions ant\u00e9rieures. Nous fournissons \u00e9galement des limites sup\u00e9rieure et inf\u00e9rieure sur le temps de convergence pour ces titres \u00e0 seuil. Nous montrons que, pour toutes les distributions ant\u00e9rieures, le prix d\u2019un titre \u00e0 seuil converge vers son prix d\u2019\u00e9quilibre des attentes rationnelles en au plus n tours, o\u00f9 n est le nombre de bits d\u2019information distribu\u00e9e. Nous montrons que cette limite du pire des cas est \u00e9troite dans un facteur deux en illustrant une situation dans laquelle un seuil de s\u00e9curit\u00e9 n\u00e9cessite n/2 tours pour converger.", "keyphrases": ["th\u00e9orie \u00e9conomique", "empire et laboratoires evid", "prix d'\u00e9quilibre", "s\u00e9curit\u00e9 financi\u00e8re", "valeur de s\u00e9curit\u00e9", "processus informatique", "chemin vers l'\u00e9quilibre", "Commer\u00e7ant", "prix du march\u00e9", "mod\u00e8le simplifi\u00e9", "strat\u00e9gie commerciale", "propri\u00e9t\u00e9s de calcul du processus", "s\u00e9curiser", "payer", "fonction de seuil", "distribution probable", "rond", "nombre de bits", "distribuer informer", "borne inf\u00e9rieure", "pire cas", "informer le march\u00e9"]}
{"file_name": "H-19", "text": "Analyse des trajectoires de caract\u00e9ristiques pour la d\u00e9tection d'\u00e9v\u00e9nements R\u00c9SUM\u00c9 Nous consid\u00e9rons le probl\u00e8me de l'analyse des trajectoires de mots dans les domaines temporel et fr\u00e9quentiel, dans le but sp\u00e9cifique d'identifier les mots importants et moins signal\u00e9s, p\u00e9riodiques et ap\u00e9riodiques. Un ensemble de mots aux tendances identiques peut \u00eatre regroup\u00e9 pour reconstituer un \u00e9v\u00e9nement de mani\u00e8re totalement non supervis\u00e9e. La fr\u00e9quence de document de chaque mot dans le temps est trait\u00e9e comme une s\u00e9rie chronologique, o\u00f9 chaque \u00e9l\u00e9ment est la fr\u00e9quence de document - fr\u00e9quence de document inverse -LRB- DFIDF -RRB- \u00e0 un instant donn\u00e9. Dans cet article, nous 1 -RRB- avons d'abord appliqu\u00e9 l'analyse spectrale pour cat\u00e9goriser les caract\u00e9ristiques de diff\u00e9rentes caract\u00e9ristiques d'\u00e9v\u00e9nements : importantes et moins signal\u00e9es, p\u00e9riodiques et ap\u00e9riodiques ; 2 -RRB- a mod\u00e9lis\u00e9 des caract\u00e9ristiques ap\u00e9riodiques avec une densit\u00e9 gaussienne et des caract\u00e9ristiques p\u00e9riodiques avec des densit\u00e9s de m\u00e9lange gaussiennes, et a ensuite d\u00e9tect\u00e9 l'\u00e9clatement de chaque caract\u00e9ristique par l'approche gaussienne tronqu\u00e9e\u00a0; 3 -RRB- a propos\u00e9 un algorithme de d\u00e9tection d'\u00e9v\u00e9nements gloutons non supervis\u00e9 pour d\u00e9tecter \u00e0 la fois les \u00e9v\u00e9nements ap\u00e9riodiques et p\u00e9riodiques. Toutes les m\u00e9thodes ci-dessus peuvent \u00eatre appliqu\u00e9es aux donn\u00e9es de s\u00e9ries chronologiques en g\u00e9n\u00e9ral. Nous avons \u00e9valu\u00e9 de mani\u00e8re approfondie nos m\u00e9thodes sur le Reuters News Corpus d'une dur\u00e9e d'un an -LSB-3-RSB- et avons montr\u00e9 qu'elles \u00e9taient capables de d\u00e9couvrir des \u00e9v\u00e9nements ap\u00e9riodiques et p\u00e9riodiques significatifs. 1. INTRODUCTION Il existe plus de 4 000 sources d'information en ligne dans le monde. Les surveiller manuellement pour d\u00e9tecter les \u00e9v\u00e9nements importants est devenu difficile, voire pratiquement impossible. En fait, la communaut\u00e9 de d\u00e9tection et de suivi de sujets -LRB-TDT-RRB- essaie depuis de nombreuses ann\u00e9es de trouver une solution pratique pour aider les gens \u00e0 surveiller efficacement l'actualit\u00e9. les solutions propos\u00e9es pour la d\u00e9tection d'\u00e9v\u00e9nements -LSB- 20, 5, 17, 4, 21, 7, 14, 10 -RSB- sont soit trop simplistes -LRB- bas\u00e9es sur la similarit\u00e9 cosinus -LSB- 5 -RSB- -RRB- soit peu pratiques en raison \u00e0 la n\u00e9cessit\u00e9 de r\u00e9gler un grand nombre de param\u00e8tres -LSB- 9 -RSB-. Ainsi, dans cet article, nous examinons les actualit\u00e9s et pr\u00e9sentons les tendances dans la perspective de l\u2019analyse d\u2019un signal de mot de s\u00e9rie chronologique. Des travaux ant\u00e9rieurs comme -LSB- 9 -RSB- ont tent\u00e9 de reconstruire un \u00e9v\u00e9nement avec ses caract\u00e9ristiques repr\u00e9sentatives. Cependant, dans de nombreuses t\u00e2ches de d\u00e9tection pr\u00e9dictive d'\u00e9v\u00e9nements -LRB-, c'est-\u00e0-dire la d\u00e9tection r\u00e9trospective d'\u00e9v\u00e9nements -RRB-, il existe un vaste ensemble de fonctionnalit\u00e9s potentielles uniquement pour un ensemble fixe d'observations -LRB-, c'est-\u00e0-dire les salves \u00e9videntes -RRB-. Parmi ces fonctionnalit\u00e9s, seul un petit nombre est cens\u00e9 \u00eatre utile. En particulier, nous \u00e9tudions le nouveau probl\u00e8me de l'analyse des trajectoires de caract\u00e9ristiques pour la d\u00e9tection d'\u00e9v\u00e9nements, en empruntant une technique bien connue au traitement du signal : l'identification des corr\u00e9lations distributionnelles entre toutes les caract\u00e9ristiques par analyse spectrale. Pour \u00e9valuer notre m\u00e9thode, nous proposons ensuite un algorithme de d\u00e9tection d'\u00e9v\u00e9nements non supervis\u00e9 pour les flux d'actualit\u00e9s. Figure 1 : Corr\u00e9lation des caract\u00e9ristiques -LRB- DFIDF : temps -RRB- entre a -RRB- P\u00e2ques et avril b -RRB- Non audit\u00e9 et termin\u00e9. \u00c0 titre d'exemple illustratif, consid\u00e9rons la corr\u00e9lation entre les mots P\u00e2ques et avril du Reuters Corpus '.\u00c0 partir du trac\u00e9 de leur DFIDF normalis\u00e9 dans la figure 1 -LRB- a -RRB-, nous observons un fort chevauchement entre les deux mots vers 04/1997, ce qui signifie qu'ils appartiennent probablement tous les deux au m\u00eame \u00e9v\u00e9nement pendant cette p\u00e9riode -LRB- F\u00eate de P\u00e2ques. -RRB-. Dans cet exemple, l'\u00e9v\u00e9nement cach\u00e9 F\u00eate de P\u00e2ques est un \u00e9v\u00e9nement ap\u00e9riodique important typique sur des donn\u00e9es d'un an. Un autre exemple est donn\u00e9 par la figure 1 -LRB- b -RRB-, o\u00f9 les mots Unaudited et Ended ` Reuters Corpus sont l'ensemble de donn\u00e9es par d\u00e9faut pour tous les exemples. pr\u00e9sentent un comportement similaire sur des p\u00e9riodes de 3 mois. Ces deux mots proviennent en fait du m\u00eame \u00e9v\u00e9nement p\u00e9riodique, les rapports sur les revenus nets et les pertes, publi\u00e9s trimestriellement par les soci\u00e9t\u00e9s cot\u00e9es en bourse. D'autres observations tir\u00e9es de la Figure 1 sont : 1 -RRB- la p\u00e9riode de rafales du mois d'avril est beaucoup plus longue que P\u00e2ques, ce qui sugg\u00e8re qu'avril peut exister dans d'autres \u00e9v\u00e9nements au cours de la m\u00eame p\u00e9riode ; 2 -RRB- Non audit\u00e9 a une valeur DFIDF moyenne plus \u00e9lev\u00e9e que Termin\u00e9, ce qui indique que Non audit\u00e9 est plus repr\u00e9sentatif de l'\u00e9v\u00e9nement sous-jacent. Ces deux exemples ne sont que la pointe de l\u2019iceberg parmi toutes les tendances et corr\u00e9lations cach\u00e9es dans un flux d\u2019informations comme Reuters. Si un grand nombre d\u2019entre eux pouvaient \u00eatre d\u00e9couverts, cela pourrait grandement faciliter les t\u00e2ches du TDT. En particulier, cela indique l\u2019importance de l\u2019exploration des caract\u00e9ristiques de corr\u00e9lation pour d\u00e9tecter les \u00e9v\u00e9nements correspondants. Pour r\u00e9sumer, nous postulons que : 1 -RRB- Un \u00e9v\u00e9nement est d\u00e9crit par ses caract\u00e9ristiques repr\u00e9sentatives. Sur la base de ces observations, nous pouvons soit exploiter des caract\u00e9ristiques repr\u00e9sentatives d'un \u00e9v\u00e9nement, soit d\u00e9tecter un \u00e9v\u00e9nement \u00e0 partir d'une liste de caract\u00e9ristiques hautement corr\u00e9l\u00e9es. Dans cet article, nous nous concentrons sur ce dernier point, c'est-\u00e0-dire sur la mani\u00e8re dont des caract\u00e9ristiques corr\u00e9l\u00e9es peuvent \u00eatre d\u00e9couvertes pour former un \u00e9v\u00e9nement de mani\u00e8re non supervis\u00e9e. 1.1 Contributions Cet article a trois contributions principales : 9 Au meilleur de nos connaissances, notre approche est la premi\u00e8re \u00e0 cat\u00e9goriser les caract\u00e9ristiques des mots pour des \u00e9v\u00e9nements h\u00e9t\u00e9rog\u00e8nes. 9 Nous proposons une approche simple et efficace bas\u00e9e sur la densit\u00e9 de m\u00e9lange pour mod\u00e9liser et d\u00e9tecter les salves de caract\u00e9ristiques. 9 Nous proposons un algorithme de d\u00e9tection d'\u00e9v\u00e9nements non supervis\u00e9 pour d\u00e9tecter \u00e0 la fois les \u00e9v\u00e9nements ap\u00e9riodiques et p\u00e9riodiques. Notre algorithme a \u00e9t\u00e9 \u00e9valu\u00e9 sur un flux d'actualit\u00e9 r\u00e9el pour montrer son efficacit\u00e9. 2. TRAVAUX CONNEXES De plus, la plupart des recherches TDT jusqu'\u00e0 pr\u00e9sent se sont concentr\u00e9es sur le regroupement/classification des documents en types de sujets, l'identification de nouvelles phrases -LSB- 6 -RSB- pour de nouveaux \u00e9v\u00e9nements, etc., sans trop se soucier de l'analyse de la trajectoire des mots par rapport au temps. Swan et Allan -LSB- 18 -RSB- ont d'abord tent\u00e9 d'utiliser des termes cooccurrents pour construire un \u00e9v\u00e9nement. Cependant, ils n\u2019ont consid\u00e9r\u00e9 que les entit\u00e9s nomm\u00e9es et les paires d\u2019expressions nominales, sans consid\u00e9rer leurs p\u00e9riodicit\u00e9s. Au contraire, notre article consid\u00e8re tout ce qui pr\u00e9c\u00e8de. R\u00e9cemment, il y a eu un int\u00e9r\u00eat significatif pour la mod\u00e9lisation d'un \u00e9v\u00e9nement dans des flux de text comme une \u00ab explosion d'activit\u00e9s \u00bb en incorporant des informations temporelles. N\u00e9anmoins, aucun des travaux existants n'a identifi\u00e9 sp\u00e9cifiquement les caract\u00e9ristiques des \u00e9v\u00e9nements, \u00e0 l'exception de Fung et al. -LSB- 9 -RSB-,qui a regroup\u00e9 les caract\u00e9ristiques aux gros seins pour identifier divers \u00e9v\u00e9nements en rafale. Notre travail diff\u00e8re de -LSB- 9 -RSB- de plusieurs mani\u00e8res : 1 -RRB- nous analysons chaque caract\u00e9ristique, pas seulement les caract\u00e9ristiques en rafale ; 2 -RRB- nous classons les caract\u00e9ristiques selon deux dimensions cat\u00e9gorielles -LRB- p\u00e9riodicit\u00e9 et puissance -RRB-, donnant au total cinq types de caract\u00e9ristiques principales\u00a0; 3 -RRB- nous ne limitons pas chaque fonctionnalit\u00e9 \u00e0 appartenir exclusivement \u00e0 un seul \u00e9v\u00e9nement. Des techniques d'analyse spectrale ont d\u00e9j\u00e0 \u00e9t\u00e9 utilis\u00e9es par Vlachos et al. -LSB- 19 -RSB- pour identifier les p\u00e9riodicit\u00e9s et les rafales des journaux de requ\u00eates. Leur objectif \u00e9tait de d\u00e9tecter plusieurs p\u00e9riodicit\u00e9s \u00e0 partir du graphique du spectre de puissance, qui \u00e9taient ensuite utilis\u00e9es pour indexer les mots pour une recherche \u00ab requ\u00eate par rafale \u00bb. Dans cet article, nous utilisons l'analyse spectrale pour classer les caract\u00e9ristiques des mots selon deux dimensions, \u00e0 savoir la p\u00e9riodicit\u00e9 et le spectre de puissance, dans le but ultime d'identifier les \u00e9v\u00e9nements de rafale p\u00e9riodiques et ap\u00e9riodiques. 8. CONCLUSIONS Cet article a adopt\u00e9 une toute nouvelle perspective de l'analyse des trajectoires de caract\u00e9ristiques en tant que signaux dans le domaine temporel. En consid\u00e9rant les fr\u00e9quences des documents Word dans les domaines temporel et fr\u00e9quentiel, nous avons pu d\u00e9river de nombreuses nouvelles caract\u00e9ristiques sur les flux d'informations qui \u00e9taient auparavant inconnues, par exemple les diff\u00e9rentes distributions de mots vides pendant les jours de semaine et les week-ends. Pour la premi\u00e8re fois dans le domaine du TDT, nous avons appliqu\u00e9 une approche syst\u00e9matique pour d\u00e9tecter automatiquement les \u00e9v\u00e9nements importants et moins signal\u00e9s, p\u00e9riodiques et ap\u00e9riodiques. L'id\u00e9e cl\u00e9 de notre travail r\u00e9side dans les observations selon lesquelles les \u00e9v\u00e9nements p\u00e9riodiques -LRB- a -RRB- ont -LRB- a -RRB- des caract\u00e9ristiques repr\u00e9sentatives p\u00e9riodiques et -LRB- un -RRB- les \u00e9v\u00e9nements importants ont -LRB- dans -RRB- actif. caract\u00e9ristiques repr\u00e9sentatives, diff\u00e9renci\u00e9es par leurs spectres de puissance et leurs p\u00e9riodes de temps. Pour r\u00e9soudre le probl\u00e8me de d\u00e9tection d'\u00e9v\u00e9nements r\u00e9els, une approche simple et efficace bas\u00e9e sur la densit\u00e9 de m\u00e9lange a \u00e9t\u00e9 utilis\u00e9e pour identifier les rafales de caract\u00e9ristiques et leurs p\u00e9riodes de rafales associ\u00e9es. Nous avons \u00e9galement con\u00e7u un algorithme glouton non supervis\u00e9 pour d\u00e9tecter \u00e0 la fois les \u00e9v\u00e9nements ap\u00e9riodiques et p\u00e9riodiques, qui a r\u00e9ussi \u00e0 d\u00e9tecter des \u00e9v\u00e9nements r\u00e9els, comme le montre l'\u00e9valuation sur un flux d'informations r\u00e9el. Bien que nous n\u2019ayons effectu\u00e9 aucune comparaison avec une autre approche, tout simplement parce qu\u2019il n\u2019existe aucun travail ant\u00e9rieur sur le probl\u00e8me abord\u00e9. N\u00e9anmoins, nous pensons que notre m\u00e9thode simple et efficace sera utile \u00e0 tous les praticiens du TDT, et sera particuli\u00e8rement utile pour l'analyse exploratoire initiale des flux d'actualit\u00e9s.Leur objectif \u00e9tait de d\u00e9tecter plusieurs p\u00e9riodicit\u00e9s \u00e0 partir du graphique du spectre de puissance, qui \u00e9taient ensuite utilis\u00e9es pour indexer les mots pour une recherche \u00ab requ\u00eate par rafale \u00bb. Dans cet article, nous utilisons l'analyse spectrale pour classer les caract\u00e9ristiques des mots selon deux dimensions, \u00e0 savoir la p\u00e9riodicit\u00e9 et le spectre de puissance, dans le but ultime d'identifier les \u00e9v\u00e9nements de rafale p\u00e9riodiques et ap\u00e9riodiques. 8. CONCLUSIONS Cet article a adopt\u00e9 une toute nouvelle perspective de l'analyse des trajectoires de caract\u00e9ristiques en tant que signaux dans le domaine temporel. En consid\u00e9rant les fr\u00e9quences des documents Word dans les domaines temporel et fr\u00e9quentiel, nous avons pu d\u00e9river de nombreuses nouvelles caract\u00e9ristiques sur les flux d'informations qui \u00e9taient auparavant inconnues, par exemple les diff\u00e9rentes distributions de mots vides pendant les jours de semaine et les week-ends. Pour la premi\u00e8re fois dans le domaine du TDT, nous avons appliqu\u00e9 une approche syst\u00e9matique pour d\u00e9tecter automatiquement les \u00e9v\u00e9nements importants et moins signal\u00e9s, p\u00e9riodiques et ap\u00e9riodiques. L'id\u00e9e cl\u00e9 de notre travail r\u00e9side dans les observations selon lesquelles les \u00e9v\u00e9nements p\u00e9riodiques -LRB- a -RRB- ont -LRB- a -RRB- des caract\u00e9ristiques repr\u00e9sentatives p\u00e9riodiques et -LRB- un -RRB- les \u00e9v\u00e9nements importants ont -LRB- dans -RRB- actif. caract\u00e9ristiques repr\u00e9sentatives, diff\u00e9renci\u00e9es par leurs spectres de puissance et leurs p\u00e9riodes de temps. Pour r\u00e9soudre le probl\u00e8me de d\u00e9tection d'\u00e9v\u00e9nements r\u00e9els, une approche simple et efficace bas\u00e9e sur la densit\u00e9 de m\u00e9lange a \u00e9t\u00e9 utilis\u00e9e pour identifier les rafales de caract\u00e9ristiques et leurs p\u00e9riodes de rafales associ\u00e9es. Nous avons \u00e9galement con\u00e7u un algorithme glouton non supervis\u00e9 pour d\u00e9tecter \u00e0 la fois les \u00e9v\u00e9nements ap\u00e9riodiques et p\u00e9riodiques, qui a r\u00e9ussi \u00e0 d\u00e9tecter des \u00e9v\u00e9nements r\u00e9els, comme le montre l'\u00e9valuation sur un flux d'informations r\u00e9el. Bien que nous n\u2019ayons effectu\u00e9 aucune comparaison avec une autre approche, tout simplement parce qu\u2019il n\u2019existe aucun travail ant\u00e9rieur sur le probl\u00e8me abord\u00e9. N\u00e9anmoins, nous pensons que notre m\u00e9thode simple et efficace sera utile \u00e0 tous les praticiens du TDT, et sera particuli\u00e8rement utile pour l'analyse exploratoire initiale des flux d'actualit\u00e9s.Leur objectif \u00e9tait de d\u00e9tecter plusieurs p\u00e9riodicit\u00e9s \u00e0 partir du graphique du spectre de puissance, qui \u00e9taient ensuite utilis\u00e9es pour indexer les mots pour une recherche \u00ab requ\u00eate par rafale \u00bb. Dans cet article, nous utilisons l'analyse spectrale pour classer les caract\u00e9ristiques des mots selon deux dimensions, \u00e0 savoir la p\u00e9riodicit\u00e9 et le spectre de puissance, dans le but ultime d'identifier les \u00e9v\u00e9nements de rafale p\u00e9riodiques et ap\u00e9riodiques. 8. CONCLUSIONS Cet article a adopt\u00e9 une toute nouvelle perspective de l'analyse des trajectoires de caract\u00e9ristiques en tant que signaux dans le domaine temporel. En consid\u00e9rant les fr\u00e9quences des documents Word dans les domaines temporel et fr\u00e9quentiel, nous avons pu d\u00e9river de nombreuses nouvelles caract\u00e9ristiques sur les flux d'informations qui \u00e9taient auparavant inconnues, par exemple les diff\u00e9rentes distributions de mots vides pendant les jours de semaine et les week-ends. Pour la premi\u00e8re fois dans le domaine du TDT, nous avons appliqu\u00e9 une approche syst\u00e9matique pour d\u00e9tecter automatiquement les \u00e9v\u00e9nements importants et moins signal\u00e9s, p\u00e9riodiques et ap\u00e9riodiques. L'id\u00e9e cl\u00e9 de notre travail r\u00e9side dans les observations selon lesquelles les \u00e9v\u00e9nements p\u00e9riodiques -LRB- a -RRB- ont -LRB- a -RRB- des caract\u00e9ristiques repr\u00e9sentatives p\u00e9riodiques et -LRB- un -RRB- les \u00e9v\u00e9nements importants ont -LRB- dans -RRB- actif. caract\u00e9ristiques repr\u00e9sentatives, diff\u00e9renci\u00e9es par leurs spectres de puissance et leurs p\u00e9riodes de temps. Pour r\u00e9soudre le probl\u00e8me de d\u00e9tection d'\u00e9v\u00e9nements r\u00e9els, une approche simple et efficace bas\u00e9e sur la densit\u00e9 de m\u00e9lange a \u00e9t\u00e9 utilis\u00e9e pour identifier les rafales de caract\u00e9ristiques et leurs p\u00e9riodes de rafales associ\u00e9es. Nous avons \u00e9galement con\u00e7u un algorithme glouton non supervis\u00e9 pour d\u00e9tecter \u00e0 la fois les \u00e9v\u00e9nements ap\u00e9riodiques et p\u00e9riodiques, qui a r\u00e9ussi \u00e0 d\u00e9tecter des \u00e9v\u00e9nements r\u00e9els, comme le montre l'\u00e9valuation sur un flux d'informations r\u00e9el. Bien que nous n\u2019ayons effectu\u00e9 aucune comparaison avec une autre approche, tout simplement parce qu\u2019il n\u2019existe aucun travail ant\u00e9rieur sur le probl\u00e8me abord\u00e9. N\u00e9anmoins, nous pensons que notre m\u00e9thode simple et efficace sera utile \u00e0 tous les praticiens du TDT, et sera particuli\u00e8rement utile pour l'analyse exploratoire initiale des flux d'actualit\u00e9s.Pour r\u00e9soudre le probl\u00e8me de d\u00e9tection d'\u00e9v\u00e9nements r\u00e9els, une approche simple et efficace bas\u00e9e sur la densit\u00e9 de m\u00e9lange a \u00e9t\u00e9 utilis\u00e9e pour identifier les rafales de caract\u00e9ristiques et leurs p\u00e9riodes de rafales associ\u00e9es. Nous avons \u00e9galement con\u00e7u un algorithme glouton non supervis\u00e9 pour d\u00e9tecter \u00e0 la fois les \u00e9v\u00e9nements ap\u00e9riodiques et p\u00e9riodiques, qui a r\u00e9ussi \u00e0 d\u00e9tecter des \u00e9v\u00e9nements r\u00e9els, comme le montre l'\u00e9valuation sur un flux d'informations r\u00e9el. Bien que nous n\u2019ayons effectu\u00e9 aucune comparaison avec une autre approche, tout simplement parce qu\u2019il n\u2019existe aucun travail ant\u00e9rieur sur le probl\u00e8me abord\u00e9. N\u00e9anmoins, nous pensons que notre m\u00e9thode simple et efficace sera utile \u00e0 tous les praticiens du TDT, et sera particuli\u00e8rement utile pour l'analyse exploratoire initiale des flux d'actualit\u00e9s.Pour r\u00e9soudre le probl\u00e8me de d\u00e9tection d'\u00e9v\u00e9nements r\u00e9els, une approche simple et efficace bas\u00e9e sur la densit\u00e9 de m\u00e9lange a \u00e9t\u00e9 utilis\u00e9e pour identifier les rafales de caract\u00e9ristiques et leurs p\u00e9riodes de rafales associ\u00e9es. Nous avons \u00e9galement con\u00e7u un algorithme glouton non supervis\u00e9 pour d\u00e9tecter \u00e0 la fois les \u00e9v\u00e9nements ap\u00e9riodiques et p\u00e9riodiques, qui a r\u00e9ussi \u00e0 d\u00e9tecter des \u00e9v\u00e9nements r\u00e9els, comme le montre l'\u00e9valuation sur un flux d'informations r\u00e9el. Bien que nous n\u2019ayons effectu\u00e9 aucune comparaison avec une autre approche, tout simplement parce qu\u2019il n\u2019existe aucun travail ant\u00e9rieur sur le probl\u00e8me abord\u00e9. N\u00e9anmoins, nous pensons que notre m\u00e9thode simple et efficace sera utile \u00e0 tous les praticiens du TDT, et sera particuli\u00e8rement utile pour l'analyse exploratoire initiale des flux d'actualit\u00e9s.", "keyphrases": ["d\u00e9tection d'\u00e9v\u00e9nement", "trajectoire de mot", "\u00e9v\u00e9nement ap\u00e9riodique", "\u00e9v\u00e9nement d'\u00e9poque", "signal de mot", "analyse spectrale", "sujet d\u00e9tecter", "piste th\u00e9matique", "flux de text", "nouveau flux", "s\u00e9rie temporelle"]}
{"file_name": "H-3", "text": "Utilisation de contexts de requ\u00eate dans la recherche d'informations R\u00c9SUM\u00c9 La requ\u00eate utilisateur est un \u00e9l\u00e9ment qui sp\u00e9cifie un besoin d'information, mais ce n'est pas le seul. Les \u00e9tudes litt\u00e9raires ont mis en \u00e9vidence de nombreux facteurs contextuels qui influencent fortement l\u2019interpr\u00e9tation d\u2019une requ\u00eate. Des \u00e9tudes r\u00e9centes ont tent\u00e9 de prendre en compte les int\u00e9r\u00eats de l'utilisateur en cr\u00e9ant un profil utilisateur. Cependant, un seul profil pour un utilisateur peut ne pas suffire pour une vari\u00e9t\u00e9 de requ\u00eates de l'utilisateur. Dans cette \u00e9tude, nous proposons d'utiliser des contexts sp\u00e9cifiques \u00e0 la requ\u00eate plut\u00f4t que des contexts centr\u00e9s sur l'utilisateur, y compris le context autour de la requ\u00eate et le context dans la requ\u00eate. Le premier sp\u00e9cifie l'environnement d'une requ\u00eate tel que le domaine d'int\u00e9r\u00eat, tandis que le second fait r\u00e9f\u00e9rence \u00e0 des mots contextuels au sein de la requ\u00eate, ce qui est particuli\u00e8rement utile pour la s\u00e9lection de relations de termes pertinentes. Dans cet article, les deux types de context sont int\u00e9gr\u00e9s dans un mod\u00e8le IR bas\u00e9 sur la mod\u00e9lisation du langage. Nos exp\u00e9riences sur plusieurs collections TREC montrent que chacun des facteurs contextuels apporte des am\u00e9liorations significatives dans l'efficacit\u00e9 de la r\u00e9cup\u00e9ration. 1. INTRODUCTION Les requ\u00eates, en particulier les requ\u00eates courtes, ne fournissent pas une sp\u00e9cification compl\u00e8te du besoin d'information. De nombreux termes pertinents peuvent \u00eatre absents des requ\u00eates et les termes inclus peuvent \u00eatre ambigus. Ces questions ont \u00e9t\u00e9 abord\u00e9es dans un grand nombre d\u2019\u00e9tudes ant\u00e9rieures. Cependant, dans ces \u00e9tudes, il a \u00e9t\u00e9 g\u00e9n\u00e9ralement suppos\u00e9 que la requ\u00eate est le seul \u00e9l\u00e9ment disponible concernant le besoin d'information de l'utilisateur. En r\u00e9alit\u00e9, la requ\u00eate est toujours formul\u00e9e dans un context de recherche. Ces facteurs incluent, entre autres, le domaine d'int\u00e9r\u00eat, les connaissances, les pr\u00e9f\u00e9rences, etc. de l'utilisateur. Tous ces \u00e9l\u00e9ments pr\u00e9cisent les 8. CONCLUSIONS Les approches IR traditionnelles consid\u00e8rent g\u00e9n\u00e9ralement la requ\u00eate comme le seul \u00e9l\u00e9ment disponible pour le besoin d'information de l'utilisateur. De nombreuses \u00e9tudes ant\u00e9rieures ont \u00e9tudi\u00e9 l'int\u00e9gration de certains facteurs contextuels dans les mod\u00e8les RI, g\u00e9n\u00e9ralement en incorporant un profil utilisateur. \u00c0 l'instar de certaines \u00e9tudes pr\u00e9c\u00e9dentes, nous proposons de mod\u00e9liser les domaines th\u00e9matiques plut\u00f4t que l'utilisateur. Les investigations pr\u00e9c\u00e9dentes sur le context se sont concentr\u00e9es sur les facteurs autour de la requ\u00eate. Nous avons montr\u00e9 dans cet article que les facteurs au sein de la requ\u00eate sont \u00e9galement importants : ils aident \u00e0 s\u00e9lectionner les relations de termes appropri\u00e9es \u00e0 appliquer dans l'expansion de la requ\u00eate. Nous avons int\u00e9gr\u00e9 les facteurs contextuels ci-dessus, ainsi que le mod\u00e8le de r\u00e9troaction, dans un mod\u00e8le de langage unique. Nos r\u00e9sultats exp\u00e9rimentaux confirment fortement l\u2019int\u00e9r\u00eat de l\u2019utilisation des contexts en IR. Ce travail montre \u00e9galement que le cadre de mod\u00e9lisation du langage est appropri\u00e9 pour int\u00e9grer de nombreux facteurs contextuels. Ce travail peut \u00eatre encore am\u00e9lior\u00e9 sur plusieurs aspects, y compris d'autres m\u00e9thodes pour extraire les relations entre termes, pour int\u00e9grer davantage de mots contextuels dans les conditions et pour identifier les domaines de requ\u00eate. Il serait \u00e9galement int\u00e9ressant de tester la m\u00e9thode sur la recherche Web en utilisant l'historique de recherche des utilisateurs.", "keyphrases": ["profil utilisateur", "context sp\u00e9cifique \u00e0 une requ\u00eate", "centr\u00e9 sur l'utilisateur", "domaine d'int\u00e9r\u00eat", "facteur de context", "sens des mots homonyme", "informer le besoin", "context de recherche", "connaissance du domaine", "utilisation des connaissances g\u00e9n\u00e9rales", "probl\u00e8me de connaissance ambigu", "ind\u00e9pendant du context", "informer le context", "mod\u00e8le de domaine", "solution radicale", "recherche de personne sur Google"]}
{"file_name": "C-28", "text": "PackageBLAST\u00a0:\u00a0un service de grille adaptative multi-politiques pour la comparaison de s\u00e9quences biologiques * R\u00c9SUM\u00c9 Dans cet article, nous proposons un cadre d'allocation de t\u00e2ches adaptative pour effectuer des recherches BLAST dans un environnement de grille sur des segments de base de donn\u00e9es de s\u00e9quences. Le framework, appel\u00e9 PackageBLAST, fournit une infrastructure permettant de choisir ou d'incorporer des strat\u00e9gies d'allocation de t\u00e2ches. De plus, nous proposons un m\u00e9canisme pour calculer le poids d'ex\u00e9cution des n\u0153uds de grille, adaptant la politique d'allocation choisie \u00e0 la puissance de calcul actuelle des n\u0153uds. Nos r\u00e9sultats pr\u00e9sentent de tr\u00e8s bonnes acc\u00e9l\u00e9rations et montrent \u00e9galement qu'aucune strat\u00e9gie d'allocation unique n'est capable d'atteindre les temps d'ex\u00e9cution les plus bas pour tous les sc\u00e9narios. 1. INTRODUCTION SW -LSB- 14 -RSB- est un algorithme exact qui trouve le meilleur alignement local entre deux s\u00e9quences de taille n dans le temps et l'espace quadratiques. Pour cette raison, des heuristiques comme BLAST -LSB- 3 -RSB- ont \u00e9t\u00e9 propos\u00e9es pour r\u00e9duire le temps d'ex\u00e9cution. CLS. Pris en charge par ACM. La planification des ressources est l'un des composants les plus importants d'un syst\u00e8me de grille. Le choix des meilleures ressources pour une application particuli\u00e8re est appel\u00e9 allocation de t\u00e2ches, qui est un probl\u00e8me NP-Complet. Les applications r\u00e9seau n'ont g\u00e9n\u00e9ralement pas des d\u00e9bits de communication \u00e9lev\u00e9s et beaucoup d'entre elles suivent le mod\u00e8le ma\u00eetre/esclave -LSB-13-RSB-. Afin de planifier les applications ma\u00eetre/esclave, de nombreuses politiques d'allocation de t\u00e2ches ont \u00e9t\u00e9 propos\u00e9es, telles que Self Scheduling -LSB- 15 -RSB- et FAC2 -LSB- 8 -RSB-. Le choix de la meilleure politique d'allocation d\u00e9pend du mod\u00e8le d'acc\u00e8s \u00e0 l'application et de l'environnement dans lequel elle s'ex\u00e9cute -LSB- 13 -RSB-. Dans cet article, nous proposons PackageBLAST, un service de grille multi-politiques adaptatif pour ex\u00e9cuter des recherches BLAST dans des grilles compos\u00e9es de bases de donn\u00e9es g\u00e9n\u00e9tiques segment\u00e9es. PackageBLAST s'ex\u00e9cute sur Globus 3 -LSB- 4 -RSB- et propose d\u00e9sormais cinq politiques d'allocation. Nous proposons \u00e9galement un m\u00e9canisme adaptatif pour attribuer des poids aux n\u0153uds de la grille, en tenant compte de leur charge de travail actuelle. \u00c0 notre connaissance, il s'agit du premier service de grille qui ex\u00e9cute BLAST avec plusieurs politiques de t\u00e2ches avec une base de donn\u00e9es segment\u00e9e sur une plate-forme h\u00e9t\u00e9rog\u00e8ne non d\u00e9di\u00e9e. Ce document est organis\u00e9 comme suit. La section 2 pr\u00e9sente le probl\u00e8me de comparaison de s\u00e9quences et l'algorithme BLAST. La section 3 d\u00e9crit les politiques d'allocation pour les r\u00e9seaux. La section 4 traite des travaux connexes. La section 5 pr\u00e9sente la conception de PackageBLAST. Les r\u00e9sultats exp\u00e9rimentaux sont discut\u00e9s dans la section 6. La section 7 conclut l'article. 4. TRAVAUX CONNEXES Premi\u00e8rement, la base de donn\u00e9es g\u00e9n\u00e9tiques est segment\u00e9e. Ensuite, les requ\u00eates sont r\u00e9parties uniform\u00e9ment entre les n\u0153uds. Si le n\u0153ud ne poss\u00e8de pas de fragment de base de donn\u00e9es, une copie locale est effectu\u00e9e. Une m\u00e9thode est propos\u00e9e qui associe des fragments de donn\u00e9es \u00e0 des n\u0153uds, en essayant de minimiser le nombre de copies. BLAST + + -LSB- 10 -RSB- regroupe plusieurs s\u00e9quences pour r\u00e9duire le nombre d'acc\u00e8s \u00e0 la base de donn\u00e9es. Une approche ma\u00eetre/esclave est utilis\u00e9e qui alloue les requ\u00eates aux esclaves selon la politique fixe -LRB- section 3.3 -RRB-. Chaque travailleur ex\u00e9cute BLAST ++ ind\u00e9pendamment et, enfin,les r\u00e9sultats sont collect\u00e9s et combin\u00e9s par le ma\u00eetre. GridBlast -LSB- 9 -RSB- est une application de grille ma\u00eetre/esclave qui utilise Globus 2. Elle distribue les s\u00e9quences entre les n\u0153uds de la grille en utilisant deux politiques d'allocation : FCFS et minmax. Cependant, pour utiliser minmax, il faut conna\u00eetre le temps total d\u2019ex\u00e9cution de chaque t\u00e2che BLAST. Apr\u00e8s avoir d\u00e9cid\u00e9 quelles s\u00e9quences seront compar\u00e9es par chaque n\u0153ud, GridBlast envoie les s\u00e9quences, les fichiers ex\u00e9cutables et l'ensemble de la base de donn\u00e9es au n\u0153ud choisi. Une fois la recherche termin\u00e9e, les r\u00e9sultats sont compact\u00e9s et envoy\u00e9s au ma\u00eetre. Grid Blast Toolkit -LRB- GBTK -RRB- -LSB- 12 -RSB- est un portail Web permettant d'ex\u00e9cuter des recherches BLAST dans Globus 3. Toutes les bases de donn\u00e9es g\u00e9n\u00e9tiques sont plac\u00e9es statiquement sur les n\u0153uds de la grille -LRB- sans r\u00e9plication -RRB-. GBTK est une application ma\u00eetre/esclave qui re\u00e7oit les s\u00e9quences et le nom de la base de donn\u00e9es g\u00e9n\u00e9tique. Il v\u00e9rifie ensuite si le n\u0153ud qui contient la base de donn\u00e9es est disponible. Si le n\u0153ud n'est pas disponible, le n\u0153ud le moins charg\u00e9 est choisi et la base de donn\u00e9es y est copi\u00e9e. La base de donn\u00e9es est r\u00e9pliqu\u00e9e dans les n\u0153uds, mais seule une partie est trait\u00e9e dans chaque n\u0153ud Figure 2 : M\u00e9canisme de segmentation et de distribution de PackageBLAST. 7. CONCLUSION Dans cet article, nous avons propos\u00e9 et \u00e9valu\u00e9 PackageBLAST, un service de grille multi-politiques adaptatif pour ex\u00e9cuter des recherches BLAST ma\u00eetre/esclave. PackageBLAST contient un cadre dans lequel l'utilisateur peut choisir ou int\u00e9grer des politiques d'allocation. Nous avons \u00e9galement d\u00e9fini une strat\u00e9gie, PSS, qui adapte la politique choisie \u00e0 un environnement de r\u00e9seau h\u00e9t\u00e9rog\u00e8ne non d\u00e9di\u00e9. Les r\u00e9sultats collect\u00e9s en ex\u00e9cutant PackageBLAST avec 5 politiques d'allocation dans un banc d'essai de grille \u00e9taient tr\u00e8s bons. Afin de comparer une s\u00e9quence d'ADN r\u00e9el de 10\u00a0KBP avec la base de donn\u00e9es g\u00e9n\u00e9tique nr, nous avons pu r\u00e9duire le temps d'ex\u00e9cution de 30,88 min \u00e0 2,11 min. En outre, nous avons montr\u00e9 que, dans notre banc d'essai, il n'existe pas de politique d'allocation qui permette toujours d'obtenir les meilleures performances, ce qui met en \u00e9vidence l'importance de fournir plusieurs politiques. De plus, nous avons montr\u00e9 que l\u2019introduction du PSS entra\u00eenait de tr\u00e8s bons gains de performance pour certaines politiques. Dans le cadre de travaux futurs, nous avons l'intention d'ex\u00e9cuter PackageBLAST dans une grille g\u00e9ographiquement dispers\u00e9e, pour \u00e9valuer l'impact des latences \u00e9lev\u00e9es du r\u00e9seau dans les politiques d'allocation et dans le PSS. Nous avons \u00e9galement l\u2019intention de prendre en charge la synchronisation des bases de donn\u00e9es g\u00e9nomiques et les op\u00e9rations dynamiques de jointure/sortie pour les esclaves.Toutes les bases de donn\u00e9es g\u00e9n\u00e9tiques sont plac\u00e9es statiquement sur les n\u0153uds de la grille -LRB- sans r\u00e9plication -RRB-. GBTK est une application ma\u00eetre/esclave qui re\u00e7oit les s\u00e9quences et le nom de la base de donn\u00e9es g\u00e9n\u00e9tique. Il v\u00e9rifie ensuite si le n\u0153ud qui contient la base de donn\u00e9es est disponible. Si le n\u0153ud n'est pas disponible, le n\u0153ud le moins charg\u00e9 est choisi et la base de donn\u00e9es y est copi\u00e9e. La base de donn\u00e9es est r\u00e9pliqu\u00e9e dans les n\u0153uds, mais seule une partie est trait\u00e9e dans chaque n\u0153ud Figure 2 : M\u00e9canisme de segmentation et de distribution de PackageBLAST. 7. CONCLUSION Dans cet article, nous avons propos\u00e9 et \u00e9valu\u00e9 PackageBLAST, un service de grille multi-politiques adaptatif pour ex\u00e9cuter des recherches BLAST ma\u00eetre/esclave. PackageBLAST contient un cadre dans lequel l'utilisateur peut choisir ou int\u00e9grer des politiques d'allocation. Nous avons \u00e9galement d\u00e9fini une strat\u00e9gie, PSS, qui adapte la politique choisie \u00e0 un environnement de r\u00e9seau h\u00e9t\u00e9rog\u00e8ne non d\u00e9di\u00e9. Les r\u00e9sultats collect\u00e9s en ex\u00e9cutant PackageBLAST avec 5 politiques d'allocation dans un banc d'essai de grille \u00e9taient tr\u00e8s bons. Afin de comparer une s\u00e9quence d'ADN r\u00e9el de 10\u00a0KBP avec la base de donn\u00e9es g\u00e9n\u00e9tique nr, nous avons pu r\u00e9duire le temps d'ex\u00e9cution de 30,88 min \u00e0 2,11 min. En outre, nous avons montr\u00e9 que, dans notre banc d'essai, il n'existe pas de politique d'allocation qui permette toujours d'obtenir les meilleures performances, ce qui met en \u00e9vidence l'importance de fournir plusieurs politiques. De plus, nous avons montr\u00e9 que l\u2019introduction du PSS entra\u00eenait de tr\u00e8s bons gains de performance pour certaines politiques. Dans le cadre de travaux futurs, nous avons l'intention d'ex\u00e9cuter PackageBLAST dans une grille g\u00e9ographiquement dispers\u00e9e, pour \u00e9valuer l'impact des latences \u00e9lev\u00e9es du r\u00e9seau dans les politiques d'allocation et dans le PSS. Nous avons \u00e9galement l\u2019intention de prendre en charge la synchronisation des bases de donn\u00e9es g\u00e9nomiques et les op\u00e9rations dynamiques de jointure/sortie pour les esclaves.Toutes les bases de donn\u00e9es g\u00e9n\u00e9tiques sont plac\u00e9es statiquement sur les n\u0153uds de la grille -LRB- sans r\u00e9plication -RRB-. GBTK est une application ma\u00eetre/esclave qui re\u00e7oit les s\u00e9quences et le nom de la base de donn\u00e9es g\u00e9n\u00e9tique. Il v\u00e9rifie ensuite si le n\u0153ud qui contient la base de donn\u00e9es est disponible. Si le n\u0153ud n'est pas disponible, le n\u0153ud le moins charg\u00e9 est choisi et la base de donn\u00e9es y est copi\u00e9e. La base de donn\u00e9es est r\u00e9pliqu\u00e9e dans les n\u0153uds, mais seule une partie est trait\u00e9e dans chaque n\u0153ud Figure 2 : M\u00e9canisme de segmentation et de distribution de PackageBLAST. 7. CONCLUSION Dans cet article, nous avons propos\u00e9 et \u00e9valu\u00e9 PackageBLAST, un service de grille multi-politiques adaptatif pour ex\u00e9cuter des recherches BLAST ma\u00eetre/esclave. PackageBLAST contient un cadre dans lequel l'utilisateur peut choisir ou int\u00e9grer des politiques d'allocation. Nous avons \u00e9galement d\u00e9fini une strat\u00e9gie, PSS, qui adapte la politique choisie \u00e0 un environnement de r\u00e9seau h\u00e9t\u00e9rog\u00e8ne non d\u00e9di\u00e9. Les r\u00e9sultats collect\u00e9s en ex\u00e9cutant PackageBLAST avec 5 politiques d'allocation dans un banc d'essai de grille \u00e9taient tr\u00e8s bons. Afin de comparer une s\u00e9quence d'ADN r\u00e9el de 10\u00a0KBP avec la base de donn\u00e9es g\u00e9n\u00e9tique nr, nous avons pu r\u00e9duire le temps d'ex\u00e9cution de 30,88 min \u00e0 2,11 min. En outre, nous avons montr\u00e9 que, dans notre banc d'essai, il n'existe pas de politique d'allocation qui permette toujours d'obtenir les meilleures performances, ce qui met en \u00e9vidence l'importance de fournir plusieurs politiques. De plus, nous avons montr\u00e9 que l\u2019introduction du PSS entra\u00eenait de tr\u00e8s bons gains de performance pour certaines politiques. Dans le cadre de travaux futurs, nous avons l'intention d'ex\u00e9cuter PackageBLAST dans une grille g\u00e9ographiquement dispers\u00e9e, pour \u00e9valuer l'impact des latences \u00e9lev\u00e9es du r\u00e9seau dans les politiques d'allocation et dans le PSS. Nous avons \u00e9galement l\u2019intention de prendre en charge la synchronisation des bases de donn\u00e9es g\u00e9nomiques et les op\u00e9rations dynamiques de jointure/sortie pour les esclaves.nous avons montr\u00e9 que l\u2019introduction du PSS entra\u00eenait de tr\u00e8s bons gains de performance pour certaines politiques. Dans le cadre de travaux futurs, nous avons l'intention d'ex\u00e9cuter PackageBLAST dans une grille g\u00e9ographiquement dispers\u00e9e, pour \u00e9valuer l'impact des latences \u00e9lev\u00e9es du r\u00e9seau dans les politiques d'allocation et dans le PSS. Nous avons \u00e9galement l\u2019intention de prendre en charge la synchronisation des bases de donn\u00e9es g\u00e9nomiques et les op\u00e9rations dynamiques de jointure/sortie pour les esclaves.nous avons montr\u00e9 que l\u2019introduction du PSS entra\u00eenait de tr\u00e8s bons gains de performance pour certaines politiques. Dans le cadre de travaux futurs, nous avons l'intention d'ex\u00e9cuter PackageBLAST dans une grille g\u00e9ographiquement dispers\u00e9e, pour \u00e9valuer l'impact des latences \u00e9lev\u00e9es du r\u00e9seau dans les politiques d'allocation et dans le PSS. Nous avons \u00e9galement l\u2019intention de prendre en charge la synchronisation des bases de donn\u00e9es g\u00e9nomiques et les op\u00e9rations dynamiques de jointure/sortie pour les esclaves.", "keyphrases": ["comparaison de s\u00e9quences biologiques", "adapter le service de r\u00e9seau multi-polici", "allocation de t\u00e2ches", "recherche explosive", "paquetblast", "bioinformatique", "calcul en grille", "informatique biologique", "projet g\u00e9nome", "bases de donn\u00e9es de g\u00e8nes de segments", "plateforme h\u00e9t\u00e9rog\u00e8ne non d\u00e9di\u00e9e", "environnement de grille", "pss", "adapter le poids du colis \u00e0 son propre planning"]}
{"file_name": "C-14", "text": "Strat\u00e9gie de d\u00e9ploiement de capteurs pour la d\u00e9tection de cibles R\u00c9SUM\u00c9 Afin de surveiller la travers\u00e9e du trafic dans une r\u00e9gion, des capteurs peuvent \u00eatre d\u00e9ploy\u00e9s pour effectuer une d\u00e9tection de cible collaborative. Un tel r\u00e9seau de capteurs atteint un certain niveau de performance de d\u00e9tection avec un co\u00fbt de d\u00e9ploiement associ\u00e9. Cet article aborde ce probl\u00e8me en proposant l'exposition au chemin comme mesure de la qualit\u00e9 d'un d\u00e9ploiement et pr\u00e9sente une approche pour un d\u00e9ploiement s\u00e9quentiel par \u00e9tapes. Il montre que le co\u00fbt de d\u00e9ploiement peut \u00eatre minimis\u00e9 pour atteindre les performances de d\u00e9tection souhait\u00e9es en choisissant de mani\u00e8re appropri\u00e9e le nombre de capteurs d\u00e9ploy\u00e9s \u00e0 chaque \u00e9tape. 1. INTRODUCTION Un tel r\u00e9seau peut \u00eatre utilis\u00e9 pour surveiller l'environnement, d\u00e9tecter, classer et localiser des \u00e9v\u00e9nements sp\u00e9cifiques et suivre des cibles dans une r\u00e9gion sp\u00e9cifique. Le d\u00e9ploiement de r\u00e9seaux de capteurs varie selon l'application consid\u00e9r\u00e9e. Il peut \u00eatre pr\u00e9d\u00e9termin\u00e9 lorsque l\u2019environnement est suffisamment connu et sous contr\u00f4le, auquel cas les capteurs peuvent \u00eatre plac\u00e9s strat\u00e9giquement \u00e0 la main. Cet article \u00e9tudie les strat\u00e9gies de d\u00e9ploiement de r\u00e9seaux de capteurs effectuant une d\u00e9tection de cible sur une r\u00e9gion d'int\u00e9r\u00eat. Les observations locales r\u00e9alis\u00e9es par les capteurs d\u00e9pendant de leur position, les performances de l'algorithme de d\u00e9tection sont fonction du d\u00e9ploiement. Une mesure possible de la qualit\u00e9 du d\u00e9ploiement pour la d\u00e9tection de cibles est appel\u00e9e exposition au chemin. Il s'agit d'une mesure de la probabilit\u00e9 de d\u00e9tecter une cible traversant la r\u00e9gion en utilisant un chemin donn\u00e9. Plus l\u2019exposition du chemin est \u00e9lev\u00e9e, meilleur est le d\u00e9ploiement. L\u2019ensemble des chemins \u00e0 consid\u00e9rer peut \u00eatre contraint par l\u2019environnement. Par exemple, si la cible doit suivre une route, seuls les chemins constitu\u00e9s de routes doivent \u00eatre pris en compte. Dans cette \u00e9tude, le d\u00e9ploiement est suppos\u00e9 al\u00e9atoire, ce qui correspond \u00e0 de nombreuses applications pratiques o\u00f9 la r\u00e9gion \u00e0 surveiller n'est pas accessible pour un placement pr\u00e9cis des capteurs. L'objectif de cet article est de d\u00e9terminer le nombre de capteurs \u00e0 d\u00e9ployer pour effectuer la d\u00e9tection de cibles dans une r\u00e9gion d'int\u00e9r\u00eat. Les compromis se situent entre les performances du r\u00e9seau, le co\u00fbt des capteurs d\u00e9ploy\u00e9s et le co\u00fbt de d\u00e9ploiement des capteurs. Ce document est organis\u00e9 comme suit. Dans la section 2, une d\u00e9finition de l'exposition au trajet est propos\u00e9e et une m\u00e9thode pour \u00e9valuer l'exposition d'un trajet donn\u00e9 est d\u00e9velopp\u00e9e. Dans la section 3, le probl\u00e8me du d\u00e9ploiement al\u00e9atoire est formul\u00e9 et plusieurs solutions sont pr\u00e9sent\u00e9es. L'article se termine par la section 7. 7. CONCLUSION Cet article aborde le probl\u00e8me du d\u00e9ploiement de capteurs dans une r\u00e9gion \u00e0 surveiller pour d\u00e9tecter l'intrusion d'une cible. Un m\u00e9canisme de collaboration entre capteurs pour effectuer la d\u00e9tection de cibles est propos\u00e9 et analys\u00e9 afin d'\u00e9valuer l'exposition des chemins \u00e0 travers la r\u00e9gion. L'exposition minimale est utilis\u00e9e comme mesure de la qualit\u00e9 du d\u00e9ploiement, l'objectif \u00e9tant de maximiser l'exposition du chemin le moins expos\u00e9 de la r\u00e9gion. Dans le cas o\u00f9 des capteurs sont plac\u00e9s al\u00e9atoirement dans une r\u00e9gion \u00e0 surveiller,un m\u00e9canisme de d\u00e9ploiement s\u00e9quentiel par \u00e9tapes est d\u00e9velopp\u00e9. La strat\u00e9gie consiste \u00e0 d\u00e9ployer un nombre limit\u00e9 de capteurs \u00e0 la fois jusqu'\u00e0 ce que l'exposition minimale souhait\u00e9e soit atteinte. La fonction de co\u00fbt utilis\u00e9e dans cette \u00e9tude d\u00e9pend du nombre de capteurs d\u00e9ploy\u00e9s \u00e0 chaque \u00e9tape et du co\u00fbt de chaque d\u00e9ploiement. Gr\u00e2ce \u00e0 la simulation, la distribution de l'exposition minimale obtenue par d\u00e9ploiement al\u00e9atoire a \u00e9t\u00e9 \u00e9valu\u00e9e pour un nombre variable de capteurs d\u00e9ploy\u00e9s. Ces r\u00e9sultats ont \u00e9t\u00e9 utilis\u00e9s pour \u00e9valuer le co\u00fbt de d\u00e9ploiement pour un nombre variable de capteurs d\u00e9ploy\u00e9s \u00e0 chaque \u00e9tape. Nous avons constat\u00e9 que le nombre optimal de capteurs d\u00e9ploy\u00e9s \u00e0 chaque \u00e9tape varie en fonction du co\u00fbt relatif attribu\u00e9 au d\u00e9ploiement et aux capteurs. Les r\u00e9sultats de cette \u00e9tude peuvent \u00eatre \u00e9tendus \u00e0 des r\u00e9gions plus vastes avec des param\u00e8tres cibles diff\u00e9rents. La solution propos\u00e9e dans cet article peut \u00e9galement \u00eatre am\u00e9lior\u00e9e en envisageant de d\u00e9ployer un nombre variable de capteurs \u00e0 chaque \u00e9tape et ce probl\u00e8me \u00e0 variables multiples n\u00e9cessite une \u00e9tude plus approfondie.", "keyphrases": ["d\u00e9tection de cible", "r\u00e9seau de capteurs", "exposition du chemin", "nombre de capteur", "d\u00e9ploiement s\u00e9quentiel", "exposition minimale", "placement al\u00e9atoire du capteur", "champ de capteur", "d\u00e9cai cible"]}
{"file_name": "C-6", "text": "Conception et mise en \u0153uvre d'un syst\u00e8me de gestion de contenu distribu\u00e9 R\u00c9SUM\u00c9 La convergence des progr\u00e8s des technologies de stockage, d'encodage et de mise en r\u00e9seau nous a amen\u00e9s \u00e0 un environnement o\u00f9 d'\u00e9normes quantit\u00e9s de contenu multim\u00e9dia continu sont r\u00e9guli\u00e8rement stock\u00e9es et \u00e9chang\u00e9es entre des appareils compatibles r\u00e9seau. Garder une trace de -LRB- ou g\u00e9rer -RRB- un tel contenu reste un d\u00e9fi en raison du grand volume de donn\u00e9es. Le stockage de m\u00e9dias continus \u00ab en direct \u00bb -LRB- tels que du contenu TV ou radio -RRB- ajoute \u00e0 la complexit\u00e9 dans la mesure o\u00f9 ce contenu n'a ni d\u00e9but ni fin bien d\u00e9finis et est donc fastidieux \u00e0 g\u00e9rer. Le stockage en r\u00e9seau permet au contenu qui est logiquement consid\u00e9r\u00e9 comme faisant partie de la m\u00eame collection d'\u00eatre en fait distribu\u00e9 sur un r\u00e9seau, ce qui rend la t\u00e2che de gestion de contenu pratiquement impossible \u00e0 g\u00e9rer sans un syst\u00e8me de gestion de contenu. Dans cet article, nous pr\u00e9sentons la conception et la mise en \u0153uvre du syst\u00e8me de gestion de contenu Spectrum, qui traite efficacement le contenu multim\u00e9dia riche dans cet environnement. Spectrum poss\u00e8de une architecture modulaire qui permet son application \u00e0 la fois \u00e0 des sc\u00e9narios autonomes et \u00e0 divers sc\u00e9narios en r\u00e9seau. Un aspect unique de Spectrum est qu'il n\u00e9cessite qu'une ou plusieurs politiques de r\u00e9tention -LRB- s'appliquent \u00e0 chaque \u00e9l\u00e9ment de contenu stock\u00e9 dans le syst\u00e8me. Cela signifie qu\u2019il n\u2019y a pas de politique d\u2019expulsion. Le contenu auquel aucune politique de r\u00e9tention n\u2019est appliqu\u00e9e est simplement supprim\u00e9 du syst\u00e8me. Diff\u00e9rentes politiques de r\u00e9tention peuvent facilement \u00eatre appliqu\u00e9es au m\u00eame contenu, facilitant ainsi naturellement le partage sans duplication. Cette approche permet \u00e9galement \u00e0 Spectrum d'appliquer facilement au contenu des politiques bas\u00e9es sur le temps, qui sont des \u00e9l\u00e9ments de base n\u00e9cessaires pour g\u00e9rer le stockage de m\u00e9dias continus en direct. Nous d\u00e9crivons non seulement les d\u00e9tails de l'architecture Spectrum, mais donnons \u00e9galement des cas d'utilisation typiques. 1. INTRODUCTION Manipuler et g\u00e9rer du contenu est et a toujours \u00e9t\u00e9 l'une des fonctions principales d'un ordinateur. Les applications informatiques initiales incluent des formateurs de text et des compilateurs de programmes. Le contenu \u00e9tait initialement g\u00e9r\u00e9 par une interaction explicite de l'utilisateur via l'utilisation de fichiers et de syst\u00e8mes de fichiers. \u00c0 mesure que la technologie progresse, les types de contenu et la mani\u00e8re dont les gens souhaitent l\u2019utiliser ont consid\u00e9rablement chang\u00e9. De nouveaux types de contenu, tels que les flux multim\u00e9dias continus, sont devenus monnaie courante en raison de la convergence des avanc\u00e9es en mati\u00e8re de technologies de stockage, d'encodage et de mise en r\u00e9seau. Un autre exemple est la combinaison de la technologie de codage et de mise en r\u00e9seau \u00e0 large bande. Cette combinaison a permis aux utilisateurs d'acc\u00e9der et de partager du contenu multim\u00e9dia sur des r\u00e9seaux locaux et distants, le r\u00e9seau lui-m\u00eame agissant comme un immense r\u00e9f\u00e9rentiel de donn\u00e9es. La prolif\u00e9ration de contenus de haute qualit\u00e9 rendue possible par ces progr\u00e8s en mati\u00e8re de technologie de stockage, d'encodage et de mise en r\u00e9seau cr\u00e9e le besoin de nouvelles fa\u00e7ons de manipuler et de g\u00e9rer les donn\u00e9es.Notre travail se concentre sur le stockage de contenu multim\u00e9dia riche et en particulier le stockage de contenu multim\u00e9dia continu sous forme pr\u00e9emball\u00e9e ou \u00ab en direct \u00bb. \u2022 Bien que cela soit vrai pour tous les types de contenu, le stockage de contenu multim\u00e9dia continu est particuli\u00e8rement probl\u00e9matique. Premi\u00e8rement, le contenu multim\u00e9dia continu est encore tr\u00e8s exigeant en termes de ressources de stockage, ce qui signifie qu'une approche de stockage sans politique ne fonctionnera pas pour tous, sauf pour les plus petits syst\u00e8mes. Deuxi\u00e8mement, le stockage de contenus \u00ab\u00a0en direct\u00a0\u00bb tels que la t\u00e9l\u00e9vision ou la radio est intrins\u00e8quement probl\u00e9matique car ces signaux sont des flux continus sans points de terminaison. Cela signifie qu\u2019avant m\u00eame de penser \u00e0 g\u00e9rer un tel contenu, il est n\u00e9cessaire de l\u2019abstraire en quelque chose qui pourrait \u00eatre manipul\u00e9 et g\u00e9r\u00e9. . Lorsqu'il s'agit de m\u00e9dias continus stock\u00e9s, il est n\u00e9cessaire de g\u00e9rer ce contenu \u00e0 la fois \u00e0 un niveau pr\u00e9cis et \u00e0 un niveau global. Par exemple, un utilisateur individuel de PVR souhaitant conserver uniquement les moments forts d'un \u00e9v\u00e9nement sportif particulier ne devrait pas \u00eatre oblig\u00e9 de stocker le contenu relatif \u00e0 l'\u00e9v\u00e9nement complet. . Comme indiqu\u00e9 ci-dessus, il est tr\u00e8s difficile d'essayer de suivre le contenu d'un syst\u00e8me autonome sans syst\u00e8me de gestion de contenu. Cependant, lorsque les p\u00e9riph\u00e9riques de stockage sont r\u00e9partis sur un r\u00e9seau, la t\u00e2che de suivi du contenu est presque impossible. Ce sc\u00e9nario est de plus en plus courant dans les syst\u00e8mes de distribution de contenu en r\u00e9seau et deviendra probablement \u00e9galement important dans les sc\u00e9narios de r\u00e9seautage domestique. Il semblerait alors clair qu'un syst\u00e8me de gestion de contenu capable de g\u00e9rer efficacement les contenus riches en m\u00e9dias tout en exploitant \u00e9galement la capacit\u00e9 en r\u00e9seau des p\u00e9riph\u00e9riques de stockage est n\u00e9cessaire. Ce syst\u00e8me devrait permettre un stockage efficace et un acc\u00e8s au contenu sur des p\u00e9riph\u00e9riques de stockage r\u00e9seau h\u00e9t\u00e9rog\u00e8nes en fonction des pr\u00e9f\u00e9rences de l'utilisateur. Le syst\u00e8me de gestion de contenu doit traduire les pr\u00e9f\u00e9rences de l'utilisateur en politiques de stockage de bas niveau appropri\u00e9es et doit permettre \u00e0 ces pr\u00e9f\u00e9rences d'\u00eatre exprim\u00e9es \u00e0 un niveau de granularit\u00e9 fin -LRB- sans l'exiger en g\u00e9n\u00e9ral -RRB-. Le syst\u00e8me de gestion de contenu doit permettre \u00e0 l'utilisateur de manipuler et de raisonner sur -LRB-, c'est-\u00e0-dire de modifier la politique de stockage associ\u00e9e \u00e0 -RRB- le stockage des parties -LRB- du contenu multim\u00e9dia continu -RRB-. R\u00e9soudre ce probl\u00e8me de gestion de contenu distribu\u00e9 est difficile en raison du nombre d'exigences impos\u00e9es au syst\u00e8me. Par exemple :. Le syst\u00e8me de gestion de contenu doit fonctionner sur un grand nombre de syst\u00e8mes h\u00e9t\u00e9rog\u00e8nes. Dans certains cas, le syst\u00e8me peut g\u00e9rer le contenu stock\u00e9 sur un syst\u00e8me de fichiers local, tandis que dans d'autres, le contenu peut \u00eatre stock\u00e9 sur un appareil de stockage r\u00e9seau distinct. Le gestionnaire de contenu peut \u00eatre responsable de la mise en \u0153uvre des politiques qu'il utilise pour r\u00e9f\u00e9rencer le contenu ou ce r\u00f4le peut \u00eatre d\u00e9l\u00e9gu\u00e9 \u00e0 un ordinateur distinct. Une interface de programme d'application -LRB-API-RRB- et les protocoles r\u00e9seau associ\u00e9s sont n\u00e9cessaires pour que le syst\u00e8me de gestion de contenu fournisse une interface uniforme. .Le syst\u00e8me de gestion de contenu doit \u00eatre flexible et capable de g\u00e9rer diff\u00e9rentes exigences en mati\u00e8re de politiques de gestion de contenu. Ces politiques refl\u00e8tent quel contenu doit \u00eatre obtenu, quand il doit \u00eatre r\u00e9cup\u00e9r\u00e9, combien de temps il doit \u00eatre conserv\u00e9 et dans quelles circonstances il doit \u00eatre supprim\u00e9. Cela signifie que le syst\u00e8me de gestion de contenu doit permettre \u00e0 plusieurs applications de r\u00e9f\u00e9rencer du contenu avec un riche ensemble de politiques et qu'elles doivent toutes fonctionner ensemble de mani\u00e8re transparente. . Le syst\u00e8me de gestion de contenu doit \u00eatre capable de surveiller les r\u00e9f\u00e9rences du contenu et d'utiliser ces informations pour placer le contenu au bon endroit sur le r\u00e9seau pour un acc\u00e8s efficace aux applications. . Le syst\u00e8me de gestion de contenu doit g\u00e9rer l'interaction entre la population implicite et explicite de contenu \u00e0 la p\u00e9riph\u00e9rie du r\u00e9seau. . Le syst\u00e8me de contenu doit \u00eatre capable de g\u00e9rer efficacement de larges ensembles de contenus, y compris des flux continus. Il doit \u00eatre capable de regrouper ce contenu de mani\u00e8re \u00e0 ce qu'il soit facilement accessible aux utilisateurs. Pour r\u00e9soudre ces probl\u00e8mes, nous avons con\u00e7u et mis en \u0153uvre l'architecture du syst\u00e8me de gestion de contenu Spectrum. Il permet \u00e0 plusieurs applications de r\u00e9f\u00e9rencer du contenu en utilisant des politiques diff\u00e9rentes. A noter que l'architecture Spectrum suppose l'existence d'un r\u00e9seau de distribution de contenu -LRB-CDN-RRB- qui peut faciliter la distribution efficace du contenu -LRB- par exemple, l'architecture PRISM CDN -LSB- 2 -RSB- -RRB-. La section 2 d\u00e9crit l'architecture de notre syst\u00e8me de gestion de contenu. Dans la section 3, nous d\u00e9crivons \u00e0 la fois notre impl\u00e9mentation de l'architecture Spectrum et des exemples de son utilisation. 4. TRAVAUX CONNEXES Plusieurs auteurs ont abord\u00e9 le probl\u00e8me de la gestion de contenu dans les r\u00e9seaux distribu\u00e9s. Une grande partie du travail se concentre sur l\u2019aspect gestion des politiques. Par exemple dans -LSB- 5 -RSB-, le probl\u00e8me de la fourniture de contenu multim\u00e9dia via des serveurs distribu\u00e9s est consid\u00e9r\u00e9. Le contenu est distribu\u00e9 entre les ressources du serveur proportionnellement \u00e0 la demande des utilisateurs \u00e0 l'aide d'un protocole de diffusion de la demande. Les performances du syst\u00e8me sont \u00e9valu\u00e9es par simulation. Dans -LSB- 1 -RSB-, le contenu est distribu\u00e9 entre les sous-caches. La base de connaissances Cache permet d'utiliser des politiques sophistiqu\u00e9es. La simulation est utilis\u00e9e pour comparer le sch\u00e9ma propos\u00e9 avec des algorithmes de remplacement bien connus. Notre travail diff\u00e8re dans le sens o\u00f9 nous envisageons plus que les aspects du probl\u00e8me li\u00e9s \u00e0 la gestion politique. Apr\u00e8s avoir soigneusement examin\u00e9 les fonctionnalit\u00e9s requises pour mettre en \u0153uvre la gestion de contenu dans l'environnement en r\u00e9seau, nous avons divis\u00e9 le syst\u00e8me en trois fonctions simples, \u00e0 savoir le gestionnaire de contenu, le gestionnaire de politiques et le gestionnaire de stockage. Cela nous a permis de mettre en \u0153uvre et d\u2019exp\u00e9rimenter facilement un syst\u00e8me prototype. D'autres travaux connexes impliquent ce que l'on appelle les syst\u00e8mes de recommandation TV qui sont utilis\u00e9s dans les PVR pour s\u00e9lectionner automatiquement le contenu pour les utilisateurs, par exemple -LSB-6-RSB-. Enfin, dans l'environnement commercial CDN, les fournisseurs -LRB- par exempleCisco et Netapp -RRB- ont d\u00e9velopp\u00e9 et mis en \u0153uvre des produits et outils de gestion de contenu. 5. CONCLUSION ET TRAVAUX FUTURS Dans cet article, nous avons pr\u00e9sent\u00e9 la conception et la mise en \u0153uvre de l'architecture de gestion de contenu Spectrum. Spectrum permet d'appliquer des politiques de stockage \u00e0 de grands volumes de contenu pour faciliter un stockage efficace. Plus pr\u00e9cis\u00e9ment, le syst\u00e8me permet d'appliquer diff\u00e9rentes politiques au m\u00eame contenu sans r\u00e9plication. Spectrum peut \u00e9galement appliquer des politiques \u00ab temporelles \u00bb qui traitent efficacement du stockage de contenu multim\u00e9dia continu. Enfin, la conception modulaire de l'architecture Spectrum permet des r\u00e9alisations \u00e0 la fois autonomes et distribu\u00e9es afin que le syst\u00e8me puisse \u00eatre d\u00e9ploy\u00e9 dans une vari\u00e9t\u00e9 d'applications. Il existe un certain nombre de questions en suspens qui n\u00e9cessiteront des travaux futurs. Certains de ces probl\u00e8mes incluent : \u2022 Nous envisageons que Spectrum soit capable de g\u00e9rer le contenu sur des syst\u00e8mes allant des grands CDN aux appareils plus petits tels que TiVO -LSB- 8 -RSB-. Pour que ces petits syst\u00e8mes prennent en charge Spectrum, ils n\u00e9cessiteront une mise en r\u00e9seau et une API externe. Lorsque cette API sera disponible, nous devrons d\u00e9terminer comment elle peut s'int\u00e9grer dans l'architecture Spectrum. \u2022 Spectrum nomme le contenu par URL, mais nous n'avons intentionnellement pas d\u00e9fini le format des URL Spectrum, la mani\u00e8re dont elles correspondent au nom r\u00e9el du contenu, ou la mani\u00e8re dont les noms et les URL doivent \u00eatre pr\u00e9sent\u00e9s \u00e0 l'utilisateur. \u2022 Dans cet article, nous nous sommes concentr\u00e9s sur la gestion de contenu pour les objets multim\u00e9dias continus. \u2022 Tout projet permettant de partager facilement du contenu multim\u00e9dia sur Internet devra surmonter des obstacles juridiques avant de pouvoir \u00eatre largement accept\u00e9. L'adaptation de Spectrum pour r\u00e9pondre aux exigences l\u00e9gales n\u00e9cessitera probablement plus de travail technique.comment ils correspondent au nom r\u00e9el du contenu, ou comment les noms et les URL doivent \u00eatre pr\u00e9sent\u00e9s \u00e0 l'utilisateur. \u2022 Dans cet article, nous nous sommes concentr\u00e9s sur la gestion de contenu pour les objets multim\u00e9dias continus. \u2022 Tout projet permettant de partager facilement du contenu multim\u00e9dia sur Internet devra surmonter des obstacles juridiques avant de pouvoir \u00eatre largement accept\u00e9. L'adaptation de Spectrum pour r\u00e9pondre aux exigences l\u00e9gales n\u00e9cessitera probablement plus de travail technique.comment ils correspondent au nom r\u00e9el du contenu, ou comment les noms et les URL doivent \u00eatre pr\u00e9sent\u00e9s \u00e0 l'utilisateur. \u2022 Dans cet article, nous nous sommes concentr\u00e9s sur la gestion de contenu pour les objets multim\u00e9dias continus. \u2022 Tout projet permettant de partager facilement du contenu multim\u00e9dia sur Internet devra surmonter des obstacles juridiques avant de pouvoir \u00eatre largement accept\u00e9. L'adaptation de Spectrum pour r\u00e9pondre aux exigences l\u00e9gales n\u00e9cessitera probablement plus de travail technique.", "keyphrases": ["syst\u00e8me de gestion du contenu du spectre", "continuer le stockage des m\u00e9dias", "sc\u00e9nario de r\u00e9seau domestique", "interface du programme d'application", "r\u00e9seau de distribution de contenu", "localisation uniforme des ressources", "gestion de la police", "r\u00e9seau activer dvr", "syst\u00e8me de bases de donn\u00e9es performant", "gestion du spectre de qualit\u00e9 op\u00e9rateur"]}
{"file_name": "H-11", "text": "Conception optimale laplacienne pour la r\u00e9cup\u00e9ration d'images R\u00c9SUM\u00c9 Le retour de pertinence est une technique puissante pour am\u00e9liorer les performances de la r\u00e9cup\u00e9ration d'images bas\u00e9e sur le contenu -LRB- CBIR -RRB-. Il sollicite les jugements de pertinence de l'utilisateur sur les images r\u00e9cup\u00e9r\u00e9es renvoy\u00e9es par les syst\u00e8mes CBIR. L'\u00e9tiquetage de l'utilisateur est ensuite utilis\u00e9 pour apprendre un classificateur permettant de distinguer les images pertinentes et non pertinentes. Cependant, les images les plus renvoy\u00e9es ne sont peut-\u00eatre pas les plus informatives. Le d\u00e9fi est donc de d\u00e9terminer quelles images non \u00e9tiquet\u00e9es seraient les plus informatives -LRB- c'est-\u00e0-dire am\u00e9lioreraient le plus le classificateur -RRB- si elles \u00e9taient \u00e9tiquet\u00e9es et utilis\u00e9es comme \u00e9chantillons d'apprentissage. Dans cet article, nous proposons un nouvel algorithme d'apprentissage actif, appel\u00e9 Laplacian Optimal Design -LRB-LOD-RRB-, pour la r\u00e9cup\u00e9ration d'images de retour de pertinence. Notre algorithme est bas\u00e9 sur un mod\u00e8le de r\u00e9gression qui minimise l'erreur des moindres carr\u00e9s sur les images mesur\u00e9es -LRB- ou \u00e9tiquet\u00e9es -RRB- et pr\u00e9serve simultan\u00e9ment la structure g\u00e9om\u00e9trique locale de l'espace image. Plus pr\u00e9cis\u00e9ment, nous supposons que si deux images sont suffisamment proches l\u2019une de l\u2019autre, alors leurs mesures -LRB- ou leurs \u00e9tiquettes -RRB- sont \u00e9galement proches. En construisant un graphe du plus proche voisin, la structure g\u00e9om\u00e9trique de l'espace image peut \u00eatre d\u00e9crite par le graphe Laplacien. Nous discutons de la mani\u00e8re dont les r\u00e9sultats du domaine de la conception exp\u00e9rimentale optimale peuvent \u00eatre utilis\u00e9s pour guider notre s\u00e9lection d'un sous-ensemble d'images, qui nous fournit le plus grand nombre d'informations. Les r\u00e9sultats exp\u00e9rimentaux sur la base de donn\u00e9es Corel sugg\u00e8rent que l'approche propos\u00e9e permet d'obtenir une plus grande pr\u00e9cision dans la r\u00e9cup\u00e9ration d'images de retour de pertinence. 1. INTRODUCTION Dans de nombreuses t\u00e2ches d'apprentissage automatique et de r\u00e9cup\u00e9ration d'informations, les donn\u00e9es non \u00e9tiquet\u00e9es ne manquent pas, mais les \u00e9tiquettes sont co\u00fbteuses. Le d\u00e9fi est donc de d\u00e9terminer quels \u00e9chantillons non \u00e9tiquet\u00e9s seraient les plus informatifs -LRB-, c'est-\u00e0-dire am\u00e9lioreraient le plus le classificateur -RRB- s'ils \u00e9taient \u00e9tiquet\u00e9s et utilis\u00e9s comme \u00e9chantillons d'apprentissage. Ce probl\u00e8me est g\u00e9n\u00e9ralement appel\u00e9 apprentissage actif -LSB- 4 -RSB-. De nombreuses applications du monde r\u00e9el peuvent \u00eatre int\u00e9gr\u00e9es dans un cadre d'apprentissage actif. En particulier, nous consid\u00e9rons le probl\u00e8me de la r\u00e9cup\u00e9ration d\u2019images bas\u00e9e sur le contenu bas\u00e9e sur le retour de pertinence -LRB-CBIR-RRB- -LSB- 13 -RSB-. La recherche d\u2019images bas\u00e9e sur le contenu a suscit\u00e9 un int\u00e9r\u00eat consid\u00e9rable au cours de la derni\u00e8re d\u00e9cennie -LSB-13-RSB-. Cette approche est motiv\u00e9e par la croissance rapide des bases de donn\u00e9es d'images num\u00e9riques qui, \u00e0 leur tour, n\u00e9cessitent des syst\u00e8mes de recherche efficaces. Plut\u00f4t que de d\u00e9crire une image \u00e0 l'aide de text, dans ces syst\u00e8mes, une requ\u00eate d'image est d\u00e9crite \u00e0 l'aide d'un ou plusieurs exemples d'images. Les caract\u00e9ristiques visuelles de bas niveau -LRB- couleur, texture, forme, etc. -RRB- sont automatiquement extraites pour repr\u00e9senter les images. Pour r\u00e9duire le foss\u00e9 s\u00e9mantique, un retour de pertinence est introduit dans CBIR -LSB-12-RSB-. Dans de nombreux syst\u00e8mes CBIR actuels pilot\u00e9s par retour de pertinence, l'utilisateur doit fournir son jugement de pertinence sur les principales images renvoy\u00e9es par le syst\u00e8me.Les images \u00e9tiquet\u00e9es sont ensuite utilis\u00e9es pour entra\u00eener un classificateur afin de s\u00e9parer les images qui correspondent au concept de requ\u00eate de celles qui ne le correspondent pas. Cependant, en g\u00e9n\u00e9ral, les images les plus renvoy\u00e9es ne sont peut-\u00eatre pas les plus informatives. Dans le pire des cas, toutes les meilleures images \u00e9tiquet\u00e9es par l'utilisateur peuvent \u00eatre positives et les techniques de classification standard ne peuvent donc pas \u00eatre appliqu\u00e9es en raison du manque d'exemples n\u00e9gatifs. Contrairement aux probl\u00e8mes de classification standard dans lesquels les \u00e9chantillons \u00e9tiquet\u00e9s sont pr\u00e9-donn\u00e9s, dans la r\u00e9cup\u00e9ration d'images par retour de pertinence, le syst\u00e8me peut s\u00e9lectionner activement les images \u00e0 \u00e9tiqueter. Ainsi, l\u2019apprentissage actif peut \u00eatre naturellement introduit dans la recherche d\u2019images. Malgr\u00e9 les nombreuses techniques d'apprentissage actif existantes, l'apprentissage actif de la machine \u00e0 vecteurs de support -LRB-SVM-RRB-LSB-14-RSB- et l'apprentissage actif bas\u00e9 sur la r\u00e9gression -LSB-1-RSB- ont suscit\u00e9 le plus d'int\u00e9r\u00eat. L\u2019inconv\u00e9nient majeur de l\u2019apprentissage actif SVM est que la limite estim\u00e9e peut ne pas \u00eatre suffisamment pr\u00e9cise. De plus, il ne peut pas \u00eatre appliqu\u00e9 au d\u00e9but de la r\u00e9cup\u00e9ration lorsqu'il n'y a pas d'images \u00e9tiquet\u00e9es. Certains autres algorithmes d'apprentissage actif bas\u00e9s sur SVM peuvent \u00eatre trouv\u00e9s dans -LSB- 7 -RSB-, -LSB- 9 -RSB-. En statistiques, le probl\u00e8me de la s\u00e9lection des \u00e9chantillons \u00e0 \u00e9tiqueter est g\u00e9n\u00e9ralement appel\u00e9 plan exp\u00e9rimental. L'\u00e9chantillon x est appel\u00e9 exp\u00e9rience et son \u00e9tiquette y est appel\u00e9e mesure. L'\u00e9tude du plan exp\u00e9rimental optimal -LRB- OED -RRB- -LSB- 1 -RSB- concerne la conception d'exp\u00e9riences cens\u00e9es minimiser les variances d'un mod\u00e8le param\u00e9tr\u00e9. L'objectif d'une conception exp\u00e9rimentale optimale est g\u00e9n\u00e9ralement de maximiser la confiance dans un mod\u00e8le donn\u00e9, de minimiser les variances des param\u00e8tres pour l'identification du syst\u00e8me ou de minimiser la variance de sortie du mod\u00e8le. Les approches classiques de conception exp\u00e9rimentale incluent la conception A-Optimal, la conception D-Optimal et la conception E-Optimal. Toutes ces approches sont bas\u00e9es sur un mod\u00e8le de r\u00e9gression des moindres carr\u00e9s. Par rapport aux algorithmes d'apprentissage actif bas\u00e9s sur SVM, les approches de conception exp\u00e9rimentale sont beaucoup plus efficaces en termes de calcul. Cependant, ce type d'approche ne prend en compte que les donn\u00e9es mesur\u00e9es -LRB- ou \u00e9tiquet\u00e9es -RRB- dans leur fonction objectif, tandis que les donn\u00e9es non mesur\u00e9es -LRB- ou non \u00e9tiquet\u00e9es -RRB- sont ignor\u00e9es. B\u00e9n\u00e9ficiant des progr\u00e8s r\u00e9cents en mati\u00e8re de conception exp\u00e9rimentale optimale et d\u2019apprentissage semi-supervis\u00e9, nous proposons dans cet article un nouvel algorithme d\u2019apprentissage actif pour la r\u00e9cup\u00e9ration d\u2019images, appel\u00e9 Laplacian Optimal Design -LRB-LOD-RRB-. Contrairement aux m\u00e9thodes de conception exp\u00e9rimentale traditionnelles dont les fonctions de perte sont d\u00e9finies uniquement sur les points mesur\u00e9s, la fonction de perte de notre algorithme LOD propos\u00e9 est d\u00e9finie \u00e0 la fois sur les points mesur\u00e9s et non mesur\u00e9s. Plus pr\u00e9cis\u00e9ment, nous introduisons un r\u00e9gulariseur pr\u00e9servant la localit\u00e9 dans la fonction de perte standard bas\u00e9e sur les moindres carr\u00e9s. La nouvelle fonction de perte vise \u00e0 trouver un classificateur localement aussi fluide que possible. En d\u2019autres termes, si deux points sont suffisamment proches l\u2019un de l\u2019autre dans l\u2019espace d\u2019entr\u00e9e, alors ils sont cens\u00e9s partager la m\u00eame \u00e9tiquette.Une fois la fonction de perte d\u00e9finie, nous pouvons s\u00e9lectionner les points de donn\u00e9es les plus informatifs qui sont pr\u00e9sent\u00e9s \u00e0 l'utilisateur pour l'\u00e9tiquetage. Il serait important de noter que les images les plus informatives ne sont peut-\u00eatre pas les images les plus renvoy\u00e9es. Le reste du document est organis\u00e9 comme suit. Dans la section 2, nous fournissons une br\u00e8ve description des travaux connexes. Notre algorithme de conception optimale laplacien propos\u00e9 est introduit dans la section 3. Dans la section 4, nous comparons notre algorithme avec les algorithmes de l'\u00e9tat de la technique et pr\u00e9sentons les r\u00e9sultats exp\u00e9rimentaux sur la r\u00e9cup\u00e9ration d'images. Enfin, nous fournissons quelques remarques finales et des suggestions pour des travaux futurs dans la section 5. 2. TRAVAUX CONNEXES Puisque notre algorithme propos\u00e9 est bas\u00e9 sur un cadre de r\u00e9gression. Le travail le plus connexe est la conception exp\u00e9rimentale optimale -LSB-1-RSB-, comprenant la conception A-Optimal, la conception D-Optimal et la conception EOptimal. Dans cette section, nous donnons une br\u00e8ve description de ces approches. 2.1 Le probl\u00e8me de l'apprentissage actif Le probl\u00e8me g\u00e9n\u00e9rique de l'apprentissage actif est le suivant. En d'autres termes, les points zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- peuvent am\u00e9liorer le plus le classificateur s'ils sont \u00e9tiquet\u00e9s et utilis\u00e9s comme points d'entra\u00eenement. 2.2 Plan exp\u00e9rimental optimal Nous consid\u00e9rons un mod\u00e8le de r\u00e9gression lin\u00e9aire. Diff\u00e9rentes observations comportent des erreurs ind\u00e9pendantes, mais avec des variances \u00e9gales \u03c32. Ainsi, l'estimation du maximum de vraisemblance pour le vecteur de poids, \u02c6w, est celle qui minimise l'erreur de somme quadratique. Les trois mesures scalaires les plus courantes de la taille de la matrice de covariance des param\u00e8tres dans le plan exp\u00e9rimental optimal sont : \u2022 Plan D-optimal : d\u00e9terminant de Hsse . \u2022 Conception A-optimale : trace de Hsse. \u2022 Conception E-optimale : valeur propre maximale de Hsse. Puisque le calcul du d\u00e9terminant et des valeurs propres d\u2019une matrice est beaucoup plus co\u00fbteux que le calcul de la trace matricielle, le plan A-optimal est plus efficace que les deux autres. Certains travaux r\u00e9cents sur la conception exp\u00e9rimentale peuvent \u00eatre trouv\u00e9s dans -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONS ET TRAVAUX FUTURS Cet article d\u00e9crit un nouvel algorithme d'apprentissage actif, appel\u00e9 conception optimale laplacienne, pour permettre une r\u00e9cup\u00e9ration plus efficace d'images de retour de pertinence. Notre algorithme est bas\u00e9 sur une fonction objectif qui minimise simultan\u00e9ment l'erreur empirique et pr\u00e9serve la structure g\u00e9om\u00e9trique locale de l'espace de donn\u00e9es. En utilisant des techniques de conception exp\u00e9rimentale, notre algorithme trouve les images les plus informatives \u00e0 \u00e9tiqueter. Ces images \u00e9tiquet\u00e9es et les images non \u00e9tiquet\u00e9es de la base de donn\u00e9es sont utilis\u00e9es pour apprendre un classificateur. Les r\u00e9sultats exp\u00e9rimentaux sur la base de donn\u00e9es Corel montrent que l'apprentissage actif et l'apprentissage semi-supervis\u00e9 peuvent am\u00e9liorer consid\u00e9rablement les performances de r\u00e9cup\u00e9ration. Dans cet article, nous consid\u00e9rons le probl\u00e8me de r\u00e9cup\u00e9ration d\u2019images sur des donn\u00e9es d\u2019image petites, statiques et de domaine ferm\u00e9. Pour la recherche d\u2019images Web, il est possible de collecter une grande quantit\u00e9 d\u2019informations sur les clics des utilisateurs. Ces informations peuvent naturellement \u00eatre utilis\u00e9es pour construire le graphe d\u2019affinit\u00e9 dans notre algorithme.nous pouvons s\u00e9lectionner les points de donn\u00e9es les plus informatifs qui sont pr\u00e9sent\u00e9s \u00e0 l'utilisateur pour l'\u00e9tiquetage. Il serait important de noter que les images les plus informatives ne sont peut-\u00eatre pas les images les plus renvoy\u00e9es. Le reste du document est organis\u00e9 comme suit. Dans la section 2, nous fournissons une br\u00e8ve description des travaux connexes. Notre algorithme de conception optimale laplacien propos\u00e9 est introduit dans la section 3. Dans la section 4, nous comparons notre algorithme avec les algorithmes de l'\u00e9tat de la technique et pr\u00e9sentons les r\u00e9sultats exp\u00e9rimentaux sur la r\u00e9cup\u00e9ration d'images. Enfin, nous fournissons quelques remarques finales et des suggestions pour des travaux futurs dans la section 5. 2. TRAVAUX CONNEXES Puisque notre algorithme propos\u00e9 est bas\u00e9 sur un cadre de r\u00e9gression. Le travail le plus connexe est la conception exp\u00e9rimentale optimale -LSB-1-RSB-, comprenant la conception A-Optimal, la conception D-Optimal et la conception EOptimal. Dans cette section, nous donnons une br\u00e8ve description de ces approches. 2.1 Le probl\u00e8me de l'apprentissage actif Le probl\u00e8me g\u00e9n\u00e9rique de l'apprentissage actif est le suivant. En d'autres termes, les points zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- peuvent am\u00e9liorer le plus le classificateur s'ils sont \u00e9tiquet\u00e9s et utilis\u00e9s comme points d'entra\u00eenement. 2.2 Plan exp\u00e9rimental optimal Nous consid\u00e9rons un mod\u00e8le de r\u00e9gression lin\u00e9aire. Diff\u00e9rentes observations comportent des erreurs ind\u00e9pendantes, mais avec des variances \u00e9gales \u03c32. Ainsi, l'estimation du maximum de vraisemblance pour le vecteur de poids, \u02c6w, est celle qui minimise l'erreur de somme quadratique. Les trois mesures scalaires les plus courantes de la taille de la matrice de covariance des param\u00e8tres dans le plan exp\u00e9rimental optimal sont : \u2022 Plan D-optimal : d\u00e9terminant de Hsse . \u2022 Conception A-optimale : trace de Hsse. \u2022 Conception E-optimale : valeur propre maximale de Hsse. Puisque le calcul du d\u00e9terminant et des valeurs propres d\u2019une matrice est beaucoup plus co\u00fbteux que le calcul de la trace matricielle, le plan A-optimal est plus efficace que les deux autres. Certains travaux r\u00e9cents sur la conception exp\u00e9rimentale peuvent \u00eatre trouv\u00e9s dans -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONS ET TRAVAUX FUTURS Cet article d\u00e9crit un nouvel algorithme d'apprentissage actif, appel\u00e9 conception optimale laplacienne, pour permettre une r\u00e9cup\u00e9ration plus efficace d'images de retour de pertinence. Notre algorithme est bas\u00e9 sur une fonction objectif qui minimise simultan\u00e9ment l'erreur empirique et pr\u00e9serve la structure g\u00e9om\u00e9trique locale de l'espace de donn\u00e9es. En utilisant des techniques de conception exp\u00e9rimentale, notre algorithme trouve les images les plus informatives \u00e0 \u00e9tiqueter. Ces images \u00e9tiquet\u00e9es et les images non \u00e9tiquet\u00e9es de la base de donn\u00e9es sont utilis\u00e9es pour apprendre un classificateur. Les r\u00e9sultats exp\u00e9rimentaux sur la base de donn\u00e9es Corel montrent que l'apprentissage actif et l'apprentissage semi-supervis\u00e9 peuvent am\u00e9liorer consid\u00e9rablement les performances de r\u00e9cup\u00e9ration. Dans cet article, nous consid\u00e9rons le probl\u00e8me de r\u00e9cup\u00e9ration d\u2019images sur des donn\u00e9es d\u2019image petites, statiques et de domaine ferm\u00e9. Pour la recherche d\u2019images Web, il est possible de collecter une grande quantit\u00e9 d\u2019informations sur les clics des utilisateurs. Ces informations peuvent naturellement \u00eatre utilis\u00e9es pour construire le graphe d\u2019affinit\u00e9 dans notre algorithme.nous pouvons s\u00e9lectionner les points de donn\u00e9es les plus informatifs qui sont pr\u00e9sent\u00e9s \u00e0 l'utilisateur pour l'\u00e9tiquetage. Il serait important de noter que les images les plus informatives ne sont peut-\u00eatre pas les images les plus renvoy\u00e9es. Le reste du document est organis\u00e9 comme suit. Dans la section 2, nous fournissons une br\u00e8ve description des travaux connexes. Notre algorithme de conception optimale laplacien propos\u00e9 est introduit dans la section 3. Dans la section 4, nous comparons notre algorithme avec les algorithmes de l'\u00e9tat de la technique et pr\u00e9sentons les r\u00e9sultats exp\u00e9rimentaux sur la r\u00e9cup\u00e9ration d'images. Enfin, nous fournissons quelques remarques finales et des suggestions pour des travaux futurs dans la section 5. 2. TRAVAUX CONNEXES Puisque notre algorithme propos\u00e9 est bas\u00e9 sur un cadre de r\u00e9gression. Le travail le plus connexe est la conception exp\u00e9rimentale optimale -LSB-1-RSB-, comprenant la conception A-Optimal, la conception D-Optimal et la conception EOptimal. Dans cette section, nous donnons une br\u00e8ve description de ces approches. 2.1 Le probl\u00e8me de l'apprentissage actif Le probl\u00e8me g\u00e9n\u00e9rique de l'apprentissage actif est le suivant. En d'autres termes, les points zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- peuvent am\u00e9liorer le plus le classificateur s'ils sont \u00e9tiquet\u00e9s et utilis\u00e9s comme points d'entra\u00eenement. 2.2 Plan exp\u00e9rimental optimal Nous consid\u00e9rons un mod\u00e8le de r\u00e9gression lin\u00e9aire. Diff\u00e9rentes observations comportent des erreurs ind\u00e9pendantes, mais avec des variances \u00e9gales \u03c32. Ainsi, l'estimation du maximum de vraisemblance pour le vecteur de poids, \u02c6w, est celle qui minimise l'erreur de somme quadratique. Les trois mesures scalaires les plus courantes de la taille de la matrice de covariance des param\u00e8tres dans le plan exp\u00e9rimental optimal sont : \u2022 Plan D-optimal : d\u00e9terminant de Hsse . \u2022 Conception A-optimale : trace de Hsse. \u2022 Conception E-optimale : valeur propre maximale de Hsse. Puisque le calcul du d\u00e9terminant et des valeurs propres d\u2019une matrice est beaucoup plus co\u00fbteux que le calcul de la trace matricielle, le plan A-optimal est plus efficace que les deux autres. Certains travaux r\u00e9cents sur la conception exp\u00e9rimentale peuvent \u00eatre trouv\u00e9s dans -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONS ET TRAVAUX FUTURS Cet article d\u00e9crit un nouvel algorithme d'apprentissage actif, appel\u00e9 conception optimale laplacienne, pour permettre une r\u00e9cup\u00e9ration plus efficace d'images de retour de pertinence. Notre algorithme est bas\u00e9 sur une fonction objectif qui minimise simultan\u00e9ment l'erreur empirique et pr\u00e9serve la structure g\u00e9om\u00e9trique locale de l'espace de donn\u00e9es. En utilisant des techniques de conception exp\u00e9rimentale, notre algorithme trouve les images les plus informatives \u00e0 \u00e9tiqueter. Ces images \u00e9tiquet\u00e9es et les images non \u00e9tiquet\u00e9es de la base de donn\u00e9es sont utilis\u00e9es pour apprendre un classificateur. Les r\u00e9sultats exp\u00e9rimentaux sur la base de donn\u00e9es Corel montrent que l'apprentissage actif et l'apprentissage semi-supervis\u00e9 peuvent am\u00e9liorer consid\u00e9rablement les performances de r\u00e9cup\u00e9ration. Dans cet article, nous consid\u00e9rons le probl\u00e8me de r\u00e9cup\u00e9ration d\u2019images sur des donn\u00e9es d\u2019image petites, statiques et de domaine ferm\u00e9. Pour la recherche d\u2019images Web, il est possible de collecter une grande quantit\u00e9 d\u2019informations sur les clics des utilisateurs. Ces informations peuvent naturellement \u00eatre utilis\u00e9es pour construire le graphe d\u2019affinit\u00e9 dans notre algorithme.Le reste du document est organis\u00e9 comme suit. Dans la section 2, nous fournissons une br\u00e8ve description des travaux connexes. Notre algorithme de conception optimale laplacien propos\u00e9 est introduit dans la section 3. Dans la section 4, nous comparons notre algorithme avec les algorithmes de l'\u00e9tat de la technique et pr\u00e9sentons les r\u00e9sultats exp\u00e9rimentaux sur la r\u00e9cup\u00e9ration d'images. Enfin, nous fournissons quelques remarques finales et des suggestions pour des travaux futurs dans la section 5. 2. TRAVAUX CONNEXES Puisque notre algorithme propos\u00e9 est bas\u00e9 sur un cadre de r\u00e9gression. Le travail le plus connexe est la conception exp\u00e9rimentale optimale -LSB-1-RSB-, comprenant la conception A-Optimal, la conception D-Optimal et la conception EOptimal. Dans cette section, nous donnons une br\u00e8ve description de ces approches. 2.1 Le probl\u00e8me de l'apprentissage actif Le probl\u00e8me g\u00e9n\u00e9rique de l'apprentissage actif est le suivant. En d'autres termes, les points zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- peuvent am\u00e9liorer le plus le classificateur s'ils sont \u00e9tiquet\u00e9s et utilis\u00e9s comme points d'entra\u00eenement. 2.2 Plan exp\u00e9rimental optimal Nous consid\u00e9rons un mod\u00e8le de r\u00e9gression lin\u00e9aire. Diff\u00e9rentes observations comportent des erreurs ind\u00e9pendantes, mais avec des variances \u00e9gales \u03c32. Ainsi, l'estimation du maximum de vraisemblance pour le vecteur de poids, \u02c6w, est celle qui minimise l'erreur de somme quadratique. Les trois mesures scalaires les plus courantes de la taille de la matrice de covariance des param\u00e8tres dans le plan exp\u00e9rimental optimal sont : \u2022 Plan D-optimal : d\u00e9terminant de Hsse . \u2022 Conception A-optimale : trace de Hsse. \u2022 Conception E-optimale : valeur propre maximale de Hsse. Puisque le calcul du d\u00e9terminant et des valeurs propres d\u2019une matrice est beaucoup plus co\u00fbteux que le calcul de la trace matricielle, le plan A-optimal est plus efficace que les deux autres. Certains travaux r\u00e9cents sur la conception exp\u00e9rimentale peuvent \u00eatre trouv\u00e9s dans -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONS ET TRAVAUX FUTURS Cet article d\u00e9crit un nouvel algorithme d'apprentissage actif, appel\u00e9 conception optimale laplacienne, pour permettre une r\u00e9cup\u00e9ration plus efficace d'images de retour de pertinence. Notre algorithme est bas\u00e9 sur une fonction objectif qui minimise simultan\u00e9ment l'erreur empirique et pr\u00e9serve la structure g\u00e9om\u00e9trique locale de l'espace de donn\u00e9es. En utilisant des techniques de conception exp\u00e9rimentale, notre algorithme trouve les images les plus informatives \u00e0 \u00e9tiqueter. Ces images \u00e9tiquet\u00e9es et les images non \u00e9tiquet\u00e9es de la base de donn\u00e9es sont utilis\u00e9es pour apprendre un classificateur. Les r\u00e9sultats exp\u00e9rimentaux sur la base de donn\u00e9es Corel montrent que l'apprentissage actif et l'apprentissage semi-supervis\u00e9 peuvent am\u00e9liorer consid\u00e9rablement les performances de r\u00e9cup\u00e9ration. Dans cet article, nous consid\u00e9rons le probl\u00e8me de r\u00e9cup\u00e9ration d\u2019images sur des donn\u00e9es d\u2019image petites, statiques et de domaine ferm\u00e9. Pour la recherche d\u2019images Web, il est possible de collecter une grande quantit\u00e9 d\u2019informations sur les clics des utilisateurs. Ces informations peuvent naturellement \u00eatre utilis\u00e9es pour construire le graphe d\u2019affinit\u00e9 dans notre algorithme.Le reste du document est organis\u00e9 comme suit. Dans la section 2, nous fournissons une br\u00e8ve description des travaux connexes. Notre algorithme de conception optimale laplacien propos\u00e9 est introduit dans la section 3. Dans la section 4, nous comparons notre algorithme avec les algorithmes de l'\u00e9tat de la technique et pr\u00e9sentons les r\u00e9sultats exp\u00e9rimentaux sur la r\u00e9cup\u00e9ration d'images. Enfin, nous fournissons quelques remarques finales et des suggestions pour des travaux futurs dans la section 5. 2. TRAVAUX CONNEXES Puisque notre algorithme propos\u00e9 est bas\u00e9 sur un cadre de r\u00e9gression. Le travail le plus connexe est la conception exp\u00e9rimentale optimale -LSB-1-RSB-, comprenant la conception A-Optimal, la conception D-Optimal et la conception EOptimal. Dans cette section, nous donnons une br\u00e8ve description de ces approches. 2.1 Le probl\u00e8me de l'apprentissage actif Le probl\u00e8me g\u00e9n\u00e9rique de l'apprentissage actif est le suivant. En d'autres termes, les points zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- peuvent am\u00e9liorer le plus le classificateur s'ils sont \u00e9tiquet\u00e9s et utilis\u00e9s comme points d'entra\u00eenement. 2.2 Plan exp\u00e9rimental optimal Nous consid\u00e9rons un mod\u00e8le de r\u00e9gression lin\u00e9aire. Diff\u00e9rentes observations comportent des erreurs ind\u00e9pendantes, mais avec des variances \u00e9gales \u03c32. Ainsi, l'estimation du maximum de vraisemblance pour le vecteur de poids, \u02c6w, est celle qui minimise l'erreur de somme quadratique. Les trois mesures scalaires les plus courantes de la taille de la matrice de covariance des param\u00e8tres dans le plan exp\u00e9rimental optimal sont : \u2022 Plan D-optimal : d\u00e9terminant de Hsse . \u2022 Conception A-optimale : trace de Hsse. \u2022 Conception E-optimale : valeur propre maximale de Hsse. Puisque le calcul du d\u00e9terminant et des valeurs propres d\u2019une matrice est beaucoup plus co\u00fbteux que le calcul de la trace matricielle, le plan A-optimal est plus efficace que les deux autres. Certains travaux r\u00e9cents sur la conception exp\u00e9rimentale peuvent \u00eatre trouv\u00e9s dans -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONS ET TRAVAUX FUTURS Cet article d\u00e9crit un nouvel algorithme d'apprentissage actif, appel\u00e9 conception optimale laplacienne, pour permettre une r\u00e9cup\u00e9ration plus efficace d'images de retour de pertinence. Notre algorithme est bas\u00e9 sur une fonction objectif qui minimise simultan\u00e9ment l'erreur empirique et pr\u00e9serve la structure g\u00e9om\u00e9trique locale de l'espace de donn\u00e9es. En utilisant des techniques de conception exp\u00e9rimentale, notre algorithme trouve les images les plus informatives \u00e0 \u00e9tiqueter. Ces images \u00e9tiquet\u00e9es et les images non \u00e9tiquet\u00e9es de la base de donn\u00e9es sont utilis\u00e9es pour apprendre un classificateur. Les r\u00e9sultats exp\u00e9rimentaux sur la base de donn\u00e9es Corel montrent que l'apprentissage actif et l'apprentissage semi-supervis\u00e9 peuvent am\u00e9liorer consid\u00e9rablement les performances de r\u00e9cup\u00e9ration. Dans cet article, nous consid\u00e9rons le probl\u00e8me de r\u00e9cup\u00e9ration d\u2019images sur des donn\u00e9es d\u2019image petites, statiques et de domaine ferm\u00e9. Pour la recherche d\u2019images Web, il est possible de collecter une grande quantit\u00e9 d\u2019informations sur les clics des utilisateurs. Ces informations peuvent naturellement \u00eatre utilis\u00e9es pour construire le graphe d\u2019affinit\u00e9 dans notre algorithme.nous comparons notre algorithme avec les algorithmes de l'\u00e9tat de la technique et pr\u00e9sentons les r\u00e9sultats exp\u00e9rimentaux sur la r\u00e9cup\u00e9ration d'images. Enfin, nous fournissons quelques remarques finales et des suggestions pour des travaux futurs dans la section 5. 2. TRAVAUX CONNEXES Puisque notre algorithme propos\u00e9 est bas\u00e9 sur un cadre de r\u00e9gression. Le travail le plus connexe est la conception exp\u00e9rimentale optimale -LSB-1-RSB-, comprenant la conception A-Optimal, la conception D-Optimal et la conception EOptimal. Dans cette section, nous donnons une br\u00e8ve description de ces approches. 2.1 Le probl\u00e8me de l'apprentissage actif Le probl\u00e8me g\u00e9n\u00e9rique de l'apprentissage actif est le suivant. En d'autres termes, les points zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- peuvent am\u00e9liorer le plus le classificateur s'ils sont \u00e9tiquet\u00e9s et utilis\u00e9s comme points d'entra\u00eenement. 2.2 Plan exp\u00e9rimental optimal Nous consid\u00e9rons un mod\u00e8le de r\u00e9gression lin\u00e9aire. Diff\u00e9rentes observations comportent des erreurs ind\u00e9pendantes, mais avec des variances \u00e9gales \u03c32. Ainsi, l'estimation du maximum de vraisemblance pour le vecteur de poids, \u02c6w, est celle qui minimise l'erreur de somme quadratique. Les trois mesures scalaires les plus courantes de la taille de la matrice de covariance des param\u00e8tres dans le plan exp\u00e9rimental optimal sont : \u2022 Plan D-optimal : d\u00e9terminant de Hsse . \u2022 Conception A-optimale : trace de Hsse. \u2022 Conception E-optimale : valeur propre maximale de Hsse. Puisque le calcul du d\u00e9terminant et des valeurs propres d\u2019une matrice est beaucoup plus co\u00fbteux que le calcul de la trace matricielle, le plan A-optimal est plus efficace que les deux autres. Certains travaux r\u00e9cents sur la conception exp\u00e9rimentale peuvent \u00eatre trouv\u00e9s dans -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONS ET TRAVAUX FUTURS Cet article d\u00e9crit un nouvel algorithme d'apprentissage actif, appel\u00e9 conception optimale laplacienne, pour permettre une r\u00e9cup\u00e9ration plus efficace d'images de retour de pertinence. Notre algorithme est bas\u00e9 sur une fonction objectif qui minimise simultan\u00e9ment l'erreur empirique et pr\u00e9serve la structure g\u00e9om\u00e9trique locale de l'espace de donn\u00e9es. En utilisant des techniques de conception exp\u00e9rimentale, notre algorithme trouve les images les plus informatives \u00e0 \u00e9tiqueter. Ces images \u00e9tiquet\u00e9es et les images non \u00e9tiquet\u00e9es de la base de donn\u00e9es sont utilis\u00e9es pour apprendre un classificateur. Les r\u00e9sultats exp\u00e9rimentaux sur la base de donn\u00e9es Corel montrent que l'apprentissage actif et l'apprentissage semi-supervis\u00e9 peuvent am\u00e9liorer consid\u00e9rablement les performances de r\u00e9cup\u00e9ration. Dans cet article, nous consid\u00e9rons le probl\u00e8me de r\u00e9cup\u00e9ration d\u2019images sur des donn\u00e9es d\u2019image petites, statiques et de domaine ferm\u00e9. Pour la recherche d\u2019images Web, il est possible de collecter une grande quantit\u00e9 d\u2019informations sur les clics des utilisateurs. Ces informations peuvent naturellement \u00eatre utilis\u00e9es pour construire le graphe d\u2019affinit\u00e9 dans notre algorithme.nous comparons notre algorithme avec les algorithmes de l'\u00e9tat de la technique et pr\u00e9sentons les r\u00e9sultats exp\u00e9rimentaux sur la r\u00e9cup\u00e9ration d'images. Enfin, nous fournissons quelques remarques finales et des suggestions pour des travaux futurs dans la section 5. 2. TRAVAUX CONNEXES Puisque notre algorithme propos\u00e9 est bas\u00e9 sur un cadre de r\u00e9gression. Le travail le plus connexe est la conception exp\u00e9rimentale optimale -LSB-1-RSB-, comprenant la conception A-Optimal, la conception D-Optimal et la conception EOptimal. Dans cette section, nous donnons une br\u00e8ve description de ces approches. 2.1 Le probl\u00e8me de l'apprentissage actif Le probl\u00e8me g\u00e9n\u00e9rique de l'apprentissage actif est le suivant. En d'autres termes, les points zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- peuvent am\u00e9liorer le plus le classificateur s'ils sont \u00e9tiquet\u00e9s et utilis\u00e9s comme points d'entra\u00eenement. 2.2 Plan exp\u00e9rimental optimal Nous consid\u00e9rons un mod\u00e8le de r\u00e9gression lin\u00e9aire. Diff\u00e9rentes observations comportent des erreurs ind\u00e9pendantes, mais avec des variances \u00e9gales \u03c32. Ainsi, l'estimation du maximum de vraisemblance pour le vecteur de poids, \u02c6w, est celle qui minimise l'erreur de somme quadratique. Les trois mesures scalaires les plus courantes de la taille de la matrice de covariance des param\u00e8tres dans le plan exp\u00e9rimental optimal sont : \u2022 Plan D-optimal : d\u00e9terminant de Hsse . \u2022 Conception A-optimale : trace de Hsse. \u2022 Conception E-optimale : valeur propre maximale de Hsse. Puisque le calcul du d\u00e9terminant et des valeurs propres d\u2019une matrice est beaucoup plus co\u00fbteux que le calcul de la trace matricielle, le plan A-optimal est plus efficace que les deux autres. Certains travaux r\u00e9cents sur la conception exp\u00e9rimentale peuvent \u00eatre trouv\u00e9s dans -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONS ET TRAVAUX FUTURS Cet article d\u00e9crit un nouvel algorithme d'apprentissage actif, appel\u00e9 conception optimale laplacienne, pour permettre une r\u00e9cup\u00e9ration plus efficace d'images de retour de pertinence. Notre algorithme est bas\u00e9 sur une fonction objectif qui minimise simultan\u00e9ment l'erreur empirique et pr\u00e9serve la structure g\u00e9om\u00e9trique locale de l'espace de donn\u00e9es. En utilisant des techniques de conception exp\u00e9rimentale, notre algorithme trouve les images les plus informatives \u00e0 \u00e9tiqueter. Ces images \u00e9tiquet\u00e9es et les images non \u00e9tiquet\u00e9es de la base de donn\u00e9es sont utilis\u00e9es pour apprendre un classificateur. Les r\u00e9sultats exp\u00e9rimentaux sur la base de donn\u00e9es Corel montrent que l'apprentissage actif et l'apprentissage semi-supervis\u00e9 peuvent am\u00e9liorer consid\u00e9rablement les performances de r\u00e9cup\u00e9ration. Dans cet article, nous consid\u00e9rons le probl\u00e8me de r\u00e9cup\u00e9ration d\u2019images sur des donn\u00e9es d\u2019image petites, statiques et de domaine ferm\u00e9. Pour la recherche d\u2019images Web, il est possible de collecter une grande quantit\u00e9 d\u2019informations sur les clics des utilisateurs. Ces informations peuvent naturellement \u00eatre utilis\u00e9es pour construire le graphe d\u2019affinit\u00e9 dans notre algorithme.les points zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- peuvent am\u00e9liorer le plus le classificateur s'ils sont \u00e9tiquet\u00e9s et utilis\u00e9s comme points d'entra\u00eenement. 2.2 Plan exp\u00e9rimental optimal Nous consid\u00e9rons un mod\u00e8le de r\u00e9gression lin\u00e9aire. Diff\u00e9rentes observations comportent des erreurs ind\u00e9pendantes, mais avec des variances \u00e9gales \u03c32. Ainsi, l'estimation du maximum de vraisemblance pour le vecteur de poids, \u02c6w, est celle qui minimise l'erreur de somme quadratique. Les trois mesures scalaires les plus courantes de la taille de la matrice de covariance des param\u00e8tres dans le plan exp\u00e9rimental optimal sont : \u2022 Plan D-optimal : d\u00e9terminant de Hsse . \u2022 Conception A-optimale : trace de Hsse. \u2022 Conception E-optimale : valeur propre maximale de Hsse. Puisque le calcul du d\u00e9terminant et des valeurs propres d\u2019une matrice est beaucoup plus co\u00fbteux que le calcul de la trace matricielle, le plan A-optimal est plus efficace que les deux autres. Certains travaux r\u00e9cents sur la conception exp\u00e9rimentale peuvent \u00eatre trouv\u00e9s dans -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONS ET TRAVAUX FUTURS Cet article d\u00e9crit un nouvel algorithme d'apprentissage actif, appel\u00e9 conception optimale laplacienne, pour permettre une r\u00e9cup\u00e9ration plus efficace d'images de retour de pertinence. Notre algorithme est bas\u00e9 sur une fonction objectif qui minimise simultan\u00e9ment l'erreur empirique et pr\u00e9serve la structure g\u00e9om\u00e9trique locale de l'espace de donn\u00e9es. En utilisant des techniques de conception exp\u00e9rimentale, notre algorithme trouve les images les plus informatives \u00e0 \u00e9tiqueter. Ces images \u00e9tiquet\u00e9es et les images non \u00e9tiquet\u00e9es de la base de donn\u00e9es sont utilis\u00e9es pour apprendre un classificateur. Les r\u00e9sultats exp\u00e9rimentaux sur la base de donn\u00e9es Corel montrent que l'apprentissage actif et l'apprentissage semi-supervis\u00e9 peuvent am\u00e9liorer consid\u00e9rablement les performances de r\u00e9cup\u00e9ration. Dans cet article, nous consid\u00e9rons le probl\u00e8me de r\u00e9cup\u00e9ration d\u2019images sur des donn\u00e9es d\u2019image petites, statiques et de domaine ferm\u00e9. Pour la recherche d\u2019images Web, il est possible de collecter une grande quantit\u00e9 d\u2019informations sur les clics des utilisateurs. Ces informations peuvent naturellement \u00eatre utilis\u00e9es pour construire le graphe d\u2019affinit\u00e9 dans notre algorithme.les points zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- peuvent am\u00e9liorer le plus le classificateur s'ils sont \u00e9tiquet\u00e9s et utilis\u00e9s comme points d'entra\u00eenement. 2.2 Plan exp\u00e9rimental optimal Nous consid\u00e9rons un mod\u00e8le de r\u00e9gression lin\u00e9aire. Diff\u00e9rentes observations comportent des erreurs ind\u00e9pendantes, mais avec des variances \u00e9gales \u03c32. Ainsi, l'estimation du maximum de vraisemblance pour le vecteur de poids, \u02c6w, est celle qui minimise l'erreur de somme quadratique. Les trois mesures scalaires les plus courantes de la taille de la matrice de covariance des param\u00e8tres dans le plan exp\u00e9rimental optimal sont : \u2022 Plan D-optimal : d\u00e9terminant de Hsse . \u2022 Conception A-optimale : trace de Hsse. \u2022 Conception E-optimale : valeur propre maximale de Hsse. Puisque le calcul du d\u00e9terminant et des valeurs propres d\u2019une matrice est beaucoup plus co\u00fbteux que le calcul de la trace matricielle, le plan A-optimal est plus efficace que les deux autres. Certains travaux r\u00e9cents sur la conception exp\u00e9rimentale peuvent \u00eatre trouv\u00e9s dans -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONS ET TRAVAUX FUTURS Cet article d\u00e9crit un nouvel algorithme d'apprentissage actif, appel\u00e9 conception optimale laplacienne, pour permettre une r\u00e9cup\u00e9ration plus efficace d'images de retour de pertinence. Notre algorithme est bas\u00e9 sur une fonction objectif qui minimise simultan\u00e9ment l'erreur empirique et pr\u00e9serve la structure g\u00e9om\u00e9trique locale de l'espace de donn\u00e9es. En utilisant des techniques de conception exp\u00e9rimentale, notre algorithme trouve les images les plus informatives \u00e0 \u00e9tiqueter. Ces images \u00e9tiquet\u00e9es et les images non \u00e9tiquet\u00e9es de la base de donn\u00e9es sont utilis\u00e9es pour apprendre un classificateur. Les r\u00e9sultats exp\u00e9rimentaux sur la base de donn\u00e9es Corel montrent que l'apprentissage actif et l'apprentissage semi-supervis\u00e9 peuvent am\u00e9liorer consid\u00e9rablement les performances de r\u00e9cup\u00e9ration. Dans cet article, nous consid\u00e9rons le probl\u00e8me de r\u00e9cup\u00e9ration d\u2019images sur des donn\u00e9es d\u2019image petites, statiques et de domaine ferm\u00e9. Pour la recherche d\u2019images Web, il est possible de collecter une grande quantit\u00e9 d\u2019informations sur les clics des utilisateurs. Ces informations peuvent naturellement \u00eatre utilis\u00e9es pour construire le graphe d\u2019affinit\u00e9 dans notre algorithme.Notre algorithme est bas\u00e9 sur une fonction objectif qui minimise simultan\u00e9ment l'erreur empirique et pr\u00e9serve la structure g\u00e9om\u00e9trique locale de l'espace de donn\u00e9es. En utilisant des techniques de conception exp\u00e9rimentale, notre algorithme trouve les images les plus informatives \u00e0 \u00e9tiqueter. Ces images \u00e9tiquet\u00e9es et les images non \u00e9tiquet\u00e9es de la base de donn\u00e9es sont utilis\u00e9es pour apprendre un classificateur. Les r\u00e9sultats exp\u00e9rimentaux sur la base de donn\u00e9es Corel montrent que l'apprentissage actif et l'apprentissage semi-supervis\u00e9 peuvent am\u00e9liorer consid\u00e9rablement les performances de r\u00e9cup\u00e9ration. Dans cet article, nous consid\u00e9rons le probl\u00e8me de r\u00e9cup\u00e9ration d\u2019images sur des donn\u00e9es d\u2019image petites, statiques et de domaine ferm\u00e9. Pour la recherche d\u2019images Web, il est possible de collecter une grande quantit\u00e9 d\u2019informations sur les clics des utilisateurs. Ces informations peuvent naturellement \u00eatre utilis\u00e9es pour construire le graphe d\u2019affinit\u00e9 dans notre algorithme.Notre algorithme est bas\u00e9 sur une fonction objectif qui minimise simultan\u00e9ment l'erreur empirique et pr\u00e9serve la structure g\u00e9om\u00e9trique locale de l'espace de donn\u00e9es. En utilisant des techniques de conception exp\u00e9rimentale, notre algorithme trouve les images les plus informatives \u00e0 \u00e9tiqueter. Ces images \u00e9tiquet\u00e9es et les images non \u00e9tiquet\u00e9es de la base de donn\u00e9es sont utilis\u00e9es pour apprendre un classificateur. Les r\u00e9sultats exp\u00e9rimentaux sur la base de donn\u00e9es Corel montrent que l'apprentissage actif et l'apprentissage semi-supervis\u00e9 peuvent am\u00e9liorer consid\u00e9rablement les performances de r\u00e9cup\u00e9ration. Dans cet article, nous consid\u00e9rons le probl\u00e8me de r\u00e9cup\u00e9ration d\u2019images sur des donn\u00e9es d\u2019image petites, statiques et de domaine ferm\u00e9. Pour la recherche d\u2019images Web, il est possible de collecter une grande quantit\u00e9 d\u2019informations sur les clics des utilisateurs. Ces informations peuvent naturellement \u00eatre utilis\u00e9es pour construire le graphe d\u2019affinit\u00e9 dans notre algorithme.", "keyphrases": ["commentaires pertinents", "l'image repr\u00e9sente", "r\u00e9cup\u00e9ration d'images contentbas", "apprentissage actif", "mod\u00e8le de r\u00e9gression des moindres carr\u00e9s", "conception d'exp\u00e9rience optimale", "image de retour en haut", "taux pr\u00e9cis", "structure g\u00e9om\u00e9trique intrins\u00e8que", "reconnaissance des motifs", "\u00e9tiquette"]}
{"file_name": "J-27", "text": "Apprendre de la pr\u00e9f\u00e9rence r\u00e9v\u00e9l\u00e9e R\u00c9SUM\u00c9 Une s\u00e9quence de prix et de demandes est rationalisable s'il existe une fonction d'utilit\u00e9 concave, continue et monotone telle que les demandes sont les maximiseurs de la fonction d'utilit\u00e9 sur l'ensemble budg\u00e9taire correspondant au prix. Afriat -LSB- 1 -RSB- pr\u00e9sentait des conditions n\u00e9cessaires et suffisantes pour qu'une s\u00e9quence finie soit rationalisable. Varian -LSB- 20 -RSB- et plus tard Blundell et al. -LSB- 3, 4 -RSB- a poursuivi cette ligne de travail en \u00e9tudiant des m\u00e9thodes non param\u00e9triques pour pr\u00e9voir la demande. Leurs r\u00e9sultats caract\u00e9risent essentiellement l\u2019aptitude \u00e0 l\u2019apprentissage de classes d\u00e9g\u00e9n\u00e9r\u00e9es de fonctions de demande et ne parviennent donc pas \u00e0 donner un degr\u00e9 g\u00e9n\u00e9ral de confiance dans les pr\u00e9visions. Le pr\u00e9sent article compl\u00e8te cette ligne de recherche en introduisant un mod\u00e8le statistique et une mesure de complexit\u00e9 gr\u00e2ce auxquels nous sommes en mesure d'\u00e9tudier la capacit\u00e9 d'apprentissage de classes de fonctions de demande et d'en tirer un degr\u00e9 de confiance dans les pr\u00e9visions. Nos r\u00e9sultats montrent que la classe de toutes les fonctions de demande a une complexit\u00e9 illimit\u00e9e et n'est donc pas apprenable, mais qu'il existe des classes int\u00e9ressantes et potentiellement utiles qui peuvent \u00eatre apprises \u00e0 partir d'\u00e9chantillons finis. Nous pr\u00e9sentons \u00e9galement un algorithme d'apprentissage qui est une adaptation d'une nouvelle preuve du th\u00e9or\u00e8me d'Afriat due \u00e0 Teo et Vohra -LSB- 17 -RSB-. 1. INTRODUCTION La relation de pr\u00e9f\u00e9rence est donc le facteur cl\u00e9 pour comprendre le comportement du consommateur. L\u2019une des hypoth\u00e8ses courantes de cette th\u00e9orie est que la relation de pr\u00e9f\u00e9rence est repr\u00e9sent\u00e9e par une fonction d\u2019utilit\u00e9 et que les agents s\u2019efforcent de maximiser leur utilit\u00e9 compte tenu d\u2019une contrainte budg\u00e9taire. Ce mod\u00e8le de comportement est l\u2019essence m\u00eame de l\u2019offre et de la demande, des \u00e9quilibres g\u00e9n\u00e9raux et d\u2019autres aspects de la th\u00e9orie de la consommation. En outre, comme nous l\u2019expliquons dans la section 2, les observations de base sur le comportement de la demande du march\u00e9 sugg\u00e8rent que les fonctions d\u2019utilit\u00e9 sont monotones et concaves. Cela nous am\u00e8ne \u00e0 la question, soulev\u00e9e pour la premi\u00e8re fois par Samuelson -LSB- 18 -RSB-, dans quelle mesure cette th\u00e9orie est-elle r\u00e9futable ? Compte tenu des observations de prix et de demande, dans quelles circonstances peut-on conclure que les donn\u00e9es sont coh\u00e9rentes avec le comportement d\u2019un agent maximisant l\u2019utilit\u00e9 \u00e9quip\u00e9 d\u2019une fonction d\u2019utilit\u00e9 concave monotone et soumis \u00e0 une contrainte budg\u00e9taire ? Samuelson a pos\u00e9 une condition n\u00e9cessaire mais insuffisante \u00e0 la pr\u00e9f\u00e9rence sous-jacente, connue sous le nom d\u2019axiome faible de la pr\u00e9f\u00e9rence r\u00e9v\u00e9l\u00e9e. Uzawa -LSB- 16 -RSB- et Mas-Colell -LSB- 10, 11 -RSB- ont introduit une notion de revenu-Lipschitz et ont montr\u00e9 que les fonctions de demande avec cette propri\u00e9t\u00e9 sont rationalisables. Ces propri\u00e9t\u00e9s ne n\u00e9cessitent aucune hypoth\u00e8se param\u00e9trique et sont techniquement r\u00e9futables, mais elles supposent une connaissance de l'ensemble de la fonction de demande et s'appuient fortement sur les propri\u00e9t\u00e9s diff\u00e9rentielles des fonctions de demande. Une quantit\u00e9 infinie d\u2019informations est donc n\u00e9cessaire pour r\u00e9futer la th\u00e9orie. Il arrive souvent qu'en dehors des observations de la demande, il existe des informations suppl\u00e9mentaires sur le syst\u00e8me et il est judicieux de formuler des hypoth\u00e8ses param\u00e9triques, \u00e0 savoir\u00a0:stipuler une forme fonctionnelle d\u2019utilit\u00e9. La coh\u00e9rence avec la maximisation de l'utilit\u00e9 d\u00e9pendrait alors de la fixation des param\u00e8tres de la fonction d'utilit\u00e9 pour qu'ils soient coh\u00e9rents avec les observations et avec un ensemble d'\u00e9quations appel\u00e9es \u00e9quations de Slutski. Si de tels param\u00e8tres existent, nous concluons que la forme d'utilit\u00e9 stipul\u00e9e est coh\u00e9rente avec les observations. Cette approche est utile lorsqu'il y a des raisons de faire ces stipulations, elle donne une fonction d'utilit\u00e9 explicite qui peut \u00eatre utilis\u00e9e pour faire des pr\u00e9visions pr\u00e9cises sur la demande pour des prix non observ\u00e9s. L\u2019inconv\u00e9nient de cette approche est que les donn\u00e9es r\u00e9elles sont souvent incompatibles avec les formes fonctionnelles pratiques. De plus, si les observations sont incoh\u00e9rentes, il n\u2019est pas clair s\u2019il s\u2019agit d\u2019une r\u00e9futation de la forme fonctionnelle stipul\u00e9e ou d\u2019une maximisation de l\u2019utilit\u00e9. Il se demande quand peut-on d\u00e9terminer qu\u2019un ensemble fini d\u2019observations est coh\u00e9rent avec la maximisation de l\u2019utilit\u00e9 sans faire d\u2019hypoth\u00e8ses param\u00e9triques ? Il montre que la rationalisabilit\u00e9 d\u2019un ensemble fini d\u2019observations \u00e9quivaut \u00e0 l\u2019axiome fort de la pr\u00e9f\u00e9rence r\u00e9v\u00e9l\u00e9e. Richter -LSB- 15 -RSB- montre qu'un axiome fort de pr\u00e9f\u00e9rence r\u00e9v\u00e9l\u00e9e \u00e9quivaut \u00e0 une rationalisabilit\u00e9 par une fonction d'utilit\u00e9 monotone strictement concave. Afriat -LSB- 1 -RSB- donne un autre ensemble de conditions de rationalisabilit\u00e9 que les observations doivent satisfaire. Varian -LSB- 20 -RSB- introduit l'axiome g\u00e9n\u00e9ralis\u00e9 de pr\u00e9f\u00e9rence r\u00e9v\u00e9l\u00e9e -LRB-GARP -RRB-, une forme \u00e9quivalente de la condition de coh\u00e9rence d'Afriat qui est plus facile \u00e0 v\u00e9rifier informatiquement. Afriat -LSB- 1 -RSB- a prouv\u00e9 son th\u00e9or\u00e8me par une construction explicite d'une fonction d'utilit\u00e9 t\u00e9moin de coh\u00e9rence. Varian -LSB- 20 -RSB- a franchi une \u00e9tape suppl\u00e9mentaire, passant de la coh\u00e9rence \u00e0 la pr\u00e9vision. L'algorithme de pr\u00e9vision de Varian exclut essentiellement les faisceaux qui se r\u00e9v\u00e8lent inf\u00e9rieurs aux faisceaux observ\u00e9s et trouve un faisceau de l'ensemble restant qui, avec les observations, est coh\u00e9rent avec GARP. De plus, il pr\u00e9sente la \u00ab m\u00e9trique mon\u00e9taire \u00bb de Samuelson comme fonction d'utilit\u00e9 canonique et donne des fonctions d'utilit\u00e9 d'enveloppe sup\u00e9rieure et inf\u00e9rieure pour la m\u00e9trique mon\u00e9taire. Knoblauch -LSB- 9 -RSB- montre que ces enveloppes peuvent \u00eatre calcul\u00e9es efficacement. Une approche diff\u00e9rente est pr\u00e9sent\u00e9e par Blundell et al. -LSB-3, 4 -RSB-. Ces articles introduisent un mod\u00e8le dans lequel un agent observe les prix et les courbes d'Engel pour ces prix. Cela donne une am\u00e9lioration par rapport aux limites initiales de Varian, m\u00eame si l'id\u00e9e de base reste d'exclure les demandes qui se r\u00e9v\u00e8lent inf\u00e9rieures. Ce mod\u00e8le est en un sens un hybride entre les approches de Mas-Colell et d'Afriat. Le premier n\u00e9cessite des informations compl\u00e8tes pour tous les prix, le second pour un nombre fini de prix. En revanche, l'approche adopt\u00e9e par Blundell et al. ne n\u00e9cessite des informations compl\u00e8tes que sur un nombre fini de trajectoires de prix. Diff\u00e9rents segments de la population sont confront\u00e9s aux m\u00eames prix avec des budgets diff\u00e9rents et, autant que les donn\u00e9es globales peuvent t\u00e9moigner des pr\u00e9f\u00e9rences individuelles,montrez comment la demande varie en fonction du budget. En appliquant des m\u00e9thodes statistiques non param\u00e9triques, ils reconstruisent une trajectoire \u00e0 partir des demandes observ\u00e9es de diff\u00e9rents segments et l'utilisent pour obtenir des limites plus strictes. Ces deux m\u00e9thodes donneraient tr\u00e8s probablement une bonne pr\u00e9vision pour une fonction de demande fixe apr\u00e8s suffisamment d\u2019observations, en supposant qu\u2019elles soient \u00e9tal\u00e9es de mani\u00e8re raisonnable. Cependant, ces m\u00e9thodes ne prennent pas en compte la complexit\u00e9 des fonctions de demande et n'utilisent aucun mod\u00e8le probabiliste des observations. Par cons\u00e9quent, ils ne sont pas en mesure de fournir une estimation du nombre d\u2019observations qui serait suffisant pour une bonne pr\u00e9vision ni du degr\u00e9 de confiance dans une telle pr\u00e9vision. Dans cet article, nous examinons la faisabilit\u00e9 de la pr\u00e9vision de la demande avec un degr\u00e9 \u00e9lev\u00e9 de confiance en utilisant les conditions d'Afriat. Nous formulons la question en termes de savoir si la classe de fonctions de demande d\u00e9riv\u00e9es d'utilitaires concaves monotones peut \u00eatre efficacement apprise par PAC. Notre premier r\u00e9sultat est n\u00e9gatif. Nous montrons, en calculant la dimension de rupture de graisse, que sans aucune hypoth\u00e8se pr\u00e9alable, l'ensemble de toutes les fonctions de demande induites par des fonctions d'utilit\u00e9 concaves monotones est trop riche pour \u00eatre efficacement apprenable par PAC. Cependant, sous certaines hypoth\u00e8ses pr\u00e9alables sur l'ensemble des fonctions de demande, nous montrons que la dimension de destruction de graisse est finie et que par cons\u00e9quent les ensembles correspondants peuvent \u00eatre appris par PAC. Dans la section 2, nous discutons bri\u00e8vement des hypoth\u00e8ses de base de la th\u00e9orie de la demande et de leurs implications. Dans la section 3, nous pr\u00e9sentons une nouvelle preuve du th\u00e9or\u00e8me d'Afriat incorporant un algorithme pour g\u00e9n\u00e9rer efficacement une fonction de pr\u00e9vision gr\u00e2ce \u00e0 Teo et Vohra -LSB- 17 -RSB-. Nous montrons que cet algorithme est efficace sur le plan informatique et peut \u00eatre utilis\u00e9 comme algorithme d\u2019apprentissage. Dans la section 4, nous donnons une br\u00e8ve introduction \u00e0 l'apprentissage PAC, y compris plusieurs modifications \u00e0 l'apprentissage de fonctions \u00e0 valeurs vectorielles r\u00e9elles. Nous esquissons \u00e9galement les r\u00e9sultats sur les limites sup\u00e9rieures. Dans la section 5, nous \u00e9tudions la capacit\u00e9 d\u2019apprentissage des fonctions de demande et calculons directement la dimension bouleversante de la classe de toutes les fonctions de demande et d\u2019une classe de fonctions de demande Lipschitziennes de revenu avec une constante Lipschitzienne de revenu globale limit\u00e9e.Nous formulons la question en termes de savoir si la classe de fonctions de demande d\u00e9riv\u00e9es d'utilitaires concaves monotones peut \u00eatre efficacement apprise par PAC. Notre premier r\u00e9sultat est n\u00e9gatif. Nous montrons, en calculant la dimension de rupture de graisse, que sans aucune hypoth\u00e8se pr\u00e9alable, l'ensemble de toutes les fonctions de demande induites par des fonctions d'utilit\u00e9 concaves monotones est trop riche pour \u00eatre efficacement apprenable par PAC. Cependant, sous certaines hypoth\u00e8ses pr\u00e9alables sur l'ensemble des fonctions de demande, nous montrons que la dimension de destruction de graisse est finie et que par cons\u00e9quent les ensembles correspondants peuvent \u00eatre appris par PAC. Dans la section 2, nous discutons bri\u00e8vement des hypoth\u00e8ses de base de la th\u00e9orie de la demande et de leurs implications. Dans la section 3, nous pr\u00e9sentons une nouvelle preuve du th\u00e9or\u00e8me d'Afriat incorporant un algorithme pour g\u00e9n\u00e9rer efficacement une fonction de pr\u00e9vision gr\u00e2ce \u00e0 Teo et Vohra -LSB- 17 -RSB-. Nous montrons que cet algorithme est efficace sur le plan informatique et peut \u00eatre utilis\u00e9 comme algorithme d\u2019apprentissage. Dans la section 4, nous donnons une br\u00e8ve introduction \u00e0 l'apprentissage PAC, y compris plusieurs modifications \u00e0 l'apprentissage de fonctions \u00e0 valeurs vectorielles r\u00e9elles. Nous esquissons \u00e9galement les r\u00e9sultats sur les limites sup\u00e9rieures. Dans la section 5, nous \u00e9tudions la capacit\u00e9 d\u2019apprentissage des fonctions de demande et calculons directement la dimension bouleversante de la classe de toutes les fonctions de demande et d\u2019une classe de fonctions de demande Lipschitziennes de revenu avec une constante Lipschitzienne de revenu globale limit\u00e9e.Nous formulons la question en termes de savoir si la classe de fonctions de demande d\u00e9riv\u00e9es d'utilitaires concaves monotones peut \u00eatre efficacement apprise par PAC. Notre premier r\u00e9sultat est n\u00e9gatif. Nous montrons, en calculant la dimension de rupture de graisse, que sans aucune hypoth\u00e8se pr\u00e9alable, l'ensemble de toutes les fonctions de demande induites par des fonctions d'utilit\u00e9 concaves monotones est trop riche pour \u00eatre efficacement apprenable par PAC. Cependant, sous certaines hypoth\u00e8ses pr\u00e9alables sur l'ensemble des fonctions de demande, nous montrons que la dimension de destruction de graisse est finie et que par cons\u00e9quent les ensembles correspondants peuvent \u00eatre appris par PAC. Dans la section 2, nous discutons bri\u00e8vement des hypoth\u00e8ses de base de la th\u00e9orie de la demande et de leurs implications. Dans la section 3, nous pr\u00e9sentons une nouvelle preuve du th\u00e9or\u00e8me d'Afriat incorporant un algorithme pour g\u00e9n\u00e9rer efficacement une fonction de pr\u00e9vision gr\u00e2ce \u00e0 Teo et Vohra -LSB- 17 -RSB-. Nous montrons que cet algorithme est efficace sur le plan informatique et peut \u00eatre utilis\u00e9 comme algorithme d\u2019apprentissage. Dans la section 4, nous donnons une br\u00e8ve introduction \u00e0 l'apprentissage PAC, y compris plusieurs modifications \u00e0 l'apprentissage de fonctions \u00e0 valeurs vectorielles r\u00e9elles. Nous esquissons \u00e9galement les r\u00e9sultats sur les limites sup\u00e9rieures. Dans la section 5, nous \u00e9tudions la capacit\u00e9 d\u2019apprentissage des fonctions de demande et calculons directement la dimension bouleversante de la classe de toutes les fonctions de demande et d\u2019une classe de fonctions de demande Lipschitziennes de revenu avec une constante Lipschitzienne de revenu globale limit\u00e9e.", "keyphrases": ["apprendre de r\u00e9v\u00e9ler pr\u00e9f\u00e9rer", "probl\u00e8me complexe", "pr\u00e9vision", "probablement \u00e0 peu pr\u00e8s correct", "fonction utilitaire concave monotone", "fonction de demande", "rationaliser", "ensemble fini d'observation", "incom-lipschitz", "dimensions de rupture de graisse"]}
{"file_name": "C-18", "text": "Analyse initiale et pr\u00e9sentation de logiciels malveillants pr\u00e9sentant un comportement semblable \u00e0 celui d'un essaim R\u00c9SUM\u00c9 Le Slammer, qui est actuellement le ver informatique le plus rapide de l'histoire enregistr\u00e9e, a \u00e9t\u00e9 observ\u00e9 comme infectant 90 % de tous les h\u00f4tes Internet vuln\u00e9rables en 10 minutes. Bien que l\u2019action principale du ver Slammer soit une r\u00e9plication relativement simple de lui-m\u00eame, elle se propage si rapidement que la r\u00e9ponse humaine s\u2019av\u00e8re inefficace. La plupart des strat\u00e9gies de contre-mesures propos\u00e9es reposent principalement sur des algorithmes de d\u00e9tection et de limitation du d\u00e9bit. Cependant, de telles strat\u00e9gies sont con\u00e7ues et d\u00e9velopp\u00e9es pour contenir efficacement les vers dont les comportements sont similaires \u00e0 ceux de Slammer. Dans notre travail, nous \u00e9mettons l\u2019hypoth\u00e8se que les vers de la prochaine g\u00e9n\u00e9ration seront radicalement diff\u00e9rents et que de telles techniques pourraient s\u2019av\u00e9rer inefficaces. Plus pr\u00e9cis\u00e9ment, nous proposons d'\u00e9tudier une nouvelle g\u00e9n\u00e9ration de vers appel\u00e9s \u00ab Swarm Worms \u00bb, dont le comportement repose sur le concept d'\u00ab intelligence \u00e9mergente \u00bb. L'intelligence \u00e9mergente est le comportement de syst\u00e8mes, tout comme les syst\u00e8mes biologiques tels que les fourmis ou les abeilles, o\u00f9 de simples interactions locales de membres autonomes, avec de simples actions primitives, donnent naissance \u00e0 un comportement global complexe et intelligent. Dans ce manuscrit, nous pr\u00e9senterons les principes de base derri\u00e8re l'id\u00e9e de \u00ab\u00a0Swarm Worms\u00a0\u00bb, ainsi que la structure de base requise pour \u00eatre consid\u00e9r\u00e9 comme un \u00ab\u00a0Swarm Worms\u00a0\u00bb. De plus, nous pr\u00e9senterons des r\u00e9sultats pr\u00e9liminaires sur les vitesses de propagation d\u2019un de ces vers en essaim, appel\u00e9 ver ZachiK. Nous montrerons que ZachiK est capable de se propager \u00e0 une vitesse 2 ordres de grandeur plus rapide que des vers similaires sans capacit\u00e9s d'essaim. 1. INTRODUCTION ET TRAVAUX ANT\u00c9RIEURS Aux petites heures du matin -LRB- 05h30 GMT -RRB- du 25 janvier 2003, le ver informatique le plus rapide de l'histoire a commenc\u00e9 \u00e0 se propager sur Internet. Depuis Slammer, les chercheurs ont explor\u00e9 les comportements des vers \u00e0 propagation rapide et ont con\u00e7u des strat\u00e9gies de contre-mesures bas\u00e9es principalement sur des algorithmes de d\u00e9tection et de limitation du taux. Par exemple, Zou et al., -LSB- 2 -RSB-, ont propos\u00e9 un sch\u00e9ma dans lequel un filtre de Kalman est utilis\u00e9 pour d\u00e9tecter la propagation pr\u00e9coce d'un ver. Autrement dit, des syst\u00e8mes sont con\u00e7us et d\u00e9velopp\u00e9s pour contenir efficacement les vers dont les comportements sont similaires \u00e0 ceux de Slammer. Dans les travaux d\u00e9crits ici, nous \u00e9mettons l\u2019hypoth\u00e8se que les vers de la prochaine g\u00e9n\u00e9ration seront diff\u00e9rents et que de telles techniques pourraient donc pr\u00e9senter des limites importantes. Plus pr\u00e9cis\u00e9ment, nous proposons d'\u00e9tudier une nouvelle g\u00e9n\u00e9ration de vers appel\u00e9s \u00ab Swarm Worms \u00bb, dont le comportement repose sur le concept d'\u00ab intelligence \u00e9mergente \u00bb. Le concept d\u2019intelligence \u00e9mergente a d\u2019abord \u00e9t\u00e9 \u00e9tudi\u00e9 en association avec les syst\u00e8mes biologiques. Dans de telles \u00e9tudes, les premiers chercheurs ont d\u00e9couvert une vari\u00e9t\u00e9 de comportements int\u00e9ressants d\u2019insectes ou d\u2019animaux dans la nature. Une vol\u00e9e d'oiseaux balaie le ciel. En g\u00e9n\u00e9ral,ce type de mouvement global a \u00e9t\u00e9 appel\u00e9 \u00ab\u00a0comportement en essaim\u00a0\u00bb. \" Des biologistes et des informaticiens dans le domaine de l'intelligence artificielle ont \u00e9tudi\u00e9 de tels essaims biologiques et ont tent\u00e9 de cr\u00e9er des mod\u00e8les expliquant comment les \u00e9l\u00e9ments d'un essaim interagissent, atteignent leurs objectifs et \u00e9voluent. Les concepts de base qui ont \u00e9t\u00e9 d\u00e9velopp\u00e9s au cours de la derni\u00e8re d\u00e9cennie pour expliquer les \u00ab essaims \u00bb et le \u00ab comportement des essaims \u00bb comprennent quatre \u00e9l\u00e9ments de base. Ce sont : 1. Simplicit\u00e9 de la logique et des actions : Un essaim est compos\u00e9 de N agents dont l'intelligence est limit\u00e9e. Les agents de l'essaim utilisent des r\u00e8gles locales simples pour r\u00e9gir leurs actions. Certains mod\u00e8les appellent cela des actions ou comportements primitifs ; 2. M\u00e9canismes de communication locaux : Les agents interagissent avec les autres membres de l'essaim via de simples m\u00e9canismes de communication \u00ab locaux \u00bb. Par exemple, un oiseau dans un troupeau d\u00e9tecte la position d\u2019un oiseau adjacent et applique une r\u00e8gle simple d\u2019\u00e9vitement et de suivi. 3. 4. ''Intelligence \u00e9mergente'' : Le comportement agr\u00e9g\u00e9 d'agents autonomes se traduit par des comportements ''intelligents'' complexes ; y compris l'auto-organisation ''. Afin de comprendre pleinement le comportement de tels essaims, il est n\u00e9cessaire de construire un mod\u00e8le expliquant le comportement de ce que nous appellerons des vers g\u00e9n\u00e9riques. Ce mod\u00e8le, qui \u00e9tend les travaux de Weaver -LSB- 5 -RSB-, est pr\u00e9sent\u00e9 ici dans la section 2. De plus, nous avons l'intention d'\u00e9tendre ledit mod\u00e8le de mani\u00e8re \u00e0 ce qu'il explique clairement les comportements de cette nouvelle classe de vers potentiellement dangereux. appel\u00e9 Swarm Worms. Les vers en essaim se comportent beaucoup comme des essaims biologiques et pr\u00e9sentent un degr\u00e9 \u00e9lev\u00e9 d\u2019apprentissage, de communication et d\u2019intelligence distribu\u00e9e. Ces vers essaims sont potentiellement plus nocifs que leurs homologues g\u00e9n\u00e9riques similaires. Plus pr\u00e9cis\u00e9ment, le premier exemple, \u00e0 notre connaissance, d'un tel ver d'apprentissage a \u00e9t\u00e9 cr\u00e9\u00e9, appel\u00e9 ZachiK. ZachiK est un simple ver essaim de piratage de mots de passe qui int\u00e8gre diff\u00e9rentes strat\u00e9gies d'apprentissage et de partage d'informations. Un tel ver en essaim a \u00e9t\u00e9 d\u00e9ploy\u00e9 \u00e0 la fois dans un r\u00e9seau local de trente h\u00f4tes - -LRB- 30 -RRB-, ainsi que simul\u00e9 dans une topologie de 10 000 n\u0153uds. Les r\u00e9sultats pr\u00e9liminaires ont montr\u00e9 que ces vers sont capables de compromettre les h\u00f4tes \u00e0 des taux jusqu'\u00e0 deux ordres de grandeur plus rapides que leur homologue g\u00e9n\u00e9rique. Le reste de ce manuscrit est structur\u00e9 comme suit. Dans la section 2, un mod\u00e8le abstrait de vers g\u00e9n\u00e9riques et de vers en essaim est pr\u00e9sent\u00e9. Ce mod\u00e8le est utilis\u00e9 dans la section 2.6 pour d\u00e9crire la premi\u00e8re instance d'un ver en essaim, ZachiK. Dans la section 4, des r\u00e9sultats pr\u00e9liminaires via des mesures empiriques et des simulations sont pr\u00e9sent\u00e9s. Enfin, dans la section 5, nos conclusions et nos id\u00e9es sur les travaux futurs sont pr\u00e9sent\u00e9es. 5. R\u00c9SUM\u00c9 ET TRAVAUX FUTURS Dans ce manuscrit, nous avons pr\u00e9sent\u00e9 un mod\u00e8le abstrait, similaire \u00e0 certains \u00e9gards \u00e0 celui de Weaver -LSB- 5 -RSB-, qui aide \u00e0 expliquer la nature g\u00e9n\u00e9rique des vers.Le mod\u00e8le pr\u00e9sent\u00e9 dans la section 2 a \u00e9t\u00e9 \u00e9tendu pour incorporer une nouvelle classe de vers potentiellement dangereux appel\u00e9s Swarm Worms. Les vers en essaim se comportent beaucoup comme des essaims biologiques et pr\u00e9sentent un degr\u00e9 \u00e9lev\u00e9 d\u2019apprentissage, de communication et d\u2019intelligence distribu\u00e9e. Ces vers essaims sont potentiellement plus nocifs que leurs homologues g\u00e9n\u00e9riques. De plus, le premier exemplaire, \u00e0 notre connaissance, d\u2019un tel ver d\u2019apprentissage a \u00e9t\u00e9 cr\u00e9\u00e9, appel\u00e9 ZachiK. ZachiK est un simple ver essaim de piratage de mots de passe qui int\u00e8gre diff\u00e9rentes strat\u00e9gies d'apprentissage et de partage d'informations. Un tel ver en essaim a \u00e9t\u00e9 d\u00e9ploy\u00e9 \u00e0 la fois dans un r\u00e9seau local de trente h\u00f4tes - -LRB- 30 -RRB-, ainsi que simul\u00e9 dans une topologie de 10 000 n\u0153uds. Les r\u00e9sultats pr\u00e9liminaires ont montr\u00e9 que ces vers sont capables de compromettre les h\u00f4tes \u00e0 des taux jusqu'\u00e0 2 ordres de grandeur plus rapides que leur homologue g\u00e9n\u00e9rique tout en conservant des capacit\u00e9s furtives. Ce travail ouvre un nouveau domaine de probl\u00e8mes int\u00e9ressants. Certains des probl\u00e8mes les plus int\u00e9ressants et les plus urgents \u00e0 consid\u00e9rer sont les suivants : \u2022 Est-il possible d'appliquer certains concepts d'apprentissage d\u00e9velopp\u00e9s au cours des dix derni\u00e8res ann\u00e9es dans les domaines de l'intelligence en essaim, des syst\u00e8mes d'agents et du contr\u00f4le distribu\u00e9 \u00e0 la conception d'essaims sophistiqu\u00e9s ? vers de telle mani\u00e8re qu'un v\u00e9ritable comportement \u00e9mergent ait lieu\u00a0? \u2022 Les techniques actuellement d\u00e9velopp\u00e9es dans la conception des syst\u00e8mes de d\u00e9tection et de contre-mesure des intrusions et des syst\u00e8mes de survie sont-elles efficaces contre cette nouvelle classe de vers ? ; et \u2022 Quelles techniques, le cas \u00e9ch\u00e9ant, peuvent \u00eatre d\u00e9velopp\u00e9es pour cr\u00e9er des d\u00e9fenses contre les vers essaims ?peut-on d\u00e9velopper pour cr\u00e9er des d\u00e9fenses contre les vers essaims ?peut-on d\u00e9velopper pour cr\u00e9er des d\u00e9fenses contre les vers essaims ?", "keyphrases": ["guerre malveillante", "ver d'essaim", "intelligence \u00e9mergente", "ver claquant", "m\u00e9canisme commun local", "zachik", "m\u00e9thode prng", "liste de cibles de pr\u00e9-g\u00e9n\u00e9ration", "distribuer l'intelligence", "d\u00e9tection d'intrusion", "syst\u00e8me de contre-mesure"]}
{"file_name": "J-26", "text": "Agence combinatoire R\u00c9SUM\u00c9 De nombreuses recherches r\u00e9centes portent sur les syst\u00e8mes, tels qu'Internet, dont les composants sont d\u00e9tenus et exploit\u00e9s par diff\u00e9rentes parties, chacune avec son propre objectif \u00ab \u00e9go\u00efste \u00bb. Le domaine de la conception de m\u00e9canismes algorithmiques traite la question des informations priv\u00e9es d\u00e9tenues par les diff\u00e9rentes parties dans de tels contexts informatiques. Cet article traite d'un probl\u00e8me compl\u00e9mentaire dans de tels contexts : la gestion des \u00ab actions cach\u00e9es \u00bb effectu\u00e9es par les diff\u00e9rentes parties. Notre mod\u00e8le est une variante combinatoire du probl\u00e8me classique agent principal issu de la th\u00e9orie \u00e9conomique. Dans notre context, un directeur doit motiver une \u00e9quipe d\u2019agents strat\u00e9giques \u00e0 d\u00e9ployer des efforts co\u00fbteux en son nom, mais leurs actions lui sont cach\u00e9es. Nous nous concentrons sur les cas o\u00f9 des combinaisons complexes d\u2019efforts des agents influencent le r\u00e9sultat. Le principal motive les agents en leur proposant un ensemble de contrats, qui placent ensemble les agents dans un point d'\u00e9quilibre du jeu induit. Nous pr\u00e9sentons des mod\u00e8les formels pour ce context, sugg\u00e9rons et entreprenons une analyse de certaines questions fondamentales, mais laissons de nombreuses questions ouvertes. 1. INTRODUCTION 1.1 Context L'une des caract\u00e9ristiques les plus frappantes des r\u00e9seaux informatiques modernes -- en particulier Internet -- est que diff\u00e9rentes parties de ceux-ci sont d\u00e9tenues et exploit\u00e9es par diff\u00e9rents individus, entreprises et organisations. L'analyse et la conception de protocoles pour cet environnement doivent donc naturellement prendre en compte les diff\u00e9rents int\u00e9r\u00eats \u00e9conomiques \u00ab \u00e9go\u00efstes \u00bb des diff\u00e9rents participants. En particulier, le domaine de la conception de m\u00e9canismes algorithmiques -LSB-6-RSB- utilise des incitations appropri\u00e9es pour \u00ab\u00a0extraire\u00a0\u00bb les informations priv\u00e9es des participants. Cet article traite du manque de connaissance compl\u00e9mentaire, celui des actions cach\u00e9es. Dans de nombreux cas, les comportements r\u00e9els \u2013 les actions \u2013 des diff\u00e9rents participants sont \u00ab cach\u00e9s \u00bb aux autres et n\u2019influencent le r\u00e9sultat final qu\u2019indirectement. Comment s\u2019assurer que la bonne combinaison d\u2019allocations est effectivement r\u00e9alis\u00e9e par les diff\u00e9rents serveurs ? Une classe connexe d'exemples concerne les probl\u00e8mes de s\u00e9curit\u00e9 : chaque \u00ab\u00a0lien\u00a0\u00bb dans un syst\u00e8me complexe peut exercer diff\u00e9rents niveaux d'effort pour prot\u00e9ger certaines propri\u00e9t\u00e9s de s\u00e9curit\u00e9 souhait\u00e9es du syst\u00e8me. Comment pouvons-nous garantir que le niveau souhait\u00e9 de 5. ASPECTS ALGORITHMIQUES Notre analyse tout au long de cet article met en lumi\u00e8re les aspects algorithmiques du calcul du meilleur contrat. Dans cette section nous \u00e9non\u00e7ons ces implications -LRB- pour les preuves voir -LSB- 2 -RSB- -RRB-. Nous consid\u00e9rons d'abord le mod\u00e8le g\u00e9n\u00e9ral o\u00f9 la fonction technologique est donn\u00e9e par une fonction monotone arbitraire t -LRB- avec des valeurs rationnelles -RRB-, puis nous consid\u00e9rons le cas de technologies structur\u00e9es donn\u00e9es par une repr\u00e9sentation en r\u00e9seau de la fonction bool\u00e9enne sous-jacente. 5.1 Technologies \u00e0 action binaire \u00e0 r\u00e9sultat binaire Nous supposons ici que l'on nous donne une technologie et une valeur v comme entr\u00e9e, et que notre sortie devrait \u00eatre le contrat optimal, c'est-\u00e0-direl'ensemble S* d'agents \u00e0 contracter et le contrat pi pour chaque i ES*. Dans le cas g\u00e9n\u00e9ral, la fonction de succ\u00e8s t est de taille exponentielle en n, le nombre d'agents, et nous devrons nous en occuper. Dans le cas particulier des technologies anonymes, la description de t porte uniquement sur les n +1 nombres t0,..., tn, et dans ce cas notre analyse de la section 3 suffit tout \u00e0 fait au calcul du contrat optimal. \u2022 L'orbite de la technologie dans les cas d'agence et non strat\u00e9giques. \u2022 Un contrat optimal pour toute valeur v donn\u00e9e, tant pour le cas d'agence que pour les cas non strat\u00e9giques. \u2022 Le prix de l'irresponsabilit\u00e9 POU -LRB- t, ~c -RRB-. PREUVE. Nous prouvons les affirmations pour le cas non anonyme, la preuve pour le cas anonyme est similaire. Nous montrons d'abord comment construire l'orbite de la technologie -LRB- la m\u00eame proc\u00e9dure s'applique dans les deux cas -RRB-. Pour construire l'orbite, nous trouvons tous les points de transition et les ensembles qui se trouvent sur l'orbite. Le contrat vide est toujours optimal pour v = 0. Supposons que nous ayons calcul\u00e9 les contrats optimaux et les points de transition jusqu'\u00e0 un point de transition v pour lequel S est un contrat optimal avec la probabilit\u00e9 de succ\u00e8s la plus \u00e9lev\u00e9e. Nous montrons comment calculer le prochain point de transition et le prochain contrat optimal. D'apr\u00e8s le lemme 3, le prochain contrat sur l'orbite -LRB- pour des valeurs plus \u00e9lev\u00e9es -RRB- a une probabilit\u00e9 de succ\u00e8s -LRB- plus \u00e9lev\u00e9e, il n'y a pas deux ensembles avec la m\u00eame probabilit\u00e9 de succ\u00e8s sur l'orbite -RRB-. Nous calculons le prochain contrat optimal par la proc\u00e9dure suivante. Nous passons en revue tous les ensembles T tels que t -LRB- T -RRB- > t -LRB- S -RRB-, et calculons la valeur pour laquelle le principal est indiff\u00e9rent entre contracter avec T et contracter avec S. La valeur minimale d'indiff\u00e9rence est le prochain point de transition et le contrat qui a la valeur d'indiff\u00e9rence minimale est le prochain contrat optimal. La lin\u00e9arit\u00e9 de l\u2019utilit\u00e9 dans la valeur et la monotonie de la probabilit\u00e9 de succ\u00e8s des contrats optimaux garantissent le bon fonctionnement de ce qui pr\u00e9c\u00e8de. Il est clair que le calcul ci-dessus est polynomial dans la taille d'entr\u00e9e. Une fois que nous avons l\u2019orbite, il est clair qu\u2019un contrat optimal pour toute valeur v donn\u00e9e peut \u00eatre calcul\u00e9. Nous trouvons le plus grand point de transition qui n\u2019est pas sup\u00e9rieur \u00e0 la valeur v, et le contrat optimal en v est l\u2019ensemble ayant la probabilit\u00e9 de succ\u00e8s la plus \u00e9lev\u00e9e \u00e0 ce point de transition. Enfin, comme nous pouvons calculer l\u2019orbite de la technologie dans les cas d\u2019agence et dans les cas non strat\u00e9giques en temps polynomial, nous pouvons trouver le prix de l\u2019irresponsabilit\u00e9 en temps polynomial. D'apr\u00e8s le lemme 1, le prix de l'irresponsabilit\u00e9 POU -LRB- t -RRB- est obtenu \u00e0 un certain point de transition, il suffit donc de parcourir tous les points de transition et de trouver celui avec le ratio de bien-\u00eatre social maximal. Une question plus int\u00e9ressante est de savoir si, si l\u2019on donne la fonction t comme une bo\u00eete noire, nous pouvons calculer le contrat optimal en temps qui soit polynomial en n. On peut montrer qu'en g\u00e9n\u00e9ral ce n'est pas le cas : TH\u00c9OR\u00c8ME 5.\u00c9tant donn\u00e9s en entr\u00e9e une bo\u00eete noire pour une fonction de r\u00e9ussite t -LRB- lorsque les co\u00fbts sont identiques -RRB-, et une valeur v, le nombre de requ\u00eates n\u00e9cessaires, dans le pire des cas, pour trouver le contrat optimal est exponentiel en n . PREUVE. Consid\u00e9rons la famille de technologies suivante. Pour certains petits e > 0 et k = -LSB- n/2 -RSB- nous d\u00e9finissons la probabilit\u00e9 de succ\u00e8s pour un ensemble T donn\u00e9 comme suit. Si l'algorithme interroge au plus -LRB- n -RRB- -- 2 ensembles fin/2 -RSB- de taille k, alors il ne peut pas toujours d\u00e9terminer le contrat optimal -LRB- comme aucun des ensembles qu'il n'a pas interrog\u00e9s about pourrait \u00eatre le meilleur -RRB-. Nous concluons que -LRB- n -RRB- -- 1 requ\u00eates fin/2 -RSB- sont n\u00e9cessaires pour d\u00e9terminer le contrat optimal, et celui-ci est exponentiel en n. 5.2 Technologies structur\u00e9es Dans cette section, nous consid\u00e9rerons la repr\u00e9sentation naturelle des r\u00e9seaux \u00e0 lecture unique pour la fonction bool\u00e9enne sous-jacente. Ainsi le probl\u00e8me que nous abordons sera : Le probl\u00e8me du contrat optimal pour les r\u00e9seaux \u00e0 lecture unique : Entr\u00e9e : Un r\u00e9seau \u00e0 lecture unique G = -LRB- V, E -RRB-, avec deux sommets sp\u00e9cifiques s, t ; des valeurs rationnelles - ye, \u03b4e pour chaque joueur e \u2208 E -LRB- et ce = 1 -RRB-, et une valeur rationnelle v. R\u00e9sultat : Un ensemble S d'agents qui devraient \u00eatre contract\u00e9s dans un contrat optimal. Soit t -LRB- E -RRB- la probabilit\u00e9 de succ\u00e8s lorsque chaque ar\u00eate r\u00e9ussit avec une probabilit\u00e9 \u03b4e. Nous remarquons d'abord que m\u00eame le calcul de la valeur t -LRB- E -RRB- est un probl\u00e8me difficile : il est appel\u00e9 probl\u00e8me de fiabilit\u00e9 du r\u00e9seau et est connu pour \u00eatre #P \u2212 hard -LSB- 8 -RSB-. Juste un petit effort r\u00e9v\u00e9lera que notre probl\u00e8me n'est pas plus simple : TH\u00c9OR\u00c8ME 6. Le probl\u00e8me de contrat optimal pour les r\u00e9seaux \u00e0 lecture unique est #P - dur -LRB- sous les r\u00e9ductions de Turing -RRB-. PREUVE. Nous montrerons qu\u2019un algorithme pour ce probl\u00e8me peut \u00eatre utilis\u00e9 pour r\u00e9soudre le probl\u00e8me de fiabilit\u00e9 du r\u00e9seau. \u00c9tant donn\u00e9 une instance d'un probl\u00e8me de fiabilit\u00e9 du r\u00e9seau < G, -LCB- -LRB- e -RCB- eEE > -LRB- o\u00f9 -LRB- e d\u00e9signe la probabilit\u00e9 de succ\u00e8s de e -RRB-, nous d\u00e9finissons une instance du contrat optimal probl\u00e8me comme suit : d\u00e9finir d'abord un nouveau graphe G ' qui s'obtient en '' Et '' ing G avec un nouveau joueur x, avec - yx tr\u00e8s proche de 21 et \u03b4x = 1 \u2212 - yx. Une fois que nous avons trouv\u00e9 une telle valeur, nous choisissons - yx st c 1 -- 2\u03b3x est plus grand que cette valeur -RRB-. Notons \u03b2x = 1 \u2212 2-yx. La valeur critique de v o\u00f9 le joueur x entre dans le contrat optimal de G' peut \u00eatre trouv\u00e9e en utilisant une recherche binaire sur l'algorithme qui est cens\u00e9 trouver le contrat optimal pour n'importe quel r\u00e9seau et n'importe quelle valeur. Notons qu'\u00e0 cette valeur critique v, le principal est indiff\u00e9rent entre l'ensemble E et E \u222a -LCB- x -RCB-. ainsi, si nous pouvons toujours trouver le contrat optimal, nous sommes \u00e9galement capables de calculer la valeur de t -LRB- E -RRB-. En conclusion, calculer le contrat optimal en g\u00e9n\u00e9ral est difficile. Ces r\u00e9sultats sugg\u00e8rent deux directions naturelles de recherche. La premi\u00e8re piste consiste \u00e0 \u00e9tudier des familles de technologies dont les contrats optimaux peuvent \u00eatre calcul\u00e9s en temps polynomial.La deuxi\u00e8me piste consiste \u00e0 explorer des algorithmes d\u2019approximation pour le probl\u00e8me du contrat optimal. Un candidat possible pour la premi\u00e8re direction est la famille des r\u00e9seaux s\u00e9rie-parall\u00e8le, pour lesquels le probl\u00e8me de fiabilit\u00e9 du r\u00e9seau -LRB- calculant la valeur de t -RRB- est polynomial.", "keyphrases": ["ensemble optimal de contrat", "agent principal classique", "qualit\u00e9 de service", "agence combinatoire", "\u00e9quilibre de Nash", "action contractuelle", "orbite k", "technologie anonyme", "r\u00e9seau s\u00e9rie-parall\u00e8le", "prix du manque de compte"]}
{"file_name": "J-11", "text": "R\u00e9seaux commerciaux avec agents de fixation des prix R\u00c9SUM\u00c9 Dans un large \u00e9ventail de march\u00e9s, les acheteurs et les vendeurs individuels n\u00e9gocient souvent par l'interm\u00e9diaire d'interm\u00e9diaires, qui d\u00e9terminent les prix en fonction de consid\u00e9rations strat\u00e9giques. En r\u00e8gle g\u00e9n\u00e9rale, tous les acheteurs et vendeurs n\u2019ont pas acc\u00e8s aux m\u00eames interm\u00e9diaires et ils n\u00e9gocient \u00e0 des prix correspondants diff\u00e9rents qui refl\u00e8tent leur pouvoir relatif sur le march\u00e9. Nous mod\u00e9lisons ce ph\u00e9nom\u00e8ne \u00e0 l'aide d'un jeu dans lequel acheteurs, vendeurs et commer\u00e7ants s'engagent dans des \u00e9changes commerciaux sur un graphique qui repr\u00e9sente l'acc\u00e8s de chaque acheteur et vendeur aux commer\u00e7ants. Dans ce mod\u00e8le, les commer\u00e7ants fixent les prix de mani\u00e8re strat\u00e9gique, puis les acheteurs et les vendeurs r\u00e9agissent aux prix qui leur sont propos\u00e9s. Nous montrons que le jeu r\u00e9sultant a toujours un \u00e9quilibre de Nash parfait en sous-jeu, et que tous les \u00e9quilibres conduisent \u00e0 une allocation -LRB- efficace, c'est-\u00e0-dire socialement optimale -RRB- des biens. Nous \u00e9tendons ces r\u00e9sultats \u00e0 un type plus g\u00e9n\u00e9ral de march\u00e9 d\u2019appariement, comme celui que l\u2019on retrouve dans l\u2019appariement de candidats \u00e0 un emploi et d\u2019employeurs. Enfin, nous consid\u00e9rons comment les b\u00e9n\u00e9fices obtenus par les traders d\u00e9pendent du graphique sous-jacent -- en gros, un trader peut r\u00e9aliser un profit positif si et seulement s'il dispose d'une connexion \u00ab essentielle \u00bb dans la structure du r\u00e9seau, fournissant ainsi un graphique- base th\u00e9orique pour quantifier le degr\u00e9 de concurrence entre les commer\u00e7ants. Notre travail diff\u00e8re des \u00e9tudes r\u00e9centes sur la fa\u00e7on dont les prix sont affect\u00e9s par la structure du r\u00e9seau par notre mod\u00e9lisation de la fixation des prix en tant qu'activit\u00e9 strat\u00e9gique men\u00e9e par un sous-ensemble d'agents dans le syst\u00e8me, plut\u00f4t que par l'\u00e9tude des prix fix\u00e9s via un \u00e9quilibre concurrentiel ou par un m\u00e9canisme v\u00e9ridique. 1. INTRODUCTION Dans toute une gamme de contexts o\u00f9 les march\u00e9s n\u00e9gocient les interactions entre acheteurs et vendeurs, on observe plusieurs propri\u00e9t\u00e9s r\u00e9currentes : les acheteurs et vendeurs individuels n\u00e9gocient souvent par l'interm\u00e9diaire d'interm\u00e9diaires, tous les acheteurs et vendeurs n'ont pas acc\u00e8s aux m\u00eames interm\u00e9diaires, et tous les acheteurs et vendeurs n'ont pas acc\u00e8s aux m\u00eames interm\u00e9diaires. les vendeurs n\u00e9gocient au m\u00eame prix. Un exemple de ce context est le commerce des produits agricoles dans les pays en d\u00e9veloppement. Compte tenu de l'insuffisance des r\u00e9seaux de transport et de l'acc\u00e8s limit\u00e9 des agriculteurs pauvres au capital, de nombreux agriculteurs n'ont d'autre choix que de commercer avec des interm\u00e9diaires sur des march\u00e9s locaux inefficaces. Un pays en d\u00e9veloppement peut avoir de nombreux march\u00e9s de ce type qui se chevauchent partiellement \u00e0 c\u00f4t\u00e9 de march\u00e9s efficaces modernes -LSB-2-RSB-. Les march\u00e9s financiers fournissent un exemple diff\u00e9rent d\u2019un environnement pr\u00e9sentant ces caract\u00e9ristiques g\u00e9n\u00e9rales. Sur ces march\u00e9s, une grande partie des \u00e9changes entre acheteurs et vendeurs est assur\u00e9e par divers agents allant des courtiers aux teneurs de march\u00e9 en passant par les syst\u00e8mes de n\u00e9gociation \u00e9lectronique. Pour de nombreux actifs, il n\u2019existe pas de march\u00e9 unique ; la n\u00e9gociation d\u2019un seul actif peut avoir lieu simultan\u00e9ment sur le parquet d\u2019une bourse, sur des r\u00e9seaux crois\u00e9s, sur des bourses \u00e9lectroniques et sur les march\u00e9s d\u2019autres pays. Certains acheteurs et vendeurs ont acc\u00e8s \u00e0 plusieurs ou \u00e0 la totalit\u00e9 de ces plateformes de n\u00e9gociation ; d\u2019autres n\u2019ont acc\u00e8s qu\u2019\u00e0 un ou quelques-uns d\u2019entre eux. Le prix auquel l'actif est n\u00e9goci\u00e9 peut diff\u00e9rer selon ces plateformes de n\u00e9gociation.En fait, il n'y a pas de \u00ab prix \u00bb puisque diff\u00e9rents commer\u00e7ants paient ou re\u00e7oivent des prix diff\u00e9rents. Dans de nombreux contexts, il existe \u00e9galement un \u00e9cart entre le prix qu'un acheteur paie pour un actif, le prix vendeur, et le prix qu'un vendeur re\u00e7oit pour l'actif, le prix acheteur. Les spreads, d\u00e9finis comme la diff\u00e9rence entre les prix acheteur et vendeur, diff\u00e8rent consid\u00e9rablement entre ces march\u00e9s, m\u00eame si le m\u00eame actif est n\u00e9goci\u00e9 sur les deux march\u00e9s. Dans cet article, nous d\u00e9veloppons un cadre dans lequel de tels ph\u00e9nom\u00e8nes \u00e9mergent d\u2019un mod\u00e8le commercial fond\u00e9 sur la th\u00e9orie des jeux, dans lequel acheteurs, vendeurs et commer\u00e7ants interagissent sur un r\u00e9seau. Les limites du r\u00e9seau relient les commer\u00e7ants aux acheteurs et aux vendeurs et repr\u00e9sentent ainsi l\u2019acc\u00e8s qu\u2019ont les diff\u00e9rents acteurs du march\u00e9 les uns aux autres. Les traders servent d'interm\u00e9diaires dans un jeu de trading en deux \u00e9tapes : ils choisissent strat\u00e9giquement les prix acheteurs et vendeurs \u00e0 proposer aux vendeurs et acheteurs avec lesquels ils sont connect\u00e9s ; les vendeurs et les acheteurs r\u00e9agissent alors aux prix auxquels ils sont confront\u00e9s. Ainsi, le r\u00e9seau code le pouvoir relatif dans les positions structurelles des acteurs du march\u00e9, y compris les niveaux implicites de concurrence entre les commer\u00e7ants. Nous montrons que ce jeu a toujours un \u00e9quilibre de Nash parfait en sous-jeu, et que tous les \u00e9quilibres conduisent \u00e0 une allocation -LRB- efficace, c'est-\u00e0-dire socialement optimale -RRB- des biens. Nous analysons \u00e9galement comment les b\u00e9n\u00e9fices des traders d\u00e9pendent de la structure du r\u00e9seau, caract\u00e9risant essentiellement en termes de th\u00e9orie des graphes comment les gains d'un trader sont d\u00e9termin\u00e9s par le degr\u00e9 de concurrence qu'il subit avec les autres traders. En d\u00e9veloppant un mod\u00e8le de r\u00e9seau qui inclut explicitement les commer\u00e7ants en tant qu'agents de fixation des prix, dans un syst\u00e8me r\u00e9unissant acheteurs et vendeurs, nous sommes en mesure de saisir la formation des prix dans un context de r\u00e9seau comme un processus strat\u00e9gique men\u00e9 par des interm\u00e9diaires, plut\u00f4t que comme le r\u00e9sultat de un m\u00e9canisme contr\u00f4l\u00e9 centralement ou exog\u00e8ne. Le mod\u00e8le de base : les biens indiscernables. Notre objectif en formulant ce mod\u00e8le est d'exprimer le processus de fixation des prix sur des march\u00e9s tels que ceux \u00e9voqu\u00e9s ci-dessus, o\u00f9 les participants n'ont pas tous un acc\u00e8s uniforme les uns aux autres. On nous donne un ensemble B d\u2019acheteurs, un ensemble S de vendeurs et un ensemble T de commer\u00e7ants. Il existe un graphique G non orient\u00e9 qui indique qui peut \u00e9changer avec qui. Cela refl\u00e8te les contraintes selon lesquelles toutes les transactions acheteur-vendeur passent par des commer\u00e7ants en tant qu\u2019interm\u00e9diaires. Dans la version la plus basique du mod\u00e8le, nous consid\u00e9rons des biens identiques, dont un exemplaire est initialement d\u00e9tenu par chaque vendeur. Les acheteurs et les vendeurs ont chacun une valeur pour une copie du bien, et nous supposons que ces valeurs sont de notori\u00e9t\u00e9 publique. Nous g\u00e9n\u00e9raliserons ensuite cela \u00e0 un context dans lequel les biens sont distinguables, les acheteurs peuvent \u00e9valuer diff\u00e9remment diff\u00e9rents biens et potentiellement les vendeurs peuvent \u00e9galement \u00e9valuer diff\u00e9remment les transactions avec diff\u00e9rents acheteurs. Le fait d'avoir diff\u00e9rentes \u00e9valuations d'acheteurs permet de capturer des param\u00e8tres tels que les achats de maisons\u00a0; l'ajout de diff\u00e9rentes \u00e9valuations de vendeurs permet \u00e9galement de capturer les march\u00e9s correspondants - par exemple,les vendeurs en tant que demandeurs d'emploi et les acheteurs en tant qu'employeurs, les deux se souciant de qui finit avec quel \u00ab\u00a0bien\u00a0\u00bb -LRB- et les commer\u00e7ants agissant comme des services qui n\u00e9gocient la recherche d'emploi -RRB-. Ainsi, pour commencer avec le mod\u00e8le de base, il existe un seul type de bien ; le bien se pr\u00e9sente en unit\u00e9s indivisibles ; et chaque vendeur d\u00e9tient initialement une unit\u00e9 du bien. Les trois types d'agents valorisent l'argent au m\u00eame taux ; et chaque i EBUS valorise en outre une copie du bien \u00e0 \u03b8i unit\u00e9s mon\u00e9taires. Aucun agent ne veut plus d'une copie du bien, donc les copies suppl\u00e9mentaires sont \u00e9valu\u00e9es \u00e0 0. Chaque agent dispose d'une dotation initiale en argent qui est sup\u00e9rieure \u00e0 toute \u00e9valuation individuelle \u03b8i ; cela a pour effet de garantir que tout acheteur qui se retrouve sans copie du bien a \u00e9t\u00e9 exclu du march\u00e9 en raison de sa valorisation et de sa position dans le r\u00e9seau, et non d'un manque de fonds. Nous imaginons chaque bien vendu circulant le long d'une s\u00e9quence de deux bords : du vendeur au commer\u00e7ant, puis du commer\u00e7ant \u00e0 l'acheteur. La mani\u00e8re particuli\u00e8re dont les marchandises circulent est d\u00e9termin\u00e9e par le jeu suivant. Premi\u00e8rement, chaque trader propose un prix acheteur \u00e0 chaque vendeur auquel il est connect\u00e9, et un prix vendeur \u00e0 chaque acheteur auquel il est connect\u00e9. Vendeurs et acheteurs choisissent ensuite parmi les offres qui leur sont pr\u00e9sent\u00e9es par les commer\u00e7ants. Si plusieurs commer\u00e7ants proposent le m\u00eame prix \u00e0 un vendeur ou \u00e0 un acheteur, il n\u2019y a pas de meilleure r\u00e9ponse stricte pour le vendeur ou l\u2019acheteur. Enfin, chaque commer\u00e7ant ach\u00e8te une copie du bien \u00e0 chaque vendeur qui accepte son offre, et vend une copie du bien \u00e0 chaque acheteur qui accepte son offre. Si un commer\u00e7ant particulier constate que plus d'acheteurs que de vendeurs acceptent ses offres, alors il s'est engag\u00e9 \u00e0 fournir plus d'exemplaires du bien qu'il n'en a re\u00e7u, et nous dirons que cela entra\u00eene une lourde p\u00e9nalit\u00e9 pour le commer\u00e7ant en cas de d\u00e9faut ; l'effet de ceci est qu'\u00e0 l'\u00e9quilibre, aucun trader ne choisira des prix acheteur et vendeur qui entra\u00eeneront un d\u00e9faut. Plus pr\u00e9cis\u00e9ment, une strat\u00e9gie pour chaque commer\u00e7ant t est une sp\u00e9cification d'un prix acheteur 3ti pour chaque vendeur i auquel t est connect\u00e9, et d'un prix vendeur \u03b1tj pour chaque acheteur j auquel t est connect\u00e9. -LRB- Nous pouvons \u00e9galement g\u00e9rer un mod\u00e8le dans lequel un commer\u00e7ant peut choisir de ne pas faire d'offre \u00e0 certains de ses vendeurs ou acheteurs adjacents. -RRB- Chaque vendeur ou acheteur choisit alors au plus un bord incident, en indiquant le commer\u00e7ant avec lequel il va traiter, au prix indiqu\u00e9. -LRB- Le choix d'un seul bord refl\u00e8te le fait que les vendeurs -LRB- a -RRB- n'ont chacun initialement qu'un seul exemplaire du bien, et que les acheteurs -LRB- b -RRB- ne veulent chacun qu'un seul exemplaire du bien. -RRB- Les gains sont les suivants : Pour chaque vendeur i, le gain en s\u00e9lectionnant le trader t est 3ti, tandis que le gain en ne s\u00e9lectionnant aucun trader est \u03b8i. -LRB- Dans le premier cas, le vendeur re\u00e7oit 3ti unit\u00e9s de monnaie, tandis que dans le second il conserve sa copie du bien, qu'il valorise \u00e0 \u03b8i. -RRB- Pour chaque acheteur j, le gain de la s\u00e9lection du commer\u00e7ant t est \u03b8j -- \u03b1tj, tandis que le gain de la s\u00e9lection d'aucun commer\u00e7ant est de 0.-LRB- Dans le premier cas, l'acheteur re\u00e7oit le bien mais c\u00e8de \u03b1tj unit\u00e9s de monnaie. -RRB- Pour chaque commer\u00e7ant t, avec des offres accept\u00e9es des vendeurs i1,..., is et des acheteurs j1,..., jb, le gain est Pr \u03b1tjr -- Pr 3tir, moins une p\u00e9nalit\u00e9 \u03c0 si b > s. La p\u00e9nalit\u00e9 est choisie pour \u00eatre suffisamment importante pour qu'un commer\u00e7ant ne l'encoure jamais \u00e0 l'\u00e9quilibre, et par cons\u00e9quent nous ne nous pr\u00e9occuperons g\u00e9n\u00e9ralement pas de la p\u00e9nalit\u00e9. Ceci d\u00e9finit les \u00e9l\u00e9ments de base du jeu. Le concept d\u2019\u00e9quilibre que nous utilisons est l\u2019\u00e9quilibre de Nash parfait en sous-jeu. Quelques exemples. Pour vous aider \u00e0 r\u00e9fl\u00e9chir au mod\u00e8le, nous d\u00e9crivons maintenant trois exemples illustratifs, repr\u00e9sent\u00e9s dans la figure 1. Tous les vendeurs dans les exemples auront des valorisations pour le bien \u00e9gales \u00e0 0 ; la valorisation de chaque acheteur est trac\u00e9e \u00e0 l'int\u00e9rieur de son cercle ; et le prix acheteur ou vendeur sur chaque bord est dessin\u00e9 au-dessus du bord. Dans la figure 1 -LRB- a -RRB-, nous montrons comment une ench\u00e8re standard au second prix d\u00e9coule naturellement de notre mod\u00e8le. Supposons que les \u00e9valuations des acheteurs de haut en bas soient w > x > y > z. Les prix acheteur et vendeur indiqu\u00e9s sont coh\u00e9rents avec un \u00e9quilibre dans lequel i1 et j1 acceptent les offres du commer\u00e7ant t1, et aucun autre acheteur n'accepte l'offre de son commer\u00e7ant adjacent : ainsi, le commer\u00e7ant t1 re\u00e7oit le bien avec un prix acheteur de x, et fait w -- x en vendant le bien \u00e0 l'acheteur j1 pour w. De cette mani\u00e8re, nous pouvons consid\u00e9rer ce cas particulier comme une vente aux ench\u00e8res pour un seul bien dans laquelle les commer\u00e7ants agissent comme des \u00ab mandataires \u00bb pour leurs acheteurs adjacents. L'acheteur ayant la valeur la plus \u00e9lev\u00e9e pour le bien finit par l'acqu\u00e9rir, et le surplus est partag\u00e9 entre le vendeur et le commer\u00e7ant associ\u00e9. Notez qu\u2019on peut tout aussi facilement construire une vente aux ench\u00e8res de k unit\u00e9s avec f > k acheteurs, en construisant un graphe bipartite complet sur k vendeurs et f commer\u00e7ants, puis en attachant chaque commer\u00e7ant \u00e0 un seul acheteur distinct. Dans la Figure 1 -LRB- b -RRB-, nous montrons comment des n\u0153uds ayant des positions diff\u00e9rentes dans la topologie du r\u00e9seau peuvent obtenir des gains diff\u00e9rents, m\u00eame lorsque tous l\u2019acheteur ayant la valeur la plus \u00e9lev\u00e9e pour le bien finit par l\u2019acqu\u00e9rir. -LRB- b -RRB- Un r\u00e9seau dans lequel le vendeur interm\u00e9diaire et l'acheteur b\u00e9n\u00e9ficient d'une concurrence parfaite entre les commer\u00e7ants, tandis que les autres vendeurs et acheteurs n'ont aucun pouvoir en raison de leur position dans le r\u00e9seau. -LRB- c -RRB- Une forme de concurrence parfaite implicite : tous les spreads bid/ask seront nuls \u00e0 l'\u00e9quilibre, m\u00eame si aucun trader n'est directement en \u00ab concurrence \u00bb avec un autre trader pour la m\u00eame paire acheteur-vendeur. les \u00e9valuations des acheteurs sont les m\u00eames num\u00e9riquement. Plus pr\u00e9cis\u00e9ment, le vendeur i2 et l'acheteur j2 occupent des positions puissantes, car les deux commer\u00e7ants sont en concurrence pour leur march\u00e9 ; \u00e0 l\u2019inverse, les autres vendeurs et acheteurs sont en position de faiblesse, car ils n\u2019ont chacun qu\u2019une seule option. Et en effet, dans tout \u00e9quilibre, il existe un nombre r\u00e9el x E -LSB- 0, 1 -RSB- tel que les deux traders proposent des prix acheteur et vendeur de x \u00e0 i2 et j2 respectivement,alors qu'ils proposent des offres de 0 et demandent des 1 aux autres vendeurs et acheteurs. Ainsi, cet exemple illustre quelques ingr\u00e9dients cruciaux que nous identifierons prochainement \u00e0 un niveau plus g\u00e9n\u00e9ral. Plus pr\u00e9cis\u00e9ment, i2 et j2 b\u00e9n\u00e9ficient des avantages de la concurrence parfaite, dans la mesure o\u00f9 les deux traders conduisent les spreads acheteur-vendeur \u00e0 0 en rivalisant pour leur activit\u00e9. D\u2019un autre c\u00f4t\u00e9, les autres vendeurs et acheteurs subissent les inconv\u00e9nients du monopole\u00a0: ils ne re\u00e7oivent aucun gain puisqu\u2019ils n\u2019ont qu\u2019une seule option de commerce et le commer\u00e7ant correspondant r\u00e9alise tous les b\u00e9n\u00e9fices. Notez en outre comment ce comportement naturel \u00e9merge du fait que les traders sont capables de proposer des prix diff\u00e9rents \u00e0 diff\u00e9rents agents -- capturant le fait qu'il n'y a pas de \u00ab prix \u00bb fixe sur les types de march\u00e9s qui motivent le mod\u00e8le, mais plut\u00f4t des prix diff\u00e9rents. des prix refl\u00e9tant le pouvoir relatif des diff\u00e9rents agents impliqu\u00e9s. L'exemple pr\u00e9c\u00e9dent montre peut-\u00eatre la mani\u00e8re la plus naturelle par laquelle le profit d'un trader sur une transaction particuli\u00e8re peut tomber \u00e0 0 : lorsqu'il existe un autre trader qui peut reproduire sa fonction avec pr\u00e9cision. -LRB- Dans cet exemple, deux commer\u00e7ants avaient chacun la possibilit\u00e9 de d\u00e9placer une copie du bien de i2 vers j2. -RRB- Mais comme nos r\u00e9sultats ult\u00e9rieurs le montreront, les traders ne r\u00e9alisent g\u00e9n\u00e9ralement aucun profit pour des raisons globales de th\u00e9orie des graphes. L'exemple de la Figure 1 -LRB- c -RRB- en donne une premi\u00e8re indication : on peut montrer que pour tout \u00e9quilibre, il existe ay E -LSB- 0, 1 -RSB- tel que chaque cours acheteur et chaque cours vendeur sont \u00e9gaux. jouet. En d\u2019autres termes, tous les commer\u00e7ants ne r\u00e9alisent aucun profit, qu\u2019une copie du bien passe ou non par eux \u2013 et pourtant, deux commer\u00e7ants n\u2019ont pas de parcours vendeur-acheteur en commun. Les spreads de prix ont \u00e9t\u00e9 ramen\u00e9s \u00e0 z\u00e9ro par une contrainte globale impos\u00e9e par le cycle long \u00e0 travers tous les agents ; il s'agit d'un exemple de concurrence parfaite implicite d\u00e9termin\u00e9e par la topologie du r\u00e9seau. Extension du mod\u00e8le aux biens distincts. Nous \u00e9tendons le mod\u00e8le de base \u00e0 un context comportant des biens distinctifs, comme suit. Une strat\u00e9gie pour un commer\u00e7ant consiste d\u00e9sormais \u00e0 proposer \u00e0 chaque vendeur une offre sp\u00e9cifiant \u00e0 la fois un prix et un acheteur, et \u00e0 proposer une demande \u00e0 chaque acheteur sp\u00e9cifiant \u00e0 la fois un prix et un vendeur. -LRB- On peut \u00e9galement g\u00e9rer un mod\u00e8le dans lequel un trader propose des offres -LRB- respectivement, demande -RRB- sous forme de vecteurs, sp\u00e9cifiant essentiellement un `` menu '' avec un prix attach\u00e9 \u00e0 chaque acheteur -LRB- resp. vendeur -RRB-. -RRB- Chaque acheteur et vendeur s\u00e9lectionne une offre d'un commer\u00e7ant adjacent, et les gains de tous les agents sont d\u00e9termin\u00e9s comme auparavant. Ici, les vendeurs sont des demandeurs d\u2019emploi, les acheteurs sont des employeurs et les commer\u00e7ants sont les agents qui servent d\u2019interm\u00e9diaires sur le march\u00e9 du travail. Bien s\u00fbr, si l'on sp\u00e9cifie des \u00e9valuations par paires pour les acheteurs mais uniquement des \u00e9valuations uniques pour les vendeurs, nous mod\u00e9lisons un cadre dans lequel les acheteurs peuvent distinguer les biens, mais les vendeurs ne se soucient pas de savoir \u00e0 qui ils vendent -- ce -LRB- en gros -RRB- capture des contexts tels que les march\u00e9s immobiliers. Nos r\u00e9sultats. Pour les pr\u00e9ciser,nous introduisons la notation suivante. -LRB- Les vendeurs figurant dans aucun triple conservent leur exemplaire du bien. -RRB- On dit que la valeur de l'allocation est \u00e9gale \u00e0 Pe \u2208 M \u03b8jeie -- \u03b8ieje. Soit \u03b8 \u2217 la valeur maximale de toute allocation M r\u00e9alisable \u00e9tant donn\u00e9 le r\u00e9seau. Nous montrons que chaque instance de notre jeu a un \u00e9quilibre, et que dans chacun de ces \u00e9quilibres, l'allocation a une valeur \u03b8 \u2217 -- en d'autres termes, elle atteint la meilleure valeur possible. Ainsi, les \u00e9quilibres dans ce mod\u00e8le sont toujours efficaces, dans le sens o\u00f9 le march\u00e9 permet au \u00ab bon \u00bb groupe de personnes d'obtenir le bien, sous r\u00e9serve des contraintes du r\u00e9seau. Nous \u00e9tablissons l'existence et l'efficacit\u00e9 des \u00e9quilibres en construisant un programme lin\u00e9aire pour capturer le flux de marchandises \u00e0 travers le r\u00e9seau ; le dual de ce programme lin\u00e9aire contient suffisamment d'informations pour extraire les prix d'\u00e9quilibre. Par la d\u00e9finition du jeu, la valeur de l'allocation d'\u00e9quilibre est divis\u00e9e en r\u00e9compenses pour les agents, et il est int\u00e9ressant de se demander comment cette valeur est distribu\u00e9e - en particulier quel profit un trader est capable de r\u00e9aliser en fonction de sa position. dans le r\u00e9seau. Nous constatons que, m\u00eame si tous les \u00e9quilibres ont la m\u00eame valeur, le gain d'un trader donn\u00e9 peut varier selon les diff\u00e9rents \u00e9quilibres. Nous obtenons \u00e9galement des r\u00e9sultats pour la somme de tous les b\u00e9n\u00e9fices des traders. Travaux connexes. L\u2019approche de base standard pour analyser l\u2019interaction entre acheteurs et vendeurs est le mod\u00e8le walrasien dans lequel des acheteurs et des vendeurs anonymes \u00e9changent un bien \u00e0 un prix d\u2019\u00e9quilibre unique du march\u00e9. Cette forme r\u00e9duite d\u2019\u00e9changes, construite sur l\u2019id\u00e9alisation d\u2019un prix de march\u00e9, constitue un mod\u00e8le puissant qui a donn\u00e9 lieu \u00e0 de nombreuses r\u00e9flexions. Mais ce n\u2019est pas un bon mod\u00e8le \u00e0 utiliser pour examiner d\u2019o\u00f9 viennent les prix ou exactement comment les acheteurs et les vendeurs \u00e9changent entre eux. La difficult\u00e9 est que dans le mod\u00e8le walrasien, aucun agent ne fixe le prix et que les agents n'\u00e9changent pas r\u00e9ellement entre eux. En fait, il n\u2019y a pas de march\u00e9, au sens courant du terme, dans le mod\u00e8le walrasien. Autrement dit, il n\u2019existe aucun lieu physique ou virtuel o\u00f9 les acheteurs et les vendeurs interagissent pour \u00e9changer et fixer les prix. Ainsi, dans ce mod\u00e8le simple, tous les acheteurs et vendeurs sont uniformes et n\u00e9gocient au m\u00eame prix, et les interm\u00e9diaires n\u2019ont pas non plus de r\u00f4le \u00e0 jouer. Il existe plusieurs ouvrages en \u00e9conomie et en finance qui examinent la mani\u00e8re dont les prix sont fix\u00e9s plut\u00f4t que de simplement d\u00e9terminer les prix d\u2019\u00e9quilibre. La litt\u00e9rature sur la concurrence imparfaite est peut-\u00eatre la plus ancienne d\u2019entre elles. Ici, un monopoleur, ou un groupe d'oliogopolistes, choisit les prix afin de maximiser ses profits -LRB- voir -LSB- 14 -RSB- pour le traitement classique de ces march\u00e9s -RRB-. Un monopoleur utilise sa connaissance de la demande du march\u00e9 pour choisir un prix, ou un ensemble de prix s'il pratique une discrimination. Les oliogopolistes jouent \u00e0 un jeu dans lequel leurs gains d\u00e9pendent de la demande du march\u00e9 et des actions de leurs concurrents. Dans cette litt\u00e9rature, il y a des agents qui fixent les prix, mais la fiction d\u2019un march\u00e9 unique est maintenue. Dans la litt\u00e9rature sur la recherche d'\u00e9quilibre,les entreprises fixent les prix et les consommateurs les recherchent -LRB- voir -LSB- 3 -RSB- -RRB-. Les consommateurs finissent par payer des prix diff\u00e9rents, mais tous ont acc\u00e8s \u00e0 toutes les entreprises et il n\u2019y a pas d\u2019interm\u00e9diaires. Dans la litt\u00e9rature sur l\u2019\u00e9quilibre g\u00e9n\u00e9ral, plusieurs tentatives ont \u00e9t\u00e9 faites pour introduire la d\u00e9termination des prix. Une technique standard de preuve de l\u2019existence d\u2019un \u00e9quilibre concurrentiel implique un m\u00e9canisme d\u2019ajustement des prix dans lequel les prix r\u00e9pondent \u00e0 une demande exc\u00e9dentaire. Des processus plus sophistiqu\u00e9s ont \u00e9t\u00e9 introduits pour \u00e9tudier la stabilit\u00e9 des prix d\u2019\u00e9quilibre ou les informations n\u00e9cessaires \u00e0 leur calcul. Mais l\u00e0 encore, il n\u2019y a pas d\u2019agents fixant les prix ici. Dans la litt\u00e9rature financi\u00e8re, les travaux sur la microstructure du march\u00e9 font appel \u00e0 des agents de fixation des prix -LRB- sp\u00e9cialistes -RRB-, dont certaines parties d\u00e9terminent des prix acheteur et vendeur distincts, et diff\u00e9rents agents re\u00e7oivent des prix diff\u00e9rents pour le m\u00eame actif -LRB- voir -LSB - 12 -RSB- pour un traitement de la th\u00e9orie de la microstructure -RRB-. Les travaux en \u00e9conomie de l'information ont identifi\u00e9 des ph\u00e9nom\u00e8nes similaires -LRB- voir par exemple -LSB- 7 -RSB- -RRB-. Mais il existe peu de recherches dans ces ouvrages examinant l\u2019effet des restrictions sur qui peut commercer avec qui. Il existe plusieurs approches pour \u00e9tudier la mani\u00e8re dont la structure du r\u00e9seau d\u00e9termine les prix. Ceux-ci ont postul\u00e9 que la d\u00e9termination des prix se faisait au moyen de d\u00e9finitions fond\u00e9es sur l'\u00e9quilibre concurrentiel ou le noyau, ou au moyen de m\u00e9canismes v\u00e9ridiques. En passant bri\u00e8vement en revue ces travaux, nous remarquerons le contraste avec notre approche, dans la mesure o\u00f9 nous mod\u00e9lisons les prix comme d\u00e9coulant du comportement strat\u00e9gique des agents du syst\u00e8me. Dans des travaux r\u00e9cents, Kakade et al. -LSB- 8 -RSB- ont \u00e9tudi\u00e9 la distribution des prix \u00e0 l'\u00e9quilibre concurrentiel dans un graphe biparti sur les acheteurs et les vendeurs, g\u00e9n\u00e9r\u00e9 \u00e0 l'aide d'un mod\u00e8le probabiliste capable de produire des distributions de degr\u00e9s \u00e0 queues lourdes -LSB- 11 -RSB-. Even-Dar et al. -LSB- 6 -RSB- s'appuient sur cela pour consid\u00e9rer les aspects strat\u00e9giques de la formation du r\u00e9seau lorsque les prix d\u00e9coulent d'un \u00e9quilibre concurrentiel. Leonard \u00e9tudie les prix des VCG dans ce context ; Baba\u00efoff et coll. et Chu et Shen fournissent en outre un m\u00e9canisme d'\u00e9quilibre budg\u00e9taire. En revanche, notre mod\u00e8le a connu des valorisations et des prix d\u00e9coulant du comportement strat\u00e9gique des traders. Demange, Gale et Sotomayor -LSB-5-RSB-, et Kranton et Minehart -LSB-9-RSB-, analysent les prix auxquels les \u00e9changes ont lieu dans un r\u00e9seau, en travaillant dans le cadre de la conception de m\u00e9canismes. Kranton et Minehart utilisent un graphe bipartite avec des liens directs entre acheteurs et vendeurs, puis utilisent un m\u00e9canisme d'ench\u00e8res ascendantes, plut\u00f4t que des interm\u00e9diaires strat\u00e9giques, pour d\u00e9terminer les prix. Leurs ench\u00e8res ont des propri\u00e9t\u00e9s d\u2019\u00e9quilibre souhaitables, mais comme le notent Kranton et Minehart, il s\u2019agit d\u2019une abstraction de la fa\u00e7on dont les biens sont r\u00e9partis et les prix sont d\u00e9termin\u00e9s, dont l\u2019esprit est similaire \u00e0 celui du commissaire-priseur walrasien.mais tous les consommateurs ont acc\u00e8s \u00e0 toutes les entreprises et il n\u2019y a pas d\u2019interm\u00e9diaires. Dans la litt\u00e9rature sur l\u2019\u00e9quilibre g\u00e9n\u00e9ral, plusieurs tentatives ont \u00e9t\u00e9 faites pour introduire la d\u00e9termination des prix. Une technique standard de preuve de l\u2019existence d\u2019un \u00e9quilibre concurrentiel implique un m\u00e9canisme d\u2019ajustement des prix dans lequel les prix r\u00e9pondent \u00e0 une demande exc\u00e9dentaire. Des processus plus sophistiqu\u00e9s ont \u00e9t\u00e9 introduits pour \u00e9tudier la stabilit\u00e9 des prix d\u2019\u00e9quilibre ou les informations n\u00e9cessaires \u00e0 leur calcul. Mais l\u00e0 encore, il n\u2019y a pas d\u2019agents fixant les prix ici. Dans la litt\u00e9rature financi\u00e8re, les travaux sur la microstructure du march\u00e9 font appel \u00e0 des agents de fixation des prix -LRB- sp\u00e9cialistes -RRB-, dont certaines parties d\u00e9terminent des prix acheteur et vendeur distincts, et diff\u00e9rents agents re\u00e7oivent des prix diff\u00e9rents pour le m\u00eame actif -LRB- voir -LSB - 12 -RSB- pour un traitement de la th\u00e9orie de la microstructure -RRB-. Les travaux en \u00e9conomie de l'information ont identifi\u00e9 des ph\u00e9nom\u00e8nes similaires -LRB- voir par exemple -LSB- 7 -RSB- -RRB-. Mais il existe peu de recherches dans ces ouvrages examinant l\u2019effet des restrictions sur qui peut commercer avec qui. Il existe plusieurs approches pour \u00e9tudier la mani\u00e8re dont la structure du r\u00e9seau d\u00e9termine les prix. Ceux-ci ont postul\u00e9 que la d\u00e9termination des prix se faisait au moyen de d\u00e9finitions fond\u00e9es sur l'\u00e9quilibre concurrentiel ou le noyau, ou au moyen de m\u00e9canismes v\u00e9ridiques. En passant bri\u00e8vement en revue ces travaux, nous remarquerons le contraste avec notre approche, dans la mesure o\u00f9 nous mod\u00e9lisons les prix comme d\u00e9coulant du comportement strat\u00e9gique des agents du syst\u00e8me. Dans des travaux r\u00e9cents, Kakade et al. -LSB- 8 -RSB- ont \u00e9tudi\u00e9 la distribution des prix \u00e0 l'\u00e9quilibre concurrentiel dans un graphe biparti sur les acheteurs et les vendeurs, g\u00e9n\u00e9r\u00e9 \u00e0 l'aide d'un mod\u00e8le probabiliste capable de produire des distributions de degr\u00e9s \u00e0 queues lourdes -LSB- 11 -RSB-. Even-Dar et al. -LSB- 6 -RSB- s'appuient sur cela pour consid\u00e9rer les aspects strat\u00e9giques de la formation du r\u00e9seau lorsque les prix d\u00e9coulent d'un \u00e9quilibre concurrentiel. Leonard \u00e9tudie les prix des VCG dans ce context ; Baba\u00efoff et coll. et Chu et Shen fournissent en outre un m\u00e9canisme d'\u00e9quilibre budg\u00e9taire. En revanche, notre mod\u00e8le a connu des valorisations et des prix d\u00e9coulant du comportement strat\u00e9gique des traders. Demange, Gale et Sotomayor -LSB-5-RSB-, et Kranton et Minehart -LSB-9-RSB-, analysent les prix auxquels les \u00e9changes ont lieu dans un r\u00e9seau, en travaillant dans le cadre de la conception de m\u00e9canismes. Kranton et Minehart utilisent un graphe bipartite avec des liens directs entre acheteurs et vendeurs, puis utilisent un m\u00e9canisme d'ench\u00e8res ascendantes, plut\u00f4t que des interm\u00e9diaires strat\u00e9giques, pour d\u00e9terminer les prix. Leurs ench\u00e8res ont des propri\u00e9t\u00e9s d'\u00e9quilibre souhaitables, mais comme le notent Kranton et Minehart, il s'agit d'une abstraction de la mani\u00e8re dont les biens sont r\u00e9partis et les prix sont d\u00e9termin\u00e9s, dont l'esprit est similaire \u00e0 celui du commissaire-priseur walrasien.mais tous les consommateurs ont acc\u00e8s \u00e0 toutes les entreprises et il n\u2019y a pas d\u2019interm\u00e9diaires. Dans la litt\u00e9rature sur l\u2019\u00e9quilibre g\u00e9n\u00e9ral, plusieurs tentatives ont \u00e9t\u00e9 faites pour introduire la d\u00e9termination des prix. Une technique standard de preuve de l\u2019existence d\u2019un \u00e9quilibre concurrentiel implique un m\u00e9canisme d\u2019ajustement des prix dans lequel les prix r\u00e9pondent \u00e0 une demande exc\u00e9dentaire. Des processus plus sophistiqu\u00e9s ont \u00e9t\u00e9 introduits pour \u00e9tudier la stabilit\u00e9 des prix d\u2019\u00e9quilibre ou les informations n\u00e9cessaires \u00e0 leur calcul. Mais l\u00e0 encore, il n\u2019y a pas d\u2019agents fixant les prix ici. Dans la litt\u00e9rature financi\u00e8re, les travaux sur la microstructure du march\u00e9 font appel \u00e0 des agents de fixation des prix -LRB- sp\u00e9cialistes -RRB-, dont certaines parties d\u00e9terminent des prix acheteur et vendeur distincts, et diff\u00e9rents agents re\u00e7oivent des prix diff\u00e9rents pour le m\u00eame actif -LRB- voir -LSB - 12 -RSB- pour un traitement de la th\u00e9orie de la microstructure -RRB-. Les travaux en \u00e9conomie de l'information ont identifi\u00e9 des ph\u00e9nom\u00e8nes similaires -LRB- voir par exemple -LSB- 7 -RSB- -RRB-. Mais il existe peu de recherches dans ces ouvrages examinant l\u2019effet des restrictions sur qui peut commercer avec qui. Il existe plusieurs approches pour \u00e9tudier la mani\u00e8re dont la structure du r\u00e9seau d\u00e9termine les prix. Ceux-ci ont postul\u00e9 que la d\u00e9termination des prix se faisait au moyen de d\u00e9finitions fond\u00e9es sur l'\u00e9quilibre concurrentiel ou le noyau, ou au moyen de m\u00e9canismes v\u00e9ridiques. En passant bri\u00e8vement en revue ces travaux, nous remarquerons le contraste avec notre approche, dans la mesure o\u00f9 nous mod\u00e9lisons les prix comme d\u00e9coulant du comportement strat\u00e9gique des agents du syst\u00e8me. Dans des travaux r\u00e9cents, Kakade et al. -LSB- 8 -RSB- ont \u00e9tudi\u00e9 la distribution des prix \u00e0 l'\u00e9quilibre concurrentiel dans un graphe biparti sur les acheteurs et les vendeurs, g\u00e9n\u00e9r\u00e9 \u00e0 l'aide d'un mod\u00e8le probabiliste capable de produire des distributions de degr\u00e9s \u00e0 queues lourdes -LSB- 11 -RSB-. Even-Dar et al. -LSB- 6 -RSB- s'appuient sur cela pour consid\u00e9rer les aspects strat\u00e9giques de la formation du r\u00e9seau lorsque les prix d\u00e9coulent d'un \u00e9quilibre concurrentiel. Leonard \u00e9tudie les prix des VCG dans ce context ; Baba\u00efoff et coll. et Chu et Shen fournissent en outre un m\u00e9canisme d'\u00e9quilibre budg\u00e9taire. En revanche, notre mod\u00e8le a connu des valorisations et des prix d\u00e9coulant du comportement strat\u00e9gique des traders. Demange, Gale et Sotomayor -LSB-5-RSB-, et Kranton et Minehart -LSB-9-RSB-, analysent les prix auxquels les \u00e9changes ont lieu dans un r\u00e9seau, en travaillant dans le cadre de la conception de m\u00e9canismes. Kranton et Minehart utilisent un graphe bipartite avec des liens directs entre acheteurs et vendeurs, puis utilisent un m\u00e9canisme d'ench\u00e8res ascendantes, plut\u00f4t que des interm\u00e9diaires strat\u00e9giques, pour d\u00e9terminer les prix. Leurs ench\u00e8res ont des propri\u00e9t\u00e9s d\u2019\u00e9quilibre souhaitables, mais comme le notent Kranton et Minehart, il s\u2019agit d\u2019une abstraction de la fa\u00e7on dont les biens sont r\u00e9partis et les prix sont d\u00e9termin\u00e9s, dont l\u2019esprit est similaire \u00e0 celui du commissaire-priseur walrasien.Des processus plus sophistiqu\u00e9s ont \u00e9t\u00e9 introduits pour \u00e9tudier la stabilit\u00e9 des prix d\u2019\u00e9quilibre ou les informations n\u00e9cessaires \u00e0 leur calcul. Mais l\u00e0 encore, il n\u2019y a pas d\u2019agents fixant les prix ici. Dans la litt\u00e9rature financi\u00e8re, les travaux sur la microstructure du march\u00e9 font appel \u00e0 des agents de fixation des prix -LRB- sp\u00e9cialistes -RRB-, dont certaines parties d\u00e9terminent des prix acheteur et vendeur distincts, et diff\u00e9rents agents re\u00e7oivent des prix diff\u00e9rents pour le m\u00eame actif -LRB- voir -LSB - 12 -RSB- pour un traitement de la th\u00e9orie de la microstructure -RRB-. Les travaux en \u00e9conomie de l'information ont identifi\u00e9 des ph\u00e9nom\u00e8nes similaires -LRB- voir par exemple -LSB- 7 -RSB- -RRB-. Mais il existe peu de recherches dans ces ouvrages examinant l\u2019effet des restrictions sur qui peut commercer avec qui. Il existe plusieurs approches pour \u00e9tudier la mani\u00e8re dont la structure du r\u00e9seau d\u00e9termine les prix. Ceux-ci ont postul\u00e9 que la d\u00e9termination des prix se faisait au moyen de d\u00e9finitions fond\u00e9es sur l'\u00e9quilibre concurrentiel ou le noyau, ou au moyen de m\u00e9canismes v\u00e9ridiques. En passant bri\u00e8vement en revue ces travaux, nous remarquerons le contraste avec notre approche, dans la mesure o\u00f9 nous mod\u00e9lisons les prix comme d\u00e9coulant du comportement strat\u00e9gique des agents du syst\u00e8me. Dans des travaux r\u00e9cents, Kakade et al. -LSB- 8 -RSB- ont \u00e9tudi\u00e9 la distribution des prix \u00e0 l'\u00e9quilibre concurrentiel dans un graphe biparti sur les acheteurs et les vendeurs, g\u00e9n\u00e9r\u00e9 \u00e0 l'aide d'un mod\u00e8le probabiliste capable de produire des distributions de degr\u00e9s \u00e0 queues lourdes -LSB- 11 -RSB-. Even-Dar et al. -LSB- 6 -RSB- s'appuient sur cela pour consid\u00e9rer les aspects strat\u00e9giques de la formation du r\u00e9seau lorsque les prix d\u00e9coulent d'un \u00e9quilibre concurrentiel. Leonard \u00e9tudie les prix des VCG dans ce context ; Baba\u00efoff et coll. et Chu et Shen fournissent en outre un m\u00e9canisme d'\u00e9quilibre budg\u00e9taire. En revanche, notre mod\u00e8le a connu des valorisations et des prix d\u00e9coulant du comportement strat\u00e9gique des traders. Demange, Gale et Sotomayor -LSB-5-RSB-, et Kranton et Minehart -LSB-9-RSB-, analysent les prix auxquels les \u00e9changes ont lieu dans un r\u00e9seau, en travaillant dans le cadre de la conception de m\u00e9canismes. Kranton et Minehart utilisent un graphe bipartite avec des liens directs entre acheteurs et vendeurs, puis utilisent un m\u00e9canisme d'ench\u00e8res ascendantes, plut\u00f4t que des interm\u00e9diaires strat\u00e9giques, pour d\u00e9terminer les prix. Leurs ench\u00e8res ont des propri\u00e9t\u00e9s d\u2019\u00e9quilibre souhaitables, mais comme le notent Kranton et Minehart, il s\u2019agit d\u2019une abstraction de la fa\u00e7on dont les biens sont r\u00e9partis et les prix sont d\u00e9termin\u00e9s, dont l\u2019esprit est similaire \u00e0 celui du commissaire-priseur walrasien.Des processus plus sophistiqu\u00e9s ont \u00e9t\u00e9 introduits pour \u00e9tudier la stabilit\u00e9 des prix d\u2019\u00e9quilibre ou les informations n\u00e9cessaires \u00e0 leur calcul. Mais l\u00e0 encore, il n\u2019y a pas d\u2019agents fixant les prix ici. Dans la litt\u00e9rature financi\u00e8re, les travaux sur la microstructure du march\u00e9 font appel \u00e0 des agents de fixation des prix -LRB- sp\u00e9cialistes -RRB-, dont certaines parties d\u00e9terminent des prix acheteur et vendeur distincts, et diff\u00e9rents agents re\u00e7oivent des prix diff\u00e9rents pour le m\u00eame actif -LRB- voir -LSB - 12 -RSB- pour un traitement de la th\u00e9orie de la microstructure -RRB-. Les travaux en \u00e9conomie de l'information ont identifi\u00e9 des ph\u00e9nom\u00e8nes similaires -LRB- voir par exemple -LSB- 7 -RSB- -RRB-. Mais il existe peu de recherches dans ces ouvrages examinant l\u2019effet des restrictions sur qui peut commercer avec qui. Il existe plusieurs approches pour \u00e9tudier la mani\u00e8re dont la structure du r\u00e9seau d\u00e9termine les prix. Ceux-ci ont postul\u00e9 que la d\u00e9termination des prix se faisait au moyen de d\u00e9finitions fond\u00e9es sur l'\u00e9quilibre concurrentiel ou le noyau, ou au moyen de m\u00e9canismes v\u00e9ridiques. En passant bri\u00e8vement en revue ces travaux, nous remarquerons le contraste avec notre approche, dans la mesure o\u00f9 nous mod\u00e9lisons les prix comme d\u00e9coulant du comportement strat\u00e9gique des agents du syst\u00e8me. Dans des travaux r\u00e9cents, Kakade et al. -LSB- 8 -RSB- ont \u00e9tudi\u00e9 la distribution des prix \u00e0 l'\u00e9quilibre concurrentiel dans un graphe biparti sur les acheteurs et les vendeurs, g\u00e9n\u00e9r\u00e9 \u00e0 l'aide d'un mod\u00e8le probabiliste capable de produire des distributions de degr\u00e9s \u00e0 queues lourdes -LSB- 11 -RSB-. Even-Dar et al. -LSB- 6 -RSB- s'appuient sur cela pour consid\u00e9rer les aspects strat\u00e9giques de la formation du r\u00e9seau lorsque les prix d\u00e9coulent d'un \u00e9quilibre concurrentiel. Leonard \u00e9tudie les prix des VCG dans ce context ; Baba\u00efoff et coll. et Chu et Shen fournissent en outre un m\u00e9canisme d'\u00e9quilibre budg\u00e9taire. En revanche, notre mod\u00e8le a connu des valorisations et des prix d\u00e9coulant du comportement strat\u00e9gique des traders. Demange, Gale et Sotomayor -LSB-5-RSB-, et Kranton et Minehart -LSB-9-RSB-, analysent les prix auxquels les \u00e9changes ont lieu dans un r\u00e9seau, en travaillant dans le cadre de la conception de m\u00e9canismes. Kranton et Minehart utilisent un graphe bipartite avec des liens directs entre acheteurs et vendeurs, puis utilisent un m\u00e9canisme d'ench\u00e8res ascendantes, plut\u00f4t que des interm\u00e9diaires strat\u00e9giques, pour d\u00e9terminer les prix. Leurs ench\u00e8res ont des propri\u00e9t\u00e9s d\u2019\u00e9quilibre souhaitables, mais comme le notent Kranton et Minehart, il s\u2019agit d\u2019une abstraction de la fa\u00e7on dont les biens sont r\u00e9partis et les prix sont d\u00e9termin\u00e9s, dont l\u2019esprit est similaire \u00e0 celui du commissaire-priseur walrasien.Mais il existe peu de recherches dans ces ouvrages examinant l\u2019effet des restrictions sur qui peut commercer avec qui. Il existe plusieurs approches pour \u00e9tudier la mani\u00e8re dont la structure du r\u00e9seau d\u00e9termine les prix. Ceux-ci ont postul\u00e9 que la d\u00e9termination des prix se faisait au moyen de d\u00e9finitions fond\u00e9es sur l'\u00e9quilibre concurrentiel ou le noyau, ou au moyen de m\u00e9canismes v\u00e9ridiques. En passant bri\u00e8vement en revue ces travaux, nous remarquerons le contraste avec notre approche, dans la mesure o\u00f9 nous mod\u00e9lisons les prix comme d\u00e9coulant du comportement strat\u00e9gique des agents du syst\u00e8me. Dans des travaux r\u00e9cents, Kakade et al. -LSB- 8 -RSB- ont \u00e9tudi\u00e9 la distribution des prix \u00e0 l'\u00e9quilibre concurrentiel dans un graphe biparti sur les acheteurs et les vendeurs, g\u00e9n\u00e9r\u00e9 \u00e0 l'aide d'un mod\u00e8le probabiliste capable de produire des distributions de degr\u00e9s \u00e0 queues lourdes -LSB- 11 -RSB-. Even-Dar et al. -LSB- 6 -RSB- s'appuient sur cela pour consid\u00e9rer les aspects strat\u00e9giques de la formation du r\u00e9seau lorsque les prix d\u00e9coulent d'un \u00e9quilibre concurrentiel. Leonard \u00e9tudie les prix des VCG dans ce context ; Baba\u00efoff et coll. et Chu et Shen fournissent en outre un m\u00e9canisme d'\u00e9quilibre budg\u00e9taire. En revanche, notre mod\u00e8le a connu des valorisations et des prix d\u00e9coulant du comportement strat\u00e9gique des traders. Demange, Gale et Sotomayor -LSB-5-RSB-, et Kranton et Minehart -LSB-9-RSB-, analysent les prix auxquels les \u00e9changes ont lieu dans un r\u00e9seau, en travaillant dans le cadre de la conception de m\u00e9canismes. Kranton et Minehart utilisent un graphe bipartite avec des liens directs entre acheteurs et vendeurs, puis utilisent un m\u00e9canisme d'ench\u00e8res ascendantes, plut\u00f4t que des interm\u00e9diaires strat\u00e9giques, pour d\u00e9terminer les prix. Leurs ench\u00e8res ont des propri\u00e9t\u00e9s d\u2019\u00e9quilibre souhaitables, mais comme le notent Kranton et Minehart, il s\u2019agit d\u2019une abstraction de la fa\u00e7on dont les biens sont r\u00e9partis et les prix sont d\u00e9termin\u00e9s, dont l\u2019esprit est similaire \u00e0 celui du commissaire-priseur walrasien.Mais il existe peu de recherches dans ces ouvrages examinant l\u2019effet des restrictions sur qui peut commercer avec qui. Il existe plusieurs approches pour \u00e9tudier la mani\u00e8re dont la structure du r\u00e9seau d\u00e9termine les prix. Ceux-ci ont postul\u00e9 que la d\u00e9termination des prix se faisait au moyen de d\u00e9finitions fond\u00e9es sur l'\u00e9quilibre concurrentiel ou le noyau, ou au moyen de m\u00e9canismes v\u00e9ridiques. En passant bri\u00e8vement en revue ces travaux, nous remarquerons le contraste avec notre approche, dans la mesure o\u00f9 nous mod\u00e9lisons les prix comme d\u00e9coulant du comportement strat\u00e9gique des agents du syst\u00e8me. Dans des travaux r\u00e9cents, Kakade et al. -LSB- 8 -RSB- ont \u00e9tudi\u00e9 la distribution des prix \u00e0 l'\u00e9quilibre concurrentiel dans un graphe biparti sur les acheteurs et les vendeurs, g\u00e9n\u00e9r\u00e9 \u00e0 l'aide d'un mod\u00e8le probabiliste capable de produire des distributions de degr\u00e9s \u00e0 queues lourdes -LSB- 11 -RSB-. Even-Dar et al. -LSB- 6 -RSB- s'appuient sur cela pour consid\u00e9rer les aspects strat\u00e9giques de la formation du r\u00e9seau lorsque les prix d\u00e9coulent d'un \u00e9quilibre concurrentiel. Leonard \u00e9tudie les prix des VCG dans ce context ; Baba\u00efoff et coll. et Chu et Shen fournissent en outre un m\u00e9canisme d'\u00e9quilibre budg\u00e9taire. En revanche, notre mod\u00e8le a connu des valorisations et des prix d\u00e9coulant du comportement strat\u00e9gique des traders. Demange, Gale et Sotomayor -LSB-5-RSB-, et Kranton et Minehart -LSB-9-RSB-, analysent les prix auxquels les \u00e9changes ont lieu dans un r\u00e9seau, en travaillant dans le cadre de la conception de m\u00e9canismes. Kranton et Minehart utilisent un graphe bipartite avec des liens directs entre acheteurs et vendeurs, puis utilisent un m\u00e9canisme d'ench\u00e8res ascendantes, plut\u00f4t que des interm\u00e9diaires strat\u00e9giques, pour d\u00e9terminer les prix. Leurs ench\u00e8res ont des propri\u00e9t\u00e9s d\u2019\u00e9quilibre souhaitables, mais comme le notent Kranton et Minehart, il s\u2019agit d\u2019une abstraction de la fa\u00e7on dont les biens sont r\u00e9partis et les prix sont d\u00e9termin\u00e9s, dont l\u2019esprit est similaire \u00e0 celui du commissaire-priseur walrasien.analyser les prix auxquels les \u00e9changes ont lieu dans un r\u00e9seau, en travaillant dans le cadre de la conception de m\u00e9canismes. Kranton et Minehart utilisent un graphe bipartite avec des liens directs entre acheteurs et vendeurs, puis utilisent un m\u00e9canisme d'ench\u00e8res ascendantes, plut\u00f4t que des interm\u00e9diaires strat\u00e9giques, pour d\u00e9terminer les prix. Leurs ench\u00e8res ont des propri\u00e9t\u00e9s d\u2019\u00e9quilibre souhaitables, mais comme le notent Kranton et Minehart, il s\u2019agit d\u2019une abstraction de la fa\u00e7on dont les biens sont r\u00e9partis et les prix sont d\u00e9termin\u00e9s, dont l\u2019esprit est similaire \u00e0 celui du commissaire-priseur walrasien.analyser les prix auxquels les \u00e9changes ont lieu dans un r\u00e9seau, en travaillant dans le cadre de la conception de m\u00e9canismes. Kranton et Minehart utilisent un graphe bipartite avec des liens directs entre acheteurs et vendeurs, puis utilisent un m\u00e9canisme d'ench\u00e8res ascendantes, plut\u00f4t que des interm\u00e9diaires strat\u00e9giques, pour d\u00e9terminer les prix. Leurs ench\u00e8res ont des propri\u00e9t\u00e9s d\u2019\u00e9quilibre souhaitables, mais comme le notent Kranton et Minehart, il s\u2019agit d\u2019une abstraction de la fa\u00e7on dont les biens sont r\u00e9partis et les prix sont d\u00e9termin\u00e9s, dont l\u2019esprit est similaire \u00e0 celui du commissaire-priseur walrasien.", "keyphrases": ["th\u00e9orie des jeux algorithmiques", "march\u00e9", "r\u00e9seau commercial", "interaction entre l'acheteur et le vendeur", "initier la dotation en argent", "prix de l'offre", "comp\u00e9tition parfaite", "avantage", "montant maximum et minimum", "\u00e9conomie et finance", "comportement strat\u00e9gique du commer\u00e7ant", "compl\u00e9mentarit\u00e9", "monopole"]}
{"file_name": "I-15", "text": "Recherche et partage d'informations dans des r\u00e9seaux dynamiques \u00e0 grande \u00e9chelle R\u00c9SUM\u00c9 Trouver les bons agents dans un r\u00e9seau vaste et dynamique pour fournir les ressources n\u00e9cessaires en temps opportun est un probl\u00e8me de longue date. Cet article pr\u00e9sente une m\u00e9thode de recherche et de partage d'informations qui combine des indices de routage avec des m\u00e9thodes bas\u00e9es sur des jetons. La m\u00e9thode propos\u00e9e permet aux agents d'effectuer des recherches efficaces en acqu\u00e9rant les int\u00e9r\u00eats de leurs voisins, en annon\u00e7ant leurs capacit\u00e9s de fourniture d'informations et en maintenant des indices pour le routage des requ\u00eates, de mani\u00e8re int\u00e9gr\u00e9e. Plus pr\u00e9cis\u00e9ment, l'article d\u00e9montre, \u00e0 travers des exp\u00e9riences de performance, comment des r\u00e9seaux d'agents statiques et dynamiques peuvent \u00eatre \u00ab r\u00e9gl\u00e9s \u00bb pour r\u00e9pondre efficacement aux requ\u00eates lorsqu'ils rassemblent des preuves des int\u00e9r\u00eats et des capacit\u00e9s de fourniture d'informations des autres, sans alt\u00e9rer la topologie ni imposer une structure superpos\u00e9e au r\u00e9seau. de connaissances. 1. INTRODUCTION r\u00e9seaux d'agents associ\u00e9s. D'autre part, il existe de nombreuses recherches sur les r\u00e9seaux de recherche s\u00e9mantiques peer to peer et les r\u00e9seaux sociaux -LSB- 1,5,6,8,9,10,16,18,19 -RSB- dont beaucoup traitent du r\u00e9glage un r\u00e9seau de pairs pour une recherche et un partage efficaces d\u2019informations. Ils le font principalement en imposant des structures de superposition logiques et s\u00e9mantiques. Cependant, \u00e0 notre connaissance, aucun travail ne d\u00e9montre l'efficacit\u00e9 d'un processus de r\u00e9glage progressif dans les r\u00e9seaux dynamiques \u00e0 grande \u00e9chelle qui \u00e9tudie l'impact des informations collect\u00e9es par les agents \u00e0 mesure que de plus en plus de requ\u00eates sont \u00e9mises et servies dans des sessions simultan\u00e9es dans le r\u00e9seau. r\u00e9seau. Le probl\u00e8me principal de cet article concerne le \u00ab r\u00e9glage \u00bb d'un r\u00e9seau d'agents, chacun poss\u00e9dant une expertise sp\u00e9cifique, pour une recherche et un partage d'informations efficaces et efficients, sans alt\u00e9rer la topologie ni imposer une structure superpos\u00e9e via le clustering, l'introduction d'indices de raccourci ou la re-structuration. c\u00e2blage. Le \u00ab Tuning \u00bb est la t\u00e2che de partager et de rassembler les connaissances n\u00e9cessaires pour que les agents puissent propager les demandes aux bonnes connaissances, en minimisant l'effort de recherche, en augmentant l'efficacit\u00e9 et les avantages du syst\u00e8me. Plus pr\u00e9cis\u00e9ment, cet article propose une m\u00e9thode de recherche et de partage d'informations dans des r\u00e9seaux dynamiques et \u00e0 grande \u00e9chelle, qui combine des indices de routage avec des m\u00e9thodes bas\u00e9es sur des jetons pour le partage d'informations dans des syst\u00e8mes multi-agents \u00e0 grande \u00e9chelle. Cet article est structur\u00e9 comme suit : La section 2 pr\u00e9sente les travaux connexes et motive la m\u00e9thode propos\u00e9e. La section 3 expose le probl\u00e8me et la section 4 pr\u00e9sente en d\u00e9tail les techniques individuelles et la m\u00e9thode globale propos\u00e9e. La section 5 pr\u00e9sente le dispositif exp\u00e9rimental et les r\u00e9sultats, et la section 6 conclut l'article en esquissant les travaux futurs. 2. TRAVAUX CONNEXES La fourniture et le partage d'informations peuvent \u00eatre consid\u00e9r\u00e9s comme un processus d\u00e9cisionnel de Markov d\u00e9centralis\u00e9 partiellement observable -LSB- 3,4,11,14 -RSB-. Dans le cas g\u00e9n\u00e9ral, le contr\u00f4le d\u00e9centralis\u00e9 des syst\u00e8mes dynamiques d\u2019agents coop\u00e9ratifs \u00e0 grande \u00e9chelle est un probl\u00e8me difficile. Les solutions optimales ne peuvent \u00eatre approch\u00e9es qu'au moyen d'heuristiques,par des assouplissements du probl\u00e8me initial ou par des solutions centralis\u00e9es. Cependant, dans un syst\u00e8me dynamique \u00e0 grande \u00e9chelle avec contr\u00f4le d\u00e9centralis\u00e9, il est tr\u00e8s difficile pour les agents de poss\u00e9der une vision partielle pr\u00e9cise de l\u2019environnement, et il est encore plus difficile pour les agents de poss\u00e9der une vision globale de l\u2019environnement. De plus, les observations des agents ne peuvent pas \u00eatre consid\u00e9r\u00e9es comme ind\u00e9pendantes, car les actions d'un agent peuvent affecter les observations des autres : par exemple, lorsqu'un agent rejoint/quitte le syst\u00e8me, cela peut alors affecter l'\u00e9valuation par d'autres agents des capacit\u00e9s de fourniture d'informations des voisins. . En consid\u00e9rant les activit\u00e9s et les observations ind\u00e9pendantes, les auteurs de -LSB-4-RSB- proposent une solution th\u00e9orique de la d\u00e9cision traitant l'action standard et l'\u00e9change d'informations comme des choix explicites que le d\u00e9cideur doit faire. Ils se rapprochent de la solution en utilisant un algorithme myope. Leur travail diff\u00e8re de celui rapport\u00e9 ici dans les aspects suivants : Premi\u00e8rement, il vise \u00e0 optimiser la communication, tandis que l'objectif ici est de r\u00e9gler le r\u00e9seau pour un partage efficace des informations, en r\u00e9duisant la communication et en augmentant les avantages du syst\u00e8me. Troisi\u00e8mement, ils consid\u00e8rent que les transitions et les observations effectu\u00e9es par les agents sont ind\u00e9pendantes, ce qui, comme d\u00e9j\u00e0 \u00e9voqu\u00e9, n'est pas vrai dans le cas g\u00e9n\u00e9ral. Enfin, contrairement \u00e0 leur approche o\u00f9 les agents diffusent des messages, les agents d\u00e9cident ici non seulement quand communiquer, mais \u00e9galement \u00e0 qui envoyer un message. Les approches bas\u00e9es sur des jetons sont prometteuses pour \u00e9tendre la coordination et donc la fourniture et le partage efficaces d'informations vers des syst\u00e8mes \u00e0 grande \u00e9chelle. Dans -LSB-11-RSB-, les auteurs fournissent un cadre math\u00e9matique pour le routage des jetons, fournissant \u00e9galement une approximation pour r\u00e9soudre le probl\u00e8me original dans le cas d'activit\u00e9s d'agents ind\u00e9pendants. La m\u00e9thode propos\u00e9e n\u00e9cessite un volume de calculs \u00e9lev\u00e9 que les auteurs visent \u00e0 r\u00e9duire en limitant son application \u00e0 des \u00e9quipes logiques statiques d'agents associ\u00e9s. Conform\u00e9ment \u00e0 cette approche, dans -LSB- 12,13,14 -RSB-, le partage d'informations est pris en compte uniquement pour les r\u00e9seaux statiques et l'auto-ajustement des r\u00e9seaux n'est pas d\u00e9montr\u00e9. Comme nous le montrerons dans la section 5, nos exp\u00e9riences montrent que bien que ces approches puissent g\u00e9rer le partage d'informations dans des r\u00e9seaux dynamiques, elles n\u00e9cessitent une plus grande quantit\u00e9 de messages par rapport \u00e0 l'approche propos\u00e9e ici et ne peuvent pas r\u00e9gler le r\u00e9seau pour un partage efficace d'informations. La communication proactive a \u00e9t\u00e9 propos\u00e9e dans -LSB- 17 -RSB- \u00e0 la suite d'une d\u00e9termination th\u00e9orique de la d\u00e9cision dynamique des strat\u00e9gies de communication. Cette approche est bas\u00e9e sur la sp\u00e9cification des agents comme \u00ab\u00a0fournisseurs\u00a0\u00bb et \u00ab\u00a0n\u00e9cessiteux\u00a0\u00bb\u00a0: ceci est r\u00e9alis\u00e9 par un pr\u00e9calcul bas\u00e9 sur un plan des besoins d'information et des capacit\u00e9s de fourniture des agents. Cependant, cette approche ne peut pas s\u2019adapter \u00e0 des r\u00e9seaux vastes et dynamiques, car il serait tr\u00e8s inefficace pour chaque agent de calculer et de d\u00e9terminer ses besoins potentiels et ses capacit\u00e9s de fourniture d\u2019informations \u00e9tant donn\u00e9 son interaction potentielle avec des centaines d\u2019autres agents.En regardant la r\u00e9cup\u00e9ration d'informations dans les syst\u00e8mes peer-to-peer du point de vue d'un syst\u00e8me multi-agents, l'approche propos\u00e9e dans -LSB-18-RSB- est bas\u00e9e sur un mod\u00e8le de langage de collection de documents d'agents. En exploitant les mod\u00e8les d'autres agents du r\u00e9seau, les agents construisent leur vision du r\u00e9seau qui est utilis\u00e9e pour prendre des d\u00e9cisions de routage. Dans un premier temps, les agents construisent leurs points de vue en utilisant les mod\u00e8les de leurs voisins. Ensuite, le syst\u00e8me se r\u00e9organise en formant des clusters d\u2019agents au contenu similaire. Les clusters sont exploit\u00e9s lors de la recherche d'informations en utilisant une approche kNN et un sch\u00e9ma de recherche par gradient. Bien que ce travail vise \u00e0 r\u00e9gler un r\u00e9seau pour une fourniture efficace d'informations -LRB- \u00e0 travers une r\u00e9organisation -RRB-, il ne d\u00e9montre pas l'efficacit\u00e9 de l'approche par rapport \u00e0 cette question. De plus, bien que lors de la r\u00e9organisation et de la r\u00e9cup\u00e9ration, ils mesurent la similarit\u00e9 du contenu entre les agents, une approche plus fine est n\u00e9cessaire pour permettre aux agents de mesurer les similitudes des \u00e9l\u00e9ments d'information ou des sous-collections d'\u00e9l\u00e9ments d'information. Sur la base de leurs travaux sur les syst\u00e8mes peer-to-peer, H.Zhand et V.Lesser dans -LSB-19-RSB- \u00e9tudient les sessions de recherche simultan\u00e9es. Compte tenu des recherches sur les syst\u00e8mes s\u00e9mantiques peer-to-peer1, la plupart des approches exploitent ce que l'on peut appeler vaguement un \u00ab indice de routage \u00bb. Une question majeure concernant la recherche d'informations est de savoir \u00ab\u00a0quelles informations doivent \u00eatre partag\u00e9es entre pairs, quand et quels ajustements doivent \u00eatre effectu\u00e9s pour que les requ\u00eates soient achemin\u00e9es vers des sources d'informations fiables de la mani\u00e8re la plus efficace et la plus efficiente\u00a0\u00bb. REMINDIN ' -LSB- 10 -RSB- les pairs collectent des informations concernant les requ\u00eates auxquelles d'autres pairs ont r\u00e9pondu avec succ\u00e8s, afin de s\u00e9lectionner ensuite les pairs auxquels transmettre les demandes\u00a0: Il s'agit d'une approche d'apprentissage paresseuse qui n'implique pas de publicit\u00e9 pour la fourniture d'informations par les pairs. capacit\u00e9s. Il en r\u00e9sulte un processus de r\u00e9glage dans lequel le rappel global augmente avec le temps, tandis que le nombre de messages par requ\u00eate reste \u00e0 peu pr\u00e8s le m\u00eame. Ici, les agents annoncent activement leurs capacit\u00e9s de fourniture d'informations en fonction des int\u00e9r\u00eats \u00e9valu\u00e9s de leurs pairs : cela se traduit par un nombre de messages par requ\u00eate bien inf\u00e9rieur \u00e0 ceux rapport\u00e9s dans REMINDIN '. Dans -LSB- 5,6 -RSB-, les pairs, utilisant une ontologie commune, annoncent leur expertise, qui est exploit\u00e9e pour la formation d'un r\u00e9seau de superposition s\u00e9mantique : les requ\u00eates se propagent dans ce r\u00e9seau en fonction de leur similarit\u00e9 avec l'expertise des pairs. Selon notre approche, les agents annoncent s\u00e9lectivement leurs capacit\u00e9s de fourniture d'informations sur des sujets sp\u00e9cifiques \u00e0 leurs voisins ayant des int\u00e9r\u00eats informationnels similaires -LRB- et uniquement \u00e0 ces derniers -RRB-. Cependant, cela se fait au fur et \u00e0 mesure que le temps passe et que les agents re\u00e7oivent des demandes de leurs pairs. Ils g\u00e9n\u00e8rent une surcharge substantielle dans des environnements hautement dynamiques, o\u00f9 les n\u0153uds rejoignent/quittent le syst\u00e8me. 248 La Sixi\u00e8me Internationale. Conf. conjointe.les agents annoncent leurs capacit\u00e9s \u00e0 fournir des informations compte tenu des int\u00e9r\u00eats de leurs voisins. Compte tenu du succ\u00e8s de cette m\u00e9thode, nous \u00e9tudierons comment l\u2019ajout de chemins logiques et l\u2019\u00e9volution progressive de la topologie du r\u00e9seau peuvent encore augmenter l\u2019efficacit\u00e9 de la m\u00e9thode propos\u00e9e. 6. CONCLUSIONS Cet article pr\u00e9sente une m\u00e9thode de traitement de requ\u00eates s\u00e9mantiques dans de grands r\u00e9seaux d'agents qui combine des indices de routage avec des m\u00e9thodes de partage d'informations. Le proc\u00e9d\u00e9 pr\u00e9sent\u00e9 permet aux agents de conserver des enregistrements des int\u00e9r\u00eats de leurs connaissances, d'annoncer leurs capacit\u00e9s de fourniture d'informations \u00e0 ceux qui s'int\u00e9ressent beaucoup \u00e0 eux, et de conserver des indices pour acheminer les requ\u00eates vers les agents qui poss\u00e8dent les capacit\u00e9s de fourniture d'informations demand\u00e9es. Plus pr\u00e9cis\u00e9ment, l'article d\u00e9montre \u00e0 travers des exp\u00e9riences de performances approfondies : -LRB- a -RRB- Comment les r\u00e9seaux d'agents peuvent \u00eatre \u00ab r\u00e9gl\u00e9s \u00bb de mani\u00e8re \u00e0 fournir efficacement les informations demand\u00e9es, augmentant ainsi le b\u00e9n\u00e9fice et l'efficacit\u00e9 du syst\u00e8me. -LRB- b -RRB- Comment diff\u00e9rents types de connaissances locales -LRB-, les r\u00e9f\u00e9rentiels d'informations locaux, le pourcentage, les int\u00e9r\u00eats et les capacit\u00e9s de fourniture d'informations des connaissances -RRB- peuvent guider les agents pour r\u00e9pondre efficacement aux requ\u00eates, en \u00e9quilibrant entre efficience et efficacit\u00e9. -LRB- c -RRB- Que la t\u00e2che de \u00ab r\u00e9glage \u00bb propos\u00e9e parvienne \u00e0 augmenter l'efficacit\u00e9 de la recherche et du partage d'informations dans des r\u00e9seaux tr\u00e8s dynamiques et \u00e9tendus. -LRB- d -RRB- Que les informations recueillies et conserv\u00e9es par les agents soutiennent la recherche et le partage efficaces et efficients d'informations\u00a0: les informations initiales sur les capacit\u00e9s de fourniture d'informations des connaissances ne sont pas n\u00e9cessaires et un petit pourcentage de connaissances suffit. D'autres travaux concernent l'exp\u00e9rimentation de donn\u00e9es et d'ontologies r\u00e9elles, les diff\u00e9rences d'ontologies entre les agents, les changements d'expertise et la construction parall\u00e8le de structures de superposition.Les int\u00e9r\u00eats et les capacit\u00e9s de fourniture d'informations des connaissances -RRB- peuvent guider les agents pour r\u00e9pondre efficacement aux requ\u00eates, en trouvant un \u00e9quilibre entre efficience et efficacit\u00e9. -LRB- c -RRB- Que la t\u00e2che de \u00ab r\u00e9glage \u00bb propos\u00e9e parvienne \u00e0 augmenter l'efficacit\u00e9 de la recherche et du partage d'informations dans des r\u00e9seaux tr\u00e8s dynamiques et \u00e9tendus. -LRB- d -RRB- Que les informations recueillies et conserv\u00e9es par les agents soutiennent la recherche et le partage efficaces et efficients d'informations\u00a0: les informations initiales sur les capacit\u00e9s de fourniture d'informations des connaissances ne sont pas n\u00e9cessaires et un petit pourcentage de connaissances suffit. D'autres travaux concernent l'exp\u00e9rimentation de donn\u00e9es et d'ontologies r\u00e9elles, les diff\u00e9rences d'ontologies entre les agents, les changements d'expertise et la construction parall\u00e8le de structures de superposition.Les int\u00e9r\u00eats et les capacit\u00e9s de fourniture d'informations des connaissances -RRB- peuvent guider les agents pour r\u00e9pondre efficacement aux requ\u00eates, en trouvant un \u00e9quilibre entre efficience et efficacit\u00e9. -LRB- c -RRB- Que la t\u00e2che de \u00ab r\u00e9glage \u00bb propos\u00e9e parvienne \u00e0 augmenter l'efficacit\u00e9 de la recherche et du partage d'informations dans des r\u00e9seaux tr\u00e8s dynamiques et \u00e9tendus. -LRB- d -RRB- Que les informations recueillies et conserv\u00e9es par les agents soutiennent la recherche et le partage efficaces et efficients d'informations\u00a0: les informations initiales sur les capacit\u00e9s de fourniture d'informations des connaissances ne sont pas n\u00e9cessaires et un petit pourcentage de connaissances suffit. D'autres travaux concernent l'exp\u00e9rimentation de donn\u00e9es et d'ontologies r\u00e9elles, les diff\u00e9rences d'ontologies entre les agents, les changements d'expertise et la construction parall\u00e8le de structures de superposition.", "keyphrases": ["informer la recherche et le partage", "r\u00e9seau social", "agent tonnelier", "r\u00e9seau de recherche peer to peer", "syst\u00e8me peer-to-peer", "r\u00e9seau dynamique et \u00e0 grande \u00e9chelle", "processus Markov Decis \u00e0 observation partielle d\u00e9centr", "contr\u00f4le d\u00e9centr\u00e9", "algorithme myope", "approche connue", "sch\u00e9ma de recherche de d\u00e9grad\u00e9"]}
{"file_name": "J-1", "text": "M\u00e9canismes g\u00e9n\u00e9ralis\u00e9s de r\u00e9duction des \u00e9changes R\u00c9SUM\u00c9 Lors de la conception d'un m\u00e9canisme, il existe plusieurs propri\u00e9t\u00e9s souhaitables \u00e0 maintenir, telles que la compatibilit\u00e9 des incitations -LRB- IC -RRB-, la rationalit\u00e9 individuelle -LRB- IR -RRB- et l'\u00e9quilibre budg\u00e9taire -LRB- BB -RRB-. Il est bien connu -LSB- 15 -RSB- qu'il est impossible pour un m\u00e9canisme de maximiser le bien-\u00eatre social tout en \u00e9tant \u00e0 la fois IR, IC et BB. Il y a eu plusieurs tentatives pour contourner -LSB-15-RSB- en \u00e9changeant le bien-\u00eatre contre BB, par exemple dans des domaines tels que les ench\u00e8res double face -LSB-13-RSB-, les march\u00e9s distribu\u00e9s -LSB-3-RSB- et la cha\u00eene d'approvisionnement. probl\u00e8mes -LSB- 2, 4 -RSB-. Dans cet article, nous proposons une proc\u00e9dure appel\u00e9e r\u00e9duction commerciale g\u00e9n\u00e9ralis\u00e9e -LRB-GTR-RRB- pour les acteurs \u00e0 valeur unique, qui, \u00e9tant donn\u00e9 un m\u00e9canisme IR et IC, produit un m\u00e9canisme IR, IC et BB avec une perte de bien-\u00eatre. Nous avons limit\u00e9 le bien-\u00eatre obtenu par notre proc\u00e9dure \u00e0 un large \u00e9ventail de domaines. En particulier, nos r\u00e9sultats am\u00e9liorent les solutions existantes \u00e0 des probl\u00e8mes tels que les march\u00e9s double face avec des biens homog\u00e8nes, les march\u00e9s distribu\u00e9s et plusieurs types de cha\u00eenes d'approvisionnement. De plus, notre solution fournit des m\u00e9canismes d\u2019\u00e9quilibre budg\u00e9taire pour plusieurs probl\u00e8mes ouverts tels que les ench\u00e8res combinatoires double face et les march\u00e9s distribu\u00e9s avec des avantages strat\u00e9giques en mati\u00e8re de transport. 1. INTRODUCTION Lors de la conception d'un m\u00e9canisme, il est souhaitable de conserver plusieurs propri\u00e9t\u00e9s cl\u00e9s. Dans de nombreux m\u00e9canismes, la fonction objectif qu'un concepteur de m\u00e9canisme tente de maximiser est le bien-\u00eatre social, c'est-\u00e0-dire le b\u00e9n\u00e9fice total pour la soci\u00e9t\u00e9. Cependant, il est bien connu d'apr\u00e8s -LSB-15-RSB- que tout m\u00e9canisme qui maximise le bien-\u00eatre social tout en maintenant la rationalit\u00e9 individuelle et la compatibilit\u00e9 des incitations est forc\u00e9ment d\u00e9ficitaire, c'est-\u00e0-dire qu'il n'est pas en \u00e9quilibre budg\u00e9taire. Pour maintenir la propri\u00e9t\u00e9 BB dans un m\u00e9canisme IR et IC, il est n\u00e9cessaire de faire des compromis sur l\u2019optimalit\u00e9 du bien-\u00eatre social. 1.1 Travaux connexes et solutions sp\u00e9cifiques Il y a eu plusieurs tentatives pour concevoir des m\u00e9canismes d'\u00e9quilibre budg\u00e9taire pour des domaines particuliers2. Dans le probl\u00e8me des march\u00e9s distribu\u00e9s -LRB- et les probl\u00e8mes \u00e9troitement li\u00e9s -RRB- les marchandises sont transport\u00e9es entre des emplacements g\u00e9ographiques tout en supportant un co\u00fbt de transport constant. -LSB- 16, 9, 3 -RSB- pr\u00e9sentent des m\u00e9canismes qui se rapprochent du bien-\u00eatre social tout en r\u00e9alisant un m\u00e9canisme IR, IC et BB. Pour les probl\u00e8mes de cha\u00eene d'approvisionnement -LSB- 2, 4 -RSB- limite la perte de bien-\u00eatre social qu'il est n\u00e9cessaire d'infliger au m\u00e9canisme afin d'obtenir la combinaison souhait\u00e9e d'IR, IC et BB. Malgr\u00e9 les travaux discut\u00e9s ci-dessus, la question de savoir comment concevoir un m\u00e9canisme g\u00e9n\u00e9ral permettant d\u2019atteindre IR, IC et BB ind\u00e9pendamment du domaine du probl\u00e8me reste ouverte. En outre, il existe plusieurs domaines dans lesquels la question de savoir comment concevoir un m\u00e9canisme IR, IC et BB qui se rapproche du bien-\u00eatre social reste un probl\u00e8me ouvert. Par exemple,Dans le domaine important des ench\u00e8res combinatoires bilat\u00e9rales, il n\u2019existe aucun r\u00e9sultat connu qui limite la perte de protection sociale n\u00e9cessaire pour atteindre l\u2019\u00e9quilibre budg\u00e9taire. Un autre exemple int\u00e9ressant est la question ouverte laiss\u00e9e par -LSB- 3 -RSB-\u00a0: comment limiter la perte de protection sociale n\u00e9cessaire pour atteindre l'\u00e9quilibre budg\u00e9taire dans un march\u00e9 distribu\u00e9 IR et IC o\u00f9 les limites du transport sont strat\u00e9giques. Naturellement, une r\u00e9ponse au march\u00e9 distribu\u00e9 BB avec des avantages strat\u00e9giques a de vastes implications pratiques, par exemple pour les r\u00e9seaux de transport. 1.2 Notre contribution Dans cet article, nous unifions tous les probl\u00e8mes discut\u00e9s ci-dessus -LRB-, tant les probl\u00e8mes r\u00e9solus que les probl\u00e8mes ouverts -RRB- en une seule proc\u00e9dure de concept de solution. La proc\u00e9dure de solution appel\u00e9e R\u00e9duction G\u00e9n\u00e9ralis\u00e9e des Echanges -LRB-GTR-RRB-. GTR accepte un m\u00e9canisme IR et IC pour les joueurs \u00e0 valeur unique et g\u00e9n\u00e8re un m\u00e9canisme IR, IC et BB. Le m\u00e9canisme de production peut subir une certaine perte de bien-\u00eatre en \u00e9change de l\u2019atteinte du BB. Il existe des cas probl\u00e9matiques dans lesquels aucune perte de bien-\u00eatre n'est n\u00e9cessaire, mais d'apr\u00e8s -LSB- 15 -RSB-, il existe des cas probl\u00e9matiques dans lesquels il y a une perte de bien-\u00eatre. N\u00e9anmoins, pour un large \u00e9ventail de probl\u00e8mes, nous sommes capables de limiter la perte de bien-\u00eatre. Un cas particuli\u00e8rement int\u00e9ressant est celui dans lequel le m\u00e9canisme d\u2019entr\u00e9e est une allocation efficace. En plus d'unifier de nombreux probl\u00e8mes BB sous un concept de solution unique, la proc\u00e9dure GTR am\u00e9liore les r\u00e9sultats existants et r\u00e9sout plusieurs probl\u00e8mes ouverts dans la litt\u00e9rature. Les solutions existantes am\u00e9lior\u00e9es par notre proc\u00e9dure GTR sont les ench\u00e8res double face homog\u00e8nes, les march\u00e9s distribu\u00e9s -LSB- 3 -RSB- et la cha\u00eene d'approvisionnement -LSB- 2, 4 -RSB-. Pour les ench\u00e8res double face homog\u00e8nes, la proc\u00e9dure de solution GTR am\u00e9liore la solution bien connue -LSB-13-RSB- en permettant dans certains cas une absence de r\u00e9duction des \u00e9changes. Pour les march\u00e9s distribu\u00e9s -LSB- 3 -RSB- et la cha\u00eene d'approvisionnement -LSB- 2, 4 -RSB-, la proc\u00e9dure de solution GTR am\u00e9liore les pertes de bien-\u00eatre li\u00e9es, c'est-\u00e0-dire permet d'obtenir un m\u00e9canisme IR, IC et BB avec une perte moindre sur le bien-\u00eatre social. R\u00e9cemment, nous avons \u00e9galement appris que la proc\u00e9dure GTR permet de transformer le mod\u00e8le nouvellement pr\u00e9sent\u00e9 -LSB-6-RSB- en un m\u00e9canisme BB. En plus de la contribution principale d\u00e9crite ci-dessus, cet article d\u00e9finit \u00e9galement une classification importante des domaines probl\u00e9matiques. Nous d\u00e9finissons des domaines bas\u00e9s sur les classes et les domaines bas\u00e9s sur les classes d'approvisionnement. Les d\u00e9finitions ci-dessus s'appuient sur les diff\u00e9rents \u00ab\u00a0pouvoirs\u00a0\u00bb de concurrence des acteurs dans un m\u00e9canisme appel\u00e9 concurrence interne et externe.2 Notre contribution Dans cet article, nous unifions tous les probl\u00e8mes discut\u00e9s ci-dessus -LRB-, tant les probl\u00e8mes r\u00e9solus que les probl\u00e8mes ouverts -RRB- en une seule proc\u00e9dure de concept de solution. La proc\u00e9dure de solution appel\u00e9e R\u00e9duction G\u00e9n\u00e9ralis\u00e9e des Echanges -LRB-GTR-RRB-. GTR accepte un m\u00e9canisme IR et IC pour les joueurs \u00e0 valeur unique et g\u00e9n\u00e8re un m\u00e9canisme IR, IC et BB. Le m\u00e9canisme de production peut subir une certaine perte de bien-\u00eatre en \u00e9change de l\u2019atteinte du BB. Il existe des cas probl\u00e9matiques dans lesquels aucune perte de bien-\u00eatre n'est n\u00e9cessaire, mais d'apr\u00e8s -LSB- 15 -RSB-, il existe des cas probl\u00e9matiques dans lesquels il y a une perte de bien-\u00eatre. N\u00e9anmoins, pour un large \u00e9ventail de probl\u00e8mes, nous sommes capables de limiter la perte de bien-\u00eatre. Un cas particuli\u00e8rement int\u00e9ressant est celui dans lequel le m\u00e9canisme d\u2019entr\u00e9e est une allocation efficace. En plus d'unifier de nombreux probl\u00e8mes BB sous un concept de solution unique, la proc\u00e9dure GTR am\u00e9liore les r\u00e9sultats existants et r\u00e9sout plusieurs probl\u00e8mes ouverts dans la litt\u00e9rature. Les solutions existantes am\u00e9lior\u00e9es par notre proc\u00e9dure GTR sont les ench\u00e8res double face homog\u00e8nes, les march\u00e9s distribu\u00e9s -LSB- 3 -RSB- et la cha\u00eene d'approvisionnement -LSB- 2, 4 -RSB-. Pour les ench\u00e8res double face homog\u00e8nes, la proc\u00e9dure de solution GTR am\u00e9liore la solution bien connue -LSB-13-RSB- en permettant dans certains cas une absence de r\u00e9duction des \u00e9changes. Pour les march\u00e9s distribu\u00e9s -LSB- 3 -RSB- et la cha\u00eene d'approvisionnement -LSB- 2, 4 -RSB-, la proc\u00e9dure de solution GTR am\u00e9liore les pertes de bien-\u00eatre li\u00e9es, c'est-\u00e0-dire permet d'obtenir un m\u00e9canisme IR, IC et BB avec une perte moindre sur le bien-\u00eatre social. R\u00e9cemment, nous avons \u00e9galement appris que la proc\u00e9dure GTR permet de transformer le mod\u00e8le nouvellement pr\u00e9sent\u00e9 -LSB-6-RSB- en un m\u00e9canisme BB. En plus de la contribution principale d\u00e9crite ci-dessus, cet article d\u00e9finit \u00e9galement une classification importante des domaines probl\u00e9matiques. Nous d\u00e9finissons des domaines bas\u00e9s sur les classes et les domaines bas\u00e9s sur les classes d'approvisionnement. Les d\u00e9finitions ci-dessus s'appuient sur les diff\u00e9rents \u00ab\u00a0pouvoirs\u00a0\u00bb de concurrence des acteurs dans un m\u00e9canisme appel\u00e9 concurrence interne et externe.2 Notre contribution Dans cet article, nous unifions tous les probl\u00e8mes discut\u00e9s ci-dessus -LRB-, tant les probl\u00e8mes r\u00e9solus que les probl\u00e8mes ouverts -RRB- en une seule proc\u00e9dure de concept de solution. La proc\u00e9dure de solution appel\u00e9e R\u00e9duction G\u00e9n\u00e9ralis\u00e9e des Echanges -LRB-GTR-RRB-. GTR accepte un m\u00e9canisme IR et IC pour les joueurs \u00e0 valeur unique et g\u00e9n\u00e8re un m\u00e9canisme IR, IC et BB. Le m\u00e9canisme de production peut subir une certaine perte de bien-\u00eatre en \u00e9change de l\u2019atteinte du BB. Il existe des cas probl\u00e9matiques dans lesquels aucune perte de bien-\u00eatre n'est n\u00e9cessaire, mais d'apr\u00e8s -LSB- 15 -RSB-, il existe des cas probl\u00e9matiques dans lesquels il y a une perte de bien-\u00eatre. N\u00e9anmoins, pour un large \u00e9ventail de probl\u00e8mes, nous sommes capables de limiter la perte de bien-\u00eatre. Un cas particuli\u00e8rement int\u00e9ressant est celui dans lequel le m\u00e9canisme d\u2019entr\u00e9e est une allocation efficace. En plus d'unifier de nombreux probl\u00e8mes BB sous un concept de solution unique, la proc\u00e9dure GTR am\u00e9liore les r\u00e9sultats existants et r\u00e9sout plusieurs probl\u00e8mes ouverts dans la litt\u00e9rature. Les solutions existantes am\u00e9lior\u00e9es par notre proc\u00e9dure GTR sont les ench\u00e8res double face homog\u00e8nes, les march\u00e9s distribu\u00e9s -LSB- 3 -RSB- et la cha\u00eene d'approvisionnement -LSB- 2, 4 -RSB-. Pour les ench\u00e8res double face homog\u00e8nes, la proc\u00e9dure de solution GTR am\u00e9liore la solution bien connue -LSB-13-RSB- en permettant dans certains cas une absence de r\u00e9duction des \u00e9changes. Pour les march\u00e9s distribu\u00e9s -LSB- 3 -RSB- et la cha\u00eene d'approvisionnement -LSB- 2, 4 -RSB-, la proc\u00e9dure de solution GTR am\u00e9liore les pertes de bien-\u00eatre li\u00e9es, c'est-\u00e0-dire permet d'obtenir un m\u00e9canisme IR, IC et BB avec une perte moindre sur le bien-\u00eatre social. R\u00e9cemment, nous avons \u00e9galement appris que la proc\u00e9dure GTR permet de transformer le mod\u00e8le nouvellement pr\u00e9sent\u00e9 -LSB-6-RSB- en un m\u00e9canisme BB. En plus de la contribution principale d\u00e9crite ci-dessus, cet article d\u00e9finit \u00e9galement une classification importante des domaines probl\u00e9matiques. Nous d\u00e9finissons des domaines bas\u00e9s sur les classes et les domaines bas\u00e9s sur les classes d'approvisionnement. Les d\u00e9finitions ci-dessus s'appuient sur les diff\u00e9rents \u00ab\u00a0pouvoirs\u00a0\u00bb de concurrence des acteurs dans un m\u00e9canisme appel\u00e9 concurrence interne et externe.Pour les ench\u00e8res double face homog\u00e8nes, la proc\u00e9dure de solution GTR am\u00e9liore la solution bien connue -LSB-13-RSB- en permettant dans certains cas une absence de r\u00e9duction des \u00e9changes. Pour les march\u00e9s distribu\u00e9s -LSB- 3 -RSB- et la cha\u00eene d'approvisionnement -LSB- 2, 4 -RSB-, la proc\u00e9dure de solution GTR am\u00e9liore les pertes de bien-\u00eatre li\u00e9es, c'est-\u00e0-dire permet d'obtenir un m\u00e9canisme IR, IC et BB avec une perte moindre sur le bien-\u00eatre social. R\u00e9cemment, nous avons \u00e9galement appris que la proc\u00e9dure GTR permet de transformer le mod\u00e8le nouvellement pr\u00e9sent\u00e9 -LSB-6-RSB- en un m\u00e9canisme BB. En plus de la contribution principale d\u00e9crite ci-dessus, cet article d\u00e9finit \u00e9galement une classification importante des domaines probl\u00e9matiques. Nous d\u00e9finissons des domaines bas\u00e9s sur les classes et les domaines bas\u00e9s sur les classes d'approvisionnement. Les d\u00e9finitions ci-dessus s'appuient sur les diff\u00e9rents \u00ab\u00a0pouvoirs\u00a0\u00bb de concurrence des acteurs dans un m\u00e9canisme appel\u00e9 concurrence interne et externe.Pour les ench\u00e8res double face homog\u00e8nes, la proc\u00e9dure de solution GTR am\u00e9liore la solution bien connue -LSB-13-RSB- en permettant dans certains cas une absence de r\u00e9duction des \u00e9changes. Pour les march\u00e9s distribu\u00e9s -LSB- 3 -RSB- et la cha\u00eene d'approvisionnement -LSB- 2, 4 -RSB-, la proc\u00e9dure de solution GTR am\u00e9liore les pertes de bien-\u00eatre li\u00e9es, c'est-\u00e0-dire permet d'obtenir un m\u00e9canisme IR, IC et BB avec une perte moindre sur le bien-\u00eatre social. R\u00e9cemment, nous avons \u00e9galement appris que la proc\u00e9dure GTR permet de transformer le mod\u00e8le nouvellement pr\u00e9sent\u00e9 -LSB-6-RSB- en un m\u00e9canisme BB. En plus de la contribution principale d\u00e9crite ci-dessus, cet article d\u00e9finit \u00e9galement une classification importante des domaines probl\u00e9matiques. Nous d\u00e9finissons des domaines bas\u00e9s sur les classes et les domaines bas\u00e9s sur les classes d'approvisionnement. Les d\u00e9finitions ci-dessus s'appuient sur les diff\u00e9rents \u00ab\u00a0pouvoirs\u00a0\u00bb de concurrence des acteurs dans un m\u00e9canisme appel\u00e9 concurrence interne et externe.", "keyphrases": ["r\u00e9duction du commerce", "solde budg\u00e9taire", "stagiaire en comp\u00e9tition", "comp\u00e9tition externe", "efficace", "pouvoir du joueur", "r\u00e9duction du commerce g\u00e9n\u00e9ral", "RTM", "optimal", "in\u00e9galit\u00e9 en mati\u00e8re de protection sociale", "joueur multi-esprit", "m\u00e9canisme d'\u00e9quilibre budg\u00e9taire", "homog\u00e8ne bon", "march\u00e9 de distribution spatiale"]}
{"file_name": "H-24", "text": "Enqu\u00eate sur le comportement d'interrogation et de navigation des utilisateurs de moteurs de recherche avanc\u00e9s R\u00c9SUM\u00c9 Une fa\u00e7on d'aider tous les utilisateurs de moteurs de recherche Web commerciaux \u00e0 mieux r\u00e9ussir leurs recherches est de mieux comprendre ce que font les utilisateurs ayant une plus grande expertise en recherche et d'utiliser ces connaissances au profit de tous. . Dans cet article, nous \u00e9tudions les journaux d'interaction des utilisateurs des moteurs de recherche avanc\u00e9s -LRB- et de ceux moins avanc\u00e9s -RRB- pour mieux comprendre comment ces groupes d'utilisateurs effectuent leurs recherches. Les r\u00e9sultats montrent qu'il existe des diff\u00e9rences marqu\u00e9es dans les requ\u00eates, les clics sur les r\u00e9sultats, la navigation post-requ\u00eate et le succ\u00e8s de recherche des utilisateurs que nous classons comme avanc\u00e9s -LRB- en fonction de leur utilisation des op\u00e9rateurs de requ\u00eate -RRB-, par rapport \u00e0 ceux class\u00e9s comme non-. avanc\u00e9. Nos r\u00e9sultats ont des implications sur la mani\u00e8re dont les utilisateurs avanc\u00e9s devraient \u00eatre soutenus lors de leurs recherches et sur la mani\u00e8re dont leurs interactions pourraient \u00eatre utilis\u00e9es pour aider les chercheurs de tous niveaux d'exp\u00e9rience \u00e0 trouver des informations plus pertinentes et \u00e0 apprendre des strat\u00e9gies de recherche am\u00e9lior\u00e9es. 1. INTRODUCTION La formulation d'instructions de requ\u00eate qui capturent \u00e0 la fois les aspects saillants des besoins d'information et qui sont significatives pour les syst\u00e8mes de recherche d'informations -LRB- IR -RRB- pose un d\u00e9fi pour de nombreux chercheurs -LSB- 3 -RSB-. Ces techniques peuvent \u00eatre utiles pour am\u00e9liorer la pr\u00e9cision des r\u00e9sultats, mais, autrement que via des analyses de logs -LRB- par exemple, -LSB- 15 -RSB- -LSB- 27 -RSB- -RRB-, elles ont g\u00e9n\u00e9ralement \u00e9t\u00e9 n\u00e9glig\u00e9es par la communaut\u00e9 des chercheurs dans leurs tentatives. pour am\u00e9liorer la qualit\u00e9 des r\u00e9sultats de recherche. La recherche en RI s'est g\u00e9n\u00e9ralement concentr\u00e9e sur des moyens alternatifs permettant aux utilisateurs de sp\u00e9cifier leurs besoins plut\u00f4t que d'accro\u00eetre l'adoption d'une syntaxe avanc\u00e9e. La recherche sur les techniques pratiques visant \u00e0 compl\u00e9ter la technologie de recherche existante et \u00e0 aider les utilisateurs s'est intensifi\u00e9e ces derni\u00e8res ann\u00e9es -LRB- par exemple -LSB- 18 -RSB- -LSB- 34 -RSB- -RRB-. Cependant, il est difficile de mettre en \u0153uvre de telles techniques \u00e0 grande \u00e9chelle avec des latences tol\u00e9rables. Les requ\u00eates typiques soumises aux moteurs de recherche Web prennent la forme d'une s\u00e9rie de jetons s\u00e9par\u00e9s par des espaces. Il existe g\u00e9n\u00e9ralement un op\u00e9rateur bool\u00e9en ET implicite entre les jetons qui restreint les r\u00e9sultats de recherche aux documents contenant tous les termes de la requ\u00eate. De Lima et Pedersen -LSB-7-RSB- ont \u00e9tudi\u00e9 l'effet de l'analyse syntaxique, de la reconnaissance de phrases et de l'expansion sur les requ\u00eates de recherche sur le Web. Ils ont montr\u00e9 que la reconnaissance automatique des expressions dans les requ\u00eates peut am\u00e9liorer la pr\u00e9cision des r\u00e9sultats de recherche sur le Web. Cependant, la valeur de la syntaxe avanc\u00e9e pour les chercheurs typiques a g\u00e9n\u00e9ralement \u00e9t\u00e9 limit\u00e9e, car la plupart des utilisateurs ne connaissent pas la syntaxe avanc\u00e9e ou ne comprennent pas comment l'utiliser -LSB- 15 -RSB-. Dans cet article, nous explorons l'utilisation des op\u00e9rateurs de requ\u00eate plus en d\u00e9tail et proposons des applications alternatives qui n'exigent pas que tous les utilisateurs utilisent explicitement une syntaxe avanc\u00e9e. Nous \u00e9mettons l'hypoth\u00e8se que les chercheurs qui utilisent une syntaxe de requ\u00eate avanc\u00e9e d\u00e9montrent un degr\u00e9 d'expertise en recherche que la majorit\u00e9 de la population d'utilisateurs ne poss\u00e8de pas ; une affirmation \u00e9tay\u00e9e par des recherches ant\u00e9rieures -LSB- 13 -RSB-.L'\u00e9tude du comportement de ces utilisateurs de moteurs de recherche avanc\u00e9s peut fournir des informations importantes sur la recherche et la navigation dans les r\u00e9sultats dont d'autres pourraient b\u00e9n\u00e9ficier. \u00c0 l\u2019aide des journaux collect\u00e9s aupr\u00e8s d\u2019un grand nombre d\u2019utilisateurs consentants, nous \u00e9tudions les diff\u00e9rences entre le comportement de recherche de ceux qui utilisent une syntaxe avanc\u00e9e et ceux qui ne l\u2019utilisent pas, ainsi que les diff\u00e9rences dans les informations cibl\u00e9es par ces utilisateurs. Nous souhaitons r\u00e9pondre \u00e0 trois questions de recherche : -LRB- i -RRB- Existe-t-il une relation entre l'utilisation d'une syntaxe avanc\u00e9e et d'autres caract\u00e9ristiques d'une recherche ? -LRB- ii -RRB- Existe-t-il une relation entre l'utilisation d'une syntaxe avanc\u00e9e et les comportements de navigation post-requ\u00eate ? -LRB- iii -RRB- Existe-t-il une relation entre l'utilisation d'une syntaxe avanc\u00e9e et les mesures du succ\u00e8s de la recherche\u00a0? Gr\u00e2ce \u00e0 une \u00e9tude et une analyse exp\u00e9rimentales, nous proposons des r\u00e9ponses potentielles \u00e0 chacune de ces questions. Une relation entre l'utilisation d'une syntaxe avanc\u00e9e et l'une de ces fonctionnalit\u00e9s pourrait prendre en charge la conception de syst\u00e8mes adapt\u00e9s aux utilisateurs avanc\u00e9s des moteurs de recherche, ou utiliser les interactions des utilisateurs avanc\u00e9s pour aider les utilisateurs non avanc\u00e9s \u00e0 mieux r\u00e9ussir leurs recherches. Nous d\u00e9crivons les travaux connexes dans la section 2, les donn\u00e9es que nous avons utilis\u00e9es dans cette \u00e9tude bas\u00e9e sur les logs dans la section 3, les caract\u00e9ristiques de recherche sur lesquelles nous concentrons notre analyse dans la section 4 et les r\u00e9sultats de cette analyse dans la section 5. 2. TRAVAUX CONNEXES Facteurs tels qu'un manque de connaissances du domaine, une mauvaise compr\u00e9hension de la collection de documents recherch\u00e9e et un besoin d'information peu d\u00e9velopp\u00e9 peuvent tous influencer la qualit\u00e9 des requ\u00eates que les utilisateurs soumettent aux syst\u00e8mes IR -LRB- -LSB- 24 -RSB-, -LSB- 28 -RSB- -RRB-. De nombreuses recherches ont \u00e9t\u00e9 men\u00e9es sur diff\u00e9rentes mani\u00e8res d'aider les utilisateurs \u00e0 pr\u00e9ciser plus efficacement leurs besoins en informations. Belkin et coll. -LSB- 4 -RSB- a exp\u00e9riment\u00e9 en fournissant un espace suppl\u00e9mentaire permettant aux utilisateurs de saisir une description plus d\u00e9taill\u00e9e de leurs besoins en informations. Une approche similaire a \u00e9t\u00e9 tent\u00e9e par Kelly et al. -LSB- 18 -RSB-, qui a utilis\u00e9 des formulaires de clarification pour obtenir des informations suppl\u00e9mentaires sur le context de recherche aupr\u00e8s des utilisateurs. Ces approches se sont r\u00e9v\u00e9l\u00e9es efficaces dans les syst\u00e8mes de r\u00e9cup\u00e9ration de meilleures correspondances o\u00f9 des requ\u00eates plus longues conduisent g\u00e9n\u00e9ralement \u00e0 des r\u00e9sultats de recherche plus pertinents -LSB- 4 -RSB-. Cependant, dans la recherche Web, o\u00f9 de nombreux syst\u00e8mes sont bas\u00e9s sur un mod\u00e8le de r\u00e9cup\u00e9ration bool\u00e9en \u00e9tendu, des requ\u00eates plus longues peuvent en r\u00e9alit\u00e9 nuire aux performances de r\u00e9cup\u00e9ration, conduisant \u00e0 la r\u00e9cup\u00e9ration d'un petit nombre de r\u00e9sultats potentiellement non pertinents. Il ne suffit pas simplement de demander davantage d'informations aux utilisateurs ; cette information doit \u00eatre de meilleure qualit\u00e9. Le retour de pertinence -LRB- RF -RRB- -LSB- 22 -RSB- et l'expansion de requ\u00eates interactives -LSB- 9 -RSB- sont des techniques populaires qui ont \u00e9t\u00e9 utilis\u00e9es pour am\u00e9liorer la qualit\u00e9 des informations que les utilisateurs fournissent aux syst\u00e8mes IR concernant leurs besoins d'information. . Dans le cas de RF, l'utilisateur pr\u00e9sente au syst\u00e8me des exemples d'informations pertinentes qui sont ensuite utilis\u00e9es pour formuler une requ\u00eate am\u00e9lior\u00e9e ou r\u00e9cup\u00e9rer un nouvel ensemble de documents.Il s'est av\u00e9r\u00e9 difficile d'amener les utilisateurs \u00e0 utiliser la RF dans le domaine Web en raison de la difficult\u00e9 \u00e0 transmettre la signification et les avantages de la RF aux utilisateurs typiques -LSB- 17 -RSB-. Les suggestions de requ\u00eates propos\u00e9es sur la base des journaux de requ\u00eates ont le potentiel d\u2019am\u00e9liorer les performances de r\u00e9cup\u00e9ration avec une charge utilisateur limit\u00e9e. Cette approche se limite \u00e0 r\u00e9ex\u00e9cuter des requ\u00eates populaires, et les chercheurs ignorent souvent les suggestions qui leur sont pr\u00e9sent\u00e9es -LSB- 1 -RSB-. De plus, ces deux techniques n\u2019aident pas les utilisateurs \u00e0 apprendre \u00e0 produire des requ\u00eates plus efficaces. La plupart des moteurs de recherche commerciaux proposent une syntaxe de requ\u00eate avanc\u00e9e qui permet aux utilisateurs de sp\u00e9cifier plus en d\u00e9tail leurs besoins en informations. Les op\u00e9rateurs bool\u00e9ens -LRB- AND, OR et NOT -RRB- peuvent joindre des termes et des expressions, et des modificateurs tels que `` site : '' et `` link : '' peuvent \u00eatre utilis\u00e9s pour restreindre l'espace de recherche. Les requ\u00eates cr\u00e9\u00e9es avec ces techniques peuvent \u00eatre puissantes. L'analyse bas\u00e9e sur les journaux des interactions des utilisateurs avec les moteurs de recherche Excite et AltaVista a montr\u00e9 que seulement 10 \u00e0 20 % des requ\u00eates contenaient une syntaxe avanc\u00e9e -LSB- 14 -RSB- -LSB- 25 -RSB-. Cette analyse peut \u00eatre un moyen utile de capturer les caract\u00e9ristiques des utilisateurs interagissant avec les syst\u00e8mes IR. Les recherches sur la mod\u00e9lisation des utilisateurs -LSB- 6 -RSB- et la personnalisation -LSB- 30 -RSB- ont montr\u00e9 que la collecte de plus d'informations sur les utilisateurs peut am\u00e9liorer l'efficacit\u00e9 des recherches, mais n\u00e9cessite plus d'informations sur les utilisateurs que ce qui est g\u00e9n\u00e9ralement disponible \u00e0 partir des seuls journaux d'interaction. \u00c0 moins d\u2019\u00eatre associ\u00e9 \u00e0 une technique qualitative, telle qu\u2019un questionnaire post-session -LSB-23-RSB-, il peut \u00eatre difficile d\u2019associer les interactions aux caract\u00e9ristiques des utilisateurs. Dans notre \u00e9tude, nous supposons qu'\u00e9tant donn\u00e9 la difficult\u00e9 de localiser les fonctionnalit\u00e9s de recherche avanc\u00e9e dans l'interface de recherche typique et les probl\u00e8mes potentiels de compr\u00e9hension de la syntaxe, les utilisateurs qui utilisent la syntaxe avanc\u00e9e repr\u00e9sentent r\u00e9guli\u00e8rement une classe distincte de chercheurs qui pr\u00e9senteront d'autres comportements de recherche courants. . D'autres \u00e9tudes sur les comportements de recherche des chercheurs avanc\u00e9s ont tent\u00e9 de mieux comprendre les connaissances strat\u00e9giques qu'ils ont acquises. N\u00e9anmoins, ils peuvent fournir des informations pr\u00e9cieuses sur les comportements des utilisateurs poss\u00e9dant une expertise en mati\u00e8re de domaine, de syst\u00e8me ou de recherche qui d\u00e9passe celle de l'utilisateur moyen. Le comportement des requ\u00eates en particulier a \u00e9t\u00e9 \u00e9tudi\u00e9 de mani\u00e8re approfondie pour mieux comprendre les utilisateurs -LSB- 31 -RSB- et prendre en charge les autres utilisateurs -LSB- 16 -RSB-. Dans cet article, nous \u00e9tudions d'autres caract\u00e9ristiques de recherche des utilisateurs de syntaxe avanc\u00e9e dans le but de d\u00e9terminer s'il y a quelque chose de diff\u00e9rent dans la fa\u00e7on dont ces utilisateurs de moteurs de recherche effectuent leurs recherches, et si leurs recherches peuvent \u00eatre utilis\u00e9es au profit de ceux qui n'utilisent pas les fonctionnalit\u00e9s avanc\u00e9es. des moteurs de recherche. Pour ce faire, nous utilisons des journaux d'interaction collect\u00e9s aupr\u00e8s d'un grand nombre d'utilisateurs consentants sur une p\u00e9riode prolong\u00e9e. Dans la section suivante, nous d\u00e9crivons les donn\u00e9es que nous utilisons pour \u00e9tudier le comportement des utilisateurs qui utilisent une syntaxe avanc\u00e9e, par rapport \u00e0 ceux qui n'utilisent pas cette syntaxe. Actes du SIGIR 2007 S\u00e9ance 11 :Comportement d'interaction tel que les requ\u00eates, les clics sur les r\u00e9sultats, la navigation post-requ\u00eate et la r\u00e9ussite de la recherche. Une classification grossi\u00e8re des utilisateurs bas\u00e9e sur une seule fonctionnalit\u00e9 facilement extractible du flux de requ\u00eates produit des r\u00e9sultats remarquables sur le comportement d'interaction des utilisateurs qui n'utilisent pas la syntaxe et de ceux qui l'utilisent. Comme nous l'avons sugg\u00e9r\u00e9, les syst\u00e8mes de recherche peuvent exploiter les interactions de ces utilisateurs pour am\u00e9liorer le classement des documents, la recommandation de pages ou m\u00eame la formation des utilisateurs.", "keyphrases": ["moteur de recherche", "requ\u00eate", "relev informer", "strat\u00e9gie de recherche", "tol\u00e9rer la latence", "syntaxe avanc\u00e9e", "comportement de navigation", "comportement de recherche", "succ\u00e8s de la recherche", "commentaires pertinents", "pertinent"]}
{"file_name": "J-8", "text": "\u00c9quilibre fort dans les jeux de connexion \u00e0 partage de co\u00fbts * R\u00c9SUM\u00c9 Dans ce travail, nous \u00e9tudions les jeux de connexion \u00e0 partage de co\u00fbts, o\u00f9 chaque joueur a une source et un puits qu'il aimerait connecter, et le co\u00fbt des bords est soit partag\u00e9 \u00e0 parts \u00e9gales - LRB - jeux de connexion \u00e9quitables - RRB- ou de mani\u00e8re arbitraire -LRB- jeux de connexion g\u00e9n\u00e9raux -RRB-. Nous \u00e9tudions les topologies de graphes qui garantissent l'existence d'un \u00e9quilibre fort -LRB- o\u00f9 aucune coalition ne peut am\u00e9liorer le co\u00fbt de chacun de ses membres -RRB- quels que soient les co\u00fbts sp\u00e9cifiques sur les bords. Nos principaux r\u00e9sultats d'existence sont les suivants : -LRB- 1 -RRB- Pour une source et un puits uniques nous montrons qu'il existe toujours un \u00e9quilibre fort -LRB- \u00e0 la fois pour les jeux de connexion \u00e9quitables et g\u00e9n\u00e9raux -RRB-. -LRB- 2 -RRB- Pour une source unique et plusieurs puits, nous montrons que pour un graphe parall\u00e8le en s\u00e9rie, un \u00e9quilibre fort existe toujours -LRB- \u00e0 la fois pour les jeux de connexion \u00e9quitables et g\u00e9n\u00e9raux -RRB-. -LRB- 3 -RRB- Pour les multi sources et puits nous montrons qu'un graphe parall\u00e8le d'extension admet toujours un \u00e9quilibre fort dans les jeux de connexions \u00e9quitables. Quant \u00e0 la qualit\u00e9 de l'\u00e9quilibre fort, nous montrons que dans tout jeu de connexions \u00e9quitables, le co\u00fbt d'un \u00e9quilibre fort est \u0398 -LRB- log n -RRB- de la solution optimale, o\u00f9 n est le nombre de joueurs. -LRB- Cela doit \u00eatre compar\u00e9 au prix \u03a9 -LRB- n -RRB- de l'anarchie pour le m\u00eame param\u00e8tre. -RRB- Pour les jeux de connexion g\u00e9n\u00e9rale \u00e0 source unique et les jeux de connexion \u00e9quitable \u00e0 source unique et \u00e0 puits unique, nous montrons qu'un \u00e9quilibre fort est toujours une solution optimale. * Recherche soutenue en partie par une subvention de la Fondation scientifique isra\u00e9lienne, de la Fondation binationale scientifique -LRB-BSF-RRB-, de la Fondation allemande-isra\u00e9lienne -LRB- GIF -RRB-, de la bourse Lady Davis, d'un prix universitaire IBM et du programme IST de Communaut\u00e9 europ\u00e9enne, dans le cadre du r\u00e9seau d'excellence PASCAL, IST-2002-506778. Cette publication refl\u00e8te uniquement les points de vue des auteurs. 1. INTRODUCTION La th\u00e9orie computationnelle des jeux a introduit la question des incitations dans de nombreux probl\u00e8mes d'optimisation combinatoire classiques. Consid\u00e9rez les probl\u00e8mes classiques de routage et de transport tels que les probl\u00e8mes de multidiffusion ou multi-produits, qui sont souvent consid\u00e9r\u00e9s comme suit. Nous recevons un graphique avec les co\u00fbts de p\u00e9riph\u00e9rie et les demandes de connectivit\u00e9 entre les n\u0153uds, et notre objectif est de trouver une solution \u00e0 co\u00fbt minimal. Le point de vue de la th\u00e9orie des jeux supposerait que chaque demande individuelle est contr\u00f4l\u00e9e par un acteur qui optimise sa propre utilit\u00e9, et le r\u00e9sultat qui en r\u00e9sulte pourrait \u00eatre loin d\u2019\u00eatre la solution optimale. Lorsqu\u2019on envisage des incitations individuelles, il faut discuter du concept de solution appropri\u00e9e. Une grande partie de la recherche en th\u00e9orie computationnelle des jeux s\u2019est concentr\u00e9e sur l\u2019\u00e9quilibre de Nash classique comme concept principal de solution. En effet l'\u00e9quilibre de Nash pr\u00e9sente de nombreux avantages, et surtout il existe toujours -LRB- dans les strat\u00e9gies mixtes -RRB-. Cependant, le concept de solution de l\u2019\u00e9quilibre de Nash ne r\u00e9siste qu\u2019aux d\u00e9viations unilat\u00e9rales, alors qu\u2019en r\u00e9alit\u00e9, les acteurs peuvent \u00eatre capables de coordonner leurs actions.Un \u00e9quilibre fort -LSB- 4 -RSB- est un \u00e9tat dont aucune coalition -LRB-, quelle que soit sa taille -RRB-, ne peut s'\u00e9carter et am\u00e9liorer l'utilit\u00e9 de chaque membre de la coalition -LRB- tout en r\u00e9duisant \u00e9ventuellement l'utilit\u00e9 des acteurs ext\u00e9rieurs \u00e0 la coalition. coalition -RRB-. Cette r\u00e9silience aux d\u00e9viations des coalitions d\u2019acteurs est tr\u00e8s attractive, et on peut esp\u00e9rer qu\u2019une fois un \u00e9quilibre fort atteint, il aura de fortes chances de se maintenir. Du point de vue de la th\u00e9orie informatique des jeux, un avantage suppl\u00e9mentaire d\u2019un \u00e9quilibre fort est qu\u2019il a le potentiel de r\u00e9duire la distance entre la solution optimale et la solution obtenue \u00e0 la suite d\u2019un comportement \u00e9go\u00efste. Le prix fort de l\u2019anarchie -LRB- SPoA -RRB-, introduit dans -LSB- 1 -RSB-, est le rapport entre le co\u00fbt du pire \u00e9quilibre fort et le co\u00fbt d\u2019une solution optimale. De toute \u00e9vidence, le SPoA n\u2019a de sens que dans les cas o\u00f9 un \u00e9quilibre fort existe. Un inconv\u00e9nient majeur de l\u2019\u00e9quilibre fort est que la plupart des jeux n\u2019admettent aucun \u00e9quilibre fort. M\u00eame les jeux classiques simples comme le dilemme du prisonnier ne poss\u00e8dent aucun \u00e9quilibre fort -LRB-, ce qui est aussi un exemple de jeu de congestion qui ne poss\u00e8de pas d'\u00e9quilibre fort -RRB-. Ce malheureux fait a r\u00e9duit la concentration en \u00e9quilibre fort, malgr\u00e9 ses propri\u00e9t\u00e9s tr\u00e8s attractives. Dans ce travail, nous nous concentrons sur les jeux de connexion \u00e0 co\u00fbt partag\u00e9, introduits par -LSB- 3, 2 -RSB-. Dans un tel jeu, il existe un graphe orient\u00e9 sous-jacent avec des co\u00fbts de bord, et les utilisateurs individuels ont des demandes de connectivit\u00e9 -LRB- entre une source et un r\u00e9cepteur -RRB-. Nous consid\u00e9rons deux mod\u00e8les. Le mod\u00e8le de connexion au juste co\u00fbt -LSB- 2 -RSB- permet \u00e0 chaque acteur de s\u00e9lectionner un chemin depuis la source jusqu'au puits2. Dans ce jeu, le co\u00fbt d'un bord est partag\u00e9 \u00e9galement entre tous les joueurs qui ont s\u00e9lectionn\u00e9 le bord, et le co\u00fbt du joueur est la somme de ses co\u00fbts sur les bords qu'il a s\u00e9lectionn\u00e9s. Le jeu de connexion g\u00e9n\u00e9rale -LSB- 3 -RSB- permet \u00e0 chaque joueur de proposer des prix pour les bords. Dans ce jeu un avantage est achet\u00e9 si la somme des offres couvre au moins son co\u00fbt, et le co\u00fbt du joueur est la somme de ses offres sur les bords achet\u00e9s -LRB- dans les deux jeux nous supposons que le joueur doit garantir l'avantage. connectivit\u00e9 entre sa source et son puits -RRB-. Dans ce travail, nous nous concentrons sur deux questions importantes. La premi\u00e8re consiste \u00e0 identifier dans quelles conditions l\u2019existence d\u2019un \u00e9quilibre fort est garantie, et la seconde est la qualit\u00e9 des \u00e9quilibres forts. Pour la partie existence, nous identifions des familles de topologies de graphes qui poss\u00e8dent un \u00e9quilibre fort pour toute affectation de co\u00fbts de bord. On peut consid\u00e9rer cette s\u00e9paration entre la topologie du graphe et les co\u00fbts des bords, comme une s\u00e9paration entre l'infrastructure sous-jacente et les co\u00fbts observ\u00e9s par les acteurs pour acheter des bords. Alors que l\u2019on s\u2019attend \u00e0 ce que l\u2019infrastructure soit stable sur de longues p\u00e9riodes, les co\u00fbts observ\u00e9s par les acteurs peuvent \u00eatre facilement modifi\u00e9s sur de courtes p\u00e9riodes. Nos r\u00e9sultats sont les suivants.Pour le cas d'une seule marchandise -LRB-, tous les joueurs ont la m\u00eame source et le m\u00eame puits -RRB-, il existe un \u00e9quilibre fort dans tout graphe -LRB- \u00e0 la fois pour les jeux de connexion \u00e9quitables et g\u00e9n\u00e9raux -RRB-. De plus, l'\u00e9quilibre fort est \u00e9galement valable alors que tout jeu de congestion est connu pour admettre au moins un \u00e9quilibre de Nash dans les strat\u00e9gies pures -LSB- 16 -RSB-. 2Le syst\u00e8me de partage \u00e9quitable des co\u00fbts est \u00e9galement attrayant du point de vue de la conception du m\u00e9canisme, car il s\u2019agit d\u2019un m\u00e9canisme de partage des co\u00fbts \u00e0 l\u2019\u00e9preuve des strat\u00e9gies -LSB-14-RSB-. la solution optimale -LRB- \u00e0 savoir, les joueurs partagent le chemin le plus court depuis la source commune jusqu'au puits commun -RRB-. Pour le cas d'une source unique et de plusieurs puits -LRB- par exemple, dans un arbre multicast -RRB-, nous montrons que dans un jeu de connexions \u00e9quitable, il existe un \u00e9quilibre fort si le graphe sous-jacent est un graphe parall\u00e8le en s\u00e9rie, et nous montrons un exemple de graphe parall\u00e8le non-s\u00e9rie qui n'a pas d'\u00e9quilibre fort. Pour le cas des multi-produits -LRB- multi sources et puits -RRB-, nous montrons que dans un jeu de connexion \u00e9quitable si le graphe est un graphe parall\u00e8le d'extension alors il y a toujours un \u00e9quilibre fort, et nous montrons un exemple de s\u00e9rie graphe parall\u00e8le qui n\u2019a pas d\u2019\u00e9quilibre fort. Pour autant que nous le sachions, nous sommes les premiers \u00e0 fournir une caract\u00e9risation topologique de l'existence \u00e0 l'\u00e9quilibre dans les jeux en r\u00e9seau multi-produits et \u00e0 source unique. Pour tout jeu de connexion \u00e9quitable, nous montrons que s'il existe un \u00e9quilibre fort, il s'agit au plus d'un facteur \u0398 -LRB- log n -RRB- de la solution optimale, o\u00f9 n est le nombre de joueurs. Cela doit \u00eatre mis en contraste avec la limite \u0398 -LRB- n -RRB- qui existe au prix de l'anarchie -LSB- 2 -RSB-. Pour les jeux de connexion g\u00e9n\u00e9rale \u00e0 source unique, nous montrons que tout graphe parall\u00e8le en s\u00e9rie poss\u00e8de un \u00e9quilibre fort, et nous montrons un exemple de graphe qui n'a pas d'\u00e9quilibre fort. Dans ce cas, nous montrons \u00e9galement que tout \u00e9quilibre fort est optimal. Travaux connexes Des caract\u00e9risations topologiques pour les jeux en r\u00e9seau \u00e0 marchandise unique ont \u00e9t\u00e9 r\u00e9cemment fournies pour diverses propri\u00e9t\u00e9s d'\u00e9quilibre, y compris l'existence \u00e0 l'\u00e9quilibre -LSB- 12, 7, 8 -RSB-, l'unicit\u00e9 de l'\u00e9quilibre -LSB- 10 -RSB- et l'efficacit\u00e9 de l'\u00e9quilibre -LSB- 17. , 11 -RSB-. L'existence d'un \u00e9quilibre de Nash pur dans les jeux de congestion de r\u00e9seau mono-produit avec des co\u00fbts ou des poids sp\u00e9cifiques aux joueurs a \u00e9t\u00e9 \u00e9tudi\u00e9e dans -LSB- 12 -RSB-. L'existence d'un \u00e9quilibre fort a \u00e9t\u00e9 \u00e9tudi\u00e9e \u00e0 la fois dans les jeux de congestion \u00e0 diminution d'utilit\u00e9 -LRB-, par exemple le routage -RRB-, et dans les jeux \u00e0 augmentation d'utilit\u00e9 -LRB-, par exemple, dans les jeux de congestion \u00e0 partage \u00e9quitable des co\u00fbts -RRB. -LSB- 7, 8 -RSB- ont fourni une caract\u00e9risation topologique compl\u00e8te de l'existence d'une SE dans des jeux de congestion d\u00e9croissant l'utilit\u00e9 d'un seul produit, et ont montr\u00e9 qu'une SE existe toujours si et seulement si le graphe sous-jacent est parall\u00e8le \u00e0 l'extension. -LSB- 19 -RSB- ont montr\u00e9 que dans les jeux de congestion augmentant l'utilit\u00e9 d'un seul produit, la caract\u00e9risation topologique est essentiellement \u00e9quivalente \u00e0 celle des liens parall\u00e8les. En outre,ils ont montr\u00e9 que ces r\u00e9sultats s'appliquent \u00e9galement aux \u00e9quilibres forts corr\u00e9l\u00e9s -LRB-, contrairement au context d\u00e9croissant, o\u00f9 les \u00e9quilibres forts corr\u00e9l\u00e9s pourraient ne pas exister du tout -RRB-. Bien que les jeux de partage \u00e9quitable des co\u00fbts que nous \u00e9tudions soient des jeux d'utilit\u00e9 augmentant la congestion du r\u00e9seau, nous en d\u00e9duisons une caract\u00e9risation diff\u00e9rente de -LSB-19-RSB- en raison des diff\u00e9rentes hypoth\u00e8ses concernant les actions des joueurs.3 4. JEUX DE CONNEXION G\u00c9N\u00c9RALE Dans cette section, nous d\u00e9river nos r\u00e9sultats pour les jeux de connexion g\u00e9n\u00e9raux. 4.1 Existence d'un \u00e9quilibre fort Nous commen\u00e7ons par une caract\u00e9risation de l'existence d'un \u00e9quilibre fort dans les jeux de connexions g\u00e9n\u00e9raux sym\u00e9triques. Semblable au Th\u00e9or\u00e8me 3.1 -LRB- en utilisant une preuve similaire -RRB- nous \u00e9tablissons le TH\u00c9OR\u00c8ME 4.1. Dans tout jeu de connexion sym\u00e9trique et \u00e9quitable, il existe un \u00e9quilibre fort. Bien que chaque jeu de connexion g\u00e9n\u00e9rale de source poss\u00e8de un \u00e9quilibre de Nash pur -LSB- 3 -RSB-, il n'admet pas n\u00e9cessairement un \u00e9quilibre fort11. Le jeu de connexion \u00e9quitable a inspir\u00e9 cet exemple. TH\u00c9OR\u00c8ME 4.2. Il existe un jeu de connexion g\u00e9n\u00e9ral \u00e0 source unique qui n\u2019admet aucun \u00e9quilibre fort. PREUVE. Consid\u00e9rons un jeu de connexion g\u00e9n\u00e9rale \u00e0 source unique avec 3 joueurs sur le graphique repr\u00e9sent\u00e9 \u00e0 la figure 4. Nous avons montr\u00e9 qu'aucun des NE n'est SE et que le jeu ne poss\u00e8de donc aucun SE. Nous montrons ensuite que pour la classe des graphes parall\u00e8les en s\u00e9rie, il existe toujours un \u00e9quilibre fort dans le cas d\u2019une source unique. PREUVE. Soit \u039b un jeu de connexion g\u00e9n\u00e9ral \u00e0 source unique sur un SPG G = -LRB- V, E -RRB- de source s et de puits t. Consid\u00e9rons d\u2019abord l\u2019ordre partiel suivant entre les joueurs. Pour les joueurs i et j, nous avons cela i \u2192 j s'il existe un chemin dirig\u00e9 de ti \u00e0 tj. L'algorithme COMPUTE-SE consid\u00e8re les joueurs dans un ordre croissant, en commen\u00e7ant par le joueur 1. Chaque joueur i ach\u00e8tera enti\u00e8rement un sous-ensemble des bords, et tout joueur j > i consid\u00e9rera le co\u00fbt de ceux -LRB- achet\u00e9s -RRB- bords \u00e0 z\u00e9ro. Lorsque COMPUTE-SE consid\u00e8re le joueur j, le co\u00fbt des bords que les joueurs 1 \u00e0 j \u2212 1 ont achet\u00e9s est fix\u00e9 \u00e0 z\u00e9ro, et le joueur j ach\u00e8te enti\u00e8rement un chemin le plus court Qj de s \u00e0 tj. A savoir, pour chaque ar\u00eate e G Qj \\ Ui < jQi nous avons pj -LRB- e -RRB- = ce et sinon pj -LRB- e -RRB- = 0. Nous montrons ensuite que l'algorithme COMPUTESE calcule une SE. Supposons par contradiction que le profil p n'est pas une SE. Il existe alors une coalition qui peut am\u00e9liorer les co\u00fbts de tous ses acteurs par une d\u00e9viation. Soit \u0393 une telle coalition de taille minimale et soit le joueur i = max -LCB- j G \u0393 -RCB-. Pour un joueur j G \u0393, soit \u00af Qj et \u00af pj le chemin et le paiement du joueur j apr\u00e8s la d\u00e9viation, respectivement. Soit Q ' un chemin depuis le puits du joueur i, c'est-\u00e0-dire ti, jusqu'au puits de G, c'est-\u00e0-dire Alors Q = \u00af Qi UQ ' est un chemin depuis la source s jusqu'au puits t. Pour tout joueur j < i, soit yj le sommet d'intersection de Q et tj -LRB- d'apr\u00e8s le lemme 2.1, il est garanti qu'il existe -RRB-. Soit y le sommet le plus \u00e9loign\u00e9 du chemin Q tel que y = yj pour certains j < i.Le chemin de la source s au n\u0153ud y \u00e9tait enti\u00e8rement pay\u00e9 par les joueurs j < i dans p -LRB- avant la d\u00e9viation -RRB-. Nous consid\u00e9rons deux cas. cas a : Apr\u00e8s la d\u00e9viation, le joueur i ne paie pas les bords dans U j \u2208 \u0393 \\ -LCB- i -RCB- \u00af Qj. Avant la d\u00e9viation de la coalition \u0393, un chemin de s vers y \u00e9tait enti\u00e8rement pay\u00e9 par les joueurs j < i. Ensuite, nous montrons qu'aucun joueur k > i ne paie pour un avantage sur un chemin quelconque de s \u00e0 ti. Consid\u00e9rons un joueur k > i et soit Q0k = Qk U Q00k, o\u00f9 Q00k est un chemin reliant tk \u00e0 t. Soit yk le sommet s\u00e9cant de Q0k et ti. Puisqu'il existe un chemin de s \u00e0 yk qui a \u00e9t\u00e9 enti\u00e8rement pay\u00e9 par les joueurs j < k avant la d\u00e9viation, en particulier le chemin Qis, yk, le joueur k ne paiera aucun avantage sur aucun chemin reliant s et yk. Par cons\u00e9quent, le joueur i paie enti\u00e8rement toutes les ar\u00eates du chemin \u00af Qiy, ti, c'est-\u00e0-dire \u00af pi -LRB- e -RRB- = ce pour toutes les ar\u00eates e E \u00af Qiy, ti. Consid\u00e9rons maintenant l'algorithme COMPUTESE \u00e0 l'\u00e9tape o\u00f9 le joueur i s\u00e9lectionne le chemin le plus court depuis la source s jusqu'\u00e0 son r\u00e9cepteur ti et d\u00e9termine son paiement pi. \u00c0 ce stade, le joueur i pouvait acheter le chemin \u00af Qiy, ti, puisqu'un chemin de s \u00e0 y \u00e9tait d\u00e9j\u00e0 pay\u00e9 par les joueurs j < i. Par cons\u00e9quent, ci -LRB- \u00af p -RRB- > ci -LRB- p -RRB-. Cela contredit le fait que le joueur i a am\u00e9lior\u00e9 son co\u00fbt et donc tous les joueurs de \u0393 ne r\u00e9duisent pas leur co\u00fbt. Cela implique que p est un \u00e9quilibre fort. 4.2 Le prix \u00e9lev\u00e9 de l'anarchie Bien que pour chaque jeu de connexion g\u00e9n\u00e9rale \u00e0 source unique, il soit \u00e9tabli que PoS = 1 -LSB- 3 -RSB-, le prix de l'anarchie peut \u00eatre aussi \u00e9lev\u00e9 que n, m\u00eame pour deux bords parall\u00e8les. Nous montrons ici que tout \u00e9quilibre fort dans les jeux de connexion g\u00e9n\u00e9rale \u00e0 source unique donne le co\u00fbt optimal. PREUVE. Soit p = -LRB- p1,..., pn -RRB- un \u00e9quilibre fort, et soit T \u2217 l'arbre de Steiner \u00e0 co\u00fbt minimum sur tous les joueurs, enracin\u00e9 dans les sources -LRB- single -RRB-. Soit Te \u2217 le sous-arbre de T \u2217 d\u00e9connect\u00e9 de s lorsque l'ar\u00eate e est supprim\u00e9e. Soit \u0393 -LRB- Te -RRB- l'ensemble des joueurs qui ont des puits dans Te. Pour un ensemble d\u2019ar\u00eates E, soit c -LRB- E -RRB- = Ee \u2208 E ce. Supposons par contradiction que c -LRB- p -RRB- > c -LRB- T \u2217 -RRB-. Nous montrerons qu'il existe un sous-arbre T0 de T \u2217, qui relie un sous-ensemble de joueurs \u0393 C _ N, et un nouvel ensemble de paiements \u00af p, tel que pour chaque i E \u0393, ci -LRB- \u00af p - RRB- < ci -LRB- p -RRB-. Cela contredirait l\u2019hypoth\u00e8se selon laquelle p est un \u00e9quilibre fort. Nous montrons d\u2019abord comment trouver un sous-arbre T0 de T \u2217, tel que pour tout arc e, les paiements des joueurs ayant des puits dans Te \u2217 soient sup\u00e9rieurs au co\u00fbt de Te \u2217 U -LCB- e -RCB-. Pour construire T0, d\u00e9finissez un bord e comme \u00e9tant mauvais si le co\u00fbt de Te \u2217 U -LCB- e -RCB- est au moins \u00e9gal aux paiements des joueurs ayant des puits dans Te \u2217, c'est-\u00e0-dire c -LRB- Te \u2217 U -LCB - e -RCB- -RRB- > P -LRB- Te \u2217 -RRB-. Soit B l\u2019ensemble des mauvaises ar\u00eates. Par cons\u00e9quent, dans T0 pour chaque ar\u00eate e, nous avons que c -LRB- Te0 U -LCB- e -RCB- -RRB- < P -LRB- T0e -RRB-.Il ne reste plus qu'\u00e0 trouver des paiements p \u00af pour les joueurs de \u0393 -LRB- T0 -RRB- tels qu'ils ach\u00e8teront l'arbre T0 et que chaque joueur de \u0393 -LRB- T0 -RRB- en baissera le co\u00fbt, c'est \u00e0 dire ci -LRB- p -RRB- > ci -LRB- \u00af p -RRB- pour i E \u0393 -LRB- T0 -RRB-. -LRB- Rappelons que les paiements ont la restriction que le joueur i ne peut payer que pour les bords sur le chemin de s \u00e0 ti. -RRB- Nous allons maintenant d\u00e9finir les paiements de coalition \u00af p. Soit ci -LRB- \u00af p, T0 e \u2208 Te \u00af pi -LRB- e -RRB- les paiements du joueur i pour le sous-arbre T0e. Consid\u00e9rons le processus ascendant suivant qui d\u00e9finit \u00af p. Nous attribuons les paiements du bord e dans T0, apr\u00e8s avoir attribu\u00e9 les paiements \u00e0 tous les bords de T0e. Par cons\u00e9quent, nous pouvons mettre \u00e0 jour les paiements p \u00af des joueurs i E \u0393 -LRB- T0e -RRB-, en fixant o\u00f9 nous avons utilis\u00e9 le fait que E e -RRB-.", "keyphrases": ["jeu de connexion \u00e0 co\u00fbt partag\u00e9", "nombre de joueur", "source et \u00e9vier uniques", "\u00e9vier multiple \u00e0 source unique", "multi source et \u00e9vier", "co\u00fbt du bord", "jeu de connexion \u00e9quitable", "jeu de connexion g\u00e9n\u00e9rique", "topologie graphique", "\u00e9quilibre fort", "coalit", "co\u00fbt sp\u00e9cifique", "\u00e9tend le graphe parall\u00e8le", "solution optimale"]}
{"file_name": "C-3", "text": "Applications auto-adaptatives sur la grille Les grilles abstraites sont intrins\u00e8quement h\u00e9t\u00e9rog\u00e8nes et dynamiques. Un probl\u00e8me important du calcul en grille est la s\u00e9lection des ressources, c'est-\u00e0-dire la recherche d'un ensemble de ressources appropri\u00e9 pour l'application. Un autre probl\u00e8me est l\u2019adaptation aux caract\u00e9ristiques changeantes de l\u2019environnement du r\u00e9seau. Les solutions existantes \u00e0 ces deux probl\u00e8mes n\u00e9cessitent qu\u2019un mod\u00e8le de performances pour une application soit connu. Cependant, construire de tels mod\u00e8les est une t\u00e2che complexe. Dans cet article, nous \u00e9tudions une approche qui ne n\u00e9cessite pas de mod\u00e8les de performances. Nous d\u00e9marrons une application sur n\u2019importe quel ensemble de ressources. Pendant l'ex\u00e9cution de l'application, nous collectons p\u00e9riodiquement des statistiques sur l'ex\u00e9cution de l'application et d\u00e9duisons les exigences de l'application \u00e0 partir de ces statistiques. Ensuite, nous ajustons l\u2019ensemble des ressources pour mieux r\u00e9pondre aux besoins de l\u2019application. Cette approche nous permet d'\u00e9viter les goulots d'\u00e9tranglement en termes de performances, tels que des liaisons WAN surcharg\u00e9es ou des processeurs tr\u00e8s lents, et peut donc g\u00e9n\u00e9rer des am\u00e9liorations significatives des performances. Nous \u00e9valuons notre approche dans un certain nombre de sc\u00e9narios typiques du Grid. 1. Introduction Ces derni\u00e8res ann\u00e9es, le calcul en grille est devenu une v\u00e9ritable alternative au calcul parall\u00e8le traditionnel. Une grille fournit une grande puissance de calcul, et offre ainsi la possibilit\u00e9 de r\u00e9soudre de tr\u00e8s gros probl\u00e8mes, surtout si les applications peuvent s'ex\u00e9cuter sur plusieurs sites en m\u00eame temps -LRB- 7 ; 15\u00a0; 20 -RRB-. Cependant, la complexit\u00e9 des environnements Grid est \u00e9galement plusieurs fois sup\u00e9rieure \u00e0 celle des machines parall\u00e8les traditionnelles telles que les clusters et les supercalculateurs. Un probl\u00e8me important est la s\u00e9lection des ressources : s\u00e9lectionner un ensemble de n\u0153uds de calcul de mani\u00e8re \u00e0 ce que l'application atteigne de bonnes performances. Dans un environnement de grille, ce probl\u00e8me est encore plus difficile, en raison de l'h\u00e9t\u00e9rog\u00e9n\u00e9it\u00e9 des ressources : les n\u0153uds de calcul ont diverses Un autre probl\u00e8me important est que les performances et la disponibilit\u00e9 des ressources de grille varient dans le temps : les liaisons r\u00e9seau ou les n\u0153uds de calcul peuvent devenir surcharg\u00e9s, ou les n\u0153uds de calcul peuvent devenir indisponibles en raison de pannes ou parce qu'ils ont \u00e9t\u00e9 r\u00e9clam\u00e9s par une application de priorit\u00e9 plus \u00e9lev\u00e9e. De nouvelles ressources, de meilleure qualit\u00e9, pourraient \u00e9galement devenir disponibles. Pour maintenir un niveau de performance raisonnable, l\u2019application doit donc s\u2019adapter aux conditions changeantes. Le probl\u00e8me d'adaptation peut \u00eatre r\u00e9duit au probl\u00e8me de s\u00e9lection des ressources : la phase de s\u00e9lection des ressources peut \u00eatre r\u00e9p\u00e9t\u00e9e lors de l'ex\u00e9cution de l'application, soit \u00e0 intervalles r\u00e9guliers, soit lorsqu'un probl\u00e8me de performances est d\u00e9tect\u00e9, soit lorsque de nouvelles ressources deviennent disponibles. Cette approche a \u00e9t\u00e9 adopt\u00e9e par un certain nombre de syst\u00e8mes -LRB- 5 ; 14\u00a0; 18 -RRB-. Pour la s\u00e9lection des ressources, le temps d'ex\u00e9cution de l'application est estim\u00e9 pour certains ensembles de ressources et l'ensemble qui g\u00e9n\u00e8re le temps d'ex\u00e9cution le plus court est s\u00e9lectionn\u00e9 pour l'ex\u00e9cution. Pr\u00e9dire le temps d\u2019ex\u00e9cution d\u2019une application sur un ensemble donn\u00e9 de ressources n\u00e9cessite toutefois des connaissances sur l\u2019application. G\u00e9n\u00e9ralement, un mod\u00e8le de performance analytique est utilis\u00e9,mais la construction d'un tel mod\u00e8le est intrins\u00e8quement difficile et n\u00e9cessite une expertise que les programmeurs d'applications ne poss\u00e8dent peut-\u00eatre pas. Dans cet article, nous introduisons et \u00e9valuons une approche alternative \u00e0 l'adaptation des applications et \u00e0 la s\u00e9lection des ressources qui ne n\u00e9cessite pas de mod\u00e8le de performance. Nous d\u00e9marrons une application sur n\u2019importe quel ensemble de ressources. Pendant l'ex\u00e9cution de l'application, nous collectons p\u00e9riodiquement des informations sur les temps de communication et les temps d'inactivit\u00e9 des processeurs. Nous utilisons ces statistiques pour estimer automatiquement les besoins en ressources de l'application. Ensuite, nous ajustons l'ensemble de ressources sur lequel l'application s'ex\u00e9cute en ajoutant ou en supprimant des n\u0153uds de calcul ou m\u00eame des clusters entiers. Des processeurs sont ajout\u00e9s ou supprim\u00e9s pour rester entre les seuils, s'adaptant ainsi automatiquement \u00e0 l'environnement changeant. Un avantage majeur de notre approche est qu\u2019elle am\u00e9liore les performances des applications dans de nombreuses situations diff\u00e9rentes typiques du calcul en grille. Il g\u00e8re tous les cas suivants : Notre travail suppose que l'application est mall\u00e9able et peut s'ex\u00e9cuter -LRB- efficacement -RRB- sur plusieurs sites d'une grille -LRB- c'est-\u00e0-dire en utilisant la co-allocation -LRB- 15 -RRB- -RRB- . latences de zone. Nous avons appliqu\u00e9 nos id\u00e9es pour diviser pour r\u00e9gner, qui r\u00e9pondent \u00e0 ces exigences. Il a \u00e9t\u00e9 d\u00e9montr\u00e9 que diviser pour r\u00e9gner est un paradigme attrayant pour les applications de grille de programmation -LRB-4\u00a0; 20 -RRB-. Nous pensons que notre approche peut \u00eatre \u00e9tendue \u00e0 d'autres classes d'applications avec les hypoth\u00e8ses donn\u00e9es. Nous avons mis en \u0153uvre notre strat\u00e9gie dans Satin, qui est un framework centr\u00e9 sur Java pour \u00e9crire des applications diviser pour r\u00e9gner compatibles avec une grille -LRB-20-RRB-. Le reste de cet article est structur\u00e9 comme suit. Dans la section 2, nous expliquons les hypoth\u00e8ses que nous faisons concernant les applications et les ressources du r\u00e9seau. Dans la section 3, nous pr\u00e9sentons notre strat\u00e9gie de s\u00e9lection et d\u2019adaptation des ressources. Dans la section 4, nous d\u00e9crivons son impl\u00e9mentation dans le framework Satin. Dans la section 5, nous \u00e9valuons notre approche dans un certain nombre de sc\u00e9narios de grille. Dans la section 6, nous comparons notre approche avec les travaux connexes. Enfin, dans la section 7, nous concluons et d\u00e9crivons les travaux futurs. 2. Context et hypoth\u00e8ses Dans cette section, nous d\u00e9crivons nos hypoth\u00e8ses concernant les applications et leurs ressources. Nous supposons le mod\u00e8le de ressource suivant. Les applications s'ex\u00e9cutent sur plusieurs sites en m\u00eame temps, o\u00f9 les sites sont des clusters ou des superordinateurs. Les processeurs appartenant \u00e0 un site sont connect\u00e9s par un r\u00e9seau local rapide avec une faible latence et une bande passante \u00e9lev\u00e9e. Les diff\u00e9rents sites sont reli\u00e9s par un WAN. La communication entre sites souffre de latences \u00e9lev\u00e9es. Nous avons \u00e9tudi\u00e9 le probl\u00e8me de l'adaptation dans le context des applications diviser pour r\u00e9gner. Cependant, nous pensons que notre m\u00e9thodologie peut \u00e9galement \u00eatre utilis\u00e9e pour d\u2019autres types d\u2019applications. Dans cette section, nous r\u00e9sumons les hypoth\u00e8ses sur les applications qui sont importantes pour notre approche. La premi\u00e8re hypoth\u00e8se que nous faisons est que l'application est mall\u00e9able, c'est-\u00e0-direil est capable de g\u00e9rer les processeurs qui rejoignent et quittent le calcul en cours. Dans -LRB-23-RRB-, nous avons montr\u00e9 comment les applications diviser pour r\u00e9gner peuvent \u00eatre rendues tol\u00e9rantes aux pannes et mall\u00e9ables. Des processeurs peuvent \u00eatre ajout\u00e9s ou supprim\u00e9s \u00e0 tout moment du calcul avec peu de frais g\u00e9n\u00e9raux. La deuxi\u00e8me hypoth\u00e8se est que l'application peut fonctionner efficacement sur des processeurs ayant des vitesses diff\u00e9rentes. Ceci peut \u00eatre r\u00e9alis\u00e9 en utilisant une strat\u00e9gie d'\u00e9quilibrage de charge dynamique, telle que le vol de travail utilis\u00e9 par les applications diviser pour r\u00e9gner -LRB-19-RRB-. De plus, les applications ma\u00eetre-travailleur utilisent g\u00e9n\u00e9ralement des strat\u00e9gies d'\u00e9quilibrage de charge dynamique -LRB- par exemple, MW -- un cadre pour \u00e9crire des applications ma\u00eetre-travailleur compatibles grille -LRB- 12 -RRB- -RRB-. Nous pensons que c'est une hypoth\u00e8se raisonnable pour une application en grille, puisque les applications pour lesquelles le processeur le plus lent devient un goulot d'\u00e9tranglement ne seront pas en mesure d'utiliser efficacement les ressources de la grille. Enfin, l'application doit \u00eatre insensible aux latences \u00e9tendues, afin de pouvoir fonctionner efficacement sur une grille \u00e9tendue -LRB- 16\u00a0; 17 -RRB-. 6. Travaux connexes Un certain nombre de projets Grid abordent la question de la s\u00e9lection et de l'adaptation des ressources. Dans GrADS -LRB- 18 -RRB- et ASSIST -LRB- 1 -RRB-, la s\u00e9lection et l'adaptation des ressources n\u00e9cessitent un mod\u00e8le de performances qui permet de pr\u00e9dire les temps d'ex\u00e9cution des applications. Lors de la phase de s\u00e9lection des ressources, un certain nombre d'ensembles de ressources possibles sont examin\u00e9s et l'ensemble de ressources ayant la dur\u00e9e d'ex\u00e9cution pr\u00e9vue la plus courte est s\u00e9lectionn\u00e9. Si une d\u00e9gradation des performances est d\u00e9tect\u00e9e lors du calcul, la phase de s\u00e9lection des ressources est r\u00e9p\u00e9t\u00e9e. GrADS utilise le rapport entre les temps d'ex\u00e9cution pr\u00e9dits -LRB- de certaines phases d'application -RRB- et les temps d'ex\u00e9cution r\u00e9els comme indicateur des performances de l'application. ASSIST utilise le nombre d'it\u00e9rations par unit\u00e9 de temps -LRB- pour les applications it\u00e9ratives -RRB- ou le nombre de t\u00e2ches par unit\u00e9 de temps -LRB- pour les applications ma\u00eetre-travailleur r\u00e9guli\u00e8res -RRB- comme indicateur de performance. La principale diff\u00e9rence entre ces approches et notre approche r\u00e9side dans l\u2019utilisation de mod\u00e8les de performance. Le principal avantage est qu\u2019une fois le mod\u00e8le de performance connu, le syst\u00e8me est capable de prendre des d\u00e9cisions de migration plus pr\u00e9cises qu\u2019avec notre approche. Cependant, m\u00eame si les performances ne s'adaptent pas avec adaptation, le probl\u00e8me de trouver un ensemble de ressources optimal -LRB-, c'est-\u00e0-dire l'ensemble de ressources avec le temps d'ex\u00e9cution minimal - est connu. RRB- est NP-complet. \u00c0 mesure que le nombre de ressources de grille disponibles augmente, la pr\u00e9cision de cette approche diminue, \u00e0 mesure que le sous-ensemble d'ensembles de ressources possibles pouvant \u00eatre examin\u00e9s dans un d\u00e9lai raisonnable diminue. Un autre inconv\u00e9nient de ces syst\u00e8mes est que la d\u00e9tection de d\u00e9gradation des performances ne convient que pour des applications it\u00e9ratives ou r\u00e9guli\u00e8res. Cactus -LRB- 2 -RRB- et GridWay -LRB- 14 -RRB- n'utilisent pas de mod\u00e8les performants. Cependant, ces frameworks ne conviennent qu\u2019aux applications s\u00e9quentielles -LRB-GridWay-RRB- ou monosite -LRB-Cactus-RRB-.Dans ce cas, le probl\u00e8me de s\u00e9lection des ressources se r\u00e9sume \u00e0 s\u00e9lectionner la machine ou le cluster le plus rapide. La vitesse d'horloge du processeur, la charge moyenne et le nombre de processeurs dans un cluster -LRB-Cactus -RRB- sont utilis\u00e9s pour classer les ressources et la ressource ayant le rang le plus \u00e9lev\u00e9 est s\u00e9lectionn\u00e9e. L'application est migr\u00e9e si une d\u00e9gradation des performances est d\u00e9tect\u00e9e ou si de meilleures ressources sont d\u00e9couvertes. Cactus et GridWay utilisent tous deux le nombre d'it\u00e9rations par unit\u00e9 de temps comme indicateur de performance. La principale limite de cette m\u00e9thodologie est qu\u2019elle ne convient qu\u2019aux applications s\u00e9quentielles ou sur un seul site. De plus, la s\u00e9lection des ressources bas\u00e9e sur la vitesse d\u2019horloge n\u2019est pas toujours pr\u00e9cise. Enfin, la d\u00e9tection de d\u00e9gradation des performances ne convient qu'aux applications it\u00e9ratives et ne peut pas \u00eatre utilis\u00e9e pour des calculs irr\u00e9guliers tels que des probl\u00e8mes de recherche et d'optimisation. Le probl\u00e8me de s\u00e9lection des ressources a \u00e9galement \u00e9t\u00e9 \u00e9tudi\u00e9 par le projet AppLeS -LRB- 5 -RRB-. Dans le cadre de ce projet, un certain nombre d'applications ont \u00e9t\u00e9 \u00e9tudi\u00e9es et des mod\u00e8les de performances pour ces applications ont \u00e9t\u00e9 cr\u00e9\u00e9s. Sur la base d'un tel mod\u00e8le, un agent de planification est construit qui utilise le mod\u00e8le de performances pour s\u00e9lectionner le meilleur ensemble de ressources et la meilleure planification d'application sur cet ensemble. Les agents de planification AppleS sont \u00e9crits au cas par cas et ne peuvent pas \u00eatre r\u00e9utilis\u00e9s pour une autre application. Deux mod\u00e8les r\u00e9utilisables ont \u00e9galement \u00e9t\u00e9 d\u00e9velopp\u00e9s pour des classes sp\u00e9cifiques d'applications, \u00e0 savoir les applications ma\u00eetre-travailleur -LRB- AMWAT template -RRB- et les param\u00e8tres de balayage -LRB- APST template -RRB-. 2 clusters sur 9 crash ont commenc\u00e9 \u00e0 ajouter des n\u0153uds 96 n\u0153uds atteints Dans -LRB- 13 -RRB-, le probl\u00e8me de la planification des applications ma\u00eetre-travailleur est \u00e9tudi\u00e9. Le probl\u00e8me se r\u00e9duit donc \u00e0 trouver le bon nombre de travailleurs. L\u2019approche ici est similaire \u00e0 la n\u00f4tre dans la mesure o\u00f9 aucun mod\u00e8le de performance n\u2019est utilis\u00e9. Au lieu de cela, le syst\u00e8me tente de d\u00e9duire les exigences de l'application au moment de l'ex\u00e9cution et ajuste le nombre de travailleurs pour se rapprocher du nombre id\u00e9al. 7. Conclusions et travaux futurs Dans cet article, nous avons \u00e9tudi\u00e9 le probl\u00e8me de la s\u00e9lection et de l'adaptation des ressources dans des environnements de grille. Les approches existantes pour r\u00e9soudre ces probl\u00e8mes supposent g\u00e9n\u00e9ralement l\u2019existence d\u2019un mod\u00e8le de performances permettant de pr\u00e9dire les temps d\u2019ex\u00e9cution des applications sur diff\u00e9rents ensembles de ressources. Cependant, la cr\u00e9ation de mod\u00e8les de performances est intrins\u00e8quement difficile et n\u00e9cessite des connaissances sur l'application. Nous proposons une approche qui ne n\u00e9cessite pas de connaissance approfondie de l\u2019application. Nous d\u00e9marrons l'application sur un ensemble arbitraire de ressources et surveillons ses performances. La surveillance des performances nous permet de conna\u00eetre certaines exigences de l'application telles que le nombre de processeurs n\u00e9cessaires \u00e0 l'application ou les exigences de bande passante de l'application. Nous utilisons ces connaissances pour affiner progressivement l'ensemble des ressources en supprimant les n\u0153uds inad\u00e9quats ou en ajoutant de nouveaux n\u0153uds si n\u00e9cessaire. Cette approche ne conduit pas \u00e0 un ensemble de ressources optimal, mais \u00e0 un ensemble de ressources raisonnable, c'est-\u00e0-direun ensemble exempt de divers goulots d'\u00e9tranglement en termes de performances tels que des connexions r\u00e9seau lentes ou des processeurs surcharg\u00e9s. Notre approche permet \u00e9galement \u00e0 l\u2019application de s\u2019adapter aux conditions changeantes du r\u00e9seau. Si l'efficacit\u00e9 moyenne pond\u00e9r\u00e9e descend en dessous d'un certain niveau, le coordinateur d'adaptation commence \u00e0 supprimer les n\u0153uds \u00ab pires \u00bb. Si l\u2019efficacit\u00e9 moyenne pond\u00e9r\u00e9e d\u00e9passe un certain niveau, de nouveaux n\u0153uds sont ajout\u00e9s. L'application s'adapte de mani\u00e8re enti\u00e8rement automatique aux conditions changeantes. Les travaux futurs consisteront \u00e0 \u00e9tendre notre strat\u00e9gie d\u2019adaptation pour soutenir les migrations opportunistes. Cela n\u00e9cessite toutefois des planificateurs de grille dot\u00e9s de fonctionnalit\u00e9s plus sophistiqu\u00e9es que celles qui existent actuellement. Des recherches suppl\u00e9mentaires sont \u00e9galement n\u00e9cessaires pour r\u00e9duire les frais g\u00e9n\u00e9raux d\u2019analyse comparative. Un autre axe de recherche que nous souhaitons \u00e9tudier consiste \u00e0 utiliser le contr\u00f4le par r\u00e9troaction pour affiner la strat\u00e9gie d'adaptation lors de l'ex\u00e9cution de l'application. Enfin, la mise en \u0153uvre centralis\u00e9e du coordinateur d'adaptation pourrait devenir un goulot d'\u00e9tranglement pour les applications qui s'ex\u00e9cutent sur un tr\u00e8s grand nombre de n\u0153uds -LRB- centaines ou milliers -RRB-.", "keyphrases": ["calcul en grille", "s\u00e9lection de ressources", "environnement de grille", "calcul parall\u00e8le", "environnement parall\u00e8le homog\u00e8ne", "h\u00e9t\u00e9rog\u00e8ne de la ressource", "r\u00e9seau local \u00e0 haut d\u00e9bit", "r\u00e9seau \u00e9tendu \u00e0 bande passante inf\u00e9rieure", "lien r\u00e9seau", "temps commun", "temps d'inactivit\u00e9 du processeur", "degr\u00e9 de parall\u00e8le", "surcharge des ressources", "diviser pour r\u00e9gner"]}
{"file_name": "I-19", "text": "Ench\u00e9rir de mani\u00e8re optimale lors d'ench\u00e8res simultan\u00e9es au deuxi\u00e8me prix de biens parfaitement substituables R\u00c9SUM\u00c9 Nous d\u00e9rivons des strat\u00e9gies d'ench\u00e8res optimales pour un agent d'ench\u00e8res mondial qui participe \u00e0 plusieurs ench\u00e8res simultan\u00e9es au deuxi\u00e8me prix avec des substituts parfaits. Nous consid\u00e9rons d\u2019abord un mod\u00e8le dans lequel tous les autres ench\u00e9risseurs sont locaux et participent \u00e0 une seule ench\u00e8re. Dans ce cas, nous prouvons que, en supposant la libre disposition, l'ench\u00e9risseur global devrait toujours placer des offres non nulles dans toutes les ench\u00e8res disponibles, quelle que soit la distribution de valorisation des ench\u00e9risseurs locaux. De plus, pour des distributions de valorisation non d\u00e9croissantes, nous prouvons que le probl\u00e8me de trouver les offres optimales se r\u00e9duit \u00e0 deux dimensions. Ces r\u00e9sultats sont valables aussi bien dans le cas o\u00f9 le nombre d'ench\u00e9risseurs locaux est connu que lorsque ce nombre est d\u00e9termin\u00e9 par une distribution de Poisson. Cette analyse s'\u00e9tend aux march\u00e9s en ligne o\u00f9, g\u00e9n\u00e9ralement, les ench\u00e8res se d\u00e9roulent \u00e0 la fois simultan\u00e9ment et s\u00e9quentiellement. De plus, en combinant les r\u00e9sultats d\u2019analyse et de simulation, nous d\u00e9montrons que des r\u00e9sultats similaires sont valables dans le cas de plusieurs soumissionnaires mondiaux, \u00e0 condition que le march\u00e9 soit compos\u00e9 \u00e0 la fois d\u2019ench\u00e9risseurs mondiaux et locaux. Enfin, nous abordons l'efficacit\u00e9 du march\u00e9 dans son ensemble et montrons que les informations sur le nombre d'ench\u00e9risseurs locaux sont un d\u00e9terminant important de la mani\u00e8re dont un ench\u00e9risseur mondial affecte l'efficacit\u00e9. 1. INTRODUCTION Le r\u00e9cent regain d'int\u00e9r\u00eat pour les ench\u00e8res en ligne a entra\u00een\u00e9 un nombre croissant d'ench\u00e8res proposant des objets tr\u00e8s similaires ou. Sur eBay seul, par exemple, il existe souvent des centaines, voire parfois des milliers d'ench\u00e8res simultan\u00e9es dans le monde entier vendant de tels objets substituables1. Dans ce context, il est essentiel de d\u00e9velopper des strat\u00e9gies d\u2019ench\u00e8res que les agents autonomes peuvent utiliser pour fonctionner efficacement sur un grand nombre d\u2019ench\u00e8res. Cependant, comme nous le montrerons, cette analyse est \u00e9galement pertinente dans un context plus large o\u00f9 les ench\u00e8res sont men\u00e9es de mani\u00e8re s\u00e9quentielle, ainsi que simultan\u00e9ment. En revanche, nous consid\u00e9rons ici les strat\u00e9gies d\u2019ench\u00e8res pour les march\u00e9s comportant plusieurs ench\u00e8res simultan\u00e9es et des substituts parfaits. En particulier, nous nous concentrons sur les ench\u00e8res Vickrey ou sur les ench\u00e8res scell\u00e9es au deuxi\u00e8me prix. Cependant, nos r\u00e9sultats se g\u00e9n\u00e9ralisent aux ench\u00e8res anglaises puisque celles-ci sont strat\u00e9giquement \u00e9quivalentes aux ench\u00e8res au second prix. Dans ce cadre, nous sommes en mesure de caract\u00e9riser, pour la premi\u00e8re fois, la strat\u00e9gie de maximisation de l'utilit\u00e9 d'un ench\u00e9risseur pour ench\u00e9rir simultan\u00e9ment dans un nombre quelconque d'ench\u00e8res de ce type et pour tout type de distribution de valorisation des ench\u00e9risseurs. De mani\u00e8re plus d\u00e9taill\u00e9e, nous consid\u00e9rons d\u2019abord un march\u00e9 dans lequel un seul ench\u00e9risseur, appel\u00e9 ench\u00e9risseur global, peut soumissionner dans un nombre quelconque d\u2019ench\u00e8res, alors que les autres ench\u00e9risseurs, appel\u00e9s ench\u00e9risseurs locaux, sont suppos\u00e9s ne soumissionner que dans une seule ench\u00e8re. Dans ce cas, nous trouvons les r\u00e9sultats suivants : \u2022 Alors que dans le cas d'une ench\u00e8re unique au second prix, la meilleure strat\u00e9gie d'un ench\u00e9risseur est d'ench\u00e9rir \u00e0 sa vraie valeur, la meilleure strat\u00e9gie pour un ench\u00e9risseur global est d'ench\u00e9rir en dessous. \u2022 Nous sommes en mesure de prouver que,m\u00eame si un ench\u00e9risseur global ne demande qu'un seul article, l'utilit\u00e9 attendue est maximis\u00e9e en participant \u00e0 toutes les ench\u00e8res qui vendent l'article souhait\u00e9. \u2022 Trouver l'offre optimale pour chaque ench\u00e8re peut \u00eatre une t\u00e2che ardue si l'on consid\u00e8re toutes les combinaisons possibles. Cependant, pour l'\u00e9valuation des soumissionnaires la plus courante, r\u00e9partissez 2. TRAVAUX CONNEXES La recherche dans le domaine des ench\u00e8res simultan\u00e9es peut \u00eatre segment\u00e9e selon deux grandes lignes. De telles analyses sont g\u00e9n\u00e9ralement utilis\u00e9es lorsque le format d'ench\u00e8res utilis\u00e9 dans les ench\u00e8res simultan\u00e9es est le m\u00eame -LRB-, par exemple s'il y a M ench\u00e8res Vickrey ou M ench\u00e8res au premier prix -RRB-. Cet article adopte la premi\u00e8re approche pour \u00e9tudier un march\u00e9 de M ench\u00e8res Vickrey simultan\u00e9es puisque cette approche donne des strat\u00e9gies d'ench\u00e8res prouv\u00e9es optimales. Leurs travaux analysent un march\u00e9 compos\u00e9 de couples ayant des \u00e9valuations \u00e9gales et souhaitant ench\u00e9rir sur une commode. Ainsi, l'espace d'ench\u00e8res du couple peut contenir au plus deux ench\u00e8res puisque le mari et la femme peuvent participer au maximum \u00e0 deux ench\u00e8res g\u00e9ographiquement r\u00e9parties simultan\u00e9ment. Ils d\u00e9rivent un \u00e9quilibre de Nash \u00e0 strat\u00e9gie mixte pour le cas particulier o\u00f9 le nombre d\u2019acheteurs est important. Notre analyse diff\u00e8re de la leur dans le sens o\u00f9 nous \u00e9tudions les ench\u00e8res concurrentes dans lesquelles les ench\u00e9risseurs ont des valorisations diff\u00e9rentes et l'ench\u00e9risseur global peut ench\u00e9rir simultan\u00e9ment sur toutes les ench\u00e8res -LRB-, ce qui est tout \u00e0 fait possible \u00e9tant donn\u00e9 les agents autonomes -RRB-. Dans la foul\u00e9e, -LSB- 7 -RSB- a ensuite \u00e9tudi\u00e9 le cas des ench\u00e8res simultan\u00e9es avec des biens compl\u00e9mentaires. Ils analysent le cas des soumissionnaires locaux et mondiaux et caract\u00e9risent les ench\u00e8res des acheteurs et l'efficacit\u00e9 du march\u00e9 qui en r\u00e9sulte. Le param\u00e8tre fourni dans -LSB- 7 -RSB- est \u00e9tendu au cas de valeurs communes dans -LSB- 9 -RSB-. Cependant, aucun de ces travaux ne s\u2019\u00e9tend facilement au cas des biens substituables que nous consid\u00e9rons. L\u2019espace des strat\u00e9gies d\u2019\u00e9quilibre mixte sym\u00e9trique est d\u00e9riv\u00e9 pour ce cas particulier, mais l\u00e0 encore notre r\u00e9sultat est plus g\u00e9n\u00e9ral. Enfin, -LSB- 11 -RSB- consid\u00e8re le cas des ench\u00e8res anglaises concurrentes, dans lesquelles il d\u00e9veloppe des algorithmes d'ench\u00e8res pour des acheteurs ayant des attitudes de risque diff\u00e9rentes. Cependant, il force les offres \u00e0 \u00eatre les m\u00eames d\u2019une vente aux ench\u00e8res \u00e0 l\u2019autre, ce qui, comme nous le montrons dans cet article, n\u2019est pas toujours optimal. 7. CONCLUSIONS Dans cet article, nous d\u00e9veloppons des strat\u00e9gies de maximisation de l'utilit\u00e9 pour ench\u00e9rir dans plusieurs ench\u00e8res simultan\u00e9es au deuxi\u00e8me prix. Nous analysons d\u2019abord le cas o\u00f9 un seul ench\u00e9risseur mondial ench\u00e9rit sur toutes les ench\u00e8res, alors que tous les autres ench\u00e9risseurs sont locaux et ench\u00e9rissent sur une seule ench\u00e8re. Pour ce param\u00e8tre, nous trouvons le r\u00e9sultat contre-intuitif selon lequel il est optimal de placer des offres non nulles dans toutes les ench\u00e8res qui vendent l'article souhait\u00e9, m\u00eame lorsqu'un ench\u00e9risseur n'a besoin que d'un seul article et ne tire aucun avantage suppl\u00e9mentaire d'en avoir plus. Ainsi, un acheteur potentiel peut obtenir un avantage consid\u00e9rable en participant \u00e0 plusieurs ench\u00e8res et en employant une strat\u00e9gie d\u2019ench\u00e8res optimale. Pour un certain nombre de distributions de valorisation courantes, nous montrons analytiquement que le probl\u00e8me de la recherche d'offres optimales se r\u00e9duit \u00e0 deux dimensions.Cela simplifie consid\u00e9rablement le probl\u00e8me d'optimisation initial et peut donc \u00eatre utilis\u00e9 en pratique pour calculer les offres optimales pour un nombre quelconque d'ench\u00e8res. De plus, nous \u00e9tudions un context avec plusieurs soumissionnaires mondiaux en combinant des solutions analytiques avec une approche de simulation. Nous constatons que la strat\u00e9gie d'un soumissionnaire mondial ne se stabilise pas lorsque seuls des soumissionnaires mondiaux sont pr\u00e9sents sur le march\u00e9, mais ne converge que lorsqu'il existe \u00e9galement des soumissionnaires locaux. Nous soutenons cependant que les march\u00e9s du monde r\u00e9el sont susceptibles de contenir \u00e0 la fois des soumissionnaires locaux et mondiaux. Les r\u00e9sultats converg\u00e9s sont alors tr\u00e8s similaires \u00e0 ceux d\u2019un seul ench\u00e9risseur global, et nous constatons qu\u2019un ench\u00e9risseur b\u00e9n\u00e9ficie d\u2019une offre optimale dans plusieurs ench\u00e8res. Pour le context plus complexe avec plusieurs ench\u00e9risseurs globaux, la simulation peut ainsi \u00eatre utilis\u00e9e pour trouver ces offres pour des cas sp\u00e9cifiques. Enfin, nous comparons l\u2019efficacit\u00e9 d\u2019un march\u00e9 avec plusieurs ench\u00e8res simultan\u00e9es avec et sans ench\u00e9risseur global. Nous montrons que si l\u2019ench\u00e9risseur peut pr\u00e9dire avec pr\u00e9cision le nombre d\u2019ench\u00e9risseurs locaux dans chaque ench\u00e8re, l\u2019efficacit\u00e9 augmente l\u00e9g\u00e8rement. En revanche, s\u2019il y a beaucoup d\u2019incertitude, l\u2019efficacit\u00e9 diminue consid\u00e9rablement \u00e0 mesure que le nombre d\u2019ench\u00e8res augmente en raison de la probabilit\u00e9 accrue qu\u2019un ench\u00e9risseur global remporte plus de deux articles. Ces r\u00e9sultats montrent que la mani\u00e8re dont l\u2019efficacit\u00e9, et donc le bien-\u00eatre social, est affect\u00e9e par un soumissionnaire global d\u00e9pend des informations dont dispose ce soumissionnaire global. Dans des travaux futurs, nous avons l'intention d'\u00e9tendre les r\u00e9sultats aux substituts imparfaits -LRB-, c'est-\u00e0-dire lorsqu'un ench\u00e9risseur global gagne en remportant des articles suppl\u00e9mentaires -RRB-, et \u00e0 des contexts o\u00f9 les ench\u00e8res ne sont plus identiques. Ce dernier cas se produit, par exemple, lorsque le nombre d'ench\u00e9risseurs -LRB- moyens -RRB- locaux diff\u00e8re par vente aux ench\u00e8res ou lorsque les ench\u00e8res ont des param\u00e8tres diff\u00e9rents tels que le prix de r\u00e9serve.l'efficacit\u00e9 diminue consid\u00e9rablement \u00e0 mesure que le nombre d'ench\u00e8res augmente en raison de la probabilit\u00e9 accrue qu'un ench\u00e9risseur global remporte plus de deux articles. Ces r\u00e9sultats montrent que la mani\u00e8re dont l\u2019efficacit\u00e9, et donc le bien-\u00eatre social, est affect\u00e9e par un soumissionnaire global d\u00e9pend des informations dont dispose ce soumissionnaire global. Dans des travaux futurs, nous avons l'intention d'\u00e9tendre les r\u00e9sultats aux substituts imparfaits -LRB-, c'est-\u00e0-dire lorsqu'un ench\u00e9risseur global gagne en remportant des articles suppl\u00e9mentaires -RRB-, et \u00e0 des contexts o\u00f9 les ench\u00e8res ne sont plus identiques. Ce dernier cas se produit, par exemple, lorsque le nombre d'ench\u00e9risseurs -LRB- moyens -RRB- locaux diff\u00e8re par vente aux ench\u00e8res ou lorsque les ench\u00e8res ont des param\u00e8tres diff\u00e9rents tels que le prix de r\u00e9serve.l'efficacit\u00e9 diminue consid\u00e9rablement \u00e0 mesure que le nombre d'ench\u00e8res augmente en raison de la probabilit\u00e9 accrue qu'un ench\u00e9risseur global remporte plus de deux articles. Ces r\u00e9sultats montrent que la mani\u00e8re dont l\u2019efficacit\u00e9, et donc le bien-\u00eatre social, est affect\u00e9e par un soumissionnaire global d\u00e9pend des informations dont dispose ce soumissionnaire global. Dans des travaux futurs, nous avons l'intention d'\u00e9tendre les r\u00e9sultats aux substituts imparfaits -LRB-, c'est-\u00e0-dire lorsqu'un ench\u00e9risseur global gagne en remportant des articles suppl\u00e9mentaires -RRB-, et \u00e0 des contexts o\u00f9 les ench\u00e8res ne sont plus identiques. Ce dernier cas se produit, par exemple, lorsque le nombre d'ench\u00e9risseurs -LRB- moyens -RRB- locaux diff\u00e8re par vente aux ench\u00e8res ou lorsque les ench\u00e8res ont des param\u00e8tres diff\u00e9rents tels que le prix de r\u00e9serve.", "keyphrases": ["strat\u00e9gie d'ench\u00e8res optimales", "agent d'ench\u00e8res global", "ench\u00e8res simultan\u00e9es au deuxi\u00e8me prix", "distribution de valeur non d\u00e9croissante", "march\u00e9 en ligne", "syst\u00e8me multiag", "efficacit\u00e9 du march\u00e9", "substitut parfait", "vente aux ench\u00e8res Vickrei", "sciences sociales et comportementales", "strat\u00e9gies d'utilit\u00e9 maximale"]}
{"file_name": "J-2", "text": "Dans le pire des cas, redistribution optimale des paiements VCG dans les ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec demande unitaire R\u00c9SUM\u00c9 De nombreux probl\u00e8mes importants dans les syst\u00e8mes multi-agents impliquent l'allocation de plusieurs ressources entre les agents. Pour les probl\u00e8mes d\u2019allocation de ressources, le m\u00e9canisme VCG bien connu satisfait une liste de propri\u00e9t\u00e9s souhait\u00e9es, notamment l\u2019efficacit\u00e9, la r\u00e9sistance \u00e0 la strat\u00e9gie, la rationalit\u00e9 individuelle et la propri\u00e9t\u00e9 de non-d\u00e9ficit. Cependant, VCG n\u2019a g\u00e9n\u00e9ralement pas un budget \u00e9quilibr\u00e9. Dans le cadre du VCG, les agents paient les paiements du VCG, ce qui r\u00e9duit le bien-\u00eatre social. Pour compenser la perte de protection sociale due aux paiements du VCG, des m\u00e9canismes de redistribution du VCG ont \u00e9t\u00e9 introduits. Ces m\u00e9canismes visent \u00e0 redistribuer autant de paiements VCG aux agents que possible, tout en conservant les propri\u00e9t\u00e9s souhait\u00e9es du m\u00e9canisme VCG susmentionn\u00e9es. Nous poursuivons la recherche de m\u00e9canismes de redistribution optimaux du VCG dans le pire des cas \u2013 des m\u00e9canismes qui maximisent la fraction du paiement total du VCG redistribu\u00e9e dans le pire des cas. Auparavant, un m\u00e9canisme de redistribution VCG optimal -LRB-, not\u00e9 WCO -RRB-, \u00e9tait caract\u00e9ris\u00e9 pour les ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes -LSB- 7 -RSB-. Plus tard, l'OMD a \u00e9t\u00e9 g\u00e9n\u00e9ralis\u00e9e \u00e0 des contexts impliquant des \u00e9l\u00e9ments h\u00e9t\u00e9rog\u00e8nes -LSB- 4 -RSB-, aboutissant au m\u00e9canisme HETERO. -LSB- 4 -RSB- a suppos\u00e9 qu'HETERO est r\u00e9alisable et, dans le pire des cas, optimal pour les ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire. Dans cet article, nous proposons une mani\u00e8re plus naturelle de g\u00e9n\u00e9raliser le m\u00e9canisme de l\u2019OMD. Nous prouvons que notre m\u00e9canisme g\u00e9n\u00e9ralis\u00e9, bien que repr\u00e9sent\u00e9 diff\u00e9remment, co\u00efncide en r\u00e9alit\u00e9 avec HETERO. Sur la base de cette nouvelle repr\u00e9sentation de HETERO, nous prouvons qu\u2019HETERO est effectivement r\u00e9alisable et, dans le pire des cas, optimal dans les ench\u00e8res d\u2019articles h\u00e9t\u00e9rog\u00e8nes avec demande unitaire. Enfin, nous conjecturons qu'HETERO reste r\u00e9alisable et, dans le pire des cas, optimal dans le cadre encore plus g\u00e9n\u00e9ral des ench\u00e8res combinatoires avec substituts bruts. 1. INTRODUCTION 1.1 M\u00e9canismes de redistribution VCG De nombreux probl\u00e8mes importants dans les syst\u00e8mes multi-agents impliquent l'allocation de plusieurs ressources entre les agents. Pour les probl\u00e8mes d'allocation de ressources, le m\u00e9canisme bien connu VCG satisfait la liste de propri\u00e9t\u00e9s souhait\u00e9es suivante : \u2022 Efficacit\u00e9 : l'allocation maximise la valorisation totale des agents -LRB- sans consid\u00e9rer les paiements -RRB-. \u2022 R\u00e9sistance \u00e0 la strat\u00e9gie : pour tout agent, rendre compte de mani\u00e8re v\u00e9ridique est une strat\u00e9gie dominante, quel que soit le type des autres agents. \u2022 -LRB- Ex post -RRB- rationalit\u00e9 individuelle : L'utilit\u00e9 finale -LRB- de chaque agent apr\u00e8s d\u00e9duction de son paiement -RRB- est toujours non n\u00e9gative. \u2022 Non d\u00e9ficitaire : le paiement total des agents est non n\u00e9gatif. Cependant, VCG n\u2019a g\u00e9n\u00e9ralement pas un budget \u00e9quilibr\u00e9. Dans le cadre du VCG, les agents paient les paiements du VCG, ce qui r\u00e9duit le bien-\u00eatre social. Pour compenser la perte de protection sociale due aux paiements du VCG, des m\u00e9canismes de redistribution du VCG ont \u00e9t\u00e9 introduits. Ces m\u00e9canismes allouent toujours les ressources \u00e0 l'aide de VCG. En plus de VCG,ces m\u00e9canismes tentent de redistribuer autant de paiements VCG que possible aux agents. Nous exigeons que la redistribution d'un agent soit ind\u00e9pendante de son propre type. Ceci est suffisant pour maintenir la s\u00e9curit\u00e9 strat\u00e9gique et l'efficacit\u00e9 -LRB-, un agent n'ayant aucun contr\u00f4le sur sa propre redistribution -RRB-. Pour les domaines connect\u00e9s en douceur -LRB-, y compris les ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes et les ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire -RRB-, l'exigence ci-dessus est \u00e9galement n\u00e9cessaire pour maintenir la s\u00e9curit\u00e9 et l'efficacit\u00e9 de la strat\u00e9gie -LSB- 8 -RSB-. Un m\u00e9canisme de redistribution VCG est r\u00e9alisable s'il conserve toutes les propri\u00e9t\u00e9s souhait\u00e9es du m\u00e9canisme VCG. Autrement dit, nous exigeons \u00e9galement que le processus de redistribution pr\u00e9serve la rationalit\u00e9 individuelle et la propri\u00e9t\u00e9 non d\u00e9ficitaire. Soit n le nombre d'agents. Puisque tous les m\u00e9canismes de redistribution VCG commencent par allouer selon le m\u00e9canisme VCG, un m\u00e9canisme de redistribution VCG est caract\u00e9ris\u00e9 par son sch\u00e9ma de redistribution r ~ = -LRB- r1, r2,..., rn -RRB-. Sous le m\u00e9canisme de redistribution VCG ~ r, la redistribution de l'agent i est \u00e9gale \u00e0 ri -LRB- 01,..., 0i \u2212 1, 0i +1,..., 0n -RRB-, o\u00f9 0j est le type de l'agent j. -LRB- Nous n'avons pas besoin de faire la diff\u00e9rence entre le vrai type d'un agent et son type rapport\u00e9, puisque tous les m\u00e9canismes de redistribution VCG sont \u00e0 l'\u00e9preuve des strat\u00e9gies. -RRB- Un m\u00e9canisme de redistribution anonyme de VCG est caract\u00e9ris\u00e9 par une seule fonction r. Sous le m\u00e9canisme de redistribution -LRB-anonyme-RRB- VCG r, la redistribution de l'agent i est \u00e9gale \u00e0 r -LRB- 0 \u2212 i -RRB-, o\u00f9 0 \u2212 i est le multiensemble des types d'agents autres que i. Nous utilisons \u03b8 ~ pour d\u00e9signer le profil de type. Soit V CG -LRB- ~ \u03b8 -RRB- le total. Nous organisons les r\u00e9sultats existants en fonction de leurs param\u00e8tres. Paiement VCG pour ce profil de type. Un m\u00e9canisme de redistribution VCG r satisfait la propri\u00e9t\u00e9 non d\u00e9ficitaire si la redistribution totale ne d\u00e9passe jamais le paiement total VCG. Un m\u00e9canisme de redistribution VCG r est -LRB- ex post -RRB- individuellement rationnel si l'utilit\u00e9 finale de chaque agent est toujours non n\u00e9gative. Apr\u00e8s redistribution, l'utilit\u00e9 de l'agent i est exactement sa redistribution r -LRB- \u03b8 \u2212 i -RRB-. Nous souhaitons trouver des m\u00e9canismes de redistribution des VCG qui maximisent la fraction du paiement total des VCG redistribu\u00e9e dans le pire des cas. Ce probl\u00e8me de conception de m\u00e9canisme est \u00e9quivalent au mod\u00e8le d'optimisation fonctionnelle suivant\u00a0: Dans cet article, nous caract\u00e9riserons analytiquement un m\u00e9canisme de redistribution VCG optimal dans le pire des cas pour les ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec demande unitaire.1 Nous concluons cette sous-section avec un exemple de m\u00e9canisme de redistribution VCG dans le cadre le plus simple des ench\u00e8res d\u2019un seul article. Dans une vente aux ench\u00e8res d'un seul objet, le type d'un agent est un nombre r\u00e9el non n\u00e9gatif repr\u00e9sentant son utilit\u00e9 pour remporter l'objet. Dans les ench\u00e8res \u00e0 objet unique, le m\u00e9canisme de redistribution Bailey-Cavallo VCG -LSB- 2, 3 -RSB- fonctionne comme suit : \u2022 Allouer l'objet selon VCG : L'agent 1 remporte l'objet et paie \u03b82. Les autres agents ne gagnent rien et ne paient pas.\u2022 Chaque agent re\u00e7oit une redistribution \u00e9gale \u00e0 n1 fois le deuxi\u00e8me autre type le plus \u00e9lev\u00e9 : les agents 1 et 2 re\u00e7oivent chacun n1 \u03b83. Les autres agents re\u00e7oivent chacun n1\u03b82. Le m\u00e9canisme ci-dessus maintient \u00e9videmment la r\u00e9sistance \u00e0 la strat\u00e9gie et l'efficacit\u00e9 -LRB-. La redistribution d'un agent ne d\u00e9pend pas de son propre type -RRB-. Cela maintient \u00e9galement la rationalit\u00e9 individuelle car toutes les redistributions sont non n\u00e9gatives. La redistribution totale est \u00e9gale \u00e0 2n \u03b83 + le m\u00e9canisme ci-dessus maintient la propri\u00e9t\u00e9 de non-d\u00e9ficit. Enfin, pour la redistribution totale de 2 n ench\u00e8res d'articles, la fraction de redistribution dans le pire des cas de cet exemple de m\u00e9canisme est n \u2212 2 n 1.2 Recherches ant\u00e9rieures sur les m\u00e9canismes de redistribution optimaux des VCG dans le pire des cas Dans cette sous-section, nous passons en revue les r\u00e9sultats existants sur les m\u00e9canismes de redistribution optimaux des VCG dans le pire des cas. m\u00e9canismes de redistribution. Redistribution optimale dans le pire des cas dans les ench\u00e8res multi-unit\u00e9s avec demande unitaire -LSB- 7, 12 -RSB- : Dans les ench\u00e8res multi-unit\u00e9s avec demande unitaire, les articles \u00e0 vendre sont identiques. Chaque agent souhaite au plus une copie de l'\u00e9l\u00e9ment. -LRB- Les ench\u00e8res \u00e0 article unique sont des cas particuliers d'ench\u00e8res \u00e0 unit\u00e9s multiples avec demande unitaire. -RRB- Soit m le nombre d'\u00e9l\u00e9ments. Tout au long de cet article, nous consid\u00e9rons uniquement les cas o\u00f9 m \u2264 n \u2212 2.2 Ici, le type d'un agent est un nombre r\u00e9el non n\u00e9gatif repr\u00e9sentant sa valorisation pour avoir gagn\u00e9 un exemplaire de l'article. -LSB- 7 -RSB- a \u00e9galement caract\u00e9ris\u00e9 un m\u00e9canisme de redistribution VCG pour les ench\u00e8res multi-unit\u00e9s avec demande d'unit\u00e9s, appel\u00e9 m\u00e9canisme de l'OMD.3 La fraction de redistribution la plus d\u00e9favorable de l'OMD est exactement \u03b1 \u2217. Autrement dit, c\u2019est le pire des cas optimal. L'OMD a \u00e9t\u00e9 obtenu en optimisant au sein de la famille des m\u00e9canismes de redistribution lin\u00e9aires du VCG. Un m\u00e9canisme de redistribution VCG lin\u00e9aire r prend la forme suivante : Ici, les ci sont des constantes. -LRB- Nous ne consid\u00e9rons que les ci qui correspondent \u00e0 des m\u00e9canismes de redistribution VCG r\u00e9alisables. -RRB- -LSB- \u03b8 \u2212 i -RSB- j est le j-\u00e8me type le plus \u00e9lev\u00e9 parmi \u03b8 \u2212 i. Le m\u00e9canisme lin\u00e9aire r est caract\u00e9ris\u00e9 par les valeurs de ci. Les valeurs optimales ci sont les suivantes : La caract\u00e9risation de l'OMD est alors la suivante : Redistribution optimale dans le pire des cas dans les ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes -LSB- 7 -RSB- : Ench\u00e8res multi-unit\u00e9s avec non2 -LSB- 7 -RSB - a montr\u00e9 que pour les ench\u00e8res multi-unit\u00e9s avec demande unitaire, lorsque m = n \u2212 1, la fraction de redistribution la plus d\u00e9favorable -LRB- de tout m\u00e9canisme de redistribution VCG r\u00e9alisable -RRB- est au plus \u00e9gale \u00e0 0. Puisque le param\u00e8tre \u00e9tudi\u00e9 dans cet article est plus g\u00e9n\u00e9rales -LRB- pour des ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire -RRB-, nous avons \u00e9galement que la fraction de redistribution dans le pire des cas est au plus \u00e9gale \u00e0 0 lorsque m = n \u2212 1. Puisque les ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec x unit\u00e9s sont des cas particuliers d'ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec x unit\u00e9s -ench\u00e8res d'articles avec x + 1 unit\u00e9s, nous avons que pour notre param\u00e8tre, la fraction de redistribution dans le pire des cas est au plus \u00e9gale \u00e0 0 lorsque m \u2265 n \u2212 1. Autrement dit, ne rien redistribuer est optimal dans le pire des cas lorsque m \u2265 n \u2212 1. De plus, pour l'objectif de -LSB- 12 -RSB- , le m\u00e9canisme optimal co\u00efncide avec l'OMD uniquement lorsque la contrainte de rationalit\u00e9 individuelle est appliqu\u00e9e.L\u2019augmentation des valeurs marginales est plus g\u00e9n\u00e9rale que les ench\u00e8res multi-unit\u00e9s avec demande unitaire. Dans ce context plus g\u00e9n\u00e9ral, les \u00e9l\u00e9ments sont toujours identiques, mais un agent peut exiger plus d'une copie de l'\u00e9l\u00e9ment. L'\u00e9valuation d'un agent pour avoir remport\u00e9 le premier exemplaire de l'article est appel\u00e9e sa valeur marginale initiale/premi\u00e8re. De m\u00eame, la valorisation suppl\u00e9mentaire d'un agent pour avoir remport\u00e9 le i-\u00e8me exemplaire de l'article est appel\u00e9e sa i-\u00e8me valeur marginale. Le type d'un agent contient m nombres r\u00e9els non n\u00e9gatifs -LRB- i-i\u00e8me valeur marginale pour i = 1,..., m -RRB-. Dans ce context, on suppose en outre que les valeurs marginales ne augmentent pas. Comme indiqu\u00e9 pr\u00e9c\u00e9demment, dans ce context plus g\u00e9n\u00e9ral, la fraction de redistribution la plus d\u00e9favorable de tout m\u00e9canisme de redistribution VCG est toujours limit\u00e9e au-dessus par \u03b1 *. -LSB- 7 -RSB- a g\u00e9n\u00e9ralis\u00e9 l'OMD \u00e0 ce param\u00e8tre et a prouv\u00e9 que sa fraction de redistribution dans le pire des cas reste la m\u00eame. Par cons\u00e9quent, WCO -LRB- apr\u00e8s g\u00e9n\u00e9ralisation -RRB- est \u00e9galement optimal dans le pire des cas pour les ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes. La d\u00e9finition originale de l'OMD ne se g\u00e9n\u00e9ralise pas directement aux ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes. Lorsqu'il s'agit d'ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes, le type d'un agent n'est plus une valeur unique, ce qui signifie qu'il n'existe pas de \u00ab j-\u00e8me type le plus \u00e9lev\u00e9 parmi \u03b8_i \u00bb. On abuse de la notation en ne diff\u00e9renciant pas les agents et leurs types. Par exemple, \u03b8_i est \u00e9quivalent \u00e0 l\u2019ensemble des agents autres que i. Soit S un ensemble d'agents. je \u2212 1 -RRB-. Ici, U -LRB- S, j -RRB- est le nouvel ensemble d'agents, apr\u00e8s avoir retir\u00e9 de S l'agent ayant la j-i\u00e8me valeur marginale initiale la plus \u00e9lev\u00e9e dans S. La forme g\u00e9n\u00e9rale de l'OMD est la suivante\u00a0: Pire des cas optimaux Redistribution dans les ench\u00e8res d'objets h\u00e9t\u00e9rog\u00e8nes \u00e0 demande unitaire -LSB- 4 -RSB- : Dans les ench\u00e8res d'objets h\u00e9t\u00e9rog\u00e8nes \u00e0 demande unitaire, les articles \u00e0 vendre sont diff\u00e9rents. Chaque agent demande au plus un objet. Ici, le type d'un agent se compose de m nombres r\u00e9els non n\u00e9gatifs -LRB- sa valorisation pour l'article gagnant i pour i = 1,..., m -RRB-. Les ench\u00e8res d\u2019articles h\u00e9t\u00e9rog\u00e8nes avec demande unitaire constituent le principal objectif de cet article. \u00c9tant donn\u00e9 que les ench\u00e8res d\u2019articles h\u00e9t\u00e9rog\u00e8nes avec demande unitaire sont plus g\u00e9n\u00e9rales que les ench\u00e8res multi-unit\u00e9s avec demande unitaire, \u03b1 * reste une limite sup\u00e9rieure de la fraction de redistribution la plus d\u00e9favorable. -LSB- 4 -RSB- a propos\u00e9 le m\u00e9canisme HETERO, en g\u00e9n\u00e9ralisant l'OMD. Les auteurs ont suppos\u00e9 qu'HETERO \u00e9tait r\u00e9alisable et avait une fraction de redistribution dans le pire des cas \u00e9gale \u00e0 \u03b1 *. Autrement dit, les auteurs ont suppos\u00e9 que HETERO \u00e9tait optimal dans le pire des cas dans ce context. La principale contribution de cet article est une preuve de cette conjecture. Redistribution dans les ench\u00e8res combinatoires avec substituts bruts -LSB- 6 -RSB- : La condition des substituts bruts a \u00e9t\u00e9 propos\u00e9e pour la premi\u00e8re fois dans -LSB- 9 -RSB-. Comme la demande unitaire, la condition de substitution brute est une condition sur le type d'agent -LRB- qui ne d\u00e9pend pas du m\u00e9canisme en discussion -RRB-. Dans les mots,le type d'un agent satisfait \u00e0 la condition de substitution brute si sa demande pour un article ne diminue pas lorsque les prix des autres articles augmentent. Les ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes et les ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec demande unitaire sont des cas particuliers d'ench\u00e8res combinatoires avec substituts bruts -LSB- 5, 9 -RSB-. Les auteurs n\u2019ont pas trouv\u00e9 de m\u00e9canisme optimal dans le pire des cas pour ce param\u00e8tre. \u00c0 la fin de cet article, nous conjecturons qu'HETERO est optimal pour les ench\u00e8res combinatoires avec substituts bruts. Enfin, Naroditskiy et al. -LSB- 13 -RSB- a propos\u00e9 une technique num\u00e9rique pour concevoir des m\u00e9canismes de redistribution optimaux dans le pire des cas. La technique propos\u00e9e ne fonctionne que pour les domaines \u00e0 param\u00e8tre unique. Cela ne s'applique pas \u00e0 notre param\u00e8tre -LRB- domaine multiparam\u00e9trique -RRB-. 1.3 Notre contribution Nous g\u00e9n\u00e9ralisons l'OMD aux ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes \u00e0 demande unitaire. Nous prouvons que le m\u00e9canisme g\u00e9n\u00e9ralis\u00e9, bien que repr\u00e9sent\u00e9 diff\u00e9remment, co\u00efncide avec le m\u00e9canisme HETERO propos\u00e9 dans -LSB- 4 -RSB-. Autrement dit, ce que nous proposons n\u2019est pas un nouveau m\u00e9canisme, mais une nouvelle repr\u00e9sentation d\u2019un m\u00e9canisme existant. Sur la base de notre nouvelle repr\u00e9sentation de HETERO, nous prouvons qu'HETERO est effectivement r\u00e9alisable et, dans le pire des cas, optimal lorsqu'il est appliqu\u00e9 \u00e0 des ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire, confirmant ainsi la conjecture soulev\u00e9e dans -LSB- 4 -RSB-. Nous concluons avec une nouvelle conjecture selon laquelle HETERO reste r\u00e9alisable et, dans le pire des cas, optimal dans le cadre encore plus g\u00e9n\u00e9ral des ench\u00e8res combinatoires avec substituts bruts. 4. CONCLUSION Nous concluons notre article avec la conjecture suivante : CONJECTURE 1. Les substituts bruts impliquent une monotonie de redistribution. Autrement dit, HETERO reste r\u00e9alisable et, dans le pire des cas, optimal dans les ench\u00e8res combinatoires avec substituts bruts. L\u2019id\u00e9e est que les ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes et les ench\u00e8res d\u2019articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire satisfont \u00e0 la monotonie de la redistribution. Une conjecture naturelle est que la \u00ab jointure la plus restrictive \u00bb de ces deux contexts satisfait \u00e9galement \u00e0 la monotonie de la redistribution. Il existe de nombreux param\u00e8tres d'ench\u00e8res bien \u00e9tudi\u00e9s qui contiennent \u00e0 la fois des ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes et des ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire -LRB- dont une liste peut \u00eatre trouv\u00e9e dans -LSB- 10 -RSB- -RRB-. Parmi ces contexts bien \u00e9tudi\u00e9s, les ench\u00e8res combinatoires avec substitutions brutes sont les plus restrictives.-LSB- 13 -RSB- a propos\u00e9 une technique num\u00e9rique pour concevoir des m\u00e9canismes de redistribution optimaux dans le pire des cas. La technique propos\u00e9e ne fonctionne que pour les domaines \u00e0 param\u00e8tre unique. Cela ne s'applique pas \u00e0 notre param\u00e8tre -LRB- domaine multiparam\u00e9trique -RRB-. 1.3 Notre contribution Nous g\u00e9n\u00e9ralisons l'OMD aux ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes \u00e0 demande unitaire. Nous prouvons que le m\u00e9canisme g\u00e9n\u00e9ralis\u00e9, bien que repr\u00e9sent\u00e9 diff\u00e9remment, co\u00efncide avec le m\u00e9canisme HETERO propos\u00e9 dans -LSB- 4 -RSB-. Autrement dit, ce que nous proposons n\u2019est pas un nouveau m\u00e9canisme, mais une nouvelle repr\u00e9sentation d\u2019un m\u00e9canisme existant. Sur la base de notre nouvelle repr\u00e9sentation de HETERO, nous prouvons qu'HETERO est effectivement r\u00e9alisable et, dans le pire des cas, optimal lorsqu'il est appliqu\u00e9 \u00e0 des ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire, confirmant ainsi la conjecture soulev\u00e9e dans -LSB- 4 -RSB-. Nous concluons avec une nouvelle conjecture selon laquelle HETERO reste r\u00e9alisable et, dans le pire des cas, optimal dans le cadre encore plus g\u00e9n\u00e9ral des ench\u00e8res combinatoires avec substituts bruts. 4. CONCLUSION Nous concluons notre article avec la conjecture suivante : CONJECTURE 1. Les substituts bruts impliquent une monotonie de redistribution. Autrement dit, HETERO reste r\u00e9alisable et, dans le pire des cas, optimal dans les ench\u00e8res combinatoires avec substituts bruts. L\u2019id\u00e9e est que les ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes et les ench\u00e8res d\u2019articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire satisfont \u00e0 la monotonie de la redistribution. Une conjecture naturelle est que la \u00ab jointure la plus restrictive \u00bb de ces deux contexts satisfait \u00e9galement \u00e0 la monotonie de la redistribution. Il existe de nombreux param\u00e8tres d'ench\u00e8res bien \u00e9tudi\u00e9s qui contiennent \u00e0 la fois des ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes et des ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire -LRB- dont une liste peut \u00eatre trouv\u00e9e dans -LSB- 10 -RSB- -RRB-. Parmi ces contexts bien \u00e9tudi\u00e9s, les ench\u00e8res combinatoires avec substitutions brutes sont les plus restrictives.-LSB- 13 -RSB- a propos\u00e9 une technique num\u00e9rique pour concevoir des m\u00e9canismes de redistribution optimaux dans le pire des cas. La technique propos\u00e9e ne fonctionne que pour les domaines \u00e0 param\u00e8tre unique. Cela ne s'applique pas \u00e0 notre param\u00e8tre -LRB- domaine multiparam\u00e9trique -RRB-. 1.3 Notre contribution Nous g\u00e9n\u00e9ralisons l'OMD aux ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes \u00e0 demande unitaire. Nous prouvons que le m\u00e9canisme g\u00e9n\u00e9ralis\u00e9, bien que repr\u00e9sent\u00e9 diff\u00e9remment, co\u00efncide avec le m\u00e9canisme HETERO propos\u00e9 dans -LSB- 4 -RSB-. Autrement dit, ce que nous proposons n\u2019est pas un nouveau m\u00e9canisme, mais une nouvelle repr\u00e9sentation d\u2019un m\u00e9canisme existant. Sur la base de notre nouvelle repr\u00e9sentation de HETERO, nous prouvons qu'HETERO est effectivement r\u00e9alisable et, dans le pire des cas, optimal lorsqu'il est appliqu\u00e9 \u00e0 des ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire, confirmant ainsi la conjecture soulev\u00e9e dans -LSB- 4 -RSB-. Nous concluons avec une nouvelle conjecture selon laquelle HETERO reste r\u00e9alisable et, dans le pire des cas, optimal dans le cadre encore plus g\u00e9n\u00e9ral des ench\u00e8res combinatoires avec substituts bruts. 4. CONCLUSION Nous concluons notre article avec la conjecture suivante : CONJECTURE 1. Les substituts bruts impliquent une monotonie de redistribution. Autrement dit, HETERO reste r\u00e9alisable et, dans le pire des cas, optimal dans les ench\u00e8res combinatoires avec substituts bruts. L\u2019id\u00e9e est que les ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes et les ench\u00e8res d\u2019articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire satisfont \u00e0 la monotonie de la redistribution. Une conjecture naturelle est que la \u00ab jointure la plus restrictive \u00bb de ces deux contexts satisfait \u00e9galement \u00e0 la monotonie de la redistribution. Il existe de nombreux param\u00e8tres d'ench\u00e8res bien \u00e9tudi\u00e9s qui contiennent \u00e0 la fois des ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes et des ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire -LRB- dont une liste peut \u00eatre trouv\u00e9e dans -LSB- 10 -RSB- -RRB-. Parmi ces contexts bien \u00e9tudi\u00e9s, les ench\u00e8res combinatoires avec substitutions brutes sont les plus restrictives.L\u2019id\u00e9e est que les ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes et les ench\u00e8res d\u2019articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire satisfont \u00e0 la monotonie de la redistribution. Une conjecture naturelle est que la \u00ab jointure la plus restrictive \u00bb de ces deux contexts satisfait \u00e9galement \u00e0 la monotonie de la redistribution. Il existe de nombreux param\u00e8tres d'ench\u00e8res bien \u00e9tudi\u00e9s qui contiennent \u00e0 la fois des ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes et des ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire -LRB- dont une liste peut \u00eatre trouv\u00e9e dans -LSB- 10 -RSB- -RRB-. Parmi ces contexts bien \u00e9tudi\u00e9s, les ench\u00e8res combinatoires avec substitutions brutes sont les plus restrictives.L\u2019id\u00e9e est que les ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes et les ench\u00e8res d\u2019articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire satisfont \u00e0 la monotonie de la redistribution. Une conjecture naturelle est que la \u00ab jointure la plus restrictive \u00bb de ces deux contexts satisfait \u00e9galement \u00e0 la monotonie de la redistribution. Il existe de nombreux param\u00e8tres d'ench\u00e8res bien \u00e9tudi\u00e9s qui contiennent \u00e0 la fois des ench\u00e8res multi-unit\u00e9s avec des valeurs marginales non croissantes et des ench\u00e8res d'articles h\u00e9t\u00e9rog\u00e8nes avec une demande unitaire -LRB- dont une liste peut \u00eatre trouv\u00e9e dans -LSB- 10 -RSB- -RRB-. Parmi ces contexts bien \u00e9tudi\u00e9s, les ench\u00e8res combinatoires avec substitutions brutes sont les plus restrictives.", "keyphrases": ["conception m\u00e9canique", "Vickrei-Clark-grove", "redistribuer le paiement", "m\u00e9canisme efficace", "\u00e0 l'\u00e9preuve des strat\u00e9gies", "m\u00e9canisme de ration individuelle", "m\u00e9canicien", "m\u00e9canisme de redistribution vcg lin\u00e9aire", "transformer en programme lin\u00e9aire", "personnage d'analyste", "m\u00e9canisme optimal dans le pire des cas"]}
{"file_name": "H-4", "text": "Vers des \u00e9valuations de la gestion des informations personnelles bas\u00e9es sur les t\u00e2ches R\u00c9SUM\u00c9 La gestion des informations personnelles -LRB-PIM-RRB- est un domaine de recherche en croissance rapide qui s'int\u00e9resse \u00e0 la mani\u00e8re dont les gens stockent, g\u00e8rent et retrouvent les informations. Une caract\u00e9ristique de la recherche PIM est que de nombreux syst\u00e8mes ont \u00e9t\u00e9 con\u00e7us pour aider les utilisateurs \u00e0 g\u00e9rer et \u00e0 retrouver des informations, mais tr\u00e8s peu ont \u00e9t\u00e9 \u00e9valu\u00e9s. Cela a \u00e9t\u00e9 not\u00e9 par plusieurs chercheurs et expliqu\u00e9 par les difficult\u00e9s li\u00e9es \u00e0 la r\u00e9alisation des \u00e9valuations PIM. Les difficult\u00e9s incluent le fait que les gens retrouvent des informations \u00e0 partir de collections personnelles uniques ; les chercheurs savent peu de choses sur les t\u00e2ches qui am\u00e8nent les gens \u00e0 retrouver des informations ; et de nombreux probl\u00e8mes de confidentialit\u00e9 concernant les informations personnelles. Dans cet article, nous visons \u00e0 faciliter les \u00e9valuations PIM en abordant chacune de ces difficult\u00e9s. Dans la premi\u00e8re partie, nous pr\u00e9sentons une \u00e9tude de journal des t\u00e2ches de recherche d'informations. L'\u00e9tude examine le type de t\u00e2ches qui n\u00e9cessitent que les utilisateurs retrouvent des informations et produit une taxonomie des t\u00e2ches de recherche pour les messages \u00e9lectroniques et les pages Web. Dans la deuxi\u00e8me partie, nous proposons une m\u00e9thodologie d'\u00e9valuation bas\u00e9e sur les t\u00e2ches bas\u00e9e sur nos r\u00e9sultats et examinons la faisabilit\u00e9 de l'approche en utilisant deux m\u00e9thodes diff\u00e9rentes de cr\u00e9ation de t\u00e2ches. 1. INTRODUCTION La gestion des informations personnelles -LRB-PIM-RRB- est un domaine de recherche en croissance rapide qui s'int\u00e9resse \u00e0 la mani\u00e8re dont les gens stockent, g\u00e8rent et retrouvent les informations. Les syst\u00e8mes PIM - les m\u00e9thodes et proc\u00e9dures par lesquelles les gens traitent, cat\u00e9gorisent et r\u00e9cup\u00e8rent des informations au quotidien -LSB- 18 -RSB- - sont de plus en plus populaires. Cependant l\u2019\u00e9valuation de ces syst\u00e8mes PIM est probl\u00e9matique. L\u2019une des principales difficult\u00e9s r\u00e9side dans la nature personnelle du PIM. Les gens collectent des informations comme une cons\u00e9quence naturelle de l\u2019accomplissement d\u2019autres t\u00e2ches. Cela signifie que les collections que les gens g\u00e9n\u00e8rent leur sont propres et que les informations contenues dans une collection sont intrins\u00e8quement li\u00e9es aux exp\u00e9riences personnelles du propri\u00e9taire. Les collections personnelles \u00e9tant uniques, nous ne pouvons pas cr\u00e9er de t\u00e2ches d'\u00e9valuation applicables \u00e0 tous les participants \u00e0 une \u00e9valuation. Deuxi\u00e8mement, les collections personnelles peuvent contenir des informations que les participants ne sont pas \u00e0 l'aise de partager dans le cadre d'une \u00e9valuation. La nature pr\u00e9cise de ces informations \u2013 celles que les individus pr\u00e9f\u00e9reraient garder priv\u00e9es \u2013 varie selon les individus, ce qui rend difficile la base des t\u00e2ches de recherche sur le contenu de collections individuelles. Par cons\u00e9quent, les exp\u00e9rimentateurs sont confront\u00e9s \u00e0 un certain nombre de d\u00e9fis pour mener des \u00e9valuations PIM r\u00e9alistes mais contr\u00f4l\u00e9es. Toutefois, r\u00e9cemment, les chercheurs ont commenc\u00e9 \u00e0 se concentrer sur les moyens de r\u00e9soudre le probl\u00e8me de l\u2019\u00e9valuation PIM. Capra -LSB- 6 -RSB- identifie \u00e9galement la n\u00e9cessit\u00e9 d'\u00e9valuations contr\u00f4l\u00e9es en laboratoire PIM pour compl\u00e9ter d'autres techniques d'\u00e9valuation, en mettant un accent particulier sur la n\u00e9cessit\u00e9 de comprendre le comportement du PIM au niveau de la t\u00e2che. Dans cet article, nous tentons d\u2019aborder les difficult\u00e9s li\u00e9es \u00e0 la facilitation des \u00e9valuations PIM contr\u00f4l\u00e9es en laboratoire.Dans la premi\u00e8re partie de cet article, nous pr\u00e9sentons une \u00e9tude de journal des t\u00e2ches de recherche d'informations. L'\u00e9tude examine le type de t\u00e2ches qui n\u00e9cessitent que les utilisateurs retrouvent des informations et produit une taxonomie des t\u00e2ches de recherche pour les messages \u00e9lectroniques et les pages Web. Nous examinons \u00e9galement les caract\u00e9ristiques des t\u00e2ches qui rendent la recherche difficile. Dans la deuxi\u00e8me partie, nous proposons une m\u00e9thodologie d'\u00e9valuation bas\u00e9e sur les t\u00e2ches bas\u00e9e sur nos r\u00e9sultats et examinons la faisabilit\u00e9 de l'approche en utilisant diff\u00e9rentes m\u00e9thodes de cr\u00e9ation de t\u00e2ches. Ainsi, cet article offre deux contributions au domaine\u00a0: une meilleure compr\u00e9hension du comportement du PIM au niveau des t\u00e2ches et une m\u00e9thode d'\u00e9valuation qui facilitera des investigations plus approfondies. 2. TRAVAUX CONNEXES Une vari\u00e9t\u00e9 d'approches sont disponibles pour \u00e9tudier le PIM. Les approches naturalistes \u00e9tudient les participants ex\u00e9cutant naturellement, accomplissant leurs propres t\u00e2ches au fur et \u00e0 mesure qu'elles se produisent, dans des environnements familiers. Ces approches permettent aux chercheurs de surmonter bon nombre des difficult\u00e9s caus\u00e9es par la nature personnelle du PIM. Comme les t\u00e2ches effectu\u00e9es sont \u00ab r\u00e9elles \u00bb et non simul\u00e9es, les participants peuvent utiliser leurs propres exp\u00e9riences, connaissances ant\u00e9rieures et collections d'informations pour accomplir les t\u00e2ches. Les m\u00e9thodes ethnographiques et de terrain n\u00e9cessitent la pr\u00e9sence d\u2019un exp\u00e9rimentateur pour \u00e9valuer la mani\u00e8re dont le PIM est r\u00e9alis\u00e9, ce qui soul\u00e8ve un certain nombre de questions. Premi\u00e8rement, une telle \u00e9valuation co\u00fbte cher ; il faut de longues p\u00e9riodes pour \u00e9tudier un petit nombre de participants et ces petits \u00e9chantillons peuvent ne pas \u00eatre repr\u00e9sentatifs du comportement de populations plus larges. Deuxi\u00e8mement, comme les participants ne peuvent pas \u00eatre observ\u00e9s en permanence, les exp\u00e9rimentateurs doivent choisir le moment o\u00f9 ils les observent, ce qui peut affecter les r\u00e9sultats. Une strat\u00e9gie alternative \u00e0 la conduite d\u2019\u00e9valuations naturalistes consiste \u00e0 utiliser l\u2019analyse des fichiers journaux. Cette approche utilise un logiciel de journalisation qui capture un large \u00e9chantillon d'activit\u00e9s des utilisateurs dans le context de l'utilisation naturelle d'un syst\u00e8me. Cela r\u00e9v\u00e8le la n\u00e9cessit\u00e9 de compl\u00e9ter les \u00e9tudes naturalistes par des exp\u00e9riences contr\u00f4l\u00e9es dans lesquelles l'exp\u00e9rimentateur peut relier le comportement des participants \u00e0 l'\u00e9tude aux objectifs associ\u00e9s \u00e0 des t\u00e2ches de recherche connues. L\u2019une des difficult\u00e9s li\u00e9es \u00e0 la r\u00e9alisation de ce type d\u2019\u00e9valuation consiste \u00e0 trouver des collections \u00e0 \u00e9valuer. Kelly -LSB-16-RSB- propose l'introduction d'une collection de tests partag\u00e9e qui fournirait des ensembles de donn\u00e9es, des t\u00e2ches et des mesures partageables et r\u00e9utilisables pour ceux qui souhaitent mener des recherches PIM. Cependant, une collection partag\u00e9e ne serait pas adapt\u00e9e aux \u00e9tudes utilisateurs car il ne serait pas possible d\u2019incorporer les aspects personnels du PIM tout en utilisant une collection commune et peu famili\u00e8re. Une approche alternative consiste \u00e0 demander aux utilisateurs de fournir leurs propres collections d'informations pour simuler des environnements familiers au sein du laboratoire. Cette approche a \u00e9t\u00e9 appliqu\u00e9e pour \u00e9tudier la recherche de photographies personnelles -LSB- 11 -RSB-, de messages \u00e9lectroniques -LSB- 20 -RSB- et de signets Web -LSB- 21 -RSB-. L'utilit\u00e9 de cette approche d\u00e9pend de la facilit\u00e9 avec laquelle il est possible de transf\u00e9rer la collection ou d'y acc\u00e9der \u00e0 distance.Une autre solution consiste \u00e0 utiliser l'ensemble du Web comme une collection lors de l'\u00e9tude de la recherche de pages Web -LSB- 4 -RSB-. Cela peut \u00eatre appropri\u00e9 pour \u00e9tudier la recherche de pages Web, car des \u00e9tudes ant\u00e9rieures ont montr\u00e9 que les gens utilisent souvent les moteurs de recherche Web \u00e0 cette fin -LSB- 5 -RSB-. Une deuxi\u00e8me difficult\u00e9 dans la r\u00e9alisation d\u2019\u00e9tudes PIM en laboratoire est de cr\u00e9er des t\u00e2ches que les participants doivent accomplir et qui peuvent \u00eatre r\u00e9solues en recherchant dans une collection partag\u00e9e ou personnelle. Les t\u00e2ches concernent l'activit\u00e9 qui entra\u00eene un besoin d'informations -LSB- 14 -RSB- et sont reconnues comme \u00e9tant importantes pour d\u00e9terminer le comportement de l'utilisateur -LSB- 26 -RSB-. De nombreux travaux ont \u00e9t\u00e9 r\u00e9alis\u00e9s pour comprendre la nature des t\u00e2ches et comment le type de t\u00e2che influence le comportement de recherche d'informations des utilisateurs. Par exemple, les t\u00e2ches ont \u00e9t\u00e9 class\u00e9es en termes de complexit\u00e9 croissante -LSB- 3 -RSB- et il a \u00e9t\u00e9 sugg\u00e9r\u00e9 que la complexit\u00e9 des t\u00e2ches affecte la fa\u00e7on dont les chercheurs per\u00e7oivent leurs besoins en informations -LSB- 25 -RSB- et comment ils essaient de trouver des informations -LSB- 3 -RSB-. D'autres travaux ant\u00e9rieurs ont fourni des m\u00e9thodologies permettant la simulation de t\u00e2ches lors de l'\u00e9tude du comportement de recherche d'informations -LSB- 2 -RSB-. Cependant, on sait peu de choses sur les types de t\u00e2ches qui am\u00e8nent les gens \u00e0 rechercher dans leurs magasins personnels ou \u00e0 retrouver des informations qu'ils ont vues auparavant. Par cons\u00e9quent, il est difficile de concevoir des situations de t\u00e2ches de travail simul\u00e9es pour le PIM. L'exception est l'\u00e9tude de la gestion des photographies personnelles, o\u00f9 le travail de Rodden sur la cat\u00e9gorisation des t\u00e2ches de recherche de photographies personnelles a facilit\u00e9 la cr\u00e9ation de situations de t\u00e2ches de travail simul\u00e9es -LSB- 22 -RSB-. Il y a eu d'autres suggestions sur la mani\u00e8re de classer les t\u00e2ches PIM. Bien qu\u2019il s\u2019agisse de propri\u00e9t\u00e9s int\u00e9ressantes susceptibles d\u2019affecter la fa\u00e7on dont une t\u00e2che sera ex\u00e9cut\u00e9e, elles ne donnent pas aux exp\u00e9rimentateurs suffisamment de latitude pour concevoir des t\u00e2ches. Les collections personnelles sont l'une des raisons pour lesquelles la cr\u00e9ation de t\u00e2ches est si difficile. La taxonomie des t\u00e2ches photographiques de Rodden apporte ici une solution car elle permet de cat\u00e9goriser les t\u00e2ches adapt\u00e9es aux collections priv\u00e9es. Les syst\u00e8mes peuvent ensuite \u00eatre compar\u00e9s entre types de t\u00e2ches pour diff\u00e9rents utilisateurs -LSB- 11 -RSB-. Malheureusement, aucune taxonomie \u00e9quivalente n\u2019existe pour d\u2019autres types d\u2019objets informationnels. De plus, d'autres types d'objets sont plus sensibles \u00e0 la vie priv\u00e9e que les photographies ; il est peu probable que les participants soient aussi satisfaits de permettre aux chercheurs de parcourir leurs collections de courriers \u00e9lectroniques pour cr\u00e9er des t\u00e2ches comme ils l'\u00e9taient avec des photographies dans -LSB-11-RSB-. Cela pose un probl\u00e8me s\u00e9rieux : comment les chercheurs peuvent-ils concevoir des t\u00e2ches qui correspondent \u00e0 des collections priv\u00e9es sans comprendre les types de t\u00e2ches effectu\u00e9es par les gens et sans mettre en danger la vie priv\u00e9e des participants \u00e0 l'\u00e9tude ? Quelques m\u00e9thodes ont \u00e9t\u00e9 propos\u00e9es. Par exemple, -LSB- 20 -RSB- a \u00e9tudi\u00e9 la recherche d'e-mails en demandant aux participants de retrouver les e-mails qui avaient \u00e9t\u00e9 envoy\u00e9s \u00e0 chaque membre d'un d\u00e9partement ; permettant aux m\u00eames t\u00e2ches d'\u00eatre utilis\u00e9es pour tous les participants \u00e0 l'\u00e9tude.Cette approche garantissait que les probl\u00e8mes de confidentialit\u00e9 \u00e9taient \u00e9vit\u00e9s et que les participants pouvaient utiliser des \u00e9l\u00e9ments dont ils se souvenaient pour accomplir leurs t\u00e2ches. N\u00e9anmoins, les syst\u00e8mes n'ont \u00e9t\u00e9 test\u00e9s qu'en utilisant un seul type de t\u00e2che : les participants ont \u00e9t\u00e9 invit\u00e9s \u00e0 trouver des e-mails uniques, chacun partageant des propri\u00e9t\u00e9s communes. Dans la section 4, nous montrons que les gens effectuent un \u00e9ventail de t\u00e2ches de recherche d'e-mails plus large que cela. Dans -LSB-4-RSB-, des t\u00e2ches de recherche g\u00e9n\u00e9riques ont \u00e9t\u00e9 cr\u00e9\u00e9es artificiellement en ex\u00e9cutant des \u00e9valuations sur deux sessions. Lors de la premi\u00e8re s\u00e9ance, les participants ont \u00e9t\u00e9 invit\u00e9s \u00e0 effectuer des t\u00e2ches de travail impliquant la recherche d'informations inconnues. Lors de la deuxi\u00e8me s\u00e9ance, les participants ont accompli \u00e0 nouveau les m\u00eames t\u00e2ches, ce qui impliquait naturellement un certain comportement de recherche. Les limites de cette technique sont qu'elle ne permet pas aux participants d'exploiter des liens personnels avec l'information, car les informations qu'ils recherchent peuvent ne correspondre \u00e0 aucun autre aspect de leur vie. Notre examen des approches d\u2019\u00e9valuation justifie l\u2019exigence d\u2019exp\u00e9riences contr\u00f4l\u00e9es en laboratoire permettant de tester des aspects \u00e9troitement d\u00e9finis des syst\u00e8mes ou des interfaces. Malheureusement, il a \u00e9galement \u00e9t\u00e9 d\u00e9montr\u00e9 que ce type d'\u00e9valuation pr\u00e9sente des difficult\u00e9s : il est difficile de rechercher des collections et de concevoir des t\u00e2ches qui correspondent \u00e0 des collections priv\u00e9es, tout en prot\u00e9geant la vie priv\u00e9e des participants \u00e0 l'\u00e9tude. Dans la section suivante, nous pr\u00e9sentons une \u00e9tude de journal sur les t\u00e2ches de recherche de courrier \u00e9lectronique et de pages Web. Le r\u00e9sultat est une classification de t\u00e2ches similaire \u00e0 celle con\u00e7ue par Rodden pour les photographies personnelles -LSB- 22 -RSB-. Dans la section 5, nous nous appuyons sur ce travail en examinant les m\u00e9thodes permettant de cr\u00e9er des t\u00e2ches qui ne compromettent pas la vie priv\u00e9e des participants et discutons de la mani\u00e8re dont notre travail peut faciliter les \u00e9valuations des utilisateurs PIM bas\u00e9es sur les t\u00e2ches. Nous montrons qu'en collectant des t\u00e2ches \u00e0 l'aide de journaux \u00e9lectroniques, nous pouvons non seulement en apprendre davantage sur les t\u00e2ches qui am\u00e8nent les gens \u00e0 retrouver des informations personnelles, mais \u00e9galement sur le contenu des collections priv\u00e9es sans compromettre la vie priv\u00e9e des participants. Ces connaissances peuvent ensuite \u00eatre utilis\u00e9es pour construire des t\u00e2ches \u00e0 utiliser dans les \u00e9valuations PIM. 6. CONCLUSIONS Cet article s'est concentr\u00e9 sur la r\u00e9solution des difficult\u00e9s li\u00e9es \u00e0 la r\u00e9alisation d'\u00e9valuations PIM. La nature personnelle du PIM signifie qu'il est difficile de construire des exp\u00e9riences \u00e9quilibr\u00e9es car les participants poss\u00e8dent chacun leurs propres collections uniques, auto-g\u00e9n\u00e9r\u00e9es en accomplissant d'autres t\u00e2ches. Nous avons sugg\u00e9r\u00e9 que pour int\u00e9grer les aspects personnels du PIM dans les \u00e9valuations, les performances des syst\u00e8mes ou des utilisateurs devraient \u00eatre examin\u00e9es lorsque les utilisateurs effectuent des t\u00e2ches sur leurs propres collections. Cette approche elle-m\u00eame pose des probl\u00e8mes car la cr\u00e9ation de t\u00e2ches pour les collections personnelles est difficile : les chercheurs ne savent pas grand-chose des types de t\u00e2ches de recherche effectu\u00e9es par les gens et ils ne savent pas quelles informations se trouvent dans les collections personnelles individuelles.Dans cet article, nous avons d\u00e9crit les moyens de surmonter ces d\u00e9fis pour faciliter les \u00e9valuations des utilisateurs du PIM bas\u00e9es sur les t\u00e2ches. Dans la premi\u00e8re partie de cet article, nous avons r\u00e9alis\u00e9 une \u00e9tude de journal qui a examin\u00e9 les t\u00e2ches qui ont amen\u00e9 les gens \u00e0 retrouver des messages \u00e9lectroniques et des pages Web. Les donn\u00e9es collect\u00e9es comprenaient un large \u00e9ventail de t\u00e2ches li\u00e9es au travail et non li\u00e9es au travail, et sur la base des donn\u00e9es, nous avons cr\u00e9\u00e9 une taxonomie des t\u00e2ches de recherche sur le Web et les e-mails. Nous avons d\u00e9couvert que les gens effectuent trois principaux types de t\u00e2ches de recherche\u00a0: les t\u00e2ches qui n\u00e9cessitent des informations sp\u00e9cifiques \u00e0 partir d'une seule ressource, les t\u00e2ches qui n\u00e9cessitent une seule ressource compl\u00e8te et les t\u00e2ches qui n\u00e9cessitent la r\u00e9cup\u00e9ration d'informations \u00e0 partir de plusieurs ressources. Dans la deuxi\u00e8me partie de l'article, nous avons discut\u00e9 de l'importance de la taxonomie en ce qui concerne l'\u00e9valuation PIM. Nous avons d\u00e9montr\u00e9 que des exp\u00e9riences \u00e9quilibr\u00e9es pouvaient \u00eatre men\u00e9es pour comparer les performances du syst\u00e8me ou des utilisateurs sur les cat\u00e9gories de t\u00e2ches au sein de la taxonomie. Nous avons \u00e9galement sugg\u00e9r\u00e9 deux m\u00e9thodes pour cr\u00e9er des t\u00e2ches pouvant \u00eatre effectu\u00e9es sur des collections personnelles. Ces m\u00e9thodes ne compromettent pas la vie priv\u00e9e des participants \u00e0 l'\u00e9tude. Nous avons examin\u00e9 les techniques propos\u00e9es, d'une part en simulant une situation exp\u00e9rimentale - les participants \u00e9taient invit\u00e9s \u00e0 r\u00e9ex\u00e9cuter leurs propres t\u00e2ches au fur et \u00e0 mesure qu'ils les enregistraient, et d'autre part dans le cadre d'une \u00e9valuation compl\u00e8te. R\u00e9aliser des \u00e9valuations de cette mani\u00e8re permettra de tester les syst\u00e8mes propos\u00e9s pour am\u00e9liorer la capacit\u00e9 des utilisateurs \u00e0 g\u00e9rer et \u00e0 retrouver leurs informations, afin que nous puissions conna\u00eetre les besoins et les d\u00e9sirs des utilisateurs. Ainsi, cet article a offert deux contributions au domaine\u00a0: une meilleure compr\u00e9hension du comportement du PIM au niveau des t\u00e2ches et une m\u00e9thode d'\u00e9valuation qui facilitera des investigations plus approfondies.R\u00e9aliser des \u00e9valuations de cette mani\u00e8re permettra de tester les syst\u00e8mes propos\u00e9s pour am\u00e9liorer la capacit\u00e9 des utilisateurs \u00e0 g\u00e9rer et \u00e0 retrouver leurs informations, afin que nous puissions conna\u00eetre les besoins et les d\u00e9sirs des utilisateurs. Ainsi, cet article a offert deux contributions au domaine\u00a0: une meilleure compr\u00e9hension du comportement du PIM au niveau des t\u00e2ches et une m\u00e9thode d'\u00e9valuation qui facilitera des investigations plus approfondies.R\u00e9aliser des \u00e9valuations de cette mani\u00e8re permettra de tester les syst\u00e8mes propos\u00e9s pour am\u00e9liorer la capacit\u00e9 des utilisateurs \u00e0 g\u00e9rer et \u00e0 retrouver leurs informations, afin que nous puissions conna\u00eetre les besoins et les d\u00e9sirs des utilisateurs. Ainsi, cet article a offert deux contributions au domaine\u00a0: une meilleure compr\u00e9hension du comportement du PIM au niveau des t\u00e2ches et une m\u00e9thode d'\u00e9valuation qui facilitera des investigations plus approfondies.", "keyphrases": ["la personne informe la direction", "mesurer", "exp\u00e9rience", "facteur humain", "retrouver informer", "probl\u00e8me de confidentialit\u00e9", "taxonomie", "collecte individuelle", "message \u00e9lectronique", "approche naturaliste", "\u00e9tudes de base en laboratoire"]}
{"file_name": "I-12", "text": "Partager des exp\u00e9riences pour apprendre les caract\u00e9ristiques des utilisateurs dans des environnements dynamiques avec des donn\u00e9es \u00e9parses R\u00c9SUM\u00c9 Cet article \u00e9tudie le probl\u00e8me de l'estimation de la valeur des param\u00e8tres probabilistes n\u00e9cessaires \u00e0 la prise de d\u00e9cision dans des environnements dans lesquels un agent, op\u00e9rant au sein d'un syst\u00e8me multi-agents, ne dispose d'aucune information a priori sur la structure de la distribution des valeurs des param\u00e8tres. L'agent doit \u00eatre capable de produire des estimations m\u00eame s'il n'a effectu\u00e9 qu'un petit nombre d'observations directes, et doit donc \u00eatre capable d'op\u00e9rer avec des donn\u00e9es \u00e9parses. L'article d\u00e9crit un m\u00e9canisme qui permet \u00e0 l'agent d'am\u00e9liorer consid\u00e9rablement son estimation en augmentant ses observations directes avec celles obtenues par d'autres agents avec lesquels il se coordonne. Pour \u00e9viter les biais ind\u00e9sirables dans des environnements relativement h\u00e9t\u00e9rog\u00e8nes tout en utilisant efficacement des donn\u00e9es pertinentes pour am\u00e9liorer ses estimations, le m\u00e9canisme pond\u00e8re les contributions des observations d'autres agents sur la base d'une estimation en temps r\u00e9el du niveau de similarit\u00e9 entre chacun de ces agents et lui-m\u00eame. Le module \u00ab\u00a0autonomie de coordination\u00a0\u00bb d'un syst\u00e8me coordination-gestionnaire a fourni un cadre empirique pour l'\u00e9valuation. Les \u00e9valuations bas\u00e9es sur la simulation ont d\u00e9montr\u00e9 que le m\u00e9canisme propos\u00e9 surpasse les estimations bas\u00e9es exclusivement sur les propres observations d'un agent ainsi que les estimations bas\u00e9es sur un agr\u00e9gat non pond\u00e9r\u00e9 des observations de tous les autres agents. 1. INTRODUCTION Pour de nombreux sc\u00e9narios du monde r\u00e9el, les agents autonomes doivent op\u00e9rer dans des environnements dynamiques et incertains dans lesquels ils ne disposent que d'informations incompl\u00e8tes sur les r\u00e9sultats de leurs actions et les caract\u00e9ristiques des autres agents ou des personnes avec lesquelles ils doivent coop\u00e9rer ou collaborer. Dans de tels environnements, les agents peuvent b\u00e9n\u00e9ficier du partage des informations qu\u2019ils collectent, en mettant en commun leurs exp\u00e9riences individuelles pour am\u00e9liorer leurs estimations des param\u00e8tres inconnus n\u00e9cessaires au raisonnement sur les actions dans des conditions d\u2019incertitude. Cet article aborde le probl\u00e8me de l'apprentissage de la distribution des valeurs d'un param\u00e8tre probabiliste qui repr\u00e9sente une caract\u00e9ristique d'une personne qui interagit avec un agent informatique. La caract\u00e9ristique \u00e0 apprendre est -LRB- ou est clairement li\u00e9e \u00e0 -RRB- un facteur important dans la prise de d\u00e9cision de l'agent.1 Le cadre de base que nous consid\u00e9rons est celui dans lequel un agent accumule des observations sur une caract\u00e9ristique utilisateur sp\u00e9cifique et les utilise. pour produire une estimation opportune d'une mesure qui d\u00e9pend de la distribution de cette caract\u00e9ristique. G\u00e9n\u00e9ralement, les agents doivent prendre des d\u00e9cisions en temps r\u00e9el, parall\u00e8lement \u00e0 l\u2019ex\u00e9cution des t\u00e2ches et au milieu d\u2019une grande incertitude. Dans la suite de cet article, nous utilisons le terme \u00ab\u00a0\u00e0 rythme rapide\u00a0\u00bb pour d\u00e9signer de tels environnements. Dans des environnements en \u00e9volution rapide, la collecte d\u2019informations peut \u00eatre limit\u00e9e et il n\u2019est pas possible d\u2019apprendre hors ligne ou d\u2019attendre que de grandes quantit\u00e9s de donn\u00e9es soient collect\u00e9es avant de prendre des d\u00e9cisions. Ainsi,le but des m\u00e9thodes d'estimation pr\u00e9sent\u00e9es dans cet article est de minimiser l'erreur moyenne au fil du temps, plut\u00f4t que de d\u00e9terminer une valeur pr\u00e9cise \u00e0 la fin d'une longue p\u00e9riode d'interaction. Autrement dit, l'agent est cens\u00e9 travailler avec l'utilisateur pendant une dur\u00e9e limit\u00e9e et tente de minimiser l'erreur globale dans ses estimations. Dans de tels environnements, les donn\u00e9es acquises individuellement -LRB- et ses propres observations -RRB- par un agent sont trop rares pour qu'il puisse obtenir de bonnes estimations dans les d\u00e9lais requis. \u00c9tant donn\u00e9 l\u2019absence de contrainte de structure dans l\u2019environnement, les approches qui d\u00e9pendent de distributions structur\u00e9es peuvent entra\u00eener un biais d\u2019estimation consid\u00e9rablement \u00e9lev\u00e9. Nous consid\u00e9rons ce probl\u00e8me dans le context d'un syst\u00e8me distribu\u00e9 multi-agents dans lequel des agents informatiques assistent des personnes effectuant des t\u00e2ches complexes dans un environnement dynamique. Le fait que les agents fassent partie d'un environnement multi-agents, dans lequel d'autres agents peuvent \u00e9galement collecter des donn\u00e9es pour estimer une caract\u00e9ristique similaire de leurs utilisateurs, offre la possibilit\u00e9 \u00e0 un agent d'augmenter ses propres observations avec celles d'autres agents, am\u00e9liorant ainsi la pr\u00e9cision de son processus d\u2019apprentissage. De plus, dans les environnements que nous consid\u00e9rons, les agents accumulent g\u00e9n\u00e9ralement des donn\u00e9es \u00e0 un rythme relativement similaire. N\u00e9anmoins, la mesure dans laquelle les observations d'autres agents seront utiles \u00e0 un agent donn\u00e9 d\u00e9pend de la mesure dans laquelle les distributions des caract\u00e9ristiques de leurs utilisateurs sont corr\u00e9l\u00e9es \u00e0 celles de l'utilisateur de cet agent. Il n\u2019y a aucune garantie que la distribution de deux agents diff\u00e9rents soit fortement corr\u00e9l\u00e9e positivement, et encore moins qu\u2019ils soient identiques. Ainsi, pour utiliser une approche de partage de donn\u00e9es, un m\u00e9canisme d\u2019apprentissage doit \u00eatre capable d\u2019identifier efficacement le niveau de corr\u00e9lation entre les donn\u00e9es collect\u00e9es par diff\u00e9rents agents et de pond\u00e9rer les donn\u00e9es partag\u00e9es en fonction du niveau de corr\u00e9lation. La conception d'un module d'autonomie de coordination -LRB- CA -RRB- au sein d'un syst\u00e8me de coordination-gestionnaire -LRB- dans le cadre du projet DARPA coordinateurs -LSB- 18 -RSB- -RRB-, dans lequel des agents supportent une t\u00e2che de planification distribu\u00e9e, a fourni la motivation initiale et un cadre conceptuel pour ce travail. Cependant, les m\u00e9canismes eux-m\u00eames sont g\u00e9n\u00e9raux et peuvent \u00eatre appliqu\u00e9s non seulement \u00e0 d'autres domaines en \u00e9volution rapide, mais \u00e9galement \u00e0 d'autres contexts multi-agents dans lesquels les agents collectent des donn\u00e9es qui se chevauchent dans une certaine mesure, \u00e0 des rythmes \u00e0 peu pr\u00e8s similaires, et dans lesquels l'environnement impose les contraintes de non-structure, d'utilisation limit\u00e9e et pr\u00e9coce d\u00e9finies ci-dessus -LRB-, par exemple l'exploration de plan\u00e8tes \u00e9loign\u00e9es -RRB-. En particulier, nos techniques seraient utiles dans tout context dans lequel un groupe d'agents entreprend une t\u00e2che dans un nouvel environnement, chaque agent obtenant des observations \u00e0 un rythme similaire sur les param\u00e8tres individuels dont il a besoin pour sa prise de d\u00e9cision. Dans cet article, nous pr\u00e9sentons un m\u00e9canisme utilis\u00e9 pour apprendre les caract\u00e9ristiques cl\u00e9s des utilisateurs dans des environnements en \u00e9volution rapide.Le m\u00e9canisme fournit des estimations relativement pr\u00e9cises dans des d\u00e9lais courts en augmentant les observations directes d'un agent individuel avec des observations obtenues par d'autres agents avec lesquels il se coordonne. En particulier, nous nous concentrons sur les probl\u00e8mes connexes li\u00e9s \u00e0 l'estimation du co\u00fbt de l'interruption d'une personne et \u00e0 l'estimation de la probabilit\u00e9 que cette personne dispose des informations requises par le syst\u00e8me. Le m\u00e9canisme a \u00e9t\u00e9 test\u00e9 avec succ\u00e8s \u00e0 l'aide d'un syst\u00e8me qui simule un environnement de coordinateurs. La section suivante de l'article d\u00e9crit le probl\u00e8me de l'estimation des param\u00e8tres li\u00e9s \u00e0 l'utilisateur dans des domaines en \u00e9volution rapide. La section 3 donne un aper\u00e7u des m\u00e9thodes que nous avons d\u00e9velopp\u00e9es. La mise en \u0153uvre, le cadre empirique et les r\u00e9sultats sont pr\u00e9sent\u00e9s dans les sections 4 et 5. Une comparaison avec les m\u00e9thodes associ\u00e9es est donn\u00e9e dans la section 6 et les conclusions dans la section 7. 6. TRAVAUX CONNEXES En plus de la litt\u00e9rature sur la gestion des interruptions examin\u00e9e dans la section 2, plusieurs autres les domaines de travaux ant\u00e9rieurs sont pertinents pour le m\u00e9canisme de partage s\u00e9lectif d\u00e9crit dans le pr\u00e9sent document. Le filtrage collaboratif, qui effectue des pr\u00e9dictions -LRB- filtering -RRB- sur les int\u00e9r\u00eats d'un utilisateur -LSB- 7 -RSB-, fonctionne de mani\u00e8re similaire au partage s\u00e9lectif. Cependant, les syst\u00e8mes de filtrage collaboratif pr\u00e9sentent des performances m\u00e9diocres lorsqu'il n'y a pas suffisamment d'informations sur les utilisateurs et lorsqu'il n'y a pas suffisamment d'informations sur un nouvel utilisateur dont le syst\u00e8me tente de pr\u00e9dire les go\u00fbts -LSB- 7 -RSB-. Le partage s\u00e9lectif repose sur la capacit\u00e9 \u00e0 trouver des similitudes entre des parties sp\u00e9cifiques de la fonction de distribution de probabilit\u00e9 associ\u00e9es \u00e0 une caract\u00e9ristique de diff\u00e9rents utilisateurs. Cette capacit\u00e9 est \u00e9troitement li\u00e9e au clustering et \u00e0 la classification, un domaine largement \u00e9tudi\u00e9 en apprentissage automatique. Compte tenu des consid\u00e9rations spatiales, notre examen de ce domaine se limite \u00e0 quelques approches repr\u00e9sentatives du regroupement. Il est particuli\u00e8rement important que l'autorit\u00e9 de certification doit trouver des similitudes entre les fonctions, d\u00e9finies sur un intervalle continu, sans attributs pr\u00e9d\u00e9finis distincts. Une difficult\u00e9 suppl\u00e9mentaire consiste \u00e0 d\u00e9finir la mesure de la distance. De nombreuses techniques de clustering ont \u00e9t\u00e9 utilis\u00e9es en data mining -LSB- 2 -RSB-, avec un accent particulier sur les mises \u00e0 jour incr\u00e9mentielles du clustering, en raison de la tr\u00e8s grande taille des bases de donn\u00e9es -LSB- 3 -RSB-. Cependant, leur applicabilit\u00e9 \u00e0 des domaines en \u00e9volution rapide est assez limit\u00e9e car elles reposent sur un large ensemble de donn\u00e9es existantes. La m\u00e9thode la plus pertinente pour nos besoins est l\u2019indice d\u2019entropie relative de Kullback-Leibler qui est utilis\u00e9 en th\u00e9orie des probabilit\u00e9s et en th\u00e9orie de l\u2019information -LSB- 12 -RSB-. Cependant, la m\u00e9thode fonctionnera mal dans les sc\u00e9narios dans lesquels les fonctions alternent entre diff\u00e9rents niveaux tout en conservant la structure et les moments \u00ab g\u00e9n\u00e9raux \u00bb. 208 La Sixi\u00e8me Internationale. Conf. conjointe. sur les agents autonomes et les syst\u00e8mes multi-agents -LRB- AAMAS 07 -RRB-, tandis que notre approche bas\u00e9e sur Wilcoxon leur donnera le rang le plus \u00e9lev\u00e9 en termes de similarit\u00e9. Bien que le test de Wilcoxon soit une proc\u00e9dure statistique largement utilis\u00e9e -LSB- 22,14 -RSB-, il est g\u00e9n\u00e9ralement utilis\u00e9 pour comparer deux ensembles de donn\u00e9es \u00e0 variable unique. \u00c0 notre connaissance, aucune tentative n\u2019a encore \u00e9t\u00e9 faite pour \u00e9tendre ses propri\u00e9t\u00e9s en tant qu\u2019infrastructure permettant de d\u00e9terminer avec qui et dans quelle mesure les informations doivent \u00eatre partag\u00e9es, comme pr\u00e9sent\u00e9 dans cet article. Dans ces applications, il est principalement utilis\u00e9 comme outil d\u2019identification et crit\u00e8re de classement.", "keyphrases": ["param\u00e8tre probabiliste", "agent", "informer partager", "prendre des d\u00e9cisions", "environnement au rythme rapide", "syst\u00e8me de distribution multi-agents", "apprendre la m\u00e9canique", "s\u00e9lectionner-partager", "estimation des param\u00e8tres"]}
{"file_name": "I-1", "text": "Aborting Tasks in BDI Agents ABSTRACT Intelligent agents that are intended to work in dynamic environments must be able to gracefully handle unsuccessful tasks and plans. In addition, such agents should be able to make rational decisions about an appropriate course of action, which may include aborting a task or plan, either as a result of the agent 's own deliberations, or potentially at the request of another agent. In this paper we investigate the incorporation of aborts into a BDI-style architecture. We discuss some conditions under which aborting a task or plan is appropriate, and how to determine the consequences of such a decision. We augment each plan with an optional abort-method, analogous to the failure method found in some agent programming languages. We provide an operational semantics for the execution cycle in the presence of aborts in the abstract agent language CAN, which enables us to specify a BDI-based execution model without limiting our attention to a particular agent system -LRB- such as JACK, Jadex, Jason, or SPARK -RRB-. A key technical challenge we address is the presence of parallel execution threads and of sub-tasks, which require the agent to ensure that the abort methods for each plan are carried out in an appropriate sequence. 1. INTRODUCTION Intelligent agents generally work in complex, dynamic environments, such as air traffic control or robot navigation, in which the success of any particular action or plan can not be guaranteed -LSB- 13 -RSB-. Accordingly, dealing with failure is fundamental to agent programming, and is an important element of agent characteristics such as robustness, flexibility, and persistence -LSB- 21 -RSB-. In agent architectures inspired by the Belief-Desire-Intention -LRB- BDI -RRB- model -LSB- 16 -RSB-, these properties are often characterized by the interactions between beliefs, goals, and plans -LSB- 2 -RSB-.1 In general, an agent that wishes to achieve a particular set of tasks will pursue a number of plans concurrently. When failures occur, the choice of plans will be reviewed. This may involve seeking alternative plans for a particular task, re-scheduling tasks to better comply with resource constraints, dropping some tasks, or some other decision that will increase the likelihood of success -LSB- 12, 14 -RSB-. Given this need for deliberation about failed tasks or plans, failure deliberation is commonly built into the agent 's execution cycle. Besides dealing with failure, an important capability of an intelligent agent is to be able to abort a particular task or plan. Aborting a task or plan is distinct from its failure. In contrast, aborting says nothing about the ability to perform ; it merely eliminates the need. Failure propagates from the bottom up, whereas aborting propagates from the top down. The potential for concurrently executing sub-plans introduces different complexities for aborting and failure. For aborting, it means that multiple concurrent sub-plans may need to be aborted as the abort is propagated down. For failure, it means that parallel-sibling plans may need to be aborted as the failure is propagated up. There has been a considerable amount of work on plan failures -LRB- such as detecting and resolving resource conflicts -LSB- 20, 10 -RSB- -RRB- and most agent systems incorporate some notion of failure handling. However, there has been relatively little work on the development of abort techniques beyond simple dropping of currently intended plans and tasks, which does not deal with the clean-up required. As one consequence, most agent systems are quite limited in their treatment of the situation where one branch of a parallel construct 1One can consider both tasks to be performed and goals to achieve a certain state of the world. A task can be considered a goal of achieving the state of `` the task having been performed '', and a goal can be considered a task of bringing about that state of the world. We adopt the latter view and use `` task '' to also refer to goals. fails -LRB- common approaches include either letting the other branch run to completion unhindered or dropping it completely -RRB-. In this paper we discuss in detail the incorporation of abort cleanup methods into the agent execution cycle, providing a unified approach to failure and abort. A key feature of our procedure-based approach is that we allow each plan to execute some particular code on a failure and on an abort. This allows a plan to attempt to ensure a stable, known state, and possibly to recover some resources and otherwise clean up before exiting. Accordingly, a central technical challenge is to manage the orderly execution of the appropriate clean-up code. We show how aborts can be smoothly introduced into a BDI-style architecture, and for the first time we give an operational semantics for aborting in the abstract agent language CAN -LSB- 23, 17 -RSB-. Our focus is on a single agent, complementary to related work that considers exception handling for single - and multiagent systems -LRB- e.g., -LSB- 22, 5, 6 -RSB- -RRB-. This paper is organized as follows. In Section 2 we give an example of the consequences of aborting a task, and in Section 3 we discuss some circumstances under which aborts should occur, and the appropriate representation and invocation procedures. In Section 4 we show how we can use CAN to formally specify the behaviour of an aborted plan. Section 5 discusses related work, and in Section 6 we present our conclusions and future work. 5. RELATED WORK Plan failure is handled in the extended version of AgentSpeak found in the Jason system -LSB- 6 -RSB-. Failure `` clean-up '' plans are triggered from goal deletion events --! g. In a goal deletion plan, the programmer can specify any `` undo '' actions and whether to attempt the goal again. If no goal deletion plan is provided, Jason 's default behaviour is to not reattempt the goal. Failure handling is applied only to plans triggered by addition of an achievement or test goal ; in particular, goal deletion events are not posted for failure of a goal deletion plan. The implementation of H \u00a8 ubner et al. -LSB- 6 -RSB- requires Jason 's internal actions. A requirement for implementing our approach is a reflective capability in the BDI agent implementation. All three allow meta level methods that are cued by meta events such as goal adoption or plan failure, and offer introspective capabilities over goal and intention states. Such meta level facilities are also required by the approach of Unruh et al. -LSB- 21 -RSB-, who define goal-based semantic compensation for an agent. Failure-handling goals are invoked according to failurehandling strategy rules, by a dedicated agent Failure Handling Component -LRB- FHC -RRB- that tracks task execution. These goals are specified by the agent programmer and attached to tasks, much like our FAb -LRB- P, PF, PA -RRB- construct associates failure and abort methods with a plan P. Note, however, that in contrast to both -LSB- 6 -RSB- and our semantics, -LSB- 21 -RSB- attach the failure-handling knowledge at the goal, not plan, level. Their failure-handling goals may consist of stabilization goals that perform localized, immediate `` clean-up '' to restore the agent 's state to a known, stable state, and compensation goals that perform `` undo '' actions. Compensation goals are triggered on aborting a goal, and so not necessarily on goal failure -LRB- i.e., if the FHC directs the agent to retry the failed goal and the retry is successful -RRB-. This contrasts with simplistic plan-level failure handling in which the what and how are intermingled in domain task knowledge. While our approach is defined at the plan level, our extended BDI semantics provides for the separation of execution and failure handling. Further, the FHC explicitly maintains data structures to track agent execution. We leverage the existing execution structures and self-reflective ability of a BDI agent to accomplish both aborting and failure handling without additional overhead. FHC 's failure-handling strategy rules -LRB- e.g., whether to retry a failed goal -RRB- are replaced by instructions in our PF and PA plans, together with meta-level default failure handlers according to the agent 's nature -LRB- e.g., blindly committed -RRB-. The FHC approach is independent of the architecture of the agent itself, in contrast to our work that is dedicated to the BDI formalism -LRB- although not tied to any one agent system -RRB-. 14 The Sixth Intl.. Joint Conf. on Autonomous Agents and Multi-Agent Systems -LRB- AAMAS 07 -RRB- a state-based protocol. This approach, together with state checkpointing, is used for multi-agent systems in -LSB- 22 -RSB-. The resulting architecture embeds their failure handling approach within a pair processing architecture for agent crash recovery. Other work on multi-agent exception handling includes AOEX 's distributed exception handling agents -LSB- 5 -RSB-, and the similar sentinels of -LSB- 8 -RSB-. In both cases, failure-handling logic and knowledge are decoupled from the agents ; by contrast, while separating exception handling from domain-specific knowledge, Unruh et al. 's FHC and our approach both retain failure-handling logic within an agent. 6. CONCLUSION AND FUTURE WORK The tasks and plans of an agent may not successfully reach completion, either by the choice of the agent to abort them -LRB- perhaps at the request of another agent to do so -RRB-, or by unbidden factors that lead to failure. In this paper we have presented a procedure-based approach that incorporates aborting tasks and plans into the deliberation cycle of a BDI-style agent, thus providing a unified approach to failure and abort. Our primary contribution is an analysis of the requirements on the operation of the agent for aborting tasks and plans, and a corresponding operational semantics for aborting in the abstract agent language CAN. We are planning to implement an instance of our approach in the SPARK agent system -LSB- 9 -RSB- ; in particular, the work of this paper will be the basis for SPARK 's abort handling mechanism. An intelligent agent will not only gracefully handle unsuccessful tasks and plans, but also will deliberate over its cognitive attitudes to decide its next course of action. We have assumed the default behaviour of a BDI-style agent, according to its nature : for instance, to retry alternatives to a failed plan until one succeeds or until no alternative plans remain -LRB- in which case to fail the task -RRB-. Future work is to place our approach in service of more dynamic agent reasoning, such as the introspection that an agent capable of reasoning over task interaction effects and resource requirements can accomplish -LSB- 19, 12 -RSB-. Related to this is determining the cost of aborting a task or plan, and using this as an input to the deliberation process. This would in particular influence the commitment the agent has towards a particular task : the higher the cost, the greater the commitment. A further item of interest is extending our approach to failure and abort to maintenance goals -LSB- 1 -RSB-. For such goals a different operational semantics for abort is necessary than for achievement goals, to match the difference in semantics of the goals themselves.", "keyphrases": ["intellig agent", "failur", "deal", "cleanup method", "abort-method", "oper semant", "task", "goal", "goal construct"]}
{"file_name": "I-9", "text": "Temporal Linear Logic as a Basis for Flexible Agent Interactions ABSTRACT Interactions between agents in an open system such as the Internet require a significant degree of flexibility. A crucial aspect of the development of such methods is the notion of commitments, which provides a mechanism for coordinating interactive behaviors among agents. In this paper, we investigate an approach to model commitments with tight integration with protocol actions. This means that there is no need to have an explicit mapping from protocols actions to operations on commitments and an external mechanism to process and enforce commitments. We show how agents can reason about commitments and protocol actions to achieve the end results of protocols using a reasoning system based on temporal linear logic, which incorporates both temporal and resource-sensitive reasoning. We also discuss the application of this framework to scenarios such as online commerce. 1. INTRODUCTION AND MOTIVATION The agent paradigm has become well suited as a design metaphor to deal with complex systems comprising many components each having their own thread of control and purposes and involved in dynamic and complex interactions. In multi-agent environments, agents often need to interact with each other to fulfill their goals. Protocols are used to regulate interactions. In traditional approaches to protocol specification, like those using Finite State Machines or Petri Nets, protocols are often predetermined legal sequences of interactive behaviors. Therefore, agents are required to adapt their interactive behaviors to succeed and interactions among agents should not be constructed rigidly. To achieve flexibility, as characterized by Yolum and Singh in -LSB- 11 -RSB-, interaction protocols should ensure that agents have autonomy over their interactive behaviors, and be free from any unnecessary constraints. Also, agents should be allowed to adjust their interactive actions to take advantages of opportunities or handle exceptions that arise during interaction. For example, consider the scenario below for online sales. Cus has a goal of obtaining from Mer a cricket bat at some time. There are two options for Cus to pay. If Cus uses credit payment, Mer needs a bank Ebank to check Cus 's credit. If Cus 's credit is approved, Ebank will arrange the credit payment. Otherwise, Cus may then take the option to pay via PayPal. The interaction ends when goods are delivered and payment is arranged. A flexible approach to this example should include several features. Secondly, there should be no unnecessary constraint on the order in which actions are performed, such as which of making payments and sending the cricket bat should come first. Thirdly, choosing a sequence of interactive actions should be based on reasoning about the intrinsic meanings of protocol actions, which are based on the notion of commitment, i.e. which refers to a strong promise to other agent -LRB- s -RRB- to undertake some courses of action. Current approaches -LSB- 11, 12, 10, 1 -RSB- to achieve flexibilities using the notion of commitment make use of an abstract layer of commitments. However, in these approaches, a mapping from protocol actions onto operations on commitments as well as handling and enforcement mechanisms of commitments must be externally provided. Execution of protocol actions also requires concurrent execution of operations on related commitments. As a result, the overhead of processing the commitment layer makes specification and execution of protocols more complicated and error prone. There is also a lack of a logic to naturally express aspects of resources, internal and external choices as well as time of protocols. Rather than creating another layer of commitment outside protocol actions, we try to achieve a modeling of commitments that is integrated with protocol actions. Both commitments and protocol actions can then be reasoned about in one consistent system. In order to achieve that, we specify protocols in a declarative manner, i.e. what is to be achieved rather then how agents should interact. A key to this is using logic. Temporal logic, in particular, is suitable for describing and reasoning about temporal constraints while linear logic -LSB- 3 -RSB- is quite suitable for modeling resources. We suggest using a combination of linear logic and temporal logic to construct a commitment based interaction framework which allows both temporal and resource-related reasoning for interaction protocols. This provides a natural manipulation and reasoning mechanism as well as internal enforcement mechanisms for commitments based on proof search. Section 2 discusses the background material of linear logic, temporal linear logic and commitments. Section 3 introduces our modeling framework and specification of protocols. Section 4 discusses how our framework can be used for an example of online sale interactions between a merchant, a bank and a customer. We then discuss the advantages and limitations of using our framework to model interaction protocols and achieve flexibility in Section 5. Section 6 presents our conclusions and items of further work. 2. BACKGROUND In order to increase the agents ' autonomy over their interactive behaviors, protocols should be specified in terms of what is to be achieved rather than how the agents should act. In other words, protocols should be specified in a declarative manner. Using logic is central to this specification process. 2.1 Linear Logic Logic has been used as formalism to model and reason about agent systems. Linear logic -LSB- 3 -RSB- is well-known for modeling resources as well as updating processes. It has been considered in agent systems to support agent negotiation and planning by means of proof search -LSB- 5, 8 -RSB-. In real life, resources are consumed and new resources are created. In such logic as classical or temporal logic, however, a direct mapping of resources onto formulas is troublesome. If we model resources like A as `` one dollar '' and B as `` a chocolate bar '', then A = * B in classical logic is read as `` from one dollar we can get a chocolate bar ''. In order to resolve such resource - formula mapping issues, Girard proposed the constraints on which formulas will be used exactly once and can no longer be freely added or removed in derivations and hence treating linear logic formulas as resources. In linear logic, a linear implication A -- B, however, allows A to be removed after deriving B, which means the dollar is gone after using one dollar to buy a chocolate bar. Classical conjunction -LRB- and -RRB- and disjunction -LRB- or -RRB- are recast over different uses of contexts - multiplicative as combining and additive as sharing to come up with four connectives. The ability to specify choices via the additive connectives is a particularly useful feature of linear logic. A & -LRB- additive conjunction -RRB- B, stands for one own choice, either of A or B but not both. In agent systems, this duality between inner and outer choices is manifested by one agent having the power to choose between alternatives and the other having to react to whatever choice is made. Moreover, during interaction, the ability to match consumption and supply of resources among agents can simplify the specification of resource allocations. Linear logic is a natural mechanism to provide this ability -LSB- 5 -RSB-. In addition, it is emphasized in -LSB- 8 -RSB- that linear logic is used to model agent states as sets of consumable resources and particularly, linear implication is used to model transitions among states and capabilities of agents. 2.2 Temporal Linear Logic While linear logic provides advantages to modeling and reasoning about resources, it does not deal naturally with time constraints. Temporal logic, on the other hand, is a formal system which addresses the description and reasoning about the changes of truth values of logic expressions over time -LSB- 2 -RSB-. Temporal logic can be used for specification and verification of concurrent and reactive programs -LSB- 2 -RSB-. Temporal Linear Logic -LRB- TLL -RRB- -LSB- 6 -RSB- is the result of introducing temporal logic into linear logic and hence is resourceconscious as well as deals with time. The temporal operators used are Q -LRB- next -RRB-, \u2751 -LRB- anytime -RRB-, and O -LRB- sometime -RRB- -LSB- 6 -RSB-. Formulas with no temporal operators can be considered as being available only at present. Adding Q to a formula A, i.e. QA, means that A can be used only at the next time and exactly once. Similarly, \u2751 A means that A can be used at any time and exactly once. OA means that A can be used once at some time. Though both \u2751 and O refer to a point in time, the choice of which time is different. Regarding \u2751, the choice is an internal choice, as appropriate to one 's own capability. With O, the choice is externally decided by others. 2.3 Commitment The concept of social commitment has been recognized as fundamental to agent interaction. Indeed, social commitment provides intrinsic meanings of protocol actions and states -LSB- 11 -RSB-. In particular, persistence in commitments introduces into agents ' consideration a certain level of predictability of other agents ' actions, which is important when agents deal with issues of inter-dependencies, global constraints or The Sixth Intl.. Joint Conf. resources sharing -LSB- 7 -RSB-. Commitment based approaches associate protocols actions with operations on commitments and protocol states with the set of effective commitments -LSB- 11 -RSB-. Completing the protocol is done via means-end reasoning on commitment operations to bring the current state to final states where all commitments are resolved. From then, the corresponding legal sequences of interactive actions are determined. Hence, the approaches systematically enhance a variety of legal computations -LSB- 11 -RSB-. Commitments can be reduced to a more fundamental form known as pre-commitments. A pre-commitment here refers to a potential commitment that specifies what the owner agent is willing to commit -LSB- 4 -RSB-, like performing some actions or achieving a particular state. Agents can negotiate about pre-commitments by sending proposals of them to others. Once a precommitment is agreed, it then becomes a commitment and the process moves from negotiation phase to commitment phase, in which the agents act to fulfill their commitments.", "keyphrases": ["multi-agent environ", "interact behavior", "tempor constraint", "interact protocol", "linear logic", "multipl conjunct", "classic conjunct", "level of predict", "pre-commit", "linear implic", "emerg protocol", "condit commit", "request messag", "causal relationship"]}
{"file_name": "J-3", "text": "Budget Optimization in Search-Based Advertising Auctions ABSTRACT Internet search companies sell advertisement slots based on users ' search queries via an auction. While there has been previous work on the auction process and its game-theoretic aspects, most of it focuses on the Internet company. In this work, we focus on the advertisers, who must solve a complex optimization problem to decide how to place bids on keywords to maximize their return -LRB- the number of user clicks on their ads -RRB- for a given budget. We model the entire process and study this budget optimization problem. While most variants are NP-hard, we show, perhaps surprisingly, that simply randomizing between two uniform strategies that bid equally on all the keywords works well. More precisely, this strategy gets at least a 1 \u2212 1/e fraction of the maximum clicks possible. As our preliminary experiments show, such uniform strategies are likely to be practical. We also present inapproximability results, and optimal algorithms for variants of the budget optimization problem. 1. INTRODUCTION Online search is now ubiquitous and Internet search companies such as Google, Yahoo! and MSN let companies and * Work done while visiting Google, Inc., New York, NY. individuals advertise based on search queries posed by users. Conventional media outlets, such as TV stations or newspapers, price their ad slots individually, and the advertisers buy the ones they can afford. In contrast, Internet search companies find it difficult to set a price explicitly for the advertisements they place in response to user queries. Thus, they rely on the market to determine suitable prices by using auctions amongst the advertisers. It is a challenging problem to set up the auction in order to effect a stable market in which all the parties -LRB- the advertisers, users as well as the Internet search company -RRB- are adequately satisfied. The perspective in this paper is not of the Internet search company that displays the advertisements, but rather of the advertisers. The challenge from an advertiser 's point of view is to understand and interact with the auction mechanism. The advertiser determines a set of keywords of their interest and then must create ads, set the bids for each keyword, and provide a total -LRB- often daily -RRB- budget. When a user poses a search query, the Internet search company determines the advertisers whose keywords match the query and who still have budget left over, runs an auction amongst them, and presents the set of ads corresponding to the advertisers who `` win '' the auction. The advertiser whose ad appears pays the Internet search company if the user clicks on the ad. The focus in this paper is on how the advertisers bid. For the particular choice of keywords of their interest1, an advertiser wants to optimize the overall effect of the advertising campaign. The Internet search companies are supportive to1The choice of keywords is related to the domain-knowledge of the advertiser, user behavior and strategic considerations. Internet search companies provide the advertisers with summaries of the query traffic which is useful for them to optimize their keyword choices interactively. We do not directly address the choice of keywords in this paper, which is addressed elsewhere -LSB- 13 -RSB-. wards advertisers and provide statistics about the history of click volumes and prediction about the future performance of various keywords. 9 There are complex interactions between keywords because a user query may match two or more keywords, since the advertiser is trying to cover all the possible keywords in some domain. In effect the advertiser ends up competing with herself. As a result, the advertisers face a challenging optimization problem. The focus of this paper is to solve this optimization problem. 1.1 The Budget Optimization Problem We present a short discussion and formulation of the optimization problem faced by advertisers ; a more detailed description is in Section 2. A given advertiser sees the state of the auctions for searchbased advertising as follows. There is a set K of keywords of interest ; in practice, even small advertisers typically have a large set K. There is a set Q of queries posed by the users. For each query q G Q, there are functions giving the clicksq -LRB- b -RRB- and costq -LRB- b -RRB- that result from bidding a particular amount b in the auction for that query, which we model more formally in the next section. There is a bipartite graph G on the two vertex sets representing K and Q. For any query q G Q, the neighbors of q in K are the keywords that are said to `` match '' the query q. 2 The budget optimization problem is as follows. Given graph G together with the functions clicksq -LRB-. -RRB- and costq -LRB-. -RRB- on the queries, as well as a budget U, determine the bids bk for each keyword k G K such that Pq clicksq -LRB- bq -RRB- is maximized subject to Pq costq -LRB- bq -RRB- < U, where the `` effective bid '' bq on a query is some function of the keyword bids in the neighborhood of q. While we can cast this problem as a traditional optimization problem, there are different challenges in practice depending on the advertiser 's access to the query and graph information, and indeed the reliability of this information -LRB- e.g., it could be based on unstable historical data -RRB-. Thus it is important to find solutions to this problem that not only get many clicks, but are also simple, robust and less reliant on the information. In this paper we define the notion of a `` uniform '' strategy which is essentially a strategy that bids uniformly on all keywords. Since this type of strategy obviates the need to know anything about the particulars of the graph, and effectively aggregates the click and cost functions on the queries, it is quite robust, and thus desirable in practice. What is surprising is that uniform strategy actually performs well, which we will prove. 1.2 Our Main Results and Technical Overview We present positive and negative results for the budget optimization problem. In particular, we show : 9 Nearly all formulations of the problem are NP-Hard. In cases slightly more general than the formulation above, where the clicks have weights, the problem is inapproximable better than a factor of 1 -- 1e, unless P = NP. 9 We give a -LRB- 1 -- 1/e -RRB- - approximation algorithm for the budget optimization problem. The strategy found by the algorithm is a two-bid uniform strategy, which means that it randomizes between bidding some value b1 on all keywords, and bidding some other value b2 on all keywords until the budget is exhausted3. We show that this approximation ratio is tight for uniform strategies. We also give a -LRB- 1/2 -RRB- - approximation algorithm that offers a single-bid uniform strategy, only using one value b1. -LRB- This is tight for single-bid uniform strategies. -RRB- These strategies can be computed in time nearly linear in JQJ + JKJ, the input size. Uniform strategies may appear to be naive in first consideration because the keywords vary significantly in their click and cost functions, and there may be complex interaction between them when multiple keywords are relevant to a query. After all, the optimum can configure arbitrary bids on each of the keywords. Even for the simple case when the graph is a matching, the optimal algorithm involves placing different bids on different keywords via a knapsack-like packing -LRB- Section 2 -RRB-. So, it might be surprising that a simple two-bid uniform strategy is 63 % or more effective compared to the optimum. Our proof of the 1 -- 1/e approximation ratio relies on an adversarial analysis. We define a factor-revealing LP -LRB- Section 4 -RRB- where primal solutions correspond to possible instances, and dual solutions correspond to distributions over bidding strategies. We have conducted simulations using real auction data from Google. The results of these simulations, which are highlighted at the end of Section 4, suggest that uniform bidding strategies could be useful in practice. 8. CONCLUDING REMARKS Another interesting generalization is to consider weights on the clicks, which is a way to model conversions. -LRB- A conversion corresponds to an action on the part of the user who clicked through to the advertiser site ; e.g., a sale or an account sign-up. -RRB- Finally, we have looked at this system as a black box returning clicks as a function of bid, whereas in reality it is a complex repeated game involving multiple advertisers. In -LSB- 3 -RSB-, it was shown that when a set of advertisers use a strategy similar to the one we suggest here, under a slightly modified first-price auction, the prices approach a well-understood market equilibrium.", "keyphrases": ["budget optim", "search-base advertis auction", "internet", "advertis", "game theori", "intrigu heurist", "keyword", "uniform bid strategi", "vickrei clark grove", "lp", "gener second price"]}
{"file_name": "I-18", "text": "Collaboration Among a Satellite Swarm ABSTRACT The paper deals with on-board planning for a satellite swarm via communication and negotiation. We aim at defining individual behaviours that result in a global behaviour that meets the mission requirements. We will present the formalization of the problem, a communication protocol, a solving method based on reactive decision rules, and first results. 1. INTRODUCTION Multi-agent architectures have been developed for satellite swarms -LSB- 36, 38, 42 -RSB- but strong assumptions on deliberation and communication capabilities are made in order to build a collective plan. In a multi-agent context, agents that build a collective plan must be able to change their goals, reallocate resources and react to environment changes and to the others ' choices. However, this step needs high communication and computation capabilities. In order to relax communication constraints, coordination based on norms and conventions -LSB- 16 -RSB- or strategies -LSB- 17 -RSB- are considered. Norms constraint agents in their decisions in such a way that the possibilities of conflicts are reduced. Strategies are private decision rules that allow an agent to draw benefit from the knowledgeable world without communication. However, communication is still needed in order to share information and build collective conjectures and plans. Communication can be achieved through a stigmergic approach -LRB- via the environment -RRB- or through message exchange and a protocol. A protocol defines interactions between agents and can not be uncoupled from its goal, e.g. exchanging information, finding a trade-off, allocating tasks and so on. Protocols can be viewed as an abstraction of an interaction -LSB- 9 -RSB-. However, an agent can not always communicate with another agent or the communication possibilites are restricted to short time intervals. At the individual level, agents are deliberative in order to create a local plan but at the collective level, they use normative decision rules in order to coordinate with one another. We will present the features of our problem, a communication protocol, a method for request allocation and finally, collaboration strategies. 7. EXPERIMENTS Satellite swarm simulations have been implemented in JAVA with the JADE platform -LSB- 3 -RSB-. The on-board planner is implemented with linear programming using ILOG CPLEX -LSB- 1 -RSB-. The simulation scenario implements 3 satellites on 6hour orbits. Two scenarios have been considered : the first one with a set of 40 requests with low mutual exclusion and conflict rate and the second one with a set of 74 requests with high mutual exclusion and conflict rate. In the case of low mutual exclusion and conflict rate -LRB- Table 1 -RRB-, centralized and isolated simulations lead to the same number of observations, with the same average priorities. Isolation leading to a lower cost is due to the high number of redundancies : many agents carry out the same request at different costs. The informed simulation reduces the number of redundancies but sligthly increases the average cost for the same reason. We can notice that the use of 5For instance, the rank-1-expert agent withdraws due to the altruist strategy and the cost increases by a in the worst case, then rank-2-expert agent withdraws due to the altruist strategy and the cost increases by e in the worst case. So the cost has increased by 2e in the worst case. 292 The Sixth Intl.. Joint Conf. Table 1 : Scenario 1 - the 40-request simulation results Table 2 : Scenario 2 - the 74-request simulation results collaboration strategies allows the number of redundancies to be much more reduced but the number of observations decreases owing to the constraint created by commitments. Furthermore, the average cost is increased too. Nevertheless each avoided redundancy corresponds to saved resources to realize on-board generated requests during the simulation. In the case of high mutual exclusion and conflict rate -LRB- Table 2 -RRB-, noteworthy differences exist between the centralized and isolated simulations. We can notice that all informed simulations -LRB- with or without strategies -RRB- allow to perform more observations than isolated agents do with less redundancies. Likewise, we can notice that all politics reduce the average cost contrary to the first scenario. The drastic politics is interesting because not only does it allow to perform more observations than isolated agents do but it allows to highly reduce the average cost with the lowest number of redundancies. As far as the number of exchanged messages is concerned, there are 12 meetings between 2 agents during the simulations. In the worst case, at each meeting each agent sends N pieces of information on the requests plus 3N pieces of information on the agents ' intentions plus 1 message for the end of communication, where N is the total number of requests. Consequently, 3864 messages are exchanged in the worst case for the 40-request simulations and 7128 messages for the 74-request simulations. These numbers are much higher than the number of messages that are actually exchanged. We can notice that the informed simulations, that communicate only requests, allow a higher reduction. In the general case, using communication and strategies allows to reduce redundancies and saves resources but increases the average cost : if a request is realized, agents that know it do not plan it even if its cost can be reduce afterwards. It is not the case with isolated agents. Using strategies on little constrained problems such as scenario 1 constrains the agents too much and causes an additional cost increase. Strategies are more useful on highly constrained problems such as scenario 2. Although agents constrain themselves on the number of observations, the average cost is widely reduce. 8. CONCLUSION AND FUTURE WORK An observation satellite swarm is a cooperative multiagent system with strong constraints in terms of communication and computation capabilities. In order to increase the global mission outcome, we propose an hybrid approach : deliberative for individual planning and reactive for collaboration. Agents reason both on requests to carry out and on the other agents ' intentions -LRB- candidacies -RRB-. An epidemic communication protocol uses all communication opportunities to update this information. Reactive decision rules -LRB- strategies -RRB- are proposed to solve conflicts that may arise between agents. Through the tuning of the strategies -LRB- \u03b1, e and \u03bb -RRB- and their plastic interlacing within the protocol, it is possible to coordinate agents without additional communication : the number of exchanged messages remains nearly the same between informed simulations and simulations implementing strategies. Some simulations have been made to experimentally validate these protocols and the first results are promising but raise many questions. What is the trade-off between the constraint rate of the problem and the need of strategies? To what extent are the number of redundancies and the average cost affected by the tuning of the strategies? Future works will focus on new strategies to solve new conflicts, specially those arising when relaxing the independence assumption between the requests. A second point is to take into account the complexity of the initial planning problem. Indeed, the chosen planning approach results in a combinatory explosion with big sets of requests : an anytime or a fully reactive approach has to be considered for more complex problems.", "keyphrases": ["on-board plan", "satellit swarm", "commun and negoti", "reactiv decis rule", "inform system applic", "multiag system", "task and resourc alloc", "objectag architectur", "teamag", "dip", "prospect ant"]}
{"file_name": "H-16", "text": "The Impact of Caching on Search Engines ABSTRACT In this paper we study the trade-offs in designing efficient caching systems for Web search engines. We explore the impact of different approaches, such as static vs. dynamic caching, and caching query results vs. caching posting lists. Using a query log spanning a whole year we explore the limitations of caching and we demonstrate that caching posting lists can achieve higher hit rates than caching query answers. We propose a new algorithm for static caching of posting lists, which outperforms previous methods. We also study the problem of finding the optimal way to split the static cache between answers and posting lists. Finally, we measure how the changes in the query log affect the effectiveness of static caching, given our observation that the distribution of the queries changes slowly over time. Our results and observations are applicable to different levels of the data-access hierarchy, for instance, for a memory/disk layer or a broker/remote server layer. 1. INTRODUCTION Millions of queries are submitted daily to Web search engines, and users have high expectations of the quality and speed of the answers. In such a setting, to achieve a fast response time and to increase the query throughput, using a cache is crucial. Caching can be applied at different levels with increasing response latencies or processing requirements. The decision of what to cache is either off-line -LRB- static -RRB- or online -LRB- dynamic -RRB-. A static cache is based on historical information and is periodically updated. A dynamic cache replaces entries according to the sequence of requests. When a new request arrives, the cache system decides whether to evict some entry from the cache in the case of a cache miss. Such online decisions are based on a cache policy, and several different policies have been studied in the past. For a search engine, there are two possible ways to use a cache memory : Caching answers : As the engine returns answers to a particular query, it may decide to store these answers to resolve future queries. Caching terms : As the engine evaluates a particular query, it may decide to store in memory the posting lists of the involved query terms. Often the whole set of posting lists does not fit in memory, and consequently, the engine has to select a small set to keep in memory and speed up query processing. Returning an answer to a query that already exists in the cache is more efficient than computing the answer using cached posting lists. On the other hand, previously unseen queries occur more often than previously unseen terms, implying a higher miss rate for cached answers. Caching of posting lists has additional challenges. As posting lists have variable size, caching them dynamically is not very efficient, due to the complexity in terms of efficiency and space, and the skewed distribution of the query stream, as shown later. Static caching of posting lists poses even more challenges : when deciding which terms to cache one faces the trade-off between frequently queried terms and terms with small posting lists that are space efficient. Finally, before deciding to adopt a static caching policy the query stream should be analyzed to verify that its characteristics do not change rapidly over time. Figure 1 : One caching level in a distributed search architecture. In this paper we explore the trade-offs in the design of each cache level, showing that the problem is the same and only a few parameters change. In general, we assume that each level of caching in a distributed search architecture is similar to that shown in Figure 1. We use a query log spanning a whole year to explore the limitations of dynamically caching query answers or posting lists for query terms. More concretely, our main conclusions are that : \u2022 Caching query answers results in lower hit ratios compared to caching of posting lists for query terms, but it is faster because there is no need for query evaluation. We provide a framework for the analysis of the trade-off between static caching of query answers and posting lists ; \u2022 Static caching of terms can be more effective than dynamic caching with, for example, LRU. We provide algorithms based on the KNAPSACK problem for selecting the posting lists to put in a static cache, and we show improvements over previous work, achieving a hit ratio over 90 % ; \u2022 Changes of the query distribution over time have little impact on static caching. Sections 2 and 3 summarize related work and characterize the data sets we use. Section 4 discusses the limitations of dynamic caching. Sections 5 and 6 introduce algorithms for caching posting lists, and a theoretical framework for the analysis of static caching, respectively. Section 7 discusses the impact of changes in the query distribution on static caching, and Section 8 provides concluding remarks. 2. RELATED WORK There is a large body of work devoted to query optimization. More recent examples demonstrate that the top k documents for a query can be returned without the need for evaluating the complete set of posting lists -LSB- 1, 4, 15 -RSB-. Although these approaches seek to improve query processing efficiency, they differ from our current work in that they do not consider caching. Markatos -LSB- 10 -RSB- shows the existence of temporal locality in queries, and compares the performance of different caching policies. Fagni et al. follow Markatos ' work by showing that combining static and dynamic caching policies together with an adaptive prefetching policy achieves a high hit ratio -LSB- 7 -RSB-. Different from our work, they consider caching and prefetching of pages of results. Saraiva et al. propose a new architecture for Web search engines using a two-level dynamic caching system -LSB- 13 -RSB-. Their goal for such systems has been to improve response time for hierarchical engines. In their architecture, both levels use an LRU eviction policy. They find that the second-level cache can effectively reduce disk traffic, thus increasing the overall throughput. Long and Suel propose a caching system structured according to three different levels -LSB- 9 -RSB-. The intermediate level contains frequently occurring pairs of terms and stores the intersections of the corresponding inverted lists. These last two papers are related to ours in that they exploit different caching strategies at different levels of the memory hierarchy. Finally, our static caching algorithm for posting lists in Section 5 uses the ratio frequency/size in order to evaluate the goodness of an item to cache. Similar ideas have been used in the context of file caching -LSB- 17 -RSB-, Web caching -LSB- 5 -RSB-, and even caching of posting lists -LSB- 9 -RSB-, but in all cases in a dynamic setting. To the best of our knowledge we are the first to use this approach for static caching of posting lists. 8. CONCLUSIONS Caching is an effective technique in search engines for improving response time, reducing the load on query processors, and improving network bandwidth utilization. We present results on both dynamic and static caching. Dynamic caching of queries has limited effectiveness due to the high number of compulsory misses caused by the number of unique or infrequent queries. Our results show that in our UK log, the minimum miss rate is 50 % using a working set strategy. Caching terms is more effective with respect to miss rate, achieving values as low as 12 %. We also propose a new algorithm for static caching of posting lists that outperforms previous static caching algorithms as well as dynamic algorithms such as LRU and LFU, obtaining hit rate values that are over 10 % higher compared these strategies. We present a framework for the analysis of the trade-off between caching query results and caching posting lists, and we simulate different types of architectures. Our results show that for centralized and LAN environments, there is an optimal allocation of caching query results and caching of posting lists, while for WAN scenarios in which network time prevails it is more important to cache query results. Figure 14 : Impact of distribution changes on the static caching of posting lists.", "keyphrases": ["effici cach system", "web search engin", "static cach", "dynam cach", "cach queri result", "cach post list", "static cach", "answer and post list", "queri log", "effect of static cach", "distribut of the queri", "data-access hierarchi", "disk layer", "remot server layer"]}
{"file_name": "J-32", "text": "Nash Equilibria in Graphical Games on Trees Revisited * Graphical games have been proposed as a game-theoretic model of large-scale distributed networks of non-cooperative agents. When the number of players is large, and the underlying graph has low degree, they provide a concise way to represent the players ' payoffs. It has recently been shown that the problem of finding Nash equilibria in a general degree-3 graphical game with two actions per player is complete for the complexity class PPAD, indicating that it is unlikely that there is any polynomial-time algorithm for this problem. In this paper, we study the complexity of graphical games with two actions per player on bounded-degree trees. This setting was first considered by Kearns, Littman and Singh, who proposed a dynamic programming-based algorithm that computes all Nash equilibria of such games. The running time of their algorithm is exponential, though approximate equilibria can be computed efficiently. Later, Littman, Kearns and Singh proposed a modification to this algorithm that can find a single Nash equilibrium in polynomial time. We show that this modified algorithm is incorrect -- the output is not always a Nash equilibrium. We then propose a new algorithm that is based on the ideas of Kearns et al. and computes all Nash equilibria in quadratic time if the input graph is a path, and in polynomial time if it is an arbitrary graph of maximum degree 2. Moreover, our algorithm can be used to compute Nash equilibria of graphical games on arbitrary trees, but the running time can be exponential, even when the tree has bounded degree. We show that this is inevitable -- any algorithm of this type will take exponential time, even on bounded-degree trees with pathwidth 2. It is an open question whether our algorithm runs in polynomial time on graphs with pathwidth 1, but we show that finding a Nash equilibrium for a 2-action graphical game in which the underlying graph has maximum degree 3 and constant pathwidth is PPAD-complete -LRB- so is unlikely to be tractable -RRB-. * This research is supported by the EPSRC research grants `` Algorithmics of Network-sharing Games '' and `` Discontinuous Behaviour in the Complexity of randomized Algorithms ''. 1. INTRODUCTION Graphical games were introduced in the papers of Kearns et al. -LSB- 8 -RSB- and Littman et al. -LSB- 9 -RSB- as a succinct representation of games with a large number of players. The classical normal form -LRB- or matrix form -RRB- representation has a size that is exponential in the number of players, making it unsuitable for large-scale distributed games. A graphical game associates each player with a vertex of an underlying graph G, and the payoff to that player is a function of the actions chosen by himself and his neighbours in G ; if G has low degree, this is a concise way to represent a game with many players. The papers -LSB- 8, 9 -RSB- give a dynamic-programming algorithm for finding Nash equilibria in graphical games where there are two actions per player and G is a tree. The first of these papers describes a generic algorithm for this problem that can be specialized in two ways : as an algorithm that computes approximations to all Nash equilibria in time polynomial in the input size and the approximation quality, or as an exponential-time algorithm that allows the exact computation of all Nash equilibria in G. In -LSB- 9 -RSB-, the authors propose a modification to the latter algorithm that aims to find a single Nash equilibrium in polynomial time. This does not quite work, as we show in Section 3, though it introduces a useful idea. 1.1 Background The generic algorithm of -LSB- 8 -RSB- consists of two phases which we will refer to as the upstream pass and the downstream pass ; 1 the former starts at the leaves of the tree and ends at the root, while the latter starts at the root and ends at the leaves. there is a Nash equilibrium in the graphical game downstream of V -LRB- inclusive -RRB- given that W plays w -LRB- for a more technical definition, the reader is referred to Section 2 -RRB-. The generic algorithm does not address the problem of representing the best response policy ; in fact, the most important difference between the two instantiations of the generic algorithm described in -LSB- 8 -RSB- is in their approach to this issue. The computation is performed inductively : the best response policy for V is computed based on the best response policies of V 's children U1,..., Uk. By the end of the upstream pass, all children of the root have computed their best response policies. In the beginning of the downstream pass, the root selects its strategy and informs its children about its choice. It also selects a strategy for each child. A necessary and sufficient condition for the algorithm to proceed is that the strategy of the root is a best response to the strategies of its children and, for each child, the chosen strategy is one of the pre-computed potential best responses to the chosen strategy of the root. The equilibrium then propagates downstream, with each vertex selecting its children 's actions. The action of the child is chosen to be any strategy from the pre-computed potential best responses to the chosen strategy of the parent. To bound the running time of this algorithm, the paper -LSB- 8 -RSB- shows that any best response policy can be represented as a union of an exponential number of rectangles ; the polynomial time approximation algorithm is obtained by combining this representation with a polynomial-sized grid. 1.2 Our Results One of the main contributions of our paper is to show that the algorithm proposed by -LSB- 9 -RSB- is incorrect. In Section 3 we describe a simple example for which the algorithm of -LSB- 9 -RSB- outputs a vector of strategies that does not constitute a Nash equilibrium of the underlying game. In Sections 4, 5 and 6 we show how to fix the algorithm of -LSB- 9 -RSB- so that it always produces correct output. Section 4 considers the case in which the underlying graph is a path of length n. For this case, we show that the number of rectangles in each of the best response policies is O -LRB- n2 -RRB-. This gives us an O -LRB- n3 -RRB- algorithm for finding a Nash equilibrium, and for computing a representation of all Nash equilibria. -LRB- This algorithm is a special case of the generic algorithm of -LSB- 8 -RSB- -- we show that it runs in polynomial time when the underlying graph is a path. -RRB- We can improve the running time of the generic algorithm using the ideas of -LSB- 9 -RSB-. In particular, we give an O -LRB- n2 -RRB- algorithm for finding a Nash equilibrium of a graphical game on a path of length n. Instead of storing best response policies, this algorithm stores appropriately-defined subsets, which, following -LSB- 9 -RSB-, we call breakpoint policies -LRB- modifying the definition as necessary -RRB-. We obtain the following theorem THEOREM 1. There is an O -LRB- n2 -RRB- algorithm that finds a Nash equilibrium of a graphical game with two actions per player on an n-vertex path. There is an O -LRB- n3 -RRB- algorithm that computes a representation of all Nash equilibria of such a game. In Section 5 we extend the results of Section 4 to general degree2 graphs, obtaining the following theorem. THEOREM 2. There is a polynomial-time algorithm thatfinds a Nash equilibrium of a graphical game with two actions per player on a graph with maximum degree 2. In Section 6 we extend our algorithm so that it can be used to find a Nash equilibrium of a graphical game on an arbitrary tree. Even when the tree has bounded degree, the running time can be exponential. We show that this is inevitable by constructing a family of graphical games on bounded-degree trees for which best response policies of some of the vertices have exponential size, and any twopass algorithm -LRB- i.e., an algorithm that is similar in spirit to that of -LSB- 8 -RSB- -RRB- has to store almost all points of the best response policies. In particular, we show the following. THEOREM 3. There is an infinite family ofgraphical games on bounded-degree trees with pathwidth 2 such that any two-pass algorithm for finding Nash equilibria on these trees requires exponential time and space. It is interesting to note that the trees used in the proof of Theorem 3 have pathwidth 2, that is, they are very close to being paths. It is an open question whether our algorithm runs in polynomial time for graphs of pathwidth 1. This question can be viewed as a generalization of a very natural computational geometry problem -- we describe it in more detail in Section 8. In Section 7, we give a complexity-theoretic intractability result for the problem of finding a Nash equilibrium of a graphical game on a graph with small pathwidth. We prove the following theorem. THEOREM 4. Consider the problem offinding a Nash equilibrium for a graphical game in which the underlying graph has maximum degree 3 and pathwidth k. There is a constant k such that this problem is PPAD-complete. Theorem 4 limits the extent to which we can exploit `` path-like '' properties of the underlying graph, in order to find Nash equilibria. To prove Theorem 4, we use recent PPAD-completeness results for games, in particular the papers -LSB- 7, 4 -RSB- which show that the problem of finding Nash equilibria in graphical games of degree d -LRB- for d > 3 -RRB- is computationally equivalent to the problem of solving r-player normal-form games -LRB- for r > 4 -RRB-, both of which are PPAD-complete. 8. OPEN PROBLEMS The most important problem left open by this paper is whether it is possible to find a Nash equilibrium of a graphical game on a bounded-degree tree in polynomial time. Our construction shows that any two-pass algorithm that explicitly stores breakpoint policies needs exponential time and space. However, it does not preclude the existence of an algorithm that is based on a similar idea, but, instead of computing the entire breakpoint policy for each vertex, uses a small number of additional passes through the graph to decide which -LRB- polynomial-sized -RRB- parts of each breakpoint policy should be computed. In particular, such an algorithm may be based on the approximation algorithm of -LSB- 8 -RSB-, where the value of e is chosen adaptively. Another intriguing question is related to the fact that the graph for which we constructed an exponential-sized breakpoint policy has pathwidth 2, while our positive results are for a path, i.e., a graph of pathwidth 1. It is not clear if for any bounded-degree graph of pathwidth 1 the running time of -LRB- the breakpoint policybased version of -RRB- our algorithm will be polynomial. In particular, it is instructive to consider a `` caterpillar '' graph, i.e., the graph that can be obtained from Tn by deleting the vertices S1,..., Sn. This implies that the problem of bounding the size of the best response policy -LRB- or, alternatively, the breakpoint policy -RRB-, can be viewed as a generalization of the following computational geometry problem, which we believe may be of independent interest : PROBLEM 1. Ifyes, can it be the case that in this set, there is no path with a polynomial number of turns that connects the endpoints of the original segment? This implies that even for a caterpillar, the best response policy can be exponentially large. However, in our example -LRB- which is omitted from this version of the paper due to space constraints -RRB-, there exists a polynomial-size path through the best response policy, i.e., it does not prove that the breakpoint policy is necessarily exponential in size. If one can prove that this is always the case, it may be possible to adapt this proof to show that there can be an exponential gap between the sizes of best response policies and breakpoint policies.", "keyphrases": ["graphic game", "larg-scale distribut network", "nash equilibrium", "degre", "dynam program-base algorithm", "ppad-complet", "bound-degre tree", "gener algorithm", "respons polici", "downstream pass", "breakpoint polici"]}
{"file_name": "I-16", "text": "An Advanced Bidding Agent for Advertisement Selection on Public Displays ABSTRACT In this paper we present an advanced bidding agent that participates in first-price sealed bid auctions to allocate advertising space on BluScreen -- an experimental public advertisement system that detects users through the presence of their Bluetooth enabled devices. Our bidding agent is able to build probabilistic models of both the behaviour of users who view the adverts, and the auctions that it participates within. It then uses these models to maximise the exposure that its adverts receive. We evaluate the effectiveness of this bidding agent through simulation against a range of alternative selection mechanisms including a simple bidding strategy, random allocation, and a centralised optimal allocation with perfect foresight. Our bidding agent significantly outperforms both the simple bidding strategy and the random allocation, and in a mixed population of agents it is able to expose its adverts to 25 % more users than the simple bidding strategy. Moreover, its performance is within 7.5 % of that of the centralised optimal allocation despite the highly uncertain environment in which it must operate. 1. INTRODUCTION Electronic displays are increasingly being used within public environments, such as airports, city centres and retail stores, in order to advertise commercial products, or to entertain and inform passersby. of interactive public displays have been proposed. As such, these systems assume prior knowledge about the target audience, and require either that a single user has exclusive access to the display, or that users carry specific tracking devices so that their presence can be identified -LSB- 6, 11 -RSB-. However, these approaches fail to work in public spaces, where no prior knowledge regarding the users who may view the display exists, and where such displays need to react to the presence of several users simultaneously. By contrast, Payne et al. have developed an intelligent public display system, named BluScreen, that detects and tracks users through the Bluetooth enabled devices that they carry with them everyday -LSB- 8 -RSB-. Within this system, a decentralised multi-agent auction mechanism is used to efficiently allocate advertising time on each public display. Each advert is represented by an individual advertising agent that maintains a history of users who have already been exposed to the advert. This agent then seeks to acquire advertising cycles -LRB- during which it can display its advert on the public displays -RRB- by submitting bids to a marketplace agent who implements a sealed bid auction. The value of these bids is based upon the number of users who are currently present in front of the screen, the history of these users, and an externally derived estimate of the value of exposing an advert to a user. In this paper, we present an advanced bidding agent that significantly extends the sophistication of this approach. In particular, we consider the more general setting in which it is impossible to determine an a priori valuation for exposing an advert to a user. In addition, it is also likely to be the case within new commercial installations where limited market experience makes estimating a valuation impossible. The advertising agent is then simply tasked with using this budget to maximum effect -LRB- i.e. to achieve the maximum possible advert exposure within this time period -RRB-. Now, in order to achieve this goal, the advertising agent must be capable of modelling the behaviour of the users in order to predict the number who will be present in any future advertising cycle. In addition, it must also understand the auction environment in which it competes, in order that it may make best use of its limited budget. Thus, in developing an advanced bidding agent that achieves this, we advance the state of the art in four key ways : 1. We enable the advertising agents to model the arrival and departure of users as independent Poisson processes, and to make maximum likelihood estimates of the rates of these processes based on their observations. We show how these agents can then calculate the expected number of users who will be present during any future advertising cycle. 2. Using a decision theoretic approach we enable the advertising agents to model the probability of winning any given auction when a specific amount is bid. The cumulative form of the gamma distribution is used to represent this probability, and its parameters are fitted using observations of both the closing price of previous auctions, and the bids that that advertising agent itself submits. 3. We show that our explicit assumption that the advertising agent derives no additional benefit by showing an advert to a single user more than once, causes the expected utility of each future advertising cycle to be dependent on the expected outcome of all the auctions that precede it. We thus present a stochastic optimisation algorithm based upon simulated annealing that enables the advertising agent to calculate the optimal sequence of bids that maximises its expected utility. 4. The remainder of this paper is organised as follows : Section 2 discusses related work where agents and auction-based marketplaces are used to allocated advertising space. Section 3 describes the prototype BluScreen system that motivates our work. In section 4 we present a detailed description of the auction allocation mechanism, and in section 5 we describe our advanced bidding strategy for the advertising agents. In section 6 we present an empirical validation of our approach, and finally, we conclude in section 7. 2. RELATED WORK The commercial attractiveness of targeted advertising has been amply demonstrated on the internet, where recommendation systems and contextual banner adverts are the norm -LSB- 1 -RSB-. Attempts to apply these approaches within the real world have been much more limited. Gerding et al. present a simulated system -LRB- CASy -RRB- whereby a Vickrey auction mechanism is used to sell advertising space within a modelled electronic shopping mall -LSB- 2 -RSB-. The auction is used to rank a set of possible advertisements provided by different retail outlets, and the top ranking advertisements are selected for presentation on public displays. Feedback is provided through subsequent sales information, allowing the model to build up a profile of a user 's preferences. However, unlike the BluScreen Figure 1 : A deployed BluScreen prototype. system that we consider here, it is not suitable for advertising to many individuals simultaneously, as it requires explicit interaction with a single user to acquire the user 's preferences. User identification is based on infrared badges and embedded sensors within an office environment. When several users pass by the display, a centralised system compares the user 's profiles to identify common areas of interest, and content that matches this common interest is shown. Thus, whilst CASy is a simulated system that allows advertisers to compete for the attention of single user, GroupCast is a prototype system that detects the presence of groups of users and selects content to match their profiles. Despite their similarities, neither system addresses the settings that interests us here : how to allocate advertising space between competing advertisers who face an audience of multiple individuals about whom there is no a priori profile information. Thus, in the next section we describe the prototype BluScreen system that motivates our work. 7. CONCLUSIONS In this paper, we presented an advanced bidding strategy for use by advertising agents within the BluScreen advertising system. This bidding strategy enabled advertising agents to model and predict the arrival and departure of users, and also to model their success within a first-price sealed bid auction by observing both the bids that they themselves submitted and the winning bid. The ex The Sixth Intl.. Joint Conf. Figure 8 : Comparison of an evenly mixed population of advertising agents using simple and advanced bidding strategies over a range of parameter settings. Results are averaged over 50 simulation runs and error bars indicate the standard error in the mean. Figure 9 : Comparison of an unevenly mixed population of advertising agents using simple and advanced bidding strategies. Results are averaged over 50 simulation runs and error bars indicate the standard error in the mean. pected utility, measured as the number of users who the advertising agent exposes its advert to, was shown to depend on these factors, and resulted in a complex expression where the expected utility of each auction depended on the success or otherwise of earlier auctions. We presented an algorithm based upon simulated annealing to solve for the optimal bidding strategy, and in simulation, this bidding strategy was shown to significantly outperform a simple bidding strategy that had none of these features. Its performance closely approached that of a central optimal allocation, with perfect knowledge of the arrival and departure of users, despite the uncertain environment in which the strategy must operate. This work will continue to be done in conjunction with the deployment of more BluScreen prototypes in order to gain further real world experience.", "keyphrases": ["advanc bid agent", "bluscreen", "experiment public advertis system", "bluetooth", "probabilist model", "centralis optim alloc", "distribut artifici intellig", "decentralis multi-agent auction mechan", "independ poisson process", "decis theoret approach", "stochast optimis algorithm"]}
{"file_name": "J-18", "text": "Mediators in Position Auctions ABSTRACT A mediator is a reliable entity, which can play on behalf of agents in a given game. A mediator however can not enforce the use of its services, and each agent is free to participate in the game directly. In this paper we introduce a study of mediators for games with incomplete information, and apply it to the context of position auctions, a central topic in electronic commerce. VCG position auctions, which are currently not used in practice, possess some nice theoretical properties, such as the optimization of social surplus and having dominant strategies. These properties may not be satisfied by current position auctions and their variants. We therefore concentrate on the search for mediators that will allow to transform current position auctions into VCG position auctions. We require that accepting the mediator services, and reporting honestly to the mediator, will form an ex post equilibrium, which satisfies the following rationality condition : an agent 's payoff can not be negative regardless of the actions taken by the agents who did not choose the mediator 's services, or by the agents who report false types to the mediator. We prove the existence of such desired mediators for the next-price -LRB- Google-like -RRB- position auctions, as well as for a richer class of position auctions, including all k-price position auctions, k > 1. For k = 1, the self-price position auction, we show that the existence of such mediator depends on the tie breaking rule used in the auction. 1. INTRODUCTION Consider an interaction in a multi-agent system, in which every player holds some private information, which is called the player 's type. For example, in an auction interaction the type of a player is its valuation, or, in more complex auctions, its valuation function. This interaction is modeled as a game with incomplete information. This game is called a Bayesian game, when a commonly known probability measure on the profiles of types is added to the system. Otherwise it is called a pre-Bayesian game. In this paper we deal only with pre-Bayesian games. Consider the following simple example of a pre-Bayesian game, which possesses an ex post equilibrium. The game is denoted by H.", "keyphrases": ["auction", "mediat", "ex post equilibrium", "agent", "posit auction", "electron commerc", "richer class of posit auction", "next-price posit auction", "multi-agent system", "t-strategi", "vcg outcom function", "self-price posit auction"]}
{"file_name": "H-29", "text": "Estimation and Use of Uncertainty in Pseudo-relevance Feedback ABSTRACT Existing pseudo-relevance feedback methods typically perform averaging over the top-retrieved documents, but ignore an important statistical dimension : the risk or variance associated with either the individual document models, or their combination. Treating the baseline feedback method as a black box, and the output feedback model as a random variable, we estimate a posterior distribution for the feedback model by resampling a given query 's top-retrieved documents, using the posterior mean or mode as the enhanced feedback model. We then perform model combination over several enhanced models, each based on a slightly modified query sampled from the original query. We find that resampling documents helps increase individual feedback model precision by removing noise terms, while sampling from the query improves robustness -LRB- worst-case performance -RRB- by emphasizing terms related to multiple query aspects. The result is a meta-feedback algorithm that is both more robust and more precise than the original strong baseline method. 1. INTRODUCTION Uncertainty is an inherent feature of information retrieval. Even if the query were perfectly specified, language in the collection documents is inherently complex and ambiguous and matching such language effectively is a formidable problem by itself. In this way, retrieval algorithms may attempt to quantify the risk or uncertainty associated with their output rankings, or improve the stability or precision of their internal calculations. Current algorithms for pseudo-relevance feedback -LRB- PRF -RRB- tend to follow the same basic method whether we use vector space-based algorithms such as Rocchio 's formula -LSB- 16 -RSB-, or more recent language modeling approaches such as Relevance Models -LSB- 10 -RSB-. First, a set of top-retrieved documents is obtained from an initial query and assumed to approximate a set of relevant documents. Next, a single feedback model vector is computed according to some sort of average, centroid, or expectation over the set of possibly-relevant document models. For example, the document vectors may be combined with equal weighting, as in Rocchio, or by query likelihood, as may be done using the Relevance Model '. The use of an expectation is reasonable for practical and theoretical reasons, but by itself ignores potentially valuable information about the risk of the feedback model. Our main hypothesis in this paper is that estimating the uncertainty in feedback is useful and leads to better individual feedback models and more robust combined models. Therefore, we propose a method for estimating uncertainty associated with an individual feedback model in terms of a posterior distribution over language models. To do this, we systematically vary the inputs to the baseline feedback method and fit a Dirichlet distribution to the output. We use the posterior mean or mode as the improved feedback model estimate. This process is shown in Figure 1. As we show later, the mean and mode may vary significantly from the single feedback model proposed by the baseline method. We also perform model combination using several improved feedback language models obtained by a small number of new queries sampled from the original query. A model 's weight combines two complementary factors : the model 's probability of generating the query, and the variance of the model, with high-variance models getting lower weight. ` For example, an expected parameter vector conditioned on the query observation is formed from top-retrieved documents, which are treated as training strings -LRB- see -LSB- 10 -RSB-, p. 62 -RRB-. Figure 1 : Estimating the uncertainty of the feedback model for a single query. 4. RELATED WORK Our approach is related to previous work from several areas of information retrieval and machine learning. These studies use the idea of creating multiple subqueries and then examining the nature of the overlap in the documents and/or expansion terms that result from each subquery. Model combination is performed using heuristics. In particular, the studies of Amati et al. and Carpineto et al. investigated combining terms from individual distributional methods using a term-reranking combination heuristic. In a set of TREC topics they found wide average variation in the rank-distance of terms from different expansion methods. Their combination method gave modest positive improvements in average precision. The idea of examining the overlap between lists of suggested terms has also been used in early query expansion approaches. On the document side, recent work by Zhou & Croft -LSB- 21 -RSB- explored the idea of adding noise to documents, re-scoring them, and using the stability of the resulting rankings as an estimate of query difficulty. This is related to our use of document sampling to estimate the risk of the feedback model built from the different sets of top-retrieved documents. Sakai et al. -LSB- 17 -RSB- proposed an approach to improving the robustness of pseudo-relevance feedback using a method they call selective sampling. Greiff, Morgan and Ponte -LSB- 8 -RSB- explored the role of variance in term weighting. In a series of simulations that simplified the problem to 2-feature documents, they found that average precision degrades as term frequency variance -- high noise -- increases. Downweighting terms with high variance resulted in improved average precision. This seems in accord with our own findings for individual feedback models. Estimates of output variance have recently been used for improved text classification. Lee et al. -LSB- 11 -RSB- used queryspecific variance estimates of classifier outputs to perform improved model combination. Instead of using sampling, they were able to derive closed-form expressions for classifier variance by assuming base classifiers using simple types of inference networks. Ando and Zhang proposed a method that they call structural feedback -LSB- 3 -RSB- and showed how to apply it to query expansion for the TREC Genomics Track. They used r query variations to obtain R different sets Sr of top-ranked documents that have been intersected with the top-ranked documents obtained from the original query qorig. For each Si, the normalized centroid vector \u02c6wi of the documents is calculated. Principal component analysis -LRB- PCA -RRB- is then applied to the \u02c6wi to obtain the matrix 4 -RRB- of H left singular vectors \u03c6h that are used to obtain the new, expanded query The use of variance as a feedback model quality measure occurs indirectly through the application of PCA. It would be interesting to study the connections between this approach and our own modelfitting method. Finally, in language modeling approaches to feedback, Tao and Zhai -LSB- 18 -RSB- describe a method for more robust feedback that allows each document to have a different feedback \u03b1. The feedback weights are derived automatically using regularized EM. A roughly equal balance of query and expansion model is implied by their EM stopping condition. They propose tailoring the stopping parameter \u03b7 based on a function of some quality measure of feedback documents. 5. CONCLUSIONS We have presented a new approach to pseudo-relevance feedback based on document and query sampling. Such variance estimates, for example, may be naturally used in a Bayesian framework for improved model estimation and combination. While our study uses the language modeling approach as a framework for experiments, we make few assumptions about the actual workings of the feedback algorithm. We believe it is likely that any reasonably effective baseline feedback algorithm would benefit from our approach. Our results on standard TREC collections show that our framework improves the robustness of a strong baseline feedback method across a variety of collections, without sacrificing average precision. It also gives small but consistent gains in top10 precision. In future work, we envision an investigation into how varying the set of sampling methods used and the number of samples controls the trade-off between robustness, accuracy, and efficiency.", "keyphrases": ["feedback method", "posterior distribut", "enhanc feedback model", "inform retriev", "queri expans", "probabl distribut", "pseudo-relev feedback", "vector space-base algorithm", "risk", "feedback model", "estim uncertainti", "languag model", "feedback distribut"]}
{"file_name": "H-20", "text": "New Event Detection Based on Indexing-tree and Named Entity ABSTRACT New Event Detection -LRB- NED -RRB- aims at detecting from one or multiple streams of news stories that which one is reported on a new event -LRB- i.e. not reported previously -RRB-. With the overwhelming volume of news available today, there is an increasing need for a NED system which is able to detect new events more efficiently and accurately. In this paper we propose a new NED model to speed up the NED task by using news indexing-tree dynamically. Moreover, based on the observation that terms of different types have different effects for NED task, two term reweighting approaches are proposed to improve NED accuracy. In the first approach, we propose to adjust term weights dynamically based on previous story clusters and in the second approach, we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories. Experimental results on two Linguistic Data Consortium -LRB- LDC -RRB- datasets TDT2 and TDT3 show that the proposed model can improve both efficiency and accuracy of NED task significantly, compared to the baseline system and other existing systems. 1. INTRODUCTION New Event Detection -LRB- NED -RRB- is one of the five tasks in TDT. A Topic is defined as `` a seminal event or activity, along with directly related events and activities '' -LSB- 2 -RSB-. An Event is defined as `` something -LRB- non-trivial -RRB- happening in a certain place at a certain time '' -LSB- 3 -RSB-. Useful news information is usually buried in a mass of data generated everyday. Therefore, NED systems are very useful for people who need to detect novel information from real-time news stream. These real-life needs often occur in domains like financial markets, news analysis, and intelligence gathering. In most of state-of-the-art -LRB- currently -RRB- NED systems, each news story on hand is compared to all the previous received stories. If all the similarities between them do not exceed a threshold, then the story triggers a new event. The core problem of NED is to identify whether two stories are on the same topic. Obviously, these systems can not take advantage of topic information. Other systems organize previous stories into clusters -LRB- each cluster corresponds to a topic -RRB-, and new story is compared to the previous clusters instead of stories. This manner can reduce comparing times significantly. This is because sometimes stories within a topic drift far away from each other, which could lead low similarity between a story and its topic. On the other hand, some proposed NED systems tried to improve accuracy by making better use of named entities -LSB- 10, 11, 12, 13 -RSB-. However, none of the systems have considered that terms of different types -LRB- e.g. Noun, Verb or Person name -RRB- have different effects for different classes of stories in determining whether two stories are on the same topic. For example, the names of election candidates -LRB- Person name -RRB- are very important for stories of election class ; the locations -LRB- Location name -RRB- where accidents happened are important for stories of accidents class. -LRB- 2 -RRB- How to make good use of cluster -LRB- topic -RRB- information to improve accuracy? -LRB- 3 -RRB- How to obtain better news story representation by better understanding of named entities. Driven by these problems, we have proposed three approaches in this paper. -LRB- 1 -RRB- To make the detection procedure faster, we propose a new NED procedure based on news indexing-tree created dynamically. Story indexing-tree is created by assembling similar stories together to form news clusters in different hierarchies according to their values of similarity. Comparisons between current story and previous clusters could help find the most similar story in less comparing times. The new procedure can reduce the amount of comparing times without hurting accuracy. -LRB- 2 -RRB- We use the clusters of the first floor in the indexing-tree as news topics, in which term weights are adjusted dynamically according to term distribution in the clusters. In this approach, cluster -LRB- topic -RRB- information is used properly, so the problem of theme decentralization is avoided. -LRB- 3 -RRB- Based on observations on the statistics obtained from training data, we found that terms of different types -LRB- e.g. Noun and Verb -RRB- have different effects for different classes of stories in determining whether two stories are on the same topic. And we propose to use statistics to optimize the weights of the terms of different types in a story according to the news class that the story belongs to. The rest of the paper is organized as follows. We start off this paper by summarizing the previous work in NED in section 2. Section 3 presents the basic model for NED that most current systems use. Section 4 describes our new detection procedure based on news indexing-tree. In section 5, two term reweighting methods are proposed to improve NED accuracy. Section 6 gives our experimental data and evaluation metrics. We finally wrap up with the experimental results in Section 7, and the conclusions and future work in Section 8. 2. RELATED WORK Papka et al. proposed Single-Pass clustering on NED -LSB- 6 -RSB-. When a new story was encountered, it was processed immediately to extract term features and a query representation of the story 's content is built up. Then it was compared with all the previous queries. If the document did not trigger any queries by exceeding a threshold, it was marked as a new event. Lam et al build up previous query representations of story clusters, each of which corresponds to a topic -LSB- 7 -RSB-. In this manner comparisons happen between stories and clusters. Recent years, most work focus on proposing better methods on comparison of stories and document representation. Good improvements on TDT bench-marks were shown. Stokes et al. -LSB- 9 -RSB- utilized a combination of evidence from two distinct representations of a document 's content. One of the representations was the usual free text vector, the other made use of lexical chains -LRB- created using WordNet -RRB- to build another term vector. Then the two representations are combined in a linear fashion. A marginal increase in effectiveness was achieved when the combined representation was used. Some efforts have been done on how to utilize named entities to improve NED. Yang et al. gave location named entities four times weight than other terms and named entities -LSB- 10 -RSB-. DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity -LSB- 11 -RSB- -LSB- 12 -RSB-. UMass -LSB- 13 -RSB- research group split document representation into two parts : named entities and non-named entities. And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation. Both -LSB- 10 -RSB- and -LSB- 13 -RSB- used text categorization technique to classify news stories in advance. In -LSB- 13 -RSB- news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class. In -LSB- 10 -RSB- frequent terms for each class are removed from document representation. In their work, effectiveness of different kinds of names -LRB- or terms with different POS -RRB- for NED in different news classes are not investigated. 8. CONCLUSION We have proposed a news indexing-tree based detection procedure in our model. It reduces comparing times to about one seventh of traditional method without hurting NED accuracy. We also have presented two extensions to the basic TF-IDF model. The first extension is made by adjust term weights based on term distributions between the whole corpus and a cluster story set. And the second extension to basic TF-IDF model is better use of term types -LRB- named entities types and part-of-speed -RRB- according to news categories. Our experimental results on TDT2 and TDT3 datasets show that both of the two extensions contribute significantly to improvement in accuracy. For the future work, we want to collect news set which span for a longer period from internet, and integrate time information in NED task. Since topic is a relative coarse-grained news cluster, we also want to refine cluster granularity to event-level, and identify different events and their relations within a topic.", "keyphrases": ["new event detect", "stream of new stori", "volum of new", "new index-tree", "term reweight approach", "ned accuraci", "term weight", "statist", "train data", "name entiti reweight mode", "class of stori", "linguist data consortium", "baselin system", "exist system"]}
{"file_name": "H-7", "text": "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems ABSTRACT A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual user 's interest. A system serving millions of users can learn a better user profile for a new user, or a user with little feedback, by borrowing information from other users through the use of a Bayesian hierarchical model. Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive. The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications. This paper proposes a new fast learning technique to learn a large number of individual user profiles. The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens. 1. INTRODUCTION For example, online stores, such as Amazon and Netflix, provide customized recommendations for additional products or services based on a user 's history. One major personalization topic studied in the information retrieval community is content-based personal recommendation systems '. These systems learn user-specific pro'Content - based recommendation is also called adaptive fil files from user feedback so that they can recommend information tailored to each individual user 's interest without requiring the user to make an explicit query. Learning the user profiles is the core problem for these systems. A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user. One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small. This is known as the `` cold start '' problem. This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile. There has been much research on improving classification accuracy when the amount of labeled training data is small. The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal -LSB- 26 -RSB-. Another approach is using domain knowledge. The third approach is borrowing training data from other resources -LSB- 5 -RSB- -LSB- 7 -RSB-. The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data. One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach. Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial performance for each user -LSB- 27 -RSB- -LSB- 25 -RSB-. In order to learn a Bayesian hierarchical model, the system usually tries to find the most likely model parameters for the given data. A mature recommendation system usually works for millions of users. It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users. The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee. However, a content based recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector. With careful analysis of the EM algorithm in this scenario -LRB- Section 4 -RRB-, we find that the EM tering, or item-based collaborative filtering. In this paper, the words `` filtering '' and `` recommendation '' are used interchangeably. algorithm converges very slowly due to the sparseness of the input variables. We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O -LRB- MK -RRB-, where M is the number of users and K is the number of dimensions. This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the `` Modified EM algorithm. '' This greatly reduces the computation at a single EM iteration, and also has the benefit of increasing the convergence speed of the learning algorithm. The proposed technique is not only well supported by theory, but also by experimental results. The organization of the remaining parts of this paper is as follows : Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations. Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper. The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6. 2. RELATED WORK Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970 's. The approaches that have been used to solve this problem can be roughly classified into two major categories : content based filtering versus collaborative filtering. Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user. Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past. Memorybased heuristics and model based approaches have been used in collaborative filtering task -LSB- 15 -RSB- -LSB- 8 -RSB- -LSB- 2 -RSB- -LSB- 14 -RSB- -LSB- 12 -RSB- -LSB- 11 -RSB-. This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models, which have a strong theoretical basis and good empirical performance on recommendation tasks -LSB- 27 -RSB- -LSB- 25 -RSB-. This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better. We think each complements the other, and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback. Similar to some other researchers -LSB- 18 -RSB- -LSB- 1 -RSB- -LSB- 21 -RSB-, we found that a recommendation system will be more effective when both techniques are combined. 7. CONCLUSION Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user, especially for recommending new items with a small number of ratings. The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors. This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM. We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm. Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold. It is worth mentioning that even if the original problem space is not sparse, sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity. The proposed technique can also be adapted to improve the learning in such a scenario. We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU. Our work is one major step on the road to make Bayesian hierarchical linear models more practical. The proposed new technique can be easily adapted to run on a cluster of machines, and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users. The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems. EM algorithm is a commonly used machine learning technique. It is used to find model parameters in many IR problems where the training data is very sparse. Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering, the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems.", "keyphrases": ["model", "content-base", "recommend system", "linear regress", "collabor filter", "paramet", "learn techniqu", "ir", "em algorithm", "classif", "rate"]}
{"file_name": "I-32", "text": "An Adversarial Environment Model for Bounded Rational Agents in Zero-Sum Interactions ABSTRACT Multiagent environments are often not cooperative nor collaborative ; in many cases, agents have conflicting interests, leading to adversarial interactions. This paper presents a formal Adversarial Environment model for bounded rational agents operating in a zero-sum environment. In such environments, attempts to use classical utility-based search methods can raise a variety of difficulties -LRB- e.g., implicitly modeling the opponent as an omniscient utility maximizer, rather than leveraging a more nuanced, explicit opponent model -RRB-. We define an Adversarial Environment by describing the mental states of an agent in such an environment. We then present behavioral axioms that are intended to serve as design principles for building such adversarial agents. We explore the application of our approach by analyzing log files of completed Connect-Four games, and present an empirical analysis of the axioms ' appropriateness. 1. INTRODUCTION Early research in multiagent systems -LRB- MAS -RRB- considered cooperative groups of agents ; because individual agents had MAS research, however, soon began to consider interacting agents with individuated interests, as representatives of different humans or organizations with non-identical interests. When these types of interactions occur, environments require appropriate behavior from the agents situated in them. We call these environments Adversarial Environments, and call the clashing agents Adversaries. Models of cooperation and teamwork have been extensively explored in MAS through the axiomatization of mental states -LRB- e.g., -LSB- 8, 4, 5 -RSB- -RRB-. However, none of this research dealt with adversarial domains and their implications for agent behavior. Our paper addresses this issue by providing a formal, axiomatized mental state model for a subset of adversarial domains, namely simple zero-sum adversarial environments. In addition, traditional search methods -LRB- like Min-Max -RRB- do not make use of a model of the opponent, which has proven to be a valuable addition to adversarial planning -LSB- 9, 3, 11 -RSB-. In this paper, we develop a formal, axiomatized model for bounded rational agents that are situated in a zero-sum adversarial environment. The model uses different modality operators, and its main foundations are the SharedPlans -LSB- 4 -RSB- model for collaborative behavior. We explore environment properties and the mental states of agents to derive behavioral axioms ; these behavioral axioms constitute a formal model that serves as a specification and design guideline for agent design in such settings. We then investigate the behavior of our model empirically using the Connect-Four board game. We show that this game conforms to our environment definition, and analyze players ' behavior using a large set of completed match log 4. RELATED WORK However, all these formal theories deal with agent teamwork and cooperation. As far as we know, our model is the first to provide a formalized model for explicit adversarial environments and agents ' behavior in it. The classical Min-Max adversarial search algorithm was the first attempt to integrate the opponent into the search space with a weak assumption of an optimally playing opponent. Since then, much effort has gone into integrating the opponent model into the decision procedure to predict future behavior. Additional Adversarial planning work was done by Willmott et al. -LSB- 13 -RSB-, which provided an adversarial planning approach to the game of GO. The research mentioned above dealt with adversarial search and the integration of opponent models into classical utilitybased search methods. That work shows the importance of opponent modeling and the ability to exploit it to an agent 's advantage. However, the basic limitations of those search methods still apply ; our model tries to overcome those limitations by presenting a formal model for a new, mental state-based adversarial specification. 5. CONCLUSIONS We presented an Adversarial Environment model for a 2These were later removed from the final analysis. bounded rational agent that is situated in an N-player, zerosum environment. We used the SharedPlans formalization to define the model and the axioms that agents can apply as behavioral guidelines. The model is meant to be used as a guideline for designing agents that need to operate in such adversarial environments. We presented empirical results, based on ConnectFour log file analysis, that exemplify the model and the axioms for a bilateral instance of the environment. The results we presented are a first step towards an expanded model that will cover all types of adversarial environments, for example, environments that are non-zero-sum, and environments that contain natural agents that are not part of the direct conflict. Those challenges and more will be dealt with in future research.", "keyphrases": ["multiag environ", "adversari interact", "adversari environ", "behavior axiom", "bilater and multilater instanti", "evalu function", "benefici action", "connect-four game", "empir studi", "axiomat model", "zero-sum encount", "treatment group", "eval valu", "interact"]}
{"file_name": "I-29", "text": "Distributed Management of Flexible Times Schedules ABSTRACT We consider the problem of managing schedules in an uncertain, distributed environment. We assume a team of collaborative agents, each responsible for executing a portion of a globally pre-established schedule, but none possessing a global view of either the problem or solution. The goal is to maximize the joint quality obtained from the activities executed by all agents, given that, during execution, unexpected events will force changes to some prescribed activities and reduce the utility of executing others. We describe an agent architecture for solving this problem that couples two basic mechanisms : -LRB- 1 -RRB- a `` flexible times '' representation of the agent 's schedule -LRB- using a Simple Temporal Network -RRB- and -LRB- 2 -RRB- an incremental rescheduling procedure. The former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions, and the latter acts to revise the agent 's schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set. Basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter-dependent activities. Then, as time permits, the core local problem solving infra-structure is used to drive an inter-agent option generation and query process, aimed at identifying opportunities for solution improvement through joint change. Using a simulator to model the environment, we compare the performance of our multi-agent system with that of an expected optimal -LRB- but non-scalable -RRB- centralized MDP solver. 1. INTRODUCTION The practical constraints of many application environments require distributed management of executing plans and schedules. In this paper, we consider the problem of managing and executing schedules in an uncertain and distributed environment as defined by the DARPA Coordinators program. We assume a team of collaborative agents, each responsible for executing a portion of a globally preestablished schedule, but none possessing a global view of either the problem or solution. The team goal is to maximize the total quality of all activities executed by all agents, given that unexpected events will force changes to pre-scheduled activities and alter the utility of executing others as execution unfolds. To provide a basis for distributed coordination, each agent is aware of dependencies between its scheduled activities and those of other agents. Each agent is also given a pre-computed set of local contingency -LRB- fall-back -RRB- options. Central to our approach to solving this multi-agent problem is an incremental flexible-times scheduling framework. In a flexible-times representation of an agent 's schedule, the execution intervals associated with scheduled activities are not fixed, but instead are allowed to float within imposed time and activity sequencing constraints. However their use in distributed problem solving settings has been quite sparse -LRB- -LSB- 7 -RSB- is one exception -RRB-, and prior approaches to multi-agent scheduling -LRB- e.g., -LSB- 6, 13, 5 -RSB- -RRB- have generally operated with fixed-times representations of agent schedules. We define an agent architecture centered around incremental management of a flexible times schedule. Local change is ac Figure 1 : A two agent C TAEMS problem. complished by an incremental scheduler, designed to maximize quality while attempting to minimize schedule change. To this schedule management infra-structure, we add two mechanisms for multi-agent coordination. Basic coordination with other agents is achieved by simple communication of local schedule changes to other agents with interdependent activities. Layered over this is a non-local option generation and evaluation process -LRB- similar in some respects to -LSB- 5 -RSB- -RRB-, aimed at identification of opportunities for global improvement through joint changes to the schedules of multiple agents. We begin by briefly summarizing the general distributed scheduling problem of interest in our work. Next, we introduce the agent architecture we have developed to solve this problem and sketch its operation. In the following sections, we describe the components of the architecture in more detail, considering in turn issues relating to executing agent schedules, incrementally revising agent schedules and coordinating schedule changes among multiple agents. We then give some experimental results to indicate current system performance. Finally we conclude with a brief discussion of current research plans. 8. STATUS AND DIRECTIONS Our current research efforts are aimed at extending the capabilities of the Year 1 agent and scaling up to significantly larger problems. Year 2 programmatic evaluation goals call for solving problems on the order of 100 agents and 10,000 methods. This scale places much higher computational demands on all of the agent 's components. We have recently completed a re-implementation of the prototype agent designed to address some recognized performance issues. In addition to verifying that the performance on Year 1 problems is matched or exceeded, we have recently run some successful tests with the agent on a few 100 agent problems. To fully address various scale up issues, we are investigating a number of more advanced coordination mechanisms. To provide more global perspective to local scheduling decisions, we are introducing mechanisms for computing, communicating and using estimates of the non-local impact of remote nodes. To better address the problem of establishing inter-agent synchronization points, we expanding the use of task owners and qaf-specifc protocols as a means for directing coordination activity. Finally, we plan to explore the use of more advanced STN-driven coordination mechanisms, including the use of temporal decoupling -LSB- 7 -RSB- to insulate the actions of inter-dependent agents and the introduction of probability sensitive contingency schedules.", "keyphrases": ["manag schedul", "distribut environ", "agent architectur", "schedul", "inter-depend activ", "geograph separ", "flexibl time", "central plan", "manag", "schedul-execut", "slack", "shortest path algorithm", "activ alloc", "conflict-driven approach", "optimist synchron", "inter-agent coordin", "perform"]}
{"file_name": "C-30", "text": "Bullet : High Bandwidth Data Dissemination Using an Overlay Mesh ABSTRACT In recent years, overlay networks have become an effective alternative to IP multicast for efficient point to multipoint communication across the Internet. Typically, nodes self-organize with the goal of forming an efficient overlay tree, one that meets performance targets without placing undue burden on the underlying network. In this paper, we target high-bandwidth data distribution from a single source to a large number of receivers. Applications include large-file transfers and real-time multimedia streaming. For these applications, we argue that an overlay mesh, rather than a tree, can deliver fundamentally higher bandwidth and reliability relative to typical tree structures. This paper presents Bullet, a scalable and distributed algorithm that enables nodes spread across the Internet to self-organize into a high bandwidth overlay mesh. We construct Bullet around the insight that data should be distributed in a disjoint manner to strategic points in the network. Individual Bullet receivers are then responsible for locating and retrieving the data from multiple points in parallel. Key contributions of this work include : i -RRB- an algorithm that sends data to different points in the overlay such that any data object is equally likely to appear at any node, ii -RRB- a scalable and decentralized algorithm that allows nodes to locate and recover missing data items, and iii -RRB- a complete implementation and evaluation of Bullet running across the Internet and in a large-scale emulation environment reveals up to a factor two bandwidth improvements under a variety of circumstances. In addition, we find that, relative to tree-based solutions, Bullet reduces the need to perform expensive bandwidth probing. In a tree, it is critical that a node 's parent delivers a high rate of application data to each child. In Bullet however, nodes simultaneously receive data from multiple sources in parallel, making it less important to locate any single source capable of sustaining a high transmission rate. 1. INTRODUCTION In this paper, we consider the following general problem. Given a sender and a large set of interested receivers spread across the Internet, how can we maximize the amount of bandwidth delivered to receivers? Our problem domain includes software or video distribution and real-time multimedia streaming. Traditionally, native IP multicast has been the preferred method for delivering content to a set of receivers in a scalable fashion. However, a number of considerations, including scale, reliability, and congestion control, have limited the wide-scale deployment of IP multicast. Even if all these problems were to be addressed, IP multicast does not consider bandwidth when constructing its distribution tree. More recently, overlays have emerged as a promising alternative to multicast for network-efficient point to multipoint data delivery. Typical overlay structures attempt to mimic the structure of multicast routing trees. In network-layer multicast however, interior nodes consist of high speed routers with limited processing power and extensibility. Overlays, on the other hand, use programmable -LRB- and hence extensible -RRB- end hosts as interior nodes in the overlay tree, with these hosts acting as repeaters to multiple children down the tree. Overlays have shown tremendous promise for multicast-style applications. However, we argue that a tree structure has fundamental limitations both for high bandwidth multicast and for high reliability. One difficulty with trees is that bandwidth is guaranteed to be monotonically decreasing moving down the tree. Any loss high up the tree will reduce the bandwidth available to receivers lower down the tree. A number of techniques have been proposed to recover from losses and hence improve the available bandwidth in an overlay tree -LSB- 2, 6 -RSB-. However, fundamentally, the bandwidth available to any host is limited by the bandwidth available from that node 's single parent in the tree. Thus, our work operates on the premise that the model for high-bandwidth multicast data dissemination should be re-examined. Rather than sending identical copies of the same data stream to all nodes in a tree and designing a scalable mechanism for recovering from loss, we propose that participants in a multicast overlay cooperate to strategically transmit disjoint data sets to various points in the network. Here, the sender splits data into sequential blocks. Blocks are further subdivided into individual objects which are in turn transmitted to different points in the network. Nodes still receive a set of objects from their parents, but they are then responsible for locating peers that hold missing data objects. We use a distributed algorithm that aims to make the availability of data items uniformly spread across all overlay participants. In this way, we avoid the problem of locating the `` last object '', which may only be available at a few nodes. To illustrate Bullet 's behavior, consider a simple three node overlay with a root R and two children A and B. R has 1 Mbps of available -LRB- TCP-friendly -RRB- bandwidth to each of A and B. However, there is also 1 Mbps of available bandwidth between A and B. In this example, Bullet would transmit a disjoint set of data at 1 Mbps to each of A and B. A and B would then each independently discover the availability of disjoint data at the remote peer and begin streaming data to one another, effectively achieving a retrieval rate of 2 Mbps. On the other hand, any overlay tree is restricted to delivering at most 1 Mbps even with a scalable technique for recovering lost data. Any solution for achieving the above model must maintain a number of properties. First, it must be TCP friendly -LSB- 15 -RSB-. Second, it must impose low control overhead. There are many possible sources of such overhead, including probing for available bandwidth between nodes, locating appropriate nodes to `` peer '' with for data retrieval and redundantly receiving the same data objects from multiple sources. Third, the algorithm should be decentralized and scalable to thousands of participants. No node should be required to learn or maintain global knowledge, for instance global group membership or the set of data objects currently available at all nodes. Finally, the approach must be robust to individual failures. For example, the failure of a single node should result only in a temporary reduction in the bandwidth delivered to a small subset of participants ; no single failure should result in the complete loss of data for any significant fraction of nodes, as might be the case for a single node failure `` high up '' in a multicast overlay tree. In this context, this paper presents the design and evaluation of Bullet, an algorithm for constructing an overlay mesh that attempts to maintain the above properties. Bullet nodes begin by self-organizing into an overlay tree, which can be constructed by any of a number of existing techniques -LSB- 1, 18, 21, 24, 34 -RSB-. Each Bullet node, starting with the root of the underlying tree, then transmits a disjoint set of data to each of its children, with the goal of maintaining uniform representativeness of each data item across all participants. The level of disjointness is determined by the bandwidth available to each of its children. Bullet then employs a scalable and efficient algorithm to enable nodes to quickly locate multiple peers capable of transmitting missing data items to the node. Thus, Bullet layers a high-bandwidth mesh on top of an arbitrary overlay tree. Finally, we use TFRC -LSB- 15 -RSB- to transfer data both down the overlay tree and among peers. One important benefit of our approach is that the bandwidth delivered by the Bullet mesh is somewhat independent of the bandwidth available through the underlying overlay tree. One significant limitation to building high bandwidth overlay trees is the overhead associated with the tree construction protocol. In these trees, it is critical that each participant locates a parent via probing with a high level of available bandwidth because it receives data from only a single source -LRB- its parent -RRB-. Thus, even once the tree is constructed, nodes must continue their probing to adapt to dynamically changing network conditions. While bandwidth probing is an active area of research -LSB- 20, 35 -RSB-, accurate results generally require the transfer of a large amount of data to gain confidence in the results. Our approach with Bullet allows receivers to obtain high bandwidth in aggregate using individual transfers from peers spread across the system. Thus, in Bullet, the bandwidth available from any individual peer is much less important than in any bandwidthoptimized tree. Further, all the bandwidth that would normally be consumed probing for bandwidth can be reallocated to streaming data across the Bullet mesh. We have completed a prototype of Bullet running on top of a number of overlay trees. Our evaluation of a 1000-node overlay running across a wide variety of emulated 20,000 node network topologies shows that Bullet can deliver up to twice the bandwidth of a bandwidth-optimized tree -LRB- using an offline algorithm and global network topology information -RRB-, all while remaining TCP friendly. For these live Internet runs, we find that Bullet can deliver comparable bandwidth performance improvements. In both cases, the overhead of maintaining the Bullet mesh and locating the appropriate disjoint data is limited to 30 Kbps per node, acceptable for our target high-bandwidth, large-scale scenarios. The remainder of this paper is organized as follows. Section 2 presents Bullet 's system components including RanSub, informed content delivery, and TFRC. Section 3 then details Bullet, an efficient data distribution system for bandwidth intensive applications. Section 4 evaluates Bullet 's performance for a variety of network topologies, and compares it to existing multicast techniques. Section 5 places our work in the context of related efforts and Section 6 presents our conclusions. 5. RELATED WORK Snoeren et al. -LSB- 36 -RSB- use an overlay mesh to achieve reliable and timely delivery of mission-critical data. In this system, every node chooses n `` parents '' from which to receive duplicate packet streams. Since its foremost emphasis is reliability, the system does not attempt to improve the bandwidth delivered to the overlay participants by sending disjoint data at each level. Further, during recovery from parent failure, it limits an overlay router 's choice of parents to nodes with a level number that is less than its own level number. Kazaa nodes are organized into a scalable, hierarchical structure. Individual users search for desired content in the structure and proceed to simultaneously download potentially disjoint pieces from nodes that already have it. Since Kazaa does not address the multicast communication model, a large fraction of users downloading the same file would consume more bandwidth than nodes organized into the Bullet overlay structure. BitTorrent -LSB- 3 -RSB- is another example of a file distribution system currently deployed on the Internet. The tracker poses a scalability limit, as it continuously updates the systemwide distribution of the file. Similar to Bullet, BitTorrent incorporates the notion of `` choking '' at each node with the goal of identifying receivers that benefit the most by downloading from that particular source. FastReplica -LSB- 11 -RSB- addresses the problem of reliable and efficient file distribution in content distribution networks -LRB- CDNs -RRB-. In the basic algorithm, nodes are organized into groups of fixed size -LRB- n -RRB-, with full group membership information at each node. To distribute the file, a node splits it into n equal-sized portions, sends the portions to other group members, and instructs them to download the missing pieces in parallel from other group members. Since only a fixed portion of the file is transmitted along each of the overlay links, the impact of congestion is smaller than in the case of tree distribution. However, since it treats all paths equally, FastReplica does not take full advantage of highbandwidth overlay links in the system. There are numerous protocols that aim to add reliability to IP multicast. In Scalable Reliable Multicast -LRB- SRM -RRB- -LSB- 16 -RSB-, nodes multicast retransmission requests for missed packets. Bullet is closely related to efforts that use epidemic data propagation techniques to recover from losses in the nonreliable IP-multicast tree. In pbcast -LSB- 2 -RSB-, a node has global group membership, and periodically chooses a random subset of peers to send a digest of its received packets. A node that receives the digest responds to the sender with the missing packets in a last-in, first-out fashion. Since lbpcast does not require an underlying tree for data distribution and relies on the push-gossiping model, its network overhead can be quite high. Compared to the reliable multicast efforts, Bullet behaves favorably in terms of the network overhead because nodes do not `` blindly '' request retransmissions from their peers. Instead, Bullet uses the summary views it obtains through RanSub to guide its actions toward nodes with disjoint content. Further, a Bullet node splits the retransmission load between all of its peers. We note that pbcast nodes contain a mechanism to rate-limit retransmitted packets and to send different packets in response to the same digest. However, this does not guarantee that packets received in parallel from multiple peers will not be duplicates. More importantly, the multicast recovery methods are limited by the bandwidth through the tree, while Bullet strives to provide more bandwidth to all receivers by making data deliberately disjoint throughout the tree. Narada -LSB- 19 -RSB- builds a delay-optimized mesh interconnecting all participating nodes and actively measures the available bandwidth on overlay links. It then runs a standard routing protocol on top of the overlay mesh to construct forwarding trees using each node as a possible source. Narada nodes maintain global knowledge about all group participants, limiting system scalability to several tens of nodes. Further, the bandwidth available through a Narada tree is still limited to the bandwidth available from each parent. On the other hand, the fundamental goal of Bullet is to increase bandwidth through download of disjoint data from multiple peers. Overcast -LSB- 21 -RSB- is an example of a bandwidth-efficient overlay tree construction algorithm. In this system, all nodes join at the root and migrate down to the point in the tree where they are still able to maintain some minimum level of bandwidth. Bullet is expected to be more resilient to node departures than any tree, including Overcast. Instead of a node waiting to get the data it missed from a new parent, a node can start getting data from its perpendicular peers. Overcast convergence time is limited by probes to immediate siblings and ancestors. Bullet is able to provide approximately a target bandwidth without having a fully converged tree. In parallel to our own work, SplitStream -LSB- 9 -RSB- also has the goal of achieving high bandwidth data dissemination. It operates by splitting the multicast stream into k stripes, transmitting each stripe along a separate multicast tree built using Scribe -LSB- 34 -RSB-. Perhaps more importantly, SplitStream assumes that there is enough available bandwidth to carry each stripe on every link of the tree, including the links between the data source and the roots of individual stripe trees independently chosen by Scribe. To some extent, Bullet and SplitStream are complementary. For instance, Bullet could run on each of the stripes to maximize the bandwidth delivered to each node along each stripe. CoopNet -LSB- 29 -RSB- considers live content streaming in a peerto-peer environment, subject to high node churn. Consequently, the system favors resilience over network efficiency. In the case of on-demand streaming, CoopNet -LSB- 30 -RSB- addresses the flash-crowd problem at the central server by redirecting incoming clients to a fixed number of nodes that have previously retrieved portions of the same content. Compared to CoopNet, Bullet provides nodes with a uniformly random subset of the system-wide distribution of the file. 6. CONCLUSIONS Typically, high bandwidth overlay data streaming takes place over a distribution tree. In this paper, we argue that, in fact, an overlay mesh is able to deliver fundamentally higher bandwidth. Of course, a number of difficult challenges must be overcome to ensure that nodes in the mesh do not repeatedly receive the same data from peers. This paper presents the design and implementation of Bullet, a scalable and efficient overlay construction algorithm that overcomes this challenge to deliver significant bandwidth improvements relative to traditional tree structures. Specifically, this paper makes the following contributions : 9 We present the design and analysis of Bullet, an overlay construction algorithm that creates a mesh over any distribution tree and allows overlay participants to achieve a higher bandwidth throughput than traditional data streaming. As a related benefit, we eliminate the overhead required to probe for available bandwidth in traditional distributed tree construction techniques. 9 We provide a technique for recovering missing data from peers in a scalable and efficient manner. RanSub periodically disseminates summaries of data sets received by a changing, uniformly random subset of global participants. 9 We propose a mechanism for making data disjoint and then distributing it in a uniform way that makes the probability of finding a peer containing missing data equal for all nodes. 9 A large-scale evaluation of 1000 overlay participants running in an emulated 20,000 node network topology, as well as experimentation on top of the PlanetLab Internet testbed, shows that Bullet running over a random tree can achieve twice the throughput of streaming over a traditional bandwidth tree.", "keyphrases": ["overlai mesh", "data dissemin", "overlai network", "ip multicast", "multipoint commun", "high-bandwidth data distribut", "larg-file transfer", "real-time multimedia stream", "bullet", "bandwidth probe", "peer-to-peer", "ransub", "content deliveri", "tfrc"]}
{"file_name": "I-30", "text": "Distributed Task Allocation in Social Networks ABSTRACT This paper proposes a new variant of the task allocation problem, where the agents are connected in a social network and tasks arrive at the agents distributed over the network. We show that the complexity of this problem remains NPhard. Moreover, it is not approximable within some factor. We develop an algorithm based on the contract-net protocol. Our algorithm is completely distributed, and it assumes that agents have only local knowledge about tasks and resources. We conduct a set of experiments to evaluate the performance and scalability of the proposed algorithm in terms of solution quality and computation time. Three different types of networks, namely small-world, random and scale-free networks, are used to represent various social relationships among agents in realistic applications. The results demonstrate that our algorithm works well and that it scales well to large-scale applications. 1. INTRODUCTION Recent years have seen a lot of work on task and resource allocation methods, which can potentially be applied to many real-world applications. However, some interesting applications where relations between agents play a role require a slightly more general model. range of task allocation methods. The question is how VOs are to be dynamically composed and re-composed from individual agents, when different tasks and subtasks need to be performed. This would be done by allocating them to different agents who may each be capable of performing different subsets of those tasks. In this paper, we study the problem of task allocation from the perspective of such a complex interrelated structure. Specifically, therefore, we consider agents to be connected to each other in a social network. Other than modeling the interrelated structure between business partners, the social network introduced in this paper can also be used to represent other types of connections or constraints among autonomous entities that arise from other application domains. The next section gives a formal description of the task allocation problem on social networks. In Section 3, we prove that the complexity of this problem remains NP-hard. We then proceed to develop a distributed algorithm in Section 4, and perform a series of experiments with this algorithm, as described in Section 5. Section 6 discusses related work, and Section 7 concludes. 6. RELATED WORK Task allocation in multiagent systems has been investigated by many researchers in recent years with different assumptions and emphases. However, most of the research to date on task allocation does not consider social connections among agents, and studies the problem in a centralized The Sixth Intl.. Joint Conf. on Autonomous Agents and Multi-Agent Systems -LRB- AAMAS 07 -RRB- 505 Figure 6 : The quality of the GDAP algorithm for a uniform and a skewed task benefit distribution related to the resource ratio -LRB- the first graph -RRB-, and the network degree -LRB- the second graph -RRB-. setting. For example, Kraus et al. -LSB- 12 -RSB- develop an auction protocol that enables agents to form coalitions with time constraints. It assumes each agent knows the capabilities of all others. The proposed protocol is centralized, where one manager is responsible for allocating the tasks to all coalitions. Manisterski at al. -LSB- 14 -RSB- discuss the possibilities of achieving efficient allocations in both cooperative and noncooperative settings. They propose a centralized algorithm to find the optimal solution. In contrast to this work, we introduce also an efficient completely distributed protocol that takes the social network into account. Task allocation has also been studied in distributed settings by for example Shehory and Kraus -LSB- 18 -RSB- and by Lerman and Shehory -LSB- 13 -RSB-. They propose distributed algorithms with low communication complexity for forming coalitions in large-scale multiagent systems. However, they do not assume the existence of any agent network. The work of Sander et al. -LSB- 16 -RSB- introduces computational geometry-based algorithms for distributed task allocation in geographical domains. Agents are then allowed to move and actively search for tasks, and the capability of agents to perform tasks is homogeneous. In order to apply their approach, agents need to have some knowledge about the geographical positions of tasks and some other agents. Other work -LSB- 17 -RSB- proposes a location mechanism for open multiagent systems to allocate tasks to unknown agents. In this approach each agent caches a list of agents they know. The analysis of the communication complexity of this method is based on lattice-like graphs, while we investigate how to efficiently solve task allocation in a social network, whose topology can be arbitrary. Networks have been employed in the context of task allocation in some other works as well, for example to limit the Figure 8 : The quality of the GDAP algorithm compared to the upper bound. interactions between agents and mediators -LSB- 1 -RSB-. Mediators in this context are agents who receive the task and have connections to other agents. They break up the task into subtasks, and negotiate with other agents to obtain commitments to execute these subtasks. Their focus is on modeling the decision process of just a single mediator. Another approach is to partition the network into cliques of nodes, representing coalitions which the agents involved may use as a coordination mechanism -LSB- 20 -RSB-. The focus of that work is distributed coalition formation among agents, but in our approach, we do not need agents to form groups before allocating tasks. Easwaran and Pitt -LSB- 6 -RSB- study ` complex tasks ' that require ` services ' for their accomplishment. The problem concerns the allocation of subtasks to service providers in a supply chain. Another study of task allocation in supply chains is -LSB- 21 -RSB-, where it is argued that the defining characteristic of Supply Chain Formation is hierarchical subtask decomposition -LRB- HSD -RRB-. HSD is implemented using task dependency networks -LRB- TDN -RRB-, with agents and goods as nodes, and I/O relations between them as edges. Here, the network is given, and the problem is to select a subgraph, for which the authors propose a market-based algorithm, in particular, a series of auctions. Compared to these works, our approach is more general in the sense that we are able to model different types of connections or constraints among agents for different problem domains in addition to supply chain formation. Finally, social networks have been used in the context of team formation. Previous work has shown how to learn which relations are more beneficial in the long run -LSB- 8 -RSB-, and adapt the social network accordingly. We believe these results can be transferred to the domain of task allocation as well, leaving this as a topic for further study. Figure 7 : The run time of the GDAP algorithm. 506 The Sixth Intl.. Joint Conf. on Autonomous Agents and Multi-Agent Systems -LRB- AAMAS 07 -RRB- 7. CONCLUSIONS In this paper we studied the task allocation problem in a social network -LRB- STAP -RRB-, which can be seen as a new, more general, variant of the TAP. We believe it has a great amount of potential for realistic problems. We provided complexity results on computing the efficient solution for the STAP, as well as a bound on possible approximation algorithms. Next, we presented a distributed protocol, related to the contractnet protocol. We also introduced an exponential algorithm to compute the optimal solution, as well as a fast upperbound algorithm. The results presented in this paper show that the distributed algorithm performs well in small-world, scale-free, and random networks, and for many different settings. Also other experiments were done -LRB- e.g. on grid networks -RRB- and these results held up over a wider range of scenarios. Furthermore, we showed that it scales well to large networks, both in terms of quality and of required computation time. The results also suggest that small-world networks are slightly better suited for local task allocation, because there are no nodes with very few neighbors. There are many interesting extensions to our current work. In this paper, we focus on the computational aspect in the design of the distributed algorithm. In our future work, we would also like to address some of the related issues in game theory, such as strategic agents, and show desirable properties of a distributed protocol in such a context. In the current algorithm we assume that agents can only contact their neighbors to request resources, which may explain why our algorithm performs not as good in the scalefree networks as in the small-world networks. Our future work may allow agents to reallocate -LRB- sub -RRB- tasks. We are interested in seeing how such interactions will affect the performance of task allocation in different social networks. A third interesting topic for further work is the addition of reputation information among the agents. This may help to model changing business relations and incentivize agents to follow the protocol. Finally, it would be interesting to study real-life instances of the social task allocation problem, and see how they relate to the randomly generated networks of different types studied in this paper. Acknowledgments.", "keyphrases": ["social network", "social relationship", "task alloc", "util", "alloc", "algorithm", "commun messag", "behavior", "multiag system", "strateg agent", "interact"]}
{"file_name": "J-21", "text": "A Strategic Model for Information Markets ABSTRACT Information markets, which are designed specifically to aggregate traders ' information, are becoming increasingly popular as a means for predicting future events. Recent research in information markets has resulted in two new designs, market scoring rules and dynamic parimutuel markets. We develop an analytic method to guide the design and strategic analysis of information markets. Our central contribution is a new abstract betting game, the projection game, that serves as a useful model for information markets. We demonstrate that this game can serve as a strategic model of dynamic parimutuel markets, and also captures the essence of the strategies in market scoring rules. The projection game is tractable to analyze, and has an attractive geometric visualization that makes the strategic moves and interactions more transparent. We use it to prove several strategic properties about the dynamic parimutuel market. We also prove that a special form of the projection game is strategically equivalent to the spherical scoring rule, and it is strategically similar to other scoring rules. Finally, we illustrate two applications of the model to analysis of complex strategic scenarios : we analyze the precision of a market in which traders have inertia, and a market in which a trader can profit by manipulating another trader 's beliefs. 1. INTRODUCTION Markets have long been used as a medium for trade. As a side effect of trade, the participants in a market reveal something about their preferences and beliefs. For example, in a financial market, agents would buy shares which they think are undervalued, and sell shares which they think are overvalued. It has long been observed that, because the market price is influenced by all the trades taking place, it aggregates the private information of all the traders. Thus, in a situation in which future events are uncertain, and each trader might have a little information, the aggregated information contained in the market prices can be used to predict future events. This has motivated the creation of information markets, which are mechanisms for aggregating the traders ' information about an uncertain event. Information markets can be modeled as a game in which the participants bet on a number of possible outcomes, such as the results of a presidential election, by buying shares of the outcomes and receiving payoffs when the outcome is realized. As in financial markets, the participants aim to maximize their profit by buying low and selling high. The benefit of well-designed information markets goes beyond information aggregation ; they can also be used as a hedging instrument, to allow traders to insure against risk. Recently, researchers have turned to the problem of designing market structures specifically to achieve better information aggregation properties than traditional markets. Two designs for information markets have been proposed : the Dynamic Parimutuel Market -LRB- DPM -RRB- by Pennock -LSB- 10 -RSB- and the Market Scoring Rules -LRB- MSR -RRB- by Hanson -LSB- 6 -RSB-. Both the DPM and the MSR were designed with the goal of giving informed traders an incentive to trade, and to reveal their information as soon as possible, while also controlling the subsidy that the market designer needs to pump into the market. One version of the DPM was implemented in the Yahoo! Buzz market -LSB- 8 -RSB- to experimentally test the market 's prediction properties. The innovation in the MSR is to use these scoring rules as instruments that can be traded, thus providing traders who have new information an incentive to trade. The MSR was to be used in a policy analysis market in the Middle East -LSB- 15 -RSB-, which was subsequently withdrawn. Information markets rely on informed traders trading for their own profit, so it is critical to understand the strategic properties of these markets. This is not an easy task, because markets are complex, and traders can influence each other 's beliefs through their trades, and hence, can potentially achieve long term gains by manipulating the market. For the DPM, we are not aware of any prior strategic analysis of this nature ; in fact, a strategic hole was discovered while testing the DPM in the Yahoo! Buzz market -LSB- 8 -RSB-. 1.1 Our Results In this paper, we seek to develop an analytic method to guide the design and strategic analysis of information markets. Our central contribution is a new abstract betting game, the projection 1 game, that serves as a useful model for information markets. The projection game is conceptually simpler than the MSR and DPM, and thus it is easier to analyze. In addition it has an attractive geometric visualization, which makes the strategic moves and interactions more transparent. We present an analysis of the optimal strategies and profits in this game. We then undertake an analysis of traders ' costs and profits in the dynamic parimutuel market. Remarkably, we find that the cost of a sequence of trades in the DPM is identical to the cost of the corresponding moves in the projection game. Further, if we assume that the traders beliefs at the end of trading match the true probability of the event being predicted, the traders ' payoffs and profits in the DPM are identical to their payoffs and profits in a corresponding projection game. We use the equivalence between the DPM and the projection game to prove that the DPM is arbitrage-free, deduce profitable strategies in the DPM, and demonstrate that constraints on the agents ' trades are necessary to prevent a strategic breakdown. We also prove an equivalence between the projection game and the MSR : We show that play in the MSR is strategically equivalent to play in a restricted projection game, at least for myopic strategies and small trades. This allows us to use the projection game as a conceptual model for market scoring rules. Further, because the restricted projection game corresponds to a DPM with a natural trading constraint, this sheds light on an intriguing connection between the MSR and the DPM. Lastly, we illustrate how the projection game model can be used to analyze the potential for manipulation of information markets for long-term gain.2 We present an example scenario in which such manipulation can occur, and suggest additional rules that might mitigate the possibility of manipulation. We also illustrate another application to analyzing how a market maker can improve the prediction accuracy of a market in which traders will not trade unless their expected profit is above a threshold. 1.2 Related Work Numerous studies have demonstrated empirically that market prices are good predictors of future events, and seem to aggregate the collected wisdom of all the traders -LSB- 2, 3, 12, 1, 5, 16 -RSB-. A number of recent studies have addressed the design of the market structure and trading rules for information markets, as well as the incentive to participate and other strategic issues. However, strategic issues in information markets have also been studied by Mangold et al. -LSB- 8 -RSB- and by Hanson, Oprea and Porter -LSB- 7 -RSB-. An upcoming survey paper -LSB- 11 -RSB- discusses costfunction formulations of automated market makers. Organization of the paper The rest of this paper is organized as follows : In Section 2, we describe the projection game, and analyze the players ' costs, profits, and optimal strategies in this game. In Section 3, we study the dynamic parimutuel market, and show that trade in a DPM is equivalent to a projection game. We establish a connection between the projection game and the MSR in Section 4. In Section 5, we illustrate how the projection game can be used to analyze non-myopic, and potentially manipulative, actions. We present our conclusions, and suggestions for future work, in Section 6. 6. CONCLUSIONS AND FUTURE WORK We have presented a simple geometric game, the projection game, that can serve as a model for strategic behavior in information markets, as well as a tool to guide the design of new information markets. We have used this model to analyze the cost, profit, and strategies of a trader in a dynamic parimutuel market, and shown that both the dynamic parimutuel market and the spherical market scoring rule are strategically equivalent to the restricted projection game under slight distortion of the prior probabilities. The general analysis was based on the assumption that traders do not actively try to mislead other traders for future profit. In section 5, however, we analyze a small example market without this assumption. We demonstrate that the projection game can be used to analyze traders ' strategies in this scenario, and potentially to help design markets with better strategic properties. Our results raise several very interesting open questions. Firstly, the payoffs of the projection game can not be directly implemented in situations in which the true probability is not ultimately revealed. Finally, the existence of long-range manipulative strategies in information markets is of great interest. The example we studied in section 5 merely scratches the surface of this area. A general study of this class of manipulations, together with a characterization of markets in which it can or can not arise, would be very useful for the design of information markets.", "keyphrases": ["inform market", "dynam parimutuel market", "project game model", "predict market", "market score rule", "spheric score rule", "long-rang manipul strategi", "social and behavior scienc-econom", "liquid time"]}
{"file_name": "H-18", "text": "Topic Segmentation with Shared Topic Detection and Alignment of Multiple Documents ABSTRACT Topic detection and tracking -LSB- 26 -RSB- and topic segmentation -LSB- 15 -RSB- play an important role in capturing the local and sequential information of documents. Previous work in this area usually focuses on single documents, although similar multiple documents are available in many domains. In this paper, we introduce a novel unsupervised method for shared topic detection and topic segmentation of multiple similar documents based on mutual information -LRB- MI -RRB- and weighted mutual information -LRB- WMI -RRB- that is a combination of MI and term weights. The basic idea is that the optimal segmentation maximizes MI -LRB- or WMI -RRB-. Our approach can detect shared topics among documents. It can find the optimal boundaries in a document, and align segments among documents at the same time. It also can handle single-document segmentation as a special case of the multi-document segmentation and alignment. Our methods can identify and strengthen cue terms that can be used for segmentation and partially remove stop words by using term weights based on entropy learned from multiple documents. Our experimental results show that our algorithm works well for the tasks of single-document segmentation, shared topic detection, and multi-document segmentation. Utilizing information from multiple documents can tremendously improve the performance of topic segmentation, and using WMI is even better than using MI for the multi-document segmentation. 1. INTRODUCTION Many researchers have worked on topic detection and tracking -LRB- TDT -RRB- -LSB- 26 -RSB- and topic segmentation during the past decade. Topic segmentation intends to identify the boundaries in a document with the goal to capture the latent topical structure. Topic segmentation tasks usually fall into two categories -LSB- 15 -RSB- : text stream segmentation where topic transition is identified, and coherent document segmentation in which documents are split into sub-topics. Traditional approaches perform topic segmentation on documents one at a time -LSB- 15, 25, 6 -RSB-. Most of them perform badly in subtle tasks like coherent document segmentation -LSB- 15 -RSB-. Often, end-users seek documents that have the similar content. At a finer granularity, users may actually be looking to obtain sections of a document similar to a particular section that presumably discusses a topic of the users interest. Thus, the extension of topic segmentation from single documents to identifying similar segments from multiple similar documents with the same topic is a natural and necessary direction, and multi-document topic segmentation is expected to have a better performance since more information is utilized. Traditional approaches using similarity measurement based on term frequency generally have the same assumption that similar vocabulary tends to be in a coherent topic segment -LSB- 15, 25, 6 -RSB-. However, they usually suffer the issue of identifying stop words. For example, additional document-dependent stop words are removed together with the generic stop words in -LSB- 15 -RSB-. There are two reasons that we do not remove stop words directly. First, identifying stop words is another issue -LSB- 12 -RSB- that requires estimation in each domain. Removing common stop words may result in the loss of useful information in a specific domain. We employ a soft classification using term weights. Topic alignment of multiple similar documents can be achieved by clustering sentences on the same topic into the same cluster. Single-document topic segmentation is just a special case of the multi-document topic segmentation and alignment problem. Usually, human readers can identify topic transition based on cue words, and can ignore stop words. Inspired by this, we give each term -LRB- or term cluster -RRB- a weight based on entropy among different documents and different segments of documents. Not only can this approach increase the contribution of cue words, but it can also decrease the effect of common stop words, noisy word, and document-dependent stop words. These words are common in a document. Many methods based on sentence similarity require that these words are removed before topic segmentation can be performed -LSB- 15 -RSB-. Our results in Figure 3 show that term weights are useful for multi-document topic segmentation and alignment. The major contribution of this paper is that it introduces a novel method for topic segmentation using MI and shows that this method performs better than previously used criteria. Also, we have addressed the problem of topic segmentation and alignment across multiple documents, whereas most existing research focused on segmentation of single documents. Multi-document segmentation and alignment can utilize information from similar documents and improves the performance of topic segmentation greatly. Obviously, our approach can handle single documents as a special case when multiple documents are unavailable. It can detect shared topics among documents to judge if they are multiple documents on the same topic. We also introduce the new criterion of WMI based on term weights learned from multiple similar documents, which can improve performance of topic segmentation further. We propose an iterative greedy algorithm based on dynamic programming and show that it works well in practice. Some of our prior work is in -LSB- 24 -RSB-. The rest of this paper is organized as follows : In Section 2, we review related work. Section 3 contains a formulation of the problem of topic segmentation and alignment of multiple documents with term co-clustering, a review of the criterion of MI for clustering, and finally an introduction to WMI. In Section 4, we first propose the iterative greedy algorithm of topic segmentation and alignment with term co-clustering, and then describe how the algorithm can be optimized by us Figure 1 : Illustration of multi-document segmentation and alignment. ing dynamic programming. In Section 5, experiments about single-document segmentation, shared topic detection, and multi-document segmentation are described, and results are presented and discussed to evaluate the performance of our algorithm. Conclusions and some future directions of the research work are discussed in Section 6. 2. PREVIOUS WORK Supervised learning usually has good performance, since it learns functions from labelled training sets. However, often getting large training sets with manual labels on document sentences is prohibitively expensive, so unsupervised approaches are desired. Some approaches also focus on cue words as hints of topic transitions -LSB- 11 -RSB-. While some existing methods only consider information in single documents -LSB- 6, 15 -RSB-, others utilize multiple documents -LSB- 16, 14 -RSB-. There are not many works in the latter category, even though the performance of segmentation is expected to be better with utilization of information from multiple documents. Previous research studied methods to find shared topics -LSB- 16 -RSB- and topic segmentation and summarization between just a pair of documents -LSB- 14 -RSB-. Text classification and clustering is a related research area which categorizes documents into groups using supervised or unsupervised methods. Criteria of these approaches can be utilized in the issue of topic segmentation. Some of those methods have been extended into the area of topic segmentation, such as PLSA -LSB- 5 -RSB- and maximum entropy -LSB- 7 -RSB-, but to our best knowledge, using MI for topic segmentation has not been studied. 6. CONCLUSIONS AND FUTURE WORK We proposed a novel method for multi-document topic segmentation and alignment based on weighted mutual information, which can also handle single-document cases. We used dynamic programming to optimize our algorithm. Our approach outperforms all the previous methods on singledocument cases. Moreover, we also showed that doing segmentation among multiple documents can improve the performance tremendously. Our results also illustrated that using weighted mutual information can utilize the information of multiple documents to reach a better performance. We only tested our method on limited data sets. More data sets especially complicated ones should be tested. More previous methods should be compared with. Moreover, natural segmentations like paragraphs are hints that can be used to find the optimal boundaries. Supervised learning also can be considered.", "keyphrases": ["topic detect", "track", "topic segment", "local and sequenti inform of document", "singl document", "multipl document", "wmu", "share topic", "optim boundari", "singl-document segment", "multi-document segment", "cue term", "stop word", "term weight", "perform of topic segment"]}
{"file_name": "I-6", "text": "Dynamic Semantics for Agent Communication Languages ABSTRACT This paper proposes dynamic semantics for agent communication languages -LRB- ACLs -RRB- as a method for tackling some of the fundamental problems associated with agent communication in open multiagent systems. Based on the idea of providing alternative semantic `` variants '' for speech acts and transition rules between them that are contingent on previous agent behaviour, our framework provides an improved notion of grounding semantics in ongoing interaction, a simple mechanism for distinguishing between compliant and expected behaviour, and a way to specify sanction and reward mechanisms as part of the ACL itself. We extend a common framework for commitment-based ACL semantics to obtain these properties, discuss desiderata for the design of concrete dynamic semantics together with examples, and analyse their properties. 1. INTRODUCTION The field of agent communication language -LRB- ACL -RRB- research has long been plagued by problems of verifiability and grounding -LSB- 10, 13, 17 -RSB-. Unable to safeguard themselves against abuse by malicious, deceptive or malfunctioning agents, mentalistic semantics are inherently unreliable and inappropriate for use in open MAS in which agents with potentially conflicting objectives might deliberately exploit their adversaries ' conceptions of message semantics to provoke a certain behaviour. Commitment-based semantics -LSB- 6, 8, 14 -RSB-, on the other hand, define the meaning of messages exchanged among agents in terms of publicly observable commitments, i.e. pledges to bring about a state of affairs or to perform certain actions. Such semantics solve the verifiability problem as they allow for tracing the status of existing commitments at any point in time given observed messages and actions so that any observer can, for example, establish whether an agent has performed a promised action. Further, this implies that the semantics specification does not provide an interface to agents ' deliberation and planning mechanisms and hence it is unclear how rational agents would be able to decide whether to subscribe to a suggested ACL semantics when it is deployed. Finally, none of the existing approaches allows the ACL to specify how to respond to a violation of its semantics by individual agents. Secondly, existing approaches fail to exploit the possibilities of sanctioning and rewarding certain behaviours in a communication-inherent way by modifying the future meaning of messages uttered or received by compliant/deviant agents. In this paper, we propose dynamic semantics -LRB- DSs -RRB- for ACLs as a solution to these problems. Our notion of DS is based on the very simple idea of defining different alternatives for the meaning of individual speech acts -LRB- so-called semantic variants -RRB- in an ACL semantics specification, and transition rules between semantic states -LRB- i.e. collections of variants for different speech acts -RRB- that describe the current meaning of the ACL. These elements taken together result in a FSM-like view of ACL specifications where each individual state provides a complete ACL semantics and state transitions are triggered by observed agent behaviour in order to -LRB- 1 -RRB- reflect future expectations based on previous interaction experience and -LRB- 2 -RRB- sanction or reward certain kinds of behaviour. In defining a DS framework for commitment-based ACLs, this paper makes three contributions : 1. An extension of commitment-based ACL semantics to provide an improved notion of grounding commitments in agent interaction and to allow ACL specifications to be directly used for planning-based rational decision making. 2. A simple way of distinguishing between compliant and expected behaviour with respect to an ACL specification that enables reasoning about the potential behaviour of agents purely from an ACL semantics perspective. 3. A mechanism for specifying how meaning evolves with agent behaviour and how this can be used to describe communication-inherent sanctioning and rewarding mechanisms essential to the design of open MASs.. Furthermore, we discuss desiderata for DS design that can be derived from our framework, present examples and analyse their properties. The remainder of this paper is structured as follows : Section 2 introduces a formal framework for dynamic ACL semantics. In section 3 we present an analysis and discussion of this framework and discuss desiderata for the design of ACLs with dynamic semantics. Section 4 reviews related approaches, and section 5 concludes. 4. RELATED WORK Expectation-based reasoning about interaction was first proposed in -LSB- 2 -RSB-, considering the evolution of expectations described as probabilistic expectations of communication and action sequences. The same authors suggested a more general framework for expectation-based communication semantics -LSB- 9 -RSB-, and argue for a `` consequentialist '' view of semantics that is based on defining the meaning of utterances in terms of their expected consequences and updating these expectations with new observations -LSB- 11 -RSB-. However, their approach does not use an explicit notion of commitments which in our framework mediates between communication and behaviour-based grounding, and provides a clear distinction between a normative notion of compliance and a more empirical notion of expectation. Grounding for -LRB- mentalistic -RRB- ACL semantics has been investigated in -LSB- 7 -RSB- where grounded information is viewed as `` information that is publicly expressed and accepted as being true by all the agents participating in a conversation ''. Like -LSB- 1 -RSB- -LRB- which bases the notion of `` publicly expressed '' on roles rather than internal states of agents -RRB- these authors ' main concern is to provide a verifiable basis for determining the semantics of expressed mental states and commitments. 11In a non-trivial sense, i.e. when some initial transitions are possible in principle 106 The Sixth Intl.. Joint Conf. Our framework is also related to deontic methods for the specification of obligations, norms and sanctions. In this area, -LSB- 16 -RSB- is the only framework that we are aware of which considers dynamic obligations, norms and sanctions. However, as we have described above we solely utilise semantic evolution as a sanctioning and rewarding mechanism, i.e. unlike this work we do not assume that agents can be directly punished or rewarded. 5. CONCLUSION This paper introduces dynamic semantics for ACLs as a method for dealing with some fundamental problems of agent communication in open systems, the simple underlying idea being that different courses of agent behaviour can give rise to different interpretations of meaning of the messages exchanged among agents. Based on a common framework of commitment-based semantics, we presented a notion of grounding for commitments based on notions of compliant and expected behaviour. We then defined dynamic semantics as state transition systems over different semantic states that can be viewed as different `` versions '' of ACL semantics in the traditional sense, and can be easily associated with a planning-based view of reasoning about communication. Thereby, our focus was on simplicity and on providing mechanisms for tracking semantic evolution in a `` down-toearth '', algorithmic fashion to ensure applicability to many different agent designs. We discussed the properties of our framework showing how it can be used as a powerful communication-inherent mechanism for rewarding and sanctioning agent behaviour in open systems without compromising agent autonomy, discussed its integration with agents ' planning processes, complexity issues, and presented a list of desiderata for the design of ACLs with such semantics.", "keyphrases": ["agent commun languag", "dynam semant", "social reason", "commit-base semant", "state transit system", "reput-base adapt", "mutual of expect", "recoveri mechan", "non-redund"]}
{"file_name": "J-13", "text": "On The Complexity of Combinatorial Auctions : Structured Item Graphs and Hypertree Decompositions ABSTRACT The winner determination problem in combinatorial auctions is the problem of determining the allocation of the items among the bidders that maximizes the sum of the accepted bid prices. While this problem is in general NPhard, it is known to be feasible in polynomial time on those instances whose associated item graphs have bounded treewidth -LRB- called structured item graphs -RRB-. Formally, an item graph is a graph whose nodes are in one-to-one correspondence with items, and edges are such that for any bid, the items occurring in it induce a connected subgraph. Note that many item graphs might be associated with a given combinatorial auction, depending on the edges selected for guaranteeing the connectedness. In fact, the tractability of determining whether a structured item graph of a fixed treewidth exists -LRB- and if so, computing one -RRB- was left as a crucial open problem. In this paper, we solve this problem by proving that the existence of a structured item graph is computationally intractable, even for treewidth 3. Motivated by this bad news, we investigate different kinds of structural requirements that can be used to isolate tractable classes of combinatorial auctions. We show that the notion of hypertree decomposition, a recently introduced measure of hypergraph cyclicity, turns out to be most useful here. Indeed, we show that the winner determination problem is solvable in polynomial time on instances whose bidder interactions can be represented with -LRB- dual -RRB- hypergraphs having bounded hypertree width. Even more surprisingly, we show that the class of tractable instances identified by means of our approach properly contains the class of instances having a structured item graph. 1. INTRODUCTION Combinatorial auctions. Combinatorial auctions are well-known mechanisms for resource and task allocation where bidders are allowed to simultaneously bid on combinations of items. This is desirable when a bidder 's valuation of a bundle of items is not equal to the sum of her valuations of the individual items. An outcome for -LRB- Z, B -RRB- is a subset b of B such that item -LRB- Bi -RRB- n item -LRB- Bj -RRB- = 0, for each pair Bi and Bj of bids in b with i = ~ j. The winner determination problem. A crucial problem for combinatorial auctions is to determine the outcome b \u2217 that maximizes the sum of the accepted bid prices -LRB- i.e., Bi \u2208 b \u2217 pay -LRB- Bi -RRB- -RRB- over all the possible outcomes. This problem, called winner determination problem -LRB- e.g., -LSB- 11 -RSB- -RRB-, is known to be intractable, actually NP-hard -LSB- 17 -RSB-, and even not approximable in polynomial time unless NP = ZPP -LSB- 19 -RSB-. Hence, it comes with no surprise that several efforts have been spent to design practically efficient algorithms for general auctions -LRB- e.g., -LSB- 20, 5, 2, 8, 23 -RSB- -RRB- and to identify classes of instances where solving the winner determination problem is feasible in polynomial time -LRB- e.g., -LSB- 15, 22, 12, 21 -RSB- -RRB-. In fact, constraining bidder interaction was proven to be useful for identifying classes of tractable combinatorial auctions. Item graphs. Currently, the most general class of tractable combinatorial auctions has been singled out by modelling interactions among bidders with the notion of item graph, which is a graph whose nodes are in one-to-one correspondence with items, and edges are such that for any Figure 1 : Example MaxWSP problem : -LRB- a -RRB- Hypergraph H -LRB- To, go -RRB-, and a packing h for it ; -LRB- b -RRB- Primal graph for H -LRB- To, go -RRB- ; and, -LRB- c, d -RRB- Two item graphs for H -LRB- To, go -RRB-. bid, the items occurring in it induce a connected subgraph. Indeed, the winner determination problem was proven to be solvable in polynomial time if interactions among bidders can be represented by means of a structured item graph, i.e., a tree or, more generally, a graph having tree-like structure -LSB- 3 -RSB- -- formally bounded treewidth -LSB- 16 -RSB-. To have some intuition on how item graphs can be built, we notice that bidder interaction in a combinatorial auction ~ I, B ~ can be represented by means of a hypergraph H -LRB- T, g -RRB- such that its set of nodes N -LRB- H -LRB- T, g -RRB- -RRB- coincides with set of items I, and where its edges E -LRB- H -LRB- T, g -RRB- -RRB- are precisely the bids of the buyers -LCB- item -LRB- Bi -RRB- | Bi \u2208 B -RCB-. A special item graph for ~ I, B ~ is the primal graph of H -LRB- T, g -RRB-, denoted by G -LRB- H -LRB- T, g -RRB- -RRB-, which contains an edge between any pair of nodes in some hyperedge of H -LRB- T, g -RRB-. Then, any item graph for H -LRB- T, g -RRB- can be viewed as a simplification of G -LRB- H -LRB- T, g -RRB- -RRB- obtained by deleting some edges, yet preserving the connectivity condition on the nodes included in each hyperedge. EXAMPLE 1. The hypergraph H -LRB- To, go -RRB- reported in Figure 1. -LRB- a -RRB- is an encoding for a combinatorial auction ~ I0, B0 ~, where I0 = -LCB- I1,..., I5 -RCB-, and item -LRB- Bi -RRB- = hi, for each 1 \u2264 i \u2264 3. The primal graph for H -LRB- To, go -RRB- is reported in Figure 1. -LRB- b -RRB-, while two example item graphs are reported in Figure 1. -LRB- c -RRB- and -LRB- d -RRB-, where edges required for maintaining the connectivity for h1 are depicted in bold. < Open Problem : Computing structured item graphs efficiently. The above mentioned tractability result on structured item graphs turns out to be useful in practice only when a structured item graph either is given or can be efficiently determined. However, exponentially many item graphs might be associated with a combinatorial auction, and it is not clear how to determine whether a structured item graph of a certain -LRB- constant -RRB- treewidth exists, and if so, how to compute such a structured item graph efficiently. Weighted Set Packing. Let us note that the hypergraph representation H -LRB- T, g -RRB- of a combinatorial auction ~ I, B ~ is also useful to make the analogy between the winner determination problem and the maximum weighted-set packing problem on hypergraphs clear -LRB- e.g., -LSB- 17 -RSB- -RRB-. Formally, a packing h for a hypergraph H is a set of hyperedges of H such that for each pair h, h ' \u2208 h with h = ~ h ', it holds that h \u2229 h ' = \u2205. Then, the set of the solutions for the weighted set packing problem for H -LRB- T, g -RRB- w.r.t. w -LRB- T, g -RRB- coincides with the set of the solutions for the winner determination problem on ~ I, B ~. EXAMPLE 2. Consider again the hypergraph H -LRB- To, go -RRB- reported in Figure 1. -LRB- a -RRB-. An example packing for H -LRB- To, go -RRB- is h = -LCB- h1 -RCB-, which intuitively corresponds to an outcome for ~ I0, B0 ~, where the auctioneer accepted the bid B1. Indeed, the packing Contributions The primary aim of this paper is to identify large tractable classes for the winner determination problem, that are, moreover polynomially recognizable. Towards this aim, we first study structured item graphs and solve the open problem in -LSB- 3 -RSB-. The result is very bad news : \u25ba It is NP complete to check whether a combinatorial auction has a structured item graph of treewidth 3. More formally, letting C -LRB- ig, k -RRB- denote the class of all the hypergraphs having an item tree of treewidth bounded by k, we prove that deciding whether a hypergraph -LRB- associated with a combinatorial auction problem -RRB- belongs to C -LRB- ig, 3 -RRB- is NP-complete. In the light of this result, it was crucial to assess whether there are some other kinds of structural requirement that can be checked in polynomial time and that can still be used to isolate tractable classes of the maximum weightedset packing problem or, equivalently, the winner determination problem. E -LRB- H -RRB- -RCB- is in E. We show that MaxWSP is tractable on the class of those instances whose dual hypergraphs have hypertree width -LSB- 7 -RSB- bounded by k -LRB- short : class C -LRB- hw, k -RRB- of hypergraphs -RRB-. Note that a key issue of the tractability is to consider the hypertree width of the dual hypergraph H \u00af instead of the auction hypergraph H. In fact, we can show that MaxWSP remains NP-hard even when H is acyclic -LRB- i.e., when it has hypertree width 1 -RRB-, even when each node is contained in 3 hyperedges at most. \u25ba For some relevant special classes of hypergraphs in C -LRB- hw, k -RRB-, we design a higly-parallelizeable algorithm for MaxWSP. Recall, in fact, that LOGCFL is the class of decision problems that are logspace reducible to context free languages, and that LOGCFL C _ NC2 C _ P -LRB- see, e.g., -LSB- 9 -RSB- -RRB-. \u25ba Surprisingly, we show that nothing is lost in terms of generality when considering the hypertree decomposition of dual hypergraphs instead of the treewidth of item graphs. To the contrary, the proposed hypertree-based decomposition method is strictly more general than the method of structured item graphs. In fact, we show that strictly larger classes of instances are tractable according to our new approach than according to the structured item graphs approach. Intuitively, the NP-hardness of recognizing bounded-width structured item graphs is thus not due to its great generality, but rather to some peculiarities in its definition. \u25ba The proof of the above results give us some interesting insight into the notion of structured item graph. Indeed, we show that structured item graphs are in one-to-one correspondence with some special kinds of hypertree decomposition of the dual hypergraph, which we call strict hypertree decompositions. The rest of the paper is organized as follows. Section 2 discusses the intractability of structured item graphs. Section 3 presents the polynomial-time algorithm for solving MaxWSP on the class of those instances whose dual hypergraphs have bounded hypertree width, and discusses the cases where the algorithm is also highly parallelizable. The comparison between the classes C -LRB- ig, k -RRB- and C -LRB- hw, k -RRB- is discussed in Section 4. Finally, in Section 5 we draw our conclusions by also outlining directions for further research. 5. CONCLUSIONS We have solved the open question of determining the complexity of computing a structured item graph associated with a combinatorial auction scenario. The result is bad news, since it turned out that it is NP-complete to check whether a combinatorial auction has a structured item graph, even for treewidth 3. Motivated by this result, we investigated the use of hypertree decomposition -LRB- on the dual hypergraph associated with the scenario -RRB- and we shown that the problem is tractable on the class of those instances whose dual hypergraphs have bounded hypertree width. For some special, yet relevant cases, a highly parallelizable algorithm is also discussed. Interestingly, it also emerged that the class of structured item graphs is properly contained in the class of instances having bounded hypertree width -LRB- hence, the reason of their intractability is not their generality -RRB-. In particular, the latter result is established by showing a precise relationship between structured item graphs and restricted forms of hypertree decompositions -LRB- on the dual hypergraph -RRB-, called query decompositions -LRB- see, e.g., -LSB- 7 -RSB- -RRB-. In the light of this observation, we note that proving some approximability results for structured item graphs requires a deep understanding of the approximability of query decompositions, which is currently missing in the literature.", "keyphrases": ["hypergraph", "combinatori auction", "hypertre decomposit", "well-known mechan for resourc and task alloc", "hypertre-base decomposit method", "hypergraph hg", "complex of structur item graph", "simplif of the primal graph", "structur item graph", "fix treewidth", "accept bid price", "polynomi time"]}
{"file_name": "C-33", "text": "Rewards-Based Negotiation for Providing Context Information ABSTRACT How to provide appropriate context information is a challenging problem in context-aware computing. Most existing approaches use a centralized selection mechanism to decide which context information is appropriate. In this paper, we propose a novel approach based on negotiation with rewards to solving such problem. Distributed context providers negotiate with each other to decide who can provide context and how they allocate proceeds. In order to support our approach, we have designed a concrete negotiation model with rewards. We also evaluate our approach and show that it indeed can choose an appropriate context provider and allocate the proceeds fairly. 1. INTRODUCTION Context-awareness is a key concept in pervasive computing. Context informs both recognition and mapping by providing a structured, unified view of the world in which the system operates -LSB- 1 -RSB-. Context-aware applications exploit context information, such as location, preferences of users and so on, to adapt their behaviors in response to changing requirements of users and pervasive environments. However, one specific kind of context can often be provided by different context providers -LRB- sensors or other data sources of context information -RRB- with different quality levels. For example, Because context-aware applications utilize context information to adapt their behaviors, inappropriate context information may lead to inappropriate behavior. Thus we should design a mechanism to provide appropriate context information for current context-aware applications. In pervasive environments, context providers considered as relatively independent entities, have their own interests. They hope to get proceeds when they provide context information. However, most existing approaches consider context providers as entities without any personal interests, and use a centralized `` arbitrator '' provided by the middleware to decide who can provide appropriate context. Thus the burden of the middleware is very heavy, and its decision may be unfair and harm some providers ' interests. Moreover, when such `` arbitrator '' is broken down, it will cause serious consequences for context-aware applications. In this paper, we let distributed context providers themselves decide who provide context information. Since high reputation could help providers get more opportunities to provide context and get more proceeds in the future, providers try to get the right to provide `` good '' context to enhance their reputation. In order to get such right, context providers may agree to share some portion of the proceeds with its opponents. Thus context providers negotiate with each other to reach agreement on the issues who can provide context and how they allocate the proceeds. Our approach has some specific advantages : 1. We do not need an `` arbitrator '' provided by the middleware of pervasive computing to decide who provides context. Thus it will reduce the burden of the middleware. 2. It is more reasonable that distributed context providers decide who provide context, because it can avoid the serious consequences caused by a breakdown of a centralized `` arbitrator ''. 3. It can guarantee providers ' interests and provide fair proceeds allocation when providers negotiate with each other to reach agreement on their concerned problems. 4. This approach can choose an appropriate provider au tomatically. The negotiation model we have designed to support our approach is also a novel model in negotiation domain. This model can help negotiators reach agreement in the present negotiation process by providing some guarantees over the outcome of next negotiation process -LRB- i.e. rewards -RRB-. It will cost more time to reach agreement. It also expands the negotiation space considered in present negotiation process, and therefore provides more possibilities to find better agreement. Section 2 presents some assumptions. Section 3 describes our approach based on negotiation detailedly, including utility functions, negotiation protocol and context providers ' strategies. Section 4 evaluates our approach. In section 5 we introduce some related work and conclude in section 6. 5. RELATED WORK In -LSB- 4 -RSB-, Huebscher and McCann have proposed an adaptive middleware design for context-aware applications. Their adaptive middleware uses utility functions to choose the best context provider -LRB- given the QoC requirements of applications and the QoC of alternative means of context acquisition -RRB-. In our negotiation model, the calculation of utility function Uc was inspired by this approach. Henricksen and Indulska propose an approach to modelling and using imperfect information in -LSB- 3 -RSB-. They characterize various types and sources of imperfect context information and present a set of novel context modelling constructs. They also outline a software infrastructure that supports the management and use of imperfect context information. -LSB- 10 -RSB- presents a framework for realizing dynamic context consistency management. The framework supports inconsistency detection based on a semantic matching and inconsistency triggering model, and inconsistency resolution with proactive actions to context sources. Most approaches to provide appropriate context utilize a centralized `` arbitrator ''. In our approach, we let distributed context providers themselves decide who can provide appropriate context information. Our approach can reduce the burden of the middleware, because we do not need the middleware to provide a context selection mechanism. Also, it can guarantee context providers ' interests. 6. CONCLUSION AND FUTURE WORK How to provide the appropriate context information is a challenging problem in pervasive computing. In this paper, we have presented a novel approach based on negotiation with rewards to attempt to solve such problem. Distributed context providers negotiate with each other to reach agreement on the issues who can provide the appropriate context and how they allocate the proceeds. The results of our experiments have showed that our approach can choose an appropriate context provider, and also can guarantee providers ' interests by a relatively fair proceeds allocation. In this paper, we only consider how to choose an appropriate context provider from two providers. In the future work, this negotiation model will be extended, and more than two context providers can negotiate with each other to decide who is the most appropriate context provider. In the extended negotiation model, how to design efficient negotiation strategies will be a challenging problem. We assume that the context provider will fulfill its promise of reward in the next negotiation process. In fact, the context provider might deceive its opponent and provide illusive promise. We should solve this problem in the future.", "keyphrases": ["context-awar", "context provid", "negoti", "context-awar comput", "concret negoti model", "distribut applic", "pervas comput", "reput", "qualiti of context", "persuas argument"]}
{"file_name": "H-12", "text": "Fast Generation of Result Snippets in Web Search ABSTRACT The presentation of query biased document snippets as part of results pages presented by search engines has become an expectation of search engine users. In this paper we explore the algorithms and data structures required as part of a search engine to allow efficient generation of query biased snippets. We begin by proposing and analysing a document compression method that reduces snippet generation time by 58 % over a baseline using the zlib compression library. These experiments reveal that finding documents on secondary storage dominates the total cost of generating snippets, and so caching documents in RAM is essential for a fast snippet generation process. Using simulation, we examine snippet generation performance for different size RAM caches. Finally we propose and analyse document reordering and compaction, revealing a scheme that increases the number of document cache hits with only a marginal affect on snippet quality. This scheme effectively doubles the number of documents that can fit in a fixed size cache. 1. INTRODUCTION Each result in search results list delivered by current WWW search engines such as search.yahoo.com, google.com and search.msn.com typically contains the title and URL of the actual document, links to live and cached versions of the document and sometimes an indication of file size and type. In addition, one or more snippets are usually presented, giving the searcher a sneak preview of the document contents. Snippets are short fragments of text extracted from the document content -LRB- or its metadata -RRB-. A query-biased snippet is one selectively extracted on the basis of its relation to the searcher 's query. The addition of informative snippets to search results may substantially increase their value to searchers. Accurate snippets allow the searcher to make good decisions about which results are worth accessing and which can be ignored. In the best case, snippets may obviate the need to open any documents by directly providing the answer to the searcher 's real information need, such as the contact details of a person or an organization. Generation of query-biased snippets by Web search engines indexing of the order of ten billion web pages and handling hundreds of millions of search queries per day imposes a very significant computational load -LRB- remembering that each search typically generates ten snippets -RRB-. The simpleminded approach of keeping a copy of each document in a file and generating snippets by opening and scanning files, works when query rates are low and collections are small, but does not scale to the degree required. The overhead of opening and reading ten files per query on top of accessing the index structure to locate them, would be manifestly excessive under heavy query load. Even storing ten billion files and the corresponding hundreds of terabytes of data is beyond the reach of traditional filesystems. Note that the utility of snippets is by no means restricted to whole-of-Web search applications. Efficient generation of snippets is also important at the scale of whole-of-government search services such as www.firstgov.gov -LRB- c. 25 million pages -RRB- and govsearch.australia.gov.au -LRB- c. 5 million pages -RRB- and within large enterprises such as IBM -LSB- 2 -RSB- -LRB- c. 50 million pages -RRB-. Snippets may be even more useful in database or filesystem search applications in which no useful URL or title information is present. We present a new algorithm and compact single-file structure designed for rapid generation of high quality snippets and compare its space/time performance against an obvious baseline based on the zlib compressor on various data sets. We report the proportion of time spent for disk seeks, disk reads and cpu processing ; demonstrating that the time for locating each document -LRB- seek time -RRB- dominates, as expected. As the time to process a document in RAM is small in comparison to locating and reading the document into memory, it may seem that compression is not required. However, this is only true if there is no caching of documents in RAM. Controlling the RAM of physical systems for experimentation is difficult, hence we use simulation to show that caching documents dramatically improves the performance of snippet generation. In turn, the more documents can be compressed, the more can fit in cache, and hence the more disk seeks can be avoided : the classic data compression tradeoff that is exploited in inverted file structures and computing ranked document lists -LSB- 24 -RSB-. As hitting the document cache is important, we examine document compaction, as opposed to compression, schemes by imposing an a priori ordering of sentences within a document, and then only allowing leading sentences into cache for each document. This leads to further time savings, with only marginal impact on the quality of the snippets returned. 2. RELATED WORK Snippet generation is a special type of extractive document summarization, in which sentences, or sentence fragments, are selected for inclusion in the summary on the basis of the degree to which they match the search query. Early Web search engines presented query-independent snippets consisting of the first k bytes of the result document. Generating these is clearly much simpler and much less computationally expensive than processing documents to extract query biased summaries, as there is no need to search the document for text fragments containing query terms. To our knowledge, Google was the first whole-ofWeb search engine to provide query biased summaries, but summarization is listed by Brin and Page -LSB- 1 -RSB- only under the heading of future work. Most of the experimental work using query-biased summarization has focused on comparing their value to searchers relative to other types of summary -LSB- 20, 21 -RSB-, rather than efficient generation of summaries. Despite the importance of efficient summary generation in Web search, few algorithms appear in the literature. White et al -LSB- 21 -RSB- report some experimental timings of their WebDocSum system, but the snippet generation algorithms themselves are not isolated, so it is difficult to infer snippet generation time comparable to the times we report in this paper. N/M documents. The total amount of RAM required by a single machine, therefore, would be N/M -LRB- 8.192 + 10.24 + 8 -RRB- bytes. Assuming that each machine has 8 Gb of RAM, and that there are 20 billion pages to index on the Web, a total of M = 62 machines would be required for the Snippet Engine. These machines would also need access to 37 Tb of disk to store the compressed document representations that were not in cache. In this work we have deliberately avoided committing to one particular scoring method for sentences in documents. Rather, we have reported accuracy results in terms of the four components that have been previously shown to be important in determining useful snippets -LSB- 20 -RSB-. The document compaction techniques using sentence re-ordering, however, remove the spatial relationship between sentences, and so if a scoring technique relies on the position of a sentence within a document, the aggressive compaction techniques reported here can not be used. As seek time dominates the snippet generation process, we have not focused on this portion of the snippet generation in detail in this paper. We will explore alternate compression schemes in future work.", "keyphrases": ["search engin", "snippet gener", "document cach", "link graph measur", "perform", "web summari", "special-purpos filesystem", "ram", "document compact", "text fragment", "precomput final result page", "vbyte code scheme", "semi-static compress"]}
{"file_name": "H-10", "text": "Regularized Clustering for Documents * ABSTRACT In recent years, document clustering has been receiving more and more attentions as an important and fundamental technique for unsupervised document organization, automatic topic extraction, and fast information retrieval or filtering. In this paper, we propose a novel method for clustering documents using regularization. Unlike traditional globally regularized clustering methods, our method first construct a local regularized linear label predictor for each document vector, and then combine all those local regularizers with a global smoothness regularizer. So we call our algorithm Clustering with Local and Global Regularization -LRB- CLGR -RRB-. We will show that the cluster memberships of the documents can be achieved by eigenvalue decomposition of a sparse symmetric matrix, which can be efficiently solved by iterative methods. Finally our experimental evaluations on several datasets are presented to show the superiorities of CLGR over traditional document clustering methods. 1. INTRODUCTION Document clustering has been receiving more and more attentions as an important and fundamental technique for unsupervised document organization, automatic topic extraction, and fast information retrieval or filtering. A good document clustering approach can assist the computers to automatically organize the document corpus into a meaningful cluster hierarchy for efficient browsing and navigation, which is very valuable for complementing the deficiencies of traditional information retrieval technologies. In such cases, efficient browsing through a good cluster hierarchy will be definitely helpful. Generally, document clustering methods can be mainly categorized into two classes : hierarchical methods and partitioning methods. The hierarchical methods group the data points into a hierarchical tree structure using bottom-up or top-down approaches. For example, hierarchical agglomerative clustering -LRB- HAC -RRB- -LSB- 13 -RSB- is a typical bottom-up hierarchical clustering method. It takes each data point as a single cluster to start off with and then builds bigger and bigger clusters by grouping similar data points together until the entire dataset is encapsulated into one final cluster. On the other hand, partitioning methods decompose the dataset into a number of disjoint clusters which are usually optimal in terms of some predefined criterion functions. For instance, K-means -LSB- 13 -RSB- is a typical partitioning method which aims to minimize the sum of the squared distance between the data points and their corresponding cluster centers. In this paper, we will focus on the partitioning methods. In the last decades, many methods have been proposed to overcome the above problems of the partitioning methods -LSB- 19 -RSB- -LSB- 28 -RSB-. Recently, another type of partitioning methods based on clustering on data graphs have aroused considerable interests in the machine learning and data mining community. The basic idea behind these methods is to first model the whole dataset as a weighted graph, in which the graph nodes represent the data points, and the weights on the edges correspond to the similarities between pairwise points. Then the cluster assignments of the dataset can be achieved by optimizing some criterions defined on the graph. After some relaxations, these criterions can usually be optimized via eigen-decompositions, which is guaranteed to be global optimal. In this way, spectral clustering efficiently avoids the problems of the traditional partitioning methods as we introduced in last paragraph. In this paper, we propose a novel document clustering algorithm that inherits the superiority of spectral clustering, i.e. the final cluster results can also be obtained by exploit the eigen-structure of a symmetric matrix. So we call our method Clustering with Local and Global Regularization -LRB- CLGR -RRB-. The idea of incorporating both local and global information into label prediction is inspired by the recent works on semi-supervised learning -LSB- 31 -RSB-, and our experimental evaluations on several real document datasets show that CLGR performs better than many state-of-the-art clustering methods. The rest of this paper is organized as follows : in section 2 we will introduce our CLGR algorithm in detail. The experimental results on several datasets are presented in section 3, followed by the conclusions and discussions in section 4. 4. CONCLUSIONS AND FUTURE WORKS In this paper, we derived a new clustering algorithm called clustering with local and global regularization. Our method preserves the merit of local learning algorithms and spectral clustering. Our experiments show that the proposed algorithm outperforms most of the state of the art algorithms on many benchmark datasets. In the future, we will focus on the parameter selection and acceleration issues of the CLGR algorithm.", "keyphrases": ["document cluster", "regular", "global regular", "cluster hierarchi", "spectrum", "specifi search", "hierarch method", "partit method", "label predict", "function estim", "manifold"]}
{"file_name": "C-32", "text": "BuddyCache : High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN * ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task. They require strong consistency for shared persistent data and efficient access to fine-grained objects. These properties are difficult to provide in wide-area networks because of high network latency. BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments. The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers. We have implemented a BuddyCache prototype and evaluated its performance. Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50 % the latency of access to shared objects compared to accessing the remote servers directly. 1. INTRODUCTION Nevertheless, distributed applications may perform poorly in wide-area network environments. Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited. BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment. Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project. Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data. Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable -LSB- 24 -RSB-. For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems -LSB- 22 -RSB-. Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics. If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened. Cooperative web caching -LSB- 10, 11, 15 -RSB- is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server. However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient access to fine-grained objects. Cooperative object caching systems -LSB- 2 -RSB- provide these properties. However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page. Interaction with the server increases latency. The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments. The engineers use a collaborative CAD application to revise and update complex project design documents. The shared documents are stored in transactional repository servers at the company home site. The engineers use workstations running repository clients. The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow. To improve access latency, clients fetch objects from repository servers and cache and access them locally. A coherence protocol ensures that client caches remain consistent when objects are modified. The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects. With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group. BuddyCache presents two main technical challenges. One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system. The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes. BuddyCache uses a '' redirection '' approach similar to one used in cooperative web caching systems -LSB- 11 -RSB-. A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers. If the client request can not be served locally, the redirector forwards it to a remote server. When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients. BuddyCache redirects subsequent requests for this object to the caching client. Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members. BuddyCache uses redirection to support peer update, a lightweight '' application-level multicast '' technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group. Nevertheless, in a transactional system, redirection interferes with shared object availability. Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently. A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information. We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements. We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency. These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2. RELATED WORK Cooperative caching techniques -LSB- 20, 16, 13, 2, 28 -RSB- provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network. These techniques use the server to provide redirection and do not consider issues of high network latency. Cooperative Web caching techniques, -LRB- e.g. -LSB- 11, 15 -RSB- -RRB- investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes. This work does not consider issues of consistent concurrent updates to shared fine-grained objects. This multicast transport level solution is geared to the single writer semantics of web objects. In contrast, BuddyCache uses '' application level '' multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects. Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in -LSB- 27 -RSB-. The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing. The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions. The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme. In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system. Anderson, Eastham and Vahdat in WebFS -LSB- 29 -RSB- present a global file system coherence protocol that allows clients to choose on per file basis between receiving updates or invalidations. Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels. The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems. BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 7. CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task. They require strong consistency for shared persistent data and efficient access to fine-grained objects. These properties are difficult to provide in wide-area network because of high network latency. This paper described BuddyCache, a new transactional cooperative caching -LSB- 20, 16, 13, 2, 28 -RSB- technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments. The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients. Redirection, however, can interfere with object availability. Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers. It provides fine-grained validation using inexpensive coarse-grain version information. We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system -LSB- 23 -RSB- and evaluated the benefits and costs of the system over a range of network latencies. fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency.", "keyphrases": ["object storag system", "collabor strong-consist applic", "wide-area network", "cooper web cach", "fine-grain share", "transact", "fault-toler properti", "buddycach", "domin perform cost", "optimist system", "peer fetch", "multi-user oo7 benchmark"]}
{"file_name": "J-17", "text": "Truthful Mechanism Design for Multi-Dimensional Scheduling via Cycle Monotonicity ABSTRACT We consider the problem of makespan minimization on m unrelated machines in the context of algorithmic mechanism design, where the machines are the strategic players. This is a multidimensional scheduling domain, and the only known positive results for makespan minimization in such a domain are O -LRB- m -RRB- - approximation truthful mechanisms -LSB- 22, 20 -RSB-. We study a well-motivated special case of this problem, where the processing time of a job on each machine may either be `` low '' or `` high '', and the low and high values are public and job-dependent. This preserves the multidimensionality of the domain, and generalizes the restricted-machines -LRB- i.e., -LCB- pj, \u221e -RCB- -RRB- setting in scheduling. We give a general technique to convert any c-approximation algorithm to a 3capproximation truthful-in-expectation mechanism. This is one of the few known results that shows how to export approximation algorithms for a multidimensional problem into truthful mechanisms in a black-box fashion. When the low and high values are the same for all jobs, we devise a deterministic 2-approximation truthful mechanism. These are the first truthful mechanisms with non-trivial performance guarantees for a multidimensional scheduling domain. Our constructions are novel in two respects. First, we do not utilize or rely on explicit price definitions to prove truthfulness ; instead we design algorithms that satisfy cycle monotonicity. Cycle monotonicity -LSB- 23 -RSB- is a necessary and sufficient condition for truthfulness, is a generalization of value monotonicity for multidimensional domains. However, whereas value monotonicity has been used extensively and successfully to design truthful mechanisms in singledimensional domains, ours is the first work that leverages cycle monotonicity in the multidimensional setting. Second, our randomized mechanisms are obtained by first constructing a fractional truthful mechanism for a fractional relaxation of the problem, and then converting it into a truthfulin-expectation mechanism. This builds upon a technique of -LSB- 16 -RSB-, and shows the usefulness of fractional mechanisms in truthful mechanism design. 1. INTRODUCTION Mechanism design studies algorithmic constructions under the presence of strategic players who hold the inputs to the algorithm. Algorithmic mechanism design has focused mainly on settings were the social planner or designer wishes to maximize the social welfare -LRB- or equivalently, minimize social cost -RRB-, or on auction settings where revenuemaximization is the main goal. In this paper, we consider such an alternative goal in the context of machine scheduling, namely, makespan minimization. There are n jobs or tasks that need to be assigned to m machines, where each job has to be assigned to exactly one machine. Hence, we approach the problem via mechanism design : the social designer, who holds the set of jobs to be assigned, needs to specify, in addition to a schedule, suitable payments to the players in order to incentivize them to reveal their true processing times. Such a mechanism is called a truthful mechanism. Instead, it corresponds to maximizing the minimum welfare and the notion of max-min fairness, and appears to be a much harder problem from the viewpoint of mechanism design. In particular, the celebrated VCG -LSB- 26, 9, 10 -RSB- family of mechanisms does not apply here, and we need to devise new techniques. The possibility of constructing a truthful mechanism for makespan minimization is strongly related to assumptions on the players ' processing times, in particular, the `` dimensionality '' of the domain. Nisan and Ronen considered the setting of unrelated machines where the pij values may be arbitrary. This is a multidimensional domain, since a player 's private value is its entire vector of processing times -LRB- pij -RRB- j. Very few positive results are known for multidimensional domains in general, and the only positive results known for multidimensional scheduling are O -LRB- m -RRB- - approximation truthful mechanisms -LSB- 22, 20 -RSB-. We emphasize that regardless of computational considerations, even the existence of a truthful mechanism with a significantly better -LRB- than m -RRB- approximation ratio is not known for any such scheduling domain. On the negative side, -LSB- 22 -RSB- showed that no truthful deterministic mechanism can achieve approximation ratio better than 2, and strengthened this lower bound to m for two specific classes of deterministic mechanisms. Recently, -LSB- 20 -RSB- extended this lower bound to randomized mechanisms, and -LSB- 8 -RSB- improved the deterministic lower bound. In stark contrast with the above state of affairs, much stronger -LRB- and many more -RRB- positive results are known for a special case of the unrelated machines problem, namely, the setting of related machines. Here, we have pij = pj/si for every i, j, where pj is public knowledge, and the speed si is the only private parameter of machine i. This assumption makes the domain of players ' types single-dimensional. Truthfulness in such domains is equivalent to a convenient value-monotonicity condition -LSB- 21, 3 -RSB-, which appears to make it significantly easier to design truthful mechanisms in such domains. Archer and Tardos -LSB- 3 -RSB- first considered the related machines setting and gave a randomized 3-approximation truthful-in-expectation mechanism. The gap between the single-dimensional and multidimensional domains is perhaps best exemplified by the fact that -LSB- 3 -RSB- showed that there exists a truthful mechanism that always outputs an optimal schedule. -LRB- Recall that in the multidimensional unrelated machines setting, it is impossible to obtain a truthful mechanism with approximation ratio better than 2. -RRB- Various follow-up results -LSB- 2, 4, 1, 13 -RSB- have strengthened the notion of truthfulness and/or improved the approximation ratio. Such difficulties in moving from the single-dimensional to the multidimensional setting also arise in other mechanism design settings -LRB- e.g., combinatorial auctions -RRB-. Thus, in addition to the specific importance of scheduling in strategic environments, ideas from multidimensional scheduling may also have a bearing in the more general context of truthful mechanism design for multidimensional domains. In this paper, we consider the makespan-minimization problem for a special case of unrelated machines, where the processing time of a job is either `` low '' or `` high '' on each machine. We call this model the `` jobdependent two-values '' case. This model generalizes the classic `` restricted machines '' setting, where pij \u2208 -LCB- Lj, \u221e -RCB- which has been well-studied algorithmically. A special case of our model is when Lj = L and Hj = H for all jobs j, which we denote simply as the `` two-values '' scheduling model. Both of our domains are multidimensional, since the machines are unrelated : one job may be low on one machine and high on the other, while another job may follow the opposite pattern. Thus, the private information of each machine is a vector specifying which jobs are low and high on it. Thus, they retain the core property underlying the hardness of truthful mechanism design for unrelated machines, and by studying these special settings we hope to gain some insights that will be useful for tackling the general problem. Our Results and Techniques We present various positive results for our multidimensional scheduling domains. Our first result is a general method to convert any capproximation algorithm for the job-dependent two values setting into a 3c-approximation truthful-in-expectation mechanism. This is one of the very few known results that use an approximation algorithm in a black-box fashion to obtain a truthful mechanism for a multidimensional problem. Our result implies that there exists a 3-approximation truthfulin-expectation mechanism for the Lj-Hj setting. Our second result applies to the twovalues setting -LRB- Lj = L, Hj = H -RRB-, for which we improve both the approximation ratio and strengthen the notion of truthfulness. We obtain a deterministic 2-approximation truthful mechanism -LRB- along with prices -RRB- for this problem. These are the first truthful mechanisms with non-trivial performance guarantees for a multidimensional scheduling domain. Complementing this, we observe that even this seemingly simple setting does not admit truthful mechanisms that return an optimal schedule -LRB- unlike in the case of related machines -RRB-. By exploiting the multidimensionality of the domain, we prove that no truthful deterministic mechanism can obtain an approximation ratio better than 1.14 to the makespan -LRB- irrespective of computational considerations -RRB-. The main technique, and one of the novelties, underlying our constructions and proofs, is that we do not rely on explicit price specifications in order to prove the truthfulness of our mechanisms. Instead we exploit certain algorithmic monotonicity conditions that characterize truthfulness to first design an implementable algorithm, i.e., an algorithm for which prices ensuring truthfulness exist, and then find these prices -LRB- by further delving into the proof of implementability -RRB-. This kind of analysis has been the method of choice in the design of truthful mechanisms for singledimensional domains, where value-monotonicity yields a convenient characterization enabling one to concentrate on the algorithmic side of the problem -LRB- see, e.g., -LSB- 3, 7, 4, 1, 13 -RSB- -RRB-. Our work is the first to leverage monotonicity conditions for truthful mechanism design in arbitrary domains. The monotonicity condition we use, which is sometimes called cycle monotonicity, was first proposed by Rochet -LSB- 23 -RSB- -LRB- see also -LSB- 11 -RSB- -RRB-. It is a generalization of value-monotonicity and completely characterizes truthfulness in every domain. Our methods and analyses demonstrate the potential benefits of this characterization, and show that cycle monotonicity can be effectively utilized to devise truthful mechanisms for multidimensional domains. Consider, for example, our first result showing that any c-approximation algorithm can be `` exported '' to a 3c-approximation truthful-in-expectation mechanism. At the level of generality of an arbitrary approximation algorithm, it seems unlikely that one would be able to come up with prices to prove truthfulness of the constructed mechanism. But, cycle monotonicity does allow us to prove such a statement. In fact, some such condition based only on the underlying algorithm -LRB- and not on the prices -RRB- seems necessary to prove such a general statement. The method for converting approximation algorithms into truthful mechanisms involves another novel idea. Our randomized mechanism is obtained by first constructing a truthful mechanism that returns a fractional schedule. Moving to a fractional domain allows us to `` plug-in '' truthfulness into the approximation algorithm in a rather simple fashion, while losing a factor of 2 in the approximation ratio. We then use a suitable randomized rounding procedure to convert the fractional assignment into a random integral assignment. This preserves truthfulness, but we lose another additive factor equal to the approximation ratio. Our construction uses and extends some observations of Lavi and Swamy -LSB- 16 -RSB-, and further demonstrates the benefits of fractional mechanisms in truthful mechanism design. Related Work Nisan and Ronen -LSB- 22 -RSB- first considered the makespan-minimization problem for unrelated machines. They gave an m-approximation positive result and proved various lower bounds. This been improved in -LSB- 2, 4, 1, 13 -RSB- to : a 2-approximation randomized mechanism -LSB- 2 -RSB- ; an FPTAS for any fixed number of machines given by Andelman, Azar and Sorani -LSB- 1 -RSB-, and a 3-approximation deterministic mechanism by Kov \u00b4 acs -LSB- 13 -RSB-. The algorithmic problem -LRB- i.e., without requiring truthfulness -RRB- of makespan-minimization on unrelated machines is well understood and various 2-approximation algorithms are known. Lenstra, Shmoys and Tardos -LSB- 18 -RSB- gave the first such algorithm. Shmoys and Tardos -LSB- 25 -RSB- later gave a 2approximation algorithm for the generalized assignment problem, a generalization where there is a cost cij for assigning a job j to a machine i, and the goal is to minimize the cost subject to a bound on the makespan. Recently, Kumar, Marathe, Parthasarathy, and Srinivasan -LSB- 14 -RSB- gave a randomized rounding algorithm that yields the same bounds. We use their procedure in our randomized mechanism. The characterization of truthfulness for arbitrary domains in terms of cycle monotonicity seems to have been first observed by Rochet -LSB- 23 -RSB- -LRB- see also Gui et al. -LSB- 11 -RSB- -RRB-. This generalizes the value-monotonicity condition for single-dimensional domains which was given by Myerson -LSB- 21 -RSB- and rediscovered by -LSB- 3 -RSB-. As mentioned earlier, this condition has been exploited numerous times to obtain truthful mechanisms for single-dimensional domains -LSB- 3, 7, 4, 1, 13 -RSB-. For convex domains -LRB- i.e., each players ' set of private values is convex -RRB-, it is known that cycle monotonicity is implied by a simpler condition, called weak monotonicity -LSB- 15, 6, 24 -RSB-. But even this simpler condition has not found much application in truthful mechanism design for multidimensional problems. Objectives other than social-welfare maximization and revenue maximization have received very little attention in mechanism design. In the context of combinatorial auctions, the problems of maximizing the minimum value received by a player, and computing an envy-minimizing allocation have been studied briefly. Lavi, Mu'alem, and Nisan -LSB- 15 -RSB- showed that the former objective can not be implemented truthfully ; Bezakova and Dani -LSB- 5 -RSB- gave a 0.5-approximation mechanism for two players with additive valuations. These lower bounds were strengthened in -LSB- 20 -RSB-. 2. PRELIMINARIES 2.1 The scheduling domain In our scheduling problem, we are given n jobs and m machines, and each job must be assigned to exactly one machine. In the unrelated-machines setting, each machine i is characterized by a vector of processing times -LRB- pij -RRB- j, where pij E R \u2265 0 U -LCB- oo -RCB- denotes i 's processing time for job j with the value oo specifying that i can not process j. We consider two special cases of this problem : 1. The job-dependent two-values case, where pij E -LCB- Lj, Hj -RCB- for every i, j, with Lj < Hj, and the values Lj, Hj are known. This generalizes the classic scheduling model of restricted machines, where Hj = oo. 2. We say that a job j is low on machine i if pij = Lj, and high if pij = Hj. We will use the terms schedule and assignment interchangeably. We will also consider randomized algorithms and algorithms that return a fractional assignment. We denote the load of machine i -LRB- under a given assignj xijpij, and the makespan of a schedule is defined as the maximum load on any machine, i.e., maxi li. The goal in the makespan-minimization problem is to assign the jobs to the machines so as to minimize the makespan of the schedule. 2.2 Mechanism design We consider the makespan-minimization problem in the above scheduling domains in the context of mechanism design. Mechanism design studies strategic settings where the social designer needs to ensure the cooperation of the different entities involved in the algorithmic procedure. Following the work of Nisan and Ronen -LSB- 22 -RSB-, we consider the machines to be the strategic players or agents. The social designer holds the set of jobs that need to be assigned, but does not know the -LRB- true -RRB- processing times of these jobs on the different machines. Each machine is a selfish entity, that privately knows its own processing time for each job. We consider direct-revelation mechanisms : each machine reports its -LRB- possibly false -RRB- vector of processing times, the mechanism then computes a schedule and hands out payments to the players -LRB- i.e., machines -RRB- to compensate them for the cost they incur in processing their assigned jobs. A -LRB- direct-revelation -RRB- mechanism thus consists of a tuple -LRB- x, P -RRB- : x specifies the schedule, and P = -LCB- Pi -RCB- specifies the payments handed out to the machines, where both x and the Pis are functions of the reported processing times p = -LRB- pij -RRB- i, j. The mechanism must therefore incentivize the machines/players to truthfully reveal their processing times via the payments. This is made precise using the notion of dominant-strategy truthfulness. To put it in words, in a truthful mechanism, no machine can improve its utility by declaring a false processing time, no matter what the other machines declare. We will also consider fractional mechanisms that return a fractional assignment, and randomized mechanisms that are allowed to toss coins and where the assignment and the payments may be random variables. The notion of truthfulness for a fractional mechanism is the same as in Definition 2.1, where x1, x2 are now fractional assignments. For a randomized mechanism, we will consider the notion of truthfulness in expectation -LSB- 3 -RSB-, which means that a machine -LRB- player -RRB- maximizes her expected utility by declaring her true processing-time vector. For our two scheduling domains, the informational assumption is that the values Lj, Hj are publicly known. The private information of a machine is which jobs have value Lj -LRB- or L -RRB- and which ones have value Hj -LRB- or H -RRB- on it. We emphasize that both of our domains are multidimensional, since each machine i needs to specify a vector saying which jobs are low and high on it.", "keyphrases": ["mechan design", "approxim algorithm", "schedul", "multi-dimension schedul", "cycl monoton", "makespan minim", "algorithm", "random mechan", "us of fraction mechan", "truth mechan design", "fraction domain"]}
{"file_name": "I-26", "text": "Sequential Decision Making in Parallel Two-Sided Economic Search ABSTRACT This paper presents a two-sided economic search model in which agents are searching for beneficial pairwise partnerships. In each search stage, each of the agents is randomly matched with several other agents in parallel, and makes a decision whether to accept a potential partnership with one of them. The distinguishing feature of the proposed model is that the agents are not restricted to maintaining a synchronized -LRB- instantaneous -RRB- decision protocol and can sequentially accept and reject partnerships within the same search stage. We analyze the dynamics which drive the agents ' strategies towards a stable equilibrium in the new model and show that the proposed search strategy weakly dominates the one currently in use for the two-sided parallel economic search model. By identifying several unique characteristics of the equilibrium we manage to efficiently bound the strategy space that needs to be explored by the agents and propose an efficient means for extracting the distributed equilibrium strategies in common environments. 1. INTRODUCTION A two-sided economic search is a distributed mechanism for forming agents ' pairwise partnerships -LSB- 5 -RSB-.1 On every stage of the process, each of the agents is randomly matched with another agent 1Notice that the concept of '' search '' here is very different from the classical definition of '' search '' in AI. While AI search is an active process in which an agent finds a sequence of actions that will bring it from the initial state to a goal state, economic search refers to the identification of the best agent to commit to a partnership with. and the two interact bilaterally in order to learn the benefit encapsulated in a partnership between them. The interaction does not involve bargaining thus each agent merely needs to choose between accepting or rejecting the partnership with the other agent. A typical market where this kind of two-sided search takes place is the marriage market -LSB- 22 -RSB-. Recent literature suggests various software agent-based applications where a two-sided distributed -LRB- i.e., with no centralized matching mechanisms -RRB- search takes place. An important class of such applications includes secondary markets for exchanging unexploited resources. For example, through a twosided search, agents, representing different service providers, can exchange unused bandwidth -LSB- 21 -RSB- and communication satellites can transfer communication with a greater geographical coverage. Twosided agents-based search can also be found in applications of buyers and sellers in eMarkets and peer-to-peer applications. The twosided nature of the search suggests that a partnership between a pair of agents is formed only if it is mutually accepted. By forming a partnership the agents gain an immediate utility and terminate their search. When resuming the search, on the other hand, a more suitable partner might be found however some resources will need to be consumed for maintaining the search process. In this paper we focus on a specific class of two-sided search matching problems, in which the performance of the partnership applies to both parties, i.e., both gain an equal utility -LSB- 13 -RSB-. The equal utility scenario is usually applicable in domains where the partners gain from the synergy between them. In all these applications, any two agents can form a partnership and the performance of any given partnership depends on the skills or the characteristics of its members. Furthermore, the equal utility scenario can also hold whenever there is an option for side-payments and the partnership 's overall utility is equally split among the two agents forming it -LSB- 22 -RSB-. While the two-sided search literature offers comprehensive equilibrium analysis for various models, it assumes that the agents ' search is conducted in a purely sequential manner : each agent locates and interacts with one other agent in its environment at a time -LSB- 5, 22 -RSB-. Nevertheless, when the search is assigned to autonomous software agents a better search strategy can be used. Here an agent can take advantage of its unique inherent filtering and information processing capabilities and its ability to efficiently -LRB- in comparison to people -RRB- maintain concurrent interactions with several other agents at each stage of its search. Such use of parallel interactions in search is favorable whenever the average cost2 per interaction with another agent, when interacting in parallel with a batch of other agents, is smaller than the cost of maintaining one interaction at a time -LRB- i.e., advantage to size -RRB-. For example, the analysis of the costs associated with evaluating potential partnerships between service providers reveals both fixed and variable components when using the parallel search, thus the average cost per interaction decreases as the number of parallel interactions increases -LSB- 21 -RSB-. Despite the advantages identified for parallel interactions in adjacent domains -LRB- e.g., in one-sided economic search -LSB- 7, 16 -RSB- -RRB-, a first attempt for modeling a repeated pairwise matching process in which agents are capable of maintaining interaction with several other agents at a time was introduced only recently -LSB- 21 -RSB-. However, the agents in that seminal model are required to synchronize their decision making process. Thus each agent, upon reviewing the opportunities available in a specific search stage, has to notify all other agents of its decision whether to commit to a partnership -LRB- at most with one of them -RRB- or reject the partnership -LRB- with the rest of them -RRB-. This inherent restriction imposes a significant limitation on the agents ' strategic behavior. In our model, the agents are free to notify the other agents of their decisions in an asynchronous manner. The asynchronous approach allows the agents to re-evaluate their strategy, based on each new response they receive from the agents they interact with. The new model is a much more realistic pairwise model and, as we show in the analysis section, is always preferred by any single agents participating in the process. In the absence of other economic two-sided parallel search models, we use the model that relies on an instantaneous -LRB- synchronous -RRB- decision making process -LSB- 21 -RSB- -LRB- denoted I-DM throughout the rest of the paper -RRB- as a benchmark for evaluating the usefulness of our proposed sequential -LRB- asynchronous -RRB- decision making strategy -LRB- denoted S-DM -RRB-. The main contributions of this paper are threefold : First, we formally model and analyze a two-sided search process in which the agents have no temporal decision making constraints concerning the rejection of or commitment to potential partnerships they encounter in parallel -LRB- the S-DM model -RRB-. This model is a general search model which can be applied in various -LRB- not necessarily software agents-based -RRB- domains. Second, we prove that the agents ' SDM strategy weakly dominates the I-DM strategy, thus every agent has an incentive to deviate to the S-DM strategy when all other agents are using the I-DM strategy. Finally, by using an innovative recursive presentation of the acceptance probabilities of different potential partnerships, we identify unique characteristics of the equilibrium strategies in the new model. These are used for supplying an appropriate computational means that facilitates the calculation of the agents ' equilibrium strategy. This latter contribution is We manage to extract the agents ' new equilibrium strategies without increasing the computational complexity in comparison to the I-DM model. Throughout the paper we demonstrate the different properties of the new model and compare it with the I-DM model using an artificial synthetic environment. In the following section we formally present the S-DM model. An equilibrium analysis and computational means for finding the equilibrium strategy are provided in Section 3. In Section 4 we review related MAS and economic search theory literature. 4. RELATED WORK The two-sided economic search for partnerships in AI literature is a sub-domain of coalition formation8. As in the general 8The use of the term '' partnership '' in this context refers to the agreement between two individual agents to cooperate in a pre-defined manner. For example, in the buyer-seller application a partnership is defined as an agreed transaction between the two-parties -LSB- 9 -RSB-. coalition formation case, agents have the incentive to form partnerships when they are incapable of executing a task by their own or when the partnership can improve their individual utilities -LSB- 14 -RSB-. Various centralized matching mechanisms can be found in the literature -LSB- 6, 2, 8 -RSB-. However, in many MAS environments, in the absence of any reliable central matching mechanism, the matching process is completely distributed. While the search in agent-based environments is well recognized to be costly -LSB- 11, 21, 1 -RSB-, most of the proposed coalition formation mechanisms assume that an agent can scan as many partnership opportunities in its environment as needed or have access to central matchers or middle agents -LSB- 6 -RSB-. The incorporation of costly search in this context is quite rare -LSB- 21 -RSB- and to the best of our knowledge, a distributed two-sided search for partners model similar to the S-DM model has not been studied to date. Classical economic search theory -LRB- -LSB- 15, 17 -RSB-, and references therein -RRB- widely addresses the problem of a searcher operating in a costly environment, seeking to maximize his long term utility. In these models, classified as one-sided search, the focus is on establishing the optimal strategies for the searcher, assuming no mutual search activities -LRB- i.e., no influence on the environment -RRB-. Here the sequential search procedure is often applied, allowing the searcher to investigate a single -LSB- 15 -RSB- or multiple -LSB- 7, 19 -RSB- opportunities at a time. While the latter method is proven to be beneficial for the searcher, it was never used in the '' two-sided '' search models that followed -LRB- where dual search activities are modeled -RRB- -LSB- 22, 5, 18 -RSB-. Therefore, in these models, the equilibrium strategies are always developed based on the assumption that the agents interact with others sequentially -LRB- i.e., with one agent at a time -RRB-. A first attempt to integrate the parallel search into a two-sided search model is given in -LSB- 21 -RSB-, as detailed in the introduction section. The models presented in this area do not associate the coalition formation process with search costs, which is the essence of the analysis that economic search theory aims to supply. Furthermore, even in repeated pairwise bargaining -LSB- 10 -RSB- models the agents are always limited to initiating a single bargaining interaction at a time.", "keyphrases": ["pairwis partnership", "decis", "peer-to-peer applic", "inform process", "util", "search cost", "multi-equilibrium scenario", "equilibrium strategi", "parallel interact", "bound methodolog", "coalit format", "partnership format", "partnership", "costli environ", "search perform", "instantan decis make", "sequenti decis make", "two-side search"]}
{"file_name": "H-8", "text": "Robust Test Collections for Retrieval Evaluation ABSTRACT Low-cost methods for acquiring relevance judgments can be a boon to researchers who need to evaluate new retrieval tasks or topics but do not have the resources to make thousands of judgments. While these judgments are very useful for a one-time evaluation, it is not clear that they can be trusted when re-used to evaluate new systems. In this work, we formally define what it means for judgments to be reusable : the confidence in an evaluation of new systems can be accurately assessed from an existing set of relevance judgments. We then present a method for augmenting a set of relevance judgments with relevance estimates that require no additional assessor effort. Using this method practically guarantees reusability : with as few as five judgments per topic taken from only two systems, we can reliably evaluate a larger set of ten systems. Even the smallest sets of judgments can be useful for evaluation of new systems. 1. INTRODUCTION Consider an information retrieval researcher who has invented a new retrieval task. She has built a system to perform the task and wants to evaluate it. Since the task is new, it is unlikely that there are any extant relevance judgments. She does not have the time or resources to judge every document, or even every retrieved document. She can only judge the documents that seem to be the most informative and stop when she has a reasonable degree of confidence in her conclusions. But what happens when she develops a new system and needs to evaluate it? Or another research group decides to implement a system to perform the task? Can they reliably reuse the original judgments? Can they evaluate without more relevance judgments? Evaluation is an important aspect of information retrieval research, but it is only a semi-solved problem : for most retrieval tasks, it is impossible to judge the relevance of every document ; there are simply too many of them. The solution used by NIST at TREC -LRB- Text REtrieval Conference -RRB- is the pooling method -LSB- 19, 20 -RSB- : all competing systems contribute N documents to a pool, and every document in that pool is judged. This method creates large sets of judgments that are reusable for training or evaluating new systems that did not contribute to the pool -LSB- 21 -RSB-. This solution is not adequate for our hypothetical researcher. The pooling method gives thousands of relevance judgments, but it requires many hours of -LRB- paid -RRB- annotator time. As we will see, the judgments these methods produce can significantly bias the evaluation of a new set of systems. Returning to our hypothetical resesarcher, can she reuse her relevance judgments? First we must formally define what it means to be `` reusable ''. In previous work, reusability has been tested by simply assessing the accuracy of a set of relevance judgments at evaluating unseen systems. We need a more careful definition of reusability. Specifically, the question of reusability is not how accurately we can evaluate new systems. A `` malicious adversary '' can always produce a new ranked list that has not retrieved any of the judged documents. The real question is how much confidence we have in our evaluations, and, more importantly, whether we can trust our estimates of confidence. Even if confidence is not high, as long as we can trust it, we can identify which systems need more judgments in order to increase confidence. Any set of judgments, no matter how small, becomes reusable to some degree. Small, reusable test collections could have a huge impact on information retrieval research. Research groups would be able to share the relevance judgments they have done `` in-house '' for pilot studies, new tasks, or new topics. The amount of data available to researchers would grow exponentially over time. 6. CONCLUSIONS AND FUTURE WORK In this work we have offered the first formal definition of the common idea of `` reusability '' of a test collection and presented a model that is able to achieve reusability with very small sets of relevance judgments. The confidence estimates of RTC, in addition to being accurate, provide a guide for obtaining additional judgments : focus on judging documents from the lowest-confidence comparisons. In the long run, we see small sets of relevance judg Table 5 : Accuracy, W, mean \u03c4, and median number of judgments for all 8 testing sets. The results are highly consistent across data sets. ments being shared by researchers, each group contributing a few more judgments to gain more confidence about their particular systems. As time goes on, the number of judgments grows until there is 100 % confidence in every evaluation -- and there is a full test collection for the task. It could be applied to evaluation on a dynamic test collection as defined by Soboroff -LSB- 18 -RSB-. The model we presented in Section 3 is by no means the only possibility for creating a robust test collection. In addition to expert aggregation, we could estimate probabilities by looking at similarities between documents. This is an obvious area for future exploration. We have many more experimental results that we unfortunately did not have space for but that reinforce the notion that RTC is highly robust : with just a few judgments per topic, we can accurately assess the confidence in any pairwise comparison of systems.", "keyphrases": ["inform retriev", "evalu", "relev judgement", "reusabl", "lowerest-confid comparison", "mtc", "rtc", "expect", "varianc", "distribut of relev"]}
{"file_name": "H-21", "text": "Robust Classification of Rare Queries Using Web Knowledge ABSTRACT We propose a methodology for building a practical robust query classification system that can identify thousands of query classes with reasonable accuracy, while dealing in realtime with the query volume of a commercial web search engine. We use a blind feedback technique : given a query, we determine its topic by classifying the web search results retrieved by the query. Motivated by the needs of search advertising, we primarily focus on rare queries, which are the hardest from the point of view of machine learning, yet in aggregation account for a considerable fraction of search engine traffic. Empirical evaluation confirms that our methodology yields a considerably higher classification accuracy than previously reported. We believe that the proposed methodology will lead to better matching of online ads to rare queries and overall to a better user experience. 1. INTRODUCTION One thing, however, has remained constant : people use very short queries. Various studies estimate the average length of a search query between 2.4 and 2.7 words, which by all accounts can carry only a small amount of information. Commercial search engines do a remarkably good job in interpreting these short strings, but they are not -LRB- yet! -RRB- omniscient. Therefore, using additional external knowledge to augment the queries can go a long way in improving the search results and the user experience. In this study we present a methodology for query classification, where our aim is to classify queries onto a commercial taxonomy of web queries with approximately 6000 nodes. Given such classifications, one can directly use them to provide better search results as well as more focused ads. The problem of query classification is extremely difficult owing to the brevity of queries. Observe, however, that in many cases a human looking at a search query and the search query results does remarkably well in making sense of it. Of course, the sheer volume of search queries does not lend itself to human supervision, and therefore we need alternate sources of knowledge about the world. Search engines index colossal amounts of information, and as such can be viewed as very comprehensive repositories of knowledge. Following the heuristic described above, we propose to use the search results themselves to gain additional insights for query interpretation. To this end, we employ the pseudo relevance feedback paradigm, and assume the top search results to be relevant to the query. Certainly, not all results are equally relevant, and thus we use elaborate voting schemes in order to obtain reliable knowledge about the query. For the purpose of this study we first dispatch the given query to a general web search engine, and collect a number of the highest-scoring URLs. We crawl the Web pages pointed by these URLs, and classify these pages. Finally, we use these result-page classifications to classify the original query. Our empirical evaluation confirms that using Web search results in this manner yields substantial improvements in the accuracy of query classification. Note that in a practical implementation of our methodology within a commercial search engine, all indexed pages can be pre-classified using the normal text-processing and indexing pipeline. Thus, at run-time we only need to run the voting procedure, without doing any crawling or classification. This additional overhead is minimal, and therefore the use of search results to improve query classification is entirely feasible in run-time. Another important aspect of our work lies in the choice of queries. The volume of queries in today 's search engines follows the familiar power law, where a few queries appear very often while most queries appear only a few times. While individual queries in this long tail are rare, together they account for a considerable mass of all searches. However, the `` tail '' queries simply do not have enough occurrences to allow statistical learning on a per-query basis. Therefore, we need to aggregate such queries in some way, and to reason at the level of aggregated query clusters. A natural choice for such aggregation is to classify the queries into a topical taxonomy. Knowing which taxonomy nodes are most relevant to the given query will aid us to provide the same type of support for rare queries as for frequent queries. Consequently, in this work we focus on the classification of rare queries, whose correct classification is likely to be particularly beneficial. Early studies in query interpretation focused on query augmentation through external dictionaries -LSB- 22 -RSB-. More recent studies -LSB- 18, 21 -RSB- also attempted to gather some additional knowledge from the Web. Specifically, earlier works in the field used very small query classification taxonomies of only a few dozens of nodes, which do not allow ample specificity for online advertising -LSB- 11 -RSB-. First, we build the query classifier directly for the target taxonomy, instead of using a secondary auxiliary structure ; this greatly simplifies taxonomy maintenance and development. The taxonomy used in this work is two orders of magnitude larger than that used in prior studies. The empirical evaluation demonstrates that our methodology for using external knowledge achieves greater improvements than those previously reported. Since our taxonomy is considerably larger, the classification problem we face is much more difficult, making the improvements we achieve particularly notable. We also report the results of a thorough empirical study of different voting schemes and different depths of knowledge -LRB- e.g., using search summaries vs. entire crawled pages -RRB-. We found that crawling the search results yields deeper knowledge and leads to greater improvements than mere summaries. This result is in contrast with prior findings in query classification -LSB- 20 -RSB-, but is supported by research in mainstream text classification -LSB- 5 -RSB-. 4. RELATED WORK Even though the average length of search queries is steadily increasing over time, a typical query is still shorter than 3 words. Consequently, many researchers studied possible ways to enhance queries with additional information. One important direction in enhancing queries is through query expansion. This can be done either using electronic dictionaries and thesauri -LSB- 22 -RSB-, or via relevance feedback techniques that make use of a few top-scoring search results. Early work in information retrieval concentrated on manually reviewing the returned results -LSB- 16, 15 -RSB-. More recently, studies in query augmentation focused on classification of queries, assuming such classifications to be beneficial for more focused query interpretation. Indeed, Kowalczyk et al. -LSB- 10 -RSB- found that using query classes improved the performance of document retrieval. Studies in the field pursue different approaches for obtaining additional information about the queries. Beitzel et al. -LSB- 1 -RSB- used semi-supervised learning as well as unlabeled data -LSB- 2 -RSB-. Gravano et al. -LSB- 6 -RSB- classified queries with respect to geographic locality in order to determine whether their intent is local or global. The 2005 KDD Cup on web query classification inspired yet another line of research, which focused on enriching queries using Web search engines and directories -LSB- 11, 18, 20, 9, 21 -RSB-. The KDD task specification provided a small taxonomy -LRB- 67 nodes -RRB- along with a set of labeled queries, and posed a challenge to use this training data to build a query classifier. Several teams used the Web to enrich the queries and provide more context for classification. The main research questions of this approach the are -LRB- 1 -RRB- how to build a document classifier, -LRB- 2 -RRB- how to translate its classifications into the target taxonomy, and -LRB- 3 -RRB- how to determine the query class based on document classifications. The winning solution of the KDD Cup -LSB- 18 -RSB- proposed using an ensemble of classifiers in conjunction with searching multiple search engines. To address issue -LRB- 1 -RRB- above, their solution used the Open Directory Project -LRB- ODP -RRB- to produce an ODP-based document classifier. The ODP hierarchy was then mapped into the target taxonomy using word matches at individual nodes. A document classifier was built for the target taxonomy by using the pages in the ODP taxonomy that appear in the nodes mapped to the particular target node. Thus, Web documents were first classified with respect to the ODP hierarchy, and their classifications were subsequently mapped to the target taxonomy for query classification. Compared to this approach, we solved the problem of document classification directly in the target taxonomy by using the queries to produce document classifier as described in Section 2. This simplifies the process and removes the need for mapping between taxonomies. This also streamlines taxonomy maintenance and development. Using this approach, we were able to achieve good performance in a very large scale taxonomy. We also evaluated a few alternatives how to combine individual document classifications when actually classifying the query. In a follow-up paper -LSB- 19 -RSB-, Shen et al. proposed a framework for query classification based on bridging between two taxonomies. In this approach, the problem of not having a document classifier for web results is solved by using a training set available for documents with a different taxonomy. For this, an intermediate taxonomy with a training set -LRB- ODP -RRB- is used. As opposed to this, we built a document classifier for the target taxonomy directly, without using documents from an intermediate taxonomy. While we were not able to directly compare the results due to the use of different taxonomies -LRB- we used a much larger taxonomy -RRB-, our precision and recall results are consistently higher even over the hardest query set. 5. CONCLUSIONS Query classification is an important information retrieval task. Accurate classification of search queries is likely to benefit a number of higher-level tasks such as Web search and ad matching. Since search queries are usually short, by themselves they usually carry insufficient information for adequate classification accuracy. To address this problem, we proposed a methodology for using search results as a source of external knowledge. To this end, we send the query to a search engine, and assume that a plurality of the highestranking search results are relevant to the query. Classifying these results then allows us to classify the original query with substantially higher accuracy. The results of our empirical evaluation definitively confirmed that using the Web as a repository of world knowledge contributes valuable information about the query, and aids in its correct classification. Furthermore, the taxonomy used in this study is approximately 2 orders of magnitude larger than that used in prior works. When using search results, one can either use only summaries of the results provided by 3Since the field of query classification does not yet have established and agreed upon benchmarks, direct comparison of results is admittedly tricky. the search engine, or actually crawl the results pages for even deeper knowledge. Overall, query classification performance was the best when using the full crawled pages -LRB- Table 1 -RRB-. These results are consistent with prior studies -LSB- 5 -RSB-, which found that using full crawled pages is superior for document classification than using only brief summaries. Our findings, however, are different from those reported by Shen et al. -LSB- 19 -RSB-, who found summaries to yield better results. We attribute our observations to using a more elaborate voting scheme among the classifications of individual search results, as well as to using a more difficult set of rare queries. In this study we used two major search engines, A and B. Interestingly, we found notable distinctions in the quality of their output. Notably, for engine A the overall results were better when using the full crawled pages of the search results, while for engine B it seems to be more beneficial to use the summaries of results. This implies that while the quality of search results returned by engine A is apparently better, engine B does a better work in summarizing the pages. We also found that the best results were obtained by using full crawled pages and performing voting among their individual classifications. On the other hand, for the owners of a search engine, full page classification is much more efficient, since it is easy to preprocess all indexed pages by classifying them once onto the -LRB- fixed -RRB- taxonomy. Then, page classifications are obtained as part of the meta-data associated with each search result, and query classification can be nearly instantaneous. When using summaries it appears that better results are obtained by first concatenating individual summaries into a meta-document, and then using its classification as a whole. Consistent with our intuition, using too few search results yields useful but insufficient knowledge, and using too many search results leads to inclusion of marginally relevant Web pages. The best results were obtained when using 40 top search hits. In this work, we first classify search results, and then use their classifications directly to classify the original query. Alternatively, one can use the classifications of search results as features in order to learn a second-level classifier. We plan to further investigate this direction in our future work. If the search engine classifies crawled pages during indexing, then at query time we only need to fetch these classifications and do the voting. To conclude, we believe our methodology for using Web search results holds considerable promise for substantially improving the accuracy of Web search queries. We believe our findings will have immediate applications to improving the handling of rare queries, both for improving the search results as well as yielding better matched advertisements. In our further research we also plan to make use of session information in order to leverage knowledge about previous queries to better classify subsequent ones.", "keyphrases": ["queri classif", "search engin", "search advertis", "machin learn", "relev feedback", "vote scheme", "crawl", "topic taxonomi", "affin score", "condit probabl", "adapt", "inform retriev"]}
{"file_name": "C-4", "text": "Intra-flow Loss Recovery and Control for ABSTRACT `` Best effort '' packet-switched networks, like the Internet, do not offer a reliable transmission of packets to applications with real-time constraints such voice. Thus, the loss of packets impairs the application-level utility. For voice this utility impairment is twofold : on one hand, even short bursts of lost packets may decrease significantly the ability of the receiver to conceal the packet loss and the speech signal out is interrupted. On the other hand, some packets may be particular sensitive to loss as they carry more important information in terms of user perception than other packets. We first develop an end-to-end model based on loss lengths with which we can describe the loss distribution within a These packet-level metrics are then linked to user-level objective speech quality metrics. Using this framework, we find that for low-compressing sample-based codecs -LRB- PCM -RRB- with loss concealment isolated packet losses can be concealed well, whereas burst losses have a higher perceptual impact. For high-compressing frame-based codecs -LRB- G. 729 -RRB- on one hand the impact of loss is amplified through error propagation caused by the decoder filter memories, though on the other hand such coding schemes help to perform loss concealment by extrapolation of decoder state. Contrary to sample-based codecs we show that the concealment performance may `` break '' at transitions within the speech signal however. We then propose mechanisms which differentiate between packets within a voice data to minimize the impact of packet loss. We designate these methods as loss recovery and control. At the end-to-end level, identification of packets sensitive to loss -LRB- sender -RRB- as well as loss concealment -LRB- receiver -RRB- takes place. Hop-by-hop support schemes then allow to -LRB- statistically -RRB- trade the loss of one packet, which is considered more important, against another one of the same flow which is of lower importance. As both ets require the same cost in terms of network transmission, a gain in user perception is obtainable. We show that significant speech quality improvements can be achieved and additional data and delay overhead can be avoided while still maintaining a network service which is virtually identical to best effort in the long term. 1. INTRODUCTION Considering that a real-time may experience some packet loss, the impact of loss may vary significantly dependent on which packets are lost within a flow. In the following we distinguish two reasons for such a variable loss sensitivity : Temporal sensitivity : Loss of which is correlated in time may lead to disruptions in the service. For voice, as a single packet contains typically several -LRB- voice frames -RRB- this effect is thus more significant than e.g. for video. It translates basically to isolated packet losses versus losses that occur in bursts. Figure 1 : Schematic utility functions dependent on the loss of more and less -LRB- -1 -RRB- important packets more important with regard to user perception than others of the same flow. Let us consider a flow with two frame types of largely different perceptual importance -LRB- we same size, frequency and no interdependence between the frames -RRB-. Under the loss of 50 % of the packets, the perceptual quality varies hugely between the where the 50 % of the frames with high perceptual importance are received and the where the 50 % less important frames received. Network support for real-time multimedia flows can on one hand aim at offering a service, which, however, to be implemented within pa & et-switched network, will be costly for the network provider and thus for the user. On the other hand, within a lossy service, the above sensitivity constraints must be taken into account. Let us now consider the case that 50 % of packets of flow identified more important -LRB- designated by or less important due to any of the above sensitivity constraints. Figure 1 a -RRB- shows a generic utility function describing the level Quality of Service dependent on the percentage of packets lost. For real-time multimedia traffic, such utility should correspond to perceived video/voice quality. If the relative importance of the packets is not known by the transmission system, the loss rates for the and -1 packets are equal. Due to the over-proportional sensitivity of the packets to loss as well as the dependence of the end loss recovery performance on the packets, the utility function is decreasing significantly in a non-linear way -LRB- approximated in the figure by piece-wise linear functions -RRB- with an increasing loss rate. Figure 1 b -RRB- presents the where all packets are protected at the expense of -1 The decay of the utility function -LRB- for loss rates < 50 % -RRB- is reduced, because the packets are protected and the endto-end loss recovery can thus operate properly a wider range of loss rates indicated by the shaded area. This results in a graceful degradation of the application 's utility. Note that the higher the non-linearity of the utility contribution of the packets is -LRB- deviation from the dotted curve in Fig. 1 a -RRB-, the higher is the potential gain in utility when the protection for is enabled. Results for actual perceived quality utility for multimedia applications exhibit such non-linear behavior *. As mechanisms have to be implemented within the network -LRB- hopby-hop -RRB- and/or in the end systems -LRB- end-to-end -RRB-, we have another axis of classification. The adaptation of the sender 's to the current network congestion state an scheme -LRB- loss avoidance, is difficult to apply to voice. Considering that voice flows have very low the relative cost of transmitting the feedback information is -LRB- when compared e.g. to a video flow -RRB-. The major however, the lack of a codec is truly scalable in terms of its output and corresponding perceptual quality. when the availability of computing power is assumed, the lowest codec can be chosen permanently without actually decreasing the perceptual quality. For loss on an end-to-end basis, due to the realtime delay constraints, open-loop schemes like Forward Error Correction -LRB- FEC -RRB- have been proposed While attractive because they can be used on the Internet today, they also have several drawbacks. The amount of redundant information needs to be adaptive to avoid taking bandwidth away from other flows. Using redundancy has also implications to the delay adaptation -LRB- -LSB- lo -RSB- -RRB- employed to de-jitter the packets at the receiver. Note that the presented types of loss sensitivity also apply to we have obtained results which confirm the shape of the `` overall utility '' curve shown in Fig. 1, clearly the utility functions of the `` sub ''. flows and their relationship are more complex and only approximately additive. Table 1 : State and transition probabilities computed for an end-to-end Internet trace using a general Markov model -LRB- third order -RRB- by Yajnik et. al.. which are enhanced by end-to-end loss recovery mechanisms. End-to-end mechanisms can reduce and shift such sensitivities but can not come close to eliminate them. Therefore in this work we assume that the lowest possible trate which provides the desired quality is chosen. Neither feedback/adaptation nor redundancy is used, however, at the end-to-end level, identification/marking of packets sensitive to loss -LRB- sender -RRB- as well as loss concealment -LRB- receiver -RRB- takes place. Hop-by-hop support schemes then allow trading the loss of one packet, which is considered more important, against another one of the same flow which is of lower importance. We employ actual and measure their utility in the presence of packet loss using objective speech quality measurement. The paper is structured as follows : Section 2 introduces packet - and user-level metrics. We employ these metrics to describe the sensitivity of traffic to packet loss in section 3. Section 4 briefly introduces a queue management algorithm which can be used for intra-flow loss control. In section 5, we present results documenting the performance of the proposed mechanisms at both the end-to-end and by-hop level. Section 6 concludes the paper.", "keyphrases": ["end-to-end model", "sampl-base codec", "loss recoveri and control", "loss sensit", "network support for real-time multimedia", "qualiti of servic", "end-to-end loss recoveri", "voip traffic", "intra-flow loss control", "packet-level metric", "gener markov model", "sensit of voip traffic", "queue manag algorithm", "frame-base codec"]}
{"file_name": "C-22", "text": "Runtime Metrics Collection for Middleware Supported Adaptation of Mobile Applications ABSTRACT This paper proposes, implements, and evaluates in terms of worst case performance, an online metrics collection strategy to facilitate application adaptation via object mobility using a mobile object framework and supporting middleware. The solution is based upon an abstract representation of the mobile object system, which holds containers aggregating metrics for each specific component including host managers, runtimes and mobile objects. A key feature of the solution is the specification of multiple configurable criteria to control the measurement and propagation of metrics through the system. The MobJeX platform was used as the basis for implementation and testing with a number of laboratory tests conducted to measure scalability, efficiency and the application of simple measurement and propagation criteria to reduce collection overhead. 1. INTRODUCTION Effective adaptation requires detailed and up to date information about both the system and the software itself. Metrics related to system wide information -LRB- e.g. processor, memory and network load -RRB- are referred to as environmental metrics -LSB- 5 -RSB-, while metrics representing application behaviour are referred as software metrics -LSB- 8 -RSB-. Furthermore, the type of metrics required for performing adaptation is dependent upon the type of adaptation required. For example, service-based adaptation, in which service quality or service behaviour is modified in response to changes in the runtime environment, generally requires detailed environmental metrics but only simple software metrics -LSB- 4 -RSB-. On the other hand, adaptation via object mobility -LSB- 6 -RSB-, also requires detailed software metrics -LSB- 9 -RSB- since object placement is dependent on the execution characteristics of the mobile objects themselves. With the exception of MobJeX -LSB- 6 -RSB-, existing mobile object systems such as Voyager -LSB- 10 -RSB-, FarGo -LSB- 11, 12 -RSB-, and JavaParty -LSB- 13 -RSB- do not provide automated adaptation, and therefore lack the metrics collection process required to support this process. In the case of MobJeX, although an adaptation engine has been implemented -LSB- 5 -RSB-, preliminary testing was done using synthetic pre-scripted metrics since there is little prior work on the dynamic collection of software metrics in mobile object frameworks, and no existing means of automatically collecting them. Consequently, the main contribution of this paper is a solution for dynamic metrics collection to support adaptation via object mobility for mobile applications. This problem is non-trivial since typical mobile object frameworks consist of multiple application and middleware components, and thus metrics collection must be performed at different locations and the results efficiently propagated to the adaptation engine. The rest of this paper is organised as follows : Section 2 describes the general structure and implementation of mobile object frameworks in order to understand the challenges related to the collection, propagation and delivery of metrics as described in section 3. Section 4 describes some initial testing and results and section 5 closes with a summary, conclusions and discussion of future work. 2. BACKGROUND In general, an object-oriented application consists of objects collaborating to provide the functionality required by a given problem domain. Mobile object frameworks allow some of these objects to be tagged as mobile objects, providing middleware support for such objects to be moved at runtime to other hosts. At a minimum, a mobile object framework with at least one running mobile application consists of the following components : runtimes, mobile objects, and proxies -LSB- 14 -RSB-, although the terminology used by individual frameworks can differ -LSB- 6, 10-13 -RSB-. A runtime is a container process for the management of mobile objects. For example, in FarGo -LSB- 15 -RSB- this component is known as a core and in most systems separate runtimes are required to allow different applications to run independently, although this is not the case with MobJeX, which can run multiple applications in a single runtime using threads. The applications themselves comprise mobile objects, which interact with each other through proxies -LSB- 14 -RSB-. Upon migration, proxy objects move with the source object. The Java based system MobJeX, which is used as the implementation platform for the metrics collection solution described in this paper, adds a number of additional middleware components. Firstly, a host manager -LRB- known as a service in MobJeX -RRB- provides a central point of communication by running on a known port on a per host basis, thus facilitating the enumeration or lookup of components such as runtimes or mobile objects. Secondly, MobJeX has a per-application mobile object container called a transport manager -LRB- TM -RRB-. As such the host and transport managers are considered in the solution provided in the next section but could be omitted in the general case. Finally, depending on adaptation mode, MobJeX can have a centralised system controller incorporating a global adaptation engine for performing system wide optimisation. 5. SUMMARY AND CONCLUSIONS Given the challenges of developing mobile applications that run in dynamic/heterogeneous environments, and the subsequent interest in application adaptation, this paper has proposed and implemented an online metrics collection strategy to assist such adaptation using a mobile object framework and supporting middleware. Controlled lab studies were conducted to determine worst case performance, as well as show the reduction in collection overhead when applying simple collection criteria. In addition, further testing provided an initial indication of the characteristics of application objects -LRB- based on method execution time -RRB- that would be good candidates for adaptation using the worst case implementation of the proposed metrics collection strategy. A key feature of the solution was the specification of multiple configurable criteria to control the propagation of metrics through the system, thereby reducing collection overhead. Furthermore, such a temporal history could also facilitate intelligent decisions regarding the collection of metrics since for example a metric that is known to be largely constant need not be frequently measured. Future work will also involve the evaluation of a broad range of adaptation scenarios on the MobJeX framework to quantity the gains that can be made via adaptation through object mobility and thus demonstrate in practise, the efficacy of the solution described in this paper. Finally, the authors wish to explore applying the metrics collection concepts described in this paper to a more general and reusable context management system -LSB- 20 -RSB-.", "keyphrases": ["data", "object-orient applic", "mobil object framework", "mobjex", "java", "metricscontain", "metric collect", "proxi", "perform and scalabl", "measur", "propag and deliveri", "framework"]}
{"file_name": "H-26", "text": "A Support Vector Method for Optimizing Average Precision ABSTRACT Machine learning is commonly used to improve ranked retrieval systems. Due to computational difficulties, few learning techniques have been developed to directly optimize for mean average precision -LRB- MAP -RRB-, despite its widespread use in evaluating such systems. Existing approaches optimizing MAP either do not find a globally optimal solution, or are computationally expensive. In contrast, we present a general SVM learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of MAP. We evaluate our approach using the TREC 9 and TREC 10 Web Track corpora -LRB- WT10g -RRB-, comparing against SVMs optimized for accuracy and ROCArea. In most cases we show our method to produce statistically significant improvements in MAP scores. 1. INTRODUCTION State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions. However, most current approaches do not optimize for the evaluation measure most often used, namely Mean Average Precision -LRB- MAP -RRB-. Instead, current algorithms tend to take one of two general approaches. The first approach is to learn a model that estimates the probability of a document being relevant given If solved effectively, the ranking with best MAP performance can easily be derived from the probabilities of relevance. However, achieving high MAP only requires finding a good ordering of the documents. As a result, finding good probabilities requires solving a more difficult problem than necessary, likely requiring more training data to achieve the same MAP performance. The second common approach is to learn a function that maximizes a surrogate measure. Performance measures optimized include accuracy -LSB- 17, 15 -RSB-, ROCArea -LSB- 1, 5, 10, 11, 13, 21 -RSB- or modifications of ROCArea -LSB- 4 -RSB-, and NDCG -LSB- 2, 3 -RSB-. Learning a model to optimize for such measures might result in suboptimal MAP performance. In fact, although some previous systems have obtained good MAP performance, it is known that neither achieving optimal accuracy nor ROCArea can guarantee optimal MAP performance -LSB- 7 -RSB-. In this paper, we present a general approach for learning ranking functions that maximize MAP performance. Specifically, we present an SVM algorithm that globally optimizes a hinge-loss relaxation of MAP. This approach simplifies the process of obtaining ranking functions with high MAP performance by avoiding additional intermediate steps and heuristics. The new algorithm also makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for accuracy and ROCArea. In contrast to recent work directly optimizing for MAP performance by Metzler & Croft -LSB- 16 -RSB- and Caruana et al. -LSB- 6 -RSB-, our technique is computationally efficient while finding a globally optimal solution. We now describe the algorithm in detail and provide proof of correctness. Following this, we provide an analysis of running time. We have also developed a software package implementing our algorithm that is available for public user. 6. CONCLUSIONS AND FUTURE WORK We have presented an SVM method that directly optimizes MAP. It provides a principled approach and avoids difficult to control heuristics. We formulated the optimization problem and presented an algorithm which provably finds the solution in polynomial time. We have shown empirically that our method is generally superior to or competitive with conventional SVMs methods. Our new method makes it conceptually just as easy to optimize SVMs for MAP as was previously possible only for Accuracy and ROCArea. Since other methods typically require tuning multiple heuristics, we also expect to train fewer models before finding one which achieves good performance. The learning framework used by our method is fairly general.", "keyphrases": ["machin learn", "rank retriev system", "learn techniqu", "mean averag precis", "optim solut", "relax of map", "inform retriev system", "probabl", "surrog measur", "loss function", "supervis learn"]}
{"file_name": "H-25", "text": "Term Feedback for Information Retrieval with Language Models ABSTRACT I n t hi s paper w e s t udy t er m - based f eedback f or i nf or mat i on r etrieval in the language modeling approach. With term feedback a user directly judges the relevance of individual terms without interaction with feedback documents, taking full control of the query expansion process. We propose a cluster-based method for selecting terms to present to the user for judgment, as well as effective algorithms for constructing refined query language models from user term feedback. Our algorithms are shown to bring significant improvement in retrieval accuracy over a non-feedback baseline, and achieve comparable performance to relevance feedback. They are helpful even when there are no relevant documents in the top. 1. INTRODUCTION In the language modeling approach to information retrieval, feedback is often modeled as estimating an improved query model or relevance model based on a set of feedback documents -LSB- 25, 13 -RSB-. This is in line with the traditional way of doing relevance feedback - presenting a user with documents/passages for relevance judgment and then extracting terms from the judged documents or passages to expand the initial query. It is an indirect way of seeking user 's assistance for query model construction, in the sense that the refined query model -LRB- based on terms -RRB- is learned through feedback documents/passages, which are high-level structures of terms. It has the disadvantage that irrelevant terms, which occur along with relevant ones in the judged content, may be erroneously used for query expansion, causing undesired effects. For example, for the TREC query `` Hubble telescope achievements '', when a relevant document talks more about the telescope 's repair than its discoveries, irrelevant terms such as `` spacewalk '' can be added into the modified query. We can consider a more direct way to involve a user in query model improvement, without an intermediary step of document feedback that can introduce noise. The idea is to present a -LRB- reasonable -RRB- number of individual terms to the user and ask him/her to judge the relevance of each term or directly specify their probabilities in the query model. Compared to traditional relevance feedback, this term-based approach to interactive query model refinement has several advantages. First, the user has better control of the final query model through direct manipulation of terms : he/she can dictate which terms are relevant, irrelevant, and possibly, to what degree. This avoids the risk of bringing unwanted terms into the query model, although sometimes the user introduces low-quality terms. This is especially helpful for interactive adhoc search. In this case, relevance feedback is useless, as no relevant document can be leveraged on, but term feedback is still often helpful, by allowing relevant terms to be picked from irrelevant documents. During our participation in the TREC 2005 HARD Track and continued study afterward, we explored how to exploit term feedback from the user to construct improved query models for information retrieval in the language modeling approach. We identified two key subtasks of term-based feedback, i.e., pre-feedback presentation term selection and post-feedback query model construction, with effective algorithms developed for both. We imposed a secondary cluster structure on terms and found that a cluster view sheds additional insight into the user 's information need, and provides a good way of utilizing term feedback. Through experiments we found that term feedback improves significantly over the nonfeedback baseline, even though the user often makes mistakes in relevance judgment. Among our algorithms, the one with best retrieval performance is TCFB, the combination of TFB, the direct term feedback algorithm, and CFB, the cluster-based feedback algorithm. We also varied the number of feedback terms and observed reasonable improvement even at low numbers. Finally, by comparing term feedback with document-level feedback, we found it to be a viable alternative to the latter with competitive retrieval performance. The rest of the paper is organized as follows. Section 2 discusses some related work. Section 4 outlines our general approach to term feedback. We present our method for presentation term selection in Section 3 and algorithms for query model construction in Section 5. The experiment results are given in Section 6. Section 7 concludes this paper. 2. RELATED WORK Relevance feedback -LSB- 17, 19 -RSB- has long been recognized as an effective method for improving retrieval performance. Normally, the top N documents retrieved using the original query are presented to the user for judgment, after which terms are extracted from the judged relevant documents, weighted by their potential of attracting more relevant documents, and added into the query model. The expanded query usually represents the user 's information need better than the original one, which is often just a short keyword query. A second iteration of retrieval using this modified query usually produces significant increase in retrieval accuracy. In cases where true relevance judgment is unavailable and all top N documents are assumed to be relevant, it is called blind or pseudo feedback -LSB- 5, 16 -RSB- and usually still brings performance improvement. Because document is a large text unit, when it is used for relevance feedback many irrelevant terms can be introduced into the feedback process. To overcome this, passage feedback is proposed and shown to improve feedback performance -LSB- 1, 23 -RSB-. A more direct solution is to ask the user for their relevance judgment of feedback terms. For example, in some relevance feedback systems such as -LSB- 12 -RSB-, there is an interaction step that allows the user to add or remove expansion terms after they are automatically extracted from relevant documents. In many cases term relevance feedback has been found to effectively improve retrieval performance -LSB- 6, 22, 12, 4, 10 -RSB-. For example, the study in -LSB- 12 -RSB- shows that the user prefers to have explicit knowledge and direct control of which terms are used for query expansion, and the penetrable interface that provides this freedom is shown to perform better than other interfaces. However, in some other cases there is no significant benefit -LSB- 3, 14 -RSB-, even if the user likes interacting with expansion terms. The user is found to be not good at identifying useful terms for query expansion, when a simple term presentation interface is unable to provide sufficient semantic context of the feedback terms. Our work differs from the previous ones in two important aspects. The usual way for feedback term presentation is just to display the terms in a list. There have been some works on alternative user interfaces. In both studies, however, there is no significant performance difference. In our work we adopt the simplest approach of terms + checkboxes. We focus on term presentation and query model construction from feedback terms, and believe using contexts to improve feedback term quality should be orthogonal to our method. 7. CONCLUSIONS In this paper we studied the use of term feedback for interactive information retrieval in the language modeling approach. We proposed a cluster-based method for selecting presentation terms as well as algorithms to estimate refined query models from user term feedback. We saw significant improvement in retrieval accuracy brought by term feedback, in spite of the fact that a user often makes mistakes in relevance judgment that hurts its performance. We found the best-performing algorithm to be TCFB, which benefits from the combination of directly observed term evidence with TFB and indirectly learned cluster relevance with CFB. When we reduced the number of presentation terms, term feedback is still able to keep much of its performance gain over the baseline. Finally, we compared term feedback to document-level relevance feedback, and found that TCFB3C 's performance is on a par with the latter with 5 feedback documents. We regarded term feedback as a viable alternative to traditional relevance feedback, especially when there are no relevant documents in the top. We propose to extend our work in several ways. First, we want to study whether the use of various contexts can help the user to better identify term relevance, while not sacrificing the simplicity and compactness of term feedback. Second, currently all terms are presented to the user in a single batch. We could instead consider iterative term feedback, by presenting a small number of terms first, and show more terms after receiving user feedback or stop when the refined query is good enough. The presented terms should be selected dynamically to maximize learning benefits at any moment. Third, we have plans to incorporate term feedback into our UCAIR toolbar -LSB- 20 -RSB-, an Internet Explorer plugin, to make it work for web search. We are also interested in studying how to combine term feedback with relevance feedback or implicit feedback. We could, for example, allow the user to dynamically modify terms in a language model learned from feedback documents.", "keyphrases": ["term-base feedback", "inform retriev", "languag model", "queri expans process", "queri model", "interact adhoc search", "retriev perform", "probabl", "kl-diverg", "present term"]}
{"file_name": "H-9", "text": "Learn from Web Search Logs to Organize Search Results ABSTRACT Effective organization of search results is critical for improving the utility of any search engine. Clustering search results is an effective way to organize search results, which allows a user to navigate into relevant documents quickly. However, two deficiencies of this approach make it not always work well : -LRB- 1 -RRB- the clusters discovered do not necessarily correspond to the interesting aspects of a topic from the user 's perspective ; and -LRB- 2 -RRB- the cluster labels generated are not informative enough to allow a user to identify the right cluster. In this paper, we propose to address these two deficiencies by -LRB- 1 -RRB- learning `` interesting aspects '' of a topic from Web search logs and organizing search results accordingly ; and -LRB- 2 -RRB- generating more meaningful cluster labels using past query words entered by users. We evaluate our proposed method on a commercial search engine log data. Compared with the traditional methods of clustering search results, our method can give better result organization and more meaningful labels. 1. INTRODUCTION The utility of a search engine is affected by multiple factors. While the primary factor is the soundness of the underlying retrieval model and ranking function, how to organize and present search results is also a very important factor that can affect the utility of a search engine significantly. Compared with the vast amount of literature on retrieval models, however, there is relatively little research on how to improve the effectiveness of search result organization. The most common strategy of presenting search results is a simple ranked list. Intuitively, such a presentation strategy is reasonable for non-ambiguous, homogeneous search results ; in general, it would work well when the search results are good and a user can easily find many relevant documents in the top ranked results. In these examples, a clustering view of the search results would be much more useful to a user than a simple ranked list. Clustering is also useful when the search results are poor, in which case, a user would otherwise have to go through a long list sequentially to reach the very first relevant document. As a primary alternative strategy for presenting search results, clustering search results has been studied relatively extensively -LSB- 9, 15, 26, 27, 28 -RSB-. The general idea in virtually all the existing work is to perform clustering on a set of topranked search results to partition the results into natural clusters, which often correspond to different subtopics of the general query topic. A label will be generated to indicate what each cluster is about. A user can then view the labels to decide which cluster to look into. However, this clustering strategy has two deficiencies which make it not always work well : First, the clusters discovered in this way do not necessarily correspond to the interesting aspects of a topic from the user 's perspective. But the clusters discovered by the current methods may partition the results into `` local codes '' and `` international codes. '' Such clusters would not be very useful for users ; even the best cluster would still have a low precision. Second, the cluster labels generated are not informative enough to allow a user to identify the right cluster. There are two reasons for this problem : -LRB- 1 -RRB- The clusters are not corresponding to a user 's interests, so their labels would not be very meaningful or useful. For example, the ambiguous query `` jaguar '' may mean an animal or a car. A cluster may be labeled as `` panthera onca. '' In this paper, we propose a different strategy for partitioning search results, which addresses these two deficiencies through imposing a user-oriented partitioning of the search results. That is, we try to figure out what aspects of a search topic are likely interesting to a user and organize the results accordingly. Specifically, we propose to do the following : First, we will learn `` interesting aspects '' of similar topics from search logs and organize search results based on these `` interesting aspects ''. For example, if the current query has occurred many times in the search logs, we can look at what kinds of pages viewed by the users in the results and what kind of words are used together with such a query. In case when the query is ambiguous such as `` jaguar '' we can expect to see some clear clusters corresponding different senses of `` jaguar ''. Such aspects can be very useful for organizing future search results about `` car ''. Second, we will generate more meaningful cluster labels using past query words entered by users. Thus they can be better labels than those extracted from the ordinary contents of search results. To implement the ideas presented above, we rely on search engine logs and build a history collection containing the past queries and the associated clickthroughs. Given a new query, we find its related past queries from the history collection and learn aspects through applying the star clustering algorithm -LSB- 2 -RSB- to these past queries and clickthroughs. We can then organize the search results into these aspects using categorization techniques and label each aspect by the most representative past query in the query cluster. We evaluate our method for result organization using logs of a commercial search engine. We compare our method with the default search engine ranking and the traditional clustering of search results. The results show that our method is effective for improving search utility and the labels generated using past query words are more readable than those generated using traditional clustering approaches. The rest of the paper is organized as follows. We first review the related work in Section 2. In Section 3, we describe search engine log data and our procedure of building a history collection. In Section 4, we present our approach in details. We describe the data set in Section 5 and the experimental results are discussed in Section 6. Finally, we conclude our paper and discuss future work in Section 7. 2. RELATED WORK Our work is closely related to the study of clustering search results. In -LSB- 9, 15 -RSB-, the authors used Scatter/Gather algorithm to cluster the top documents returned from a traditional information retrieval system. Their results validate the cluster hypothesis -LSB- 20 -RSB- that relevant documents tend to form clusters. In these papers, the authors proposed to cluster the results of a real search engine based on the snippets or the contents of returned documents. Several clustering algorithms are compared and the Suffix Tree Clustering algorithm -LRB- STC -RRB- was shown to be the most effective one. They also showed that using snippets is as effective as using whole documents. However, an important challenge of document clustering is to generate meaningful labels for clusters. To overcome this difficulty, in -LSB- 28 -RSB-, supervised learning algorithms were studied to extract meaningful phrases from the search result snippets and these phrases were then used to group search results. In -LSB- 13 -RSB-, the authors proposed to use a monothetic clustering algorithm, in which a document is assigned to a cluster based on a single feature, to organize search results, and the single feature is used to label the corresponding cluster. Clustering search results has also attracted a lot of attention in industry and commercial Web services such as Vivisimo -LSB- 22 -RSB-. However, in all these works, the clusters are generated solely based on the search results. Thus the obtained clusters do not necessarily reflect users ' preferences and the generated labels may not be informative from a user 's viewpoint. Methods of organizing search results based on text categorization are studied in -LSB- 6, 8 -RSB-. In this work, a text classifier is trained using a Web directory and search results are then classified into the predefined categories. The authors designed and studied different category interfaces and they found that category interfaces are more effective than list interfaces. However predefined categories are often too general to reflect the finer granularity aspects of a query. Search logs have been exploited for several different purposes in the past. For example, clustering search queries to find those Frequent Asked Questions -LRB- FAQ -RRB- is studied in -LSB- 24, 4 -RSB-. In our work, we explore past query history in order to better organize the search results for future queries. We use the star clustering algorithm -LSB- 2 -RSB-, which is a graph partition based approach, to learn interesting aspects from search logs given a new query. 7. CONCLUSIONS AND FUTURE WORK In this paper, we studied the problem of organizing search results in a user-oriented manner. To attain this goal, we rely on search engine logs to learn interesting aspects from users ' perspective. Given a query, we retrieve its related queries from past query history, learn the aspects by clustering the past queries and the associated clickthrough information, and categorize the search results into the aspects learned. We compared our log-based method with the traditional cluster-based method and the baseline of search engine ranking. The experiments show that our log-based method can consistently outperform cluster-based method and improve over the ranking baseline, especially when the queries are difficult or the search results are diverse. Furthermore, our log-based method can generate more meaningful aspect labels than the cluster labels generated based on search results when we cluster search results. There are several interesting directions for further extending our work : First, although our experiment results have clearly shown promise of the idea of learning from search logs to organize search results, the methods we have experimented with are relatively simple. It would be interesting to explore other potentially more effective methods. In particular, we hope to develop probabilistic models for learning aspects and organizing results simultaneously. Second, with the proposed way of organizing search results, we can expect to obtain informative feedback information from a user -LRB- e.g., the aspect chosen by a user to view -RRB-. It would thus be interesting to study how to further improve the organization of the results based on such feedback information. Finally, we can combine a general search log with any personal search log to customize and optimize the organization of search results for each individual user.", "keyphrases": ["retriev model", "rank function", "ambigu", "cluster view", "meaning cluster label", "histori collect", "past queri", "clickthrough", "star cluster algorithm", "suffix tree cluster algorithm", "search result snippet", "monothet cluster algorithm", "pseudo-document", "pairwis similar graph", "similar threshold paramet", "centroid-base method", "cosin similar", "centroid prototyp", "reciproc rank", "log-base method", "mean averag precis"]}
{"file_name": "H-5", "text": "Utility-based Information Distillation Over Temporally Sequenced Documents ABSTRACT This paper examines a new approach to information distillation over temporally ordered documents, and proposes a novel evaluation scheme for such a framework. It combines the strengths of and extends beyond conventional adaptive filtering, novelty detection and non-redundant passage ranking with respect to long-lasting information needs -LRB- ` tasks ' with multiple queries -RRB-. Our approach supports fine-grained user feedback via highlighting of arbitrary spans of text, and leverages such information for utility optimization in adaptive settings. For our experiments, we defined hypothetical tasks based on news events in the TDT4 corpus, with multiple queries per task. Answer keys -LRB- nuggets -RRB- were generated for each query and a semiautomatic procedure was used for acquiring rules that allow automatically matching nuggets against system responses. We also propose an extension of the NDCG metric for assessing the utility of ranked passages as a combination of relevance and novelty. Our results show encouraging utility enhancements using the new approach, compared to the baseline systems without incremental learning or the novelty detection components. 1. INTRODUCTION Tracking new and relevant information from temporal data streams for users with long-lasting needs has been a challenging research topic in information retrieval. Adaptive filtering -LRB- AF -RRB- is one such task of online prediction of the relevance of each new document with respect to pre-defined topics. Based on the initial query and a few positive examples -LRB- if available -RRB-, an AF system maintains a profile for each such topic of interest, and constantly updates it based on feedback from the user. Despite substantial achievements in recent adaptive filtering research, significant problems remain unsolved regarding how to leverage user feedback effectively and efficiently. Specifically, the following issues may seriously limit the true utility of AF systems in real-world applications : adaptive filtering setup -- he or she reacts to the system only when the system makes a ` yes ' decision on a document, by confirming or rejecting that decision. A more ` active ' alternative would be to allow the user to issue multiple queries for a topic, review a ranked list of candidate documents -LRB- or passages -RRB- per query, and provide feedback on the ranked list, thus refining their information need and requesting updated ranked lists. The latter form of user interaction has been highly effective in standard retrieval for ad hoc queries. How to deploy such a strategy for long-lasting information needs in AF settings is an open question for research. 2. However, a real user may be willing to provide more informative, fine-grained feedback via highlighting some pieces of text in a retrieved document as relevant, instead of labeling the entire document as relevant. Effectively leveraging such fine-grained feedback could substantially enhance the quality of an AF system. For this, we need to enable supervised learning from labeled pieces of text of arbitrary span instead of just allowing labeled documents. 3. System-selected documents are often highly redundant. A conventional AF system would select all these redundant news stories for user feedback, wasting the user 's time while offering little gain. Clearly, techniques for novelty detection can help in principle -LSB- 25, 2, 22 -RSB- for improving the utility of the AF systems. However, the effectiveness of such techniques at passage level to detect novelty with respect to user 's -LRB- fine-grained -RRB- feedback and to detect redundancy in ranked lists remains to be evaluated using a measure of utility that mimics the needs of a real user. We call the new process utility-based information distillation. Note that conventional benchmark corpora for AF evaluations, which have relevance judgments at the document level and do not define tasks with multiple queries, are insufficient for evaluating the new approach. Therefore, we extended a benchmark corpus -- the TDT4 collection of news stories and TV broadcasts -- with task definitions, multiple queries per task, and answer keys per query. We have conducted our experiments on this extended TDT4 corpus and have made the additionally generated data publicly available for future comparative evaluations 1. To automatically evaluate the system-returned arbitrary spans of text using our answer keys, we further developed an evaluation scheme with semi-automatic procedure for acquiring rules that can match nuggets against system responses. Moreover, we propose an extension of NDCG -LRB- Normalized Discounted Cumulated Gain -RRB- -LSB- 9 -RSB- for assessing the utility of ranked passages as a function of both relevance and novelty. Section 2 outlines the information distillation process with a concrete example. Section 3 describes the technical cores of our system called CAF \u00b4 E -- CMU Adaptive Filtering Engine. Section 4 discusses issues with respect to evaluation methodology and proposes a new scheme. Section 5 describes the extended TDT4 corpus. Section 6 presents our experiments and results. Section 7 concludes the study and gives future perspectives. 7. CONCLUDING REMARKS This paper presents the first investigation on utility-based information distillation with a system that learns the longlasting information needs from fine-grained user feedback over a sequence of ranked passages. Our system, called CAF \u00b4 E, combines adaptive filtering, novelty detection and antiredundant passage ranking in a unified framework for utility optimization. We developed a new scheme for automated evaluation and feedback based on a semi-automatic procedure for acquiring rules that allow automatically matching nuggets against system responses. We also proposed an extension of the NDCG metric for assessing the utility of ranked passages as a weighted combination of relevance and novelty. Our experiments on the newly annotated TDT4 benchmark corpus show encouraging utility enhancement over Indri, and also over our own system with incremental learning and novelty detection turned off.", "keyphrases": ["util-base inform distil", "tempor order document", "passag rank", "adapt filter", "ad-hoc retriev", "novelti detect", "new evalu methodolog", "answer kei", "nugget-match rule", "unifi framework", "ndcg metric"]}
{"file_name": "C-8", "text": "Operation Context and Context-based Operational Transformation ABSTRACT Operational Transformation -LRB- OT -RRB- is a technique for consistency maintenance and group undo, and is being applied to an increasing number of collaborative applications. The theoretical foundation for OT is crucial in determining its capability to solve existing and new problems, as well as the quality of those solutions. The theory of causality has been the foundation of all prior OT systems, but it is inadequate to capture essential correctness requirements. Past research had invented various patches to work around this problem, resulting in increasingly intricate and complicated OT algorithms. After having designed, implemented, and experimented with a series of OT algorithms, we reflected on what had been learned and set out to develop a new theoretical framework for better understanding and resolving OT problems, reducing its complexity, and supporting its continual evolution. In this paper, we report the main results of this effort : the theory of operation context and the COT -LRB- Context-based OT -RRB- algorithm. The COT algorithm is capable of supporting both do and undo of any operations at anytime, without requiring transformation functions to preserve Reversibility Property, Convergence Property 2, Inverse Properties 2 and 3. The COT algorithm is not only simpler and more efficient than prior OT control algorithms, but also simplifies the design of transformation functions. We have implemented the COT algorithm in a generic collaboration engine and used it for supporting a range of novel collaborative applications. 1. INTRODUCTION Operational Transformation -LRB- OT -RRB- was originally invented for consistency maintenance in plain-text group editors -LSB- 4 -RSB-. To effectively and efficiently support existing and new applications, we must continue to improve the capability and quality of OT in solving both old and new problems. The soundness of the theoretical foundation for OT is crucial in this process. However, the theory of causality is inadequate to capture essential OT conditions for correct transformation. The limitation of the causality theory had caused correctness problems from the very beginning of OT. The dOPT algorithm was the first OT algorithm and was based solely on the concurrency relationships among operations -LSB- 4 -RSB- : a pair of operations are transformable as long as they are concurrent. However, later research discovered that the concurrency condition alone is not sufficient to ensure the correctness of transformation. Another condition is that the two concurrent operations must be defined on the same document state. This puzzle was solved in various ways, but the theory of causality as well as its limitation were inherited by all follow-up OT algorithms. The causality theory limitation became even more prominent when OT was applied to solve the undo problem in group editors. The concept of causality is unsuitable to capture the relationships between an inverse operation -LRB- as an interpretation of a meta-level undo command -RRB- and other normal editing operations. In fact, the causality relation is not defined for inverse operations -LRB- see Section 2 -RRB-. Various patches were invented to work around this problem, resulting in more intricate complicated OT algorithms -LSB- 18, 21 -RSB-. supporting its continual evolution. In this paper, we report the main results of this effort : the theory of operation context and the COT -LRB- Context-based OT -RRB- algorithm. First, we define causal-dependency / - independency and briefly describe their limitations in Section 2. Then, we present the key elements of the operation context theory, including the definition of operation context, context-dependency / - independency relations, context-based conditions, and context vectors in Section 3. In Section 4, we present the basic COT algorithm for supporting consistency maintenance -LRB- do -RRB- and group undo under the assumption that underlying transformation functions are able to preserve some important transformation properties. Then, these transformation properties and their pre-conditions are discussed in Section 5. The COT solutions to these transformation properties are presented in Section 6. Comparison of the COT work to prior OT work, OT correctness issues, and future work are discussed in Section 7. Finally, major contributions of this work are summarized in Section 8. 8. CONCLUSIONS We have contributed the theory of operation context and the COT -LRB- Context-based OT -RRB- algorithm. The theory of operation context is capable of capturing essential relationships and conditions for all types of operation in an OT system ; it provides a new foundation for better understanding and resolving OT problems. The COT algorithm provides uniformed solutions to both consistency maintenance and undo problems ; it is simpler and more efficient than prior OT control algorithms with similar capabilities ; and it significantly simplifies the design of transformation functions. The COT algorithm has been implemented in a generic collaboration engine and used for supporting a range of novel collaborative applications -LSB- 24 -RSB-. Real-world applications provide exciting opportunities and challenges to future OT research. The theory of operation context and the COT algorithm shall serve as new foundations for addressing the technical challenges in existing and emerging OT applications.", "keyphrases": ["oper transform", "cot", "context-base ot", "causal-depend", "concurr condit", "concurr relat", "invers oper", "document state", "origin oper", "transform oper", "invers cluster", "vector represent of oper context", "histori buffer", "exclus transform"]}
{"file_name": "J-4", "text": "Revenue Analysis of a Family of Ranking Rules for Keyword Auctions ABSTRACT Keyword auctions lie at the core of the business models of today 's leading search engines. Advertisers bid for placement alongside search results, and are charged for clicks on their ads. Advertisers are typically ranked according to a score that takes into account their bids and potential clickthrough rates. We consider a family of ranking rules that contains those typically used to model Yahoo! and Google 's auction designs as special cases. We find that in general neither of these is necessarily revenue-optimal in equilibrium, and that the choice of ranking rule can be guided by considering the correlation between bidders ' values and click-through rates. We propose a simple approach to determine a revenue-optimal ranking rule within our family, taking into account effects on advertiser satisfaction and user experience. We illustrate the approach using Monte-Carlo simulations based on distributions fitted to Yahoo! bid and click-through rate data for a high-volume keyword. 1. INTRODUCTION Major search engines like Google, Yahoo!, and MSN sell advertisements by auctioning off space on keyword search results pages. For example, when a user searches the web for * This work was done while the author was at Yahoo! Research. `` iPod '', the highest paying advertisers -LRB- for example, Apple or Best Buy -RRB- for that keyword may appear in a separate `` sponsored '' section of the page above or to the right of the algorithmic results. Generally, advertisements that appear in a higher position on the page garner more attention and more clicks from users. Thus, all else being equal, advertisers prefer higher positions to lower positions. Advertisers bid for placement on the page in an auctionstyle format where the larger their bid the more likely their listing will appear above other ads on the page. By convention, sponsored search advertisers generally bid and pay per click, meaning that they pay only when a user clicks on their ad, and do not pay if their ad is displayed but not clicked. Overture Services, formerly GoTo.com and now owned by Yahoo! Inc., is credited with pioneering sponsored search advertising. Overture 's success prompted a number of companies to adopt similar business models, most prominently Google, the leading web search engine today. Microsoft 's MSN, previously an affiliate of Overture, now operates its own keyword auction marketplace. The search engine evaluates the advertisers ' bids and allocates the positions on the page accordingly. Notice that, although bids are expressed as payments per click, the search engine can not directly allocate clicks, but rather allocates impressions, or placements on the screen. Clicks relate only stochastically to impressions. Until recently, Yahoo! ranked bidders in decreasing order of advertisers ' stated values per click, while Google ranks in decreasing order of advertisers ' stated values per impression. We refer to these rules as `` rank-by-bid '' and `` rank-by-revenue '', respectively. ' We analyze a family of ranking rules that contains the Yahoo! and Google models as special cases. We consider rank ` These are industry terms. We will see, however, that rankby-revenue is not necessarily revenue-optimal. ing rules where bidders are ranked in decreasing order of score eqb, where e denotes an advertiser 's click-through rate -LRB- normalized for position -RRB- and b his bid. Notice that q = 0 corresponds to Yahoo! 's rank-by-bid rule and q = 1 corresponds to Google 's rank-by-revenue rule. Our premise is that bidders are playing a symmetric equilibrium, as defined by Edelman, Ostrovsky, and Schwarz -LSB- 3 -RSB- and Varian -LSB- 11 -RSB-. We show through simulation that although q = 1 yields the efficient allocation, settings of q considerably less than 1 can yield superior revenue in equilibrium under certain conditions. The key parameter is the correlation between advertiser value and click-through rate. If this correlation is strongly positive, then smaller q are revenue-optimal. Our simulations are based on distributions fitted to data from Yahoo! keyword auctions. We propose that search engines set thresholds of acceptable loss in advertiser satisfaction and user experience, then choose the revenue-optimal q consistent with these constraints. In Section 2 we give a formal model of keyword auctions, and establish its equilibrium properties in Section 3. In Section 4 we note that giving agents bidding credits can have the same effect as tuning the ranking rule explicitly. In Section 5 we give a general formulation of the optimal keyword auction design problem as an optimization problem, in a manner analogous to the single-item auction setting. We then provide some theoretical insight into how tuning q can improve revenue, and why the correlation between bidders ' values and click-through rates is relevant. In Section 6 we consider the effect of q on advertiser satisfaction and user experience. In Section 7 we describe our simulations and interpret their results. Related work. Both papers independently define an appealing refinement of Nash equilibrium for keyword auctions and analyze its equilibrium properties. They called this refinement `` locally envy-free equilibrium '' and `` symmetric equilibrium '', respectively. Varian also provides some empirical analysis. The general model of keyword auctions used here, where bidders are ranked according to a weight times their bid, was introduced by Aggarwal, Goel, and Motwani -LSB- 1 -RSB-. That paper also makes a connection between the revenue of keyword auctions in incomplete information settings with the revenue in symmetric equilibrium. Iyengar and Kumar -LSB- 5 -RSB- study the optimal keyword auction design problem in a setting of incomplete information, and also make the connection to symmetric equilibrium. We make use of this connection when formulating the optimal auction design problem in our setting. They were the first to realize that the correlation between bidder values and click-through rates should be a key parameter affecting the revenue performance of various ranking mechanisms. For simplicity, they assume bidders bid their true values, so their model is very different from ours and consequently so are their findings. According to their simulations, rank-by-revenue always -LRB- weakly -RRB- dominates rank-by-bid in terms of revenue, whereas our results suggest that rank-by-bid may do much better for negative correlations. Lahaie -LSB- 8 -RSB- gives an example that suggests rank-by-bid should yield more revenue when values and click-through rates are positively correlated, whereas rank-by-revenue should do better when the correlation is negative. In this work we make a deeper study of this conjecture. 8. CONCLUSIONS In this work we looked into the revenue properties of a family of ranking rules that contains the Yahoo! and Google models as special cases. In practice, it should be very simple to move between rules within the family : this simply involves changing the exponent q applied to advertiser effects. We also showed that, in principle, the same effect could be obtained by using bidding credits. Despite the simplicity of the rule change, simulations revealed that properly tuning q can significantly improve revenue. In the simulations, the revenue improvements were greater than what could be obtained using reserve prices. On the other hand, we showed that advertiser satisfaction and user experience could suffer if q is made too small. It would be interesting to do this analysis for a variety of keywords, to see if the optimal setting of q is always so sensitive to the level of correlation. If it is, then simply using rank-bybid where there is positive correlation, and rank-by-revenue where there is negative correlation, could be fine to a first approximation and already improve revenue. It would also be interesting to compare the effects of tuning q versus reserve pricing for keywords that have few bidders. In principle the minimum revenue in Nash equilibrium can be found by linear programming. However, many allocations can arise in Nash equilibrium, and a linear program needs to be solved for each of these. There is as yet no efficient way to enumerate all possible Nash allocations, so finding the minimum revenue is currently infeasible. If this problem could be solved, we could run simulations for Nash equilibrium instead of symmetric equilibrium, to see if our insights are robust to the choice of solution concept. Larger classes of ranking rules could be relevant. For instance, it is possible to introduce discounts ds and rank according to wsbs \u2212 ds ; the equilibrium analysis generalizes to this case as well. With this larger class the virtual score can equal the score, e.g. in the case of a uniform marginal distribution over values. Figure 4 : Revenue, efficiency, and relevance for different reserve scores r, with Spearman correlation of 0.4 and q = 1.", "keyphrases": ["revenu", "keyword auction", "revenu-optim rank", "rank rule", "search engin", "advertis", "sponsor search", "rank-by-bid", "rank-by-revenu", "profit", "advertis revenu", "price search keyword", "optim auction design problem"]}
{"file_name": "C-31", "text": "Apocrita : A Distributed Peer-to-Peer File Sharing System for Intranets ABSTRACT Many organizations are required to author documents for various purposes, and such documents may need to be accessible by all member of the organization. This access may be needed for editing or simply viewing a document. In some cases these documents are shared between authors, via email, to be edited. This can easily cause incorrect version to be sent or conflicts created between multiple users trying to make amendments to a document. There may even be multiple different documents in the process of being edited. The user may be required to search for a particular document, which some search tools such as Google Desktop may be a solution for local documents but will not find a document on another user 's machine. Another problem arises when a document is made available on a user 's machine and that user is offline, in which case the document is no longer accessible. In this paper we present Apocrita, a revolutionary distributed P2P file sharing system for Intranets. 1. INTRODUCTION The Peer-to-Peer -LRB- P2P -RRB- computing paradigm is becoming a completely new form of mutual resource sharing over the Internet. With the increasingly common place broadband Internet access, P2P technology has finally become a viable way to share documents and media files. There are already programs on the market that enable P2P file sharing. These programs enable millions of users to share files among themselves. The downloaded files still require a lot of manual management by the user. The user still needs to put the files in the proper directory, manage files with multiple versions, delete the files when they are no longer wanted. We strive to make the process of sharing documents within an Intranet easier. Many organizations are required to author documents for various purposes, and such documents may need to be accessible by all members of the organization. This access may be needed for editing or simply viewing a document. In some cases these documents are sent between authors, via email, to be edited. This can easily cause incorrect version to be sent or conflicts created between multiple users trying to make amendments to a document. There may even be multiple different documents in the process of being edited. The user may be required to search for a particular document, which some search tools such as Google Desktop may be a solution for local documents but will not find a document on another user 's machine. Furthermore, some organizations do not have a file sharing server or the necessary network infrastructure to enable one. In this paper we present Apocrita, which is a cost-effective distributed P2P file sharing system for such organizations. In section 2, we present Apocrita. The distributed indexing mechanism and protocol are presented in Section 3. Section 4 presents the peer-topeer distribution model. A proof of concept prototype is presented in Section 5, and performance evaluations are discussed in Section 6. Related work is presented is Section 7, and finally conclusions and future work are discussed in Section 8. 7. RELATED WORK Several decentralized P2P systems -LSB- 1, 2, 3 -RSB- exist today that Apocrita features some of their functionality. However, Apocrita also has unique novel searching and indexing features that make this system unique. For example, Majestic-12 -LSB- 4 -RSB- is a distributed search and indexing project designed for searching the Internet. Each user would install a client, which is responsible for indexing a portion of the web. A central area for querying the index is available on the Majestic-12 web page. The index itself is not distributed, only the act of indexing is distributed. The distributed indexing aspect of this project most closely relates Apocrita goals. YaCy -LSB- 6 -RSB- is a peer-to-peer web search application. YaCy is designed to maintain a distributed index of the Internet. It used a distributed hash table -LRB- DHT -RRB- to maintain the index. The local node is used to query but all results that are returned are accessible on the Internet. YaCy used many peers and DHT to maintain a distributed index. Apocrita will also use a distributed index in future implementations and may benefit from using an implementation of a DHT. YaCy however, is designed as a web search engine and, as such solves a much different problem than Apocrita. 8. CONCLUSIONS AND FUTURE WORK We presented Apocrita, a distributed P2P searching and indexing system intended for network users on an Intranet. It can help organizations with no network file server or necessary network infrastructure to share documents. It eliminates the need for documents to be manually shared among users while being edited and reduce the possibility of conflicting versions being distributed. Despite these shortcomings, the experience gained from the design and implementation of Apocrita has given us more insight into building challenging distributed systems.", "keyphrases": ["peer-to-peer", "file share system", "intranet", "author", "document", "apocrita", "jxta", "distribut index", "peer-to-peer distribut model", "idl queri", "index file", "incom file", "p2p search"]}
{"file_name": "C-20", "text": "Live Data Center Migration across WANs : A Robust Cooperative Context Aware Approach ABSTRACT A significant concern for Internet-based service providers is the continued operation and availability of services in the face of outages, whether planned or unplanned. In this paper we advocate a cooperative, context-aware approach to data center migration across WANs to deal with outages in a non-disruptive manner. We specifically seek to achieve high availability of data center services in the face of both planned and unanticipated outages of data center facilities. We make use of server virtualization technologies to enable the replication and migration of server functions. We propose new network functions to enable server migration and replication across wide area networks -LRB- e.g., the Internet -RRB-, and finally show the utility of intelligent and dynamic storage replication technology to ensure applications have access to data in the face of outages with very tight recovery point objectives. 1. INTRODUCTION A significant concern for Internet-based service providers is the continued operation and availability of services in the face of outages, whether planned or unplanned. A relatively minor outage can disrupt and inconvenience a large number of users. Today these services are almost exclusively hosted in data centers. Recent advances in server virtualization technologies -LSB- 8, 14, 22 -RSB- allow for the live migration of services within a local area network -LRB- LAN -RRB- environment. In the LAN environment, these technologies have proven to be a very effective tool to enable data center management in a non-disruptive fashion. Not only can it support planned maintenance events -LSB- 8 -RSB-, but it can also be used in a more dynamic fashion to automatically balance load between the physical servers in a data center -LSB- 22 -RSB-. When using these technologies in a LAN environment, services execute in a virtual server, and the migration services provided by the underlying virtualization framework allows for a virtual server to be migrated from one physical server to another, without any significant downtime for the service or application. In particular, since the virtual server retains the same network address as before, any ongoing network level interactions are not disrupted. Similarly, in a LAN environment, storage requirements are normally met via either network attached storage -LRB- NAS -RRB- or via a storage area network -LRB- SAN -RRB- which is still reachable from the new physical server location to allow for continued storage access. Unfortunately in a wide area environment -LRB- WAN -RRB-, live server migration is not as easily achievable for two reasons : First, live migration requires the virtual server to maintain the same network address so that from a network connectivity viewpoint the migrated server is indistinguishable from the original. Second, while fairly sophisticated remote replication mechanisms have been developed in the context of disaster recovery -LSB- 20, 7, 11 -RSB-, these mechanisms are ill suited to live data center migration, because in general the available technologies are unaware of application/service level semantics. In this paper we outline a design for live service migration across WANs. Our design makes use of existing server virtualization technologies and propose network and storage mechanisms to facilitate migration across a WAN. The essence of our approach is cooperative, context aware migration, where a migration management system orchestrates the data center migration across all three subsystems involved, namely the server platforms, the wide area network and the disk storage system. While conceptually similar in nature to the LAN based work described above, using migration technologies across a wide area network presents unique challenges and has to our knowledge not been achieved. Our main contribution is the design of a framework that will allow the migration across a WAN of all subsystems involved with enabling data center services. We describe new mechanisms as well as extensions to existing technologies to enable this and outline the cooperative, context aware functionality needed across the different subsystems to enable this. 4. RELATED WORK Prior work on this topic falls into several categories : virtual machine migration, storage replication and network support. At the core of our technique is the ability of encapsulate applications within virtual machines that can be migrated without application downtimes -LSB- 15 -RSB-. As indicated earlier, these techniques assume that migration is being done on a LAN. VM migration has also been studied in the Shirako system -LSB- 10 -RSB- and for grid environments -LSB- 17, 19 -RSB-. Current virtual machine software support a suspend and resume feature that can be used to support WAN migration, but with downtimes -LSB- 18, 12 -RSB-. Recently live WAN migration using IP tunnels was demonstrated in -LSB- 21 -RSB-, where an IP tunnel is set up from the source to destination server to transparently forward packets to and from the application ; we advocate an alternate approach that assumes edge router support. An excellent description of these and others, as well as a detailed taxonomy of the different approaches for replication can be found in -LSB- 11 -RSB-. The Ursa Minor system argues that no single fault model is optimal for all applications and proposed supporting data-type specific selections of fault models and encoding schemes for replication -LSB- 1 -RSB-. In the context of network support, our work is related to the RouterFarm approach -LSB- 2 -RSB-, which makes use of orchestrated network changes to realize near hitless maintenance on provider edge routers. In addition to being in a different application area, our approach differs from the RouterFarm work in two regards. Second, due to the stringent timing requirements of live migration, we expect that our approach would require new router functionality -LRB- as opposed to being realizable via the existing configuration interfaces -RRB-. In a similar spirit to ROC, we advocate using mechanisms from live VM migration to storage replication to support planned and unplanned outages in data centers -LRB- rather than full replication to mask such failures -RRB-. 5. CONCLUSION A significant concern for Internet-based service providers is the continued operation and availability of services in the face of outages, whether planned or unplanned. In this paper we advocated a cooperative, context-aware approach to data center migration across WANs to deal with outages in a non-disruptive manner. We sought to achieve high availability of data center services in the face of both planned and incidental outages of data center facilities. We advocated using server virtualization technologies to enable the replication and migration of server functions. We proposed new network functions to enable server migration and replication across wide area networks -LRB- such as the Internet or a geographically distributed virtual private network -RRB-, and finally showed the utility of intelligent and dynamic storage replication technology to ensure applications have access to data in the face of outages with very tight recovery point objectives.", "keyphrases": ["internet-base servic", "data center migrat", "wan", "lan", "virtual server", "storag replic", "synchron replic", "asynchron replic", "network support", "storag", "voic-over-ip", "voip", "databas"]}
{"file_name": "J-20", "text": "Clearing Algorithms for Barter Exchange Markets : Enabling Nationwide Kidney Exchanges ABSTRACT In barter-exchange markets, agents seek to swap their items with one another, in order to improve their own utilities. These swaps consist of cycles of agents, with each agent receiving the item of the next agent in the cycle. We focus mainly on the upcoming national kidney-exchange market, where patients with kidney disease can obtain compatible donors by swapping their own willing but incompatible donors. With over 70,000 patients already waiting for a cadaver kidney in the US, this market is seen as the only ethical way to significantly reduce the 4,000 deaths per year attributed to kidney disease. The clearing problem involves finding a social welfare maximizing exchange when the maximum length of a cycle is fixed. Long cycles are forbidden, since, for incentive reasons, all transplants in a cycle must be performed simultaneously. Also, in barter-exchanges generally, more agents are affected if one drops out of a longer cycle. We prove that the clearing problem with this cycle-length constraint is NP-hard. Solving it exactly is one of the main challenges in establishing a national kidney exchange. We present the first algorithm capable of clearing these markets on a nationwide scale. The key is incremental problem formulation. We adapt two paradigms for the task : constraint generation and column generation. For each, we develop techniques that dramatically improve both runtime and memory usage. We conclude that column generation scales drastically better than constraint generation. Our algorithm also supports several generalizations, as demanded by real-world kidney exchanges. Our algorithm replaced CPLEX as the clearing algorithm of the Alliance for Paired Donation, one of the leading kidney exchanges. The match runs are conducted every two weeks and transplants based on our optimizations have already been conducted. 1. INTRODUCTION The role of kidneys is to filter waste from blood. Kidney failure results in accumulation of this waste, which leads to death in months. One treatment option is dialysis, in which the patient goes to a hospital to have his/her blood filtered by an external machine. Several visits are required per week, and each takes several hours. The quality of life on dialysis can be extremely low, and in fact many patients opt to withdraw from dialysis, leading to a natural death. Only 12 % of dialysis patients survive 10 years -LSB- 23 -RSB-. Instead, the preferred treatment is a kidney transplant. Kidney transplants are by far the most common transplant. Unfortunately, the demand for kidneys far outstrips supply. In the United States in 2005, 4,052 people died waiting for a life-saving kidney transplant. During this time, almost 30,000 people were added to the national waiting list, while only 9,913 people left the list after receiving a deceaseddonor kidney. For many patients with kidney disease, the best option is to find a living donor, that is, a healthy person willing to donate one of his/her two kidneys. In 2005, there were 6,563 live donations in the US. and his intended recipient are blood-type or tissue-type incompatible. In the past, the incompatible donor was sent home, leaving the patient to wait for a deceased-donor kidney. However, there are now a few regional kidney exchanges in the United States, in which patients can swap their incompatible donors with each other, in order to each obtain a compatible donor. These markets are examples of barter exchanges. In a barter-exchange market, agents -LRB- patients -RRB- seek to swap their items -LRB- incompatible donors -RRB- with each other. These swaps consist of cycles of agents, with each agent receiving the item of the next agent in the cycle. Barter exchanges are ubiquitous : examples include Peerflix -LRB- DVDs -RRB- -LSB- 11 -RSB-, Read It Swap It -LRB- books -RRB- -LSB- 12 -RSB-, and Intervac -LRB- holiday houses -RRB- -LSB- 9 -RSB-. For many years, there has even been a large shoe exchange in the United States -LSB- 10 -RSB-. People with different-sized feet use this to avoid having to buy two pairs of shoes. Leg amputees have a separate exchange to share the cost of buying a single pair of shoes. We can encode a barter exchange market as a directed graph G = -LRB- V, E -RRB- in the following way. Construct one vertex for each agent. Add a weighted edge e from one agent vi to another vj, if vi wants the item of vj. The weight we of e represents the utility to vi of obtaining vj 's item. A cycle c in this graph represents a possible swap, with each agent in the cycle obtaining the item of the next agent. The weight wc of a cycle c is the sum of its edge weights. An exchange is a collection of disjoint cycles. The weight of an exchange is the sum of its cycle weights. A social welfare maximizing exchange is one with maximum weight. Figure 1 illustrates an example market with 5 agents, -LCB- v1, v2,..., v5 -RCB-, in which all edges have weight 1. The market has 4 cycles, c1 = -LRB- v1, v2 -RRB-, c2 = -LRB- v2, v3 -RRB-, c3 = -LRB- v3, v4 -RRB- and c4 = -LRB- v1, v2, v3, v4, v5 -RRB-, and two -LRB- inclusion -RRB- maximal exchanges, namely M1 = -LCB- c4 -RCB- and M2 = -LCB- c1, c3 -RCB-. Exchange M1 has both maximum weight and maximum cardinality -LRB- i.e., it includes the most edges/vertices -RRB-. Figure 1 : Example barter exchange market. The clearing problem is to find a maximum-weight exchange consisting of cycles with length at most some small constant L. This cycle-length constraint arises naturally for several reasons. For example, in a kidney exchange, all operations in a cycle have to be performed simultaneously ; otherwise a donor might back out after his incompatible partner has received a kidney. Due to such resource constraints, the upcoming national kidney exchange market will likely allow only cycles of length 2 and 3. Another motivation for short cycles is that if the cycle fails to exchange, fewer agents are affected. For example, last-minute testing in a kidney exchange often reveals new incompatibilities that were not detected in the initial testing -LRB- based on which the compatibility graph was constructed -RRB-. In Section 3, we show that -LRB- the decision version of -RRB- the clearing problem is NP-complete for L > 3. One approach then might be to look for a good heuristic or approximation algorithm. However, for two reasons, we aim for an exact algorithm based on an integer-linear program -LRB- ILP -RRB- formulation, which we solve using specialized tree search. 9 First, any loss of optimality could lead to unnecessary patient deaths. 9 Second, an attractive feature of using an ILP formula tion is that it allows one to easily model a number of variations on the objective, and to add additional constraints to the problem. Or, if for various -LRB- e.g., ethical -RRB- reasons one requires a maximum cardinality exchange, one can at least in a second pass find the solution -LRB- out of all maximum cardinality solutions -RRB- that has the fewest 3-cycles. Other variations one can solve for include finding various forms of `` fault tolerant '' -LRB- non-disjoint -RRB- collections of cycles in the event that certain pairs that were thought to be compatible turn out to be incompatible after all. In this paper, we present the first algorithm capable of clearing these markets on a nationwide scale. Straight-forward ILP encodings are too large to even construct on current hardware -- not to talk about solving them. The key then is incremental problem formulation. We adapt two paradigms for the task : constraint generation and column generation. For each, we develop a host of -LRB- mainly problemspecific -RRB- techniques that dramatically improve both runtime and memory usage. 1.1 Prior Work Several recent papers have used simulations and marketclearing algorithms to explore the impact of a national kidney exchange -LSB- 13, 20, 6, 14, 15, 17 -RSB-. For example, using Edmond 's maximum-matching algorithm -LSB- 4 -RSB-, -LSB- 20 -RSB- shows that a national pairwise-exchange market -LRB- using length-2 cycles only -RRB- would result in more transplants, reduced waiting time, and savings of $ 750 million in heath care costs over 5 years. Those results are conservative in two ways. Firstly, the simulated market contained only 4,000 initial patients, with 250 patients added every 3 months. It has been reported to us that the market could be almost double this size. Secondly, the exchanges were restricted to length-2 cycles -LRB- because that is all that can be modeled as maximum matching, and solved using Edmonds 's algorithm -RRB-. Allowing length-3 cycles leads to additional significant gains. This has been demonstrated on kidney exchange markets with 100 patients by using CPLEX to solve an integer-program encoding of the clearing problem -LSB- 15 -RSB-. In this paper, we present an alternative algorithm for this integer program that can clear markets with over 10,000 patients -LRB- and that same number of willing donors -RRB-. Allowing cycles of length more than 3 often leads to no improvement in the size of the exchange -LSB- 15 -RSB-. -LRB- Furthermore, in a simplified theoretical model, any kidney exchange can be converted into one with cycles of length at most 4 -LSB- 15 -RSB-. -RRB- Whilst this does not hold for general barter exchanges, or even for all kidney exchange markets, in Section 5.2.3 we make use of the observation that short cycles suffice to dramatically increase the speed of our algorithm. At a high-level, the clearing problem for barter exchanges is similar to the clearing problem -LRB- aka winner determination problem -RRB- in combinatorial auctions. In both settings, the idea is to gather all the pertinent information about the agents into a central clearing point and to run a centralized clearing algorithm to determine the allocation. Both problems are NP-hard. Both are best solved using tree search techniques. Since 1999, significant work has been done in computer science and operations research on faster optimal tree search algorithms for clearing combinatorial auctions. However, the kidney exchange clearing problem -LRB- with a limit of 3 or more on cycle size -RRB- is different from the combinatorial auction clearing problem in significant ways. The most important difference is that the natural formulations of the combinatorial auction problem tend to easily fit in memory, so time is the bottleneck in practice. In contrast, the natural formulations of the kidney exchange problem -LRB- with L = 3 -RRB- take at least cubic space in the number of patients to even model, and therefore memory becomes a bottleneck much before time does when using standard tree search, such as branch-andcut in CPLEX, to tackle the problem. Therefore, the approaches that have been developed for combinatorial auctions can not handle the kidney exchange problem. 1.2 Paper Outline The rest of the paper is organized as follows. Section 2 discusses the process by which we generate realistic kidney exchange market data, in order to benchmark the clearing algorithms. Section 3 contains a proof that the market clearing decision problem is NP-complete. Sections 4 and 5 each contain an ILP formulation of the clearing problem. We also detail in those sections our techniques used to solve those programs on large instances. Section 6 presents experiments on the various techniques. Section 7 discusses recent fielding of our algorithm. Finally, we present our conclusions in Section 8, and suggest future research directions. 7. FIELDING THE TECHNOLOGY Our algorithm and implementation replaced CPLEX as the clearing algorithm of the Alliance for Paired Donation, one of the leading kidney exchanges, in December 2006. We conduct a match run every two weeks, and the first transplants based on our solutions have already been conducted. While there are -LRB- for political/inter-personal reasons -RRB- at least four kidney exchanges in the US currently, everyone understands that a unified unfragmented national exchange would save more lives. We are in discussions with additional kidney exchanges that are interested in adopting our technology. This way our technology -LRB- and the processes around it -RRB- will hopefully serve as a substrate that will eventually help in unifying the exchanges. At least computational scalability is no longer an obstacle. 8. CONCLUSION AND FUTURE RESEARCH In this work we have developed the most scalable exact algorithms for barter exchanges to date, with special focus on the upcoming national kidney-exchange market in which patients with kidney disease will be matched with compatible donors by swapping their own willing but incompatible donors. With over 70,000 patients already waiting for a cadaver kidney in the US, this market is seen as the only ethical way to significantly reduce the 4,000 deaths per year attributed to kidney disease. Our work presents the first algorithm capable of clearing these markets on a nationwide scale. It optimally solves the kidney exchange clearing problem with 10,000 donordonee pairs. The best prior technology -LRB- vanilla CPLEX -RRB- can not handle instances beyond about 900 donor-donee pairs because it runs out of memory. The key to our improvement is incremental problem formulation. We adapted two paradigms for the task : constraint generation and column generation. For each, we developed a host of techniques that substantially improve both runtime and memory usage. Some of the techniques use domain-specific observations while others are domain independent. We conclude that column generation scales dramatically better than constraint generation. Undoubtedly, further parameter tuning and perhaps additional speed improvement techniques could be used to make the algorithm even faster. Our algorithm also supports several generalizations, as desired by real-world kidney exchanges. Because we use an ILP methodology, we can also support a variety of side constraints, which often play an important role in markets in practice -LSB- 19 -RSB-. We can also support forcing part of the allocation, for example, `` This acutely sick teenager has to get a kidney if possible. '' Our work has treated the kidney exchange as a batch problem with full information -LRB- at least in the short run, kidney exchanges will most likely continue to run in batch mode every so often -RRB-. Two important directions for future work are to explicitly address both online and limited-information aspects of the problem. The online aspect is that donees and donors will be arriving into the system over time, and it may be best to not execute the myopically optimal exchange now, but rather save part of the current market for later matches.", "keyphrases": ["barter-exchang market", "match", "column gener", "kidnei", "transplant", "market characterist", "instanc gener", "solut approach", "edg formul", "cycl formul"]}
{"file_name": "H-2", "text": "Personalized Query Expansion for the Web ABSTRACT The inherent ambiguity of short keyword queries demands for enhanced methods for Web retrieval. In this paper we propose to improve such Web queries by expanding them with terms collected from each user 's Personal Information Repository, thus implicitly personalizing the search output. We introduce five broad techniques for generating the additional query keywords by analyzing user data at increasing granularity levels, ranging from term and compound level analysis up to global co-occurrence statistics, as well as to using external thesauri. Our extensive empirical analysis under four different scenarios shows some of these approaches to perform very well, especially on ambiguous queries, producing a very strong increase in the quality of the output rankings. Subsequently, we move this personalized search framework one step further and propose to make the expansion process adaptive to various features of each query. A separate set of experiments indicates the adaptive algorithms to bring an additional statistically significant improvement over the best static expansion approach. 1. INTRODUCTION The booming popularity of search engines has determined simple keyword search to become the only widely accepted user interface for seeking information over the Web. Yet keyword queries are * Part of this work was performed while the author was visiting Yahoo! Research, Barcelona, Spain. inherently ambiguous. The query `` canon book '' for example covers several different areas of interest : religion, photography, literature, and music. Clearly, one would prefer search output to be aligned with user 's topic -LRB- s -RRB- of interest, rather than displaying a selection of popular URLs from each category. Studies have shown that more than 80 % of the users would prefer to receive such personalized search results -LSB- 33 -RSB- instead of the currently generic ones. Query expansion assists the user in formulating a better query, by appending additional keywords to the initial search request in order to encapsulate her interests therein, as well as to focus the Web search output accordingly. It has been shown to perform very well over large data sets, especially with short input queries -LRB- see for example -LSB- 19, 3 -RSB- -RRB-. This is exactly the Web search scenario! In this paper we propose to enhance Web query reformulation by exploiting the user 's Personal Information Repository -LRB- PIR -RRB-, i.e., the personal collection of text documents, emails, cached Web pages, etc.. Several advantages arise when moving Web search personalization down to the Desktop level -LRB- note that by `` Desktop '' we refer to PIR, and we use the two terms interchangeably -RRB-. First is of course the quality of personalization : The local Desktop is a rich repository of information, accurately describing most, if not all interests of the user. Our algorithms expand Web queries with keywords extracted from user 's PIR, thus implicitly personalizing the search output. After a discussion of previous works in Section 2, we first investigate the analysis of local Desktop query context in Section 3.1.1. We propose several keyword, expression, and summary based techniques for determining expansion terms from those personal documents matching the Web query best. In Section 3.1.2 we move our analysis to the global Desktop collection and investigate expansions based on co-occurrence metrics and external thesauri. The experiments presented in Section 3.2 show many of these approaches to perform very well, especially on ambiguous queries, producing NDCG -LSB- 15 -RSB- improvements of up to 51.28 %. In Section 4 we move this algorithmic framework further and propose to make the expansion process adaptive to the clarity level of the query. This yields an additional improvement of 8.47 % over the previously identified best algorithm. We conclude and discuss further work in Section 5. 2. PREVIOUS WORK This paper brings together two IR areas : Search Personalization and Automatic Query Expansion. There exists a vast amount of algorithms for both domains. In this section we thus present a separate analysis, first introducing some approaches to personalize search, as this represents the main goal of our research, and then discussing several query expansion techniques and their relationship to our algorithms. 2.1 Personalized Search Personalized search comprises two major components : -LRB- 1 -RRB- User profiles, and -LRB- 2 -RRB- The actual search algorithm. This section splits the relevant background according to the focus of each article into either one of these elements. Approaches focused on the User Profile. Sugiyama et al. -LSB- 32 -RSB- analyzed surfing behavior and generated user profiles as features -LRB- terms -RRB- of the visited pages. Upon issuing a new query, the search results were ranked based on the similarity between each URL and the user profile. Qiu and Cho -LSB- 26 -RSB- used Machine Learning on the past click history of the user in order to determine topic preference vectors and then apply Topic-Sensitive PageRank -LSB- 13 -RSB-. User profiling based on browsing history has the advantage of being rather easy to obtain and process. This is probably why it is also employed by several industrial search engines -LRB- e.g., Yahoo! MyWeb2 -RRB-. However, it is definitely not sufficient for gathering a thorough insight into user 's interests. Moreover, none of these investigated the adaptive application of personalization. Approaches focused on the Personalization Algorithm. Haveliwala -LSB- 13 -RSB- computed a topicoriented PageRank, in which 16 PageRank vectors biased on each of the main topics of the Open Directory were initially calculated off-line, and then combined at run-time based on the similarity between the user query and each of the 16 topics. 2.2 Automatic Query Expansion Automatic query expansion aims at deriving a better formulation of the user query in order to enhance retrieval. It is based on exploiting various social or collection specific characteristics in order to generate additional terms, which are appended to the original in put keywords before identifying the matching documents returned as output. In this section we survey some of the representative query expansion works grouped according to the source employed to generate additional terms : -LRB- 1 -RRB- Relevance feedback, -LRB- 2 -RRB- Collection based co-occurrence statistics, and -LRB- 3 -RRB- Thesaurus information. Some other approaches are also addressed in the end of the section. Relevance Feedback Techniques. The main idea of Relevance Feedback -LRB- RF -RRB- is that useful information can be extracted from the relevant documents returned for the initial query. First approaches were manual -LSB- 28 -RSB- in the sense that the user was the one choosing the relevant results, and then various methods were applied to extract new terms, related to the query and the selected documents. Efthimiadis -LSB- 11 -RSB- presented a comprehensive literature review and proposed several simple methods to extract such new keywords based on term frequency, document frequency, etc.. We used some of these as inspiration for our Desktop specific techniques. Chang and Hsu -LSB- 5 -RSB- asked users to choose relevant clusters, instead of documents, thus reducing the amount of interaction necessary. RF has also been shown to be effectively automatized by considering the top ranked documents as relevant -LSB- 37 -RSB- -LRB- this is known as Pseudo RF -RRB-. Lam and Jones -LSB- 21 -RSB- used summarization to extract informative sentences from the top-ranked documents, and appended them to the user query. Finally, Yu et al. -LSB- 38 -RSB- selected the expansion terms from vision-based segments of Web pages in order to cope with the multiple topics residing therein. Co-occurrence Based Techniques. Terms highly co-occurring with the issued keywords have been shown to increase precision when appended to the query -LSB- 17 -RSB-. We have also investigated three such approaches in order to identify query relevant keywords from the rich, yet rather complex Personal Information Repository. Thesaurus Based Techniques. A broadly explored method is to expand the user query with new terms, whose meaning is closely related to the input keywords. Just as for the co-occurrence methods, initial experiments with this approach were controversial, either reporting improvements, or even reductions in output quality -LSB- 36 -RSB-. We also use WordNet based expansion terms. However, we base this process on analyzing the Desktop level relationship between the original query and the proposed new keywords. Other Techniques. There are many other attempts to extract expansion terms. Though orthogonal to our approach, two works are very relevant for the Web environment : Cui et al. -LSB- 8 -RSB- generated word correlations utilizing the probability for query terms to appear in each document, as computed over the search engine logs. Kraft and Zien -LSB- 19 -RSB- showed that anchor text is very similar to user queries, and thus exploited it to acquire additional keywords. 5. CONCLUSIONS AND FURTHER WORK In this paper we proposed to expand Web search queries by exploiting the user 's Personal Information Repository in order to automatically extract additional keywords related both to the query itself and to user 's interests, personalizing the search output. In this context, the paper includes the following contributions : \u2022 We proposed five techniques for determining expansion terms from personal documents. Each of them produces additional query keywords by analyzing user 's Desktop at increasing granularity levels, ranging from term and expression level analysis up to global co-occurrence statistics and external thesauri. Figure 1 : Relative NDCG gain -LRB- in % -RRB- for each algorithm overall, as well as separated per query category. \u2022 We provided a thorough empirical analysis of several variants of our approaches, under four different scenarios. We showed some of these approaches to perform very well, producing NDCG improvements of up to 51.28 %. \u2022 We moved this personalized search framework further and proposed to make the expansion process adaptive to features of each query, a strong focus being put on its clarity level. \u2022 Within a separate set of experiments, we showed our adaptive algorithms to provide an additional improvement of 8.47 % over the previously identified best approach. We are currently performing investigations on the dependency between various query features and the optimal number of expansion terms. We are also analyzing other types of approaches to identify query expansion suggestions, such as applying Latent Semantic Analysis on the Desktop data. Finally, we are designing a set of more complex combinations of these metrics in order to provide enhanced adaptivity to our algorithms.", "keyphrases": ["short keyword queri", "web retriev", "web queri", "person inform repositori", "search output", "addit queri keyword", "granular level", "term and compound level analysi", "global co-occurr statist", "extern thesauru", "extens empir analysi", "ambigu queri", "qualiti", "output rank", "person search framework", "expans process", "variou featur of each queri", "adapt algorithm", "signific improv", "static expans approach"]}
{"file_name": "J-30", "text": "Implementation with a Bounded Action Space ABSTRACT While traditional mechanism design typically assumes isomorphism between the agents ' type - and action spaces, in many situations the agents face strict restrictions on their action space due to, e.g., technical, behavioral or regulatory reasons. We devise a general framework for the study of mechanism design in single-parameter environments with restricted action spaces. Our contribution is threefold. First, we characterize sufficient conditions under which the information-theoretically optimal social-choice rule can be implemented in dominant strategies, and prove that any multilinear social-choice rule is dominant-strategy implementable with no additional cost. Second, we identify necessary conditions for the optimality of action-bounded mechanisms, and fully characterize the optimal mechanisms and strategies in games with two players and two alternatives. Finally, we prove that for any multilinear social-choice rule, the optimal mechanism with k actions incurs an expected loss of O -LRB- k21 -RRB- compared to the optimal mechanisms with unrestricted action spaces. Our results apply to various economic and computational settings, and we demonstrate their applicability to signaling games, public-good models and routing in networks. 1. INTRODUCTION Mechanism design is a sub-field of game theory that studies how to design rules of games resulting in desirable outcomes, when the players are rational. In a standard setting, players hold some private information -- their `` types '' -- and choose `` actions '' from their action spaces to maximize their utilities. The social planner wishes to implement a social-choice function, which maps each possible state of the world -LRB- i.e., a profile of the players ' types -RRB- to a single alternative. For example, a government that wishes to undertake a public-good project -LRB- e.g., building a bridge -RRB- only if the total benefit for the players exceeds its cost. Much of the literature on mechanism design restricts attention to direct revelation mechanisms, in which a player 's action space is identical to his type space. This focus is owing to the revelation principle that asserts that if some mechanism achieves a certain result in an equilibrium, the same result can be achieved in a truthful one -- an equilibrium where each agent simply reports his private type -LSB- 15 -RSB-. Nonetheless, in many environments, direct-revelation mechanisms are not viable since the actions available for the players have a limited expressive power. Consider, for example, the well-studied `` screening '' model, where an insurance firm wishes to sell different types of policies to different drivers based on their caution levels, which is their private information. There are various reasons for such strict restrictions on the action spaces. The buyers in such environemnts face only two actions -- to buy or not to buy -- although they may have an infinite number of possible values for the item. In many similar settings, players might be also reluctant to reveal their accurate types, but willing to disclose partial information about them. For example, agents will typically be unwilling to reveal their types, even if it is beneficial for them in the short run, since it might harm them in future transactions. Agents may also not trust the mechanism to keep their valuations private -LSB- 16 -RSB-, or not even know their exact type while computing it may be expensive -LSB- 12 -RSB-. Consider for example a public-good model : a social planner needs to decide whether to build a bridge. The two players in the game have some privately known benefits \u03b81, \u03b82 \u2208 -LSB- 0, 1 -RSB- from using this bridge. The social planner aims to build the bridge only if the sum of these benfits exceeds the construction cost of the bridge. The social planner can not access the private data of the players, and can only learn about it from the players ' actions. When direct revelation is allowed, the social planner can run the well-known VCG mechanism, where the players have incentives to report their true data ; hence, the planner can elicit the exact private information of the players and build the bridge only when it should be built. Assume now that the players can not send their entire secret data, but can only choose an action out of two possible actions -LRB- e.g., `` 0 '' or `` 1 '' -RRB-. Now, the social planner will clearly no longer be able to always build the bridge according to her objective function, due to the limited expressivness of the players ' messages. In this work we try to analyze what can be achieved in the presence of such restrictions. Restrictions on the action space, for specific models, were studied in several earlier papers. They studied single-item auctions where bidders are allowed to send messages with severely bounded size. They characterized the optimal mechanisms under this restriction, and showed that nearly optimal results can be achieved even with very strict limitations on the action space. Our work generalizes the main results of Blumrosen et al. to a general mechanism-design framework that can be applied to a multitude of models. A standard mechanism design setting is composed of agents with private information -LRB- their `` types '' -RRB-, and a social planner, who wishes to implement a social choice function, c -- a function that maps any profile of the agents ' types into a chosen alternative. A classic result in this setting says that under some monotonicity assumption on the agents ' preferences -- the `` single-crossing '' assumption -LRB- see definition below -RRB- -- a social-choice function is implementable in dominant strategies if and only if it is monotone in the players ' types. However, in environments with restricted action spaces, the social planner can not typically implement every social-choice function due to inherent informational constraints. That is, for some realizations of the players ' types, the decision of the social planner will be incompatible with the social-choice function c. In order to quantitatively measure how well bounded-action mechanisms can approximate the original social-choice functions, we follow a standard assumption that the social choice function is derived from a social-value function, g, which assigns a real value for every alternative A and realization of the players ' types. The social-choice function c will therefore choose an alternative that maximizes the social value function, given the type \u2192 \u2212 \u03b8 = -LRB- \u03b81,. . Observe that the social-value function is not necessarily the social welfare function -- the social welfare function is a special case of g in which g is defined to be the sum of the players ' valuations for the chosen alternative. Following are several simple examples of social-value functions : \u2022 Public goods. A government wishes to build a bridge only if the sum of the benefits that agents gain from it exceeds its construction cost C. The social value functions in a 2-player game will therefore be : g -LRB- \u03b81, \u03b82, `` build '' -RRB- = \u03b81 + \u03b82-C and g -LRB- \u03b81, \u03b82, `` do not build '' -RRB- = 0. \u2022 Routing in networks. Consider a network that is composed of two links in parallel. Each link has a secret probability pi of transferring a message successfully. A sender wishes to send his message through the network only if the probability of success is greater than, say, 90 percent - the known probability in an alternate network. \u2022 Single-item auctions. Consider a 2-player auction, where the auctioneer wishes to allocate the item to the player who values it the most. The social choice function is given by : g -LRB- \u03b81, \u03b82, `` player 1 wins '' -RRB- = \u03b81 and for the second alternative is g -LRB- \u03b81, \u03b82, `` player 2 wins '' -RRB- = \u03b82. 1.1 Our Contribution In this paper, we present a general framework for the study of mechanism design in environments with a limited number of actions. We assume a Bayesian model where players have one-dimensional private types, independently distributed on some real interval. The main question we ask is : when agents are only allowed to use k different actions, which mechanisms achieve the optimal expected social-value? Note that this question is actually composed of two separate questions. The first question is an information-theoretic question : what is the optimal result achievable when the players can only reveal information using these k actions -LRB- recall that their type space may be continuous -RRB-. The other question involves gametheoretic considerations : what is the best result achievable with k actions, where this result should be achieved in a dominant-strategy equilibrium. These questions raise the question about the `` price of implementation '' : can the optimal information-theoretic result always be implemented in a dominant-strategy equilibrium? And if not, to what extent does the dominant-strategy requirement degrades the optimal result? Our first contribution is the characterization of sufficient conditions for implementing the optimal informationtheoretic social-choice rule in dominant strategies. We show that for the family of multilinear social-value functions -LRB- that Theorem : Given any multilinear single-crossing socialvalue function, and for any number of alternatives and players, the social choice rule that is information-theoretically optimal is implementable in dominant strategies. Multilinear social-value functions capture many important and well-studied models, and include, for instance, the routing example given above, and any social welfare function in which the players ' valuations are linear in their types -LRB- such as public-goods and auctions -RRB-. The implementability of the information-theoretically optimal mechanisms enables us to use a standard routine in Mechanism Design and first determine the optimal socialchoice rule, and then calculate the appropriate payments that ensure incentive compatibility. To show this result, we prove a useful lemma that gives another characterization for social-choice functions whose `` price of implementation '' is zero. We show that for any social-choice function, incentive compatibility in action-bounded mechanisms is equivalent to the property that the optimal expected social value is achieved with non-decreasing strategies -LRB- or threshold strategies -RRB-.1 In other words, this lemma implies that one can always implement, with dominant strategies, the best socialchoice rule that is achievable with non-decreasing strategies. Our second contribution is in characterizing the optimal action-bounded mechanisms. We identify some necessary conditions for the optimality of mechanisms in general, and using these conditions, we fully characterize the optimal mechanisms in environments with two players and two alternatives. We complete the characterization of the optimal mechanisms with the depiction of the optimal strategies -- strategies that are `` mutually maximizers ''. Since the payments in a dominantstrategy implementation are uniquely defined by a monotone allocation and a profile of strategies, this also defines the payments in the mechanism. We give an intuitive proof for the optimality of such strategies, generalizing the concept of optimal `` mutually-centered '' strategies from -LSB- 4 -RSB-. Surprisingly, as opposed to the optimal auctions in -LSB- 4 -RSB-, for some non-trivial social-value functions, the optimal `` diagonal '' mechanism may not utilize all the k available actions. Theorem : For any multilinear single-crossing social-value function over two alternatives, the informationally optimal 2-player k-action mechanism is diagonal, and the optimal dominant strategies are mutually-maximizers. Achieving a full characterization of the optimal actionbounded mechanism for multi-player or multi-alternative environments seems to be harder. To support this claim, we observe that the number of mechanisms that satisfy the necessary conditions above is growing exponentially in the number of players. 1The restriction to non-decreasing strategies is very common in the literature. One remarkable result by Athey -LSB- 1 -RSB- shows that when a non-decreasing strategy is a best response for any other profile of non-decreasing strategies, a pure Bayesian-Nash equilibrium must exist. Our next result compares the expected social-value in k-action mechanisms to the optimal expected social value when the action space is unrestricted. For any number of players or alternatives, and for any profile of independent distribution functions, we construct mechanisms that are nearly optimal -- up to an additive difference of O -LRB- k21 -RRB-. This result is achieved in dominant strategies. Theorem : For any multilinear social-value function, the optimal k-action mechanism incurs an expected social loss of O -LRB- k21 -RRB-. Note that there are social-choice functions that can be implemented with k actions with no loss at all -LRB- for example, the rule `` always choose alternative A '' -RRB-. However, we know that in some settings -LRB- e.g., auctions -LSB- 5 -RSB- -RRB- the optimal loss may be proportional to 1k2, thus a better general upper bound is impossible. Finally, we present our results in the context of several natural applications. First, we give an explicit solution for a public-good game with k-actions. This is a natural application in our context since education levels are often discrete -LRB- e.g., B.A, M.A and PhD -RRB-. The latter example illustrates how our results apply to settings where the goal of the social planner is not welfare maximization -LRB- nor variants of it like `` affine maximizers '' -RRB-. The rest of the paper is organized as follows : our model and notations are described in Section 2. We then describe our general results regarding implementation in multi-player and multi-alternative environments in Section 3, including the asymptotic analysis of the social-value loss. In Section 4, we fully characterize the optimal mechanisms for 2player environments with two alternative. In Section 5, we conclude with applying our general results to several wellstudied models. 5. EXAMPLES Our results apply to a variety of economic, computational and networked settings. In this section, we demonstrate the applicability of our results to public-good models, signaling games and routing applications. 5.1 Application 1 : Public Goods The public-good model deals with a social planner -LRB- e.g., government -RRB- that needs to decide whether to supply a public good, such as building a bridge. Let Yes and No denote the respective alternatives of building and not building the bridge. v = v1,..., vn is the vector of the players ' types -- the values they gain from using the bridge. The decision that maximizes the social welfare is to build the bridge if and only if P is built, the social welfare is P i vi is greater than its cost, denoted by C. The utility of player i under payment pi is ui = vi -- pi if the bridge is built, and 0 otherwise. It is well-known that under no restriction on the action space, it is possible to induce truthful revelation by VCG mechanisms, therefore full efficiency can be achieved. Obviously, when the action set is limited to k actions, we can not achieve full efficiency due to the informational constraints. Hence, the information-theoretically optimal kaction mechanism is implementable in dominant strategies. Moreover, as Theorem 3 suggests, in the k-action 2-player public-good game, we can fully characterize the optimal mechanisms. In the proof of Theorem 3, we saw that when for both players g -LRB- \u03b8i, \u03b8i, A -RRB- = g -LRB- \u03b8i, \u03b8i, B -RRB-, the mechanism is non-degenerate with respect to both players.6 This condition clearly holds here -LRB- 1 + 0 -- C = 0 + 1 -- C -RRB-, therefore the optimal mechanisms will use all k actions. 1. Allocation : Build the bridge if j '' b1 + b2 > k. Strategies : Threshold strategies based on the vectors \u2192 -- x, -- \u2192 y where for every 1 < i < k-1, 2. Allocation : Build the bridge if j '' b1 + b2 > k -- 1. Strategies : Threshold strategies based on the vectors \u2192 -- x, -- \u2192 y where for every 1 < i < k-1 : Recall that we define the optimal mechanisms by their allocation scheme and by the optimal strategies for the players. It is well known, that the allocation scheme in monotone mechanisms uniquely defines the payments that ensure incentive-compatibility. In public-good games, these payments satisfy the rule that a player pays his lowest value for which the bridge is built, when the action of the other player is fixed. Therefore, the payments for the players 1 and 2 reporting the actions b1 and b2 are as follows : in mechanism 1 from Proposition 3, p1 = xb2 and p2 = yb1 ; in mechanism 2 from Proposition 3, p1 = xb2 -- 1 and p2 = yb1 -- 1. We now show a more specific example that assumes uniform distributions. The example shows how the optimal mechanism is determined by the cost C : for low costs, mechanism of type 1 is optimal, and for high costs the optimal mechanism is of type 2. An additional interesting feature of the optimal mechanisms in the example is that they are symmetric with respect to the players. This come as opposed to the optimal mechanisms in the auction model -LSB- 5 -RSB- that are asymmetric -LRB- even when the players ' values are drawn from identical distributions -RRB-. Figure 2 : Optimal mechanisms in a 2-player, 2-alternative, 2-action public-goods game, when the types are uniformly distributed in -LSB- 0, 1 -RSB-. The mechanism on the left is optimal when C < 1 and the other is optimal when C > 1. EXAMPLE 1. Suppose that the types of both players are uniformly distributed on -LSB- 0, 1 -RSB-. Figure 2 illustrates the optimal mechanisms for k = 2, and shows how both the allocation scheme and the payments depend on the construction cost C. Then, the welfare-maximizing mechanisms are : 5.2 Application 2 : Signaling We now study a signaling model in labor markets. In this model, the type of each worker, \u03b8i \u2208 -LSB- \u03b8, \u03b8 -RSB-, describes the worker 's productivity level. The firm wants to make her hiring decisions according to a decision function f -LRB- \u2212 \u2192 \u03b8 -RRB-. For example, the firm may want to hire the most productive worker -LRB- like the auction model -RRB-, or hire a group of workers only if their sum of productivities is greater than some threshold -LRB- similar to the public-good model -RRB-. However, the worker 's productivity is invisible to the firm ; the firm only observes the worker 's education level e that should convey signals about her productivity level. Note that the assumption here is that acquiring education, at any level, does not affect the productivity of the worker, but only signals about the worker 's skills. A main component in this model, is the fact that as the worker is more productive, it is easier for him to acquire high-level education. In addition, the cost of acquiring education increases with the education level. More formally, a continuous function C -LRB- e, \u03b8 -RRB- describes the cost to a worker from acquiring each education level as a function of his productivity. An action for a worker in this game is the education level he chooses to acquire. In standard models, this action space is continuous, and then a `` fully separating equilibrium '' exists -LRB- under the single-crossing conditions on the cost function -RRB-. That is, there exists an equilibrium in which every type is mapped into a different education level ; thus, the firm can induce the exact productivity levels of the workers by this signaling mechanism. However, it is hard to imagine a world with a continuum of education levels. It is usually the case that there are only several discrete education levels -LRB- e.g., BSc, MSc, PhD -RRB-. With k education levels, the firm may not be able to exactly follow the decision function f. For achieving the best result in k actions, the firm may want the workers to play according to specific threshold strategies. It turns out that the standard condition, the single-crossing condition on the cost function, suffices for ensuring that these threshold strategies will be dominant for the players. COROLLARY 4. Consider a multilinear decision function f, and a single-crossing cost function for the players. With k education levels, the firm can implement in dominant strategies a decision function that incurs a loss of O -LRB- k21 -RRB- compared with the decision function f. 5.3 Application 3 : Routing In our last example, we show the applicability of our results to routing in lossy networks. In such systems, a sender needs to decide through which network to transmit his message. In this example, we focus on parallel-path networks. The edges in these networks are controlled by different selfish agents, and each edge appears only in one of the networks. Suppose that the sender, who wishes to send a message from the source to the sink, knows the topology of each network, but the probability of success on each link, pi, is the link 's private information. The problem of the sender is to decide whether to send a message through the network N1 or through an alternate network N2. Obviously, the sender wishes to send the message through N1 only if the total probability of success in N1 is greater than the success probability in N2. Let f N -LRB- \u2212 \u2192 p -RRB- denote the probability of success in network N with a successprobability vector \u2192 \u2212 p. The social choice function in this example is thus : c -LRB- \u2212 \u2192 p -RRB- \u2208 argmax -LCB- N1, N2 -RCB- -LCB- fN1 -LRB- \u2212 \u2192 p -RRB-, f N2 -LRB- \u2212 \u2192 p -RRB- -RCB-. Figure 3 : An example for a parallel-path network, where each link has a probability pi for transmission success. We show that the overall probability of success in such networks is multilinear in pi, and thus the optimal k-action social-choice function is dominant-strategy implementable. In this example, we assume that every agent has a singlecrossing valuation function over the alternatives. That is, each player wishes that the message will be sent through his network, and his benefit is positively correlated with his secret data -LRB- e.g., the valuation of player i may be exactly pi -RRB-. We would like to emphasize that the social planner in this example -LRB- the sender -RRB- does not aim to maximize the social welfare. That is, the social value is not the sum of the players ' types nor any weighted sum of the types -LRB- `` affine maximizer '' -RRB-. The success probability of sending a message through a parallel-path network is multilinear, since it can be expressed by the following multilinear formula -LRB- where P denotes the set of all paths between the source and the sink -RRB- : Note that for every link i, the partial derivative in pi of the success probability written in Equation 3 is positive. In all the other networks, that do not contain link i, the partial derivative is clearly zero. Therefore, the social-value function is single crossing and our general results can be applied. COROLLARY 5. For any social-choice function that maximizes the success probability over parallel-path networks, the informationally optimal k-action social-choice function is implementable -LRB- for any k -RRB-. Acknowledgment. The work of the second author is also supported by the Lady Davis Trust Fellowship.", "keyphrases": ["bound action space", "implement", "domin strategi", "social-choic function", "decis function", "singl-cross condit", "multilinear function", "optim mechan", "action-bound mechan", "probabl of success"]}
{"file_name": "C-19", "text": "Service Interface : A New Abstraction for Implementing and Composing Protocols * ABSTRACT In this paper we compare two approaches to the design of protocol frameworks -- tools for implementing modular network protocols. The most common approach uses events as the main abstraction for a local interaction between protocol modules. We argue that an alternative approach, that is based on service abstraction, is more suitable for expressing modular protocols. It also facilitates advanced features in the design of protocols, such as dynamic update of distributed protocols. We then describe an experimental implementation of a service-based protocol framework in Java. 1. INTRODUCTION They allow complex protocols to be implemented by decomposing them into several modules cooperating together. This approach facilitates code reuse and customization of distributed protocols in order to fit the needs of different applications. Moreover, protocol modules can be plugged in to the system dynamically. All these features of protocol frameworks make them an interesting enabling technology for implementing adaptable systems -LSB- 14 -RSB- - an important class of applications. Most protocol frameworks are based on events -LRB- all frameworks cited above are based on this abstraction -RRB-. Events are used for asynchronous communication between different modules on the same machine. For instance, the composition of modules may require connectors to route events, which introduces burden for a protocol composer -LSB- 4 -RSB-. Protocol frameworks such as Appia and Eva extend the event-based approach with channels. However, in our opinion, this solution is not satisfactory since composition of complex protocol stacks becomes more difficult. In this paper, we propose a new approach for building modular protocols, that is based on a service abstraction. We compare this new approach with the common, event-based approach. We show that protocol frameworks based on services have several advantages, e.g. allow for a fairly straightforward protocol composition, clear implementation, and better support of dynamic replacement of distributed protocols. To validate our claims, we have implemented SAMOA -- an experimental protocol framework that is purely based on the service-based approach to module composition and implementation. The framework allowed us to compare the service - and event-based implementations of an adaptive group communication middleware. Section 2 defines general notions. Section 3 presents the main characteristics of event-based frameworks, and features that are distinct for each framework. Section 4 describes our new approach, which is based on service abstraction. Section 5 discusses the advantages of a service-based protocol framework compared to an event-based protocol framework. The description of our experimental implementation is presented in Section 6. Finally, we conclude in Section 7. 7. CONCLUSION In the paper, we proposed a new approach to the protocol composition that is based on the notion of Service Interface, instead of events. We believe that the service-based framework has several advantages over event-based frameworks. A prototype implementation allowed us to validate our ideas.", "keyphrases": ["protocol framework", "distribut algorithm", "distribut system", "servic interfac", "network", "commun", "event-base framework", "stack", "modul", "request", "repli"]}
{"file_name": "I-21", "text": "Interactions between Market Barriers and Communication Networks in Marketing Systems ABSTRACT We investigate a framework where agents search for satisfying products by using referrals from other agents. Our model of a mechanism for transmitting word-of-mouth and the resulting behavioural effects is based on integrating a module governing the local behaviour of agents with a module governing the structure and function of the underlying network of agents. Local behaviour incorporates a satisficing model of choice, a set of rules governing the interactions between agents, including learning about the trustworthiness of other agents over time, and external constraints on behaviour that may be imposed by market barriers or switching costs. Local behaviour takes place on a network substrate across which agents exchange positive and negative information about products. We use various degree distributions dictating the extent of connectivity, and incorporate both small-world effects and the notion of preferential attachment in our network models. We compare the effectiveness of referral systems over various network structures for easy and hard choice tasks, and evaluate how this effectiveness changes with the imposition of market barriers. 1. INTRODUCTION Defection behaviour, that is, why people might stop using a particular product or service, largely depends on the psychological affinity or satisfaction that they feel toward the currently-used product -LSB- 14 -RSB- and the availability of more attractive alternatives -LSB- 17 -RSB-. However, in many cases the decision about whether to defect or not is also dependent on various external constraints that are placed on switching behaviour, either by the structure of the market, by the suppliers themselves -LRB- in the guise of formal or informal contracts -RRB-, or other so-called ` switching costs ' or market barriers -LSB- 12, 5 -RSB-. The key feature of all these cases is that the extent to which psychological affinity plays a role in actual decision-making is constrained by market barriers, so that agents are prevented from pursuing those courses of action which would be most satisfying in an unconstrained market. While the level of satisfaction with a currently-used product will largely be a function of one 's own experiences of the product over the period of use, knowledge of any potentially more satisfying alternatives is likely to be gained by augmenting the information gained from personal experiences with information about the experiences of others gathered from casual word-of-mouth communication. Moreover, there is an important relationship between market barriers and word-of-mouth communication. In the presence of market barriers, constrained economic agents trapped in dissatisfying product relationships will tend to disseminate this information to other agents. In the absence of such barriers, agents are free to defect from unsatisfying products and word-of-mouth communication would thus tend to be of the positive variety. Since the imposition of at least some forms of market barriers is often a strategic decision taken by product suppliers, these relationships may be key to the success of a particular supplier. In addition, the relationship between market barriers and word-of-mouth communication may be a reciprocal one. The structure and function of the network across which word-ofmouth communication is conducted, and particularly the way in which the network changes in response to the imposition of market barriers, also plays a role in determining which market barriers are most effective. An agent-based model framework allows for an investigation at the level of the individual decision maker, at the 2. BACKGROUND 2.1 Word-of-mouth communication The role of word-of-mouth communication on the behaviour of complex systems has been studied in both analytical and simulation models. Simulation-based investigations of wordof-mouth -LSB- 6, 13 -RSB- have focused on developing strategies for ensuring that a system reaches an equilibrium level where all agents are satisfied, largely by learning about the effectiveness of others ' referrals or by varying the degree of inertia in individual behaviour. The simulation framework allows for a more complex modelling of the environment than the analytical models, in which referrals are at random and only two choices are available, and the work in -LSB- 6 -RSB- in particular is a close antecedent of the work presented in this paper, our main contribution being to include network structure and the constraints imposed by market barriers as additional effects. 2.2 Market barriers The extent to which market barriers are influential in affecting systems behaviour draws attention mostly from economists interested in how barriers distort competition and marketers interested in how barriers distort consumer choices. A useful typology of market barriers distinguishes ` transactional ' barriers associated with the monetary cost of changing -LRB- e.g. in financial services -RRB-, ` learning ' barriers associated with deciding to replace well-known existing products, and ` contractual ' barriers imposing legal constraints for the term of the contract -LSB- 12 -RSB-. A different typology -LSB- 5 -RSB- introduces the additional aspect of ` relational ' barriers arising from personal relationships that may be interwoven with the use of a particular product. There is generally little empirical evidence on the relationship between the creation of barriers to switching and the retention of a customer base, and to the best of our knowledge no previous work using agent-based modelling to generate empirical findings. Burnham et al. -LSB- 5 -RSB- find that perceived market barriers account for nearly twice the variance in intention to stay with a product than that explained by satisfaction with the product -LRB- 30 % and 16 % respectively -RRB-, and that so-called relational barriers are considerably more influential than either transactional or learning barriers. Further, they find that switching costs are perceived by consumers to exist even in markets which are fluid and where barriers would seem to be weak. Simply put, market barriers appear to play a greater role in what people do than satisfaction ; and their presence may be more pervasive than is generally thought. 5. CONCLUSIONS AND RELATED WORK Purchasing behaviour in many markets takes place on a substrate of networks of word-of-mouth communication across which agents exchange information about products and their likes and dislikes. Understanding the ways in which flows of word-of-mouth communication influence aggregate market behaviour requires one to study both the underlying structural properties of the network and the local rules governing the behaviour of agents on the network when making purchase decisions and when interacting with other agents. These local rules are often constrained by the nature of a particular market, or else imposed by strategic suppliers or social customs. The proper modelling of a mechanism for word-of-mouth transmittal and resulting behavioural effects thus requires a consideration of a number of complex and interacting components : networks of communication, source credibility, learning processes, habituation and memory, external constraints on behaviour, theories of information transfer, and adaptive behaviour. In this paper we have attempted to address some of these issues in a manner which reflects how agents might act in the real world. It is the final finding that is likely to be most surprising and practically relevant for the marketing research field, and suggests that it may not always be in the best interests of a market leader to impose barriers that prevent customers from leaving. In poorly-connected networks, the effect of barriers on market shares is slight. In contrast, in well-connected networks, negative word-of-mouth can prevent agents from trying a product that they might otherwise have found satisfying, and this can inflict significant harm on market share. Products with small market share -LRB- which, in the context of our simulations, is generally due to the product offering poor performance -RRB- are relatively unaffected by negative word-of-mouth, since most product trials are likely to be unsatisfying in any case. Agent-based modelling provides a natural way for beginning to investigate the types of dynamics that occur in marketing systems. Naturally the usefulness of results is for the most part dependent on the quality of the modelling of the two ` modules ' comprising network structure and local behaviour. On the network side, future work might investigate the relationship between degree distributions, the way connections are created and destroyed over time, whether preferential attachment is influential, and the extent to which social identity informs network strucutre, all in larger networks of more heterogenous agents. On the behavioural side, one might look at the adaptation of satisfaction thresholds during the course of communication, responses to systematic changes in product performances over time, the integration of various information sources, and different market barrier structures. All these areas provide fascinating opportunities to introduce psychological realities into models of marketing systems and to observe the resulting behaviour of the system under increasingly realistic scenario descriptions.", "keyphrases": ["referr system", "purchas behaviour", "word-of-mouth commun", "market system", "defect behaviour", "psycholog affin", "switch behaviour", "agent-base model", "social psycholog", "market barrier", "consum choic", "switch cost"]}
{"file_name": "C-34", "text": "Researches on Scheme of Pairwise Key Establishment for Distributed Sensor Networks ABSTRACT Security schemes of pairwise key establishment, which enable sensors to communicate with each other securely, play a fundamental role in research on security issue in wireless sensor networks. A new kind of cluster deployed sensor networks distribution model is presented, and based on which, an innovative Hierarchical Hypercube model - H -LRB- k, u, m, v, n -RRB- and the mapping relationship between cluster deployed sensor networks and the H -LRB- k, u, m, v, n -RRB- are proposed. By utilizing nice properties of H -LRB- k, u, m, v, n -RRB- model, a new general framework for pairwise key predistribution and a new pairwise key establishment algorithm are designed, which combines the idea of KDC -LRB- Key Distribution Center -RRB- and polynomial pool schemes. Furthermore, the working performance of the newly proposed pairwise key establishment algorithm is seriously inspected. Theoretic analysis and experimental figures show that the new algorithm has better performance and provides higher possibilities for sensor to establish pairwise key, compared with previous related works. 1. INTRODUCTION Security communication is an important requirement in many sensor network applications, so shared secret keys are used between communicating nodes to encrypt data. As one of the most fundamental security services, pairwise key establishment enables the sensor nodes to communicate securely with each other using cryptographic techniques. However, due to the sensor nodes ' limited computational capabilities, battery energy, and available memory, it is not feasible for them to use traditional pairwise key establishment techniques such as public key cryptography and key distribution center -LRB- KDC -RRB-. Several alternative approaches have been developed recently to perform pairwise key establishment on resource-constrained sensor networks without involving the use of traditional cryptography -LSB- 14 -RSB-. Eschenauer and Gligor proposed a basic probabilistic key predistribution scheme for pairwise key establishment -LSB- 1 -RSB-. In the scheme, each sensor node randomly picks a set of keys from a key pool before the deployment so that any two of the sensor nodes have a certain probability to share at least one common key. Chan et al. further extended this idea and presented two key predistribution schemes : a q-composite key pre-distribution scheme and a random pairwise keys scheme. The q-composite scheme requires any two sensors share at least q pre-distributed keys. The random scheme randomly picks pair of sensors and assigns each pair a unique random key -LSB- 2 -RSB-. Based on such a framework, they presented two pairwise key pre-distribution schemes : a random subset assignment scheme and a grid-based scheme. A polynomial pool is used in those schemes, instead of using a key pool in the previous techniques. The random subset assignment scheme assigns each sensor node the secrets generated from a random subset of polynomials in the polynomial pool. The gridbased scheme associates polynomials with the rows and the columns of an artificial grid, assigns each sensor node to a unique coordinate in the grid, and gives the node the secrets generated from the corresponding row and column polynomials. Based on this grid, each sensor node can then identify whether it can directly establish a pairwise key with another node, and if not, what intermediate nodes it can contact to indirectly establish the pairwise key. A similar approach to those schemes described by Liu et al was independently developed by Du et a. -LSB- 5 -RSB-. Rather than on Blundo 's scheme their approach is based on Blom 's scheme -LSB- 6 -RSB-. All of those schemes above improve the security over the basic probabilistic key pre-distribution scheme. However, the pairwise key establishment problem in sensor networks is still not well solved. For the basic probabilistic and the q-composite key predistribution schemes, as the number of compromised nodes increases, the fraction of affected pairwise keys increases quickly. As a result, a small number of compromised nodes may affect a large fraction of pairwise keys -LSB- 3 -RSB-. Though the random pairwise keys scheme doses not suffer from the above security problem, it incurs a high memory overhead, which increases linearly with the number of nodes in the network if the level of security is kept constant -LSB- 2 -RSB- -LSB- 4 -RSB-. For the random subset assignment scheme, it suffers higher communication and computation overheads. In 2004, Liu proposed a new hypercube-based pairwise key predistribution scheme -LSB- 7 -RSB-, which extends the grid-based scheme from a two dimensional grid to a multi-dimensional hypercube. The analysis shows that hypercube-based scheme keeps some attractive properties of the grid-based scheme, including the guarantee of establishing pairwise keys and the resilience to node compromises. Also, when perfect security against node compromise is required, the hypercube-based scheme can support a larger network by adding more dimensions instead of increasing the storage overhead on sensor nodes. Though hypercube-based scheme -LRB- we consider the grid-based scheme is a special case of hypercube-based scheme -RRB- has many attractive properties, it requires any two nodes in sensor networks can communication directly with each other. This strong assumption is impractical in most of the actual applications of the sensor networks. In this paper, we present a kind of new cluster-based distribution model of sensor networks, and for which, we propose a new pairwise key pre-distribution scheme. Based on the topology, we propose a novel cluster distribution based hierarchical hypercube model to establish the pairwise key. We develop a kind of new pairwise key establishment algorithm with our hierarchical hypercube model. The structure of this paper is arranged as follows : In section 3, a new distribution model of cluster deployed sensor networks is presented. In section 4, a new Hierarchical Hypercube model is proposed. In section 5, the mapping relationship between the clusters deployed sensor network and Hierarchical Hypercube model is discussed. In section 6 and section 7, new pairwise key establishment algorithm are designed based on the Hierarchical Hypercube model and detailed analyses are described. Finally, section 8 presents a conclusion. 2. PRELIMINARY Definition 1 -LRB- Key Predistribution -RRB- : The procedure, which is used to encode the corresponding encryption and decryption algorithms in sensor nodes before distribution, is called Key Predistribution. Definition 2 -LRB- Pairwise Key -RRB- : For any two nodes A and B, if they have a common key E, then the key E is called a pairwise key between them. 8. CONCLUSION A new hierarchical hypercube model named H -LRB- k, u, m, v, n -RRB- is proposed, which can be used for pairwise key predistribution for cluster deployed sensor networks. And Based on the H -LRB- k, u, m, v, n -RRB- model, an innovative pairwise key predistribution scheme and algorithm are designed respectively, by combing the good properties of the Polynomial Key and Key Pool encryption schemes. So, the traditional pairwise key predistribution algorithm based on hypercube model -LSB- 7 -RSB- is only a special case of the new algorithm proposed in this paper. Theoretical and experimental analyses show that the newly proposed algorithm is an efficient pairwise key establishment algorithm that is suitable for the cluster deployed sensor networks.", "keyphrases": ["sensor network", "kei pool", "kei predistribut", "hierarch hypercub model", "secur", "pairwis kei establish algorithm", "cluster-base distribut model", "polynomi kei", "encrypt", "node code", "high fault-toler"]}
{"file_name": "H-32", "text": "Interesting Nuggets and Their Impact on Definitional Question Answering ABSTRACT Current approaches to identifying definitional sentences in the context of Question Answering mainly involve the use of linguistic or syntactic patterns to identify informative nuggets. This is insufficient as they do not address the novelty factor that a definitional nugget must also possess. This paper proposes to address the deficiency by building a `` Human Interest Model '' from external knowledge. It is hoped that such a model will allow the computation of human interest in the sentence with respect to the topic. We compare and contrast our model with current definitional question answering models to show that interestingness plays an important factor in definitional question answering. 1. DEFINITIONAL QUESTION ANSWERING Definitional Question Answering was first introduced to the TExt Retrieval Conference Question Answering Track main task in 2003. The Definition questions, also called Other questions in recent years, are defined as follows. Given a question topic X, the task of a definitional QA system is akin to answering the question `` What is X? '' . The definitional QA system is to search through a news corpus and return return a set of answers that best describes the question topic. Each answer should be a unique topic-specific nugget that makes up one facet in the definition of the question topic. 1.1 The Two Aspects of Topic Nuggets Officially, topic-specific answer nuggets or simply topic nuggets are described as `` informative nuggets ''. Each informative nugget is a sentence fragment that describe some factual information about the topic. From observation of the answer set for definitional question answering from TREC 2003 to 2005, it seems that a significant number of topic nuggets can not simply be described as informative nuggets. Rather, these topic nuggets have a trivia-like quality associated with them. Typically, these are out of the ordinary pieces of information about a topic that can pique a human reader 's interest. For this reason, we decided to define answer nuggets that can evoke human interest as `` interesting nuggets ''. In essence, interesting nuggets answer the questions `` What is X famous for? '' , `` What defines X? '' . We now have two very different perspective as to what constitutes an answer to Definition questions. An answer can be some important factual information about the topic or some novel and interesting aspect about the topic. This duality of informativeness and interestingness can be clearly observed in the five vital answer nuggets for a TREC 2005 topic of `` George Foreman ''. Certain answer nuggets are more informative while other nuggets are more interesting in nature. Informative Nuggets - Became oldest world champion in boxing history. Interesting Nuggets - Returned to boxing after 10 yr hiatus. As seen here, interesting nuggets has some surprise factor or unique quality that makes them interesting to human readers. 1.2 Identifying Interesting Nuggets Since the original official description for definitions comprise of identifying informative nuggets, most research has focused entirely on identifying informative nuggets. In this paper, we focus on exploring the properties of interesting nuggets and develop ways of identify such interesting nuggets. A '' Human Interest Model '' definitional question answering system is developed with emphasis on identifying interesting nuggets in order to evaluate the impact of interesting nuggets on the performance of a definitional question answering system. We further experimented with combining the Human Interest Model with a lexical pattern based definitional question answering system in order to capture both informative and interesting nuggets. 2. RELATED WORK There are currently two general methods for Definitional Question Answering. The more common method uses a lexical patternbased approach was first proposed by Blair-Goldensohn et al. -LSB- 1 -RSB- and Xu et al. -LSB- 14 -RSB-. Both groups predominantly used patterns such as copulas and appositives, as well as manually crafted lexicosyntactic patterns to identify sentences that contain informative nuggets. For example, Xu et al. used 40 manually defined `` structured patterns '' in their 2003 definitional question answering system. Since then, in an attempt to capture a wider class of informational nuggets, many such systems of increasing complexity has been created. A recent system by Harabagiu et al. -LSB- 6 -RSB- created a definitional question answering system that combines the use of 150 manually defined positive and negative patterns, named entity relations and specially crafted information extraction templates for 33 target domains. As one can imagine, this is a knowledge intensive approach that requires an expert linguist to manually define all possible lexical or syntactic patterns required to identify specific types of information. Instead of manually encoding patterns, answers to previous definitional question answering evaluations were converted into generic patterns and a probabilistic model is trained to identify such patterns in sentences. Such lexicalosyntactic patterns approach have been shown to be adept at identifying factual informative nuggets such as a person 's birthdate, or the name of a company 's CEO. However, these patterns are either globally applicable to all topics or to a specific set of entities such as musicians or organizations. This is in direct contrast to interesting nuggets that are highly specific to individual topics and not to a set of entities. For example, the interesting nuggets for George Foreman are specific only George Foreman and no other boxer or human being. Topic specificity or topic relevance is thus an important criteria that helps identify interesting nuggets. This leads to the exploration of the second relevance-based approach that has been used in definitional question answering. Predominantly, this approach has been used as a backup method for identifying definitional sentences when the primary method of lexicalosyntactic patterns failed to find a sufficient number of informative nuggets -LSB- 1 -RSB-. A similar approach has also been used as a baseline system for TREC 2003 -LSB- 14 -RSB-. More recently, Chen et al. -LSB- 3 -RSB- adapted a bi-gram or bi-term language model for definitional Question Answering. Generally, the relevance-based approach requires a `` definitional corpus '' that contain documents highly relevant to the topic. The baseline system in TREC 2003 simply uses the topic words as its definitional corpus. Blair-Goldensohn et al. -LSB- 1 -RSB- uses a machine learner to include in the definitonal corpus sentences that are likely to be definitional. Chen et al. -LSB- 3 -RSB- collect snippets from Google to build its definitional corpus. From the definitional corpus, a definitional centroid vector is built or a set of centroid words are selected. This centroid vector or set of centroid words is taken to be highly indicative of the topic. Systems can then use this centroid to identify definitional answers by using a variety of distance metrics to compare against sentences found in the set of retrieved documents for the topic. BlairGoldensohn et al. -LSB- 1 -RSB- uses Cosine similarity to rank sentences by `` centrality ''. As described here, the relevance-based approach is highly specific to individual topics due to its dependence on a topic specific definitional corpus. However if individual sentences are viewed as a document, then relevance-based approaches essentially use the collected topic specific centroid words as a form of document retrieval with automated query expansion to identify strongly relevant sentences. Thus such methods identify relevant sentences and not sentences containing definitional nuggets. Yet, the TREC 2003 baseline system -LSB- 14 -RSB- outperformed all but one other system. The bi-term language model -LSB- 3 -RSB- is able to report results that are highly competitive to state-of-the-art results using this retrieval-based approach. At TREC 2006, a simple weighted sum of all terms model with terms weighted using solely Google snippets outperformed all other systems by a significant margin -LSB- 7 -RSB-. We believe that interesting nuggets often come in the form of trivia, novel or rare facts about the topic that tend to strongly cooccur with direct mention of topic keywords. This may explain why relevance-based method can perform competitively in definitional question answering. However, simply comparing against a single centroid vector or set of centroid words may have over emphasized topic relevance and has only identified interesting definitional nuggets in an indirect manner. Still, relevance based retrieval methods can be used as a starting point in identifying interesting nuggets. We will describe how we expand upon such methods to identify interesting nuggets in the next section. 7. CONCLUSION This paper has presented a novel perspective for answering definitional questions through the identification of interesting nuggets. Interesting nuggets are uncommon pieces of information about the topic that can evoke a human reader 's curiosity. The notion of an '' average human reader '' is an important consideration in our approach. This is very different from the lexico-syntactic pattern approach where the context of a human reader is not even considered when finding answers for definitional question answering. Using this perspective, we have shown that using a combination of a carefully selected external corpus, matching against multiple centroids and taking into consideration rare but highly topic specific terms, we can build a definitional question answering module that is more focused on identifying nuggets that are of interest to human beings. Experimental results has shown this approach can significantly outperform state-of-the-art definitional question answering systems. We further showed that at least two different types of answer nuggets are required to form a more thorough set of definitional answers. What seems to be a good set of definition answers is some general information that provides a quick informative overview mixed together with some novel or interesting aspects about the topic. Thus we feel that a good definitional question answering system would need to pick up both informative and interesting nugget types in order to provide a complete definitional coverage on all important aspects of the topic. Indeed, this is natural as the two models have been designed to identify two very different types of definition answers using very different types of features. As a result, we are currently only able to achieve a hybrid system that has the same level of performance as our proposed Human Interest Model. We approached the problem of definitional question answering from a novel perspective, with the notion that interest factor plays a role in identifying definitional answers. Although the methods we used are simple, they have been shown experimentally to be effective. Our approach may also provide some insight into a few anomalies in past definitional question answering 's trials. For instance, the top definitional system at the recent TREC 2006 evaluation was able to significantly outperform all other systems using relatively simple unigram probabilities extracted from Google snippets. We suspect the main contributor to the system 's performance Table 3 : TREC 2005 Topics Grouped by Entity Type In our future work, we seek to further improve on the combined system by incorporating more evidence in support of correct definitional answers or to filter away obviously wrong answers.", "keyphrases": ["us of linguist", "extern knowledg", "comput of human interest", "new corpu", "question topic", "inform nugget", "sentenc fragment", "human reader", "interest", "interest nugget", "uniqu qualiti", "surpris factor", "lexic pattern", "manual labor", "baselin system"]}
{"file_name": "I-4", "text": "Meta-Level Coordination for Solving Negotiation Chains in Semi-Cooperative Multi-Agent Systems ABSTRACT A negotiation chain is formed when multiple related negotiations are spread over multiple agents. In order to appropriately order and structure the negotiations occurring in the chain so as to optimize the expected utility, we present an extension to a singleagent concurrent negotiation framework. This work is aimed at semi-cooperative multi-agent systems, where each agent has its own goals and works to maximize its local utility ; however, the performance of each individual agent is tightly related to other agent 's cooperation and the system 's overall performance. We introduce a pre-negotiation phase that allows agents to transfer meta-level information. Using this information, the agent can build a more accurate model of the negotiation in terms of modeling the relationship of flexibility and success probability. This more accurate model helps the agent in choosing a better negotiation solution in the global negotiation chain context. The agent can also use this information to allocate appropriate time for each negotiation, hence to find a good ordering of all related negotiations. The experimental data shows that these mechanisms improve the agents ' and the system 's overall performance significantly. 1. INTRODUCTION Sophisticated negotiation for task and resource allocation is crucial for the next generation of multi-agent systems -LRB- MAS -RRB- applications. Groups of agents need to efficiently negotiate over multiple related issues concurrently in a complex, distributed setting where there are deadlines by which the negotiations must be completed. This is an important research area where there has been very little work done. This work is aimed at semi-cooperative multi-agent systems, where each agent has its own goals and works to maximize its local utility ; however, the performance of each individual agent is tightly related to other agent 's cooperation and the system 's overall performance. There is no single global goal in such systems, either because each agent represents a different organization/user, or because it is difficult/impossible to design one single global goal. This issue arises due to multiple concurrent tasks, resource constrains and uncertainties, and thus no agent has sufficient knowledge or computational resources to determine what is best for the whole system -LSB- 11 -RSB-. To accomplish tasks continuously arriving in the virtual organization, cooperation and sub-task relocation are needed and preferred. There is no single global goal since each agent may be involved in multiple virtual organizations. Meanwhile, the performance of each individual agent is tightly related to other agents ' cooperation and the virtual organization 's overall performance. The negotiation in such systems is not a zero-sum game, a deal that increases both agents ' utilities can be found through efficient negotiation. Additionally, there are multiple encounters among agents since new tasks are arriving all the time. In such negotiations, price may or may not be important, since it can be fixed resulting from a long-term contract. Other factors like quality and delivery time are important too. Reputation mechanisms in the system makes cheating not attractive from a long term viewpoint due to multiple encounters among agents. Another major difference between this work and other work on negotiation is that negotiation, here, is not viewed as a stand-alone process. Rather it is one part of the agent 's activity which is tightly interleaved with the planning, scheduling and executing of the agent 's activities, which also may relate to other negotiations. Based on this recognition, this work on negotiation is concerned more about the meta-level decision-making process in negotiation rather than the basic protocols or languages. the negotiations be performed. These macro-strategies are different from those micro-strategies that direct the individual negotiation thread, such as whether the agent should concede and how much the agent should concede, etc -LSB- 3 -RSB-. In this paper we extend a multi-linked negotiation model -LSB- 10 -RSB- from a single-agent perspective to a multi-agent perspective, so that a group of agents involved in chains of interrelated negotiations can find nearly-optimal macro negotiation strategies for pursuing their negotiations. Section 2 describes the basic negotiation process and briefly reviews a single agent 's model of multi-linked negotiation. Section 3 introduces a complex supply-chain scenario. Section 4 details how to solve those problems arising in the negotiation chain. Section 5 reports on the experimental work. Section 6 discusses related work and Section 7 presents conclusions and areas of future work. 2. BACKGROUND ON MULTI-LINKED NEGOTIATION This process can go back and forth until an agreement is reached or the agents decide to stop. If an agreement is reached and one agent can not fulfill the commitment, it needs to pay the other party a decommitment penalty as specified in the commitment. A negotiation starts with a proposal, which announces that a task -LRB- t -RRB- needs to be performed includes the following attributes : 1. deadline -LRB- dl -RRB- : the latest finish time of the task ; the task needs to be finished before the deadline dl. 3. minimum quality requirement -LRB- minq -RRB- : the task needs to be finished with a quality achievement no less than minq. 4. regular reward -LRB- r -RRB- : if the task is finished as the contract requested, the contractor agent will get reward r. 5. early finish reward rate -LRB- e -RRB- : if the contractor agent can finish the task earlier than dl, it will get the extra early finish reward proportional to this rate. 6. The multi-linked negotiation problem has two dimensions : the negotiations, and the subjects of negotiations. The negotiations are interrelated and the subjects are interrelated ; the attributes of negotiations and the attributes of the subjects are interrelated as well. This two-dimensional complexity of interrelationships distinguishes it from the classic project management problem or scheduling problem, where all tasks to be scheduled are local tasks and no negotiation is needed. 1. negotiation duration -LRB- \u03b4 -LRB- v -RRB- -RRB- : the maximum time allowed for negotiation v to complete, either reaching an agreed upon proposal -LRB- success -RRB- or no agreement -LRB- failure -RRB-. 2. negotiation start time -LRB- \u03b1 -LRB- v -RRB- -RRB- : the start time of negotiation v. \u03b1 -LRB- v -RRB- is an attribute that needs to be decided by the agent. 3. negotiation deadline -LRB- e -LRB- v -RRB- -RRB- : negotiation v needs to be finished before this deadline e -LRB- v -RRB-. The negotiation is no longer valid after time e -LRB- v -RRB-, which is the same as a failure outcome of this negotiation. 4. It depends on a set of attributes, including both attributes-in-negotiation -LRB- i.e. reward, flexibility, etc. -RRB- and attributes-of-negotiation -LRB- i.e. negotiation start time, negotiation deadline, etc. -RRB-. An agent involved in multiple related negotiation processes needs to reason on how to manage these negotiations in terms of ordering them and choosing the appropriate values for features. This is the multi-linked negotiation problem -LSB- 10 -RSB- : \u03c1 -LRB- v -RRB- -RRB-, which describes the relationship between negotiation v and its children. The AND relationship associated with a negotiation v means the successful accomplishment of the commitment on v requires all its children nodes have successful accomplishments. The OR relationship associated with a negotiation v means the successful accomplishment of the commitment on v requires at least one child node have successful accomplishment, where the multiple children nodes represent alternatives to accomplish the same goal. Multi-linked negotiation problem is a local optimization problem. To solve a multi-linked negotiation problem is to find a negotiation solution -LRB- 0, \u03d5 -RRB- with optimized expected utility Elf -LRB- 0, \u03d5 -RRB-, which is defined as : A negotiation ordering 0 defines a partial order of all negotiation issues. A feature assignment \u03d5 is a mapping function that assigns a value to each attribute that needs to be decided in the negotiation. A negotiation outcome \u03c7 for a set of negotiations -LCB- vj 1, -LRB- j = 1,..., n -RRB- specifies the result for each negotiation, either success or failure. There are a total of 2n different outcomes for n negotiations : -LCB- chii1, -LRB- i = 1,..., 2n -RRB-. P -LRB- \u03c7i, \u03d5 -RRB- denotes the probability of the outcome \u03c7i given the feature assignment \u03d5, which is calculated based on the success probability of each negotiation. The Sixth Intl.. Joint Conf. Figure 1 : A Complex Negotiation Chain Scenario A heuristic search algorithm -LSB- 10 -RSB- has been developed to solve the single agent 's multi-linked negotiation problem that produces nearly-optimal solutions. This algorithm is used as the core of the decision-making for each individual agent in the negotiation chain scenario. In the rest of the paper, we present our work on how to improve the local solution of a single agent in the global negotiation chain context. 6. RELATED WORK Fatima, Wooldridge and Jennings -LSB- 1 -RSB- studied the multiple issues in negotiation in terms of the agenda and negotiation procedure. However, this work is limited since it only involves a single agent 's perspective without any understanding that the agent may be part of a negotiation chain. Mailler and Lesser -LSB- 4 -RSB- have presented an approach to a distributed resource allocation problem where the negotiation chain scenario occurs. It models the negotiation problem as a distributed constraint optimization problem -LRB- DCOP -RRB- and a cooperative mediation mechanism is used to centralize relevant portions of the DCOP. In our work, the negotiation involves more complicated issues such as reward, penalty and utility ; also, we adopt a distribution approach where no centralized control is needed. A mediator-based partial centralized approach has been applied to the coordination and scheduling of complex task network -LSB- 8 -RSB-, which is different from our work since the system is a complete cooperative system and individual utility of single agent is not concerned at all. A combinatorial auction -LSB- 2, 9 -RSB- could be another approach to solving the negotiation chain problem. However, in a combinatorial auction, the agent does not reason about the ordering of negotiations. This would lead to a problem similar to those we discussed when the same-deadline policy is used. 7. CONCLUSION AND FUTURE WORK In this paper, we have solved negotiation chain problems by extending our multi-linked negotiation model from the perspective of a single agent to multiple agents. Instead of solving the negotiation chain problem in a centralized approach, we adopt a distributed approach where each agent has an extended local model and decisionmaking process. We have introduced a pre-negotiation phase that allows agents to transfer meta-level information on related negotiation issues. Using this information, the agent can build a more accurate model of the negotiation in terms of modeling the relationship of flexibility and success probability. This more accurate model helps the agent in choosing the appropriate negotiation solution. The experimental data shows that these mechanisms improve the agent 's and the system 's overall performance significantly. In future extension of this work, we would like to develop mechanisms to verify how reliable the agents are.", "keyphrases": ["multipl agent", "negoti framework", "negoti chain", "semi-cooper multi-agent system", "pre-negoti", "multi-link negoti", "agent", "distribut set", "multipl concurr task", "virtual organ", "sub-task reloc", "reput mechan", "complex suppli-chain scenario"]}
{"file_name": "I-14", "text": "A Reinforcement Learning based Distributed Search Algorithm For Hierarchical Peer-to-Peer Information Retrieval Systems ABSTRACT The dominant existing routing strategies employed in peerto-peer -LRB- P2P -RRB- based information retrieval -LRB- IR -RRB- systems are similarity-based approaches. In these approaches, agents depend on the content similarity between incoming queries and their direct neighboring agents to direct the distributed search sessions. However, such a heuristic is myopic in that the neighboring agents may not be connected to more relevant agents. In this paper, an online reinforcement-learning based approach is developed to take advantage of the dynamic run-time characteristics of P2P IR systems as represented by information about past search sessions. Specifically, agents maintain estimates on the downstream agents ' abilities to provide relevant documents for incoming queries. These estimates are updated gradually by learning from the feedback information returned from previous search sessions. Based on this information, the agents derive corresponding routing policies. Thereafter, these agents route the queries based on the learned policies and update the estimates based on the new routing policies. Experimental results demonstrate that the learning algorithm improves considerably the routing performance on two test collection sets that have been used in a variety of distributed IR studies. 1. INTRODUCTION Over the last few years there have been increasing interests in studying how to control the search processes in peer-to-peer -LRB- P2P -RRB- based information retrieval -LRB- IR -RRB- systems -LSB- 6, 13, 14, 15 -RSB-. In this line of research, one of the core problems that concerns researchers is to efficiently route user queries in the network to agents that are in possession of appropriate documents. In the absence of global information, the dominant strategies in addressing this problem are content-similarity based approaches -LSB- 6, 13, 14, 15 -RSB-. While the content similarity between queries and local nodes appears to be a creditable indicator for the number of relevant documents residing on each node, these approaches are limited by a number of factors. Second, the similarity-based approaches do not take into account the run-time characteristics of the P2P IR systems, including environmental parameters, bandwidth usage, and the historical information of the past search sessions, that provide valuable information for the query routing algorithms. In this paper, we develop a reinforcement learning based IR approach for improving the performance of distributed IR search algorithms. Agents can acquire better search strategies by collecting and analyzing feedback information from previous search sessions. Particularly, agents maintain estimates, namely expected utility, on the downstream agents ' capabilities of providing relevant documents for specific types of incoming queries. These estimates are updated gradually by learning from the feedback information returned from previous search sessions. Based on the updated expected utility information, the agents derive corresponding routing policies. Thereafter, these agents route the queries based on the learned policies and update the estimates on the expected utility based on the new routing policies. This process is conducted in an iterative manner. The goal of the learning algorithm, even though it consumes some network bandwidth, is to shorten the routing time so that more queries are processed per time unit while at the same time finding more relevant documents. This contrasts with the content-similarity based approaches where similar operations are repeated for every incoming query and the processing time keeps largely constant over time. Another way of viewing this paper is that our basic approach to distributed IR search is to construct a hierarchical overlay network -LRB- agent organization -RRB- based on the contentsimilarity measure among agents ' document collections in a bottom-up fashion. In the past work, we have shown that this organization improves search performance significantly. The intention of the reinforcement learning is to adapt the agents ' routing decisions to the dynamic network situations and learn from past search sessions. Specifically, the contributions of this paper include : -LRB- 1 -RRB- a reinforcement learning based approach for agents to acquire satisfactory routing policies based on estimates of the potential contribution of their neighboring agents ; -LRB- 2 -RRB- two strategies to speed up the learning process. The remainder of this paper is organized as follows : Section 2 reviews the hierarchical content sharing systems and the two-phase search algorithm based on such topology. Section 3 describes a reinforcement learning based approach to direct the routing process ; Section 4 details the experimental settings and analyze the results. Section 5 discusses related studies and Section 6 concludes the paper. 5. RELATED WORK The content routing problem differs from the networklevel routing in packet-switched communication networks in that content-based routing occurs in application-level networks. In addition, the destination agents in our contentrouting algorithms are multiple and the addresses are not known in the routing process. IP-level Routing problems have been attacked from the reinforcement learning perspective -LSB- 2, 5, 11, 12 -RSB-. There are two major classes of adaptive, distributed packet routing algorithms in the literature : distance-vector algorithms and link-state algorithms. While this line of studies carry a certain similarity with our work, it has mainly focused on packet-switched communication networks. Each agent maintains estimations, probabilistically or deterministically, on the distance to a certain destination through its neighbors. A variant of Q-Learning techniques is deployed The Sixth Intl.. Joint Conf. to update the estimations to converge to the real distances. It has been discovered that the locality property is an important feature of information retrieval systems in user modeling studies -LSB- 3 -RSB-. The learning based approach is perceived to be more beneficial for real distributed information retrieval systems which exhibit locality property. This is because the users ' traffic and query patterns can reduce the state space and speed up the learning process. Related work in taking advantage of this property include -LSB- 7 -RSB-, where the authors attempted to address this problem by user modeling techniques. 6. CONCLUSIONS In this paper, a reinforcement-learning based approach is developed to improve the performance of distributed IR search algorithms. Particularly, agents maintain estimates, namely expected utility, on the downstream agents ' ability to provide relevant documents for incoming queries. These estimates are updated gradually by learning from the feedback information returned from previous search sessions. Based on the updated expected utility information, the agents modify their routing policies. Thereafter, these agents route the queries based on the learned policies and update the estimates on the expected utility based on the new routing policies. The experiments on two different distributed IR datasets illustrates that the reinforcement learning approach improves considerably the cumulative utility over time.", "keyphrases": ["peer-to-peer inform retriev system", "reinforc learn", "distribut search algorithm", "rout decis", "util", "network", "learn algorithm", "rout polici", "queri"]}
{"file_name": "C-23", "text": "Implementation of a Dynamic Adjustment Mechanism with Efficient Replica Selection in Data Grid Environments ABSTRACT The co-allocation architecture was developed in order to enable parallel downloading of datasets from multiple servers. Several co-allocation strategies have been coupled and used to exploit rate differences among various client-server links and to address dynamic rate fluctuations by dividing files into multiple blocks of equal sizes. However, a major obstacle, the idle time of faster servers having to wait for the slowest server to deliver the final block, makes it important to reduce differences in finishing time among replica servers. In this paper, we propose a dynamic coallocation scheme, namely Recursive-Adjustment Co-Allocation scheme, to improve the performance of data transfer in Data Grids. Our approach reduces the idle time spent waiting for the slowest server and decreases data transfer completion time. We also provide an effective scheme for reducing the cost of reassembling data blocks. 1. INTRODUCTION Data Grids aggregate distributed resources for solving large-size dataset management problems. Most Data Grid applications execute simultaneously and access large numbers of data files in the Grid environment. Certain data-intensive scientific applications, such as high-energy physics, bioinformatics applications and virtual astrophysical observatories, entail huge amounts of data that require data file management systems to replicate files and manage data transfers and distributed data access. Downloading large datasets from several replica locations may result in varied performance rates, because the replica sites may have different architectures, system loadings, and network connectivity. One way to improve download speeds is to determine the best replica locations using replica selection techniques -LSB- 19 -RSB-. This method selects the best servers to provide optimum transfer rates because bandwidth quality can vary unpredictably due to the sharing nature of the internet. Another way is to use co-allocation technology -LSB- 17 -RSB- to download data. Co-allocation of data transfers enables the clients to download data from multiple locations by establishing multiple connections in parallel. Several co-allocation strategies were provided in previous work -LSB- 17 -RSB-. An idle-time drawback remains since faster servers must wait for the slowest server to deliver its final block. Therefore, it is important to reduce the differences in finishing time among replica servers. In this paper, we propose a dynamic co-allocation scheme based on co-allocation Grid data transfer architecture called RecursiveAdjustment Co-Allocation scheme that reduces the idle time spent waiting for the slowest server and improves data transfer performance -LSB- 24 -RSB-. Experimental results show that our approach is superior to previous methods and achieved the best overall performance. We also discuss combination cost and provide an effective scheme for reducing it. Related background review and studies are presented in Section 2 and the co-allocation architecture and related work are introduced in Section 3. In Section 4, an efficient replica selection service is proposed by us. Our research approaches are outlined in Section 5, and experimental results and a performance evaluation of our scheme are presented in Section 6. Section 7 concludes this research paper. 2. BACKGROUND 2.1 Data Grid Data Grids -LSB- 1, 2, 16 -RSB- federate a lot of storage resources. Large collections of measured or computed data are emerging as important resources in many data intensive applications. 2.1.1 Replica Management Replica management involves creating or removing replicas at a data grid site -LSB- 19 -RSB-. In other words, the role of a replica manager is to create or delete replicas, within specified storage systems. Most often, these replicas are exact copies of the original files, created only to harness certain performance benefits. A replica manager typically maintains a replica catalog containing replica site addresses and the file instances. The replica management service is responsible for managing the replication of complete and partial copies of datasets, defined as collections of files. The replica management service is just one component in a Data Grid environment that provides support for high-performance, data-intensive applications. A replica or location is a subset of a collection that is stored on a particular physical storage system. There may be multiple possibly overlapping subsets of a collection stored on multiple storage systems in a Data Grid. These Grid storage systems may use a variety of underlying storage technologies and data movement protocols, which are independent of replica management. 2.1.2 Replica Catalog As mentioned above, the purpose of the replica catalog is to provide mappings between logical names for files or collections and one or more copies of the objects on physical storage systems. The replica catalog includes optional entries that describe individual logical files. Logical files are entities with globally unique names that may have one or more physical instances. The catalog may optionally contain one logical file entry in the replica catalog for each logical file in a collection. A Data Grid may contain multiple replica catalogs. For example, a community of researchers interested in a particular research topic might maintain a replica catalog for a collection of data sets of mutual interest. It is possible to create hierarchies of replica catalogs to impose a directory-like structure on related logical collections. In addition, the replica manager can perform access control on entire catalogs as well as on individual logical files. 2.1.3 Replica Selection The purpose of replica selection -LSB- 16 -RSB- is to select a replica from among the sites which constitute a Data Grid -LSB- 19 -RSB-. The criteria of selection depend on characteristics of the application. By using this mechanism, users of the Data Grid can easily manage replicas of data sets at their sites, with better performance. Much previous effort has been devoted to the replica selection problem. The common process of replica selection consists of three steps : data preparation, preprocessing and prediction. Then, applications can select a replica according to its specific attributes. Replica selection is important to data-intensive applications, and it can provide location transparency. When a user requests for accessing a data set, the system determines an appropriate way to deliver the replica to the user. 2.2 Globus Toolkit and GridFTP The Globus Project -LSB- 9, 11, 16 -RSB- provides software tools collectively called The Globus Toolkit that makes it easier to build computational Grids and Grid-based applications. Many organizations use the Globus Toolkit to build computational Grids to support their applications. The composition of the Globus Toolkit can be pictured as three pillars : Resource Management, Information Services, and Data Management. GRAM implements a resource management protocol, MDS implements an information services protocol, and GridFTP implements a data transfer protocol. The Globus alliance proposed a common data transfer and access protocol called GridFTP that provides secure, efficient data movement in Grid environments -LSB- 3 -RSB-. This protocol, which extends the standard FTP protocol, provides a superset of the features offered by the various Grid storage systems currently in use. In order to solve the appearing problems, the Data Grid community tries to develop a secure, efficient data transport mechanism and replica management services. GridFTP is a reliable, secure and efficient data transport protocol which is developed as a part of the Globus project. There is another key technology from Globus project, called replica catalog -LSB- 16 -RSB- which is used to register and manage complete and partial copies of data sets. The replica catalog contains the mapping information from a logical file or collection to one or more physical files. 2.3 Network Weather Service The Network Weather Service -LRB- NWS -RRB- -LSB- 22 -RSB- is a generalized and distributed monitoring system for producing short-term performance forecasts based on historical performance measurements. The goal of the system is to dynamically characterize and forecast the performance deliverable at the application level from a set of network and computational resources. 2.4 Sysstat Utilities The Sysstat -LSB- 15 -RSB- utilities are a collection of performance monitoring tools for the Linux OS. The Sysstat package incorporates the sar, mpstat, and iostat commands. The sar command collects and reports system activity information, which can also be saved in a system activity file for future inspection. The iostat command reports CPU statistics and I/O statistics for tty devices and disks. 7. CONCLUSIONS The co-allocation architecture provides a coordinated agent for assigning data blocks. A previous work showed that the dynamic co-allocation scheme leads to performance improvements. However, it can not handle the idle time of faster servers, which must wait for the slowest server to deliver its final block. We proposed the Recursive-Adjustment Co-Allocation scheme to improve data transfer performances using the co-allocation architecture in -LSB- 17 -RSB-. In this approach, the workloads of selected replica servers are continuously adjusted during data transfers, and we provide a function that enables users to define a final block threshold, according to their data grid environment. Experimental results show the effectiveness of our proposed technique in improving transfer time and reducing overall idle time spent waiting for the slowest server. We also discussed the re-combination cost and provided an effective scheme for reducing it.", "keyphrases": ["distribut resourc", "data grid applic", "replic", "co-alloc", "larg dataset", "resourc manag protocol", "replica", "co-alloc strategi", "server", "perform"]}
{"file_name": "J-28", "text": "Approximately-Strategyproof and Tractable Multi-Unit Auctions ABSTRACT We present an approximately-efficient and approximatelystrategyproof auction mechanism for a single-good multi-unit allocation problem. The bidding language in our auctions allows marginal-decreasing piecewise constant curves. First, we develop a fully polynomial-time approximation scheme for the multi-unit allocation problem, which computes a -LRB- 1 + e -RRB- approximation in worst-case time T = O -LRB- n3/e -RRB-, given n bids each with a constant number of pieces. Second, we embed this approximation scheme within a Vickrey-Clarke-Groves -LRB- VCG -RRB- mechanism and compute payments to n agents for an asymptotic cost of O -LRB- T log n -RRB-. The maximal possible gain from manipulation to a bidder in the combined scheme is bounded by e / -LRB- 1 + e -RRB- V, where V is the total surplus in the efficient outcome. 1. INTRODUCTION In this paper we present a fully polynomial-time approximation scheme for the single-good multi-unit auction problem. Our scheme is both approximately efficient and approximately strategyproof. The auction settings considered in our paper are motivated by recent trends in electronic commerce ; for instance, corporations are increasingly using auctions for their strategic sourcing. We consider both a reverse auction variation and a forward auction variation, and propose a compact and expressive bidding language that allows marginal-decreasing piecewise constant curves. In the reverse auction, we consider a single buyer with a demand for M units of a good and n suppliers, each with a marginal-decreasing piecewise-constant cost function. In addition, each supplier can also express an upper bound, or capacity constraint on the number of units she can supply. The reverse variation models, for example, a procurement auction to obtain raw materials or other services -LRB- e.g. circuit boards, power suppliers, toner cartridges -RRB-, with flexible-sized lots. In the forward auction, we consider a single seller with M units of a good and n buyers, each with a marginal-decreasing piecewise-constant valuation function. A buyer can also express a lower bound, or minimum lot size, on the number of units she demands. The forward variation models, for example, an auction to sell excess inventory in flexible-sized lots. We consider the computational complexity of implementing the Vickrey-Clarke-Groves -LSB- 22, 5, 11 -RSB- mechanism for the multiunit auction problem. The Vickrey-Clarke-Groves -LRB- VCG -RRB- mechanism has a number of interesting economic properties in this setting, including strategyproofness, such that truthful bidding is a dominant strategy for buyers in the forward auction and sellers in the reverse auction, and allocative efficiency, such that the outcome maximizes the total surplus in the system. However, as we discuss in Section 2, the application of the VCG-based approach is limited in the reverse direction to instances in which the total payments to the sellers are less than the value of the outcome to the buyer. Otherwise, either the auction must run at a loss in these instances, or the buyer can not be expected to voluntarily choose to participate. This is an example of the budget-deficit problem that often occurs in efficient mechanism design -LSB- 17 -RSB-. The computational problem is interesting, because even with marginal-decreasing bid curves, the underlying allocation problem turns out to -LRB- weakly -RRB- intractable. For instance, the classic 0/1 knapsack is a special case of this problem.1 We model the 1However, the problem can be solved easily by a greedy scheme if we remove all capacity constraints from the seller and all allocation problem as a novel and interesting generalization of the classic knapsack problem, and develop a fully polynomialtime approximation scheme, computing a -LRB- 1 + ~ -RRB- - approximation in worst-case time T = O -LRB- n3 / \u03b5 -RRB-, where each bid has a fixed number of piecewise constant pieces. Given this scheme, a straightforward computation of the VCG payments to all n agents requires time O -LRB- nT -RRB-. This upper-bound tends to 1 as the number of sellers increases. The approximate VCG mechanism is -LRB- \u03b5 1 + \u03b5 -RRB- - strategyproof for an approximation to within -LRB- 1 + ~ -RRB- of the optimal allocation. This means that a bidder can gain at most -LRB- \u03b5 1 + \u03b5 -RRB- V from a nontruthful bid, where V is the total surplus from the efficient allocation. Section 2 formally defines the forward and reverse auctions, and defines the VCG mechanisms. We also prove our claims about \u03b5-strategyproofness. Section 3 provides the generalized knapsack formulation for the multi-unit allocation problems and introduces the fully polynomial time approximation scheme. Section 4 defines the approximation scheme for the payments in the VCG mechanism. Section 5 concludes. 1.1 Related Work There has been considerable interest in recent years in characterizing polynomial-time or approximable special cases of the general combinatorial allocation problem, in which there are multiple different items. The combinatorial allocation problem -LRB- CAP -RRB- is both NP-complete and inapproximable -LRB- e.g. -LSB- 6 -RSB- -RRB-. We identify a non-trivial but approximable allocation problem with an expressive exclusiveor bidding language -- the bid taker in our setting is allowed to accept at most one point on the bid curve. The idea of using approximations within mechanisms, while retaining either full-strategyproofness or \u03b5-dominance has received some previous attention. For instance, Lehmann et al. -LSB- 15 -RSB- propose a greedy and strategyproof approximation to a single-minded combinatorial auction problem. Feigenminimum-lot size constraints from the buyers. baum & Shenker -LSB- 8 -RSB- have defined the concept of strategically faithful approximations, and proposed the study of approximations as an important direction for algorithmic mechanism design. Eso et al. -LSB- 7 -RSB- have studied a similar procurement problem, but for a different volume discount model. This earlier work formulates the problem as a general mixed integer linear program, and gives some empirical results on simulated data. Kalagnanam et al. -LSB- 12 -RSB- address double auctions, where multiple buyers and sellers trade a divisible good. The focus of this paper is also different : it investigates the equilibrium prices using the demand and supply curves, whereas our focus is on efficient mechanism design. Ausubel -LSB- 1 -RSB- has proposed an ascending-price multi-unit auction for buyers with marginal-decreasing values -LSB- 1 -RSB-, with an interpretation as a primal-dual algorithm -LSB- 2 -RSB-. 5. CONCLUSIONS We presented a fully polynomial-time approximation scheme for the single-good multi-unit auction problem, using marginal decreasing piecewise constant bidding language. Our scheme is both approximately efficient and approximately strategyproof within any specified factor \u03b5 > 0. As such it is an example of computationally tractable \u03b5-dominance result, as well as an example of a non-trivial but approximable allocation problem. It is particularly interesting that we are able to compute the payments to n agents in a VCG-based mechanism in worst-case time O -LRB- T log n -RRB-, where T is the time complexity to compute the solution to a single allocation problem.", "keyphrases": ["approxim-effici and approximatelystrategyproof auction mechan", "singl-good multi-unit alloc problem", "fulli polynomi-time approxim scheme", "vickrei-clark-grove", "forward auction", "revers auction", "equilibrium", "margin-decreas piecewis constant curv", "bid languag", "dynam program"]}
{"file_name": "C-40", "text": "Edge Indexing in a Grid for Highly Dynamic Virtual Environments \u2217 ABSTRACT Newly emerging game -- based application systems such as Second Life1 provide 3D virtual environments where multiple users interact with each other in real -- time. They are filled with autonomous, mutable virtual content which is continuously augmented by the users. To make the systems highly scalable and dynamically extensible, they are usually built on a client -- server based grid subspace division where the virtual worlds are partitioned into manageable sub -- worlds. In each sub -- world, the user continuously receives relevant geometry updates of moving objects from remotely connected servers and renders them according to her viewpoint, rather than retrieving them from a local storage medium. In such systems, the determination of the set of objects that are visible from a user 's viewpoint is one of the primary factors that affect server throughput and scalability. Specifically, performing real -- time visibility tests in extremely dynamic virtual environments is a very challenging task as millions of objects and sub-millions of active users are moving and interacting. We recognize that the described challenges are closely related to a spatial database problem, and hence we map the moving geometry objects in the virtual space to a set of multi-dimensional objects in a spatial database while modeling each avatar both as a spatial object and a moving query. Unfortunately, existing spatial indexing methods are unsuitable for this kind of new environments. The main goal of this paper is to present an efficient spatial index structure that minimizes unexpected object popping and supports highly scalable real -- time visibility determination. We then uncover many useful properties of this structure and compare the index structure with various spatial indexing methods in terms of query quality, system throughput, and resource utilization. We expect our approach to lay the groundwork for next -- generation virtual frameworks that may merge into existing web -- based services in the near future. \u2217 This research has been funded in part by NSF grants EEC9529152 -LRB- IMSC ERC -RRB- and IIS-0534761, and equipment gifts from Intel Corporation, Hewlett-Packard, Sun Microsystems and Raptor Networks Technology. Categories and Subject Descriptors : C. 2.4 -LSB- Computer -- Com 1. INTRODUCTION Recently, Massively Multiplayer Online Games -LRB- MMOGs -RRB- have been studied as a framework for next -- generation virtual environments. In this paper, we mainly focus on the first two requirements. Dynamic extensibility allows regular game -- users to deploy their own created content. This is a powerful concept, but unfortunately, user -- created content tends to create imbalances among the existing scene complexity, causing system -- wide performance problems. Another important requirement is scalability. By carefully partitioning the world into multiple sub -- worlds or replicating worlds at geographically dispersed locations, massive numbers of concurrent users can be supported. Second Life -LSB- 4 -RSB- is the first successfully deployed MMOG system that meets both requirements. But we acknowledge that these requirements are also valid for new virtual environments. Figure 1 : Object popping occurred as a user moves forward -LRB- screenshots from Second Life -RRB- where \u0394 = 2 seconds. employs a client/server based 3D object streaming model -LSB- 5 -RSB-. In this model, a server continuously transmits both update events and geometry data to every connected user. As a result, this extensible gaming environment has accelerated the deployment of user -- created content and provides users with unlimited freedom to pursue a navigational experience in its space. One of the main operations in MMOG applications that stream 3D objects is to accurately calculate all objects that are visible to a user. The traditional visibility determination approach, however, has an object popping problem. For example, a house outside a user 's visible range is not drawn at time t, illustrated in Figure 1 -LRB- a -RRB-. As the user moves forward, the house will suddenly appear at time -LRB- t + \u0394 -RRB- as shown in Figure 1 -LRB- b -RRB-. The visibility calculation for each user not only needs to be accurate, but also fast. This challenge is illustrated by the fact that the maximum number of concurrent users per server of Second Life is still an order of magnitude smaller than for stationary worlds. To address these challenges, we propose a method that identifies the most relevant visible objects from a given geometry database -LRB- view model -RRB- and then put forth a fast indexing method that computes the visible objects for each user -LRB- spatial indexing -RRB-. Our two novel methods represent the main contributions of this work. Section 2 presents related work. Section 3 describes our new view method. In Section 4, we present assumptions on our target application and introduce a new spatial indexing method designed to support real -- time visibility computations. We also discuss its optimization issues. Section 5 reports on the quantitative analysis and Section 6 presents preliminary results of our simulation based experiments. Finally, we conclude and address future research directions in Section 7. 2. RELATED WORK Visibility determination has been widely explored in the field of 3D graphics. Various local rendering algorithms have been proposed to eliminate unnecessary objects before rendering or at any stage in the rendering pipeline. However, these algorithms assume that all the candidate visible objects have been stored locally. If the target objects are stored on remote servers, the clients receive the geometry items that are necessary for rendering from the server databases. However, these online optimization algorithms fail to address performance issue at the server in highly crowded environments. On the other hand, our visibility computation model, a representative of this category, is based on different assumptions on the data representation of virtual entities. In the graphics area, there has been little work on supporting real -- time visibility computations for a massive number of moving objects and users. Here we recognize that such graphics related issues have a very close similarity to spatial database problems. Recently, a number of publications have addressed the scalability issue on how to support massive numbers of objects and queries in highly dynamic environments. To support frequent updates, two partitioning policies have been studied in depth : -LRB- 1 -RRB- R-tree based spatial indexing, and -LRB- 2 -RRB- grid -- based spatial indexing. The grid -- based partitioning model is a special case of fixed partitioning. Recently, it has been re -- discovered since it can be efficient in highly dynamic environments. Q-Index -LSB- 13, 11 -RSB- is one of the earlier work that re -- discovers the usefulness of grid -- based space partitioning for emerging moving object environments. In contrast to traditional spatial indexing methods that construct an index on the moving objects, it builds an index on the continuous range queries, assuming that the queries move infrequently while the objects move freely. The basic idea of the Q+R tree -LSB- 14 -RSB- is to separate indexing structures for quasi -- stationary objects and moving objects : fast -- moving objects are indexed in a Quadtree and quasi -- stationary objects are stored in an R \u2217 - tree. SINA -LSB- 10 -RSB- was proposed to provide efficient query evaluations for any combination of stationary/moving objects and stationary/moving queries. Specifically, this approach only detects newly discovered -LRB- positive -RRB- or no longer relevant -LRB- negative -RRB- object updates efficiently. Unlike other spatial indexing methods that focus on reducing the query evaluation cost, Hu et al. -LSB- 12 -RSB- proposed a general framework that minimizes the communication cost for location updates by maintaining a rectangular area called a safe region around moving objects. As long as any object resides in this region, all the query results are guaranteed to be valid in the system. If objects move out of their region, location update requests should be delivered to the database server and the affected queries are re -- evaluated on the fly. Our indexing method is very similar to the above approaches. The major difference is that we are more concentrating on real -- time visibility determination while others assume loose timing constraints. 6. EVALUATION This section presents two simulation setups and their performance results. Section 6.1 examines whether our new view approach is superior to existing view models, in spite of its higher indexing complexity. Section 6.2 discusses the degree of practicality and scalability of our indexing method that is designed for our new view model. 6.1 Justification of Object-initiated View Model 6.1.1 Evaluation Metrics P is the ratio of relevant, retrieved items to all retrieved items. A lower value of P implies that the query result set contains a large number of unnecessary objects that do not have to be delivered to a client. A higher P value means a higher network traffic load than required. R is the ratio of relevant, retrieved items to all relevant items. A lower R value means that more objects that should be recognized are ignored. From the R measure, we can quantitatively estimate the occurrence of object popping. In addition to the P and R metrics, we use a standardized single -- valued query evaluation metric that combines P and R, called E -- measure -LSB- 15 -RSB-. The E -- measure is defined as : If \u03b2 is less than 1, P becomes more important. Otherwise, R will affect the E -- measure significantly. A lower E -- measure value implies that the tested view model has a higher quality. The best E -- measure value is zero, where the best values for P and R are both ones. 6.1.2 Simulation Setup We tested four query processing schemes, which use either a user -- initiated or an object -- initiated view model : \u2022 User-initiated visibility computation -- RQ -- OP : Region Query -- Object Point \u2022 Object-oriented visibility computation -- PQ-OR : Point Query -- Object Region -- RQ-OR : Region Query -- Object Region -- ACQ-OR : Approximate Cell Query -- Object Region RQ -- OP is the typical computation scheme that collects all objects whose location is inside a user defined AOI. PQ -- OR collects a set of objects whose AOI intersects with a given user point, formally -LCB- o | q.P \u2208 o.R -RCB-. RQ -- OR, an imaginary computation scheme, is the combination of RQ -- OP and PQ -- OR where the AOI of an object intersects with that of a user, -LCB- o | o.R \u2229 q.R = ~ \u2205 -RCB-. Lastly, ACQ -- OR, an approximate visibility computation model, is a special scheme designed for grid -- based space partitioning, which is our choice of cell evaluation methodology for edge indexing. If a virtual space is partitioned into tiled cells and a user point belongs to one of the cells, the ACQ -- OR searches the objects whose AOI Table 5 : P and R computations of different visibility determination schemes. Table 6 : Measured elapsed time -LRB- seconds -RRB- of 100K moving objects and 10K moving users in a slowly moving environment would intersect with the region of the corresponding grid cell. It identifies any object o satisfying the condition c.R n o.R _ ~ 0 where the cell c satisfies q.P E c.R as well. Our simulation program populated 100K object entities and 10K user entities in a 2D unit space, -LSB- 0, 1 -RRB- x -LSB- 0, 1 -RRB-. The populated entities are uniformly located in the unit space. The program performs intersection tests between all user and all object entities exhaustively and computes the P, R, and E -- measure values -LRB- shown in Table 5 -RRB-. 6.1.3 Experimental Results Distribution of P and R measure : Figure 7 shows the distribution of P and R for RQ -- OP. We can observe that P and R are roughly inversely proportional to each other when varying a user AOI range. A smaller side length leads to higher accuracy but lower comprehensiveness. For example, 5 % of the side length of a user AOI detects all objects whose side length of the AOI is at least 5 %. Thus, every object retrieved by RQ -- OP is guaranteed to be all rendered at the client. But RQ -- OP can not detect the objects outside the AOI of the user, thus suffering from too many missing objects that should be rendered. Similarly, the user whose AOI is wider than any other AOI can not miss any objects that should be rendered, but detects too many unnecessary objects. To remove any object popping problem, the side length of any AOI should be greater than or equal to the maximum visible distance of any object in the system, which may incur significant system degradation. E-measure Distribution : Figure 8 reveals two trends. First, the precision values of RQ -- OP lie in between those of ACQ -- OR -LRB- 100 x 100 grid -RRB- and RQ -- OR. Second, the tendency curve of the Precision -- to -- E -- measure plot of RQ -- OR shows resemblance to that of ACQ -- OR. Effect of Different Grid Size : Figure 9 shows the statistical difference of E -- measure values of seven different grid partitioning schemes -LRB- using ACQ -- OR -RRB- and one RQ -- OP model. We use a box -- and -- whisker plot to show both median values and the variances of E-measure distributions and the outliers of each scheme. We also draw the median value of the RQ -- OP E -- measures -LRB- green line -RRB- for comparison purposes. While the ACQ -- OR schemes have some outliers, their E-measure values are heavily concentrated around the median values, thus, they are less sensitive to object AOI. As expected, fine-grained grid partitioning showed a smaller E-measure value. The RQ -- OP scheme showed a wider variance of its quality than other schemes, which is largely attributable to different user side lengths. As the R measure becomes more important, the query quality of ACQ -- OR is improved more evidently than that of RQ -- OP. From Figure 9, the 20x20 grid scheme had a better E-measure Table 7 : Measured elapsed time -LRB- seconds -RRB- of 100K moving objects and 10K moving users in a highly dynamic environment -LRB- value in a prioritized environment than in an equal-prioritized environment. As a result, we can roughly anticipate that at least the 20x20 grid cell partitioning retrieves a higher quality of visible sets than the RQ -- OP. 6.2 Evaluation of Edge Indexing In this section, we present the preliminary results of the simulations that examine the applicability of our edge indexing implementation. To estimate the degree of real -- time support of our indexing method, we used the total elapsed time of updating all moving entities and computing visible sets for every cell. We also experimented with different grid partitioning policies and compared them with exhaustive search solutions. 6.2.1 Simulation Setup We implemented edge indexing algorithms in C and ran the experiments on a 64-bit 900MHz Itanium processor with 8 GBs of memory. We implemented a generalized hash table mechanism to store node and edge structures. 6.2.2 Experimental Results Periodic Monitoring Cost : Tables 6 and 7 show the performance numbers of different edge indexing methods by varying v. The moving speed of entities was also uniformly assigned between 0 and v. However, the two -- table method showed a slightly higher evaluation time than the two single -- table methods because of its sequential token removal. Table 7 exemplified the elapsed time of index updates and cell evaluations in a highly dynamic environment where slowly moving and dynamically moving objects co -- exist. Compared with the results shown in Table 6, the two -- table approach produced similar performance numbers regardless of the underlying moving environments. However, the performance gain obtained by the incremental policy of the single -- table is decreased compared with that in the slowly moving environment. Effect of Different Grid Size : How many object updates and cell evaluations can be supported in a given time period is an important performance metric to quantify system throughput. In this section, we evaluate the performance results of three different visibility computation models : two computation -- driven exhaustive search methods ; and one two -- table edge indexing method with different grid sizes. Figure 7 : Distribution of P and R measured by RQ -- OP. Figure 8 : E -- measure value as a function of Figure 9 : E -- measure value as a function of ACQ -- QR grid partitioning scheme when Figure 10 : Total elapsed time of different indexing schemes. Exhaustive search methods do not maintain any intermediate results. They simply compute whether a given user point is inside a given object AOI. They can tolerate unpredictable behavior of object movement. Figure 10 reveals the performance difference between the exhaustive solutions and the two -- table methods, a difference of up to two orders of magnitude. As shown in Section 5, the total elapsed time of object updates and cell evaluations is linear with respect to the average side length of object AOI. Because the side length is represented by cell units, an increase in the number of cells increases the side lengths proportionally. Figure 10 illustrates that the measured simulation results roughly match the expected performance gain computed from the analysis. 7. CONCLUSION AND FUTURE WORK To support dynamic extensibility and scalability in highly dynamic environments, we proposed a new view paradigm, the object-initiated view model, and its efficient indexing method, edge indexing. Compared with the traditional view model, our new view model promises to eliminate any object popping problem that can easily be observed in existing virtual environments at the expense of increased indexing complexity. Our edge indexing model, however, can overcome such higher indexing complexity by indexing spatial extensions at edge -- level not at node -- level in a grid partitioned sub -- world and was validated through quantitative analyses and simulations. However, for now our edge indexing still retains a higher complexity, even in a two -- dimensional domain. Currently, we are developing another edge indexing method to make the indexing complexity constant. Once indexing complexity becomes constant, we plan to index 3D spatial extensions and multi -- resolutional geometry data. We expect that our edge indexing can contribute to successful deployment of next -- generation gaming environments.", "keyphrases": ["edg index", "dynam virtual environ", "game-base applic", "mutabl virtual content", "spatial databas", "spatial index method", "real-time visibl test", "object-initi view model", "object pop", "3d spatial extens"]}
{"file_name": "C-86", "text": "Addressing Strategic Behavior in a Deployed Microeconomic Resource Allocator ABSTRACT While market-based systems have long been proposed as solutions for distributed resource allocation, few have been deployed for production use in real computer systems. Towards this end, we present our initial experience using Mirage, a microeconomic resource allocation system based on a repeated combinatorial auction. Mirage allocates time on a heavily-used 148-node wireless sensor network testbed. In particular, we focus on observed strategic user behavior over a four-month period in which 312,148 node hours were allocated across 11 research projects. Based on these results, we present a set of key challenges for market-based resource allocation systems based on repeated combinatorial auctions. Finally, we propose refinements to the system 's current auction scheme to mitigate the strategies observed to date and also comment on some initial steps toward building an approximately strategyproof repeated combinatorial auction. 1. INTRODUCTION Market-based systems have long been proposed as solutions for resource allocation in distributed systems including computational Grids -LSB- 2, 20 -RSB-, wide-area network testbeds -LSB- 9 -RSB-, and peer-to-peer systems -LSB- 17 -RSB-. Yet, while the theoretical underpinnings of market-based schemes have made significant strides in recent years, practical integration of market-based mechanisms into real computer systems and empirical observations of such systems under real workloads has remained an elusive goal. Towards this end, we have designed, implemented, and deployed a microeconomic resource allocation system called Mirage -LSB- 3 -RSB- for scheduling testbed time on a 148-node wireless sensor network -LRB- SensorNet -RRB- testbed at Intel Research. The system, which employs a repeated combinatorial auction -LSB- 5, 14 -RSB- to schedule allocations, has been in production use for over four months and has scheduled over 312,148 node hours across 11 research projects to date. In designing and deploying Mirage, we had three primary goals. First, we wanted to validate whether a market-based resource allocation scheme was necessary at all. An economic problem only exists when resources are scarce. Therefore, a key goal was to first measure both resource contention and the range of underlying valuations users place on the resources during periods of resource scarcity. Second, we wanted to observe how users would actually behave in a market-based environment. With Mirage, we wanted to observe to what extent rationality held and in what ways users would attempt to strategize and game the system. Finally, we wanted to identify what other practical problems would emerge in a deployment of a market based system. In this paper, we report briefly on our first goal while focusing primarily on the second. In deploying Mirage, we made the early decision to base the system on a repeated combinatorial auction known not to be strategyproof. That is, self-interested users could attempt to increase their personal gain, at the expense of others, by not revealing their true value to the system. We made this decision mainly because designing a strategyproof mechanism remains an open, challenging problem and we wanted to deploy a working system and gain experience with real users to address our three goals in a timely manner. Deploying a non-strategyproof mechanism also had the benefit of testing rationality and seeing how and to what extent users would try to game the system. The key contribution of this paper is an analysis of such strategic behavior as observed over a four-month time period and proposed refinements for mitigating such behavior en route to building an approximately strategyproof repeated combinatorial auction. The rest of this paper is organized as follows. In Section 2, we present an overview of Mirage including high-level observations on usage over a four-month period. In Section 3, we examine strategic user behavior, focusing on the four primary types of strategies employed by users in the system. Based on these results, Section 4 presents a set of key challenges for market-based resource allocation systems based on repeated combinatorial auctions. As a first step in addressing some of these challenges, we describe refinements to Mirage 's current auction scheme that mitigate the strategies observed to date and also comment on some initial steps towards building an approximately strategyproof repeated combinatorial auction for Mirage. Finally, in Section 5, we conclude the paper. 5. CONCLUSION Despite initially using a repeated combinatorial auction known not to be strategyproof, Mirage has shown significant promise as a vehicle for SensorNet testbed allocation. Fully realizing these gains, however, requires addressing key problems in strategyproof mechanism design and combinatorial optimization. The temporal nature of computational resources and the combinatorial resource demands of distributed applications adds an additional layer of complexity.", "keyphrases": ["resourc alloc system", "combinatori auction", "market-base system", "distribut system", "strateg behavior", "ration", "auction-base scheme", "mirag system", "sensornet testb", "node-hour price", "usabl overhead", "batch schedul", "distribut applic"]}
