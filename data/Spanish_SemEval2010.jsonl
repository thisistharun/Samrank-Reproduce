{"file_name": "C-38", "text": "Un marco para dise\u00f1ar superposiciones dirigidas por receptor de igual a igual RESUMEN Este art\u00edculo presenta un marco simple y escalable para dise\u00f1ar superposiciones de igual a igual llamado Superposici\u00f3n impulsada por receptor de igual a igual -LRB- o PRO -RRB-. PRO est\u00e1 dise\u00f1ado para aplicaciones de streaming no interactivas y su principal objetivo de dise\u00f1o es maximizar el ancho de banda entregado -LRB- y, por lo tanto, la calidad entregada -RRB- a pares con ancho de banda heterog\u00e9neo y asim\u00e9trico. Para lograr este objetivo, PRO adopta un enfoque impulsado por el receptor donde cada receptor -LRB- o par participante -RRB- -LRB- i -RRB- descubre de forma independiente a otros pares en la superposici\u00f3n a trav\u00e9s de chismes, y -LRB- ii -RRB- ego\u00edstamente. determina el mejor subconjunto de pares principales a trav\u00e9s del cual conectarse a la superposici\u00f3n para maximizar su propio ancho de banda entregado. Los pares participantes forman una superposici\u00f3n no estructurada que es inherentemente resistente a una alta tasa de abandono. Adem\u00e1s, cada receptor aprovecha el ancho de banda controlado por congesti\u00f3n de sus padres como se\u00f1al impl\u00edcita para detectar y reaccionar ante cambios a largo plazo en la red o en la condici\u00f3n de superposici\u00f3n sin ninguna coordinaci\u00f3n expl\u00edcita con otros pares participantes. La selecci\u00f3n de padres independiente por parte de pares individuales converge din\u00e1micamente hacia una estructura superpuesta eficiente. 1. INTRODUCCI\u00d3N heterogeneidad y asimetr\u00eda de la conectividad del ancho de banda entre los pares participantes -LSB- 19 -RSB-. Hacer frente a las variaciones del ancho de banda, la heterogeneidad y la asimetr\u00eda es particularmente importante en el dise\u00f1o de superposici\u00f3n entre pares para aplicaciones de streaming porque la calidad entregada a cada par est\u00e1 directamente determinada por su conectividad de ancho de banda con -LRB- otro par -LRB- s -RRB- en -RRB- la superposici\u00f3n. Este art\u00edculo presenta un marco simple para dise\u00f1ar una superposici\u00f3n dirigida por receptor punto a punto, llamada PRO. La principal filosof\u00eda de dise\u00f1o en PRO es que a cada par se le debe permitir determinar de forma independiente y ego\u00edsta la mejor manera de conectarse a la superposici\u00f3n para maximizar la calidad de su propia entrega. Con este fin, cada par puede conectarse a la topolog\u00eda de superposici\u00f3n en m\u00faltiples puntos -LRB-, es decir, recibir contenido a trav\u00e9s de m\u00faltiples pares padres -RRB-. Por lo tanto, los pares participantes forman una superposici\u00f3n no estructurada que puede hacer frente con gracia a una alta tasa de abandono -LSB- 5 -RSB-. Adem\u00e1s, tener varios padres pares se adapta a la heterogeneidad y asimetr\u00eda del ancho de banda y al mismo tiempo mejora la resiliencia frente a la din\u00e1mica de participaci\u00f3n de los pares. PRO consta de dos componentes clave: -LRB- i -RRB- Descubrimiento de pares basado en chismes: cada par intercambia peri\u00f3dicamente mensajes -LRB- es decir, chismes -RRB- con otros pares conocidos para aprender progresivamente sobre un subconjunto de pares participantes en la superposici\u00f3n. que probablemente sean buenos padres. -LRB- ii -RRB- Selecci\u00f3n de padres impulsada por el receptor: dada la informaci\u00f3n recopilada sobre otros pares participantes mediante un mecanismo de chismes,cada par -LRB- o receptor -RRB- mejora gradualmente su propia calidad entregada seleccionando din\u00e1micamente un subconjunto adecuado de pares padres que colectivamente maximizan el ancho de banda proporcionado al receptor. Dado que el ancho de banda disponible de diferentes pares participantes a un receptor -LRB- y la posible correlaci\u00f3n entre ellos -RRB- se pueden medir s\u00f3lo en ese receptor, un enfoque impulsado por el receptor es la soluci\u00f3n natural para maximizar el ancho de banda disponible para pares heterog\u00e9neos. Adem\u00e1s, el ancho de banda disponible de los pares principales sirve como una se\u00f1al impl\u00edcita para que un receptor detecte y reaccione a cambios en la red o condici\u00f3n de superposici\u00f3n sin ninguna coordinaci\u00f3n expl\u00edcita con otros pares participantes. La selecci\u00f3n independiente de padres por parte de pares individuales conduce a una superposici\u00f3n eficiente que maximiza la calidad entregada a cada par. PRO incorpora varias funciones de amortiguaci\u00f3n para garantizar la estabilidad de la superposici\u00f3n a pesar de acciones descoordinadas por parte de diferentes pares. PRO es parte de una arquitectura m\u00e1s amplia que hemos desarrollado para la transmisi\u00f3n de igual a igual. Por lo tanto, PRO y PALS est\u00e1n impulsados \u200b\u200bpor el receptor pero se complementan entre s\u00ed. M\u00e1s espec\u00edficamente, PRO determina un subconjunto adecuado de pares principales que colectivamente maximizan el ancho de banda entregado a cada receptor, mientras que PALS coordina la transmisi\u00f3n \"en el tiempo\" de diferentes segmentos de contenido multimedia de estos padres a pesar de las variaciones impredecibles en su ancho de banda disponible. Esta divisi\u00f3n de funcionalidad proporciona una gran flexibilidad porque desacopla la construcci\u00f3n superpuesta del mecanismo de entrega. En este art\u00edculo, nos centramos principalmente en el mecanismo de construcci\u00f3n de superposici\u00f3n, o PRO. El resto de este art\u00edculo est\u00e1 organizado de la siguiente manera: en la Secci\u00f3n 2, revisamos el problema de la construcci\u00f3n de superposiciones para la transmisi\u00f3n entre pares e identificamos sus dos componentes clave y exploramos su espacio de dise\u00f1o. Presentamos nuestro marco propuesto en la Secci\u00f3n 3. En las Secciones 4 y 5, los componentes clave de nuestro marco se describen con m\u00e1s detalle. Finalmente, la Secci\u00f3n 6 concluye el documento y presenta nuestros planes futuros. 6. CONCLUSIONES Y TRABAJO FUTURO En este art\u00edculo, presentamos un marco simple impulsado por un receptor para dise\u00f1ar estructuras superpuestas peer-to-pee llamado PRO. PRO permite que cada par determine de manera ego\u00edsta e independiente la mejor manera de conectarse a la superposici\u00f3n para maximizar su rendimiento. Por lo tanto, PRO deber\u00eda poder maximizar la calidad entregada a pares con conectividad de ancho de banda heterog\u00e9nea y asim\u00e9trica. Tanto el descubrimiento como la selecci\u00f3n de pares en este marco son escalables. Adem\u00e1s, PRO utiliza un ancho de banda controlado por congesti\u00f3n como una se\u00f1al impl\u00edcita para detectar cuellos de botella compartidos entre los padres existentes, as\u00ed como cambios en la red o condiciones de superposici\u00f3n para remodelar adecuadamente la estructura. Describimos el marco b\u00e1sico y sus componentes clave, y esbozamos nuestras soluciones de prueba. Este es un punto de partida para nuestro trabajo en PRO. Actualmente estamos evaluando varios aspectos de este marco mediante simulaci\u00f3n,y explorar el espacio de dise\u00f1o de componentes clave. Tambi\u00e9n estamos creando un prototipo de este marco para realizar experimentos del mundo real en Planet-Lab en un futuro pr\u00f3ximo.", "keyphrases": ["flujo de igual a igual", "control de congesti\u00f3n", "enfoque basado en la recepci\u00f3n", "superposici\u00f3n impulsada por recepci\u00f3n", "sistema de distribuci\u00f3n", "dise\u00f1o", "medir", "estructura superpuesta eficiente", "Pro", "subconjunto adecuado de pares padres", "descubrimiento de pares basado en chismes", "selecci\u00f3n de padres basada en recepci\u00f3n"]}
{"file_name": "H-17", "text": "Pol\u00edticas de poda para \u00edndices invertidos de dos niveles con garant\u00eda de correcci\u00f3n RESUMEN Los motores de b\u00fasqueda web mantienen \u00edndices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de informaci\u00f3n. Para hacer frente a las grandes cantidades de cargas de consultas, los motores de b\u00fasqueda podan su \u00edndice para mantener los documentos que probablemente se devolver\u00e1n como resultados principales y utilizan este \u00edndice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tama\u00f1o del \u00edndice, si calculamos los resultados principales solo a partir del \u00edndice eliminado podemos notar una degradaci\u00f3n significativa en la calidad del resultado: si un documento deber\u00eda estar entre los resultados principales pero no se incluy\u00f3 en el \u00edndice podado, se colocar\u00e1 detr\u00e1s de los resultados calculados a partir del \u00edndice podado. Dada la feroz competencia en el mercado de las b\u00fasquedas online, este fen\u00f3meno es claramente indeseable. En este art\u00edculo, estudiamos c\u00f3mo podemos evitar cualquier degradaci\u00f3n de la calidad de los resultados debido a la optimizaci\u00f3n del rendimiento basada en la poda, sin dejar de aprovechar la mayor parte de sus beneficios. Nuestra contribuci\u00f3n es una serie de modificaciones en las t\u00e9cnicas de poda para crear el \u00edndice podado y un nuevo algoritmo de c\u00e1lculo de resultados que garantiza que las p\u00e1ginas con mejores coincidencias siempre se coloquen en los primeros resultados de b\u00fasqueda, aunque estemos calculando el primer lote de las p\u00e1ginas podadas. \u00edndice la mayor parte del tiempo. Tambi\u00e9n mostramos c\u00f3mo determinar el tama\u00f1o \u00f3ptimo de un \u00edndice podado y evaluamos experimentalmente nuestros algoritmos en una colecci\u00f3n de 130 millones de p\u00e1ginas web. 1. INTRODUCCI\u00d3N Seg\u00fan un estudio reciente -LSB- 13 -RSB-, se estima que el \u2217 Trabajo realizado mientras el autor estaba en el Departamento de Inform\u00e1tica de UCLA. \u2020 Este trabajo est\u00e1 parcialmente financiado por subvenciones NSF, IIS-0534784, IIS0347993 y CNS-0626702. Debido a esta inmensa cantidad de informaci\u00f3n disponible, los usuarios se vuelven cada vez m\u00e1s dependientes de los motores de b\u00fasqueda web para localizar informaci\u00f3n relevante en la Web. Normalmente, los motores de b\u00fasqueda web, al igual que otras aplicaciones de recuperaci\u00f3n de informaci\u00f3n, utilizan una estructura de datos llamada \u00edndice invertido. Un \u00edndice invertido permite la recuperaci\u00f3n eficaz de los documentos -LRB- o p\u00e1ginas web -RRB- que contienen una determinada palabra clave. En la mayor\u00eda de los casos, una consulta que realiza el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de b\u00fasqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. Luego, el usuario revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente -LSB- 16 -RSB- indic\u00f3 que aproximadamente el 80 % de los usuarios examinan como m\u00e1ximo los 3 primeros lotes de resultados. Es decir, el 80% de los usuarios suelen ver como m\u00e1ximo entre 30 y 60 resultados por cada consulta que realizan a un motor de b\u00fasqueda. Al mismo tiempo, dado el tama\u00f1o de la Web,el \u00edndice invertido que mantienen los motores de b\u00fasqueda puede crecer mucho. Una soluci\u00f3n natural a este problema es crear un peque\u00f1o \u00edndice en un subconjunto de los documentos que probablemente se devolver\u00e1n como resultados principales -LRB- utilizando, por ejemplo, las t\u00e9cnicas de poda en -LSB- 7, 20 -RSB- -RRB- y calcular el primer lote de respuestas utilizando el \u00edndice podado. Si bien se ha demostrado que este enfoque ofrece una mejora significativa en el rendimiento, tambi\u00e9n conduce a una degradaci\u00f3n notable en la calidad de los resultados de b\u00fasqueda, porque las respuestas principales se calculan \u00fanicamente a partir del \u00edndice recortado -LSB- 7, 20 -RSB-. Es decir, incluso si una p\u00e1gina debe colocarse como la p\u00e1gina con mejores coincidencias seg\u00fan la m\u00e9trica de clasificaci\u00f3n de un motor de b\u00fasqueda, la p\u00e1gina puede colocarse detr\u00e1s de las contenidas en el \u00edndice eliminado si la p\u00e1gina no pas\u00f3 a formar parte del \u00edndice eliminado. por diversos motivos -LSB- 7, 20 -RSB-. Dada la feroz competencia entre los motores de b\u00fasqueda actuales, esta degradaci\u00f3n es claramente indeseable y debe abordarse si es posible. En este art\u00edculo, estudiamos c\u00f3mo podemos evitar cualquier degradaci\u00f3n de la calidad de la b\u00fasqueda debido a la optimizaci\u00f3n del rendimiento anterior y al mismo tiempo aprovechar la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios -LRB- simples pero importantes -RRB- en las t\u00e9cnicas de poda para crear el \u00edndice podado. Nuestra principal contribuci\u00f3n es un nuevo algoritmo de c\u00e1lculo de respuestas que garantiza que las p\u00e1ginas m\u00e1s coincidentes -LRB- seg\u00fan la m\u00e9trica de clasificaci\u00f3n del motor de b\u00fasqueda -RRB- siempre se coloquen en la parte superior de los resultados de b\u00fasqueda, incluso aunque estemos calculando la primera. lote de respuestas del \u00edndice eliminado la mayor parte del tiempo. Estas t\u00e9cnicas de poda mejoradas y algoritmos de c\u00e1lculo de respuestas se exploran en el context de la arquitectura de cl\u00faster com\u00fanmente empleada por los motores de b\u00fasqueda actuales. Finalmente, estudiamos y presentamos c\u00f3mo los motores de b\u00fasqueda pueden minimizar el costo operativo de responder consultas y al mismo tiempo proporcionar resultados de b\u00fasqueda de alta calidad. Figura 1: -LRB- un motor de b\u00fasqueda -RRB- replica su \u00edndice completo IF para aumentar la capacidad de respuesta a consultas. -LRB- b -RRB- En el primer nivel, los \u00edndices IP peque\u00f1os manejan la mayor\u00eda de las consultas. Cuando IP no puede responder una consulta, se redirige al segundo nivel, donde se utiliza el \u00edndice IF completo para calcular la respuesta. 6. TRABAJOS RELACIONADOS -LSB- 3, 30 -RSB- proporcionan una buena descripci\u00f3n general de la indexaci\u00f3n invertida en motores de b\u00fasqueda web y sistemas de IR. Los estudios experimentales y los an\u00e1lisis de varios esquemas de partici\u00f3n para un \u00edndice invertido se presentan en -LSB- 6, 23, 33 -RSB-. Los algoritmos de poda que hemos presentado en este art\u00edculo son independientes del esquema de partici\u00f3n utilizado. Sin embargo, -LSB- 1, 5, 7, 27 -RSB- no considera ninguna calidad independiente de la consulta -LRB- como el PageRank -RRB- en la funci\u00f3n de clasificaci\u00f3n. -LSB- 32 -RSB- presenta un marco gen\u00e9rico para calcular las respuestas top-k aproximadas con algunos l\u00edmites probabil\u00edsticos en la calidad de los resultados. Nuestro trabajo se extiende esencialmente -LSB- 1, 2, 4, 7, 20, 27,31 -RSB- proponiendo mecanismos para proporcionar la garant\u00eda de exactitud a los resultados top-k calculados. Los motores de b\u00fasqueda utilizan varios m\u00e9todos de almacenamiento en cach\u00e9 como medio para reducir el coste asociado a las consultas -LSB- 18, 19, 21, 31 -RSB-. Este hilo de trabajo tambi\u00e9n es ortogonal al nuestro porque un esquema de almacenamiento en cach\u00e9 puede operar sobre nuestro \u00edndice p para minimizar el costo de c\u00e1lculo de la respuesta. Las funciones de clasificaci\u00f3n exactas empleadas por los motores de b\u00fasqueda actuales son secretos muy bien guardados. Sin embargo, en general, las clasificaciones se basan en la relevancia dependiente de la consulta y en la \"calidad\" del documento independiente de la consulta. '' De manera similar, hay una serie de trabajos que miden la `` calidad '' de los documentos, t\u00edpicamente capturada a trav\u00e9s del an\u00e1lisis basado en enlaces -LSB- 17, 28, 26 -RSB-. Dado que nuestro trabajo no asume una forma particular de funci\u00f3n de clasificaci\u00f3n, es complementario a este cuerpo de trabajo. Ha habido una gran cantidad de trabajo en el c\u00e1lculo de los resultados top-k. 7. COMENTARIOS FINALES Los motores de b\u00fasqueda web suelen podar sus \u00edndices invertidos a gran escala para poder escalar a enormes cargas de consultas. Si bien este enfoque puede mejorar el rendimiento, al calcular los mejores resultados de un \u00edndice recortado podemos notar una degradaci\u00f3n significativa en la calidad de los resultados. En este art\u00edculo, proporcionamos un marco para nuevas t\u00e9cnicas de poda y algoritmos de c\u00e1lculo de respuestas que garantizan que las p\u00e1ginas con mayores coincidencias siempre se coloquen en la parte superior de los resultados de b\u00fasqueda en el orden correcto. Estudiamos dos t\u00e9cnicas de poda, a saber, la poda basada en palabras clave y la poda basada en documentos, as\u00ed como su combinaci\u00f3n. Nuestros resultados experimentales demostraron que nuestros algoritmos se pueden utilizar eficazmente para podar un \u00edndice invertido sin degradar la calidad de los resultados. En particular, un \u00edndice recortado por palabras clave puede garantizar el 73 % de las consultas con un tama\u00f1o del 30 % del \u00edndice completo, mientras que un \u00edndice recortado por documentos puede garantizar el 68 % de las consultas con el mismo tama\u00f1o. Cuando combinamos los dos algoritmos de poda podemos garantizar el 60% de las consultas con un tama\u00f1o de \u00edndice del 16%. Esperamos que nuestro trabajo ayude a los motores de b\u00fasqueda a desarrollar \u00edndices mejores, m\u00e1s r\u00e1pidos y m\u00e1s eficientes y as\u00ed proporcionar una mejor experiencia de b\u00fasqueda al usuario en la Web.es complementario a este cuerpo de trabajo. Ha habido una gran cantidad de trabajo en el c\u00e1lculo de los resultados top-k. 7. COMENTARIOS FINALES Los motores de b\u00fasqueda web suelen podar sus \u00edndices invertidos a gran escala para poder escalar a enormes cargas de consultas. Si bien este enfoque puede mejorar el rendimiento, al calcular los mejores resultados de un \u00edndice recortado podemos notar una degradaci\u00f3n significativa en la calidad de los resultados. En este art\u00edculo, proporcionamos un marco para nuevas t\u00e9cnicas de poda y algoritmos de c\u00e1lculo de respuestas que garantizan que las p\u00e1ginas con mayores coincidencias siempre se coloquen en la parte superior de los resultados de b\u00fasqueda en el orden correcto. Estudiamos dos t\u00e9cnicas de poda, a saber, la poda basada en palabras clave y la poda basada en documentos, as\u00ed como su combinaci\u00f3n. Nuestros resultados experimentales demostraron que nuestros algoritmos se pueden utilizar eficazmente para podar un \u00edndice invertido sin degradar la calidad de los resultados. En particular, un \u00edndice recortado por palabras clave puede garantizar el 73 % de las consultas con un tama\u00f1o del 30 % del \u00edndice completo, mientras que un \u00edndice recortado por documentos puede garantizar el 68 % de las consultas con el mismo tama\u00f1o. Cuando combinamos los dos algoritmos de poda podemos garantizar el 60% de las consultas con un tama\u00f1o de \u00edndice del 16%. Esperamos que nuestro trabajo ayude a los motores de b\u00fasqueda a desarrollar \u00edndices mejores, m\u00e1s r\u00e1pidos y m\u00e1s eficientes y as\u00ed proporcionar una mejor experiencia de b\u00fasqueda al usuario en la Web.es complementario a este cuerpo de trabajo. Ha habido una gran cantidad de trabajo en el c\u00e1lculo de los resultados top-k. 7. COMENTARIOS FINALES Los motores de b\u00fasqueda web suelen podar sus \u00edndices invertidos a gran escala para poder escalar a enormes cargas de consultas. Si bien este enfoque puede mejorar el rendimiento, al calcular los mejores resultados de un \u00edndice recortado podemos notar una degradaci\u00f3n significativa en la calidad de los resultados. En este art\u00edculo, proporcionamos un marco para nuevas t\u00e9cnicas de poda y algoritmos de c\u00e1lculo de respuestas que garantizan que las p\u00e1ginas con mayores coincidencias siempre se coloquen en la parte superior de los resultados de b\u00fasqueda en el orden correcto. Estudiamos dos t\u00e9cnicas de poda, a saber, la poda basada en palabras clave y la poda basada en documentos, as\u00ed como su combinaci\u00f3n. Nuestros resultados experimentales demostraron que nuestros algoritmos se pueden utilizar eficazmente para podar un \u00edndice invertido sin degradar la calidad de los resultados. En particular, un \u00edndice recortado por palabras clave puede garantizar el 73 % de las consultas con un tama\u00f1o del 30 % del \u00edndice completo, mientras que un \u00edndice recortado por documentos puede garantizar el 68 % de las consultas con el mismo tama\u00f1o. Cuando combinamos los dos algoritmos de poda podemos garantizar el 60% de las consultas con un tama\u00f1o de \u00edndice del 16%. Esperamos que nuestro trabajo ayude a los motores de b\u00fasqueda a desarrollar \u00edndices mejores, m\u00e1s r\u00e1pidos y m\u00e1s eficientes y as\u00ed proporcionar una mejor experiencia de b\u00fasqueda al usuario en la Web.", "keyphrases": ["motor de b\u00fasqueda web", "\u00edndice invertido a gran escala", "carga de consultas", "\u00edndice de poda", "mercado de b\u00fasqueda en l\u00ednea", "degradaci\u00f3n de la calidad del resultado", "base de poda realizar optimizaci\u00f3n", "t\u00e9cnica de poda", "algoritmo de c\u00e1lculo de resultados", "p\u00e1gina de mejores coincidencias", "resultado de b\u00fasqueda superior", "tama\u00f1o \u00f3ptimo"]}
{"file_name": "J-25", "text": "Apuestas de estilo booleano: un marco para la negociaci\u00f3n de valores basado en f\u00f3rmulas l\u00f3gicas RESUMEN Desarrollamos un marco para la negociaci\u00f3n de valores compuestos: instrumentos financieros que se amortizan dependiendo de los resultados de declaraciones arbitrarias en l\u00f3gica proposicional. Comprar o vender valores (que pueden considerarse como una apuesta a favor o en contra de un resultado futuro particular) permite a los agentes cubrir riesgos y obtener ganancias -LRB- con expectativa -RRB- de predicciones subjetivas. Un mercado de valores compuesto permite a los agentes realizar apuestas sobre combinaciones booleanas arbitrarias de eventos, lo que les permite alcanzar m\u00e1s estrechamente su exposici\u00f3n \u00f3ptima al riesgo y permite que el mercado en su conjunto alcance m\u00e1s estrechamente el \u00f3ptimo social. La desventaja de permitir tal expresividad est\u00e1 en la complejidad de los problemas de optimizaci\u00f3n de los agentes y del subastador. Desarrollamos y motivamos el concepto de mercado de valores compuesto, presentando el marco a trav\u00e9s de una serie de definiciones formales y ejemplos. Luego analizamos en detalle el problema de emparejamiento del subastador. Mostramos que, con n eventos, el problema de emparejamiento es co-NP-completo en el caso divisible y \u03a3p2-completo en el caso indivisible. Mostramos que este \u00faltimo resultado de dureza se mantiene incluso bajo severas restricciones de idioma en las ofertas. Con eventos log n, el problema es polin\u00f3mico en el caso divisible y NP-completo en el caso indivisible. Discutimos brevemente los algoritmos de coincidencia y los casos especiales manejables. 1. INTRODUCCI\u00d3N Los mercados de valores permiten efectivamente a los operadores hacer apuestas sobre los resultados de propuestas futuras inciertas. El valor econ\u00f3mico de los mercados de valores es doble. En primer lugar, permiten a los operadores cubrir riesgos o asegurarse contra resultados indeseables. Por ejemplo, el propietario de una acci\u00f3n podr\u00eda comprar una opci\u00f3n de venta -LRB- (el derecho a vender la acci\u00f3n a un precio determinado -RRB-) para asegurarse contra una ca\u00edda de la acci\u00f3n. En segundo lugar, los mercados de valores permiten a los operadores especular u obtener una ganancia esperada subjetiva cuando los precios de mercado no reflejan su evaluaci\u00f3n de la probabilidad de resultados futuros. Por ejemplo, un comerciante podr\u00eda comprar una opci\u00f3n de compra si cree que es alta la probabilidad de que el precio de la acci\u00f3n subyacente suba, independientemente de la exposici\u00f3n al riesgo de cambios en el precio de la acci\u00f3n. Dado que los comerciantes pueden obtener ganancias si pueden realizar evaluaciones de probabilidad efectivas, a menudo los precios en los mercados financieros producen pron\u00f3sticos agregados muy precisos de eventos futuros -LSB- 10, 29, 27, 28 -RSB-. Los mercados de valores reales tienen estructuras de pagos complejas con varios factores desencadenantes. Sin embargo, todos ellos pueden modelarse como colecciones de valores Arrow-Debreu m\u00e1s b\u00e1sicos o at\u00f3micos -LSB- 1, 8, 20 -RSB-. Una unidad de un valor Arrow-Debreu paga un d\u00f3lar si y s\u00f3lo si -LRB- iff -RRB- ocurre un evento binario correspondiente; no paga nada si el evento no ocurre. Entonces, por ejemplo, una unidad de un valor denominado -LRB- Acme100 -RRB- podr\u00eda pagar $1 si las acciones de Acme est\u00e1n por encima de $100 el 4 de enero.2004. Una opci\u00f3n sobre acciones de Acme, tal como se definir\u00eda en una bolsa financiera, puede considerarse como una cartera de dichos valores at\u00f3micos.1 En este art\u00edculo, desarrollamos y analizamos un marco para la negociaci\u00f3n en mercados de valores compuestos con pagos supeditados a decisiones arbitrarias. combinaciones l\u00f3gicas de eventos, incluidos los condicionales. Por ejemplo, dados los eventos binarios A, B y C, un operador podr\u00eda ofertar para comprar tres unidades de un valor denominado -LRB- A n B \u00af VC -RRB- que paga $ 1 si se produce el evento compuesto A n B \u00af VC ocurre por treinta centavos cada uno. Dado un conjunto de ofertas de este tipo, el subastador se enfrenta a un complejo problema de emparejamiento para decidir qu\u00e9 ofertas se aceptan, por cu\u00e1ntas unidades y a qu\u00e9 precio. Normalmente, el subastador no busca asumir ning\u00fan riesgo propio y s\u00f3lo busca igualar transacciones aceptables entre los postores, pero tambi\u00e9n consideramos formulaciones alternativas en las que el subastador act\u00faa como un creador de mercado dispuesto a aceptar alg\u00fan riesgo. Examinamos la complejidad computacional del problema de emparejamiento del subastador. Sea la longitud de la descripci\u00f3n de todos los valores disponibles O -LRB- n -RRB-. Con n eventos, el problema de coincidencia es co-NP-completo en el caso divisible y Ep2-completo en el caso indivisible. Esta dureza completa de Ep2 se mantiene incluso cuando el lenguaje de licitaci\u00f3n est\u00e1 significativamente restringido. Con eventos log n, el problema es polin\u00f3mico en el caso divisible y NP-completo en el caso indivisible. La Secci\u00f3n 2 presenta algunos antecedentes necesarios, motivaci\u00f3n y trabajo relacionado. La secci\u00f3n 3 describe formalmente nuestro marco para valores compuestos y define el problema de igualaci\u00f3n del subastador. La secci\u00f3n 4 analiza brevemente los algoritmos naturales para resolver el problema de emparejamiento. La secci\u00f3n 5 demuestra nuestros resultados centrales de complejidad computacional. La secci\u00f3n 6 analiza la posibilidad de casos especiales tratables. La secci\u00f3n 7 concluye con un resumen y algunas ideas de direcciones futuras. 2. PRELIMINARES 2.1 Antecedentes y notaci\u00f3n En este mundo simple hay cuatro posibles estados futuros: todas las combinaciones posibles de los resultados de los eventos binarios: golpeado n acme100, golpeado n acme100, golpeado n acme100, golpeado n acme100. El riesgo de cobertura puede considerarse como una acci\u00f3n de mover dinero entre varios estados futuros posibles. Por ejemplo, insur1. T\u00e9cnicamente, una opci\u00f3n es una cartera de infinitos valores at\u00f3micos, aunque se puede modelar aproximadamente con un n\u00famero finito. ing la propia casa transfiere dinero desde los estados futuros donde se golpea no es cierto hacia los estados donde se encuentra. Vender un valor denominado -LRB- acme100 -RRB- - que paga $ 1 si ocurre el evento acme100 - transfiere dinero de estados futuros donde el precio de Acme es superior a $ 100 el 4 de enero a estados donde no lo es. La especulaci\u00f3n tambi\u00e9n es un acto de transferir dinero entre estados futuros, aunque generalmente se asocia con maximizar el rendimiento esperado en lugar de reducir el riesgo. Por ejemplo, apostar en un equipo de f\u00fatbol mueve dinero del estado \"el equipo pierde\" al estado \"el equipo gana\".Todos los posibles resultados futuros forman un espacio de estados \u03a9, que consta de estados mutuamente excluyentes y exhaustivos \u03c9 E \u03a9. A menudo, una forma m\u00e1s natural de pensar en posibles resultados futuros es como un espacio de eventos A de eventos linealmente independientes AEA que pueden superponerse arbitrariamente. Entonces, en nuestro ejemplo de juguete, el golpe en acme100 es uno de los cuatro estados disjuntos, mientras que el golpe es uno de los dos eventos. Tenga en cuenta que un conjunto de n eventos linealmente independientes define un espacio de estados \u03a9 de tama\u00f1o 2 '' que consta de todas las combinaciones posibles de resultados de eventos. Por el contrario, cualquier espacio de estados \u03a9 se puede factorizar en eventos -LSB- log l\u03a9ll. Supongamos que A cubre exhaustivamente todos los resultados futuros significativos -LRB-, es decir, cubre todas las eventualidades contra las que los agentes pueden desear protegerse y/o especular sobre ellas -RRB-. Entonces, la existencia de 2'' valores linealmente independientes (llamado mercado completo) permite a los agentes distribuir su riqueza arbitrariamente entre estados futuros.2 Un agente puede crear cualquier cobertura o especulaci\u00f3n que desee. En condiciones cl\u00e1sicas, los agentes que operan en un mercado completo forman un equilibrio en el que el riesgo se asigna de manera \u00f3ptima en el sentido de Pareto. Si el mercado es incompleto, es decir, consta de menos de 2'' valores linealmente independientes, entonces en general los agentes no pueden construir coberturas arbitrarias y las asignaciones de equilibrio pueden ser no \u00f3ptimas -LSB- 1, 8, 19, 20 -RSB-. En entornos del mundo real, el n\u00famero de eventos significativos n es grande y, por lo tanto, el n\u00famero de seguridades necesarias para que est\u00e9 completo es intratable. No existe ni existir\u00e1 jam\u00e1s un mercado verdaderamente completo. Una motivaci\u00f3n detr\u00e1s de los mercados de valores compuestos es proporcionar un mecanismo que respalde la mayor transferencia de riesgo utilizando el menor n\u00famero de transacciones posible. Los valores compuestos permiten un alto grado de expresividad en la construcci\u00f3n de ofertas. La compensaci\u00f3n por una mayor expresividad es una mayor complejidad computacional, tanto desde el punto de vista del postor como del subastador. 2.2 Trabajo relacionado La b\u00fasqueda para reducir el n\u00famero de instrumentos financieros necesarios para respaldar una asignaci\u00f3n \u00f3ptima de riesgos data del trabajo original de Arrow -LSB- 1 -RSB-. El requisito mencionado anteriormente de \"s\u00f3lo\" 2 \"t\u00edtulos linealmente independientes es en s\u00ed mismo una reducci\u00f3n de la formulaci\u00f3n m\u00e1s sencilla. En una econom\u00eda con k bienes est\u00e1ndar, el mercado completo m\u00e1s sencillo contiene k \u2022 2 '' valores, cada uno de los cuales se amortiza en un bien bajo un estado de realizaci\u00f3n. La flecha -LSB- 1 -RSB- mostr\u00f3 que un mercado donde los valores y los bienes est\u00e1n esencialmente separados, con 2 '' valores que pagan en un solo bien numerario m\u00e1s k mercados al contado en los bienes est\u00e1ndar, tambi\u00e9n es completo. Para nuestros prop\u00f3sitos, necesitamos considerar s\u00f3lo el mercado de valores. 2Por valores linealmente independientes queremos decir que los vectores de pagos en todos los estados futuros de estos valores son linealmente independientes. Varian -LSB- 34 -RSB- muestra que se puede construir un mercado completo utilizando menos de 2n valores,reemplazar los valores faltantes con opciones. A\u00fan as\u00ed, el n\u00famero de instrumentos financieros linealmente independientes (valores m\u00e1s opciones) debe ser 2n para garantizar la integridad. Los autores muestran que en algunos casos el mercado puede estructurarse y \"compactarse\" en analog\u00eda con las representaciones de redes bayesianas de distribuciones de probabilidad conjuntas -LSB- 23 -RSB-. Muestran que, si las independencias neutrales al riesgo de todos los agentes concuerdan con las independencias codificadas en la estructura del mercado, entonces el mercado est\u00e1 operativamente completo. Para conjuntos de agentes con aversi\u00f3n absoluta y constante al riesgo, el acuerdo sobre las independencias de Markov es suficiente. Bossaerts, Fine y Ledyard -LSB- 2 -RSB- desarrollan un mecanismo que llaman negociaci\u00f3n de valor combinado -LRB- CVT -RRB- que permite a los operadores ordenar una cartera arbitraria de valores en una sola oferta, en lugar de dividir la orden en una secuencia de ofertas sobre valores individuales. Si se acepta la orden de cartera, todas las operaciones impl\u00edcitas sobre valores individuales se ejecutan simult\u00e1neamente, eliminando as\u00ed el llamado riesgo de ejecuci\u00f3n de que los precios cambien en medio de una secuencia planificada de \u00f3rdenes. Los autores llevan a cabo experimentos de laboratorio que muestran que, incluso en mercados reducidos donde el comercio secuencial ordinario fracasa, la CVT respalda la fijaci\u00f3n de precios y la asignaci\u00f3n eficiente. Tenga en cuenta que la CVT difiere significativamente de la negociaci\u00f3n de valores compuestos. CVT permite la negociaci\u00f3n instant\u00e1nea de cualquier combinaci\u00f3n lineal de valores, mientras que los valores compuestos permiten valores m\u00e1s expresivos que pueden codificar combinaciones booleanas no lineales de eventos. Por ejemplo, CVT puede permitir a un agente ordenar valores -LRB- A -RRB- y -LRB- B -RRB- en un paquete que se amortiza como una combinaci\u00f3n lineal de A y B,3 pero CVT no permitir\u00e1 el construcci\u00f3n de un valor compuesto -LRB- A n B -RRB- que paga $ 1 si ocurren tanto A como B, o un valor compuesto -LRB- AIB -RRB-. Las subastas combinatorias permiten a los postores asignar valores distintos a todos los posibles paquetes de bienes en lugar de solo a bienes individuales. Los valores compuestos se diferencian de las subastas combinatorias en concepto y complejidad. Los valores compuestos permiten a los postores construir una apuesta arbitraria sobre cualquiera de los 22n eventos compuestos posibles expresables como funciones l\u00f3gicas de los n eventos base, condicionados a cualquier otro de los 22n eventos compuestos. Los agentes optimizan en funci\u00f3n de sus propias probabilidades subjetivas y actitud de riesgo -LRB- y, en general, de sus creencias sobre las creencias y utilidades de otros agentes, ad infinitum -RRB-. El problema central del subastador es identificar oportunidades de arbitraje: es decir, igualar apuestas sin asumir ning\u00fan riesgo. Las subastas combinatorias, por otro lado, permiten pujar por cualquiera de los 2n paquetes de n bienes. La incertidumbre (y por tanto el riesgo) no se considera. El problema central del subastador es maximizar el bienestar social. Tenga en cuenta tambi\u00e9n que los problemas se encuentran en diferentes clases de complejidad.Mientras que la compensaci\u00f3n de una subasta combinatoria es polin\u00f3mica en el caso divisible y NP-completa en el caso indivisible, la casaci\u00f3n en un mercado de valores compuesto es NP-completa en el caso divisible y Ep2-completa en el caso indivisible. De hecho, incluso el problema de decidir si dos ofertas sobre valores compuestos coinciden, incluso en el caso divisible, es NP-completo -LRB- ver Secci\u00f3n 5.2 -RRB-. En cierto sentido es posible traducir nuestro problema de emparejamiento de valores compuestos en un problema an\u00e1logo para compensar intercambios combinatorios bilaterales -LSB- 31 -RSB- de tama\u00f1o exponencial. Espec\u00edficamente, si consideramos el pago en un estado particular como un bien, entonces los valores compuestos pueden verse como paquetes de -LRB- cantidades fraccionarias de -RRB- dichos bienes. La restricci\u00f3n de equilibrio de materiales que enfrenta el subastador combinatorio corresponde a una restricci\u00f3n que impide al subastador de valores compuestos asumir cualquier riesgo. Tenga en cuenta que esta traducci\u00f3n no es del todo \u00fatil para abordar el problema de emparejamiento de valores compuestos, ya que el intercambio combinatorio resultante tiene un n\u00famero exponencial de bienes. Hanson -LSB- 15 -RSB- desarrolla un mecanismo de mercado llamado regla de puntuaci\u00f3n de mercado que es especialmente adecuado para permitir apuestas sobre un n\u00famero combinatorio de resultados. El mecanismo mantiene una distribuci\u00f3n de probabilidad conjunta en los 2n estados, ya sea expl\u00edcita o impl\u00edcitamente utilizando una red bayesiana u otra representaci\u00f3n compacta. En el l\u00edmite de un \u00fanico operador, el mecanismo se comporta como una regla de puntuaci\u00f3n, adecuada para sondear a un \u00fanico agente su distribuci\u00f3n de probabilidad. En el caso de muchos comerciantes, produce una estimaci\u00f3n combinada. Dado que el mercado esencialmente siempre tiene un conjunto completo de precios publicados para todos los resultados posibles, el mecanismo evita el problema de los mercados delgados o la iliquidez, que necesariamente afecta a cualquier mercado que contenga un n\u00famero exponencial de inversiones alternativas. Las ofertas de valores compuestos pueden considerarse expresiones de desigualdades probabil\u00edsticas: por ejemplo, una oferta para comprar -LRB- A n B -RRB- al precio 0,3 es una afirmaci\u00f3n de que la probabilidad de A n B es mayor que 0,3. Si un conjunto de ofertas unitarias corresponde a un conjunto de desigualdades probabil\u00edsticas inconsistentes, entonces hay una coincidencia. Abordamos estas cuestiones a continuaci\u00f3n.La restricci\u00f3n de equilibrio de materiales que enfrenta el subastador combinatorio corresponde a una restricci\u00f3n que impide al subastador de valores compuestos asumir cualquier riesgo. Tenga en cuenta que esta traducci\u00f3n no es del todo \u00fatil para abordar el problema de emparejamiento de valores compuestos, ya que el intercambio combinatorio resultante tiene un n\u00famero exponencial de bienes. Hanson -LSB- 15 -RSB- desarrolla un mecanismo de mercado llamado regla de puntuaci\u00f3n de mercado que es especialmente adecuado para permitir apuestas sobre un n\u00famero combinatorio de resultados. El mecanismo mantiene una distribuci\u00f3n de probabilidad conjunta en los 2n estados, ya sea expl\u00edcita o impl\u00edcitamente utilizando una red bayesiana u otra representaci\u00f3n compacta. En el l\u00edmite de un \u00fanico operador, el mecanismo se comporta como una regla de puntuaci\u00f3n, adecuada para sondear a un \u00fanico agente su distribuci\u00f3n de probabilidad. En el caso de muchos comerciantes, produce una estimaci\u00f3n combinada. Dado que el mercado esencialmente siempre tiene un conjunto completo de precios publicados para todos los resultados posibles, el mecanismo evita el problema de los mercados delgados o la iliquidez, que necesariamente afecta a cualquier mercado que contenga un n\u00famero exponencial de inversiones alternativas. Las ofertas de valores compuestos pueden considerarse expresiones de desigualdades probabil\u00edsticas: por ejemplo, una oferta para comprar -LRB- A n B -RRB- al precio 0,3 es una afirmaci\u00f3n de que la probabilidad de A n B es mayor que 0,3. Si un conjunto de ofertas unitarias corresponde a un conjunto de desigualdades probabil\u00edsticas inconsistentes, entonces hay una coincidencia. Abordamos estas cuestiones a continuaci\u00f3n.La restricci\u00f3n de equilibrio de materiales que enfrenta el subastador combinatorio corresponde a una restricci\u00f3n que impide al subastador de valores compuestos asumir cualquier riesgo. Tenga en cuenta que esta traducci\u00f3n no es del todo \u00fatil para abordar el problema de emparejamiento de valores compuestos, ya que el intercambio combinatorio resultante tiene un n\u00famero exponencial de bienes. Hanson -LSB- 15 -RSB- desarrolla un mecanismo de mercado llamado regla de puntuaci\u00f3n de mercado que es especialmente adecuado para permitir apuestas sobre un n\u00famero combinatorio de resultados. El mecanismo mantiene una distribuci\u00f3n de probabilidad conjunta en los 2n estados, ya sea expl\u00edcita o impl\u00edcitamente utilizando una red bayesiana u otra representaci\u00f3n compacta. En el l\u00edmite de un \u00fanico operador, el mecanismo se comporta como una regla de puntuaci\u00f3n, adecuada para sondear a un \u00fanico agente su distribuci\u00f3n de probabilidad. En el caso de muchos comerciantes, produce una estimaci\u00f3n combinada. Dado que el mercado esencialmente siempre tiene un conjunto completo de precios publicados para todos los resultados posibles, el mecanismo evita el problema de los mercados delgados o la iliquidez, que necesariamente afecta a cualquier mercado que contenga un n\u00famero exponencial de inversiones alternativas. Las ofertas de valores compuestos pueden considerarse expresiones de desigualdades probabil\u00edsticas: por ejemplo, una oferta para comprar -LRB- A n B -RRB- al precio 0,3 es una afirmaci\u00f3n de que la probabilidad de A n B es mayor que 0,3. Si un conjunto de ofertas unitarias corresponde a un conjunto de desigualdades probabil\u00edsticas inconsistentes, entonces hay una coincidencia. Abordamos estas cuestiones a continuaci\u00f3n.Abordamos estas cuestiones a continuaci\u00f3n.Abordamos estas cuestiones a continuaci\u00f3n.", "keyphrases": ["apuesta combinatoria", "efecto probable evaluar", "combinaci\u00f3n l\u00f3gica arbitraria", "seguro compuesto", "red bayesiana", "comercio de valor combinado", "algoritmo aproximado", "vector de pago", "caso manejable", "base segura"]}
{"file_name": "J-15", "text": "Descomposici\u00f3n generalizada del valor y subastas estructuradas de m\u00faltiples atributos RESUMEN Los mecanismos de subasta de m\u00faltiples atributos generalmente permanecen agn\u00f3sticos sobre las preferencias de los comerciantes o asumen formas altamente restrictivas, como la aditividad total. Las preferencias reales a menudo exhiben dependencias entre atributos, pero pueden poseer alguna estructura que puede explotarse de manera \u00fatil para agilizar la comunicaci\u00f3n y simplificar el funcionamiento de una subasta de m\u00faltiples atributos. Desarrollamos dicha estructura utilizando la teor\u00eda de funciones de valor mensurables, una representaci\u00f3n de utilidad cardinal basada en un orden subyacente sobre las diferencias de preferencia. Un conjunto de relaciones de independencia condicional local sobre tales diferencias respalda una representaci\u00f3n de preferencia aditiva generalizada, que descompone la utilidad en grupos superpuestos de atributos relacionados. Introducimos un mecanismo de subasta iterativo que mantiene los precios en grupos locales de atributos en lugar del espacio completo de configuraciones conjuntas. Cuando las preferencias de los comerciantes son consistentes con la estructura aditiva generalizada de la subasta, el mecanismo produce asignaciones aproximadamente \u00f3ptimas, a precios VCG aproximados. 1. INTRODUCCI\u00d3N Los mecanismos de negociaci\u00f3n de atributos m\u00faltiples ampl\u00edan los mecanismos tradicionales basados \u200b\u200b\u00fanicamente en el precio al facilitar la negociaci\u00f3n sobre un conjunto de atributos predefinidos que representan varios aspectos del acuerdo no relacionados con el precio. En lugar de negociar sobre un bien o servicio completamente definido, un mecanismo de atributos m\u00faltiples retrasa el compromiso con configuraciones espec\u00edficas hasta que se identifican los candidatos m\u00e1s prometedores. Por ejemplo, el departamento de adquisiciones de una empresa puede utilizar una subasta de atributos m\u00faltiples para seleccionar un proveedor de discos duros. Para tener en cuenta las preferencias de los comerciantes, el mecanismo de subasta debe extraer informaci\u00f3n evaluativa sobre un dominio complejo de configuraciones multidimensionales. Construir y comunicar una especificaci\u00f3n de preferencias completa puede ser una carga severa incluso para un n\u00famero moderado de atributos; por lo tanto, las subastas pr\u00e1cticas de atributos m\u00faltiples deben acomodar especificaciones parciales o soportar la expresi\u00f3n compacta de preferencias asumiendo alguna forma simplificada. Con diferencia, la forma de atributos m\u00faltiples m\u00e1s popular a adoptar es la m\u00e1s simple: una representaci\u00f3n aditiva donde el valor general es una combinaci\u00f3n lineal de valores asociados con cada atributo. Por ejemplo, varias propuestas recientes de subastas iterativas de atributos m\u00faltiples -LSB- 2, 3, 8, 19 -RSB- requieren representaciones de preferencias aditivas. Tal aditividad reduce exponencialmente la complejidad de la especificaci\u00f3n de preferencias -LRB- en comparaci\u00f3n con el caso discreto general -RRB-, pero excluye la expresi\u00f3n de cualquier interdependencia entre los atributos. Sin embargo, en la pr\u00e1ctica las interdependencias entre los atributos naturales son bastante comunes. En tales casos, una funci\u00f3n de valor aditivo puede no ser capaz de proporcionar ni siquiera una aproximaci\u00f3n razonable de las preferencias reales. Por otra parte, los modelos totalmente generales son intratables,y es razonable esperar que las preferencias multiatributo exhiban alguna estructura. Nuestro objetivo, por lo tanto, es identificar las representaciones estructuradas m\u00e1s sutiles pero de mayor aplicaci\u00f3n y explotar estas propiedades de las preferencias en los mecanismos comerciales. Proponemos un mecanismo de subasta iterativo basado precisamente en una estructura de preferencias flexible. Nuestro enfoque est\u00e1 inspirado en el dise\u00f1o de una subasta de adquisici\u00f3n iterativa de atributos m\u00faltiples para preferencias de aditivos, debido a Parkes y Kalagnanam -LRB- PK -RRB- -LSB- 19 -RSB-. PK propone dos tipos de subastas iterativas: la primera -LRB- NLD -RRB- no hace suposiciones sobre las preferencias de los comerciantes y permite a los vendedores ofertar en todo el espacio de atributos multidimensionales. Debido a que NLD mantiene una estructura de precios exponencial, solo es adecuado para dominios peque\u00f1os. La otra subasta -LRB- AD -RRB- asume funciones aditivas de valoraci\u00f3n del comprador y coste del vendedor. Recopila ofertas de venta por nivel de atributo y para un \u00fanico plazo de descuento. El precio de una configuraci\u00f3n se define como la suma de los precios de los niveles de atributos elegidos menos el descuento. La subasta que proponemos tambi\u00e9n admite espacios de precios compactos, aunque para niveles de grupos de atributos en lugar de \u00fanicos. Dadas sus ra\u00edces en la teor\u00eda de la utilidad multiatributo -LSB- 13 -RSB-, la condici\u00f3n GAI se define con respecto a la funci\u00f3n de utilidad esperada. Por lo tanto, aplicarlo para modelar valores para ciertos resultados requiere una reinterpretaci\u00f3n de la preferencia bajo certeza. Para este fin, aprovechamos el hecho de que los resultados de las subastas est\u00e1n asociados con precios continuos, lo que proporciona una escala natural para evaluar la magnitud de la preferencia. Primero, presentamos un marco de representaci\u00f3n para las preferencias que captura, adem\u00e1s de ordenamientos simples entre los valores de configuraci\u00f3n de los atributos, la diferencia en la disposici\u00f3n a pagar -LRB- wtp -RRB- por cada uno. A continuaci\u00f3n, construimos un v\u00ednculo directo y formalmente justificado desde declaraciones de preferencia sobre resultados con precio hasta una descomposici\u00f3n aditiva generalizada de la funci\u00f3n dap. Despu\u00e9s de dise\u00f1ar esta infraestructura, empleamos esta herramienta de representaci\u00f3n para el desarrollo de un mecanismo de subasta iterativo de atributos m\u00faltiples que permite a los comerciantes expresar sus preferencias complejas en formato GAI. Luego estudiamos las propiedades pr\u00e1cticas, computacionales y de asignaci\u00f3n de la subasta. En la Secci\u00f3n 2 presentamos antecedentes esenciales de nuestro marco de representaci\u00f3n, la funci\u00f3n de valor medible -LRB- MVF -RRB-. La secci\u00f3n 3 desarrolla nuevas estructuras de atributos m\u00faltiples para MVF, que respaldan descomposiciones aditivas generalizadas. A continuaci\u00f3n, mostramos la aplicabilidad del marco te\u00f3rico a las preferencias en el comercio. El resto del art\u00edculo est\u00e1 dedicado al mecanismo de subasta propuesto.Nuestro enfoque est\u00e1 inspirado en el dise\u00f1o de una subasta de adquisici\u00f3n iterativa de atributos m\u00faltiples para preferencias de aditivos, debido a Parkes y Kalagnanam -LRB- PK -RRB- -LSB- 19 -RSB-. PK propone dos tipos de subastas iterativas: la primera -LRB- NLD -RRB- no hace suposiciones sobre las preferencias de los comerciantes y permite a los vendedores ofertar en todo el espacio de atributos multidimensionales. Debido a que NLD mantiene una estructura de precios exponencial, solo es adecuado para dominios peque\u00f1os. La otra subasta -LRB- AD -RRB- asume funciones aditivas de valoraci\u00f3n del comprador y coste del vendedor. Recopila ofertas de venta por nivel de atributo y para un \u00fanico plazo de descuento. El precio de una configuraci\u00f3n se define como la suma de los precios de los niveles de atributos elegidos menos el descuento. La subasta que proponemos tambi\u00e9n admite espacios de precios compactos, aunque para niveles de grupos de atributos en lugar de \u00fanicos. Dadas sus ra\u00edces en la teor\u00eda de la utilidad multiatributo -LSB- 13 -RSB-, la condici\u00f3n GAI se define con respecto a la funci\u00f3n de utilidad esperada. Por lo tanto, aplicarlo para modelar valores para ciertos resultados requiere una reinterpretaci\u00f3n de la preferencia bajo certeza. Para este fin, aprovechamos el hecho de que los resultados de las subastas est\u00e1n asociados con precios continuos, lo que proporciona una escala natural para evaluar la magnitud de la preferencia. Primero, presentamos un marco de representaci\u00f3n para las preferencias que captura, adem\u00e1s de ordenamientos simples entre los valores de configuraci\u00f3n de los atributos, la diferencia en la disposici\u00f3n a pagar -LRB- wtp -RRB- por cada uno. A continuaci\u00f3n, construimos un v\u00ednculo directo y formalmente justificado desde declaraciones de preferencia sobre resultados con precio hasta una descomposici\u00f3n aditiva generalizada de la funci\u00f3n dap. Despu\u00e9s de dise\u00f1ar esta infraestructura, empleamos esta herramienta de representaci\u00f3n para el desarrollo de un mecanismo de subasta iterativo de atributos m\u00faltiples que permite a los comerciantes expresar sus preferencias complejas en formato GAI. Luego estudiamos las propiedades pr\u00e1cticas, computacionales y de asignaci\u00f3n de la subasta. En la Secci\u00f3n 2 presentamos antecedentes esenciales de nuestro marco de representaci\u00f3n, la funci\u00f3n de valor medible -LRB- MVF -RRB-. La secci\u00f3n 3 desarrolla nuevas estructuras de atributos m\u00faltiples para MVF, que respaldan descomposiciones aditivas generalizadas. A continuaci\u00f3n, mostramos la aplicabilidad del marco te\u00f3rico a las preferencias en el comercio. El resto del art\u00edculo est\u00e1 dedicado al mecanismo de subasta propuesto.Nuestro enfoque est\u00e1 inspirado en el dise\u00f1o de una subasta de adquisici\u00f3n iterativa de atributos m\u00faltiples para preferencias de aditivos, debido a Parkes y Kalagnanam -LRB- PK -RRB- -LSB- 19 -RSB-. PK propone dos tipos de subastas iterativas: la primera -LRB- NLD -RRB- no hace suposiciones sobre las preferencias de los comerciantes y permite a los vendedores ofertar en todo el espacio de atributos multidimensionales. Debido a que NLD mantiene una estructura de precios exponencial, solo es adecuado para dominios peque\u00f1os. La otra subasta -LRB- AD -RRB- asume funciones aditivas de valoraci\u00f3n del comprador y coste del vendedor. Recopila ofertas de venta por nivel de atributo y para un \u00fanico plazo de descuento. El precio de una configuraci\u00f3n se define como la suma de los precios de los niveles de atributos elegidos menos el descuento. La subasta que proponemos tambi\u00e9n admite espacios de precios compactos, aunque para niveles de grupos de atributos en lugar de \u00fanicos. Dadas sus ra\u00edces en la teor\u00eda de la utilidad multiatributo -LSB- 13 -RSB-, la condici\u00f3n GAI se define con respecto a la funci\u00f3n de utilidad esperada. Por lo tanto, aplicarlo para modelar valores para ciertos resultados requiere una reinterpretaci\u00f3n de la preferencia bajo certeza. Para este fin, aprovechamos el hecho de que los resultados de las subastas est\u00e1n asociados con precios continuos, lo que proporciona una escala natural para evaluar la magnitud de la preferencia. Primero, presentamos un marco de representaci\u00f3n para las preferencias que captura, adem\u00e1s de ordenamientos simples entre los valores de configuraci\u00f3n de los atributos, la diferencia en la disposici\u00f3n a pagar -LRB- wtp -RRB- por cada uno. A continuaci\u00f3n, construimos un v\u00ednculo directo y formalmente justificado desde declaraciones de preferencia sobre resultados con precio hasta una descomposici\u00f3n aditiva generalizada de la funci\u00f3n dap. Despu\u00e9s de dise\u00f1ar esta infraestructura, empleamos esta herramienta de representaci\u00f3n para el desarrollo de un mecanismo de subasta iterativo de atributos m\u00faltiples que permite a los comerciantes expresar sus preferencias complejas en formato GAI. Luego estudiamos las propiedades pr\u00e1cticas, computacionales y de asignaci\u00f3n de la subasta. En la Secci\u00f3n 2 presentamos antecedentes esenciales de nuestro marco de representaci\u00f3n, la funci\u00f3n de valor medible -LRB- MVF -RRB-. La secci\u00f3n 3 desarrolla nuevas estructuras de atributos m\u00faltiples para MVF, que respaldan descomposiciones aditivas generalizadas. A continuaci\u00f3n, mostramos la aplicabilidad del marco te\u00f3rico a las preferencias en el comercio. El resto del art\u00edculo est\u00e1 dedicado al mecanismo de subasta propuesto.El precio de una configuraci\u00f3n se define como la suma de los precios de los niveles de atributos elegidos menos el descuento. La subasta que proponemos tambi\u00e9n admite espacios de precios compactos, aunque para niveles de grupos de atributos en lugar de \u00fanicos. Dadas sus ra\u00edces en la teor\u00eda de la utilidad multiatributo -LSB- 13 -RSB-, la condici\u00f3n GAI se define con respecto a la funci\u00f3n de utilidad esperada. Por lo tanto, aplicarlo para modelar valores para ciertos resultados requiere una reinterpretaci\u00f3n de la preferencia bajo certeza. Para este fin, aprovechamos el hecho de que los resultados de las subastas est\u00e1n asociados con precios continuos, lo que proporciona una escala natural para evaluar la magnitud de la preferencia. Primero, presentamos un marco de representaci\u00f3n para las preferencias que captura, adem\u00e1s de ordenamientos simples entre los valores de configuraci\u00f3n de los atributos, la diferencia en la disposici\u00f3n a pagar -LRB- wtp -RRB- por cada uno. A continuaci\u00f3n, construimos un v\u00ednculo directo y formalmente justificado desde declaraciones de preferencia sobre resultados con precio hasta una descomposici\u00f3n aditiva generalizada de la funci\u00f3n dap. Despu\u00e9s de dise\u00f1ar esta infraestructura, empleamos esta herramienta de representaci\u00f3n para el desarrollo de un mecanismo de subasta iterativo de atributos m\u00faltiples que permite a los comerciantes expresar sus preferencias complejas en formato GAI. Luego estudiamos las propiedades pr\u00e1cticas, computacionales y de asignaci\u00f3n de la subasta. En la Secci\u00f3n 2 presentamos antecedentes esenciales de nuestro marco de representaci\u00f3n, la funci\u00f3n de valor medible -LRB- MVF -RRB-. La secci\u00f3n 3 desarrolla nuevas estructuras de atributos m\u00faltiples para MVF, que respaldan descomposiciones aditivas generalizadas. A continuaci\u00f3n, mostramos la aplicabilidad del marco te\u00f3rico a las preferencias en el comercio. El resto del art\u00edculo est\u00e1 dedicado al mecanismo de subasta propuesto.El precio de una configuraci\u00f3n se define como la suma de los precios de los niveles de atributos elegidos menos el descuento. La subasta que proponemos tambi\u00e9n admite espacios de precios compactos, aunque para niveles de grupos de atributos en lugar de \u00fanicos. Dadas sus ra\u00edces en la teor\u00eda de la utilidad multiatributo -LSB- 13 -RSB-, la condici\u00f3n GAI se define con respecto a la funci\u00f3n de utilidad esperada. Por lo tanto, aplicarlo para modelar valores para ciertos resultados requiere una reinterpretaci\u00f3n de la preferencia bajo certeza. Para este fin, aprovechamos el hecho de que los resultados de las subastas est\u00e1n asociados con precios continuos, lo que proporciona una escala natural para evaluar la magnitud de la preferencia. Primero, presentamos un marco de representaci\u00f3n para las preferencias que captura, adem\u00e1s de ordenamientos simples entre los valores de configuraci\u00f3n de los atributos, la diferencia en la disposici\u00f3n a pagar -LRB- wtp -RRB- por cada uno. A continuaci\u00f3n, construimos un v\u00ednculo directo y formalmente justificado desde declaraciones de preferencia sobre resultados con precio hasta una descomposici\u00f3n aditiva generalizada de la funci\u00f3n dap. Despu\u00e9s de dise\u00f1ar esta infraestructura, empleamos esta herramienta de representaci\u00f3n para el desarrollo de un mecanismo de subasta iterativo de atributos m\u00faltiples que permite a los comerciantes expresar sus preferencias complejas en formato GAI. Luego estudiamos las propiedades pr\u00e1cticas, computacionales y de asignaci\u00f3n de la subasta. En la Secci\u00f3n 2 presentamos antecedentes esenciales de nuestro marco de representaci\u00f3n, la funci\u00f3n de valor medible -LRB- MVF -RRB-. La secci\u00f3n 3 desarrolla nuevas estructuras de atributos m\u00faltiples para MVF, que respaldan descomposiciones aditivas generalizadas. A continuaci\u00f3n, mostramos la aplicabilidad del marco te\u00f3rico a las preferencias en el comercio. El resto del art\u00edculo est\u00e1 dedicado al mecanismo de subasta propuesto.Luego estudiamos las propiedades pr\u00e1cticas, computacionales y de asignaci\u00f3n de la subasta. En la Secci\u00f3n 2 presentamos antecedentes esenciales de nuestro marco de representaci\u00f3n, la funci\u00f3n de valor medible -LRB- MVF -RRB-. La secci\u00f3n 3 desarrolla nuevas estructuras de atributos m\u00faltiples para MVF, que respaldan descomposiciones aditivas generalizadas. A continuaci\u00f3n, mostramos la aplicabilidad del marco te\u00f3rico a las preferencias en el comercio. El resto del art\u00edculo est\u00e1 dedicado al mecanismo de subasta propuesto.Luego estudiamos las propiedades pr\u00e1cticas, computacionales y de asignaci\u00f3n de la subasta. En la Secci\u00f3n 2 presentamos antecedentes esenciales de nuestro marco de representaci\u00f3n, la funci\u00f3n de valor medible -LRB- MVF -RRB-. La secci\u00f3n 3 desarrolla nuevas estructuras de atributos m\u00faltiples para MVF, que respaldan descomposiciones aditivas generalizadas. A continuaci\u00f3n, mostramos la aplicabilidad del marco te\u00f3rico a las preferencias en el comercio. El resto del art\u00edculo est\u00e1 dedicado al mecanismo de subasta propuesto.", "keyphrases": ["subasta", "subasta multiatributo", "prefiero manejar", "teor\u00eda de la funci\u00f3n de valor de medida", "mecanismo de subasta iter", "mvf", "ga\u00fa", "subasta de base gai"]}
{"file_name": "I-7", "text": "Compromiso y extorsi\u00f3n * RESUMEN Hacer compromisos, por ejemplo, mediante promesas y amenazas, permite a un jugador explotar las fortalezas de su propia posici\u00f3n estrat\u00e9gica, as\u00ed como las debilidades de la de sus oponentes. Los compromisos que un jugador puede asumir con credibilidad dependen de las circunstancias. En algunos, un jugador s\u00f3lo puede comprometerse a realizar una acci\u00f3n, en otros, puede comprometerse condicionalmente a las acciones de los dem\u00e1s jugadores. Algunas situaciones incluso permiten compromisos sobre compromisos o compromisos con acciones aleatorias. Exploramos las propiedades formales de estos tipos de compromiso -LRB- condicional -RRB- y sus interrelaciones. Para evitar inconsistencias entre los compromisos condicionales, asumimos un orden en el que los jugadores asumen sus compromisos. Central para nuestros an\u00e1lisis es la noci\u00f3n de extorsi\u00f3n, que definimos, para un orden dado de jugadores, como un perfil que contiene, para cada jugador, un compromiso \u00f3ptimo dados los compromisos de los jugadores que se comprometieron anteriormente. Sobre esta base, investigamos para diferentes tipos de compromiso si es ventajoso comprometerse m\u00e1s temprano que tarde, y c\u00f3mo los resultados obtenidos a trav\u00e9s de extorsiones se relacionan con la inducci\u00f3n hacia atr\u00e1s y la eficiencia de Pareto. 1. INTRODUCCI\u00d3N Desde un punto de vista, lo menos que uno puede esperar de la teor\u00eda de juegos es que proporcione una respuesta a la pregunta de qu\u00e9 acciones maximizan la utilidad esperada de un agente en situaciones de toma de decisiones interactiva. Desde esta perspectiva, el modelo formal de un juego en forma estrat\u00e9gica s\u00f3lo esboza las caracter\u00edsticas estrat\u00e9gicas de una situaci\u00f3n interactiva. Adem\u00e1s de simplemente elegir y realizar una acci\u00f3n de un conjunto de acciones, tambi\u00e9n puede haber otros caminos abiertos a un agente. Por ejemplo, la situaci\u00f3n estrat\u00e9gica del terreno puede ser tal que una promesa, una amenaza o una combinaci\u00f3n de ambas ser\u00eda m\u00e1s conducente a sus fines. Del mismo modo, una amenaza s\u00f3lo logra disuadir a un agente si se le puede hacer creer que el amenazador est\u00e1 obligado a ejecutar la amenaza, en caso de que sea ignorada. En este sentido, las promesas y amenazas implican esencialmente un compromiso por parte de quien las hace, restringiendo as\u00ed deliberadamente su libertad de elecci\u00f3n. Las promesas y las amenazas personifican uno de los fen\u00f3menos fundamentales y quiz\u00e1s m\u00e1s sorprendentes a primera vista en la teor\u00eda de juegos: puede ocurrir que un jugador pueda mejorar su posici\u00f3n estrat\u00e9gica limitando su propia libertad de acci\u00f3n. Por compromisos entenderemos tales limitaciones del propio espacio de acci\u00f3n. La acci\u00f3n en s\u00ed misma podr\u00eda verse como el compromiso \u00faltimo. Realizar una acci\u00f3n particular significa hacerlo con exclusi\u00f3n de todas las dem\u00e1s acciones. Los compromisos se presentan de diferentes formas y puede depender de las circunstancias cu\u00e1les se pueden contraer de manera cre\u00edble y cu\u00e1les no. Adem\u00e1s de simplemente comprometerse a realizar una acci\u00f3n, un agente podr\u00eda condicionar su compromiso a las acciones de otros agentes, como lo hace, por ejemplo, el secuestrador cuando promete liberar a un reh\u00e9n al recibir un rescate.mientras amenaza con cortarle otro dedo del pie, de lo contrario. Algunas situaciones incluso permiten compromisos sobre compromisos o compromisos con acciones aleatorias. Al centrarse en la selecci\u00f3n de acciones m\u00e1s que en los compromisos, podr\u00eda parecer que la concepci\u00f3n de la teor\u00eda de juegos como mera teor\u00eda de la decisi\u00f3n interactiva es demasiado estrecha. En este sentido, la visi\u00f3n de Schelling podr\u00eda parecer evidenciar una comprensi\u00f3n m\u00e1s amplia de lo que la teor\u00eda de juegos intenta lograr. Se podr\u00eda objetar que los compromisos podr\u00edan verse como las acciones de un juego m\u00e1s amplio. -LSB-... -RSB- Lo que queremos es una teor\u00eda que sistematice el estudio de los diversos ingredientes universales que conforman la estructura de movimientos de los juegos; un modelo demasiado abstracto los perder\u00e1. -LSB- 9, pp. 156-7 -RSB- Nuestra preocupaci\u00f3n son estas t\u00e1cticas de compromiso, ya sea que nuestro an\u00e1lisis se limite a situaciones en las que los jugadores pueden comprometerse en un orden determinado y donde asumimos los compromisos que los jugadores pueden hacer. son dados. A pesar de la advertencia de Schelling sobre un marco demasiado abstracto, nuestro enfoque se basar\u00e1 en la noci\u00f3n formal de extorsi\u00f3n, que propondremos en la Secci\u00f3n 4 como una t\u00e1ctica uniforme para una clase integral de situaciones en las que los compromisos pueden hacerse secuencialmente. Sobre esta base abordamos cuestiones como la utilidad de determinados tipos de compromiso en diferentes situaciones -LRB-, juegos estrat\u00e9gicos -RRB- o si es mejor comprometerse temprano que tarde. Tambi\u00e9n proporcionamos un marco para la evaluaci\u00f3n de cuestiones m\u00e1s generales de la teor\u00eda de juegos, como la relaci\u00f3n de las extorsiones con la inducci\u00f3n hacia atr\u00e1s o la eficiencia de Pareto. Por ejemplo, se ha argumentado que los compromisos son importantes para los agentes de software que interact\u00faan, as\u00ed como para el dise\u00f1o de mecanismos. En el primer entorno, la incapacidad de reprogramar un agente de software sobre la marcha puede verse como un compromiso con su especificaci\u00f3n y, por lo tanto, explotarse para fortalecer su posici\u00f3n estrat\u00e9gica en un entorno multiagente. Un mecanismo, por otro lado, podr\u00eda verse como un conjunto de compromisos que dirige el comportamiento de los jugadores de una determinada manera deseada -LRB- ver, por ejemplo, -LSB- 2 -RSB- -RRB-. Estos juegos analizan situaciones en las que un l\u00edder apuesta por una estrategia pura o mixta, y un n\u00famero de seguidores, que luego act\u00faan simult\u00e1neamente. Despu\u00e9s de discutir brevemente el trabajo relacionado en la Secci\u00f3n 2, presentamos el marco formal de la teor\u00eda de juegos, en el que definimos las nociones de un tipo de compromiso as\u00ed como compromisos condicionales e incondicionales -LRB- Secci\u00f3n 3 -RRB-. En la Secci\u00f3n 4 proponemos el concepto gen\u00e9rico de extorsi\u00f3n, que para cada tipo de compromiso captura la idea de un perfil de compromiso \u00f3ptimo. La secci\u00f3n 5 analiza brevemente algunos otros tipos de compromiso, como los compromisos inductivos, mixtos y condicionales mixtos. 2. TRABAJOS RELACIONADOS El compromiso es un concepto central en la teor\u00eda de juegos. La posibilidad de asumir compromisos distingue la teor\u00eda de juegos cooperativa de la no cooperativa -LSB- 4, 6 -RSB-. Los juegos de liderazgo, como se mencion\u00f3 en la introducci\u00f3n,analizar las apuestas por estrategias puras o mixtas en lo que es esencialmente un escenario de dos jugadores -LSB- 15, 16 -RSB-. Informalmente, Schelling -LSB- 9 -RSB- ha enfatizado la importancia de las promesas, amenazas y similares para una comprensi\u00f3n adecuada de la interacci\u00f3n social. En un nivel m\u00e1s formal, las amenazas tambi\u00e9n han figurado en la teor\u00eda de la negociaci\u00f3n. El juego de amenazas de Nash -LSB- 5 -RSB- y las amenazas racionales de Harsanyi -LSB- 3 -RSB- son dos importantes ejemplos tempranos. Adem\u00e1s, los compromisos han jugado un papel importante en la teor\u00eda de la selecci\u00f3n del equilibrio -LRB- v\u00e9ase, por ejemplo, -LSB- 13 -RSB-. En los \u00faltimos a\u00f1os, la teor\u00eda de juegos se ha vuelto casi indispensable como herramienta de investigaci\u00f3n para la inform\u00e1tica y la investigaci\u00f3n de m\u00faltiples agentes -LRB-. Los compromisos nunca han pasado desapercibidos -LRB- ver Figura 1: Comprometerse con una estrategia dominada puede ser ventajoso. por ejemplo, -LSB- 1, 11 -RSB- -RRB-. \u00daltimamente tambi\u00e9n los aspectos estrat\u00e9gicos de los compromisos han atra\u00eddo la atenci\u00f3n de los inform\u00e1ticos. As\u00ed, Conitzer y Sandholm -LSB- 2 -RSB- han estudiado la complejidad computacional de calcular la estrategia \u00f3ptima a seguir en forma normal y en juegos bayesianos. Sandholm and Lesser -LSB- 8 -RSB- emplean compromisos nivelados para el dise\u00f1o de sistemas multiagente en los que los acuerdos contractuales no son totalmente vinculantes. Otra conexi\u00f3n entre los compromisos y la inform\u00e1tica fue se\u00f1alada por Samet -LSB- 7 -RSB- y Tennenholtz -LSB- 12 -RSB-. Su punto de partida es la observaci\u00f3n de que los programas pueden utilizarse para formular compromisos que est\u00e9n condicionados a los programas de otros sistemas. Nuestro enfoque es similar al escenario de Stackleberg en el sentido de que asumimos un orden en el que los jugadores se comprometen. Sin embargo, consideramos varios tipos diferentes de compromisos, entre ellos los compromisos condicionales, y proponemos un concepto de soluci\u00f3n gen\u00e9rico. 6. RESUMEN Y CONCLUSI\u00d3N En algunas situaciones los agentes pueden fortalecer su posici\u00f3n estrat\u00e9gica comprometi\u00e9ndose con un curso de acci\u00f3n particular. Existen varios tipos de compromiso, por ejemplo, puro, mixto y condicional. El tipo de compromiso que un agente est\u00e1 en condiciones de asumir depende esencialmente de la situaci\u00f3n que se est\u00e9 considerando. Si los agentes se comprometen en un orden determinado, existe una t\u00e1ctica com\u00fan a la realizaci\u00f3n de compromisos de cualquier tipo, que hemos formalizado mediante el concepto de extorsi\u00f3n. Este concepto gen\u00e9rico de extorsi\u00f3n puede analizarse en abstracto. Adem\u00e1s, sobre esta base se pueden comparar formal y sistem\u00e1ticamente los distintos tipos de compromisos. Hemos visto que el tipo de compromiso que un agente puede asumir tiene un profundo impacto en lo que un agente puede lograr en una situaci\u00f3n similar a la de un juego. En algunas situaciones, a un jugador le ayuda mucho estar en condiciones de comprometerse condicionalmente, mientras que en otras, los compromisos mixtos ser\u00edan m\u00e1s rentables. Esto plantea la cuesti\u00f3n de los rasgos formales caracter\u00edsticos de las situaciones en las que es ventajoso para un actor poder contraer compromisos de un tipo particular.Otro tema que dejamos para futuras investigaciones es la complejidad computacional de encontrar una extorsi\u00f3n para los diferentes tipos de compromiso.", "keyphrases": ["comprometerse", "cre\u00edble", "teor\u00eda de juegos", "tomar decisiones", "posici\u00f3n estrat\u00e9gica", "libertad de acci\u00f3n", "sistema multiag", "distribuci\u00f3n de computaci\u00f3n", "mercado de electrones", "extorsionar", "conjunto de stackleberg", "compromiso de condici\u00f3n \u00f3ptima", "tipo de confirmaci\u00f3n secuencial", "inducir hip\u00f3tesis", "eficiencia de Pareto", "Pareto Effici Condit extorsionar"]}
{"file_name": "J-10", "text": "Comprender el comportamiento del usuario en los informes de comentarios en l\u00ednea RESUMEN Las rese\u00f1as en l\u00ednea se han vuelto cada vez m\u00e1s populares como una forma de juzgar la calidad de diversos productos y servicios. Trabajos anteriores han demostrado que los informes contradictorios y los sesgos subyacentes de los usuarios dificultan juzgar el verdadero valor de un servicio. En este art\u00edculo, investigamos los factores subyacentes que influyen en el comportamiento de los usuarios al enviar comentarios. Examinamos dos fuentes de informaci\u00f3n adem\u00e1s de las calificaciones num\u00e9ricas: la evidencia ling\u00fc\u00edstica del comentario textual que acompa\u00f1a a una rese\u00f1a y los patrones en la secuencia temporal de los informes. Primero mostramos que los grupos de usuarios que discuten ampliamente una determinada caracter\u00edstica tienen m\u00e1s probabilidades de ponerse de acuerdo sobre una calificaci\u00f3n com\u00fan para esa caracter\u00edstica. En segundo lugar, mostramos que la calificaci\u00f3n de un usuario refleja en parte la diferencia entre la calidad real y la expectativa previa de calidad inferida de revisiones anteriores. Ambos nos brindan una forma menos ruidosa de producir estimaciones de calificaci\u00f3n y revelar las razones detr\u00e1s del sesgo de los usuarios. Nuestras hip\u00f3tesis fueron validadas por evidencia estad\u00edstica de rese\u00f1as de hoteles en el sitio web de TripAdvisor. 1. MOTIVACIONES Consideran seriamente los comentarios en l\u00ednea al tomar decisiones de compra y est\u00e1n dispuestos a pagar primas de reputaci\u00f3n por productos o servicios que tienen buena reputaci\u00f3n. Sin embargo, an\u00e1lisis recientes plantean cuestiones importantes sobre la capacidad de los foros existentes para reflejar la calidad real de un producto. En ausencia de incentivos claros, los usuarios con una perspectiva moderada no se molestar\u00e1n en expresar sus opiniones, lo que da lugar a una muestra de rese\u00f1as no representativa. En estas circunstancias, utilizar la media aritm\u00e9tica para predecir la calidad -LRB- como lo hacen la mayor\u00eda de los foros -RRB- le da al usuario t\u00edpico un estimador con alta varianza que a menudo es falso. Mejorar la forma en que agregamos la informaci\u00f3n disponible a partir de rese\u00f1as en l\u00ednea requiere una comprensi\u00f3n profunda de los factores subyacentes que sesgan el comportamiento de calificaci\u00f3n de los usuarios. Hu et al. -LSB- 12 -RSB- propone el ``Modelo de alardear y gemir'' donde los usuarios califican s\u00f3lo si su utilidad del producto -LRB- extra\u00eddo de una distribuci\u00f3n normal -RRB- cae fuera de un intervalo mediano. Los autores concluyen que el modelo explica la distribuci\u00f3n emp\u00edrica de los informes y ofrece informaci\u00f3n sobre formas m\u00e1s inteligentes de estimar la verdadera calidad del producto. En el presente art\u00edculo ampliamos esta l\u00ednea de investigaci\u00f3n e intentamos explicar m\u00e1s hechos sobre el comportamiento de los usuarios cuando informan comentarios en l\u00ednea. Utilizando rese\u00f1as de hoteles reales del sitio web TripAdvisor2, consideramos dos fuentes adicionales de informaci\u00f3n adem\u00e1s de las calificaciones num\u00e9ricas b\u00e1sicas enviadas por los usuarios. La primera es la simple evidencia ling\u00fc\u00edstica procedente de la revisi\u00f3n textual que suele acompa\u00f1ar a las calificaciones num\u00e9ricas. Descubrimos que los usuarios que comentan m\u00e1s sobre la misma caracter\u00edstica tienen m\u00e1s probabilidades de ponerse de acuerdo sobre una calificaci\u00f3n num\u00e9rica com\u00fan para esa caracter\u00edstica en particular. De manera intuitiva, los comentarios extensos revelan la importancia de la funci\u00f3n para el usuario.Dado que las personas tienden a tener m\u00e1s conocimientos en los aspectos que consideran importantes, se podr\u00eda suponer que los usuarios que analizan una caracter\u00edstica determinada con m\u00e1s detalle tienen m\u00e1s autoridad para evaluar esa caracter\u00edstica. En segundo lugar, investigamos la relaci\u00f3n entre una rese\u00f1a Figura 1: La p\u00e1gina de TripAdvisor que muestra rese\u00f1as de un hotel popular de Boston. El nombre del hotel y los anuncios fueron borrados deliberadamente. y las revisiones que lo precedieron. Un examen detenido de las rese\u00f1as en l\u00ednea muestra que las calificaciones a menudo son parte de hilos de discusi\u00f3n, donde una publicaci\u00f3n no es necesariamente independiente de otras publicaciones. Se pueden ver, por ejemplo, usuarios que se esfuerzan por contradecir o estar de acuerdo con vehemencia con los comentarios de usuarios anteriores. Al analizar la secuencia temporal de los informes, concluimos que las revisiones pasadas influyen en los informes futuros, ya que crean alguna expectativa previa sobre la calidad del servicio. La percepci\u00f3n subjetiva del usuario est\u00e1 influenciada por la brecha entre la expectativa previa y el desempe\u00f1o real del servicio -LSB- 17, 18, 16, 21 -RSB- que luego se reflejar\u00e1 en la calificaci\u00f3n del usuario. Proponemos un modelo que captura la dependencia de las calificaciones de las expectativas previas y lo validamos utilizando los datos emp\u00edricos que recopilamos. Ambos resultados se pueden utilizar para mejorar la forma en que los mecanismos de reputaci\u00f3n agregan la informaci\u00f3n de rese\u00f1as individuales. Nuestro primer resultado se puede utilizar para determinar una estimaci\u00f3n de calidad caracter\u00edstica por caracter\u00edstica, donde para cada caracter\u00edstica, se considera un subconjunto diferente de rese\u00f1as -LRB-, es decir, aquellas con comentarios extensos sobre esa caracter\u00edstica -RRB-. El segundo conduce a un algoritmo que genera una estimaci\u00f3n m\u00e1s precisa de la calidad real.Nuestro primer resultado se puede utilizar para determinar una estimaci\u00f3n de calidad caracter\u00edstica por caracter\u00edstica, donde para cada caracter\u00edstica, se considera un subconjunto diferente de rese\u00f1as -LRB-, es decir, aquellas con comentarios extensos sobre esa caracter\u00edstica -RRB-. El segundo conduce a un algoritmo que genera una estimaci\u00f3n m\u00e1s precisa de la calidad real.Nuestro primer resultado se puede utilizar para determinar una estimaci\u00f3n de calidad caracter\u00edstica por caracter\u00edstica, donde para cada caracter\u00edstica, se considera un subconjunto diferente de rese\u00f1as -LRB-, es decir, aquellas con comentarios extensos sobre esa caracter\u00edstica -RRB-. El segundo conduce a un algoritmo que genera una estimaci\u00f3n m\u00e1s precisa de la calidad real.", "keyphrases": ["revisi\u00f3n en l\u00ednea", "mec\u00e1nico de reputaci\u00f3n", "estimaci\u00f3n de calidad caracter\u00edstica por caracter\u00edstica", "ausencia de incentivo claro", "utilidad del producto", "modelo de alardear y gemir", "tasa", "gran probabilidad bimodal", "distribuci\u00f3n en forma de u", "orientaci\u00f3n sem\u00e1ntica de la evaluaci\u00f3n del producto", "correlacionar", "gran lapso de tiempo"]}
{"file_name": "C-1", "text": "Descubrimiento de servicios de red escalable basado en UDDI * RESUMEN El descubrimiento eficiente de servicios de red es esencial para el \u00e9xito de la computaci\u00f3n en red. La estandarizaci\u00f3n de grids basados \u200b\u200ben servicios web ha resultado en la necesidad de implementar mecanismos escalables de descubrimiento de servicios web en grids. Aunque UDDI ha sido el est\u00e1ndar de facto de la industria para el descubrimiento de servicios web, impuso requisitos de replicaci\u00f3n estricta entre registros y falta de del control aut\u00f3nomo ha dificultado gravemente su despliegue y uso generalizados. Con la llegada de la computaci\u00f3n grid, la cuesti\u00f3n de la escalabilidad de UDDI se convertir\u00e1 en un obst\u00e1culo que impedir\u00e1 su implementaci\u00f3n en grids. En este art\u00edculo presentamos nuestra arquitectura de descubrimiento de servicios web distribuidos, llamada DUDE -LRB- Distributed UDDI Deployment Engine -RRB-. DUDE aprovecha DHT -LRB- Distributed Hash Tables -RRB- como mecanismo de encuentro entre m\u00faltiples registros UDDI. DUDE permite a los consumidores consultar m\u00faltiples registros y, al mismo tiempo, permite a las organizaciones tener control aut\u00f3nomo sobre sus registros. . Basado en un prototipo preliminar en PlanetLab, creemos que la arquitectura DUDE puede soportar la distribuci\u00f3n efectiva de registros UDDI, haciendo as\u00ed que UDDI sea m\u00e1s robusto y tambi\u00e9n abordando sus problemas de escala. Adem\u00e1s, la arquitectura DUDE para distribuci\u00f3n escalable se puede aplicar m\u00e1s all\u00e1 de UDDI a cualquier mecanismo de descubrimiento de servicios de red. 1. INTRODUCCI\u00d3N El descubrimiento eficiente de servicios grid es esencial para el \u00e9xito de la computaci\u00f3n grid. Mecanismos de descubrimiento que se implementar\u00e1n en las redes. Los servicios de descubrimiento de redes brindan la capacidad de monitorear y descubrir recursos y servicios en las redes. Proporcionan la capacidad de consultar y suscribirse a informaci\u00f3n de recursos/servicios. El estado de los datos debe mantenerse en un estado suave para que la informaci\u00f3n m\u00e1s reciente est\u00e9 siempre disponible. La informaci\u00f3n recopilada debe proporcionarse a una variedad de sistemas con el fin de utilizar la cuadr\u00edcula o proporcionar informaci\u00f3n resumida. Sin embargo, el problema fundamental es la necesidad de ser escalable para manejar enormes cantidades de datos de m\u00faltiples fuentes. La comunidad de servicios web ha abordado la necesidad de descubrimiento de servicios, antes de que se anticiparan las redes, a trav\u00e9s de un est\u00e1ndar industrial llamado UDDI. Sin embargo, aunque UDDI ha sido el est\u00e1ndar de facto de la industria para el descubrimiento de servicios web, ha impuesto requisitos de replicaci\u00f3n estricta entre registros y la falta de control aut\u00f3nomo, entre otras cosas, ha obstaculizado gravemente su implementaci\u00f3n y uso generalizados -LSB- 7 -RSB- . Con la llegada de la computaci\u00f3n grid, el problema de la escalabilidad de UDDI se convertir\u00e1 en un obst\u00e1culo que impedir\u00e1 su implementaci\u00f3n en grids. Este art\u00edculo aborda el problema de la escalabilidad y una forma de encontrar servicios en m\u00faltiples registros en UDDI mediante el desarrollo de una arquitectura de descubrimiento de servicios web distribuidos. La distribuci\u00f3n de la funcionalidad UDDI se puede lograr de m\u00faltiples maneras y quiz\u00e1s utilizando diferentes infraestructuras/plataformas inform\u00e1ticas distribuidas -LRB-, por ejemplo, CORBA, DCE, etc. -RRB-.En este art\u00edculo exploramos c\u00f3mo se puede aprovechar la tecnolog\u00eda Distributed Hash Table -LRB-DHT-RRB- para desarrollar una arquitectura de descubrimiento de servicios web distribuidos escalable. Un DHT es un sistema distribuido peer-to-peer -LRB-P2P-RRB- que forma una superposici\u00f3n estructurada que permite un enrutamiento m\u00e1s eficiente que la red subyacente. El primer factor motivador es la simplicidad inherente de la abstracci\u00f3n put/get que proporcionan los DHT, lo que facilita la creaci\u00f3n r\u00e1pida de aplicaciones sobre los DHT. Otras plataformas inform\u00e1ticas distribuidas/middleware, aunque proporcionan m\u00e1s funcionalidad, tienen una sobrecarga y una complejidad mucho mayores. El segundo factor motivador surge del hecho de que los DHT son una herramienta relativamente nueva para crear aplicaciones distribuidas y nos gustar\u00eda probar su potencial aplic\u00e1ndolo al problema de la distribuci\u00f3n de UDDI. En la siguiente secci\u00f3n, brindamos una breve descripci\u00f3n general de los servicios de informaci\u00f3n de red, UDDI y sus limitaciones, seguida de una descripci\u00f3n general de los DHT en la Secci\u00f3n 3. La Secci\u00f3n 4 describe nuestra arquitectura propuesta con detalles sobre los casos de uso. En la Secci\u00f3n 5, el Art\u00edculo 2 describe nuestra implementaci\u00f3n actual, seguida de nuestras conclusiones en la Secci\u00f3n 6. La Secci\u00f3n 7 analiza el trabajo relacionado en esta \u00e1rea y la Secci\u00f3n 8 contiene nuestras observaciones finales. 2. ANTECEDENTES 2.1 Descubrimiento del servicio Grid La computaci\u00f3n Grid se basa en est\u00e1ndares que utilizan tecnolog\u00eda de servicios web. En la arquitectura presentada en -LSB- 6 -RSB-, la funci\u00f3n de descubrimiento de servicios se asigna a un servicio Grid especializado llamado Registro. Su funci\u00f3n b\u00e1sica lo hace similar al registro UDDI. Para lograr escalabilidad, los servicios Index de diferentes contenedores Globus pueden registrarse entre s\u00ed de forma jer\u00e1rquica para agregar datos. Espec\u00edficamente, este enfoque no es una buena opci\u00f3n para los sistemas que intentan explotar la convergencia de la computaci\u00f3n grid y peer-to-peer -LSB- 5 -RSB-. 2.2 UDDI M\u00e1s all\u00e1 de la computaci\u00f3n grid, el problema del descubrimiento de servicios debe abordarse de manera m\u00e1s general en la comunidad de servicios web. Una vez m\u00e1s, la escalabilidad es una preocupaci\u00f3n importante, ya que millones de compradores que buscan servicios espec\u00edficos necesitan encontrar todos los vendedores potenciales del servicio que puedan satisfacer sus necesidades. Aunque existen diferentes formas de hacerlo, los comit\u00e9s de est\u00e1ndares de servicios web abordan este requisito a trav\u00e9s de una especificaci\u00f3n denominada UDDI -LRB- Universal Descripci\u00f3n, Descubrimiento e Integraci\u00f3n -RRB-. Un registro UDDI permite a una empresa ingresar tres tipos de informaci\u00f3n en un registro UDDI: p\u00e1ginas blancas, p\u00e1ginas amarillas y p\u00e1ginas verdes. La intenci\u00f3n de la UDDI es funcionar como un registro de servicios del mismo modo que las p\u00e1ginas amarillas son un registro de empresas. Al igual que en las p\u00e1ginas amarillas, las empresas se registran a s\u00ed mismas y a sus servicios en diferentes categor\u00edas. En UDDI, las P\u00e1ginas Blancas son un listado de entidades comerciales. Las p\u00e1ginas verdes representan la informaci\u00f3n t\u00e9cnica necesaria para invocar un servicio determinado. As\u00ed, al navegar por un registro UDDI,un desarrollador deber\u00eda poder localizar un servicio y una empresa y descubrir c\u00f3mo invocar el servicio. Cuando se ofreci\u00f3 inicialmente UDDI, ofrec\u00eda un gran potencial. Sin embargo, hoy nos encontramos con que UDDI no se ha implementado ampliamente en Internet. De hecho, los \u00fanicos usos conocidos de UDDI son los llamados registros UDDI privados dentro de los l\u00edmites de una empresa. Los lectores pueden consultar -LSB- 7 -RSB- para ver un art\u00edculo reciente que analiza las deficiencias de UDDI y las propiedades de un registro de servicios ideal. La mejora del est\u00e1ndar UDDI contin\u00faa con toda su fuerza y \u200b\u200b\u200b\u200bla versi\u00f3n 3 de UDDI -LRB- V3 -RRB- fue aprobada recientemente como est\u00e1ndar OASIS. Sin embargo, la UDDI hoy tiene problemas que no han sido abordados, como la escalabilidad y la autonom\u00eda de los registros individuales. UDDI V3 proporciona mayor soporte para entornos de registros m\u00faltiples basados \u200b\u200ben la portabilidad de claves. Al permitir que las claves se vuelvan a registrar en m\u00faltiples registros, se habilita de manera efectiva la capacidad de vincular registros en varias topolog\u00edas. Sin embargo, en este momento no se proporciona ninguna descripci\u00f3n normativa de estas topolog\u00edas en la especificaci\u00f3n UDDI. Las mejoras dentro de UDDI V3 que permiten el soporte para entornos de registros m\u00faltiples son significativas y abren la posibilidad de realizar investigaciones adicionales sobre c\u00f3mo se pueden implementar entornos de registros m\u00faltiples. Un escenario de implementaci\u00f3n recomendado propuesto por la especificaci\u00f3n UDDI V3.0.2 es utilizar los registros comerciales UDDI como registros ra\u00edz, y es posible habilitar esto usando nuestra soluci\u00f3n. 2.3 Tablas Hash Distribuidas Una Tabla Hash Distribuida -LRB-DHT-RRB- es un sistema distribuido peer-to-peer -LRB-P2P-RRB- que forma una superposici\u00f3n estructurada que permite un enrutamiento m\u00e1s eficiente que la red subyacente. Mantiene una colecci\u00f3n de pares clave-valor en los nodos que participan en esta estructura gr\u00e1fica. Para nuestra implementaci\u00f3n, una clave es el hash de una palabra clave de un nombre o descripci\u00f3n de un servicio. Habr\u00e1 varios valores para esta clave, uno para cada servicio que contenga la palabra clave. Al igual que cualquier otra estructura de datos de tabla hash, proporciona una interfaz simple que consta de operaciones put -LRB- -RRB- y get -LRB- -RRB-. Esto debe hacerse con solidez debido a la naturaleza transitoria de los nodos en los sistemas P2P. Las claves DHT se obtienen de un gran espacio de identificadores. Se aplica una funci\u00f3n hash, como MD5 o SHA-1, al nombre de un objeto para obtener su clave DHT. Los nodos en un DHT tambi\u00e9n se asignan al mismo espacio de identificador aplicando la funci\u00f3n hash a su identificador, como la direcci\u00f3n IP y el n\u00famero de puerto, o la clave p\u00fablica. El espacio de identificador se asigna a los nodos de forma distribuida y determinista, de modo que el enrutamiento y la b\u00fasqueda se puedan realizar de manera eficiente. Los nodos de un DHT mantienen enlaces con algunos de los otros nodos del DHT. El patr\u00f3n de estos enlaces se conoce como geometr\u00eda del DHT. Por ejemplo, en el Bamboo DHT -LSB- 11 -RSB-, y en el Pasteler\u00eda DHT -LSB- 8 -RSB- en el que se basa Bamboo,Los nodos mantienen enlaces con nodos vecinos y con otros nodos distantes que se encuentran en una tabla de enrutamiento. La tabla de enrutamiento permite un enrutamiento superpuesto eficiente. Para lograr un enrutamiento o b\u00fasqueda consistente, se debe enrutar una clave DHT al nodo con el identificador num\u00e9ricamente m\u00e1s cercano. Para obtener detalles sobre c\u00f3mo se construyen y mantienen las tablas de enrutamiento, se remite al lector a -LSB- 8, 11 -RSB-. 5. TRABAJO RELACIONADO En -LSB-18-RSB- se ha propuesto un marco para el descubrimiento de servicios basados \u200b\u200ben QoS en redes. UDDIe, un registro UDDI extendido para publicar y descubrir servicios basados \u200b\u200ben par\u00e1metros de QoS, se propone en -LSB-19-RSB-. Nuestro trabajo es complementario ya que nos enfocamos en c\u00f3mo federar los registros UDDI y abordar el problema de escalabilidad con UDDI. El proxy DUDE puede publicar las propiedades de servicio admitidas por UDDIe en DHT y admitir consultas de rango utilizando t\u00e9cnicas propuestas para dichas consultas en DHT. Entonces podremos ofrecer los beneficios de escalabilidad de nuestra soluci\u00f3n actual a los registros UDDI y UDDIe. Se ha estudiado el descubrimiento de servicios que cumplan con los requisitos de QoS y precios en el context de una econom\u00eda de red, de modo que los programadores de redes puedan utilizar varios modelos de mercado, como mercados de productos b\u00e1sicos y subastas. Para ello se propuso el Directorio de Mercados Grid -LSB- 20 -RSB-. Las descripciones de recursos y solicitudes se expresan en RDF Schema, un lenguaje de marcado sem\u00e1ntico. Las reglas de emparejamiento se expresan en TRIPLE, un lenguaje basado en Horn Logic. Aunque nuestra implementaci\u00f3n actual se centra en UDDI versi\u00f3n 2, en el futuro consideraremos extensiones sem\u00e1nticas a UDDI, WS-Discovery -LSB- 16 -RSB- y otros est\u00e1ndares de computaci\u00f3n Grid como Monitoring and Discovery Service -LRB- MDS -RRB- -LSB. - 10 -RSB-. Entonces, la extensi\u00f3n m\u00e1s simple de nuestro trabajo podr\u00eda implicar el uso de DHT para realizar una b\u00fasqueda inicial basada en sintaxis para identificar los registros locales con los que es necesario contactar. La convergencia de la computaci\u00f3n grid y P2P se ha explorado en -LSB- 5 -RSB-. Se ha construido un servicio UDDI federado -LSB- 4 -RSB- sobre el sistema de publicaci\u00f3n-suscripci\u00f3n PlanetP -LSB- 3 -RSB- para comunidades P2P no estructuradas. El foco de este trabajo ha estado en la manejabilidad del servicio federado. El servicio UDDI se trata como un servicio de aplicaci\u00f3n del art\u00edculo 2 que debe gestionarse en su marco. Por lo tanto, no abordan la cuesti\u00f3n de la escalabilidad en UDDI y, en su lugar, utilizan una replicaci\u00f3n simple. En -LSB- 21 -RSB-, los autores describen un sistema de extensi\u00f3n UDDI -LRB- UX -RRB- que lanza una consulta federada solo si los resultados encontrados localmente no son adecuados. Si bien el servidor UX se posiciona como un intermediario similar al proxy UDDI descrito en nuestro marco DUDE, se centra m\u00e1s en el marco QoS y no intenta implementar un mecanismo de federaci\u00f3n transparente como nuestro enfoque basado en DHT. En -LSB-22-RSB-D2HT se describe un marco de descubrimiento construido sobre DHT. Sin embargo, hemos optado por utilizar UDDI adem\u00e1s de DHT. 6. CONCLUSIONES Y TRABAJO FUTURO En este art\u00edculo,Hemos descrito una arquitectura distribuida para soportar el descubrimiento a gran escala de servicios web. Nuestra arquitectura permitir\u00e1 a las organizaciones mantener un control aut\u00f3nomo sobre sus registros UDDI y al mismo tiempo permitir\u00e1 a los clientes consultar m\u00faltiples registros simult\u00e1neamente. Con base en las pruebas de prototipos iniciales, creemos que la arquitectura DUDE puede respaldar la distribuci\u00f3n efectiva de registros UDDI, lo que hace que UDDI sea m\u00e1s s\u00f3lido y tambi\u00e9n aborda sus problemas de escalamiento. El documento ha resuelto los problemas de escalabilidad con UDDI pero no excluye la aplicaci\u00f3n de este enfoque a otros mecanismos de descubrimiento de servicios. Un ejemplo de otro mecanismo de descubrimiento de servicios que podr\u00eda beneficiarse de este enfoque es el MDS de Globus Toolkit. Adem\u00e1s, planeamos investigar otros aspectos del descubrimiento de servicios de red que ampl\u00eden este trabajo. Adem\u00e1s, planeamos revisar las API de servicio para una soluci\u00f3n Grid Service Discovery aprovechando las soluciones y especificaciones disponibles, as\u00ed como el trabajo presentado en este documento.", "keyphrases": ["descubrimiento de servicio de red", "udd\u00ed", "distribuir servicio web descubrimiento arquitectura", "dht base uddi registros jer\u00e1rquicos", "implementar problema", "c\u00f3digo dht de bamb\u00fa", "b\u00fasqueda que no distingue entre may\u00fasculas y min\u00fasculas", "pregunta", "prefijo de disponibilidad m\u00e1s largo", "descubrimiento de servicios qo-base", "control aut\u00f3nomo", "registro uddi", "emisi\u00f3n escalable", "estado blando"]}
{"file_name": "J-22", "text": "Apuestas a permutaciones RESUMEN Consideramos un escenario de apuestas de permutaci\u00f3n, donde las personas apuestan al orden final de n candidatos: por ejemplo, el resultado de una carrera de caballos. Examinamos el problema del subastador de igualar apuestas sin riesgo o, de manera equivalente, encontrar oportunidades de arbitraje entre las apuestas propuestas. Exigir a los postores que enumeren expl\u00edcitamente los pedidos en los que les gustar\u00eda apostar es antinatural e intratable, \u00a1porque el n\u00famero de pedidos es n! \u00a1y el n\u00famero de subconjuntos de pedidos es 2n! . Proponemos dos lenguajes de apuestas expresivos que parecen naturales para los postores y examinamos la complejidad computacional del problema del subastador en cada caso. Las apuestas de subconjunto permiten a los operadores apostar a que un candidato terminar\u00e1 clasificado entre alg\u00fan subconjunto de posiciones en el orden final, por ejemplo, `` el caballo A terminar\u00e1 en las posiciones 4, 9 o 13-21 '', o que una posici\u00f3n ser\u00e1 tomado por alg\u00fan subconjunto de candidatos, por ejemplo `` el caballo A, B o D terminar\u00e1 en la posici\u00f3n 2 ''. Para las apuestas de subconjuntos, mostramos que el problema del subastador se puede resolver en tiempo polin\u00f3mico si las \u00f3rdenes son divisibles. Las apuestas por pares permiten a los operadores apostar sobre si un candidato terminar\u00e1 en una clasificaci\u00f3n m\u00e1s alta que otro candidato, por ejemplo, \"el caballo A vencer\u00e1 al caballo B\". Demostramos que el problema del subastador se vuelve NP-dif\u00edcil para las apuestas por parejas. Identificamos una condici\u00f3n suficiente para la existencia de un partido de apuestas por parejas que puede verificarse en tiempo polin\u00f3mico. Tambi\u00e9n mostramos que un algoritmo codicioso natural proporciona una mala aproximaci\u00f3n para \u00f3rdenes indivisibles. 1. INTRODUCCI\u00d3N Comprar o vender un t\u00edtulo financiero en efecto es una apuesta sobre el valor del t\u00edtulo. Por ejemplo, comprar una acci\u00f3n es apostar a que el valor de la acci\u00f3n es mayor que su precio actual. Cada comerciante eval\u00faa su beneficio esperado para decidir la cantidad a comprar o vender de acuerdo con su propia informaci\u00f3n y evaluaci\u00f3n de probabilidad subjetiva. La interacci\u00f3n colectiva de todas las apuestas conduce a un equilibrio que refleja una agregaci\u00f3n de la informaci\u00f3n y creencias de todos los traders. Considere comprar un valor a un precio de cincuenta y dos centavos, que pagar\u00e1 1 d\u00f3lar si y s\u00f3lo si un dem\u00f3crata gana las elecciones presidenciales de Estados Unidos en 2008. En este caso de un valor contingente a un evento, el precio (el valor de mercado del valor) corresponde directamente a la probabilidad estimada del evento. Casi todos los intercambios financieros y de apuestas existentes vinculan a socios comerciales bilaterales. Por ejemplo, un operador dispuesto a aceptar una p\u00e9rdida de x d\u00f3lares si un dem\u00f3crata no gana a cambio de una ganancia en d\u00f3lares si un dem\u00f3crata gana se enfrenta a un segundo operador dispuesto a aceptar lo contrario. Sin embargo, en muchos escenarios, incluso si no existen acuerdos bilaterales entre los comerciantes, los acuerdos multilaterales pueden ser posibles. Proponemos un intercambio donde los comerciantes tengan una flexibilidad considerable para expresar sus apuestas de forma natural y sucinta.y examinar la complejidad computacional del problema de emparejamiento resultante del subastador al identificar acuerdos bilaterales y multilaterales. En particular, nos centramos en un escenario donde los comerciantes apuestan por el resultado de una competencia entre n candidatos. Por ejemplo, supongamos que hay n candidatos en una elecci\u00f3n -LRB- o n caballos en una carrera, etc. -RRB- y por tanto n! posibles ordenamientos de candidatos despu\u00e9s del recuento final de votos. Como veremos, el problema de correspondencia se puede plantear como un programa lineal o entero, dependiendo de si los \u00f3rdenes son divisibles o indivisibles, respectivamente. Intentar reducir el problema a un problema de coincidencia bilateral creando expl\u00edcitamente n! valores, uno para cada orden final posible, es engorroso para los comerciantes y computacionalmente inviable incluso para n de tama\u00f1o modesto. Adem\u00e1s, la atenci\u00f3n de los comerciantes se repartir\u00eda entre n! opciones independientes, lo que hace que la probabilidad de que dos operadores converjan al mismo tiempo y en el mismo lugar parezca remota. Existe un equilibrio entre la expresividad del lenguaje de licitaci\u00f3n y la complejidad computacional del problema de emparejamiento. Queremos ofrecer a los operadores el lenguaje de ofertas m\u00e1s expresivo posible manteniendo al mismo tiempo la viabilidad computacional. Exploramos dos lenguajes de oferta que parecen naturales desde la perspectiva del comerciante. Las apuestas de subconjuntos, descritas en la Secci\u00f3n 3.2, permiten a los operadores apostar sobre qu\u00e9 posiciones en la clasificaci\u00f3n caer\u00e1 un candidato, por ejemplo, \"el candidato D terminar\u00e1 en la posici\u00f3n 1, 3-5 o 10\". De manera sim\u00e9trica, los operadores tambi\u00e9n pueden apostar sobre qu\u00e9 candidatos se ubicar\u00e1n en una posici\u00f3n particular. En la Secci\u00f3n 4, derivamos un algoritmo de tiempo polinomial para igualar apuestas de subconjuntos -LRB- divisibles -RRB-. Las apuestas por pares, descritas en la Secci\u00f3n 3.3, permiten a los operadores apostar sobre la clasificaci\u00f3n final de dos candidatos cualesquiera, por ejemplo, \"el candidato D derrotar\u00e1 al candidato R\". En la Secci\u00f3n 5, mostramos que el emparejamiento \u00f3ptimo de apuestas de pares -LRB- divisibles o indivisibles -RRB- es NP-dif\u00edcil, a trav\u00e9s de una reducci\u00f3n del problema del conjunto de arco de retroalimentaci\u00f3n m\u00ednimo no ponderado. Tambi\u00e9n proporcionamos una condici\u00f3n suficiente polinomialmente verificable para la existencia de un partido de apuestas por pares y mostramos que un algoritmo codicioso ofrece una mala aproximaci\u00f3n para apuestas por pares indivisibles. 2. ANTECEDENTES Y TRABAJOS RELACIONADOS Consideramos apuestas de permutaci\u00f3n, o apuestas sobre el resultado de una competencia entre n candidatos. El resultado final del ES del estado es una clasificaci\u00f3n ordinal de los n candidatos. Por ejemplo, los candidatos podr\u00edan ser caballos en una carrera y el resultado ser\u00eda la lista de caballos en orden creciente de sus tiempos de finalizaci\u00f3n. El espacio de estados S contiene todos los n! permutaciones de candidatos mutuamente excluyentes y exhaustivas. En la pr\u00e1ctica, en los hip\u00f3dromos, cada uno de estos diferentes tipos de apuestas se procesa en grupos o grupos separados. En cambio, describimos un intercambio central donde todas las apuestas sobre el resultado se procesan juntas, agregando as\u00ed liquidez y garantizando que la inferencia informativa se produzca autom\u00e1ticamente. Idealmente,Nos gustar\u00eda permitir que los operadores apuesten por cualquier propiedad del orden final que deseen, expresada exactamente en el idioma que prefieran. En la pr\u00e1ctica, permitir un lenguaje demasiado flexible crea una carga computacional para el subastador que intenta emparejar a los comerciantes dispuestos. Exploramos el equilibrio entre la expresividad del lenguaje de licitaci\u00f3n y la complejidad computacional del problema de emparejamiento. Consideramos un marco en el que las personas proponen comprar valores que pagan 1 d\u00f3lar si y s\u00f3lo si alguna propiedad del orden final es verdadera. Los comerciantes indican el precio que est\u00e1n dispuestos a pagar por acci\u00f3n y la cantidad de acciones que les gustar\u00eda comprar. Una orden divisible permite al comerciante recibir menos acciones de las solicitadas, siempre que se cumpla la restricci\u00f3n de precio; un orden indivisible es un orden de todo o nada. valores, uno para cada estado s ES -LRB- o de hecho cualquier conjunto de n! valores linealmente independientes -RRB-. Se trata del denominado mercado de valores completo Arrow-Debreu -LSB- 1 -RSB- para nuestro entorno. En la pr\u00e1ctica, los traders no quieren lidiar con especificaciones de bajo nivel de \u00f3rdenes completas: la gente piensa de manera m\u00e1s natural en t\u00e9rminos de propiedades de alto nivel de las \u00f3rdenes. Adem\u00e1s, operar n! valores es inviable en la pr\u00e1ctica desde un punto de vista computacional a medida que n crece. Un lenguaje de oferta muy simple podr\u00eda permitir a los operadores apostar s\u00f3lo sobre qui\u00e9n gana la competencia, como se hace en el grupo \"ganador\" en los hip\u00f3dromos. El problema de correspondencia correspondiente es polin\u00f3mico, sin embargo el lenguaje no es muy expresivo. Un operador que cree que A derrotar\u00e1 a B, pero que ninguno de los dos ganar\u00e1 directamente, no puede transmitir su informaci\u00f3n al mercado de manera \u00fatil. El espacio de precios del mercado revela las estimaciones colectivas de las probabilidades de ganar, pero nada m\u00e1s. Nuestro objetivo es encontrar lenguajes que sean lo m\u00e1s expresivos e intuitivos posible y que revelen la mayor cantidad de informaci\u00f3n posible, manteniendo la viabilidad computacional. Nuestro trabajo est\u00e1 en analog\u00eda directa con el trabajo de Fortnow et. Mientras que exploramos la combinatoria de permutaciones, Fortnow et. Alabama. Explora la combinatoria booleana. Los autores consideran un espacio de estados de los 2n resultados posibles de n variables binarias. Los comerciantes expresan sus apuestas en l\u00f3gica booleana. Los autores muestran que el emparejamiento divisible es co-NP-completo y el emparejamiento indivisible es p2-completo. Hanson -LSB- 9 -RSB- describe un mecanismo de reglas de puntuaci\u00f3n del mercado que puede permitir apostar sobre un n\u00famero combinatorio de resultados. El mercado comienza con una distribuci\u00f3n de probabilidad conjunta entre todos los resultados. Funciona como una versi\u00f3n secuencial de una regla de puntuaci\u00f3n. Cualquier operador puede cambiar la distribuci\u00f3n de probabilidad siempre que acepte pagar al operador m\u00e1s reciente de acuerdo con la regla de puntuaci\u00f3n. El creador de mercado paga al \u00faltimo operador. Por lo tanto, asume riesgos y puede incurrir en p\u00e9rdidas. Los mecanismos de reglas de puntuaci\u00f3n del mercado tienen la buena propiedad de que la p\u00e9rdida del creador de mercado en el peor de los casos es limitada. Sin embargo, los aspectos computacionales sobre c\u00f3mo operar el mecanismo no se han explorado completamente.Nuestros mecanismos cuentan con un subastador que no asume ning\u00fan riesgo y s\u00f3lo iguala pedidos. Las subastas combinatorias permiten a los postores asignar valores distintos a paquetes de bienes en lugar de solo a bienes individuales. Por lo general, no se consideran la incertidumbre y el riesgo y el problema central del subastador es maximizar el bienestar social. Nuestros mecanismos permiten a los operadores construir apuestas para un evento con n! resultados. Se tienen en cuenta la incertidumbre y el riesgo, y el problema del subastador es explorar oportunidades de arbitraje y igualar las apuestas sin riesgo. 6. CONCLUSI\u00d3N Consideramos un escenario de apuestas de permutaci\u00f3n, donde los operadores apuestan por el orden final de n candidatos. Si bien es antinatural e intratable permitir que los operadores apuesten directamente al n! diferentes ordenamientos finales, proponemos dos lenguajes de apuestas expresivos, apuestas de subconjuntos y apuestas de pares. En un mercado de apuestas de subconjuntos, los operadores pueden apostar en un subconjunto de posiciones que ocupa un candidato o en un subconjunto de candidatos que ocupan una posici\u00f3n espec\u00edfica en el pedido final. Las apuestas por pares permiten a los operadores apostar sobre si un candidato determinado ocupa un lugar m\u00e1s alto que otro candidato determinado. Examinamos el problema del subastador de igualar \u00f3rdenes sin incurrir en riesgos. Encontramos que en un mercado de apuestas de subconjuntos un subastador puede encontrar el conjunto \u00f3ptimo y la cantidad de \u00f3rdenes a aceptar de modo que su beneficio en el peor de los casos se maximice en tiempo polin\u00f3mico si las \u00f3rdenes son divisibles. La complejidad cambia dr\u00e1sticamente en las apuestas por parejas. Demostramos que el problema de emparejamiento \u00f3ptimo para el subastador es NP-dif\u00edcil para apuestas por pares con \u00f3rdenes tanto indivisibles como divisibles mediante reducciones al problema del conjunto de arco de retroalimentaci\u00f3n m\u00ednimo. Identificamos una condici\u00f3n suficiente para la existencia de una coincidencia, que puede verificarse en tiempo polin\u00f3mico. Se ha demostrado que un algoritmo codicioso natural proporciona una mala aproximaci\u00f3n para las apuestas de pares indivisibles. Interesantes preguntas abiertas para nuestras apuestas de permutaci\u00f3n incluyen la complejidad computacional del emparejamiento indivisible \u00f3ptimo para apuestas de subconjuntos y la condici\u00f3n necesaria para la existencia de un partido en los mercados de apuestas de pares. Estamos interesados \u200b\u200ben explorar m\u00e1s a fondo mejores algoritmos de aproximaci\u00f3n para los mercados de apuestas por parejas.En un mercado de apuestas de subconjuntos, los operadores pueden apostar en un subconjunto de posiciones que ocupa un candidato o en un subconjunto de candidatos que ocupan una posici\u00f3n espec\u00edfica en el pedido final. Las apuestas por pares permiten a los operadores apostar sobre si un candidato determinado ocupa un lugar m\u00e1s alto que otro candidato determinado. Examinamos el problema del subastador de igualar \u00f3rdenes sin incurrir en riesgos. Encontramos que en un mercado de apuestas de subconjuntos un subastador puede encontrar el conjunto \u00f3ptimo y la cantidad de \u00f3rdenes a aceptar de modo que su beneficio en el peor de los casos se maximice en tiempo polin\u00f3mico si las \u00f3rdenes son divisibles. La complejidad cambia dr\u00e1sticamente en las apuestas por parejas. Demostramos que el problema de emparejamiento \u00f3ptimo para el subastador es NP-dif\u00edcil para apuestas por pares con \u00f3rdenes tanto indivisibles como divisibles mediante reducciones al problema del conjunto de arco de retroalimentaci\u00f3n m\u00ednimo. Identificamos una condici\u00f3n suficiente para la existencia de una coincidencia, que puede verificarse en tiempo polin\u00f3mico. Se ha demostrado que un algoritmo codicioso natural proporciona una mala aproximaci\u00f3n para las apuestas de pares indivisibles. Interesantes preguntas abiertas para nuestras apuestas de permutaci\u00f3n incluyen la complejidad computacional del emparejamiento indivisible \u00f3ptimo para apuestas de subconjuntos y la condici\u00f3n necesaria para la existencia de un partido en los mercados de apuestas de pares. Estamos interesados \u200b\u200ben explorar m\u00e1s a fondo mejores algoritmos de aproximaci\u00f3n para los mercados de apuestas por parejas.En un mercado de apuestas de subconjuntos, los operadores pueden apostar en un subconjunto de posiciones que ocupa un candidato o en un subconjunto de candidatos que ocupan una posici\u00f3n espec\u00edfica en el pedido final. Las apuestas por pares permiten a los operadores apostar sobre si un candidato determinado ocupa un lugar m\u00e1s alto que otro candidato determinado. Examinamos el problema del subastador de igualar \u00f3rdenes sin incurrir en riesgos. Encontramos que en un mercado de apuestas de subconjuntos un subastador puede encontrar el conjunto \u00f3ptimo y la cantidad de \u00f3rdenes a aceptar de modo que su beneficio en el peor de los casos se maximice en tiempo polin\u00f3mico si las \u00f3rdenes son divisibles. La complejidad cambia dr\u00e1sticamente en las apuestas por parejas. Demostramos que el problema de emparejamiento \u00f3ptimo para el subastador es NP-dif\u00edcil para apuestas por pares con \u00f3rdenes tanto indivisibles como divisibles mediante reducciones al problema del conjunto de arco de retroalimentaci\u00f3n m\u00ednimo. Identificamos una condici\u00f3n suficiente para la existencia de una coincidencia, que puede verificarse en tiempo polin\u00f3mico. Se ha demostrado que un algoritmo codicioso natural proporciona una mala aproximaci\u00f3n para las apuestas de pares indivisibles. Interesantes preguntas abiertas para nuestras apuestas de permutaci\u00f3n incluyen la complejidad computacional del emparejamiento indivisible \u00f3ptimo para apuestas de subconjuntos y la condici\u00f3n necesaria para la existencia de un partido en los mercados de apuestas de pares. Estamos interesados \u200b\u200ben explorar m\u00e1s a fondo mejores algoritmos de aproximaci\u00f3n para los mercados de apuestas por parejas.", "keyphrases": ["apuesta permuta", "apuesta de subconjunto", "socio comercial bilateral", "algoritmo polin\u00f3mico-tiempo", "informar agregado", "combinador permutado", "mercado de apuestas de par", "gr\u00e1fico bipartito", "retroalimentaci\u00f3n m\u00ednima", "algoritmo codicioso", "transformada polinomial compleja"]}
{"file_name": "I-31", "text": "Razonamiento sobre juicios y agregaci\u00f3n de preferencias \u25e6 RESUMEN Los agentes que deben llegar a acuerdos con otros agentes necesitan razonar sobre c\u00f3mo sus preferencias, juicios y creencias podr\u00edan agregarse con los de otros mediante los mecanismos de elecci\u00f3n social que gobiernan sus interacciones. El campo recientemente emergente de agregaci\u00f3n de juicios estudia la agregaci\u00f3n desde una perspectiva l\u00f3gica y considera c\u00f3mo se pueden agregar m\u00faltiples conjuntos de f\u00f3rmulas l\u00f3gicas en un \u00fanico conjunto consistente. Como caso especial, se puede considerar que la agregaci\u00f3n de juicios subsume la agregaci\u00f3n de preferencias cl\u00e1sica. Presentamos una l\u00f3gica modal que pretende apoyar el razonamiento sobre escenarios de agregaci\u00f3n de juicios -LRB- y, por tanto, como caso especial, sobre agregaci\u00f3n de preferencias -RRB-: el lenguaje l\u00f3gico se interpreta directamente en reglas de agregaci\u00f3n de juicios. Presentamos una axiomatizaci\u00f3n s\u00f3lida y completa de tales reglas. Mostramos que la l\u00f3gica puede expresar reglas de agregaci\u00f3n como la votaci\u00f3n por mayor\u00eda; propiedades de las reglas como la independencia; y resultados como la paradoja discursiva, el teorema de Arrow y la paradoja de Condorcet, que son derivables como teoremas formales de la l\u00f3gica. La l\u00f3gica est\u00e1 parametrizada de tal manera que puede usarse como marco general para comparar las propiedades l\u00f3gicas de diferentes tipos de agregaci\u00f3n, incluida la agregaci\u00f3n de preferencias cl\u00e1sica. 1. INTRODUCCI\u00d3N En este art\u00edculo, nos interesan los formalismos de representaci\u00f3n del conocimiento para sistemas en los que los agentes necesitan agregar sus preferencias, juicios, creencias, etc. Por ejemplo, un agente puede necesitar razonar sobre la votaci\u00f3n mayoritaria en un grupo en el que est\u00e1. un miembro de. La agregaci\u00f3n de preferencias (combinar las relaciones de preferencia de los individuos sobre un conjunto de alternativas en una relaci\u00f3n de preferencia que representa las preferencias conjuntas del grupo mediante las llamadas funciones de bienestar social) ha sido ampliamente estudiada en la teor\u00eda de la elecci\u00f3n social -LSB- 2 -RSB- . El campo recientemente emergente de agregaci\u00f3n de juicios estudia la agregaci\u00f3n desde una perspectiva l\u00f3gica y analiza c\u00f3mo, dado un conjunto consistente de f\u00f3rmulas l\u00f3gicas para cada agente, que representan las creencias o juicios del agente, podemos agregarlos en un \u00fanico conjunto consistente de f\u00f3rmulas. Con este fin se han desarrollado una variedad de reglas de agregaci\u00f3n de juicios. Como caso especial, se puede considerar que la agregaci\u00f3n de juicios subsume la agregaci\u00f3n de preferencias -LSB- 5 -RSB-. En este art\u00edculo presentamos una l\u00f3gica, denominada L\u00f3gica de Agregaci\u00f3n de Juicios -LRB- jal -RRB-, para razonar sobre la agregaci\u00f3n de juicios. Las f\u00f3rmulas de la l\u00f3gica se interpretan como afirmaciones sobre reglas de agregaci\u00f3n de juicios, y damos una axiomatizaci\u00f3n s\u00f3lida y completa de todas esas reglas. La axiomatizaci\u00f3n est\u00e1 parametrizada de tal manera que podemos instanciarla para obtener una variedad de l\u00f3gicas de agregaci\u00f3n de juicios diferentes. Por ejemplo, un ejemplo es una axiomatizaci\u00f3n, en nuestro lenguaje, de todas las funciones de bienestar social; por lo tanto, obtenemos tambi\u00e9n una l\u00f3gica de agregaci\u00f3n de preferencias cl\u00e1sica.Y esta es una de las principales contribuciones de este art\u00edculo: identificamos las propiedades l\u00f3gicas de la agregaci\u00f3n de juicios y podemos comparar las propiedades l\u00f3gicas de diferentes clases de agregaci\u00f3n de juicios, y de la agregaci\u00f3n de juicios en general y de la agregaci\u00f3n de preferencias en particular. Por supuesto, una l\u00f3gica s\u00f3lo es interesante mientras sea expresiva. Uno de los objetivos de este art\u00edculo es investigar las capacidades l\u00f3gicas y de representaci\u00f3n que necesita un agente para juzgar y agregar preferencias; es decir, \u00bfqu\u00e9 tipo de lenguaje l\u00f3gico podr\u00eda usarse para representar y razonar sobre la agregaci\u00f3n de juicios? El lenguaje de representaci\u00f3n del conocimiento de un agente deber\u00eda poder expresar: reglas de agregaci\u00f3n comunes como la votaci\u00f3n por mayor\u00eda; propiedades com\u00fanmente discutidas de las reglas de agregaci\u00f3n de juicios y funciones de bienestar social como la independencia; paradojas com\u00fanmente utilizadas para ilustrar la agregaci\u00f3n de juicios y la agregaci\u00f3n de preferencias, a saber. la paradoja discursiva y la paradoja de Condorcet respectivamente; y otras propiedades importantes como el teorema de Arrow. De este ejemplo parece que un lenguaje formal para SWF deber\u00eda poder expresar: \u2022 Propiedades de relaciones de preferencia para diferentes agentes y propiedades de varias relaciones de preferencia diferentes para el mismo agente en la misma f\u00f3rmula. \u2022 Comparaci\u00f3n de diferentes relaciones de preferencia. \u2022 La relaci\u00f3n de preferencia resultante de aplicar un SWF a otras relaciones de preferencia. Desde estos puntos podr\u00eda parecer que tal lenguaje ser\u00eda bastante complejo -LRB- en particular, estos requisitos parecen descartar una l\u00f3gica modal proposicional est\u00e1ndar -RRB-. En la siguiente secci\u00f3n revisamos los conceptos b\u00e1sicos de la agregaci\u00f3n de juicios, as\u00ed como de la agregaci\u00f3n de preferencias, y mencionamos algunas propiedades com\u00fanmente discutidas de las reglas de agregaci\u00f3n de juicios y las funciones de bienestar social. Las f\u00f3rmulas de JAL son interpretadas directamente por las reglas de agregaci\u00f3n de juicios y, por lo tanto, representan propiedades de ellas. En la Secci\u00f3n 4 demostramos que la l\u00f3gica puede expresar propiedades com\u00fanmente discutidas de las reglas de agregaci\u00f3n de juicios, como la paradoja discursiva. En la Secci\u00f3n 5 damos una axiomatizaci\u00f3n s\u00f3lida y completa de la l\u00f3gica, bajo el supuesto de que la agenda sobre la que los agentes emiten juicios es finita. Como se mencion\u00f3 anteriormente, la agregaci\u00f3n de preferencias puede verse como un caso especial de agregaci\u00f3n de juicios, y en la Secci\u00f3n 6 introducimos una interpretaci\u00f3n alternativa de las f\u00f3rmulas JAL directamente en funciones de bienestar social. Tambi\u00e9n obtenemos una axiomatizaci\u00f3n s\u00f3lida y completa de la l\u00f3gica de la agregaci\u00f3n de preferencias. Las secciones 7 y 8 analizan el trabajo relacionado y concluyen. 7. TRABAJOS RELACIONADOS Las l\u00f3gicas formales relacionadas con la elecci\u00f3n social se han centrado principalmente en la representaci\u00f3n l\u00f3gica de las preferencias cuando el conjunto de alternativas es grande y en las propiedades de c\u00e1lculo de las preferencias agregadas para una representaci\u00f3n dada -LSB- 6, 7, 8 -RSB- . Una excepci\u00f3n notable y reciente es un marco l\u00f3gico para la agregaci\u00f3n de juicios desarrollado por Marc Pauly en -LSB- 10 -RSB-,para poder caracterizar las relaciones l\u00f3gicas entre diferentes reglas de agregaci\u00f3n de juicios. La l\u00f3gica modal de flechas -LSB- 11 -RSB- est\u00e1 dise\u00f1ada para razonar sobre cualquier objeto que pueda representarse gr\u00e1ficamente como una flecha, y tiene varios operadores modales para expresar propiedades y relaciones entre estas flechas. En la l\u00f3gica de agregaci\u00f3n de preferencias jal -LRB- LK -RRB- interpretamos f\u00f3rmulas en pares de alternativas, que pueden verse como flechas. Por lo tanto, -LRB- al menos -RRB- la variante de agregaci\u00f3n de preferencias de nuestra l\u00f3gica est\u00e1 relacionada con la l\u00f3gica de flechas. Sin embargo, si bien los operadores modales de la l\u00f3gica de flechas pueden expresar propiedades de relaciones de preferencia como la transitividad, no pueden expresar directamente la mayor\u00eda de las propiedades que hemos analizado en este art\u00edculo. Sin embargo, la relaci\u00f3n con la l\u00f3gica de flechas podr\u00eda investigarse m\u00e1s a fondo en trabajos futuros. En particular, las l\u00f3gicas de flechas suelen demostrarse completas. un \u00e1lgebra. Esto podr\u00eda significar que ser\u00eda posible utilizar dichas \u00e1lgebras como estructura subyacente para representar las preferencias individuales y colectivas. Luego, cambiar el perfil de preferencia nos lleva de un \u00e1lgebra a otra, y un SWF determina la preferencia colectiva, en cada una de las \u00e1lgebras. 8. DISCUSI\u00d3N Hemos presentado una l\u00f3gica s\u00f3lida y completa para representar y razonar sobre la agregaci\u00f3n de juicios. jal es expresivo: puede expresar reglas de agregaci\u00f3n de juicios como la votaci\u00f3n por mayor\u00eda; propiedades complicadas como la independencia; y resultados importantes como la paradoja discursiva, el teorema de Arrow y la paradoja de Condorcet. Sostenemos que estos resultados muestran exactamente qu\u00e9 capacidades l\u00f3gicas necesita un agente para poder razonar sobre la agregaci\u00f3n de juicios. Quiz\u00e1s resulte sorprendente que un lenguaje relativamente simple proporcione estas capacidades. La axiomatizaci\u00f3n describe los principios l\u00f3gicos de la agregaci\u00f3n de juicios y tambi\u00e9n se puede instanciar para razonar sobre instancias espec\u00edficas de agregaci\u00f3n de juicios, como la agregaci\u00f3n de preferencias arroviana cl\u00e1sica. As\u00ed, nuestro marco arroja luz sobre las diferencias entre los principios l\u00f3gicos detr\u00e1s de la agregaci\u00f3n de juicios generales, por un lado, y la agregaci\u00f3n de preferencias cl\u00e1sica, por el otro. En trabajos futuros ser\u00eda interesante flexibilizar los requisitos de integridad y coherencia de los conjuntos de juicios y tratar de caracterizarlos en el lenguaje l\u00f3gico, como propiedades de conjuntos de juicios generales.-LRB- al menos -RRB- la variante de agregaci\u00f3n de preferencias de nuestra l\u00f3gica est\u00e1 relacionada con la l\u00f3gica de flechas. Sin embargo, si bien los operadores modales de la l\u00f3gica de flechas pueden expresar propiedades de relaciones de preferencia como la transitividad, no pueden expresar directamente la mayor\u00eda de las propiedades que hemos analizado en este art\u00edculo. Sin embargo, la relaci\u00f3n con la l\u00f3gica de flechas podr\u00eda investigarse m\u00e1s a fondo en trabajos futuros. En particular, las l\u00f3gicas de flechas suelen demostrarse completas. un \u00e1lgebra. Esto podr\u00eda significar que ser\u00eda posible utilizar dichas \u00e1lgebras como estructura subyacente para representar las preferencias individuales y colectivas. Luego, cambiar el perfil de preferencia nos lleva de un \u00e1lgebra a otra, y un SWF determina la preferencia colectiva, en cada una de las \u00e1lgebras. 8. DISCUSI\u00d3N Hemos presentado una l\u00f3gica s\u00f3lida y completa para representar y razonar sobre la agregaci\u00f3n de juicios. jal es expresivo: puede expresar reglas de agregaci\u00f3n de juicios como la votaci\u00f3n por mayor\u00eda; propiedades complicadas como la independencia; y resultados importantes como la paradoja discursiva, el teorema de Arrow y la paradoja de Condorcet. Sostenemos que estos resultados muestran exactamente qu\u00e9 capacidades l\u00f3gicas necesita un agente para poder razonar sobre la agregaci\u00f3n de juicios. Quiz\u00e1s resulte sorprendente que un lenguaje relativamente simple proporcione estas capacidades. La axiomatizaci\u00f3n describe los principios l\u00f3gicos de la agregaci\u00f3n de juicios y tambi\u00e9n se puede instanciar para razonar sobre instancias espec\u00edficas de agregaci\u00f3n de juicios, como la agregaci\u00f3n de preferencias arroviana cl\u00e1sica. As\u00ed, nuestro marco arroja luz sobre las diferencias entre los principios l\u00f3gicos detr\u00e1s de la agregaci\u00f3n de juicios generales, por un lado, y la agregaci\u00f3n de preferencias cl\u00e1sica, por el otro. En trabajos futuros ser\u00eda interesante flexibilizar los requisitos de integridad y coherencia de los conjuntos de juicios y tratar de caracterizarlos en el lenguaje l\u00f3gico, como propiedades de conjuntos de juicios generales.-LRB- al menos -RRB- la variante de agregaci\u00f3n de preferencias de nuestra l\u00f3gica est\u00e1 relacionada con la l\u00f3gica de flechas. Sin embargo, si bien los operadores modales de la l\u00f3gica de flechas pueden expresar propiedades de relaciones de preferencia como la transitividad, no pueden expresar directamente la mayor\u00eda de las propiedades que hemos analizado en este art\u00edculo. Sin embargo, la relaci\u00f3n con la l\u00f3gica de flechas podr\u00eda investigarse m\u00e1s a fondo en trabajos futuros. En particular, las l\u00f3gicas de flechas suelen demostrarse completas. un \u00e1lgebra. Esto podr\u00eda significar que ser\u00eda posible utilizar dichas \u00e1lgebras como estructura subyacente para representar las preferencias individuales y colectivas. Luego, cambiar el perfil de preferencia nos lleva de un \u00e1lgebra a otra, y un SWF determina la preferencia colectiva, en cada una de las \u00e1lgebras. 8. DISCUSI\u00d3N Hemos presentado una l\u00f3gica s\u00f3lida y completa para representar y razonar sobre la agregaci\u00f3n de juicios. jal es expresivo: puede expresar reglas de agregaci\u00f3n de juicios como la votaci\u00f3n por mayor\u00eda; propiedades complicadas como la independencia; y resultados importantes como la paradoja discursiva, el teorema de Arrow y la paradoja de Condorcet. Sostenemos que estos resultados muestran exactamente qu\u00e9 capacidades l\u00f3gicas necesita un agente para poder razonar sobre la agregaci\u00f3n de juicios. Quiz\u00e1s resulte sorprendente que un lenguaje relativamente simple proporcione estas capacidades. La axiomatizaci\u00f3n describe los principios l\u00f3gicos de la agregaci\u00f3n de juicios y tambi\u00e9n se puede instanciar para razonar sobre instancias espec\u00edficas de agregaci\u00f3n de juicios, como la agregaci\u00f3n de preferencias arroviana cl\u00e1sica. As\u00ed, nuestro marco arroja luz sobre las diferencias entre los principios l\u00f3gicos detr\u00e1s de la agregaci\u00f3n de juicios generales, por un lado, y la agregaci\u00f3n de preferencias cl\u00e1sica, por el otro. En trabajos futuros ser\u00eda interesante flexibilizar los requisitos de integridad y coherencia de los conjuntos de juicios y tratar de caracterizarlos en el lenguaje l\u00f3gico, como propiedades de conjuntos de juicios generales.Teorema de Arrow y paradoja de Condorcet. Sostenemos que estos resultados muestran exactamente qu\u00e9 capacidades l\u00f3gicas necesita un agente para poder razonar sobre la agregaci\u00f3n de juicios. Quiz\u00e1s resulte sorprendente que un lenguaje relativamente simple proporcione estas capacidades. La axiomatizaci\u00f3n describe los principios l\u00f3gicos de la agregaci\u00f3n de juicios y tambi\u00e9n se puede instanciar para razonar sobre instancias espec\u00edficas de agregaci\u00f3n de juicios, como la agregaci\u00f3n de preferencias arroviana cl\u00e1sica. As\u00ed, nuestro marco arroja luz sobre las diferencias entre los principios l\u00f3gicos detr\u00e1s de la agregaci\u00f3n de juicios generales, por un lado, y la agregaci\u00f3n de preferencias cl\u00e1sica, por el otro. En trabajos futuros ser\u00eda interesante flexibilizar los requisitos de integridad y coherencia de los conjuntos de juicios y tratar de caracterizarlos en el lenguaje l\u00f3gico, como propiedades de conjuntos de juicios generales.Teorema de Arrow y paradoja de Condorcet. Sostenemos que estos resultados muestran exactamente qu\u00e9 capacidades l\u00f3gicas necesita un agente para poder razonar sobre la agregaci\u00f3n de juicios. Quiz\u00e1s resulte sorprendente que un lenguaje relativamente simple proporcione estas capacidades. La axiomatizaci\u00f3n describe los principios l\u00f3gicos de la agregaci\u00f3n de juicios y tambi\u00e9n se puede instanciar para razonar sobre instancias espec\u00edficas de agregaci\u00f3n de juicios, como la agregaci\u00f3n de preferencias arroviana cl\u00e1sica. As\u00ed, nuestro marco arroja luz sobre las diferencias entre los principios l\u00f3gicos detr\u00e1s de la agregaci\u00f3n de juicios generales, por un lado, y la agregaci\u00f3n de preferencias cl\u00e1sica, por el otro. En trabajos futuros ser\u00eda interesante flexibilizar los requisitos de integridad y coherencia de los conjuntos de juicios y tratar de caracterizarlos en el lenguaje l\u00f3gico, como propiedades de conjuntos de juicios generales.", "keyphrases": ["conocimiento representa formal", "funci\u00f3n de bienestar social", "axiomatis completa", "sintaxis y sem\u00e1ntica de jal", "discurre la paradoja", "regla agregada de juicio", "teorema de la flecha", "expresar", "no dictadura", "unanimidad", "prefiero agregar", "l\u00f3gica de flecha", "jala"]}
{"file_name": "C-27", "text": "Un sistema de localizaci\u00f3n de alta precisi\u00f3n y bajo costo para redes de sensores inal\u00e1mbricos RESUMEN El problema de la localizaci\u00f3n de nodos de sensores inal\u00e1mbricos se ha considerado durante mucho tiempo como muy dif\u00edcil de resolver, cuando se consideran las realidades de los entornos del mundo real. En este art\u00edculo, describimos, dise\u00f1amos, implementamos y evaluamos formalmente un novedoso sistema de localizaci\u00f3n, llamado Spotlight. Nuestro sistema utiliza las propiedades espacio-temporales de eventos bien controlados en la red -LRB-, por ejemplo, luz -RRB-, para obtener las ubicaciones de los nodos sensores. Demostramos que se puede lograr una alta precisi\u00f3n en la localizaci\u00f3n sin la ayuda de hardware costoso en los nodos sensores, como lo requieren otros sistemas de localizaci\u00f3n. Evaluamos el desempe\u00f1o de nuestro sistema en implementaciones de motas Mica2 y XSM. Mediante evaluaciones de desempe\u00f1o de un sistema real implementado en exteriores, obtenemos un error de localizaci\u00f3n de 20 cm. Una red de sensores, con cualquier n\u00famero de nodos, desplegada en un \u00e1rea de 2.500 m2, se puede localizar en menos de 10 minutos, utilizando un dispositivo que cuesta menos de 1.000 d\u00f3lares. Hasta donde sabemos, este es el primer informe de una sub- error de localizaci\u00f3n del medidor, obtenido en un entorno exterior, sin equipar los nodos de sensores inal\u00e1mbricos con hardware de alcance especializado. 1. INTRODUCCI\u00d3N Recientemente, los sistemas de redes de sensores inal\u00e1mbricos se han utilizado en muchas aplicaciones prometedoras, incluida la vigilancia militar, el monitoreo del h\u00e1bitat, el seguimiento de la vida silvestre, etc. -LSB- 12 -RSB- -LSB- 22 -RSB- -LSB- 33 -RSB- -LSB - 36 -RSB-. Si bien se han dise\u00f1ado e implementado con \u00e9xito muchos servicios de middleware para respaldar estas aplicaciones, la localizaci\u00f3n (encontrar la posici\u00f3n de los nodos sensores) sigue siendo uno de los desaf\u00edos de investigaci\u00f3n m\u00e1s dif\u00edciles de resolver en la pr\u00e1ctica. Un GPS integrado -LSB- 23 -RSB- es una soluci\u00f3n t\u00edpica de alta gama, que requiere un hardware sofisticado para lograr una sincronizaci\u00f3n horaria de alta resoluci\u00f3n con los sat\u00e9lites. Las limitaciones de energ\u00eda y costo de los peque\u00f1os nodos sensores impiden que esta sea una soluci\u00f3n viable. Otras soluciones requieren dispositivos por nodo que puedan realizar mediciones entre nodos vecinos. Las dificultades de estos enfoques son dobles. En primer lugar, bajo limitaciones de factor de forma y suministro de energ\u00eda, los alcances efectivos de dichos dispositivos son muy limitados. Por ejemplo, el alcance efectivo de los transductores ultras\u00f3nicos utilizados en el sistema Cricket es inferior a 2 metros cuando el emisor y el receptor no est\u00e1n uno frente al otro -LSB- 26 -RSB-. En segundo lugar, dado que la mayor\u00eda de los nodos sensores son est\u00e1ticos, es decir, no se espera que cambie la ubicaci\u00f3n, no es rentable equipar estos sensores con circuitos especiales s\u00f3lo para una localizaci\u00f3n \u00fanica. Para superar estas limitaciones, se han propuesto muchos esquemas de localizaci\u00f3n sin alcance. La mayor\u00eda de estos esquemas estiman la ubicaci\u00f3n de los nodos sensores explotando la informaci\u00f3n de conectividad de radio entre los nodos vecinos. Estos enfoques eliminan la necesidad de hardware especializado de alto costo, a costa de una localizaci\u00f3n menos precisa. Adem\u00e1s,Las caracter\u00edsticas de propagaci\u00f3n de radio var\u00edan con el tiempo y dependen del entorno, lo que impone altos costos de calibraci\u00f3n para los esquemas de localizaci\u00f3n sin alcance. Nuestra respuesta a este desaf\u00edo es un sistema de localizaci\u00f3n llamado Spotlight. Este sistema emplea una arquitectura asim\u00e9trica, en la que los nodos sensores no necesitan ning\u00fan hardware adicional al que tienen actualmente. Todo el hardware y la computaci\u00f3n sofisticados residen en un \u00fanico dispositivo Spotlight. El dispositivo Spotlight utiliza una fuente de luz l\u00e1ser orientable que ilumina los nodos de sensores ubicados dentro de un terreno conocido. Al mismo tiempo, dado que s\u00f3lo se necesita un dispositivo sofisticado para localizar toda la red, el costo amortizado es mucho menor que el costo de agregar componentes de hardware a los sensores individuales. 2. TRABAJOS RELACIONADOS El problema de la localizaci\u00f3n es un problema de investigaci\u00f3n fundamental en muchos dominios. Los errores de localizaci\u00f3n reportados son del orden de decenas de cent\u00edmetros, cuando se utiliza hardware de medici\u00f3n especializado, es decir, tel\u00e9metro l\u00e1ser o ultrasonido. Debido al alto coste y al factor de forma no despreciable del hardware de alcance, estas soluciones no se pueden aplicar simplemente a las redes de sensores. El RSSI ha resultado una soluci\u00f3n atractiva para estimar la distancia entre el emisor y el receptor. El sistema RADAR -LSB- 2 -RSB- utiliza el RSSI para construir un dep\u00f3sito centralizado de intensidades de se\u00f1al en varias posiciones con respecto a un conjunto de nodos de baliza. La ubicaci\u00f3n de un usuario de m\u00f3vil se estima en unos pocos metros. De manera similar, MoteTrack -LSB- 17 -RSB- distribuye los valores RSSI de referencia a los nodos de baliza. Tambi\u00e9n se han propuesto soluciones que utilizan RSSI y no requieren nodos de baliza -LSB- 5 -RSB- -LSB- 14 -RSB- -LSB- 24 -RSB- -LSB- 26 -RSB- -LSB- 29 -RSB-. Todos comparten la idea de utilizar una baliza m\u00f3vil. Los nodos sensores que reciben las balizas aplican diferentes algoritmos para inferir su ubicaci\u00f3n. En -LSB- 29 -RSB-, Sichitiu propone una soluci\u00f3n en la que los nodos que reciben la baliza construyen, en funci\u00f3n del valor RSSI, una restricci\u00f3n en su estimaci\u00f3n de posici\u00f3n. En -LSB-24-RSB-, Pathirana et al. Formule el problema de localizaci\u00f3n como una estimaci\u00f3n en l\u00ednea en un sistema din\u00e1mico no lineal y propone un filtro de Kalman extendido robusto para resolverlo. Elnahrawy -LSB- 8 -RSB- proporciona pruebas s\u00f3lidas de las limitaciones inherentes a la precisi\u00f3n de la localizaci\u00f3n utilizando RSSI en entornos interiores. Una t\u00e9cnica de determinaci\u00f3n de distancias m\u00e1s precisa utiliza la diferencia de tiempo entre una se\u00f1al de radio y una onda ac\u00fastica para obtener distancias por pares entre los nodos sensores. Este enfoque produce errores de localizaci\u00f3n m\u00e1s peque\u00f1os, a costa de hardware adicional. El sistema de soporte de localizaci\u00f3n Cricket -LSB- 25 -RSB- puede alcanzar una granularidad de localizaci\u00f3n de decenas de cent\u00edmetros con transceptores de ultrasonido de corto alcance. AHLoS, propuesto por Savvides et al. -LSB- 27 -RSB-, emplea t\u00e9cnicas de rango de tiempo de llegada -LRB- ToA -RRB- que requieren hardware extenso y la resoluci\u00f3n de sistemas de ecuaciones no lineales relativamente grandes.En -LSB-30-RSB-, Simon et al. implementar un sistema distribuido -LRB- mediante alcance ac\u00fastico -RRB- que localiza a un francotirador en un terreno urbano. Kwon et al. tambi\u00e9n utilizan el rango ac\u00fastico para la localizaci\u00f3n. -LSB- 15 -RSB-. Los errores reportados en la localizaci\u00f3n var\u00edan de 2,2 m a 9,5 m, dependiendo del tipo -LRB- centralizado vs. distribuido -RRB- del algoritmo de Escalado de M\u00ednimos Cuadrados utilizado. Para las redes de sensores inal\u00e1mbricos, el alcance es una opci\u00f3n dif\u00edcil. Sin embargo, la alta precisi\u00f3n de localizaci\u00f3n que se puede lograr con estos esquemas es muy deseable. Para superar los desaf\u00edos que plantean los esquemas de localizaci\u00f3n basados \u200b\u200ben rangos, cuando se aplican a redes de sensores, en el pasado se ha propuesto y evaluado un enfoque diferente. Este enfoque se denomina rango libre e intenta obtener informaci\u00f3n de ubicaci\u00f3n a partir de la proximidad a un conjunto de nodos de baliza conocidos. Bulusu et al. proponemos en -LSB- 4 -RSB- un esquema de localizaci\u00f3n, llamado Centroide, en el que cada nodo se localiza en el centroide de sus nodos de baliza pr\u00f3ximos. El Sistema Global de Coordenadas -LSB- 20 -RSB-, desarrollado en el MIT, utiliza el conocimiento a priori de la densidad de nodos en la red, para estimar la distancia promedio de salto. La familia DV - * de esquemas de localizaci\u00f3n -LSB- 21 -RSB-, utiliza el recuento de saltos desde nodos de baliza conocidos a los nodos de la red para inferir la distancia. La mayor\u00eda de los esquemas de localizaci\u00f3n sin alcance se han evaluado en simulaciones o entornos controlados. Langendoen y Reijers presentan un estudio comparativo detallado de varios esquemas de localizaci\u00f3n en -LSB- 16 -RSB-. Hasta donde sabemos, Spotlight es el primer esquema de localizaci\u00f3n sin alcance que funciona muy bien en un entorno exterior. Nuestro sistema requiere una l\u00ednea de visi\u00f3n entre un solo dispositivo y los nodos sensores, y el mapa del terreno donde se encuentra el campo sensor. El sistema Spotlight tiene un largo alcance efectivo -LRB- 1000 metros -RRB- y no requiere ninguna infraestructura ni hardware adicional para nodos sensores. El sistema Spotlight combina las ventajas y no sufre las desventajas de las dos clases de localizaci\u00f3n. 7. CONCLUSIONES Y TRABAJO FUTURO En este art\u00edculo presentamos el dise\u00f1o, implementaci\u00f3n y evaluaci\u00f3n de un sistema de localizaci\u00f3n para redes de sensores inal\u00e1mbricos, denominado Spotlight. Nuestra soluci\u00f3n de localizaci\u00f3n no requiere ning\u00fan hardware adicional para los nodos de sensores, aparte del que ya existe. Toda la complejidad del sistema est\u00e1 encapsulada en un \u00fanico dispositivo Spotlight. Nuestro sistema de localizaci\u00f3n es reutilizable, es decir, los costes se pueden amortizar mediante varias implementaciones y su rendimiento no se ve afectado por el n\u00famero de nodos de sensores en la red. Nuestros resultados experimentales, obtenidos de un sistema real implementado en exteriores, muestran que el error de localizaci\u00f3n es inferior a 20 cm. Este error es actualmente de \u00faltima generaci\u00f3n,incluso para sistemas de localizaci\u00f3n basados \u200b\u200ben rango y es un 75 % menor que el error obtenido cuando se utilizan dispositivos GPS o cuando el despliegue manual de nodos sensores es una opci\u00f3n factible -LSB- 31 -RSB-. Como trabajo futuro, nos gustar\u00eda explorar la autocalibraci\u00f3n y el autoajuste del sistema Spotlight. La precisi\u00f3n del sistema se puede mejorar a\u00fan m\u00e1s si se informa la distribuci\u00f3n del evento, en lugar de una \u00fanica marca de tiempo. Se podr\u00eda obtener una generalizaci\u00f3n reformulando el problema como un problema de estimaci\u00f3n angular que proporcione los componentes b\u00e1sicos para t\u00e9cnicas de localizaci\u00f3n m\u00e1s generales.", "keyphrases": ["red de sensores inal\u00e1mbricos", "local", "base de rango local", "esquema sin sonar", "transmitir", "llevar a cabo", "precisi\u00f3n", "error local", "red de sensores", "sistema de foco", "t\u00e9cnica local", "distribuir"]}
{"file_name": "C-17", "text": "Problemas de implementaci\u00f3n de un sistema de conferencias VoIP en un entorno de conferencias virtuales RESUMEN Los servicios en tiempo real han sido admitidos en gran medida en redes de conmutaci\u00f3n de circuitos. Las tendencias recientes favorecen los servicios portados en redes de conmutaci\u00f3n de paquetes. Para las audioconferencias, debemos considerar muchos aspectos: escalabilidad, calidad de la aplicaci\u00f3n de conferencia, control de sala y carga en los clientes/servidores, por nombrar algunos. En este art\u00edculo, describimos un marco de servicio de audio dise\u00f1ado para proporcionar un entorno de conferencia virtual -LRB-VCE-RRB-. El sistema est\u00e1 dise\u00f1ado para dar cabida a un gran n\u00famero de usuarios finales que hablan al mismo tiempo y repartidos por Internet. El framework se basa en Servidores de Conferencias -LSB- 14 -RSB-, que facilitan el manejo del audio, mientras explotamos las capacidades SIP para fines de se\u00f1alizaci\u00f3n. La selecci\u00f3n de clientes se basa en un cuantificador reciente llamado ``N\u00famero de volumen'' que ayuda a imitar una conferencia f\u00edsica cara a cara. Abordamos los problemas de implementaci\u00f3n de la soluci\u00f3n propuesta tanto en t\u00e9rminos de escalabilidad como de interactividad, al tiempo que explicamos las t\u00e9cnicas que utilizamos para reducir el tr\u00e1fico. Hemos implementado una aplicaci\u00f3n Conference Server -LRB- CS -RRB- en una red que abarca todo el campus de nuestro Instituto. 1. INTRODUCCI\u00d3N La Internet actual utiliza el conjunto de protocolos IP que fue dise\u00f1ado principalmente para el transporte de datos y proporciona la mejor entrega de datos. Las limitaciones y caracter\u00edsticas de los retrasos separan los datos tradicionales, por un lado, de las aplicaciones de voz y v\u00eddeo, por el otro. Por lo tanto, a medida que se van implementando en Internet aplicaciones de voz y v\u00eddeo cada vez m\u00e1s urgentes, se pone de manifiesto la insuficiencia de Internet. Adem\u00e1s, buscamos trasladar los servicios telef\u00f3nicos a Internet. Entre ellos, la instalaci\u00f3n de conferencia virtual -LRB- teleconferencia -RRB- est\u00e1 a la vanguardia. Las conferencias de audio y v\u00eddeo en Internet son populares -LSB- 25 -RSB- por las diversas ventajas que conllevan -LSB- 3,6 -RSB-. Es evidente que el ancho de banda necesario para una teleconferencia a trav\u00e9s de Internet aumenta r\u00e1pidamente con el n\u00famero de participantes; Reducir el ancho de banda sin comprometer la calidad del audio es un desaf\u00edo en la Telefon\u00eda por Internet. Hay mucha discusi\u00f3n entre la comunidad de HCI y CSCW sobre el uso de la etnometodolog\u00eda para el dise\u00f1o de aplicaciones CSCW. El enfoque b\u00e1sico es proporcionar mayor ancho de banda, m\u00e1s instalaciones y mecanismos de control m\u00e1s avanzados, con miras a una mejor calidad de interacci\u00f3n. Este enfoque ignora la utilidad funcional del entorno que se utiliza para la colaboraci\u00f3n. Por lo tanto, es necesario adoptar un enfoque que considere ambos aspectos: el t\u00e9cnico y el funcional. En este trabajo, no hablamos de videoconferencias; su inclusi\u00f3n no beneficia significativamente la calidad de la conferencia -LSB- 4 -RSB-. Nuestro enfoque est\u00e1 en entornos de audio virtuales. Primero describimos los desaf\u00edos encontrados en las audioconferencias virtuales. Luego analizamos las motivaciones seguidas por la literatura relevante. En la Secci\u00f3n 5,Te explicamos la arquitectura de nuestro sistema. La secci\u00f3n 6 comprende la descripci\u00f3n de los diversos algoritmos utilizados en nuestra configuraci\u00f3n. Abordamos problemas de implementaci\u00f3n. A continuaci\u00f3n se realiza una discusi\u00f3n sobre el desempe\u00f1o. Concluimos considerando algunos problemas de implementaci\u00f3n. 4. TRABAJO RELACIONADO El est\u00e1ndar SIP definido en RFC 3261 -LSB- 22 -RSB- y en extensiones posteriores como -LSB- 21 -RSB- no ofrece servicios de control de conferencias como control de sala o votaci\u00f3n y no prescribe c\u00f3mo una Fig. 1. Ejemplo de conferencia: 3 dominios que contienen las entidades necesarias para que se pueda realizar la conferencia. se va a gestionar la conferencia. Sin embargo, se puede utilizar SIP para iniciar una sesi\u00f3n que utilice alg\u00fan otro protocolo de control de conferencia. La especificaci\u00f3n SIP principal admite muchos modelos para conferencias -LSB- 26, 23 -RSB-. En los modelos basados \u200b\u200ben servidor, un servidor mezcla flujos de medios, mientras que en una conferencia sin servidor, la mezcla se realiza en los sistemas finales. SDP -LSB- 7 -RSB- se puede utilizar para definir capacidades de medios y proporcionar otra informaci\u00f3n sobre la conferencia. Ahora consideraremos algunos modelos de conferencias en SIP que se han propuesto recientemente -LSB-23-RSB-. Primero, analicemos los modelos sin servidor. En End-System Mixing, solo un cliente -LRB- SIP UA -RRB- maneja la se\u00f1alizaci\u00f3n y mezcla de medios para todos los dem\u00e1s, lo que claramente no es escalable y causa problemas cuando ese cliente en particular abandona la conferencia. Esto conduce a un n\u00famero cada vez mayor de saltos para las hojas remotas y no es escalable. Otra opci\u00f3n ser\u00eda utilizar la multidifusi\u00f3n para conferencias, pero la multidifusi\u00f3n no est\u00e1 habilitada a trav\u00e9s de Internet y actualmente solo es posible en una LAN. Entre los modelos basados \u200b\u200ben servidor, en una conferencia telef\u00f3nica, los UA se conectan a un servidor central que maneja toda la mezcla. Este modelo no es escalable ya que est\u00e1 limitado por la potencia de procesamiento del servidor y el ancho de banda de la red. Las conferencias centralizadas adhoc y los servidores de conferencias telef\u00f3nicas tienen mecanismos y problemas similares. Los modelos h\u00edbridos que involucran se\u00f1alizaci\u00f3n centralizada y medios distribuidos, este \u00faltimo usando unidifusi\u00f3n o multidifusi\u00f3n, plantean problemas de escalabilidad como antes. Sin embargo, una ventaja es que el control de la conferencia puede ser una soluci\u00f3n de terceros. La p\u00e9rdida de espacialismo cuando se mezclan y el aumento del ancho de banda cuando no lo hacen son problemas abiertos. Un estudio relacionado -LSB- 19 -RSB- del mismo autor propone una arquitectura de conferencia para entornos virtuales colaborativos -LRB-CVE-RRB- pero no proporciona el \u00e1ngulo de escalabilidad sin la disponibilidad de multidifusi\u00f3n. Teniendo en cuenta las limitaciones de los sistemas de conferencias propuestos, ahora detallaremos nuestra propuesta. 9. CONCLUSI\u00d3N En este art\u00edculo, hemos presentado una discusi\u00f3n sobre un entorno de conferencia virtual s\u00f3lo de voz. Hemos argumentado que la naturaleza distribuida del despliegue aqu\u00ed lo hace escalable. La interactividad se logra adaptando un esquema de selecci\u00f3n de transmisi\u00f3n reciente basado en el n\u00famero de sonoridad. De este modo se consigue una utilizaci\u00f3n significativamente eficaz del ancho de banda.Estos hacen que el discurso improvisado en una teleconferencia virtual a trav\u00e9s de VoIP sea una realidad, como en una conferencia real cara a cara. El tr\u00e1fico en la WAN -LRB- Internet -RRB- est\u00e1 limitado superiormente por el cuadrado del n\u00famero de dominios, reducido a\u00fan m\u00e1s mediante el uso de algoritmos heur\u00edsticos, que est\u00e1 muy por debajo del n\u00famero total de clientes en la conferencia. Esto se debe al uso de un servidor de conferencias local para cada dominio. Las t\u00e9cnicas VAD ayudan a reducir a\u00fan m\u00e1s el tr\u00e1fico. El uso del est\u00e1ndar SIP para la se\u00f1alizaci\u00f3n hace que esta soluci\u00f3n sea altamente interoperable. Hemos implementado una aplicaci\u00f3n CS en una red de todo el campus. Creemos que esta nueva generaci\u00f3n de entornos de conferencias virtuales ganar\u00e1 m\u00e1s popularidad en el futuro a medida que su facilidad de implementaci\u00f3n est\u00e9 garantizada gracias a tecnolog\u00edas f\u00e1cilmente disponibles y marcos escalables.", "keyphrases": ["sistema de conferencias voip", "red de conmutaci\u00f3n de paquetes", "marco de servicio de audio", "entorno de conferencia virtual", "conferir servidor", "numero fuerte", "mezcla parcial", "detecci\u00f3n activa de voz", "basta con tres altavoces simult\u00e1neos", "t\u00e9cnica vad"]}
{"file_name": "H-30", "text": "Expansi\u00f3n de conceptos latentes utilizando campos aleatorios de Markov RESUMEN La expansi\u00f3n de consultas, en forma de retroalimentaci\u00f3n de pseudo-relevancia o retroalimentaci\u00f3n de relevancia, es una t\u00e9cnica com\u00fan utilizada para mejorar la efectividad de la recuperaci\u00f3n. La mayor\u00eda de los enfoques anteriores han ignorado cuestiones importantes, como el papel de las caracter\u00edsticas y la importancia de modelar las dependencias de t\u00e9rminos. En este art\u00edculo, proponemos una t\u00e9cnica robusta de expansi\u00f3n de consultas basada en el modelo de campos aleatorios de Markov para la recuperaci\u00f3n de informaci\u00f3n. La t\u00e9cnica, denominada expansi\u00f3n de conceptos latentes, proporciona un mecanismo para modelar dependencias de t\u00e9rminos durante la expansi\u00f3n. Adem\u00e1s, el uso de caracter\u00edsticas arbitrarias dentro del modelo proporciona un marco poderoso para ir m\u00e1s all\u00e1 de las simples caracter\u00edsticas de ocurrencia de t\u00e9rminos que son utilizadas impl\u00edcitamente por la mayor\u00eda de las otras t\u00e9cnicas de expansi\u00f3n. Evaluamos nuestra t\u00e9cnica frente a modelos de relevancia, una t\u00e9cnica de expansi\u00f3n de consultas de modelado de lenguaje de \u00faltima generaci\u00f3n. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de la recuperaci\u00f3n en varios conjuntos de datos TREC. Tambi\u00e9n describimos c\u00f3mo se puede utilizar nuestra t\u00e9cnica para generar conceptos significativos de varios t\u00e9rminos para tareas como la sugerencia/reformulaci\u00f3n de consultas. 1. INTRODUCCI\u00d3N posiblemente una narrativa m\u00e1s larga. Se pierde una gran cantidad de informaci\u00f3n durante el proceso de traducci\u00f3n de la informaci\u00f3n necesaria a la consulta real. Por esta raz\u00f3n, ha habido un gran inter\u00e9s en las t\u00e9cnicas de expansi\u00f3n de consultas. Estas t\u00e9cnicas se utilizan para aumentar la consulta original y producir una representaci\u00f3n que refleje mejor la necesidad de informaci\u00f3n subyacente. Las t\u00e9cnicas de expansi\u00f3n de consultas han sido bien estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la configuraci\u00f3n de retroalimentaci\u00f3n de relevancia como en la retroalimentaci\u00f3n de pseudorelevancia -LSB- 12, 21, 28, 29 -RSB-. El modelo MRF generaliza el unigrama, el bigrama y otros modelos de dependencia diversos -LSB- 14 -RSB-. La mayor\u00eda de los modelos de dependencia de t\u00e9rminos anteriores no han logrado mostrar mejoras consistentes y significativas con respecto a las l\u00edneas de base de unigrama, con pocas excepciones -LSB- 8 -RSB-. Hasta ahora, el modelo se ha utilizado \u00fanicamente para clasificar documentos en respuesta a una consulta determinada. En este trabajo, mostramos c\u00f3mo el modelo se puede extender y utilizar para la expansi\u00f3n de consultas utilizando una t\u00e9cnica que llamamos expansi\u00f3n de conceptos latentes -LRB-LCE-RRB-. Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de t\u00e9rminos con la expansi\u00f3n de consultas. Las t\u00e9cnicas de expansi\u00f3n de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansi\u00f3n de consultas utilizando el modelo MRF, podemos estudiar la din\u00e1mica entre la dependencia de t\u00e9rminos y la expansi\u00f3n de consultas. A continuaci\u00f3n, como mostraremos, el modelo MRF permite utilizar caracter\u00edsticas arbitrarias dentro del modelo. Las t\u00e9cnicas de expansi\u00f3n de consultas en el pasado impl\u00edcitamente solo hac\u00edan uso de caracter\u00edsticas de ocurrencia de t\u00e9rminos. Al utilizar conjuntos de caracter\u00edsticas m\u00e1s s\u00f3lidos, es posible producir mejores t\u00e9rminos de expansi\u00f3n que discriminen mejor entre documentos relevantes y no relevantes. Finalmente,Nuestro enfoque propuesto proporciona perfectamente un mecanismo para generar conceptos tanto de un solo t\u00e9rmino como de varios t\u00e9rminos. La mayor\u00eda de las t\u00e9cnicas anteriores, por defecto, generan t\u00e9rminos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo dichos enfoques fueron algo heur\u00edsticos y se realizaron fuera del modelo -LSB- 19, 28 -RSB-. Nuestro enfoque tiene una motivaci\u00f3n formal y una extensi\u00f3n natural del modelo subyacente. En la Secci\u00f3n 2 describimos enfoques de expansi\u00f3n de consultas relacionados. La Secci\u00f3n 3 proporciona una descripci\u00f3n general del modelo MRF y detalla nuestra t\u00e9cnica de expansi\u00f3n de conceptos latentes propuesta. En la Secci\u00f3n 4 evaluamos nuestro modelo propuesto y analizamos los resultados. 2. TRABAJOS RELACIONADOS Uno de los enfoques cl\u00e1sicos y m\u00e1s utilizados para la expansi\u00f3n de consultas es el algoritmo de Rocchio -LSB- 21 -RSB-. El enfoque de Rocchio, que se desarroll\u00f3 dentro del modelo de espacio vectorial, vuelve a ponderar el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudorelevantes y alej\u00e1ndolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperaci\u00f3n estad\u00edstica, como el modelado del lenguaje para la recuperaci\u00f3n de informaci\u00f3n. Se han desarrollado una serie de t\u00e9cnicas de expansi\u00f3n de consultas formalizadas para el marco de modelado del lenguaje, incluida la retroalimentaci\u00f3n basada en modelos de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Croft -LSB- 12, 29 -RSB-. Ambos enfoques intentan utilizar documentos pseudorelevantes o relevantes para estimar un mejor modelo de consulta. La retroalimentaci\u00f3n basada en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo -LRB- ruido -RRB-. Esto separa el modelo de contenido del modelo de fondo. Luego, el modelo de contenido se interpola con el modelo de consulta original para formar la consulta expandida. La otra t\u00e9cnica, los modelos de relevancia, est\u00e1 m\u00e1s estrechamente relacionada con nuestro trabajo. Por tanto, entramos en los detalles del modelo. Al igual que la retroalimentaci\u00f3n basada en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La \u00fanica diferencia entre los dos enfoques es que los modelos de relevancia no modelan expl\u00edcitamente los documentos relevantes o pseudorelevantes. En cambio, modelan una noci\u00f3n m\u00e1s generalizada de relevancia, como mostramos ahora. Dada una consulta Q, un modelo de relevancia es una distribuci\u00f3n multinomial, P -LRB- \u00b7 | Q -RRB-, que codifica la probabilidad de cada t\u00e9rmino dado la consulta como evidencia. Se calcula como: donde RQ es el conjunto de documentos que son relevantes o pseudorelevantes para consultar Q. Estos supuestos leves hacen que calcular el posterior bayesiano sea m\u00e1s pr\u00e1ctico. Despu\u00e9s de estimar el modelo, los documentos se clasifican recortando el modelo de relevancia eligiendo los k t\u00e9rminos m\u00e1s probables de P -LRB- \u00b7 | Q -RRB-. Esta distribuci\u00f3n recortada luego se interpola con el modelo de consulta de m\u00e1xima verosimilitud original -LSB- 1 -RSB-. Se puede considerar que esto es una expansi\u00f3n de la consulta original en k t\u00e9rminos ponderados. A lo largo del resto de este trabajo,Nos referimos a esta instanciaci\u00f3n de modelos de relevancia como RM3. Se ha trabajado relativamente poco en el \u00e1rea de expansi\u00f3n de consultas en el context de los modelos de dependencia -LSB- 9 -RSB-. Sin embargo, ha habido varios intentos de expandirse utilizando conceptos de t\u00e9rminos m\u00faltiples. El m\u00e9todo de an\u00e1lisis del context local -LRB- LCA -RRB- de Xu y Croft combin\u00f3 la recuperaci\u00f3n a nivel de pasaje con la expansi\u00f3n de conceptos, donde los conceptos eran t\u00e9rminos y frases individuales -LSB- 28 -RSB-. Los conceptos de expansi\u00f3n se eligieron y ponderaron utilizando una m\u00e9trica basada en estad\u00edsticas de coocurrencia. Papka y Allan investigan el uso de comentarios de relevancia para realizar una expansi\u00f3n de conceptos de m\u00faltiples t\u00e9rminos para el enrutamiento de documentos -LSB- 19 -RSB-. Los resultados mostraron que la combinaci\u00f3n de conceptos de un solo t\u00e9rmino y de ventana grande y de m\u00faltiples t\u00e9rminos mejor\u00f3 significativamente la efectividad. 5. CONCLUSIONES En este art\u00edculo propusimos una t\u00e9cnica robusta de expansi\u00f3n de consultas llamada expansi\u00f3n de conceptos latentes. Se demostr\u00f3 que la t\u00e9cnica es una extensi\u00f3n natural del modelo de campo aleatorio de Markov para la recuperaci\u00f3n de informaci\u00f3n y una generalizaci\u00f3n de modelos de relevancia. Demostramos que la t\u00e9cnica se puede utilizar para producir conceptos de expansi\u00f3n de m\u00faltiples t\u00e9rminos de alta calidad, bien formados y relevantes para el tema. Los conceptos generados se pueden utilizar en un m\u00f3dulo de sugerencia de consultas alternativo. Tambi\u00e9n demostramos que el modelo es muy eficaz. De hecho, logra mejoras significativas en la precisi\u00f3n promedio sobre los modelos de relevancia en una selecci\u00f3n de conjuntos de datos TREC. Tambi\u00e9n se demostr\u00f3 que el modelo MRF en s\u00ed, sin ninguna expansi\u00f3n de consultas, supera a los modelos de relevancia en grandes conjuntos de datos web. Finalmente, reiteramos la importancia de elegir t\u00e9rminos de expansi\u00f3n que modelen la relevancia, en lugar de los documentos relevantes, y mostramos c\u00f3mo LCE captura dependencias tanto sint\u00e1cticas como sem\u00e1nticas del lado de la consulta. El trabajo futuro tambi\u00e9n buscar\u00e1 incorporar dependencias del lado del documento.Los conceptos generados se pueden utilizar en un m\u00f3dulo de sugerencia de consultas alternativo. Tambi\u00e9n demostramos que el modelo es muy eficaz. De hecho, logra mejoras significativas en la precisi\u00f3n promedio sobre los modelos de relevancia en una selecci\u00f3n de conjuntos de datos TREC. Tambi\u00e9n se demostr\u00f3 que el modelo MRF en s\u00ed, sin ninguna expansi\u00f3n de consultas, supera a los modelos de relevancia en grandes conjuntos de datos web. Finalmente, reiteramos la importancia de elegir t\u00e9rminos de expansi\u00f3n que modelen la relevancia, en lugar de los documentos relevantes, y mostramos c\u00f3mo LCE captura dependencias tanto sint\u00e1cticas como sem\u00e1nticas del lado de la consulta. El trabajo futuro tambi\u00e9n buscar\u00e1 incorporar dependencias del lado del documento.Los conceptos generados se pueden utilizar en un m\u00f3dulo de sugerencia de consultas alternativo. Tambi\u00e9n demostramos que el modelo es muy eficaz. De hecho, logra mejoras significativas en la precisi\u00f3n promedio sobre los modelos de relevancia en una selecci\u00f3n de conjuntos de datos TREC. Tambi\u00e9n se demostr\u00f3 que el modelo MRF en s\u00ed, sin ninguna expansi\u00f3n de consultas, supera a los modelos de relevancia en grandes conjuntos de datos web. Finalmente, reiteramos la importancia de elegir t\u00e9rminos de expansi\u00f3n que modelen la relevancia, en lugar de los documentos relevantes, y mostramos c\u00f3mo LCE captura dependencias tanto sint\u00e1cticas como sem\u00e1nticas del lado de la consulta. El trabajo futuro tambi\u00e9n buscar\u00e1 incorporar dependencias del lado del documento.", "keyphrases": ["consulta robusta expande la t\u00e9cnica", "modelo de lenguaje queri expande la t\u00e9cnica", "retroalimentaci\u00f3n relevante", "retroalimentaci\u00f3n pseudo-relevante", "informar recuperar", "enfoque del modelo de lenguaje", "b\u00fasqueda Web", "la consulta se expande", "mrf", "algoritmo de rocchio", "marco del modelo de lenguaje", "rm3", "ruta de documentos", "recuperaci\u00f3n ad hoc", "modelo mrf", "distribuci\u00f3n relevante"]}
{"file_name": "I 10", "text": "SMILE: Aprendizaje incremental multiagente sonoro;--RRB- * RESUMEN Este art\u00edculo aborda el problema del aprendizaje colaborativo en un sistema multiagente. Aqu\u00ed cada agente puede actualizar incrementalmente sus creencias B -LRB- la representaci\u00f3n conceptual -RRB- de manera que se mantenga consistente con todo el conjunto de informaci\u00f3n K -LRB- los ejemplos -RRB- que ha recibido del entorno o otros agentes. Extendemos esta noci\u00f3n de consistencia -LRB- o solidez -RRB- a todo el MAS y discutimos c\u00f3mo lograr que, en cualquier momento, est\u00e9 presente en cada agente una misma representaci\u00f3n conceptual consistente. El protocolo correspondiente se aplica al concepto de aprendizaje supervisado. El m\u00e9todo resultante SMILE -LRB- que significa Sound Multiagent Incremental LEarning -RRB- se describe y experimenta aqu\u00ed. Sorprendentemente, algunas f\u00f3rmulas booleanas dif\u00edciles se aprenden mejor, dado el mismo conjunto de aprendizaje, con un sistema multiagente que con un solo agente. 1. INTRODUCCI\u00d3N Este art\u00edculo aborda el problema del aprendizaje colaborativo de conceptos en un sistema multiagente. -LSB- 6 -RSB- introduce una caracterizaci\u00f3n del aprendizaje en un sistema multiagente seg\u00fan el nivel de conciencia de los agentes. En el nivel 1, los agentes aprenden * El autor principal de este art\u00edculo es un estudiante. en el sistema sin tener en cuenta la presencia de otros agentes, excepto a trav\u00e9s de la modificaci\u00f3n que su acci\u00f3n produce en el medio ambiente. El nivel 2 implica una interacci\u00f3n directa entre los agentes ya que pueden intercambiar mensajes para mejorar su aprendizaje. En este art\u00edculo nos centramos en el nivel 2, estudiando la interacci\u00f3n directa entre agentes involucrados en un proceso de aprendizaje. Se supone que cada agente es capaz de aprender incrementalmente a partir de los datos que recibe, lo que significa que cada agente puede actualizar su conjunto de creencias B para mantenerlo consistente con todo el conjunto de informaci\u00f3n K que ha recibido del entorno o de otros agentes. Adem\u00e1s, suponemos que al menos una parte Bc de las creencias de cada agente es com\u00fan a todos los agentes y debe permanecer as\u00ed. Por tanto, una actualizaci\u00f3n de este conjunto com\u00fan Bc por parte del agente r debe provocar una actualizaci\u00f3n de Bc para toda la comunidad de agentes. Nos lleva a definir cu\u00e1l es la mas-consistencia de un agente respecto de la comunidad. El proceso de actualizaci\u00f3n de las creencias de la comunidad cuando uno de sus miembros obtiene nueva informaci\u00f3n puede definirse como el proceso de mantenimiento de la coherencia que garantiza que todos los agentes de la comunidad se mantengan masconsistentes. Este proceso de mantenimiento de la coherencia masiva en el que un agente obtiene nueva informaci\u00f3n le otorga el papel de aprendiz e implica comunicaci\u00f3n con otros agentes que act\u00faan como cr\u00edticos. Sin embargo, los agentes no est\u00e1n especializados y pueden a su vez ser aprendices o cr\u00edticos, sin que ninguno de ellos cumpla un rol espec\u00edfico. La informaci\u00f3n se distribuye entre los agentes, pero puede ser redundante. No hay una memoria central. El trabajo descrito aqu\u00ed tiene su origen en un trabajo anterior sobre el aprendizaje en un sistema multiagente intencional utilizando un formalismo BDI -LSB- 6 -RSB-. En ese trabajo,Los agentes ten\u00edan planes, cada uno de ellos asociado a un context que define en qu\u00e9 condiciones puede desencadenarse. Los planes -LRB- teniendo cada uno de ellos su propio context -RRB- eran comunes a todo el conjunto de agentes de la comunidad. Los agentes deb\u00edan adaptar los contexts de sus planes en funci\u00f3n del fracaso o \u00e9xito de los planes ejecutados, utilizando un mecanismo de aprendizaje y pidiendo ejemplos a otros agentes -LRB- de planes de \u00e9xito o fracasos -RRB-. Sin embargo, este trabajo carec\u00eda de un protocolo de aprendizaje colectivo que permitiera una autonom\u00eda real del sistema multiagente. El estudio de dicho protocolo es el objeto del presente art\u00edculo. En la secci\u00f3n 2 definimos formalmente la consistencia mas de un mecanismo de actualizaci\u00f3n para todo el MAS y proponemos un mecanismo de actualizaci\u00f3n gen\u00e9rico que demostr\u00f3 ser consistente mas. En la secci\u00f3n 3 describimos SMILE, un aprendiz de conceptos incremental de m\u00faltiples agentes que aplica nuestro mecanismo de actualizaci\u00f3n mas consistente al aprendizaje de conceptos colaborativo. La Secci\u00f3n 4 describe varios experimentos con SMILE y analiza varias cuestiones, incluido c\u00f3mo var\u00edan la precisi\u00f3n y la simplicidad de la hip\u00f3tesis actual al comparar el aprendizaje de un solo agente y el aprendizaje masivo. En la secci\u00f3n 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la secci\u00f3n 6 discutiendo investigaciones adicionales sobre el aprendizaje m\u00e1s consistente. 5. TRABAJOS RELACIONADOS Desde el a\u00f1o 96 -LSB- 15 -RSB- se han realizado diversos trabajos sobre aprendizaje en MAS, pero pocos sobre aprendizaje de conceptos. En -LSB- 11 -RSB- el MAS realiza una forma de aprendizaje conjunto en el que los agentes son aprendices perezosos -LRB- no se mantiene ninguna representaci\u00f3n expl\u00edcita -RRB- y venden ejemplos in\u00fatiles a otros agentes. En -LSB- 10 -RSB- cada agente observa todos los ejemplos pero s\u00f3lo percibe una parte de su representaci\u00f3n. En el aprendizaje mutuo de conceptos en l\u00ednea -LSB- 14 -RSB- los agentes convergen hacia una hip\u00f3tesis \u00fanica, pero cada agente produce ejemplos a partir de su propia representaci\u00f3n conceptual, lo que resulta en una especie de sincronizaci\u00f3n en lugar de un aprendizaje puro de conceptos. 6. CONCLUSI\u00d3N Hemos presentado aqu\u00ed y experimentado un protocolo para el aprendizaje de conceptos en l\u00ednea MAS. Sin embargo, nuestro marco es abierto, es decir, los agentes pueden salir del sistema o entrar en \u00e9l mientras se preserva el mecanismo de coherencia. Por ejemplo, si introducimos un mecanismo de tiempo de espera, incluso cuando un agente cr\u00edtico falla u omite responder, se implica la coherencia con los dem\u00e1s cr\u00edticos -LRB- dentro del resto de agentes -RRB-. El trabajo adicional se refiere, en primer lugar, a combinar la inducci\u00f3n y la abducci\u00f3n para realizar un aprendizaje colaborativo de conceptos cuando cada agente observa solo parcialmente los ejemplos y, en segundo lugar, investigar el aprendizaje de la memoria parcial: c\u00f3mo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados.Los agentes deb\u00edan adaptar los contexts de sus planes en funci\u00f3n del fracaso o \u00e9xito de los planes ejecutados, utilizando un mecanismo de aprendizaje y pidiendo ejemplos a otros agentes -LRB- de planes de \u00e9xito o fracasos -RRB-. Sin embargo, este trabajo carec\u00eda de un protocolo de aprendizaje colectivo que permitiera una autonom\u00eda real del sistema multiagente. El estudio de dicho protocolo es el objeto del presente art\u00edculo. En la secci\u00f3n 2 definimos formalmente la consistencia mas de un mecanismo de actualizaci\u00f3n para todo el MAS y proponemos un mecanismo de actualizaci\u00f3n gen\u00e9rico que demostr\u00f3 ser consistente mas. En la secci\u00f3n 3 describimos SMILE, un aprendiz de conceptos incremental de m\u00faltiples agentes que aplica nuestro mecanismo de actualizaci\u00f3n mas consistente al aprendizaje de conceptos colaborativo. La Secci\u00f3n 4 describe varios experimentos con SMILE y analiza varias cuestiones, incluido c\u00f3mo var\u00edan la precisi\u00f3n y la simplicidad de la hip\u00f3tesis actual al comparar el aprendizaje de un solo agente y el aprendizaje masivo. En la secci\u00f3n 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la secci\u00f3n 6 discutiendo investigaciones adicionales sobre el aprendizaje m\u00e1s consistente. 5. TRABAJOS RELACIONADOS Desde el a\u00f1o 96 -LSB- 15 -RSB- se han realizado diversos trabajos sobre aprendizaje en MAS, pero pocos sobre aprendizaje de conceptos. En -LSB- 11 -RSB- el MAS realiza una forma de aprendizaje conjunto en el que los agentes son aprendices perezosos -LRB- no se mantiene ninguna representaci\u00f3n expl\u00edcita -RRB- y venden ejemplos in\u00fatiles a otros agentes. En -LSB- 10 -RSB- cada agente observa todos los ejemplos pero s\u00f3lo percibe una parte de su representaci\u00f3n. En el aprendizaje mutuo de conceptos en l\u00ednea -LSB- 14 -RSB- los agentes convergen hacia una hip\u00f3tesis \u00fanica, pero cada agente produce ejemplos a partir de su propia representaci\u00f3n conceptual, lo que resulta en una especie de sincronizaci\u00f3n en lugar de un aprendizaje puro de conceptos. 6. CONCLUSI\u00d3N Hemos presentado aqu\u00ed y experimentado un protocolo para el aprendizaje de conceptos en l\u00ednea MAS. Sin embargo, nuestro marco es abierto, es decir, los agentes pueden salir del sistema o entrar en \u00e9l mientras se preserva el mecanismo de coherencia. Por ejemplo, si introducimos un mecanismo de tiempo de espera, incluso cuando un agente cr\u00edtico falla u omite responder, se implica la coherencia con los dem\u00e1s cr\u00edticos -LRB- dentro del resto de agentes -RRB-. El trabajo adicional se refiere, en primer lugar, a combinar la inducci\u00f3n y la abducci\u00f3n para realizar un aprendizaje colaborativo de conceptos cuando cada agente observa solo parcialmente los ejemplos y, en segundo lugar, investigar el aprendizaje de la memoria parcial: c\u00f3mo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados.Los agentes deb\u00edan adaptar los contexts de sus planes en funci\u00f3n del fracaso o \u00e9xito de los planes ejecutados, utilizando un mecanismo de aprendizaje y pidiendo ejemplos a otros agentes -LRB- de planes de \u00e9xito o fracasos -RRB-. Sin embargo, este trabajo carec\u00eda de un protocolo de aprendizaje colectivo que permitiera una autonom\u00eda real del sistema multiagente. El estudio de dicho protocolo es el objeto del presente art\u00edculo. En la secci\u00f3n 2 definimos formalmente la consistencia mas de un mecanismo de actualizaci\u00f3n para todo el MAS y proponemos un mecanismo de actualizaci\u00f3n gen\u00e9rico que demostr\u00f3 ser consistente mas. En la secci\u00f3n 3 describimos SMILE, un aprendiz de conceptos incremental de m\u00faltiples agentes que aplica nuestro mecanismo de actualizaci\u00f3n mas consistente al aprendizaje de conceptos colaborativo. La Secci\u00f3n 4 describe varios experimentos con SMILE y analiza varias cuestiones, incluido c\u00f3mo var\u00edan la precisi\u00f3n y la simplicidad de la hip\u00f3tesis actual al comparar el aprendizaje de un solo agente y el aprendizaje masivo. En la secci\u00f3n 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la secci\u00f3n 6 discutiendo investigaciones adicionales sobre el aprendizaje m\u00e1s consistente. 5. TRABAJOS RELACIONADOS Desde el a\u00f1o 96 -LSB- 15 -RSB- se han realizado diversos trabajos sobre aprendizaje en MAS, pero pocos sobre aprendizaje de conceptos. En -LSB- 11 -RSB- el MAS realiza una forma de aprendizaje conjunto en el que los agentes son aprendices perezosos -LRB- no se mantiene ninguna representaci\u00f3n expl\u00edcita -RRB- y venden ejemplos in\u00fatiles a otros agentes. En -LSB- 10 -RSB- cada agente observa todos los ejemplos pero s\u00f3lo percibe una parte de su representaci\u00f3n. En el aprendizaje mutuo de conceptos en l\u00ednea -LSB- 14 -RSB- los agentes convergen hacia una hip\u00f3tesis \u00fanica, pero cada agente produce ejemplos a partir de su propia representaci\u00f3n conceptual, lo que resulta en una especie de sincronizaci\u00f3n en lugar de un aprendizaje puro de conceptos. 6. CONCLUSI\u00d3N Hemos presentado aqu\u00ed y experimentado un protocolo para el aprendizaje de conceptos en l\u00ednea MAS. Sin embargo, nuestro marco es abierto, es decir, los agentes pueden salir del sistema o entrar en \u00e9l mientras se preserva el mecanismo de coherencia. Por ejemplo, si introducimos un mecanismo de tiempo de espera, incluso cuando un agente cr\u00edtico falla u omite responder, se implica la coherencia con los dem\u00e1s cr\u00edticos -LRB- dentro del resto de agentes -RRB-. El trabajo adicional se refiere, en primer lugar, a combinar la inducci\u00f3n y la abducci\u00f3n para realizar un aprendizaje colaborativo de conceptos cuando cada agente observa solo parcialmente los ejemplos y, en segundo lugar, investigar el aprendizaje de la memoria parcial: c\u00f3mo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados.un aprendiz de conceptos incremental de m\u00faltiples agentes que aplica nuestro mecanismo de actualizaci\u00f3n m\u00e1s consistente al aprendizaje de conceptos colaborativo. La Secci\u00f3n 4 describe varios experimentos con SMILE y analiza varias cuestiones, incluido c\u00f3mo var\u00edan la precisi\u00f3n y la simplicidad de la hip\u00f3tesis actual al comparar el aprendizaje de un solo agente y el aprendizaje masivo. En la secci\u00f3n 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la secci\u00f3n 6 discutiendo investigaciones adicionales sobre el aprendizaje m\u00e1s consistente. 5. TRABAJOS RELACIONADOS Desde el a\u00f1o 96 -LSB- 15 -RSB- se han realizado diversos trabajos sobre aprendizaje en MAS, pero pocos sobre aprendizaje de conceptos. En -LSB- 11 -RSB- el MAS realiza una forma de aprendizaje conjunto en el que los agentes son aprendices perezosos -LRB- no se mantiene ninguna representaci\u00f3n expl\u00edcita -RRB- y venden ejemplos in\u00fatiles a otros agentes. En -LSB- 10 -RSB- cada agente observa todos los ejemplos pero s\u00f3lo percibe una parte de su representaci\u00f3n. En el aprendizaje mutuo de conceptos en l\u00ednea -LSB- 14 -RSB- los agentes convergen hacia una hip\u00f3tesis \u00fanica, pero cada agente produce ejemplos a partir de su propia representaci\u00f3n conceptual, lo que resulta en una especie de sincronizaci\u00f3n en lugar de un aprendizaje puro de conceptos. 6. CONCLUSI\u00d3N Hemos presentado aqu\u00ed y experimentado un protocolo para el aprendizaje de conceptos en l\u00ednea MAS. Sin embargo, nuestro marco es abierto, es decir, los agentes pueden salir del sistema o entrar en \u00e9l mientras se preserva el mecanismo de coherencia. Por ejemplo, si introducimos un mecanismo de tiempo de espera, incluso cuando un agente cr\u00edtico falla u omite responder, se implica la coherencia con los dem\u00e1s cr\u00edticos -LRB- dentro del resto de agentes -RRB-. El trabajo adicional se refiere, en primer lugar, a combinar la inducci\u00f3n y la abducci\u00f3n para realizar un aprendizaje colaborativo de conceptos cuando cada agente observa solo parcialmente los ejemplos y, en segundo lugar, investigar el aprendizaje de la memoria parcial: c\u00f3mo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados.un aprendiz de conceptos incremental de m\u00faltiples agentes que aplica nuestro mecanismo de actualizaci\u00f3n m\u00e1s consistente al aprendizaje de conceptos colaborativo. La Secci\u00f3n 4 describe varios experimentos con SMILE y analiza varias cuestiones, incluido c\u00f3mo var\u00edan la precisi\u00f3n y la simplicidad de la hip\u00f3tesis actual al comparar el aprendizaje de un solo agente y el aprendizaje masivo. En la secci\u00f3n 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la secci\u00f3n 6 discutiendo investigaciones adicionales sobre el aprendizaje m\u00e1s consistente. 5. TRABAJOS RELACIONADOS Desde el a\u00f1o 96 -LSB- 15 -RSB- se han realizado diversos trabajos sobre aprendizaje en MAS, pero pocos sobre aprendizaje de conceptos. En -LSB- 11 -RSB- el MAS realiza una forma de aprendizaje conjunto en el que los agentes son aprendices perezosos -LRB- no se mantiene ninguna representaci\u00f3n expl\u00edcita -RRB- y venden ejemplos in\u00fatiles a otros agentes. En -LSB- 10 -RSB- cada agente observa todos los ejemplos pero s\u00f3lo percibe una parte de su representaci\u00f3n. En el aprendizaje mutuo de conceptos en l\u00ednea -LSB- 14 -RSB- los agentes convergen hacia una hip\u00f3tesis \u00fanica, pero cada agente produce ejemplos a partir de su propia representaci\u00f3n conceptual, lo que resulta en una especie de sincronizaci\u00f3n en lugar de un aprendizaje puro de conceptos. 6. CONCLUSI\u00d3N Hemos presentado aqu\u00ed y experimentado un protocolo para el aprendizaje de conceptos en l\u00ednea MAS. Sin embargo, nuestro marco es abierto, es decir, los agentes pueden salir del sistema o entrar en \u00e9l mientras se preserva el mecanismo de coherencia. Por ejemplo, si introducimos un mecanismo de tiempo de espera, incluso cuando un agente cr\u00edtico falla u omite responder, se implica la coherencia con los dem\u00e1s cr\u00edticos -LRB- dentro del resto de agentes -RRB-. El trabajo adicional se refiere, en primer lugar, a combinar la inducci\u00f3n y la abducci\u00f3n para realizar un aprendizaje colaborativo de conceptos cuando cada agente observa solo parcialmente los ejemplos y, en segundo lugar, investigar el aprendizaje de la memoria parcial: c\u00f3mo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados.resultando as\u00ed en una especie de sincronizaci\u00f3n m\u00e1s que en un puro aprendizaje de conceptos. 6. CONCLUSI\u00d3N Hemos presentado aqu\u00ed y experimentado un protocolo para el aprendizaje de conceptos en l\u00ednea MAS. Sin embargo, nuestro marco es abierto, es decir, los agentes pueden salir del sistema o entrar en \u00e9l mientras se preserva el mecanismo de coherencia. Por ejemplo, si introducimos un mecanismo de tiempo de espera, incluso cuando un agente cr\u00edtico falla u omite responder, se implica la coherencia con los dem\u00e1s cr\u00edticos -LRB- dentro del resto de agentes -RRB-. El trabajo adicional se refiere, en primer lugar, a combinar la inducci\u00f3n y la abducci\u00f3n para realizar un aprendizaje colaborativo de conceptos cuando cada agente observa solo parcialmente los ejemplos y, en segundo lugar, investigar el aprendizaje de la memoria parcial: c\u00f3mo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados.resultando as\u00ed en una especie de sincronizaci\u00f3n m\u00e1s que en un puro aprendizaje de conceptos. 6. CONCLUSI\u00d3N Hemos presentado aqu\u00ed y experimentado un protocolo para el aprendizaje de conceptos en l\u00ednea MAS. Sin embargo, nuestro marco es abierto, es decir, los agentes pueden salir del sistema o entrar en \u00e9l mientras se preserva el mecanismo de coherencia. Por ejemplo, si introducimos un mecanismo de tiempo de espera, incluso cuando un agente cr\u00edtico falla u omite responder, se implica la coherencia con los dem\u00e1s cr\u00edticos -LRB- dentro del resto de agentes -RRB-. El trabajo adicional se refiere, en primer lugar, a combinar la inducci\u00f3n y la abducci\u00f3n para realizar un aprendizaje colaborativo de conceptos cuando cada agente observa solo parcialmente los ejemplos y, en segundo lugar, investigar el aprendizaje de la memoria parcial: c\u00f3mo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados.", "keyphrases": ["aprendizaje multiagente", "concepto de colaboraci\u00f3n aprender", "aprender proceso", "conocimiento", "ma-consiste", "incremento aprender", "agente", "Mecanismo de actualizaci\u00f3n", "sincr\u00f3nico"]}
{"file_name": "H-31", "text": "Un estudio del modelo de generaci\u00f3n de consultas de Poisson para la recuperaci\u00f3n de informaci\u00f3n RESUMEN Se han propuesto muchas variantes de modelos de lenguaje para la recuperaci\u00f3n de informaci\u00f3n. La mayor\u00eda de los modelos existentes se basan en una distribuci\u00f3n multinomial y calificar\u00edan los documentos seg\u00fan la probabilidad de la consulta calculada seg\u00fan un modelo probabil\u00edstico de generaci\u00f3n de consultas. En este art\u00edculo, proponemos y estudiamos una nueva familia de modelos de generaci\u00f3n de consultas basados \u200b\u200ben la distribuci\u00f3n de Poisson. Mostramos que si bien en sus formas m\u00e1s simples, la nueva familia de modelos y los modelos multinomiales existentes son equivalentes, se comportan de manera diferente para muchos m\u00e9todos de suavizado. Mostramos que el modelo de Poisson tiene varias ventajas sobre el modelo multinomial, incluida la adaptaci\u00f3n natural al suavizado por t\u00e9rminos y la posibilidad de un modelado de fondo m\u00e1s preciso. Presentamos varias variantes del nuevo modelo correspondientes a diferentes m\u00e9todos de suavizado y las evaluamos en cuatro colecciones de pruebas TREC representativas. Los resultados muestran que, si bien sus modelos b\u00e1sicos funcionan de manera comparable, el modelo de Poisson puede superar al modelo multinomial con suavizamiento por t\u00e9rminos. El rendimiento se puede mejorar a\u00fan m\u00e1s con un suavizado de dos etapas. 1. INTRODUCCI\u00d3N Como un nuevo tipo de modelos de recuperaci\u00f3n probabil\u00edsticos, los modelos de lenguaje han demostrado ser efectivos para muchas tareas de recuperaci\u00f3n -LSB- 21, 28, 14, 4 -RSB-. Luego podemos clasificar los documentos seg\u00fan la probabilidad de generar la consulta. Pr\u00e1cticamente todos los modelos de lenguajes de generaci\u00f3n de consultas existentes se basan en la distribuci\u00f3n multinomial -LSB- 19, 6, 28 -RSB- o en la distribuci\u00f3n multivariada de Bernoulli -LSB- 21, 18 -RSB-. La distribuci\u00f3n multinomial es especialmente popular y tambi\u00e9n ha demostrado ser bastante eficaz. Tenga en cuenta que la ausencia de t\u00e9rminos tambi\u00e9n se captura indirectamente en un modelo multinomial a trav\u00e9s de la restricci\u00f3n de que todas las probabilidades de los t\u00e9rminos deben sumar 1. En este art\u00edculo, proponemos y estudiamos una nueva familia de modelos de generaci\u00f3n de consultas basados \u200b\u200ben la distribuci\u00f3n de Poisson. En esta nueva familia de modelos, modelamos la frecuencia de cada t\u00e9rmino de forma independiente con una distribuci\u00f3n de Poisson. Para calificar un documento, primero estimar\u00edamos un modelo de Poisson multivariado basado en el documento y luego lo calificar\u00edamos seg\u00fan la probabilidad de la consulta dada por el modelo de Poisson estimado. En cierto sentido, el modelo de Poisson combina la ventaja del multinomial al modelar la frecuencia de los t\u00e9rminos y la ventaja del multivariado de Bernoulli al acomodar el suavizado por t\u00e9rminos. Como en el trabajo existente sobre modelos de lenguaje multinomial, el suavizado es fundamental para esta nueva familia de modelos. Derivamos varios m\u00e9todos de suavizado para el modelo de Poisson en paralelo a los utilizados para distribuciones multinomiales, y comparamos los modelos de recuperaci\u00f3n correspondientes con aquellos basados \u200b\u200ben distribuciones multinomiales. Encontramos que, si bien con algunos m\u00e9todos de suavizado, el nuevo modelo y el modelo multinomial conducen a exactamente la misma f\u00f3rmula, con algunos otros m\u00e9todos de suavizado divergen, y el modelo de Poisson aporta m\u00e1s flexibilidad para el suavizado. En particular,una diferencia clave es que el modelo de Poisson puede acomodar naturalmente el suavizado permanente, lo cual es dif\u00edcil de lograr con un modelo multinomial sin un giro heur\u00edstico de la sem\u00e1ntica de un modelo generativo. Explotamos esta ventaja potencial para desarrollar un nuevo algoritmo de suavizado dependiente de t\u00e9rminos para el modelo de Poisson y mostramos que este nuevo algoritmo de suavizado puede mejorar el rendimiento con respecto a los algoritmos de suavizado independientes de t\u00e9rminos que utilizan el modelo Poisson o multinomial. Esta ventaja se observa tanto para el suavizado de una etapa como para el de dos etapas. Otra ventaja potencial del modelo de Poisson es que su correspondiente modelo de fondo para suavizado se puede mejorar mediante el uso de un modelo de mezcla que tenga una f\u00f3rmula de forma cerrada. Se ha demostrado que este nuevo modelo de fondo supera al modelo de fondo est\u00e1ndar y reduce la sensibilidad del rendimiento de recuperaci\u00f3n al par\u00e1metro de suavizado. En la Secci\u00f3n 2, presentamos la nueva familia de modelos de generaci\u00f3n de consultas con distribuci\u00f3n de Poisson y presentamos varios m\u00e9todos de suavizado que conducen a diferentes funciones de recuperaci\u00f3n. En la Secci\u00f3n 3, comparamos anal\u00edticamente el modelo de lenguaje de Poisson con el modelo de lenguaje multinomial, desde la perspectiva de la recuperaci\u00f3n. Luego dise\u00f1amos experimentos emp\u00edricos para comparar las dos familias de modelos de lenguaje en la Secci\u00f3n 4. Discutimos el trabajo relacionado en 5 y concluimos en 6. 5. TRABAJO RELACIONADO Hasta donde sabemos, no se han realizado estudios sobre modelos de generaci\u00f3n de consultas basados \u200b\u200ben sobre la distribuci\u00f3n de Poisson. Los modelos de lenguaje han demostrado ser eficaces para muchas tareas de recuperaci\u00f3n -LSB- 21, 28, 14, 4 -RSB-. El m\u00e1s popular y fundamental es el modelo de lenguaje de generaci\u00f3n de consultas -LSB- 21, 13 -RSB-. Todos los modelos de lenguaje de generaci\u00f3n de consultas existentes se basan en la distribuci\u00f3n multinomial -LSB- 19, 6, 28, 13 -RSB- o en la distribuci\u00f3n multivariada de Bernoulli -LSB- 21, 17, 18 -RSB-. Introducimos una nueva familia de modelos de lenguaje, basados \u200b\u200ben la distribuci\u00f3n de Poisson. La distribuci\u00f3n de Poisson ha sido estudiada previamente en los modelos de generaci\u00f3n de documentos -LSB- 16, 22, 3, 24 -RSB-, dando lugar al desarrollo de una de las f\u00f3rmulas de recuperaci\u00f3n m\u00e1s efectivas BM25 -LSB- 23 -RSB-. -LSB- 24 -RSB- estudia la derivaci\u00f3n paralela de tres modelos de recuperaci\u00f3n diferentes que est\u00e1 relacionada con nuestra comparaci\u00f3n de Poisson y multinomial. Sin embargo, el modelo de Poisson en su art\u00edculo todav\u00eda se encuentra dentro del marco de generaci\u00f3n de documentos y tampoco tiene en cuenta la variaci\u00f3n de la longitud del documento. -LSB- 26 -RSB- introduce una forma de buscar emp\u00edricamente un modelo exponencial para los documentos. Las mezclas de Poisson -LSB- 3 -RSB- como 2-Poisson -LSB- 22 -RSB-, multinomial negativo y KMixture de Katz -LSB- 9 -RSB- han demostrado ser efectivas para modelar y recuperar documentos. Una vez m\u00e1s, nada de este trabajo explora la distribuci\u00f3n de Poisson en el marco de generaci\u00f3n de consultas. El suavizado de modelos de lenguaje -LSB- 2, 28, 29 -RSB- y las estructuras de fondo -LSB- 15, 10, 25, 27 -RSB- se han estudiado con modelos de lenguaje multinomiales.-LSB- 7 -RSB- muestra anal\u00edticamente que la suavizaci\u00f3n espec\u00edfica de t\u00e9rminos podr\u00eda ser \u00fatil. Mostramos que el modelo de lenguaje Poisson es natural para acomodar el suavizado por t\u00e9rminos sin giro heur\u00edstico de la sem\u00e1ntica de un modelo generativo, y es capaz de modelar mejor de manera eficiente el fondo de la mezcla, tanto anal\u00edtica como emp\u00edricamente. 6. CONCLUSIONES Presentamos una nueva familia de modelos de lenguaje de generaci\u00f3n de consultas para recuperaci\u00f3n basados \u200b\u200ben la distribuci\u00f3n de Poisson. Derivamos varios m\u00e9todos de suavizado para esta familia de modelos, incluido el suavizado de una sola etapa y el suavizado de dos etapas. Comparamos los nuevos modelos con los populares modelos de recuperaci\u00f3n multinomial tanto de forma anal\u00edtica como experimental. Nuestro an\u00e1lisis muestra que, si bien nuestros nuevos modelos y modelos multinomiales son equivalentes seg\u00fan algunos supuestos, en general son diferentes con algunas diferencias importantes. En particular, mostramos que Poisson tiene una ventaja sobre el multinomial en la adaptaci\u00f3n natural al suavizado por t\u00e9rmino. Explotamos esta propiedad para desarrollar un nuevo algoritmo de suavizado por t\u00e9rmino para los modelos de lenguaje Poisson, que ha demostrado superar el suavizado independiente de los t\u00e9rminos tanto para los modelos Poisson como para los multinomiales. Adem\u00e1s, mostramos que se puede utilizar un modelo de fondo mixto para Poisson para mejorar el rendimiento y la solidez del modelo de fondo est\u00e1ndar de Poisson. Nuestro trabajo abre muchas direcciones interesantes para una mayor exploraci\u00f3n en esta nueva familia de modelos. Explorar m\u00e1s a fondo las flexibilidades de los modelos de lenguaje multinomiales, como la normalizaci\u00f3n de longitud y la pseudorretroalimentaci\u00f3n, podr\u00eda ser un buen trabajo futuro.Explorar m\u00e1s a fondo las flexibilidades de los modelos de lenguaje multinomiales, como la normalizaci\u00f3n de longitud y la pseudorretroalimentaci\u00f3n, podr\u00eda ser un buen trabajo futuro.Explorar m\u00e1s a fondo las flexibilidades de los modelos de lenguaje multinomiales, como la normalizaci\u00f3n de longitud y la pseudorretroalimentaci\u00f3n, podr\u00eda ser un buen trabajo futuro.", "keyphrases": ["distribuci\u00f3n multinomi", "modelo probabilista de queri gener", "distribuci\u00f3n de veneno", "suave de dos etapas", "distribuci\u00f3n multivari bernoullu", "reconocimiento de voz", "frecuencia de t\u00e9rmino", "suave permanente", "nuevo algoritmo suave dependiente de t\u00e9rminos", "conjunto de vocabulario", "proceso de veneno homog\u00e9neo", "pseudot\u00e9rmino \u00fanico"]}
{"file_name": "I-35", "text": "Gesti\u00f3n distribuida de normas en sistemas regulados de m\u00faltiples agentes * RESUMEN Las normas son ampliamente reconocidas como un medio para coordinar sistemas de m\u00faltiples agentes. La gesti\u00f3n distribuida de normas es un tema desafiante y observamos una falta de realizaciones computacionales verdaderamente distribuidas de modelos normativos. Para regular el comportamiento de agentes aut\u00f3nomos que participan en m\u00faltiples actividades relacionadas, proponemos un modelo normativo, la Estructura Normativa -LRB- NS -RRB-, un artefacto que se basa en la propagaci\u00f3n de posiciones normativas -LRB- obligaciones. , prohibiciones, permisos -RRB-, como consecuencias de la actuaci\u00f3n de los agentes. Dentro de una SN, pueden surgir conflictos debido a la naturaleza din\u00e1mica del MAS y la concurrencia de acciones de los agentes. Sin embargo, garantizar la ausencia de conflictos de una SN en el momento del dise\u00f1o es computacionalmente intratable. Mostramos esto formalizando la noci\u00f3n de conflicto, proporcionando un mapeo de las NS en redes de Petri coloreadas y tomando prestados resultados te\u00f3ricos bien conocidos de ese campo. Dado que se requiere la resoluci\u00f3n de conflictos en l\u00ednea, presentamos un algoritmo manejable para ser empleado de forma distribuida. Luego demostramos que este algoritmo es primordial para la implementaci\u00f3n distribuida de una NS. 1. INTRODUCCI\u00d3N Una caracter\u00edstica fundamental de los sistemas multiagente abiertos y regulados en los que interact\u00faan agentes aut\u00f3nomos es que los agentes participantes deben cumplir con las convenciones del sistema. Las normas pueden usarse para modelar tales convenciones y, por tanto, como un medio para regular el comportamiento observable de los agentes -LSB- 6, 29 -RSB-. Existen numerosos aportes sobre el tema de las normas por parte de soci\u00f3logos, fil\u00f3sofos y l\u00f3gicos -LRB- ej., -LSB- 15, 28 -RSB- -RRB-. Sin embargo, hay muy pocas propuestas para realizaciones computacionales de modelos normativos: la forma en que las normas pueden integrarse en el dise\u00f1o y ejecuci\u00f3n de MAS. Hasta donde sabemos, ninguna propuesta realmente apoya la promulgaci\u00f3n distribuida de entornos normativos. En nuestro art\u00edculo abordamos ese problema y proponemos medios para manejar compromisos conflictivos en sistemas abiertos, regulados y multiagente de manera distribuida. El tipo de MAS regulado que contemplamos consiste en m\u00faltiples actividades concurrentes y relacionadas donde los agentes interact\u00faan. Cada agente puede participar simult\u00e1neamente en varias actividades y cambiar de una actividad a otra. Las acciones de un agente dentro de una actividad pueden tener consecuencias en forma de posiciones normativas -LRB- es decir, obligaciones, permisos y prohibiciones -RRB- -LSB- 26 -RSB- que pueden limitar su comportamiento futuro. Suponemos que los agentes pueden optar por no cumplir con todas sus obligaciones y, por tanto, pueden ser sancionados por el MAS. Obs\u00e9rvese que, cuando se distribuyen las actividades, las posiciones normativas deben fluir desde las actividades en las que se generan hasta aquellas en las que tienen efecto. Dado que en un MAS abierto y regulado no se pueden incorporar aspectos normativos en el dise\u00f1o de los agentes,Adoptamos la opini\u00f3n de que la MAS deber\u00eda complementarse con un conjunto separado de normas que regule a\u00fan m\u00e1s el comportamiento de los agentes participantes. Para modelar la separaci\u00f3n de preocupaciones entre el nivel de coordinaci\u00f3n -LRB-, interacciones de agentes -RRB- y el nivel normativo -LRB- propagaci\u00f3n de posiciones normativas -RRB-, proponemos un artefacto llamado Estructura Normativa -LRB- NS -RRB. -. Dentro de una SN pueden surgir conflictos debido a la naturaleza din\u00e1mica del MAS y la concurrencia de acciones de los agentes. Por ejemplo, un agente puede verse obligado y prohibido a realizar la misma acci\u00f3n en una actividad. Sin embargo, garantizar la ausencia de conflictos de una SN en el momento del dise\u00f1o es computacionalmente intratable. Mostramos esto formalizando la noci\u00f3n de conflicto, proporcionando un mapeo de las NS en Redes de Petri de colores -LRB-CPN-RRB- y tomando prestados resultados te\u00f3ricos bien conocidos del campo de las CPN. Creemos que es necesaria la detecci\u00f3n y resoluci\u00f3n de conflictos en l\u00ednea. Por lo tanto, presentamos un algoritmo manejable para la resoluci\u00f3n de conflictos. Este algoritmo es fundamental para la implementaci\u00f3n distribuida de una Sociedad Nacional. El documento est\u00e1 organizado de la siguiente manera. En la Secci\u00f3n 2 detallamos un escenario que servir\u00e1 como ejemplo a lo largo del art\u00edculo. A continuaci\u00f3n, en la Secci\u00f3n 3 definimos formalmente el artefacto de estructura normativa. M\u00e1s adelante, en la Secci\u00f3n 4 formalizamos la noci\u00f3n de conflicto para analizar posteriormente la complejidad de la detecci\u00f3n de conflictos en t\u00e9rminos de CPN en la Secci\u00f3n 5. La Secci\u00f3n 6 describe la gesti\u00f3n computacional de las NS describiendo su implementaci\u00f3n y presentando un algoritmo para la resoluci\u00f3n de conflictos. Finalmente, comentamos el trabajo relacionado, sacamos conclusiones e informamos sobre el trabajo futuro en la Secci\u00f3n 7. 7. TRABAJO RELACIONADO Y CONCLUSIONES Nuestras contribuciones en este documento son triples. En primer lugar, introducimos un enfoque para la gesti\u00f3n y el razonamiento sobre normas de forma distribuida. Hasta donde sabemos, hay pocos trabajos publicados en esta direcci\u00f3n. En -LSB- 8, 21 -RSB-, se presentan dos lenguajes para la aplicaci\u00f3n distribuida de normas en MAS. Sin embargo, en ambos trabajos, cada agente tiene una interfaz de mensajes local que reenv\u00eda mensajes legales seg\u00fan un conjunto de normas. Dado que estas interfaces son locales para cada agente, las normas s\u00f3lo pueden expresarse en t\u00e9rminos de acciones de ese agente. Esta es una seria desventaja, por ejemplo cuando uno necesita activar una obligaci\u00f3n hacia un agente debido a un determinado mensaje de otro. El segundo aporte es la propuesta de una estructura normativa. La noci\u00f3n es fruct\u00edfera porque permite separar las preocupaciones normativas y procesales. La estructura normativa que proponemos hace evidente la similitud entre la propagaci\u00f3n de posiciones normativas y la propagaci\u00f3n de 642 The Sixth Intl.. Joint Conf. sobre Agentes Aut\u00f3nomos y Sistemas Multi-Agente -LRB- AAMAS 07 -RRB- de tokens en Redes de Petri de Colores. Esa similitud sugiere f\u00e1cilmente una correlaci\u00f3n entre los dos y da base para un tratamiento anal\u00edtico conveniente de la estructura normativa, en general,y la complejidad de la detecci\u00f3n de conflictos, en particular. En -LSB- 5 -RSB-, las conversaciones se dise\u00f1an y analizan primero a nivel de CPN y luego se traducen en protocolos. Lin et al. -LSB- 20 -RSB- asigna esquemas de conversaci\u00f3n a CPN. Hasta donde sabemos, el uso de esta representaci\u00f3n para apoyar la detecci\u00f3n de conflictos en MAS regulados no se ha informado en ning\u00fan otro lugar. Finalmente, presentamos un mecanismo distribuido para resolver conflictos normativos. Sartor -LSB- 25 -RSB- trata los conflictos normativos desde el punto de vista de la teor\u00eda jur\u00eddica y sugiere una manera de ordenar las normas involucradas. Su idea se implementa en -LSB- 12 -RSB- pero requiere un recurso central para el mantenimiento de la norma. El enfoque para la detecci\u00f3n y resoluci\u00f3n de conflictos es una adaptaci\u00f3n y extensi\u00f3n del trabajo sobre gr\u00e1ficos de creaci\u00f3n de instancias informado en -LSB- 17 -RSB- y un algoritmo relacionado en -LSB- 27 -RSB-. Estas tres contribuciones que presentamos en este art\u00edculo abren muchas posibilidades para trabajos futuros. Esperamos que tal acoplamiento dote a las instituciones electr\u00f3nicas de un entorno normativo m\u00e1s flexible (y m\u00e1s expresivo). Desde el punto de vista te\u00f3rico, pretendemos utilizar t\u00e9cnicas de an\u00e1lisis de CPN para caracterizar clases de CPN -LRB- por ejemplo, ac\u00edclicas, sim\u00e9tricas, etc. -RRB- correspondientes a familias de Estructuras Normativas que son susceptibles de detecci\u00f3n de conflictos manejables fuera de l\u00ednea. La combinaci\u00f3n de estas t\u00e9cnicas junto con nuestros mecanismos de resoluci\u00f3n de conflictos en l\u00ednea tiene como objetivo dotar a los dise\u00f1adores de MAS de la capacidad de incorporar normas en sus sistemas de forma basada en principios.La combinaci\u00f3n de estas t\u00e9cnicas junto con nuestros mecanismos de resoluci\u00f3n de conflictos en l\u00ednea tiene como objetivo dotar a los dise\u00f1adores de MAS de la capacidad de incorporar normas en sus sistemas de forma basada en principios.La combinaci\u00f3n de estas t\u00e9cnicas junto con nuestros mecanismos de resoluci\u00f3n de conflictos en l\u00ednea tiene como objetivo dotar a los dise\u00f1adores de MAS de la capacidad de incorporar normas en sus sistemas de forma basada en principios.", "keyphrases": ["algoritmo", "activo", "gui\u00f3n", "norma postulada", "protocolo", "escena normal", "regla de tr\u00e1nsito norma", "estructura normativa", "gr\u00e1fico bipartito", "prohibir", "permitir superposici\u00f3n", "simb\u00f3lico", "conflicto"]}
{"file_name": "I-33", "text": "Un camino formal desde las normas institucionales a las estructuras organizativas RESUMEN Hasta ahora, la forma en que se han utilizado las instituciones y organizaciones en el desarrollo de sistemas abiertos no ha ido m\u00e1s all\u00e1 de una heur\u00edstica \u00fatil. Para desarrollar sistemas que realmente implementen instituciones y organizaciones, los m\u00e9todos formales deben reemplazar a los heur\u00edsticos. El art\u00edculo presenta una sem\u00e1ntica formal para la noci\u00f3n de instituci\u00f3n y sus componentes -LRB-, normas abstractas y concretas, empoderamiento de agentes, roles -RRB- y define una relaci\u00f3n formal entre instituciones y estructuras organizacionales. Como resultado, se muestra c\u00f3mo las normas institucionales pueden refinarse hasta convertirse en constructos (estructuras organizativas) que se aproximan m\u00e1s a un sistema implementado. Tambi\u00e9n se muestra c\u00f3mo dicho proceso de refinamiento puede formalizarse completamente y, por tanto, ser susceptible de una verificaci\u00f3n rigurosa. 1. INTRODUCCI\u00d3N La oportunidad de una `` transferencia de tecnolog\u00eda '' desde el campo de la teor\u00eda organizacional y social a la IA distribuida y los sistemas multiagente -LRB- MASs -RRB- ha sido defendida durante mucho tiempo -LRB- -LSB- 8 -RSB- -RRB -. En las MAS, la aplicaci\u00f3n de met\u00e1foras organizacionales e institucionales al dise\u00f1o de sistemas ha demostrado ser \u00fatil para el desarrollo de metodolog\u00edas y herramientas. En muchos casos, sin embargo, la aplicaci\u00f3n de estos aparatos conceptuales equivale a meras heur\u00edsticas que gu\u00edan el dise\u00f1o de alto nivel de los sistemas. tratados formalmente, es decir, una vez que nociones como norma, rol, estructura, etc. obtienen una sem\u00e1ntica formal. El objetivo del presente art\u00edculo es llenar este vac\u00edo con respecto a la noci\u00f3n de instituci\u00f3n proporcionando fundamentos formales para la aplicaci\u00f3n de la met\u00e1fora institucional y para su relaci\u00f3n con la met\u00e1fora organizacional. El principal resultado del art\u00edculo consiste en mostrar c\u00f3mo las restricciones abstractas -LRB- instituciones -RRB- pueden ser refinadas paso a paso hasta descripciones estructurales concretas -LRB- estructuras organizativas -RRB- del sistema que se va a implementar, cerrando as\u00ed la brecha entre normas abstractas y especificaciones concretas del sistema. Concretamente, en la Secci\u00f3n 2 se presenta un marco l\u00f3gico que proporciona una sem\u00e1ntica formal para las nociones de instituci\u00f3n, norma y rol, y que respalda la explicaci\u00f3n de caracter\u00edsticas clave de las instituciones, tales como la traducci\u00f3n de normas abstractas en normas concretas e implementables, la empoderamiento institucional de los agentes, y algunos aspectos del dise\u00f1o de la aplicaci\u00f3n de normas. En la Secci\u00f3n 3 el marco se ampl\u00eda para abordar la noci\u00f3n de infraestructura de una instituci\u00f3n. Luego se estudia el marco ampliado en relaci\u00f3n con el formalismo para representar estructuras organizativas presentado en -LSB- 11 -RSB-. En la Secci\u00f3n 4 se presentan algunas conclusiones. 4. CONCLUSIONES El art\u00edculo tuvo como objetivo proporcionar un an\u00e1lisis formal integral de la met\u00e1fora institucional y su relaci\u00f3n con la organizacional. La herramienta formal predominante ha sido la l\u00f3gica descriptiva.TBoxes se ha utilizado para representar las especificaciones de instituciones -LRB- Definici\u00f3n 3 -RRB- y sus infraestructuras -LRB- Definici\u00f3n 6 -RRB-, proporcionando por lo tanto una sem\u00e1ntica de sistema de transici\u00f3n para una serie de nociones institucionales -LRB- Ejemplos 1-7 - RRB-. Luego se han utilizado multigr\u00e1ficos para representar la especificaci\u00f3n de estructuras organizativas -LRB- Definici\u00f3n 6 -RRB-. El \u00faltimo resultado presentado se refiere a la definici\u00f3n de una correspondencia formal entre las especificaciones de instituci\u00f3n y organizaci\u00f3n -LRB- Definici\u00f3n 7 -RRB-, que proporciona una forma formal para cambiar entre los dos paradigmas. En definitiva, estos resultados ofrecen una manera de relacionar especificaciones abstractas de sistemas -LRB- es decir, instituciones como conjuntos de normas -RRB- con especificaciones m\u00e1s cercanas a un sistema implementado -LRB- es decir, estructuras organizativas -RRB-.", "keyphrases": ["m\u00e9todo formal", "norma del instituto", "restricci\u00f3n abstracta", "formal para repres organiz structur", "entidad", "propiedad", "l\u00f3gica descriptiva", "l\u00f3gica din\u00e1mica", "axioma terminol\u00f3gico", "role", "infraestructura"]}
{"file_name": "C-36", "text": "Control de acceso mediante cifrado en redes din\u00e1micas de publicaci\u00f3n/suscripci\u00f3n multidominio RESUMEN Los sistemas de publicaci\u00f3n/suscripci\u00f3n proporcionan una infraestructura de comunicaciones distribuida de \u00e1rea amplia, eficiente y basada en eventos. Es probable que los sistemas de publicaci\u00f3n/suscripci\u00f3n a gran escala empleen componentes de la red de transporte de eventos propiedad de organizaciones cooperantes pero independientes. A medida que aumenta el n\u00famero de participantes en la red, la seguridad se convierte en una preocupaci\u00f3n cada vez mayor. Este art\u00edculo ampl\u00eda el trabajo anterior para presentar y evaluar una infraestructura segura de publicaci\u00f3n/suscripci\u00f3n multidominio que admita y aplique un control de acceso detallado sobre los atributos individuales de los tipos de eventos. La actualizaci\u00f3n de claves nos permite garantizar la seguridad hacia adelante y hacia atr\u00e1s cuando los agentes de eventos se unen y abandonan la red. Demostramos que los gastos generales de tiempo y espacio se pueden minimizar mediante una cuidadosa consideraci\u00f3n de las t\u00e9cnicas de cifrado y mediante el uso de almacenamiento en cach\u00e9 para disminuir los descifrados innecesarios. Mostramos que nuestro enfoque tiene una sobrecarga de comunicaci\u00f3n general menor que los enfoques existentes para lograr el mismo grado de control sobre la seguridad en redes de publicaci\u00f3n/suscripci\u00f3n. 1. INTRODUCCI\u00d3N La publicaci\u00f3n/suscripci\u00f3n es muy adecuada como mecanismo de comunicaci\u00f3n para crear aplicaciones distribuidas basadas en eventos a escala de Internet. de participantes proviene de su desacoplamiento de editores y suscriptores al colocar un servicio de entrega de eventos asincr\u00f3nicos entre ellos. En sistemas de publicaci\u00f3n/suscripci\u00f3n verdaderamente a escala de Internet, el servicio de entrega de eventos incluir\u00e1 un gran conjunto de nodos de intermediarios interconectados que abarcan una amplia \u00e1rea geogr\u00e1fica -LRB- y, por lo tanto, de red -RRB-. Si bien las capacidades de comunicaci\u00f3n de los sistemas de publicaci\u00f3n/suscripci\u00f3n est\u00e1n bien probadas, es probable que sea necesario abordar consideraciones de seguridad para abarcar m\u00faltiples dominios administrativos. Como la seguridad y el control de acceso son casi la ant\u00edtesis del desacoplamiento, hasta ahora relativamente poca investigaci\u00f3n de publicaci\u00f3n/suscripci\u00f3n se ha centrado en la seguridad. El objetivo general de nuestra investigaci\u00f3n es desarrollar redes de publicaci\u00f3n/suscripci\u00f3n a escala de Internet que proporcionen una entrega segura y eficiente de eventos, tolerancia a fallas y autorreparaci\u00f3n en la infraestructura de entrega, y una interfaz de eventos conveniente. En -LSB-12-RSB- Pesonen et al. proponer una arquitectura de control de acceso multidominio basada en capacidades para sistemas de publicaci\u00f3n/suscripci\u00f3n. La arquitectura proporciona un mecanismo para autorizar a los clientes de eventos a publicar y suscribirse a tipos de eventos. Los privilegios del cliente son verificados por el corredor local al que se conecta el cliente para acceder al sistema de publicaci\u00f3n/suscripci\u00f3n. El enfoque implementa el control de acceso en el borde de la red de intermediarios y supone que se puede confiar en que todos los intermediarios aplicar\u00e1n las pol\u00edticas de control de acceso correctamente. Cualquier corredor malicioso, comprometido o no autorizado es libre de leer y escribir cualquier evento que pase por \u00e9l en su camino desde los editores hasta los suscriptores. Proponemos hacer cumplir el control de acceso dentro de la red de corredores cifrando el contenido del evento,y esa pol\u00edtica dicta controles sobre las claves de cifrado necesarias. Con el contenido del evento cifrado, solo aquellos intermediarios que est\u00e1n autorizados a acceder a las claves de cifrado pueden acceder al contenido del evento -LRB-, es decir, publicar, suscribirse o filtrar -RRB-. Trasladamos efectivamente la aplicaci\u00f3n del control de acceso de los intermediarios a los administradores de claves de cifrado. Esperamos que sea necesario aplicar el control de acceso en un sistema de publicaci\u00f3n/suscripci\u00f3n multidominio cuando varias organizaciones forman un sistema de publicaci\u00f3n/suscripci\u00f3n compartido pero ejecutan m\u00faltiples aplicaciones independientes. El control de acceso tambi\u00e9n podr\u00eda ser necesario cuando una sola organizaci\u00f3n consta de m\u00faltiples subdominios que entregan datos confidenciales a trav\u00e9s del sistema de publicaci\u00f3n/suscripci\u00f3n de toda la organizaci\u00f3n. Ambos casos requieren control de acceso porque la entrega de eventos en una infraestructura din\u00e1mica de publicaci\u00f3n/suscripci\u00f3n basada en una red de intermediarios compartida bien puede llevar a que los eventos se enruten a trav\u00e9s de dominios no autorizados a lo largo de sus rutas desde los editores hasta los suscriptores. Hay dos beneficios particulares al compartir la infraestructura de publicaci\u00f3n/suscripci\u00f3n, los cuales se relacionan con la red de corredores. En primer lugar, los corredores de intercambio crear\u00e1n una red f\u00edsicamente m\u00e1s grande que proporcionar\u00e1 un mayor alcance geogr\u00e1fico. En segundo lugar, aumentar la interconectividad de los corredores permitir\u00e1 que el sistema de publicaci\u00f3n/suscripci\u00f3n proporcione una mayor tolerancia a fallos. La Figura 1 muestra la red de publicaci\u00f3n/suscripci\u00f3n multidominio que utilizamos como ejemplo en este documento. Este dominio contiene un conjunto de c\u00e1maras CCTV que publican informaci\u00f3n sobre los movimientos de veh\u00edculos en el \u00e1rea de Londres. Hemos incluido al Detective Smith como suscriptor en este dominio. Dominio del servicio de cargo por congesti\u00f3n. Los sistemas dentro de este dominio emiten los cargos que se aplican a los veh\u00edculos que han pasado por la zona de Tasa de Congesti\u00f3n de Londres cada d\u00eda. Los datos de origen del reconocimiento de matr\u00edculas provienen de las c\u00e1maras del dominio de la Polic\u00eda Metropolitana. El hecho de que los CCS solo est\u00e9n autorizados a leer un subconjunto de los datos de eventos del veh\u00edculo ejercer\u00e1 algunas de las caracter\u00edsticas clave del control de acceso al sistema de publicaci\u00f3n/suscripci\u00f3n exigible presentado en este documento. Dominio PITO. Es el propietario del tipo de evento en este escenario particular. El cifrado protege la confidencialidad de los eventos en caso de que se transporten a trav\u00e9s de dominios no autorizados. Sin embargo, cifrar eventos completos significa que los agentes no autorizados no pueden tomar decisiones de enrutamiento eficientes. Nuestro enfoque es aplicar cifrado a los atributos individuales de los eventos. De esta manera, nuestra pol\u00edtica de control de acceso a m\u00faltiples dominios funciona con una granularidad m\u00e1s fina: los editores y suscriptores pueden tener acceso autorizado a un subconjunto de atributos disponibles. En los casos en los que se utilizan eventos no cifrados para el enrutamiento, podemos reducir la cantidad total de eventos enviados a trav\u00e9s del sistema sin revelar los valores de los atributos confidenciales. De este modo, preservamos la privacidad de los conductores y al mismo tiempo permitimos que el CCS haga su trabajo utilizando la infraestructura compartida de publicaci\u00f3n/suscripci\u00f3n.La detective obtiene una orden judicial que la autoriza a suscribirse a eventos de matr\u00edcula espec\u00edficos relacionados con su caso. Los sistemas actuales de control de acceso de publicaci\u00f3n/suscripci\u00f3n imponen la seguridad en el borde de la red de intermediarios donde los clientes se conectan a ella. Sin embargo, este enfoque a menudo no ser\u00e1 aceptable en sistemas a escala de Internet. Proponemos reforzar la seguridad dentro de la red de corredores, as\u00ed como en los bordes a los que se conectan los clientes de eventos, mediante el cifrado del contenido del evento. Las publicaciones se cifrar\u00e1n con sus claves de cifrado espec\u00edficas del tipo de evento. Al controlar el acceso a las claves de cifrado, podemos controlar el acceso a los tipos de eventos. El enfoque propuesto permite a los agentes de eventos enrutar eventos incluso cuando solo tienen acceso a un subconjunto de posibles claves de cifrado. Introducimos sistemas descentralizados de publicaci\u00f3n/suscripci\u00f3n y criptograf\u00eda relevante en la Secci\u00f3n 2. En la Secci\u00f3n 3 presentamos nuestro modelo para cifrar el contenido del evento tanto a nivel de evento como de atributo. La secci\u00f3n 4 analiza la gesti\u00f3n de claves de cifrado en sistemas de publicaci\u00f3n/suscripci\u00f3n multidominio. Finalmente, la Secci\u00f3n 6 analiza el trabajo relacionado con la seguridad de los sistemas de publicaci\u00f3n/suscripci\u00f3n y la Secci\u00f3n 7 proporciona comentarios finales. 2. ANTECEDENTES En esta secci\u00f3n proporcionamos una breve introducci\u00f3n a los sistemas descentralizados de publicaci\u00f3n/suscripci\u00f3n. Indicamos nuestras suposiciones sobre los sistemas de publicaci\u00f3n/suscripci\u00f3n multidominio y describimos c\u00f3mo estas suposiciones influyen en los desarrollos que hemos realizado a partir de nuestro trabajo publicado anteriormente. 2.1 Sistemas descentralizados de publicaci\u00f3n/suscripci\u00f3n Un sistema de publicaci\u00f3n/suscripci\u00f3n incluye editores, suscriptores y un servicio de eventos. Los editores publican eventos, los suscriptores se suscriben a eventos de su inter\u00e9s y el servicio de eventos es responsable de entregar los eventos publicados a todos los suscriptores cuyos intereses coincidan con el evento determinado. El servicio de eventos en un sistema de publicaci\u00f3n/suscripci\u00f3n descentralizado se distribuye entre varios nodos de intermediario. Juntos, estos corredores forman una red que es responsable de mantener las rutas de enrutamiento necesarias desde los editores hasta los suscriptores. Los clientes -LRB-, los editores y los suscriptores -RRB- se conectan a un corredor local, en el que el cliente conf\u00eda plenamente. En nuestra discusi\u00f3n nos referimos a los brokers de hosting de clientes como brokers de hosting de editores -LRB- PHB -RRB- o brokers de hosting de suscriptores -LRB- SHB -RRB- dependiendo de si el cliente conectado es un editor o un editor. implementaci\u00f3n de publicaci\u00f3n/suscripci\u00f3n multidominio por suscriptor, respectivamente. Un corredor local suele formar parte del mismo dominio que el cliente o es propiedad de un proveedor de servicios en el que el cliente conf\u00eda. Una red de intermediarios puede tener una topolog\u00eda est\u00e1tica -LRB-, por ejemplo, Siena -LSB- 3 -RSB- y Gryphon -LSB- 14 -RSB- -RRB- o una topolog\u00eda din\u00e1mica -LRB-, por ejemplo, Scribe -LSB- 4 -RSB- y Hermes. -LSB- 13 -RSB- -RRB-. Nuestro enfoque propuesto funcionar\u00e1 en ambos casos.Una topolog\u00eda est\u00e1tica permite al administrador del sistema crear dominios confiables y de esa manera mejorar la eficiencia del enrutamiento evitando cifrados innecesarios -LRB- ver Secci\u00f3n. Nuestro trabajo se basa en el sistema Hermes. Hermes es un middleware de publicaci\u00f3n/suscripci\u00f3n basado en contenido que incluye un s\u00f3lido soporte para tipos de eventos. En otras palabras, cada publicaci\u00f3n es una instancia de un tipo de evento predefinido particular. Las publicaciones se verifican en el corredor local de cada editorial. Nuestro esquema de cifrado a nivel de atributo supone que los eventos se escriben. Hermes utiliza una red superpuesta estructurada como transporte y, por lo tanto, tiene una topolog\u00eda din\u00e1mica. Una publicaci\u00f3n de Hermes consta de un identificador de tipo de evento y un conjunto de pares de valores de atributos. El identificador de tipo es el hash SHA-1 del nombre del tipo de evento. Se utiliza para enrutar la publicaci\u00f3n a trav\u00e9s de la red de agentes de eventos. Oculta convenientemente el tipo de publicaci\u00f3n, es decir, los corredores no pueden ver qu\u00e9 eventos fluyen a trav\u00e9s de ellos a menos que conozcan el nombre y el identificador del tipo de evento espec\u00edfico. 2.2 Tipos de eventos seguros Pesonen et al. introdujo tipos de eventos seguros en -LSB- 11 -RSB-, cuya integridad y autenticidad se puede confirmar mediante la verificaci\u00f3n de sus firmas digitales. Un efecto secundario \u00fatil de los tipos de eventos seguros es su tipo de evento y sus nombres de atributos \u00fanicos a nivel mundial. Las pol\u00edticas de control de acceso pueden hacer referencia a estos nombres. En este documento utilizamos el nombre seguro del tipo de evento o atributo para referirnos a la clave de cifrado utilizada para cifrar el evento o atributo. 2.3 Control de acceso basado en capacidades Pesonen et al. propuso una arquitectura de control de acceso basada en capacidades para sistemas de publicaci\u00f3n/suscripci\u00f3n multidominio en -LSB- 12 -RSB-. El modelo trata los tipos de eventos como recursos a los que los editores, suscriptores y agentes de eventos desean acceder. El propietario del tipo de evento es responsable de gestionar el control de acceso para un tipo de evento mediante la emisi\u00f3n de certificados de autorizaci\u00f3n de Infraestructura de clave p\u00fablica simple -LRB-SPKI-RRB- que otorgan al titular acceso al tipo de evento especificado. Por ejemplo, a los editores autorizados se les habr\u00e1 emitido un certificado de autorizaci\u00f3n que especifica que el editor, identificado por clave p\u00fablica, est\u00e1 autorizado a publicar instancias del tipo de evento especificado en el certificado. En este documento aprovechamos el mecanismo de control de acceso mencionado anteriormente controlando el acceso a las claves de cifrado utilizando los mismos certificados de autorizaci\u00f3n. Es decir, un editor que est\u00e1 autorizado a publicar un tipo de evento determinado tambi\u00e9n est\u00e1 autorizado a acceder a las claves de cifrado utilizadas para proteger eventos de ese tipo. 4. 2.4 Modelo de amenaza El objetivo del mecanismo propuesto es hacer cumplir el control de acceso para los participantes autorizados en el sistema. En nuestro caso, el primer nivel de control de acceso se aplica cuando el participante intenta unirse a la red de publicaci\u00f3n/suscripci\u00f3n. Los corredores de eventos no autorizados no pueden unirse a la red de corredores. De manera similar, los clientes de eventos no autorizados no pueden conectarse a un corredor de eventos.Todas las conexiones en la red de corredores entre los corredores de eventos y los clientes de eventos utilizan Transport Layer Security -LRB- TLS -RRB- -LSB- 5 -RSB- para evitar el acceso no autorizado en la capa de transporte. La arquitectura del sistema de publicaci\u00f3n/suscripci\u00f3n significa que los clientes de eventos deben conectarse a los agentes de eventos para poder acceder al sistema de publicaci\u00f3n/suscripci\u00f3n. Por tanto, asumimos que estos clientes no son una amenaza. El cliente de eventos depende completamente del corredor de eventos local para acceder a la red de corredores. Por lo tanto, el cliente del evento no puede acceder a ning\u00fan evento sin la ayuda del corredor local. Por otro lado, los corredores pueden analizar todos los eventos del sistema que pasan por ellos. Un broker puede analizar tanto el tr\u00e1fico de eventos como el n\u00famero y nombres de atributos que se pueblan en un evento -LRB- en el caso de cifrado a nivel de atributo -RRB-. Existen enfoques viables para prevenir el an\u00e1lisis del tr\u00e1fico mediante la inserci\u00f3n de eventos aleatorios en el flujo de eventos para producir un patr\u00f3n de tr\u00e1fico uniforme. 6. TRABAJOS RELACIONADOS Wang et al. han categorizado los diversos problemas de seguridad que deben abordarse en los sistemas de publicaci\u00f3n/suscripci\u00f3n en el futuro en -LSB- 20 -RSB-. El documento es una descripci\u00f3n general completa de los problemas de seguridad en los sistemas de publicaci\u00f3n/suscripci\u00f3n y, como tal, intenta llamar la atenci\u00f3n sobre los problemas en lugar de proporcionar soluciones. Tocino y cols. en -LSB- 1 -RSB- examina el uso del control de acceso basado en roles en sistemas de publicaci\u00f3n/suscripci\u00f3n distribuidos y multidominio. Opyrchal y Prakash abordan el problema de la confidencialidad de eventos en el \u00faltimo enlace entre el suscriptor y el SHB en -LSB- 10 -RSB-. Afirman correctamente que un enfoque de comunicaci\u00f3n grupal segura no es factible en un entorno como el de publicaci\u00f3n/suscripci\u00f3n que tiene membres\u00edas grupales altamente din\u00e1micas. En nuestro trabajo asumimos que el SHB es lo suficientemente potente como para mantener una conexi\u00f3n segura TLS para cada suscriptor local. Tanto Srivatsa et al. -LSB- 19 -RSB- y Raiciu et al. -LSB- 16 -RSB- presentan mecanismos para proteger la confidencialidad de los mensajes en infraestructuras descentralizadas de publicaci\u00f3n/suscripci\u00f3n. En comparaci\u00f3n con nuestro trabajo, ambos documentos tienen como objetivo proporcionar los medios para proteger la integridad y confidencialidad de los mensajes, mientras que el objetivo de nuestro trabajo es hacer cumplir el control de acceso dentro de la red de corredores. Raiciu et al. asumen en su trabajo que ninguno de los corredores de la red es confiable y, por lo tanto, todos los eventos est\u00e1n cifrados desde el editor hasta el suscriptor y que todas las coincidencias se basan en eventos cifrados. Por el contrario, suponemos que se conf\u00eda en que algunos de los intermediarios en el camino de una publicaci\u00f3n accedan a esa publicaci\u00f3n y, por lo tanto, pueden implementar la coincidencia de eventos. Tambi\u00e9n asumimos que siempre se conf\u00eda en el editor y los agentes de alojamiento de suscriptores para acceder a la publicaci\u00f3n. Finalmente, Fiege et al. aborde el tema relacionado de la visibilidad de eventos en -LSB- 6 -RSB-.Si bien el trabajo se concentr\u00f3 en el uso de \u00e1mbitos como mecanismo para estructurar sistemas basados \u200b\u200ben eventos a gran escala, la noci\u00f3n de visibilidad de eventos resuena con el control de acceso hasta cierto punto. 7. CONCLUSIONES El cifrado del contenido de eventos se puede utilizar para aplicar una pol\u00edtica de control de acceso mientras los eventos est\u00e1n en tr\u00e1nsito en la red de intermediarios de un sistema de publicaci\u00f3n/suscripci\u00f3n multidominio. Se puede implementar cifrado a nivel de atributo para aplicar pol\u00edticas de control de acceso detalladas. Adem\u00e1s de proporcionar control de acceso a nivel de atributos, el cifrado de atributos permite a los intermediarios parcialmente autorizados implementar enrutamiento basado en contenido seg\u00fan los atributos a los que tienen acceso.", "keyphrases": ["sistema seguro de publicaci\u00f3n/suscripci\u00f3n", "distribuir control de acceso", "dominio de administrador m\u00faltiple", "cifrado de atributo", "multidominio", "gastos generales comunes generales", "sistema de distribuci\u00f3n-aplicaci\u00f3n de distribuci\u00f3n", "llevar a cabo", "cifrar", "servicio de carga por congesti\u00f3n"]}
{"file_name": "C-29", "text": "Implementaci\u00f3n y evaluaci\u00f3n del rendimiento de CONFLEX-G: programa de b\u00fasqueda de espacio conformacional molecular habilitado para cuadr\u00edcula con OmniRPC RESUMEN CONFLEX-G es la versi\u00f3n habilitada para cuadr\u00edcula de un programa de b\u00fasqueda de espacio conformacional molecular llamado CONFLEX. Hemos implementado CONFLEX-G utilizando un sistema RPC de red llamado OmniRPC. En este art\u00edculo, informamos el rendimiento de CONFLEX-G en un banco de pruebas grid de varios cl\u00fasteres de PC distribuidos geogr\u00e1ficamente. Para explorar muchas conformaciones de biomol\u00e9culas grandes, CONFLEX-G genera estructuras de prueba de las mol\u00e9culas y asigna trabajos para optimizar una estructura de prueba con un m\u00e9todo confiable de mec\u00e1nica molecular en la red. OmniRPC proporciona un modelo de persistencia restringido para admitir aplicaciones de b\u00fasqueda param\u00e9trica. En este modelo, cuando el procedimiento de inicializaci\u00f3n se define en el m\u00f3dulo RPC, el m\u00f3dulo se inicializa autom\u00e1ticamente en el momento de la invocaci\u00f3n llamando al procedimiento de inicializaci\u00f3n. Esto puede eliminar comunicaciones e inicializaciones innecesarias en cada llamada en CONFLEX-G. CONFLEXG puede lograr un rendimiento comparable al de CONFLEX MPI y puede explotar m\u00e1s recursos inform\u00e1ticos al permitir el uso de un cl\u00faster de m\u00faltiples cl\u00fasteres en la red. El resultado experimental muestra que CONFLEX-G logr\u00f3 una aceleraci\u00f3n de 56,5 veces en el caso de la mol\u00e9cula 1BL1, donde la mol\u00e9cula consta de una gran cantidad de \u00e1tomos y cada optimizaci\u00f3n de la estructura de prueba requiere un tiempo significativo. El desequilibrio de carga del tiempo de optimizaci\u00f3n de la estructura de prueba tambi\u00e9n puede causar una degradaci\u00f3n del rendimiento. 1. INTRODUCCI\u00d3N Recientemente, el concepto de red computacional ha comenzado a atraer un inter\u00e9s significativo en el campo de la computaci\u00f3n en red de alto rendimiento. CONFLEX es uno de los programas de b\u00fasqueda de espacios conformacionales m\u00e1s eficientes y confiables -LSB- 1 -RSB-. Hemos aplicado este programa a la paralelizaci\u00f3n utilizando computaci\u00f3n global. El rendimiento del CONFLEX paralelizado permite la exploraci\u00f3n de la regi\u00f3n de menor energ\u00eda del espacio conformacional de p\u00e9ptidos peque\u00f1os dentro de un tiempo transcurrido disponible utilizando un grupo de PC local. Dado que la optimizaci\u00f3n de la estructura de prueba en CONFLEX se calcula mediante mec\u00e1nica molecular, la b\u00fasqueda del espacio conformacional se puede realizar r\u00e1pidamente en comparaci\u00f3n con la que se realiza mediante el c\u00e1lculo de orbitales moleculares. Aunque se utiliz\u00f3 la versi\u00f3n paralelizada de CONFLEX para calcular en paralelo la optimizaci\u00f3n de la estructura, que ocupa m\u00e1s del 90 % del procesamiento en la b\u00fasqueda de conformaci\u00f3n molecular, no se pudo lograr una mejora suficiente en la aceleraci\u00f3n solo con este m\u00e9todo. Esto requiere los vastos recursos inform\u00e1ticos de un entorno inform\u00e1tico en red. En este art\u00edculo, describimos CONFLEX-G, un programa de b\u00fasqueda conformacional molecular habilitado para cuadr\u00edculas, que utiliza OmniRPC e informamos su rendimiento en una cuadr\u00edcula de varios grupos de PC que est\u00e1n distribuidos geogr\u00e1ficamente. El prototipo CONFLEX-G asigna la optimizaci\u00f3n de las estructuras de prueba de c\u00e1lculo, que es una tarea que requiere mucho tiempo, a los nodos trabajadores en el entorno de la red para obtener un alto rendimiento.Adem\u00e1s, comparamos el rendimiento de CONFLEX-G en un cl\u00faster de PC local con el de un banco de pruebas grid. OmniRPC -LSB- 2, 3, 4 -RSB- es una implementaci\u00f3n segura para subprocesos de Ninf RPC -LSB- 5, 6 -RSB- que es una instalaci\u00f3n Grid RPC para inform\u00e1tica en entornos grid. Varios sistemas adoptan el concepto de RPC como modelo b\u00e1sico para la computaci\u00f3n en entorno grid, incluidos Ninf-G -LSB- 7 -RSB-, NetSolve -LSB- 8 -RSB- y CORBA -LSB- 9 -RSB-. El sistema RPCstyle proporciona una interfaz de programaci\u00f3n intuitiva y f\u00e1cil de usar, que permite a los usuarios del sistema grid crear f\u00e1cilmente aplicaciones habilitadas para grid. Para admitir la programaci\u00f3n paralela, un cliente RPC puede emitir solicitudes de llamadas as\u00edncronas a una computadora remota diferente para explotar el paralelismo en toda la red a trav\u00e9s de OmniRPC. En este art\u00edculo, proponemos el modelo de persistencia OmniRPC a un sistema Grid RPC y demostramos su efectividad. Para admitir una aplicaci\u00f3n t\u00edpica para un entorno de grilla, como una aplicaci\u00f3n de b\u00fasqueda param\u00e9trica, en la que la misma funci\u00f3n se ejecuta con diferentes par\u00e1metros de entrada en el mismo conjunto de datos. En el sistema GridRPC actual -LSB- 10 -RSB-, los datos establecidos por la llamada anterior no pueden ser utilizados por llamadas posteriores. Este art\u00edculo demuestra que CONFLEX-G es capaz de explotar los enormes recursos inform\u00e1ticos de un entorno de red y buscar conf\u00f3rmeros moleculares a gran escala. Demostramos CONFLEX-G en nuestro banco de pruebas de cuadr\u00edcula utilizando la prote\u00edna real como mol\u00e9cula de muestra. La funci\u00f3n OmniRPC del m\u00f3dulo inicializable autom\u00e1tico -LRB- AIM -RRB- permite al sistema calcular de manera eficiente numerosos conformadores. Adem\u00e1s, al utilizar OmniRPC, el usuario puede paralelizar en grid la aplicaci\u00f3n existente y pasar del cl\u00faster al entorno de grid sin modificar el c\u00f3digo del programa ni compilar el programa. Adem\u00e1s, el usuario puede crear f\u00e1cilmente un entorno de red privada. Una descripci\u00f3n general Figura 1: Algoritmo de b\u00fasqueda de espacio conformacional en el CONFLEX original. del sistema CONFLEX se presenta en la Secci\u00f3n 2, y la implementaci\u00f3n y el dise\u00f1o de CONFLEX-G se describen en la Secci\u00f3n 3. Informamos los resultados experimentales obtenidos usando CONFLEX-G y discutimos su desempe\u00f1o en la Secci\u00f3n 4. En la Secci\u00f3n 6, presentamos conclusiones y discutimos temas para futuros estudios. 5. TRABAJOS RELACIONADOS Recientemente se ha desarrollado un algoritmo que resuelve los problemas de paralelizaci\u00f3n y comunicaci\u00f3n en procesadores mal conectados para ser utilizados en simulaci\u00f3n. Esto nos ha permitido simular el plegamiento por primera vez y examinar directamente las enfermedades relacionadas con el plegamiento. SETI@home[14] es un programa para buscar vida extraterrestre mediante el an\u00e1lisis de se\u00f1ales de radiotelescopios utilizando datos de radiotelescopios por transformada de Fourier procedentes de telescopios de diferentes sitios. SETI@home aborda problemas inmensamente paralelos, en los que el c\u00e1lculo se puede dividir f\u00e1cilmente entre varios ordenadores. Los fragmentos de datos del radiotelescopio se pueden asignar f\u00e1cilmente a diferentes computadoras. Sin embargo, es posible que OmniRPC no requiera las habilidades y el esfuerzo necesarios para desarrollar una aplicaci\u00f3n grid.Nimrod/G -LSB- 15 -RSB- es una herramienta para modelado param\u00e9trico distribuido e implementa una granja de tareas paralela para simulaciones que requieren varios par\u00e1metros de entrada variables. Nimrod se ha aplicado a aplicaciones que incluyen bioinform\u00e1tica, investigaci\u00f3n de operaciones y modelado molecular para el dise\u00f1o de f\u00e1rmacos. NetSolve -LSB- 8 -RSB- es una instalaci\u00f3n RPC similar a OmniRPC y Ninf, que proporciona una interfaz de programaci\u00f3n similar y un mecanismo de equilibrio de carga autom\u00e1tico. Matsuoka et al. -LSB- 16 -RSB- tambi\u00e9n ha discutido varias cuestiones de dise\u00f1o relacionadas con los sistemas RPC de red. 6. CONCLUSIONES Y TRABAJO FUTURO Hemos dise\u00f1ado e implementado CONFLEX-G utilizando OmniRPC. Informamos su rendimiento en un banco de pruebas en red de varios cl\u00fasteres de PC distribuidos geogr\u00e1ficamente. Para explorar la conformaci\u00f3n de biomol\u00e9culas grandes, se utiliz\u00f3 CONFLEXG para generar estructuras de prueba de las mol\u00e9culas y asignar tareas para optimizarlas mediante la mec\u00e1nica molecular en la red. OmniRPC proporciona un modelo de persistencia restringido para que el m\u00f3dulo se inicialice autom\u00e1ticamente en el momento de la invocaci\u00f3n llamando al procedimiento de inicializaci\u00f3n. Esto puede eliminar la comunicaci\u00f3n innecesaria y la inicializaci\u00f3n en cada llamada en CONFLEX-G. CONFLEX-G puede lograr un rendimiento comparable al de CONFLEX MPI y explotar m\u00e1s recursos inform\u00e1ticos al permitir el uso de m\u00faltiples cl\u00fasteres de PC en la red. El resultado experimental muestra que CONFLEX-G logr\u00f3 una aceleraci\u00f3n de 56,5 veces para la mol\u00e9cula 1BL1, donde la mol\u00e9cula consta de una gran cantidad de \u00e1tomos y cada optimizaci\u00f3n de la estructura de prueba requiere una gran cantidad de tiempo. El desequilibrio de carga de las optimizaciones de la estructura de prueba puede provocar una degradaci\u00f3n del rendimiento. Necesitamos refinar el algoritmo utilizado para generar la estructura de prueba para mejorar la optimizaci\u00f3n del equilibrio de carga para las estructuras de prueba en CONFLEX. Los estudios futuros incluir\u00e1n el desarrollo de herramientas de implementaci\u00f3n y un examen de la tolerancia a fallos. En el OmniRPC actual, el registro de un programa de ejecuci\u00f3n en hosts remotos y las implementaciones de programas de trabajo se configuran manualmente. Se necesitar\u00e1n herramientas de implementaci\u00f3n a medida que aumente la cantidad de hosts remotos. En entornos de red en los que el entorno cambia din\u00e1micamente, tambi\u00e9n es necesario admitir tolerancia a fallos. Esta caracter\u00edstica es especialmente importante en aplicaciones a gran escala que requieren c\u00e1lculos prolongados en un entorno de red. Planeamos refinar el algoritmo de optimizaci\u00f3n conformacional en CONFLEX para explorar la b\u00fasqueda en el espacio de conformaci\u00f3n de biomol\u00e9culas m\u00e1s grandes, como la proteasa del VIH, utilizando hasta 1000 trabajadores en un entorno de red.-LSB- 16 -RSB- tambi\u00e9n ha discutido varias cuestiones de dise\u00f1o relacionadas con los sistemas RPC de red. 6. CONCLUSIONES Y TRABAJO FUTURO Hemos dise\u00f1ado e implementado CONFLEX-G utilizando OmniRPC. Informamos su rendimiento en un banco de pruebas en red de varios cl\u00fasteres de PC distribuidos geogr\u00e1ficamente. Para explorar la conformaci\u00f3n de biomol\u00e9culas grandes, se utiliz\u00f3 CONFLEXG para generar estructuras de prueba de las mol\u00e9culas y asignar tareas para optimizarlas mediante la mec\u00e1nica molecular en la red. OmniRPC proporciona un modelo de persistencia restringido para que el m\u00f3dulo se inicialice autom\u00e1ticamente en el momento de la invocaci\u00f3n llamando al procedimiento de inicializaci\u00f3n. Esto puede eliminar la comunicaci\u00f3n innecesaria y la inicializaci\u00f3n en cada llamada en CONFLEX-G. CONFLEX-G puede lograr un rendimiento comparable al de CONFLEX MPI y explotar m\u00e1s recursos inform\u00e1ticos al permitir el uso de m\u00faltiples cl\u00fasteres de PC en la red. El resultado experimental muestra que CONFLEX-G logr\u00f3 una aceleraci\u00f3n de 56,5 veces para la mol\u00e9cula 1BL1, donde la mol\u00e9cula consta de una gran cantidad de \u00e1tomos y cada optimizaci\u00f3n de la estructura de prueba requiere una gran cantidad de tiempo. El desequilibrio de carga de las optimizaciones de la estructura de prueba puede provocar una degradaci\u00f3n del rendimiento. Necesitamos refinar el algoritmo utilizado para generar la estructura de prueba para mejorar la optimizaci\u00f3n del equilibrio de carga para las estructuras de prueba en CONFLEX. Los estudios futuros incluir\u00e1n el desarrollo de herramientas de implementaci\u00f3n y un examen de la tolerancia a fallos. En el OmniRPC actual, el registro de un programa de ejecuci\u00f3n en hosts remotos y las implementaciones de programas de trabajo se configuran manualmente. Se necesitar\u00e1n herramientas de implementaci\u00f3n a medida que aumente la cantidad de hosts remotos. En entornos de red en los que el entorno cambia din\u00e1micamente, tambi\u00e9n es necesario admitir tolerancia a fallos. Esta caracter\u00edstica es especialmente importante en aplicaciones a gran escala que requieren c\u00e1lculos prolongados en un entorno de red. Planeamos refinar el algoritmo de optimizaci\u00f3n conformacional en CONFLEX para explorar la b\u00fasqueda en el espacio de conformaci\u00f3n de biomol\u00e9culas m\u00e1s grandes, como la proteasa del VIH, utilizando hasta 1000 trabajadores en un entorno de red.-LSB- 16 -RSB- tambi\u00e9n ha discutido varias cuestiones de dise\u00f1o relacionadas con los sistemas RPC de red. 6. CONCLUSIONES Y TRABAJO FUTURO Hemos dise\u00f1ado e implementado CONFLEX-G utilizando OmniRPC. Informamos su rendimiento en un banco de pruebas en red de varios cl\u00fasteres de PC distribuidos geogr\u00e1ficamente. Para explorar la conformaci\u00f3n de biomol\u00e9culas grandes, se utiliz\u00f3 CONFLEXG para generar estructuras de prueba de las mol\u00e9culas y asignar tareas para optimizarlas mediante la mec\u00e1nica molecular en la red. OmniRPC proporciona un modelo de persistencia restringido para que el m\u00f3dulo se inicialice autom\u00e1ticamente en el momento de la invocaci\u00f3n llamando al procedimiento de inicializaci\u00f3n. Esto puede eliminar la comunicaci\u00f3n innecesaria y la inicializaci\u00f3n en cada llamada en CONFLEX-G. CONFLEX-G puede lograr un rendimiento comparable al de CONFLEX MPI y explotar m\u00e1s recursos inform\u00e1ticos al permitir el uso de m\u00faltiples cl\u00fasteres de PC en la red. El resultado experimental muestra que CONFLEX-G logr\u00f3 una aceleraci\u00f3n de 56,5 veces para la mol\u00e9cula 1BL1, donde la mol\u00e9cula consta de una gran cantidad de \u00e1tomos y cada optimizaci\u00f3n de la estructura de prueba requiere una gran cantidad de tiempo. El desequilibrio de carga de las optimizaciones de la estructura de prueba puede provocar una degradaci\u00f3n del rendimiento. Necesitamos refinar el algoritmo utilizado para generar la estructura de prueba para mejorar la optimizaci\u00f3n del equilibrio de carga para las estructuras de prueba en CONFLEX. Los estudios futuros incluir\u00e1n el desarrollo de herramientas de implementaci\u00f3n y un examen de la tolerancia a fallos. En el OmniRPC actual, el registro de un programa de ejecuci\u00f3n en hosts remotos y las implementaciones de programas de trabajo se configuran manualmente. Se necesitar\u00e1n herramientas de implementaci\u00f3n a medida que aumente la cantidad de hosts remotos. En entornos de red en los que el entorno cambia din\u00e1micamente, tambi\u00e9n es necesario admitir tolerancia a fallos. Esta caracter\u00edstica es especialmente importante en aplicaciones a gran escala que requieren c\u00e1lculos prolongados en un entorno de red. Planeamos refinar el algoritmo de optimizaci\u00f3n conformacional en CONFLEX para explorar la b\u00fasqueda en el espacio de conformaci\u00f3n de biomol\u00e9culas m\u00e1s grandes, como la proteasa del VIH, utilizando hasta 1000 trabajadores en un entorno de red.El resultado experimental muestra que CONFLEX-G logr\u00f3 una aceleraci\u00f3n de 56,5 veces para la mol\u00e9cula 1BL1, donde la mol\u00e9cula consta de una gran cantidad de \u00e1tomos y cada optimizaci\u00f3n de la estructura de prueba requiere una gran cantidad de tiempo. El desequilibrio de carga de las optimizaciones de la estructura de prueba puede provocar una degradaci\u00f3n del rendimiento. Necesitamos refinar el algoritmo utilizado para generar la estructura de prueba para mejorar la optimizaci\u00f3n del equilibrio de carga para las estructuras de prueba en CONFLEX. Los estudios futuros incluir\u00e1n el desarrollo de herramientas de implementaci\u00f3n y un examen de la tolerancia a fallos. En el OmniRPC actual, el registro de un programa de ejecuci\u00f3n en hosts remotos y las implementaciones de programas de trabajo se configuran manualmente. Se necesitar\u00e1n herramientas de implementaci\u00f3n a medida que aumente la cantidad de hosts remotos. En entornos de red en los que el entorno cambia din\u00e1micamente, tambi\u00e9n es necesario admitir tolerancia a fallos. Esta caracter\u00edstica es especialmente importante en aplicaciones a gran escala que requieren c\u00e1lculos prolongados en un entorno de red. Planeamos refinar el algoritmo de optimizaci\u00f3n conformacional en CONFLEX para explorar la b\u00fasqueda en el espacio de conformaci\u00f3n de biomol\u00e9culas m\u00e1s grandes, como la proteasa del VIH, utilizando hasta 1000 trabajadores en un entorno de red.El resultado experimental muestra que CONFLEX-G logr\u00f3 una aceleraci\u00f3n de 56,5 veces para la mol\u00e9cula 1BL1, donde la mol\u00e9cula consta de una gran cantidad de \u00e1tomos y cada optimizaci\u00f3n de la estructura de prueba requiere una gran cantidad de tiempo. El desequilibrio de carga de las optimizaciones de la estructura de prueba puede provocar una degradaci\u00f3n del rendimiento. Necesitamos refinar el algoritmo utilizado para generar la estructura de prueba para mejorar la optimizaci\u00f3n del equilibrio de carga para las estructuras de prueba en CONFLEX. Los estudios futuros incluir\u00e1n el desarrollo de herramientas de implementaci\u00f3n y un examen de la tolerancia a fallos. En el OmniRPC actual, el registro de un programa de ejecuci\u00f3n en hosts remotos y las implementaciones de programas de trabajo se configuran manualmente. Se necesitar\u00e1n herramientas de implementaci\u00f3n a medida que aumente la cantidad de hosts remotos. En entornos de red en los que el entorno cambia din\u00e1micamente, tambi\u00e9n es necesario admitir tolerancia a fallos. Esta caracter\u00edstica es especialmente importante en aplicaciones a gran escala que requieren c\u00e1lculos prolongados en un entorno de red. Planeamos refinar el algoritmo de optimizaci\u00f3n conformacional en CONFLEX para explorar la b\u00fasqueda en el espacio de conformaci\u00f3n de biomol\u00e9culas m\u00e1s grandes, como la proteasa del VIH, utilizando hasta 1000 trabajadores en un entorno de red.", "keyphrases": ["conflex-g", "omnirpc", "b\u00fasqueda de espacio conforme", "biomol\u00e9cula", "m\u00f3dulo rpc", "procedimiento inicial", "mpu", "grupo de computadoras", "computaci\u00f3n en red", "sistema rpc de red", "mecanismo molecular", "m\u00f3dulo de inicializaci\u00f3n autom\u00e1tica"]}
{"file_name": "C-9", "text": "EDAS: Proporcionar un entorno para servicios adaptativos descentralizados RESUMEN A medida que la idea de la virtualizaci\u00f3n de la potencia inform\u00e1tica, el almacenamiento y el ancho de banda se vuelve cada vez m\u00e1s importante, la computaci\u00f3n grid evoluciona y se aplica a un n\u00famero cada vez mayor de aplicaciones. El entorno para servicios adaptativos descentralizados -LRB- EDAS -RRB- proporciona una infraestructura similar a una red para servicios a largo plazo a los que acceden los usuarios -LRB-, por ejemplo, servidor web, repositorio de c\u00f3digo fuente, etc. -RRB-. Su objetivo es apoyar la ejecuci\u00f3n aut\u00f3noma y la evoluci\u00f3n de los servicios en t\u00e9rminos de escalabilidad y distribuci\u00f3n consciente de los recursos. EDAS ofrece modelos de servicios flexibles basados \u200b\u200ben objetos m\u00f3viles distribuidos que van desde un escenario cliente-servidor tradicional hasta un enfoque totalmente basado en peer-to-peer. La gesti\u00f3n autom\u00e1tica y din\u00e1mica de recursos permite un uso optimizado de los recursos disponibles y al mismo tiempo minimiza la complejidad administrativa. 1. INTRODUCCI\u00d3N Las infraestructuras para computaci\u00f3n grid tienen como objetivo virtualizar un grupo de computadoras, servidores y almacenamiento como un gran sistema inform\u00e1tico. La gesti\u00f3n de recursos es una cuesti\u00f3n clave en estos sistemas, necesaria para una distribuci\u00f3n eficiente y automatizada de tareas en la red. Estas infraestructuras de red a menudo se implementan a nivel empresarial, pero proyectos como SETI@home -LSB- 1 -RSB- tambi\u00e9n han demostrado la viabilidad de redes m\u00e1s descentralizadas. Las infraestructuras de computaci\u00f3n grid actuales no brindan soporte suficiente para la ejecuci\u00f3n de servicios distribuidos a largo plazo a los que acceden los usuarios, ya que est\u00e1n dise\u00f1adas para resolver tareas inform\u00e1ticas o de uso intensivo de datos con un conjunto de par\u00e1metros m\u00e1s o menos fijo. En cambio, una infraestructura para servicios a largo plazo tiene que ubicar los servicios en funci\u00f3n de su demanda actual y sus necesidades futuras estimadas. Sin embargo, la migraci\u00f3n es costosa ya que es necesario transferir todo el estado de un servicio. Adem\u00e1s, no se puede acceder a un servicio no replicado durante la migraci\u00f3n. Por lo tanto, la gesti\u00f3n de recursos debe evitar la migraci\u00f3n si es posible. Adem\u00e1s, debe proporcionarse un concepto de servicio que, en primer lugar, evite la sobrecarga y, en segundo lugar, inhiba la indisponibilidad del servicio si no se puede evitar la migraci\u00f3n. EDAS -LSB- 2 -RSB- tiene como objetivo proporcionar una infraestructura similar a una red para servicios a largo plazo a los que acceden los usuarios que permite la adaptaci\u00f3n din\u00e1mica en tiempo de ejecuci\u00f3n, proporciona una infraestructura de gesti\u00f3n y ofrece soporte a nivel de sistema para escalabilidad y fallas. tolerancia. Los nodos pueden unirse y salir din\u00e1micamente de la infraestructura, y todas las tareas de gesti\u00f3n, especialmente la gesti\u00f3n de recursos, est\u00e1n descentralizadas. El entorno se basa en nuestra infraestructura de middleware AspectIX -LSB- 3 -RSB-, que admite directamente la reconfiguraci\u00f3n din\u00e1mica de servicios basada en QoS. La gesti\u00f3n de recursos se centra en la ejecuci\u00f3n de servicios que tienen un tiempo de funcionamiento largo y potencialmente infinito. Estos servicios est\u00e1n organizados en proyectos. Cada proyecto tiene un alcance de ejecuci\u00f3n distribuido llamado entorno de servicio. Un entorno as\u00ed posiblemente abarque m\u00faltiples instituciones.Cada instituci\u00f3n representa un dominio administrativo que puede respaldar un proyecto con un conjunto fijo de recursos. Nuestro enfoque apoya la gesti\u00f3n adaptativa de recursos de todos los proyectos en el \u00e1mbito de una instituci\u00f3n basado en un algoritmo inspirado en los algoritmos difusos para el equilibrio de carga descentralizado -LSB- 4 -RSB-. No se sabe c\u00f3mo subdividir de manera \u00f3ptima estos recursos para los servicios, ya que la demanda de recursos de los servicios puede cambiar con el tiempo o incluso fluctuar con frecuencia. Para proporcionar recursos seg\u00fan sea necesario, nuestro enfoque vuelve a dedicar autom\u00e1ticamente recursos gratuitos o no necesarios entre instancias de servicio en proyectos y nodos. En los casos en los que no sea posible la rededicaci\u00f3n, se inicia la migraci\u00f3n del servicio demandante. En una infraestructura grid de servicios a largo plazo, la replicaci\u00f3n activa tiene varios beneficios: las r\u00e9plicas pueden unirse y abandonar el grupo de objetos y, por lo tanto, se pueden migrar sin que el servicio est\u00e9 disponible. Finalmente, se puede tolerar una cierta cantidad de fallas de nodos. La secci\u00f3n 4 explica los conceptos de autogesti\u00f3n y rededicaci\u00f3n de la gesti\u00f3n adaptativa distribuida de recursos. La Secci\u00f3n 5 describe el marco para los servicios adaptativos descentralizados. La Secci\u00f3n 6 describe el trabajo relacionado y finalmente la Secci\u00f3n 7 concluye el art\u00edculo. 6. TRABAJO RELACIONADO Las infraestructuras grid como Globus-Toolkit -LSB- 11 -RSB- proporcionan servicios y mecanismos para entornos heterog\u00e9neos distribuidos para combinar recursos bajo demanda para resolver tareas que consumen recursos y computan de manera intensiva. Debido a esta orientaci\u00f3n, se centran en diferentes modelos de servicio y no brindan soporte para la movilidad de objetos, si es que siquiera admiten un enfoque de objetos distribuidos. Pero lo m\u00e1s importante es que siguen un enfoque diferente de gesti\u00f3n de recursos, ya que apuntan a la ejecuci\u00f3n paralela de un gran n\u00famero de tareas a corto y mediano plazo. Los objetos replicados activamente los proporciona Jgroup -LSB- 14 -RSB- basado en RMI. Sobre este middleware b\u00e1sico se ha implementado una capa de gesti\u00f3n de replicaci\u00f3n denominada ARM -LSB- 15 -RSB-. JGroup se centra en la replicaci\u00f3n activa de objetos pero carece de soporte para servicios m\u00e1s flexibles como lo hace EDAS. ARM se puede comparar con EDAS pero no admite distribuci\u00f3n que tenga en cuenta los recursos. Fog -LSB- 16 -RSB- y Globe -LSB- 17 -RSB- son entornos de middleware b\u00e1sicos que admiten el enfoque de objetos fragmentados. Globe considera la replicaci\u00f3n y el almacenamiento en cach\u00e9. Ambos sistemas carecen de soporte para la distribuci\u00f3n consciente de los recursos. 7. CONCLUSI\u00d3N Y TRABAJO EN CURSO Basado en el modelo de objetos fragmentados y la arquitectura del entorno EDAS, los servicios adaptativos descentralizados pueden dise\u00f1arse, implementarse y ejecutarse f\u00e1cilmente. Como se describi\u00f3, la gesti\u00f3n de recursos se puede descomponer en dos problemas principales que deben resolverse. Control y gesti\u00f3n de los l\u00edmites de recursos, incluyendo garantizar que los recursos asignados est\u00e9n disponibles -LRB- incluso en el context de ca\u00eddas de nodos -RRB- y la colocaci\u00f3n aut\u00f3noma de servicios. Para ambos problemas ofrecemos una soluci\u00f3n,un entorno de simulaci\u00f3n actualmente implementado verificar\u00e1 su viabilidad. En un siguiente paso, la gesti\u00f3n de recursos se integrar\u00e1 en un prototipo ya implementado de la arquitectura EDAS. Como se describi\u00f3, ya tenemos una implementaci\u00f3n temprana del marco para los servicios adaptativos descentralizados. Este marco debe ampliarse para interactuar sin problemas con la gesti\u00f3n de recursos y la arquitectura EDAS. En un paso final necesitamos implementar algunos servicios que verifiquen la usabilidad de todo el proyecto EDAS.", "keyphrases": ["Servicio de adaptaci\u00f3n decente.", "gesti\u00f3n de recursos", "ambiente hogare\u00f1o", "infraestructura", "cliente", "servicio a largo plazo", "eda", "l\u00edmite local", "l\u00edmite global", "recurso", "nodo"]}
{"file_name": "H-14", "text": "Estudio del uso de destinos populares para mejorar la interacci\u00f3n de b\u00fasqueda web RESUMEN Presentamos una novedosa caracter\u00edstica de interacci\u00f3n de b\u00fasqueda web que, para una consulta determinada, proporciona enlaces a sitios web visitados frecuentemente por otros usuarios con necesidades de informaci\u00f3n similares. Estos destinos populares complementan los resultados de b\u00fasqueda tradicionales, permitiendo la navegaci\u00f3n directa a recursos autorizados para el tema de consulta. Los destinos se identifican utilizando el historial de comportamiento de b\u00fasqueda y navegaci\u00f3n de muchos usuarios durante un per\u00edodo de tiempo prolongado, cuyo comportamiento colectivo proporciona una base para calcular la autoridad de la fuente. Describimos un estudio de usuarios que compar\u00f3 la sugerencia de destinos con la sugerencia previamente propuesta de consultas relacionadas, as\u00ed como con la b\u00fasqueda web tradicional sin ayuda. Los resultados muestran que la b\u00fasqueda mejorada por sugerencias de destinos supera a otros sistemas para tareas exploratorias, y el mejor rendimiento se obtiene al analizar el comportamiento anterior de los usuarios en granularidad a nivel de consulta. 1. INTRODUCCI\u00d3N El problema de la mejora de las consultas enviadas a los sistemas de Recuperaci\u00f3n de Informaci\u00f3n -LRB- IR -RRB- ha sido ampliamente estudiado en la investigaci\u00f3n de RI -LSB- 4 -RSB- -LSB- 11 -RSB-. Se pueden ofrecer formulaciones de consulta alternativas, conocidas como sugerencias de consulta, a los usuarios despu\u00e9s de una consulta inicial, lo que les permite modificar la especificaci\u00f3n de sus necesidades proporcionada al sistema, lo que conduce a un mejor rendimiento de recuperaci\u00f3n. La reciente popularidad de los motores de b\u00fasqueda web ha permitido sugerencias de consultas que se basan en el comportamiento de reformulaci\u00f3n de consultas de muchos usuarios para hacer recomendaciones de consultas basadas en interacciones anteriores de los usuarios -LSB- 10 -RSB-. Aprovechar los procesos de toma de decisiones de muchos usuarios para la reformulaci\u00f3n de consultas tiene sus ra\u00edces en la indexaci\u00f3n adaptativa -LSB- 8 -RSB-. Sin embargo, los enfoques basados \u200b\u200ben la interacci\u00f3n para la sugerencia de consultas pueden ser menos potentes cuando la necesidad de informaci\u00f3n es exploratoria, ya que una gran proporci\u00f3n de la actividad del usuario para tales necesidades de informaci\u00f3n puede ocurrir m\u00e1s all\u00e1 de las interacciones con los motores de b\u00fasqueda. En los casos en los que la b\u00fasqueda dirigida es s\u00f3lo una fracci\u00f3n del comportamiento de b\u00fasqueda de informaci\u00f3n de los usuarios, la utilidad de los clics de otros usuarios en el espacio de los resultados mejor clasificados puede ser limitada, ya que no cubre el comportamiento de navegaci\u00f3n posterior. Al mismo tiempo, la navegaci\u00f3n del usuario que sigue las interacciones del motor de b\u00fasqueda proporciona un respaldo impl\u00edcito a los recursos web preferidos por los usuarios, lo que puede ser particularmente valioso para las tareas de b\u00fasqueda exploratoria. Por lo tanto, proponemos explotar una combinaci\u00f3n de b\u00fasquedas pasadas y comportamiento de navegaci\u00f3n del usuario para mejorar las interacciones de b\u00fasqueda web de los usuarios. Los complementos del navegador y los registros del servidor proxy brindan acceso a los patrones de navegaci\u00f3n de los usuarios que trascienden las interacciones con los motores de b\u00fasqueda. En trabajos anteriores, Agichtein et al. han utilizado dichos datos para mejorar la clasificaci\u00f3n de los resultados de b\u00fasqueda. -LSB- 1 -RSB-. Radlinski y Joachims -LSB- 13 -RSB- han utilizado dicha inteligencia colectiva del usuario para mejorar la precisi\u00f3n de la recuperaci\u00f3n mediante el uso de secuencias de reformulaciones de consultas consecutivas.sin embargo, su enfoque no considera las interacciones de los usuarios m\u00e1s all\u00e1 de la p\u00e1gina de resultados de b\u00fasqueda. En este art\u00edculo, presentamos un estudio de usuarios de una t\u00e9cnica que explota el comportamiento de b\u00fasqueda y navegaci\u00f3n de muchos usuarios para sugerir p\u00e1ginas web populares, denominadas destinos en adelante, adem\u00e1s de los resultados de b\u00fasqueda habituales. Es posible que los destinos no est\u00e9n entre los resultados mejor clasificados, que no contengan los t\u00e9rminos consultados o que ni siquiera est\u00e9n indexados por el motor de b\u00fasqueda. En cambio, son p\u00e1ginas a las que otros usuarios terminan con frecuencia despu\u00e9s de enviar consultas iguales o similares y luego navegar lejos de los resultados de b\u00fasqueda en los que inicialmente hicieron clic. Conjeturamos que los destinos populares entre una gran cantidad de usuarios pueden capturar la experiencia colectiva del usuario para las necesidades de informaci\u00f3n, y nuestros resultados respaldan esta hip\u00f3tesis. En -LSB- 19 -RSB-, Wexelblat y Maes describen un sistema para soportar la navegaci\u00f3n dentro del dominio basada en las rutas de navegaci\u00f3n de otros usuarios. Sin embargo, no tenemos conocimiento de que dichos principios se apliquen a la b\u00fasqueda en la Web. Quiz\u00e1s la instancia m\u00e1s cercana de teletransportaci\u00f3n sea la oferta de los motores de b\u00fasqueda de varios atajos dentro del dominio debajo del t\u00edtulo de un resultado de b\u00fasqueda. Si bien estos pueden basarse en el comportamiento del usuario y posiblemente en la estructura del sitio, el usuario guarda como m\u00e1ximo un clic en esta funci\u00f3n. Por el contrario, nuestro enfoque propuesto puede transportar a los usuarios a ubicaciones con muchos clics m\u00e1s all\u00e1 del resultado de la b\u00fasqueda, ahorrando tiempo y brind\u00e1ndoles una perspectiva m\u00e1s amplia de la informaci\u00f3n relacionada disponible. El estudio de usuarios realizado investiga la eficacia de incluir enlaces a destinos populares como una caracter\u00edstica adicional de la interfaz en las p\u00e1ginas de resultados de los motores de b\u00fasqueda. Comparamos dos variantes de este enfoque con la sugerencia de consultas relacionadas y b\u00fasqueda web sin ayuda, y buscamos respuestas a preguntas sobre: \u200b\u200b-LRB- i -RRB- preferencia del usuario y efectividad de la b\u00fasqueda para tareas de b\u00fasqueda exploratoria y de elementos conocidos, y -LRB- ii -RRB- la distancia preferida entre la consulta y el destino utilizada para identificar destinos populares a partir de registros de comportamiento anteriores. Los resultados indican que sugerir destinos populares a los usuarios que intentan tareas exploratorias proporciona mejores resultados en aspectos clave de la experiencia de b\u00fasqueda de informaci\u00f3n, mientras que proporcionar sugerencias para refinar las consultas es m\u00e1s deseable para tareas de elementos conocidos. En la Secci\u00f3n 2 describimos la extracci\u00f3n de rutas de b\u00fasqueda y navegaci\u00f3n de los registros de actividad del usuario y su uso para identificar los principales destinos para nuevas consultas. La Secci\u00f3n 3 describe el dise\u00f1o del estudio de usuarios, mientras que las Secciones 4 y 5 presentan los hallazgos del estudio y su discusi\u00f3n, respectivamente. 6. CONCLUSIONES Presentamos un enfoque novedoso para mejorar la interacci\u00f3n de b\u00fasqueda web de los usuarios al proporcionar enlaces a sitios web visitados con frecuencia por buscadores anteriores con necesidades de informaci\u00f3n similares. Se realiz\u00f3 un estudio de usuarios en el que evaluamos la efectividad de la t\u00e9cnica propuesta en comparaci\u00f3n con un sistema de refinamiento de consultas y una b\u00fasqueda web sin ayuda. Los resultados de nuestro estudio revelaron que:Los sistemas -LRB- i -RRB- que sugieren refinamientos de consultas fueron preferidos para tareas de elementos conocidos, -LRB- ii -RRB- sistemas que ofrecen destinos populares fueron preferidos para tareas de b\u00fasqueda exploratoria, y los destinos -LRB- iii -RRB- deber\u00edan extraerse de el final de los senderos de consulta, no de los senderos de sesi\u00f3n. En general, las sugerencias de destinos populares influyeron estrat\u00e9gicamente en las b\u00fasquedas de una manera que no se puede lograr mediante los enfoques de sugerencia de consultas, al ofrecer una nueva forma de resolver problemas de informaci\u00f3n y mejorar la experiencia de b\u00fasqueda de informaci\u00f3n para muchos buscadores en la Web.", "keyphrases": ["destino popular", "interacci\u00f3n de b\u00fasqueda web", "consulta de improvisaci\u00f3n", "recuperar realizar", "pregunta relacionada", "experiencia de b\u00fasqueda de informaci\u00f3n", "sendero de consulta", "rastro de sesi\u00f3n", "enfoque de base de b\u00fasqueda", "evaluaci\u00f3n de base de registro"]}
{"file_name": "I-20", "text": "Calcular el \u00edndice de poder de Banzhaf en juegos de flujo de red RESUMEN La agregaci\u00f3n de preferencias se utiliza en una variedad de aplicaciones multiagente y, como resultado, la teor\u00eda de la votaci\u00f3n se ha convertido en un tema importante en la investigaci\u00f3n de sistemas multiagente. Sin embargo, los \u00edndices de poder -LRB- que reflejan cu\u00e1nto ``poder real'' tiene un votante en un sistema de votaci\u00f3n ponderado -RRB- han recibido relativamente poca atenci\u00f3n, aunque han sido estudiados durante mucho tiempo en ciencias pol\u00edticas y econom\u00eda. El \u00edndice de poder de Banzhaf es uno de los m\u00e1s populares; tambi\u00e9n est\u00e1 bien definido para cualquier juego de coalici\u00f3n simple. En este art\u00edculo, examinamos la complejidad computacional de calcular el \u00edndice de potencia de Banzhaf dentro de un dominio multiagente particular, un juego de flujo de red. Los agentes controlan los bordes de un gr\u00e1fico; una coalici\u00f3n gana si puede enviar un flujo de un tama\u00f1o determinado desde un v\u00e9rtice de origen a un v\u00e9rtice de destino. El poder relativo de cada borde/agente refleja su importancia para permitir dicho flujo, y en las redes del mundo real podr\u00eda usarse, por ejemplo, para asignar recursos para mantener partes de la red. Mostramos que el c\u00e1lculo del \u00edndice de potencia de Banzhaf de cada agente en este dominio de flujo de red es #P - completo. Tambi\u00e9n mostramos que para algunos dominios de flujo de red restringidos existe un algoritmo polin\u00f3mico para calcular los \u00edndices de poder de Banzhaf de los agentes. 1. INTRODUCCI\u00d3N \u00bfCu\u00e1l es la complejidad del proceso? \u00bfSe puede utilizar la complejidad para protegerse contra fen\u00f3menos no deseados? \u00bfLa complejidad del c\u00e1lculo impide la implementaci\u00f3n realista de una t\u00e9cnica? Las aplicaciones pr\u00e1cticas de la votaci\u00f3n entre agentes automatizados ya est\u00e1n muy extendidas. De hecho, para ver la generalidad del escenario de votaci\u00f3n -LRB- automatizado -RRB-, considere la b\u00fasqueda web moderna. En este art\u00edculo, consideramos un tema que ha sido menos estudiado en el context de la votaci\u00f3n automatizada de agentes: los \u00edndices de poder. Un \u00edndice de poder es una medida del poder que tiene un subgrupo, o equivalentemente un votante en un entorno de votaci\u00f3n ponderado, sobre las decisiones de un grupo m\u00e1s grande. El \u00edndice de poder de Banzhaf es una de las medidas m\u00e1s populares del poder de voto y, aunque se ha utilizado principalmente para medir el poder en juegos de votaci\u00f3n ponderada, est\u00e1 bien definido para cualquier juego de coalici\u00f3n simple. Analizamos algunos aspectos computacionales del \u00edndice de poder de Banzhaf en un entorno espec\u00edfico, es decir, un juego de flujo de red. En este juego, una coalici\u00f3n de agentes gana si puede enviar un flujo de tama\u00f1o k desde un v\u00e9rtice de origen s a un v\u00e9rtice de destino t, donde el poder relativo de cada borde refleja su importancia al permitir dicho flujo. Mostramos que el c\u00e1lculo del \u00edndice de potencia de Banzhaf de cada agente en este dominio de flujo de red general es #P - completo. En los juegos de conectividad en gr\u00e1ficos de capas acotadas -RRB-, existe un algoritmo polinomial para calcular el \u00edndice de potencia de Banzhaf de un agente. El documento procede de la siguiente manera. En la Secci\u00f3n 2 damos algunos antecedentes sobre los juegos de coalici\u00f3n y el \u00edndice de poder de Banzhaf, y en la Secci\u00f3n 3 presentamos nuestro juego de flujo de red espec\u00edfico.En la Secci\u00f3n 4 analizamos el \u00edndice de potencia de Banzhaf en juegos de flujo de redes y presentamos nuestro resultado de complejidad en el caso general. En la Secci\u00f3n 5 consideramos un caso restringido del juego del flujo de red y presentamos los resultados. En la Secci\u00f3n 6 analizamos trabajos relacionados y concluimos en la Secci\u00f3n 7. 6. TRABAJO RELACIONADO La medici\u00f3n del poder de los jugadores individuales en juegos de coalici\u00f3n se ha estudiado durante muchos a\u00f1os. Los \u00edndices m\u00e1s populares sugeridos para dicha medici\u00f3n son el \u00edndice de Banzhaf -LSB- 1 -RSB- y el \u00edndice de Shapley-Shubik -LSB- 19 -RSB-. En su art\u00edculo fundamental, Shapley -LSB- 18 -RSB- consider\u00f3 los juegos de coalici\u00f3n y la asignaci\u00f3n justa de la utilidad obtenida por la gran coalici\u00f3n -LRB- la coalici\u00f3n de todos los agentes -RRB- para sus miembros. El \u00edndice Shapley-Shubik -LSB- 19 -RSB- es la aplicaci\u00f3n directa del valor de Shapley a juegos de coalici\u00f3n simples. El \u00edndice de Banzhaf surgi\u00f3 directamente del estudio de la votaci\u00f3n en los \u00f3rganos de toma de decisiones. El \u00edndice de Banzhaf normalizado mide la proporci\u00f3n de coaliciones en las que un jugador es swinger, entre todas las coaliciones ganadoras. Este \u00edndice es similar al \u00edndice de Banzhaf analizado en la Secci\u00f3n 1 y se define como: El \u00edndice de Banzhaf se analiz\u00f3 matem\u00e1ticamente en -LSB- 3 -RSB-, donde se demostr\u00f3 que esta normalizaci\u00f3n carece de ciertas propiedades deseables, y el \u00edndice de Banzhaf m\u00e1s natural Se introduce el \u00edndice. Tanto el \u00edndice de Shapley-Shubik como el de Banzhaf han sido ampliamente estudiados, y Straffin -LSB-20-RSB- ha demostrado que cada \u00edndice refleja condiciones espec\u00edficas en un \u00f3rgano de votaci\u00f3n. -LSB- 11 -RSB- considera estos dos \u00edndices junto con varios otros, y describe los axiomas que caracterizan los diferentes \u00edndices. La ingenua implementaci\u00f3n de un algoritmo para calcular el \u00edndice de Banzhaf de un agente i enumera todas las coaliciones que contienen i. Hay 2n \u2212 1 de tales coaliciones, por lo que el desempe\u00f1o es exponencial en el n\u00famero de agentes. -LSB- 12 -RSB- contiene un estudio de algoritmos para calcular \u00edndices de poder de juegos mayoritarios ponderados. Deng y Papadimitriou -LSB- 2 -RSB- muestran que calcular el valor de Shapley en juegos de mayor\u00eda ponderada es #P - completo, utilizando una reducci\u00f3n de KNAPSACK. Dado que el valor de Shapley de cualquier juego simple tiene el mismo valor que su \u00edndice Shapley-Shubik, esto muestra que calcular el \u00edndice Shapley-Shubik en juegos de mayor\u00eda ponderada es #Pcompleto. Matsui y Matsui -LSB- 13 -RSB- han demostrado que el c\u00e1lculo de los \u00edndices de Banzhaf y Shapley-Shubik en juegos de votaci\u00f3n ponderada es NP-completo. El problema de calcular los \u00edndices de potencia en juegos simples depende de la representaci\u00f3n elegida del juego. Dado que el n\u00famero de coaliciones posibles es exponencial en el n\u00famero de agentes, el c\u00e1lculo de \u00edndices de poder en tiempo polin\u00f3mico en el n\u00famero de agentes s\u00f3lo se puede lograr en dominios espec\u00edficos. En este art\u00edculo, hemos considerado el dominio del flujo de red, donde una coalici\u00f3n de agentes debe lograr un flujo m\u00e1s all\u00e1 de un cierto valor. El juego de flujo de red que hemos definido es un juego sencillo. -LSB- 10,9 -RSB- han considerado un dominio de flujo de red similar, donde cada agente controla un borde de un gr\u00e1fico de flujo de red. Sin embargo, introdujeron un juego no simple, donde el valor que logra una coalici\u00f3n de agentes es el flujo total m\u00e1ximo. Han demostrado que ciertas familias de juegos de flujo de red y juegos similares tienen n\u00facleos no vac\u00edos. 7. CONCLUSIONES Y DIRECCIONES FUTURAS Hemos considerado juegos de flujo de red, donde una coalici\u00f3n de agentes gana si logra enviar un flujo de m\u00e1s de cierto valor k entre dos v\u00e9rtices. Hemos evaluado el poder relativo de cada agente en este escenario utilizando el \u00edndice de Banzhaf. Este \u00edndice de potencia se puede utilizar para decidir c\u00f3mo asignar recursos de mantenimiento en redes del mundo real, con el fin de maximizar nuestra capacidad de mantener un cierto flujo de informaci\u00f3n entre dos sitios. Aunque te\u00f3ricamente el \u00edndice de Banzhaf nos permite medir el poder de los agentes en el juego de flujo de red, hemos demostrado que el problema de calcular el \u00edndice de Banzhaf en este dominio en #P es completo. A pesar de este resultado desalentador para el dominio de flujo de red general, tambi\u00e9n hemos proporcionado un resultado m\u00e1s alentador para un dominio restringido. En el caso de los juegos de conectividad -LRB- donde s\u00f3lo se requiere que una coalici\u00f3n contenga un camino desde el origen hasta el destino -RRB- jugados en gr\u00e1ficos de capas acotadas, es posible calcular el \u00edndice de Banzhaf de un agente en tiempo polinomial. . Sigue siendo un problema abierto encontrar formas de aproximar de manera manejable el \u00edndice de Banzhaf en el dominio general del flujo de la red. Tambi\u00e9n es posible encontrar otros dominios restringidos \u00fatiles donde sea posible calcular exactamente el \u00edndice de Banzhaf. S\u00f3lo hemos considerado la complejidad del c\u00e1lculo del \u00edndice de Banzhaf; sigue siendo un problema abierto encontrar la complejidad de calcular el \u00edndice de Shapley-Shubik u otros \u00edndices en el dominio del flujo de red. Finalmente, creemos que hay muchos dominios interesantes adicionales adem\u00e1s de los juegos de votaci\u00f3n ponderada y los juegos de flujo de red, y valdr\u00eda la pena investigar la complejidad de calcular el \u00edndice de Banzhaf u otros \u00edndices de poder en dichos dominios.Hemos demostrado que el problema de calcular el \u00edndice de Banzhaf en este dominio en #P est\u00e1 completo. A pesar de este resultado desalentador para el dominio de flujo de red general, tambi\u00e9n hemos proporcionado un resultado m\u00e1s alentador para un dominio restringido. En el caso de los juegos de conectividad -LRB- donde s\u00f3lo se requiere que una coalici\u00f3n contenga un camino desde el origen hasta el destino -RRB- jugados en gr\u00e1ficos de capas acotadas, es posible calcular el \u00edndice de Banzhaf de un agente en tiempo polinomial. . Sigue siendo un problema abierto encontrar formas de aproximar de manera manejable el \u00edndice de Banzhaf en el dominio general del flujo de la red. Tambi\u00e9n es posible encontrar otros dominios restringidos \u00fatiles donde sea posible calcular exactamente el \u00edndice de Banzhaf. S\u00f3lo hemos considerado la complejidad del c\u00e1lculo del \u00edndice de Banzhaf; sigue siendo un problema abierto encontrar la complejidad de calcular el \u00edndice de Shapley-Shubik u otros \u00edndices en el dominio del flujo de red. Finalmente, creemos que hay muchos dominios interesantes adicionales adem\u00e1s de los juegos de votaci\u00f3n ponderada y los juegos de flujo de red, y valdr\u00eda la pena investigar la complejidad de calcular el \u00edndice de Banzhaf u otros \u00edndices de poder en dichos dominios.Hemos demostrado que el problema de calcular el \u00edndice de Banzhaf en este dominio en #P est\u00e1 completo. A pesar de este resultado desalentador para el dominio de flujo de red general, tambi\u00e9n hemos proporcionado un resultado m\u00e1s alentador para un dominio restringido. En el caso de los juegos de conectividad -LRB- donde s\u00f3lo se requiere que una coalici\u00f3n contenga un camino desde el origen hasta el destino -RRB- jugados en gr\u00e1ficos de capas acotadas, es posible calcular el \u00edndice de Banzhaf de un agente en tiempo polinomial. . Sigue siendo un problema abierto encontrar formas de aproximar de manera manejable el \u00edndice de Banzhaf en el dominio general del flujo de la red. Tambi\u00e9n es posible encontrar otros dominios restringidos \u00fatiles donde sea posible calcular exactamente el \u00edndice de Banzhaf. S\u00f3lo hemos considerado la complejidad del c\u00e1lculo del \u00edndice de Banzhaf; sigue siendo un problema abierto encontrar la complejidad de calcular el \u00edndice de Shapley-Shubik u otros \u00edndices en el dominio del flujo de red. Finalmente, creemos que hay muchos dominios interesantes adicionales adem\u00e1s de los juegos de votaci\u00f3n ponderada y los juegos de flujo de red, y valdr\u00eda la pena investigar la complejidad de calcular el \u00edndice de Banzhaf u otros \u00edndices de poder en dichos dominios.", "keyphrases": ["prefiero agregar", "aplicaci\u00f3n multiag", "teor\u00eda del voto", "\u00edndice de poder de banzhaf", "An\u00e1lisis de algoritmos y problemas complejos.", "teor\u00eda de la elecci\u00f3n social", "voto del agente autom\u00e1tico", "juego de flujo de red", "modelo probabilista", "conectar juego"]}
{"file_name": "J-7", "text": "El papel de la compatibilidad en la difusi\u00f3n de tecnolog\u00edas a trav\u00e9s de las redes sociales RESUMEN En muchos entornos, se puede ver que las tecnolog\u00edas en competencia (por ejemplo, sistemas operativos, sistemas de mensajer\u00eda instant\u00e1nea o formatos de documentos) adoptan una cantidad limitada de compatibilidad entre s\u00ed; en otras palabras, la dificultad de utilizar m\u00faltiples tecnolog\u00edas se equilibra en alg\u00fan punto entre los dos extremos de la imposibilidad y la interoperabilidad sin esfuerzo. Hay una variedad de razones por las que ocurre este fen\u00f3meno, muchas de las cuales, basadas en consideraciones legales, sociales o comerciales, parecen desafiar modelos matem\u00e1ticos concisos. Pese a ello, mostramos que las ventajas de una compatibilidad limitada pueden surgir en un modelo muy simple de difusi\u00f3n en redes sociales, ofreciendo as\u00ed una explicaci\u00f3n b\u00e1sica de este fen\u00f3meno en t\u00e9rminos puramente estrat\u00e9gicos. Nuestro enfoque se basa en el trabajo sobre la difusi\u00f3n de innovaciones en la literatura econ\u00f3mica, que busca modelar c\u00f3mo una nueva tecnolog\u00eda A podr\u00eda difundirse a trav\u00e9s de una red social de individuos que actualmente son usuarios de la tecnolog\u00eda B. Consideramos varias formas de capturar la compatibilidad de A. y B, centr\u00e1ndose principalmente en un modelo en el que los usuarios pueden elegir adoptar A, adoptar B o, con un costo adicional, adoptar tanto A como B. Caracterizamos c\u00f3mo la capacidad de A para propagarse depende tanto de su calidad relativa a B, y tambi\u00e9n este costo adicional de adoptar ambas, y encontrar algunas propiedades sorprendentes de no monotonicidad en la dependencia de estos par\u00e1metros: en algunos casos, para que una tecnolog\u00eda sobreviva a la introducci\u00f3n de otra, el costo de adoptar ambas tecnolog\u00edas debe estar equilibrado dentro de un rango estrecho e intermedio. Tambi\u00e9n ampliamos el marco al caso de m\u00faltiples tecnolog\u00edas, donde encontramos que un simple Este trabajo ha sido apoyado en parte por subvenciones NSF CCF0325453, IIS-0329064, CNS-0403340 y BCS-0537606, una subvenci\u00f3n de investigaci\u00f3n de Google, una subvenci\u00f3n de Yahoo ! Beca Research Alliance, el Instituto de Ciencias Sociales de Cornell y la Fundaci\u00f3n John D. y Catherine T. MacArthur. El modelo captura el fen\u00f3meno de dos empresas que adoptan una \"alianza estrat\u00e9gica\" limitada para defenderse de una tercera tecnolog\u00eda nueva. 1. INTRODUCCI\u00d3N Juegos de Difusi\u00f3n y Coordinaci\u00f3n en Red. Tales cuestiones surgen, por ejemplo, en la adopci\u00f3n de nuevas tecnolog\u00edas, la aparici\u00f3n de nuevas normas sociales o convenciones organizativas, o la difusi\u00f3n de lenguajes humanos -LSB- 2, 14, 15, 16, 17 -RSB-. Una l\u00ednea activa de investigaci\u00f3n en econom\u00eda y sociolog\u00eda matem\u00e1tica se preocupa por modelar este tipo de procesos de difusi\u00f3n como un juego de coordinaci\u00f3n en una red social -LSB- 1, 5, 7, 13, 19 -RSB-. Comenzamos analizando uno de los modelos de difusi\u00f3n de la teor\u00eda de juegos m\u00e1s b\u00e1sicos, propuesto en un influyente art\u00edculo de Morris -LSB-13-RSB-, que constituir\u00e1 el punto de partida de nuestro trabajo aqu\u00ed. Lo describimos en t\u00e9rminos del siguiente escenario de adopci\u00f3n de tecnolog\u00eda, aunque hay muchos otros ejemplos que servir\u00edan para el mismo prop\u00f3sito.Obs\u00e9rvese que A es la tecnolog\u00eda \"mejor\" si q < 21, en el sentido de que los beneficios de AA exceder\u00edan entonces a los de BB, mientras que A es la peor tecnolog\u00eda si q > 21. Se pueden derivar varios conocimientos cualitativos a partir de una difusi\u00f3n modelo incluso en este nivel de simplicidad. Espec\u00edficamente, considere una red G y deje que todos los nodos jueguen inicialmente con B. Ahora suponga que una peque\u00f1a cantidad de nodos comienzan a adoptar la estrategia A. Compatibilidad, Interoperabilidad y Biling\u00fcismo. Sin embargo, una pieza importante que posiblemente falta en los modelos b\u00e1sicos de difusi\u00f3n de la teor\u00eda de juegos es una imagen m\u00e1s detallada de lo que sucede en el l\u00edmite de coexistencia, donde la forma b\u00e1sica del modelo postula nodos que adoptan A vinculados a nodos que adoptan A. B. En estos entornos motivadores para los modelos, por supuesto, uno ve muy a menudo regiones de interfaz en las que los individuos esencialmente se vuelven \"biling\u00fces\". '' En el caso de la difusi\u00f3n del lenguaje humano, esta biling\u00fcismo se entiende literalmente: las regiones geogr\u00e1ficas donde hay una interacci\u00f3n sustancial con hablantes de dos idiomas diferentes tienden a tener habitantes que hablan ambos. Desde este punto de vista, es natural preguntarse c\u00f3mo se comportan los modelos de difusi\u00f3n cuando se extienden de modo que ciertos nodos puedan ser biling\u00fces en este sentido tan general, adoptando ambas estrategias con alg\u00fan costo para ellos mismos. \u00bfQu\u00e9 podr\u00edamos aprender de tal extensi\u00f3n? Para empezar, tiene el potencial de proporcionar una perspectiva valiosa sobre la cuesti\u00f3n de la compatibilidad e incompatibilidad que sustenta la competencia entre las empresas de tecnolog\u00eda. Existe una amplia literatura sobre c\u00f3mo la compatibilidad entre tecnolog\u00edas afecta la competencia entre empresas y, en particular, c\u00f3mo la incompatibilidad puede ser una decisi\u00f3n estrat\u00e9gica beneficiosa para ciertos participantes en un mercado -LSB- 3, 4, 8, 9, 12 -RSB-. Si bien estos modelos existentes de compatibilidad capturan los efectos de red en el sentido de que los usuarios en el mercado prefieren usar tecnolog\u00eda que est\u00e1 m\u00e1s extendida, no capturan el fen\u00f3meno de red m\u00e1s detallado representado por la difusi\u00f3n: que cada usuario incluye su visi\u00f3n local en la decisi\u00f3n, en base a lo que est\u00e1n haciendo sus propios vecinos de la red social. Un modelo de difusi\u00f3n que incorporara tales extensiones podr\u00eda proporcionar informaci\u00f3n sobre la estructura de los l\u00edmites en la red entre tecnolog\u00edas; Potencialmente, podr\u00eda ofrecer una base te\u00f3rica de grafos sobre c\u00f3mo la incompatibilidad puede beneficiar a una tecnolog\u00eda existente, fortaleciendo estos l\u00edmites e impidiendo la incursi\u00f3n de una tecnolog\u00eda nueva y mejor. El presente trabajo: Difusi\u00f3n con conducta biling\u00fce. En este art\u00edculo, desarrollamos un conjunto de modelos de difusi\u00f3n que incorporan nociones de compatibilidad y biling\u00fcismo, y encontramos que algunos fen\u00f3menos inesperados surgen incluso de versiones muy simples de los modelos. Comenzamos con la que tal vez sea la forma m\u00e1s sencilla de ampliar el modelo de Morris analizado anteriormente para incorporar el comportamiento biling\u00fce. Consideremos nuevamente el ejemplo de los sistemas IM A y B, con la estructura de pagos como antes,pero supongamos ahora que cada nodo puede adoptar una tercera estrategia, denominada AB, en la que decide utilizar tanto A como B. Finalmente, quien adopta AB paga una penalizaci\u00f3n de costo fijo de c -LRB- es decir, c se suma a su pago total -RRB- para representar el costo de tener que mantener ambas tecnolog\u00edas. As\u00ed, en este modelo, hay dos par\u00e1metros que pueden variar: las cualidades relativas de las dos tecnolog\u00edas -LRB- codificadas por q -RRB-, y el coste de ser biling\u00fce, que refleja un tipo de incompatibilidad -LRB- codificada por c -RRB-. Tambi\u00e9n introducimos una notaci\u00f3n adicional que ser\u00e1 \u00fatil en las secciones siguientes: definimos r = c / \u0394, la penalizaci\u00f3n fija por adoptar AB, escalada de modo que sea un costo por borde. En el modelo de Morris, donde las \u00fanicas opciones estrat\u00e9gicas son A y B, un par\u00e1metro clave es el umbral de contagio de G, denotado q \u2217 -LRB- G -RRB-: este es el supremo de q para el cual A puede volverse epid\u00e9mico en G con par\u00e1metro q en la estructura de pagos. Un resultado central de -LSB- 13 -RSB- es que 21 es el umbral de contagio m\u00e1ximo posible para cualquier gr\u00e1fico: supG q \u2217 -LRB- G -RRB- = 21. De hecho, existen gr\u00e1ficos en los que el umbral de contagio es tan grande como 21 -LRB- incluyendo la l\u00ednea infinita - el \u00fanico gr\u00e1fico 2-regular conectado infinito -RRB-; por otro lado, se puede mostrar que no existe ning\u00fan gr\u00e1fico con un umbral de contagio mayor que Figura 1: La regi\u00f3n del plano -LRB- q, r -RRB- para la cual la tecnolog\u00eda A puede volverse epid\u00e9mica en la l\u00ednea infinita. Nuestros resultados. -LRB- Encontramos formas an\u00e1logas que se vuelven a\u00fan m\u00e1s complejas para otras estructuras de gr\u00e1ficos infinitos simples; v\u00e9anse, por ejemplo, las Figuras 3 y 4. -RRB- En particular, esto significa que para valores de q cercanos pero menores que 21, la estrategia A puede volverse epid\u00e9mica en la l\u00ednea infinita si r es suficientemente peque\u00f1o o suficientemente grande, pero no si r toma valores en alg\u00fan intervalo intermedio. En otras palabras, la estrategia B -LRB- que representa la peor tecnolog\u00eda, ya que q < 21 -RRB- sobrevivir\u00e1 si y s\u00f3lo si el costo de ser biling\u00fce se calibra para que se encuentre en este intervalo medio. Esto es un reflejo de una compatibilidad limitada -que puede ser de inter\u00e9s para una tecnolog\u00eda establecida dificultar, pero no demasiado, el uso de una nueva tecnolog\u00eda- y nos sorprende que surja de un modelo b\u00e1sico sobre tales una estructura de red simple. Es natural preguntarse si existe una interpretaci\u00f3n cualitativa de c\u00f3mo esto surge del modelo y, de hecho, no es dif\u00edcil dar tal interpretaci\u00f3n, de la siguiente manera. Cuando r es muy peque\u00f1o, a los nodos les resulta barato adoptar AB como estrategia, por lo que AB se propaga por toda la red. Una vez que AB est\u00e1 en todas partes, las actualizaciones de mejor respuesta hacen que todos los nodos cambien a A, ya que obtienen los mismos beneficios de interacci\u00f3n sin pagar la penalizaci\u00f3n de r. Cuando r es muy grande, a los nodos en la interfaz, con un vecino A y un vecino B, les resultar\u00e1 demasiado caro elegir AB, por lo que elegir\u00e1n A -LRB-, la mejor tecnolog\u00eda -RRB-,y por tanto A se propagar\u00e1 paso a paso a trav\u00e9s de la red. Cuando r toma un valor intermedio, un nodo v en la interfaz, con un vecino A y un vecino B, encontrar\u00e1 m\u00e1s beneficioso adoptar AB como estrategia. Por lo tanto, este valor intermedio de r permite que se forme una `` frontera '' de AB entre los adoptantes de A y los adoptantes de B. Pero si tiene el equilibrio correcto en el valor de r, entonces las adopciones de A llegan a un det\u00e9ngase en un l\u00edmite biling\u00fce donde los nodos adoptan AB. Yendo m\u00e1s all\u00e1 de los gr\u00e1ficos espec\u00edficos G, encontramos que esta no convexidad tambi\u00e9n se cumple en un sentido mucho m\u00e1s general, al considerar la regi\u00f3n epid\u00e9mica general \u03a9 = UG\u03a9 -LRB- G -RRB-. Para cualquier valor dado de \u0394, la regi\u00f3n \u03a9 es una uni\u00f3n complicada de pol\u00edgonos acotados y no acotados, y no tenemos una descripci\u00f3n simple y cerrada para ello. Sin embargo, podemos demostrar mediante un argumento de funci\u00f3n potencial que ning\u00fan punto -LRB- q, r -RRB- con q > 21 pertenece a \u03a9. Adem\u00e1s, podemos mostrar la existencia de un punto -LRB- q, r -RRB- E ~ \u03a9 para el cual q < 21. Por otro lado, la consideraci\u00f3n de la regi\u00f3n epid\u00e9mica para la l\u00ednea infinita muestra que -LRB- 21, r -RRB- E \u03a9 para r = 0 y para r suficientemente grande. Por tanto, ni \u03a9 ni su complemento son convexos en el cuadrante positivo. Finalmente, tambi\u00e9n ampliamos una caracterizaci\u00f3n que Morris dio para el umbral de contagio -LSB- 13 -RSB-, produciendo una caracterizaci\u00f3n algo m\u00e1s intrincada de la regi\u00f3n \u03a9 -LRB- G -RRB-. En el marco de Morris, sin una estrategia AB, demostr\u00f3 que A no puede volverse epid\u00e9mico con el par\u00e1metro q si y s\u00f3lo si cada conjunto cofinito de nodos contiene un subconjunto S que funciona como una \"comunidad\" bien conectada: cada nodo en S tiene al menos una fracci\u00f3n -LRB- 1 -- q -RRB- de sus vecinos en S. En otras palabras, las comunidades muy unidas son los obst\u00e1culos naturales a la difusi\u00f3n en su entorno. Con la estrategia AB como opci\u00f3n adicional, una estructura m\u00e1s compleja se convierte en el obst\u00e1culo: demostramos que A no puede volverse epid\u00e9mico con par\u00e1metros -LRB- q, r -RRB- si y s\u00f3lo si cada conjunto cofinito contiene una estructura que consiste en una -Comunidad unida con un tipo particular de \"interfaz\" de nodos vecinos. Mostramos que dicha estructura permite a los nodos adoptar AB en la interfaz y B dentro de la propia comunidad, evitando una mayor propagaci\u00f3n de A; y a la inversa, \u00e9sta es la \u00fanica manera de bloquear la propagaci\u00f3n de A. Ampliaciones adicionales. Otra forma de modelar la compatibilidad y la interoperabilidad en los modelos de difusi\u00f3n es a trav\u00e9s de los t\u00e9rminos \"fuera de la diagonal\" que representan el beneficio de las interacciones entre un nodo que adopta A y un nodo que adopta B. En lugar de establecerlos en 0, podemos considerar establecerlos en un valor x < min -LRB- q, 1 -- q -RRB-. Encontramos que para el caso de dos tecnolog\u00edas, el modelo no se vuelve m\u00e1s general, en el sentido de que cualquier caso de este tipo es equivalente, mediante un reescalamiento de q y r, a uno donde x = 0. Adem\u00e1s,Utilizando nuestra caracterizaci\u00f3n de la regi\u00f3n \u03a9 -LRB- G -RRB- en t\u00e9rminos de comunidades e interfaces, mostramos un resultado de monoton\u00eda: si A puede volverse epid\u00e9mica en un gr\u00e1fico G con par\u00e1metros -LRB- q, r, x -RRB-, y luego se aumenta x, entonces A a\u00fan puede volverse epid\u00e9mico con los nuevos par\u00e1metros. Tambi\u00e9n consideramos el efecto de estos t\u00e9rminos fuera de la diagonal en una extensi\u00f3n a k > 2 tecnolog\u00edas competidoras; para las tecnolog\u00edas X e Y, sea qX el beneficio de una interacci\u00f3n XX en un borde y qXY el beneficio de una interacci\u00f3n XY en un borde. Consideramos un escenario en el que dos tecnolog\u00edas B y C, que inicialmente coexisten con qBC = 0, se enfrentan a la introducci\u00f3n de una tercera tecnolog\u00eda, mejor, A en un conjunto finito de nodos. Mostramos un ejemplo en el que B y C sobreviven en equilibrio si fijan qBC en un rango particular de valores, pero no si fijan qBC demasiado bajo o demasiado alto para estar en este rango. As\u00ed, incluso en un modelo de difusi\u00f3n b\u00e1sico con tres tecnolog\u00edas, se encuentran casos en los que dos empresas tienen un incentivo para adoptar una \"alianza estrat\u00e9gica\" limitada, aumentando parcialmente su interoperabilidad para defenderse de un nuevo participante en el mercado. 6. COMPATIBILIDAD LIMITADA Consideremos ahora algunas formas adicionales de modelar la compatibilidad y la interoperabilidad. Primero consideramos dos tecnolog\u00edas, como en las secciones anteriores, e introducimos pagos \"fuera de la diagonal\" para capturar un beneficio positivo en las interacciones AB directas. Encontramos que, de hecho, esto no es m\u00e1s general que el modelo con beneficios cero para las interacciones AB. Luego consideramos extensiones a tres tecnolog\u00edas, identificando situaciones en las que dos tecnolog\u00edas existentes coexistentes pueden o no querer aumentar su compatibilidad mutua frente a una tercera tecnolog\u00eda nueva. Dos tecnolog\u00edas. Una relajaci\u00f3n natural del modelo de dos tecnolog\u00edas es introducir pagos -LRB- peque\u00f1os -RRB- positivos para la interacci\u00f3n AB; es decir, la comunicaci\u00f3n entre tecnolog\u00edas produce un valor menor para ambos agentes. Podemos modelar esto usando una variable xAB que representa la recompensa obtenida por un agente con tecnolog\u00eda A cuando su vecino tiene tecnolog\u00eda B, y de manera similar, una variable xBA que representa la recompensa obtenida por un agente con B cuando su vecino tiene A. Aqu\u00ed consideramos la Caso especial en el que estas entradas ``fuera de la diagonal'' son sim\u00e9tricas, es decir, xAB = xBA = x. Tambi\u00e9n suponemos que x < q < 1 -- q. Primero mostramos que el juego con entradas fuera de la diagonal es equivalente a un juego sin estas entradas, bajo un simple reescalamiento de q y r. Tenga en cuenta que si redimensionamos todos los pagos mediante una constante aditiva o multiplicativa, el comportamiento del juego no se ve afectado. Dado un juego con entradas fuera de la diagonal parametrizadas por q, r y x, considere restar x de todos los pagos y aumentarlo en un factor de 1 / -LRB- 1 -- 2x -RRB-. Como puede verse al examinar la Tabla 1, los pagos resultantes son exactamente los de un juego sin entradas fuera de la diagonal,parametrizado por q' = -LRB- q -- x -RRB- / -LRB- 1 -- 2x -RRB- y r ' = r / -LRB- 1 -- 2x -RRB-. Por tanto, la adici\u00f3n de entradas sim\u00e9tricas fuera de la diagonal no ampl\u00eda la clase de juegos que se consideran. La Tabla 1 representa los beneficios del juego de coordinaci\u00f3n en t\u00e9rminos de estos par\u00e1metros. Sin embargo, todav\u00eda podemos preguntarnos c\u00f3mo la adici\u00f3n de una entrada fuera de la diagonal podr\u00eda afectar el resultado de un juego en particular. Como muestra el siguiente ejemplo, aumentar la compatibilidad entre dos tecnolog\u00edas puede permitir que una tecnolog\u00eda que inicialmente no era epid\u00e9mica lo sea. EJEMPLO 6.1. Considere el juego de contagio que se juega en un gr\u00e1fico de l\u00edneas gruesas -LRB- ver Secci\u00f3n 3 -RRB- con r = 5/32 y q = 3/8. En este caso, A no es epid\u00e9mica, como se puede ver al examinar la Figura 1, ya que 2r < q y q + r > 1/2. Sin embargo, si insertamos pagos sim\u00e9tricos fuera de la diagonal x = 1/4, tenemos un nuevo juego, equivalente a un juego parametrizado por r ' = 5/16 y q ' = 1/4. Dado que q ' < 1/2 y q ' < 2r ', A es epid\u00e9mica en este juego y, por tanto, tambi\u00e9n en el juego con compatibilidad limitada. Ahora mostramos que, en general, si A es la tecnolog\u00eda superior -LRB-, es decir, q < 1/2 -RRB-, agregar un t\u00e9rmino de compatibilidad x solo puede ayudar a que A se expanda. TEOREMA 6.2. Sea G un juego sin compatibilidad, parametrizado por r y q en una red particular. Sea G ' el mismo juego, pero con un t\u00e9rmino de compatibilidad sim\u00e9trico agregado x. Si A es epid\u00e9mica para G, entonces A es epid\u00e9mica para G'. PRUEBA. Demostraremos que cualquier estructura de bloqueo en G ' es tambi\u00e9n una estructura de bloqueo en G. Seg\u00fan nuestro teorema de caracterizaci\u00f3n, el Teorema 4.6, esto implica el resultado deseado. Tenemos que G' equivale a un juego sin compatibilidad parametrizado por q' = -LRB- q -- x -RRB- / -LRB- 1 -- 2x -RRB- y r ' = r / -LRB- 1 -- 2x -RRB-. Considere una estructura de bloqueo -LRB- SB, SAB -RRB- para G'. Por tanto, m\u00e1s de dos tecnolog\u00edas. Dada la compleja estructura inherente a los juegos de contagio con dos tecnolog\u00edas, la comprensi\u00f3n de los juegos de contagio con tres o m\u00e1s tecnolog\u00edas est\u00e1 en gran medida abierta. Aqu\u00ed indicamos algunos de los problemas t\u00e9cnicos que surgen con m\u00faltiples tecnolog\u00edas, a trav\u00e9s de una serie de resultados iniciales. La configuraci\u00f3n b\u00e1sica que estudiamos es aquella en la que inicialmente coexisten dos tecnolog\u00edas existentes, B y C, y una tercera tecnolog\u00eda A, superior a ambas, se introduce inicialmente en un conjunto finito de nodos. Primero presentamos un teorema que establece que para cualquier \u0394 par, hay un juego de contagio en un \u0394: gr\u00e1fico regular en el que las dos tecnolog\u00edas actuales B y C pueden encontrar beneficioso aumentar su compatibilidad para evitar ser eliminadas por el nueva tecnolog\u00eda superior A. En particular, consideramos una situaci\u00f3n en la que inicialmente, dos tecnolog\u00edas B y C con compatibilidad cero se encuentran en un estado estable. Por estado estable queremos decir que ninguna perturbaci\u00f3n finita de los estados actuales puede provocar una epidemia ni para B ni para C. Tambi\u00e9n tenemos una tecnolog\u00eda A que es superior tanto a B como a C,y puede convertirse en una epidemia al obligar a un solo nodo a elegir A. Sin embargo, al aumentar su compatibilidad, B y C pueden mantener su estabilidad y resistir una epidemia de A. Sea qA denota los beneficios de dos nodos adyacentes que eligen la tecnolog\u00eda A, y defina qB y qC de manera an\u00e1loga. Supondremos qA > qB > qC. Tambi\u00e9n suponemos que r, el costo de seleccionar tecnolog\u00edas adicionales, es lo suficientemente grande como para garantizar que los nodos nunca adopten m\u00e1s de una tecnolog\u00eda. Finalmente, consideramos un par\u00e1metro de compatibilidad qBC que representa los pagos a dos nodos adyacentes cuando uno selecciona B y el otro selecciona C. Por lo tanto, nuestro juego de contagio ahora se describe mediante cinco par\u00e1metros -LRB- G, qA, qB, qC, qBC -RRB -. PRUEBA. -LRB- Boceto. -RRB- Dado \u0394, defina G comenzando con una cuadr\u00edcula infinita y conectando cada nodo a su \u0394 m\u00e1s cercano: 2 vecinos que est\u00e1n en la misma fila. El estado inicial s asigna la estrategia B a filas pares y la estrategia C a filas impares. Las afirmaciones primera, tercera y cuarta del teorema se pueden verificar verificando las desigualdades correspondientes. La segunda afirmaci\u00f3n se deriva de la primera y de la observaci\u00f3n de que las filas alternas contienen cualquier posible epidemia que crezca verticalmente. El teorema anterior muestra que dos tecnolog\u00edas pueden sobrevivir a la introducci\u00f3n de una nueva tecnolog\u00eda aumentando su nivel de compatibilidad entre s\u00ed. Como era de esperar, Tabla 1: Los pagos en el juego de coordinaci\u00f3n. La entrada -LRB- x, y -RRB- en la fila i, columna j indica que el jugador de la fila obtiene un pago de x y el jugador de la columna obtiene un pago de y cuando el jugador de la fila juega la estrategia i y el jugador de la columna juega la estrategia j. Hay casos en los que una mayor compatibilidad entre dos tecnolog\u00edas ayuda a una tecnolog\u00eda a expensas de la otra. Pero, sorprendentemente, tambi\u00e9n hay casos en los que la compatibilidad resulta perjudicial para ambas partes; el siguiente ejemplo considera una configuraci\u00f3n inicial fija con las tecnolog\u00edas A, B y C que est\u00e1 en equilibrio cuando qBC = 0. Sin embargo, si este t\u00e9rmino de compatibilidad aumenta lo suficiente, el equilibrio se pierde y A se vuelve epid\u00e9mica. EJEMPLO 6.4. Considere la uni\u00f3n de un gr\u00e1fico de cuadr\u00edcula bidimensional infinito con nodos u -LRB- x, y -RRB- y un gr\u00e1fico de l\u00edneas infinitas con nodos v -LRB- y -RRB-. Agregue una arista entre u -LRB- 1, y -RRB- y v -LRB- y -RRB- para todo y. Para esta red, consideramos la configuraci\u00f3n inicial en la que todos los nodos v -LRB- y -RRB- seleccionan A, y el nodo u -LRB- x, y -RRB- selecciona B si x < 0 y selecciona C en caso contrario. Ahora definimos los par\u00e1metros de este juego de la siguiente manera. Se verifica f\u00e1cilmente que para estos valores, la configuraci\u00f3n inicial dada anteriormente es un equilibrio. Sin embargo, supongamos ahora que aumentamos el t\u00e9rmino de coordinaci\u00f3n, estableciendo qBC = 0,9. Esto no es un equilibrio, ya que cada nodo de la forma u -LRB- 0, y -RRB- ahora tiene un incentivo para cambiar de C -LRB- generando un pago de 3.9 -RRB- a B -LRB- generando as\u00ed un pago de 3,95 -RRB-. Sin embargo,una vez que estos nodos han adoptado B, la mejor respuesta para cada nodo de la forma u -LRB- 1, y -RRB- es A -LRB- A genera un pago de 4 mientras que B solo genera un pago de 3,95 -RRB- . A partir de aqu\u00ed, no es dif\u00edcil demostrar que A se propaga directamente por toda la red.", "keyphrases": ["proceso difuso", "modelo difuso de teor\u00eda de juegos", "estrategia incompatible", "biling\u00fce", "l\u00edmite de compatibilidad", "interoperar", "propiedad no convexa", "personaje", "teorema de morri", "umbral de contagio", "juego de contagio", "funci\u00f3n potencia"]}
{"file_name": "I-34", "text": "Resoluci\u00f3n de conflictos e inconsistencias en organizaciones virtuales reguladas por normas RESUMEN Las organizaciones virtuales gobernadas por normas definen, gobiernan y facilitan el intercambio coordinado de recursos y la resoluci\u00f3n de problemas en sociedades de agentes. Con una descripci\u00f3n expl\u00edcita de las normas, se puede lograr la apertura en las organizaciones virtuales: se pueden acomodar sin problemas nuevos componentes, dise\u00f1ados por varias partes. Nos centramos en organizaciones virtuales realizadas como sistemas multiagente, en las que agentes humanos y de software interact\u00faan para lograr objetivos individuales y globales. Sin embargo, cualquier explicaci\u00f3n realista de las normas debe abordar su naturaleza din\u00e1mica: las normas cambiar\u00e1n a medida que los agentes interact\u00faan entre s\u00ed y con su entorno. Debido a la naturaleza cambiante de las normas o a normas derivadas de diferentes organizaciones virtuales, habr\u00e1 situaciones en las que una acci\u00f3n se permite y se proh\u00edbe simult\u00e1neamente, es decir, surge un conflicto. Asimismo, habr\u00e1 situaciones en las que una acci\u00f3n sea a la vez obligada y prohibida, es decir, surja una inconsistencia. Introducimos un enfoque, basado en la unificaci\u00f3n de primer orden, para detectar y resolver dichos conflictos e inconsistencias. En nuestra soluci\u00f3n propuesta, anotamos una norma con el conjunto de valores que sus variables no deber\u00edan tener para evitar un conflicto o una inconsistencia con otra norma. Nuestro enfoque se adapta perfectamente a las interrelaciones dependientes del dominio entre acciones y los conflictos/inconsistencias indirectas que estas pueden causar. De manera m\u00e1s general, podemos capturar una noci\u00f3n \u00fatil de delegaci\u00f3n entre agentes -LRB- y entre roles -RRB- de acciones y normas asociadas a ellas, y utilizarla para abordar conflictos/inconsistencias causados \u200b\u200bpor la delegaci\u00f3n de acciones. Ilustramos nuestro enfoque con un ejemplo de e-Ciencia en el que los agentes apoyan los servicios Grid. 1. INTRODUCCI\u00d3N Las organizaciones virtuales -LRB- VOs -RRB- facilitan el intercambio coordinado de recursos y la resoluci\u00f3n de problemas que involucran a varias partes geogr\u00e1ficamente remotas -LSB- 9 -RSB-. Los VO definen y regulan las interacciones -LRB- facilitando as\u00ed la coordinaci\u00f3n -RRB- entre software y/o agentes humanos que se comunican para lograr objetivos individuales y globales -LSB- 16 -RSB-. Los VO se realizan como sistemas de m\u00faltiples agentes y una caracter\u00edstica m\u00e1s deseable de dichos sistemas es la apertura, mediante la cual los nuevos componentes dise\u00f1ados por otras partes se adaptan sin problemas. Las normas regulan el comportamiento observable de agentes de software heterog\u00e9neos e interesados, dise\u00f1ados por varias partes que pueden no confiar completamente entre s\u00ed -LSB- 3, 24 -RSB-. Sin embargo, las VO reguladas por normas pueden experimentar problemas cuando las normas asignadas a sus agentes est\u00e1n en conflicto -LRB- es decir, una acci\u00f3n est\u00e1 simult\u00e1neamente prohibida y permitida -RRB- o inconsistente -LRB- es decir, una acci\u00f3n est\u00e1 simult\u00e1neamente prohibida y obligada -RRB- . Proponemos un medio para detectar y resolver autom\u00e1ticamente conflictos e inconsistencias en VO reguladas por normas. Hacemos uso de la unificaci\u00f3n de t\u00e9rminos de primer orden -LSB- 8 -RSB- para descubrir si y c\u00f3mo las normas se superponen en su influencia -LRB- es decir,los agentes y valores de par\u00e1metros en las acciones de los agentes que las normas pueden afectar -RRB-. Esto permite una soluci\u00f3n detallada mediante la cual se restringe la influencia de normas conflictivas o inconsistentes para conjuntos de valores particulares. Por ejemplo, las normas `` al agente x se le permite enviar la oferta -LRB- ag1, 20 -RRB- '' y `` al agente ag2 se le proh\u00edbe enviar la oferta -LRB- y, z -RRB- '' -LRB- donde x, y, z son variables y ag1, ag2, 20 son constantes -RRB- est\u00e1n en conflicto porque sus agentes, acciones y t\u00e9rminos -LRB- dentro de las acciones -RRB- se unifican. Resolvemos el conflicto anotando normas con conjuntos de valores que sus variables no pueden tener, restringiendo as\u00ed su influencia. En nuestro ejemplo, el conflicto se evita si requerimos que la variable y no pueda ser ag1 y que z no pueda ser 20. En la siguiente secci\u00f3n proporcionamos una definici\u00f3n minimalista para VO regulados por normas. En la secci\u00f3n 3 definimos formalmente los conflictos normativos y explicamos c\u00f3mo se detectan y resuelven. En la secci\u00f3n 4 describimos c\u00f3mo se puede adaptar la maquinaria de la secci\u00f3n anterior para detectar y resolver inconsistencias normativas. En la secci\u00f3n 5 describimos c\u00f3mo se utilizan nuestras normas restringidas en sociedades de agentes conscientes de las normas. En la secci\u00f3n 6 explicamos c\u00f3mo se puede utilizar nuestra maquinaria para detectar y resolver conflictos/inconsistencias indirectas, es decir, aquellos causados \u200b\u200ba trav\u00e9s de relaciones entre acciones; ampliamos y adaptamos la maquinaria para dar cabida a la delegaci\u00f3n de normas. En la secci\u00f3n 7 ilustramos nuestro enfoque con un ejemplo de agentes de software regulados por normas que sirven al Grid.En la secci\u00f3n 7 ilustramos nuestro enfoque con un ejemplo de agentes de software regulados por normas que sirven al Grid.En la secci\u00f3n 7 ilustramos nuestro enfoque con un ejemplo de agentes de software regulados por normas que sirven al Grid.", "keyphrases": ["\u00f3rgano virtual", "sistema multiagente", "norma-regular vo", "agente", "conflicto de normas", "conflicto prohibir", "norma inconsistente", "agente externo", "agente gobernador"]}
{"file_name": "J-31", "text": "Calcular la estrategia \u00f3ptima a seguir \u2217 RESUMEN En los sistemas multiagente, los escenarios estrat\u00e9gicos a menudo se analizan bajo el supuesto de que los jugadores eligen sus estrategias simult\u00e1neamente. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisi\u00f3n. Estos modelos se denominan sin\u00f3nimos de liderazgo, compromiso o Stackelberg, y el juego \u00f3ptimo en dichos modelos suele ser significativamente diferente del juego \u00f3ptimo en el modelo en el que las estrategias se seleccionan simult\u00e1neamente. El reciente aumento del inter\u00e9s en soluciones inform\u00e1ticas de teor\u00eda de juegos ha ignorado hasta ahora los modelos de liderazgo -LRB- con la excepci\u00f3n del inter\u00e9s en el dise\u00f1o de mecanismos, donde el dise\u00f1ador est\u00e1 impl\u00edcitamente en una posici\u00f3n de liderazgo -RRB-. En este art\u00edculo, estudiamos c\u00f3mo calcular estrategias \u00f3ptimas para comprometerse tanto con estrategias puras como con estrategias mixtas, tanto en juegos de forma normal como bayesianos. Damos tanto resultados positivos -LRB- de algoritmos eficientes -RRB- como resultados negativos -LRB- resultados de dureza NP -RRB-. 1. INTRODUCCI\u00d3N En sistemas multiagente con agentes interesados \u200b\u200b-LRB-, incluyendo la mayor\u00eda de entornos econ\u00f3micos -RRB-, la acci\u00f3n \u00f3ptima que debe tomar un agente depende de las acciones que toman los otros agentes. Para analizar c\u00f3mo deber\u00eda comportarse un agente en tales entornos, es necesario aplicar las herramientas de la teor\u00eda de juegos. Normalmente, cuando se modela un escenario estrat\u00e9gico en el marco de la teor\u00eda de juegos, se supone que los jugadores eligen sus estrategias simult\u00e1neamente. Esto es especialmente cierto cuando el escenario se modela como un juego de forma normal, que s\u00f3lo especifica la utilidad de cada agente en funci\u00f3n del vector de estrategias que los agentes eligen, y no proporciona ninguna informaci\u00f3n sobre el orden en el que los agentes hacen sus acciones. sus decisiones y lo que los agentes observan sobre decisiones anteriores de otros agentes. Dado que el juego se modela en forma normal, normalmente se analiza utilizando el concepto de equilibrio de Nash. Un equilibrio de Nash especifica una estrategia para cada jugador, de modo que ning\u00fan jugador tiene un incentivo para desviarse individualmente de este perfil de estrategias. -LRB- Normalmente, se permite que las estrategias sean mixtas, es decir, distribuciones de probabilidad sobre las estrategias -LRB- puras -RRB- originales. -RRB- Se garantiza la existencia de un equilibrio de Nash -LRB- de estrategia mixta -RRB- en juegos finitos -LSB- 18 -RSB-, pero un problema es que puede haber m\u00faltiples equilibrios de Nash. Esto conduce al problema de selecci\u00f3n del equilibrio: c\u00f3mo un agente puede saber qu\u00e9 estrategia utilizar si no sabe qu\u00e9 equilibrio debe utilizar. Cuando el escenario se modela como un juego extensivo, es posible especificar que algunos jugadores reciban cierta informaci\u00f3n sobre las acciones realizadas por otros anteriormente en el juego antes de decidir sobre su acci\u00f3n. Sin embargo, en general, los jugadores no saben todo lo que pas\u00f3 al principio del juego. Debido a esto,Por lo general, estos juegos todav\u00eda se analizan utilizando un concepto de equilibrio, donde se especifica una estrategia mixta para cada jugador y se requiere que la estrategia de cada jugador sea la mejor respuesta a las estrategias de los dem\u00e1s. -LRB- Normalmente ahora se impone una restricci\u00f3n adicional a las estrategias para garantizar que los jugadores no jueguen de una manera irracional con respecto a la informaci\u00f3n que han recibido hasta ahora. Esto conduce a refinamientos del equilibrio de Nash, como el equilibrio perfecto en subjuegos y el equilibrio secuencial. -RRB- Sin embargo, en muchos entornos del mundo real, las estrategias no se seleccionan de manera tan simult\u00e1nea. Muchas veces, un jugador -LRB- el l\u00edder -RRB- es capaz de comprometerse con una estrategia antes que otro jugador -LRB- el seguidor -RRB-. Esto puede deberse a diversas razones. Por ejemplo, uno de los jugadores puede llegar al sitio en el que se va a jugar el juego antes que otro agente -LRB-. Por ejemplo, en escenarios econ\u00f3micos, un jugador puede ingresar a un mercado antes y comprometerse con una forma de hacer negocios -RRB. -. Ese poder de compromiso tiene un profundo impacto en c\u00f3mo se debe jugar el juego. Por ejemplo, al l\u00edder le puede convenir jugar una estrategia que est\u00e9 dominada en la representaci\u00f3n normal del juego. En general, si es posible comprometerse con estrategias mixtas, entonces -LRB- bajo supuestos menores -RRB- nunca est\u00e1 de m\u00e1s, y a menudo ayuda, comprometerse con una estrategia -LSB- 26 -RSB-. Verse obligado a comprometerse con una estrategia pura a veces ayuda y a veces perjudica -LRB- por ejemplo, comprometerse con una estrategia pura en piedra, papel o tijera antes de que la decisi\u00f3n del otro jugador naturalmente resulte en una p\u00e9rdida -RRB-. En este art\u00edculo asumiremos que el compromiso siempre es forzado; si no es as\u00ed, el jugador que tiene la opci\u00f3n de comprometerse puede simplemente comparar el resultado del compromiso con el resultado de no compromiso -LRB- movimiento simult\u00e1neo -RRB-. Los modelos de liderazgo son especialmente importantes en entornos con m\u00faltiples agentes de software interesados. Una vez que se finaliza el c\u00f3digo para un agente -LRB- o para un equipo de agentes -RRB- y se implementa el agente, el agente se compromete a ejecutar la estrategia -LRB- posiblemente aleatoria -RRB- que prescribe el c\u00f3digo. Finalmente, tambi\u00e9n existe una situaci\u00f3n de liderazgo impl\u00edcita en el campo del dise\u00f1o de mecanismos, en la que un jugador -LRB-, el dise\u00f1ador -RRB-, elige las reglas del juego que luego juegan los jugadores restantes. De hecho, el dise\u00f1ador del mecanismo puede beneficiarse al comprometerse con una elecci\u00f3n que, si las acciones de los agentes -LRB- restantes -RRB- fueran fijas, ser\u00eda sub\u00f3ptima. Sin embargo, se ha ignorado el c\u00e1lculo de la estrategia \u00f3ptima con la que comprometerse en una situaci\u00f3n de liderazgo. Te\u00f3ricamente, las situaciones de liderazgo pueden considerarse simplemente como un juego extensivo en el que un jugador elige primero una estrategia -LRB- para el juego original -RRB-. Sin embargo, el n\u00famero de estrategias en este juego extensivo puede ser extremadamente grande. Por ejemplo, si el l\u00edder puede comprometerse con una estrategia mixta en el juego original,entonces cada una de las estrategias mixtas -LRB- de -RRB- constituye una estrategia pura en la representaci\u00f3n en forma extensiva de la situaci\u00f3n de liderazgo. -LRB- Observamos que no es lo mismo un compromiso de reparto que un reparto sobre compromisos. -RRB- Adem\u00e1s, si el juego original es en s\u00ed mismo un juego en forma extensiva, el n\u00famero de estrategias en la representaci\u00f3n en forma extensiva de la situaci\u00f3n de liderazgo -LRB- que es un juego en forma extensiva diferente -RRB- se vuelve a\u00fan mayor. Debido a esto, normalmente no es factible desde el punto de vista computacional transformar simplemente el juego original en una representaci\u00f3n en forma extensiva de la situaci\u00f3n de liderazgo; en cambio, tenemos que analizar el juego en su representaci\u00f3n original. En este art\u00edculo, estudiamos c\u00f3mo calcular la estrategia \u00f3ptima a seguir, tanto en juegos de forma normal -LRB- Secci\u00f3n 2 -RRB- como en juegos bayesianos, que son un caso especial de juegos de forma extensiva -LRB- Secci\u00f3n 3 -RRB -. 4. CONCLUSIONES E INVESTIGACIONES FUTURAS En los sistemas multiagente, los escenarios estrat\u00e9gicos a menudo se analizan bajo el supuesto de que los jugadores eligen sus estrategias simult\u00e1neamente. Esto requiere alguna noci\u00f3n de equilibrio -LRB-, equilibrio de Nash y sus refinamientos -RRB-, y a menudo conduce al problema de selecci\u00f3n de equilibrio: no est\u00e1 claro para cada jugador individual seg\u00fan qu\u00e9 equilibrio debe jugar. Sin embargo, este modelo no siempre es realista. En muchos escenarios, un jugador puede comprometerse con una estrategia antes de que el otro jugador tome una decisi\u00f3n. Por ejemplo, un agente puede llegar al sitio -LRB- real o virtual -RRB- del juego antes que el otro, o, en el caso espec\u00edfico de los agentes de software, el c\u00f3digo de un agente puede completarse y confirmarse antes que el de otro. agente. Estos modelos se denominan sin\u00f3nimos de liderazgo, compromiso o Stackelberg, y el juego \u00f3ptimo en dichos modelos suele ser significativamente diferente del juego \u00f3ptimo en el modelo en el que las estrategias se seleccionan simult\u00e1neamente. Espec\u00edficamente, si el compromiso con estrategias mixtas es posible, entonces el compromiso -LRB- \u00f3ptimo -RRB- nunca perjudica al l\u00edder y, a menudo, ayuda. El reciente aumento del inter\u00e9s en soluciones inform\u00e1ticas de teor\u00eda de juegos ha ignorado hasta ahora los modelos de liderazgo -LRB- con la excepci\u00f3n del inter\u00e9s en el dise\u00f1o de mecanismos, donde el dise\u00f1ador est\u00e1 impl\u00edcitamente en una posici\u00f3n de liderazgo -RRB-. En este art\u00edculo, estudiamos c\u00f3mo calcular estrategias \u00f3ptimas para comprometerse tanto con estrategias puras como con estrategias mixtas, tanto en juegos de forma normal como bayesianos. Para juegos de forma normal, demostramos que la estrategia pura \u00f3ptima con la que comprometerse se puede encontrar de manera eficiente para cualquier n\u00famero de jugadores. Se puede encontrar una estrategia mixta \u00f3ptima para comprometerse en un juego de forma normal de manera eficiente para dos jugadores usando programaci\u00f3n lineal -LRB- y no m\u00e1s eficientemente que eso, en el sentido de que cualquier programa lineal con una restricci\u00f3n de probabilidad puede codificarse como tal. problema -RRB-.-LRB- Esta es una generalizaci\u00f3n de la computabilidad en tiempo polinomial de estrategias minimax en juegos de forma normal. -RRB- El problema se vuelve NP-dif\u00edcil para tres jugadores -LRB- o m\u00e1s -RRB-. En los juegos bayesianos, el problema de encontrar una estrategia pura \u00f3ptima con la que comprometerse es NP-dif\u00edcil incluso en juegos de dos jugadores en los que el seguidor tiene un solo tipo, aunque los juegos de dos jugadores en los que el l\u00edder tiene un solo tipo pueden resolverse de manera eficiente. El problema de encontrar una estrategia mixta \u00f3ptima con la que comprometerse en un juego bayesiano es NP-dif\u00edcil incluso en juegos de dos jugadores en los que el l\u00edder tiene un solo tipo, aunque los juegos de dos jugadores en los que el seguidor tiene un solo tipo pueden resolverse eficientemente utilizando una generalizaci\u00f3n del enfoque de programaci\u00f3n lineal para juegos de forma normal. Las dos tablas siguientes resumen estos resultados. Resultados por apuesta por estrategias mixtas. -LRB- Con m\u00e1s de 2 jugadores, el ``seguidor'' es el \u00faltimo jugador en comprometerse, el ``l\u00edder'' es el primero. -RRB- La investigaci\u00f3n futura puede tomar varias direcciones. Tambi\u00e9n podemos estudiar el c\u00e1lculo de estrategias \u00f3ptimas para comprometernos en otras1 representaciones concisas de juegos de forma normal, por ejemplo, en juegos gr\u00e1ficos -LSB- 10 -RSB- o juegos de gr\u00e1ficos de acci\u00f3n/efecto local -LSB- 14, 1. -RSB-. Para los casos en los que calcular una estrategia \u00f3ptima con la que comprometerse es NP-dif\u00edcil, tambi\u00e9n podemos estudiar el c\u00e1lculo de estrategias aproximadamente \u00f3ptimas con las que comprometerse. Tambi\u00e9n se pueden estudiar modelos en los que varios jugadores -LRB- pero no todos -RRB- se comprometen al mismo tiempo. Otra direcci\u00f3n interesante a seguir es ver si calcular estrategias mixtas \u00f3ptimas con las que comprometernos puede ayudarnos o arrojar luz sobre el c\u00e1lculo de los equilibrios de Nash. A menudo, las estrategias mixtas \u00f3ptimas a las que comprometerse son tambi\u00e9n estrategias de equilibrio de Nash -LRB- por ejemplo, en juegos de dos jugadores de suma cero esto siempre es cierto -RRB-, aunque no siempre es as\u00ed -LRB- por ejemplo, como Como ya hemos se\u00f1alado, a veces la estrategia \u00f3ptima con la que comprometerse es una estrategia estrictamente dominada, que nunca puede ser una estrategia de equilibrio de Nash -RRB-.el ``l\u00edder'' es el primero. -RRB- La investigaci\u00f3n futura puede tomar varias direcciones. Tambi\u00e9n podemos estudiar el c\u00e1lculo de estrategias \u00f3ptimas para comprometernos en otras1 representaciones concisas de juegos de forma normal, por ejemplo, en juegos gr\u00e1ficos -LSB- 10 -RSB- o juegos de gr\u00e1ficos de acci\u00f3n/efecto local -LSB- 14, 1. -RSB-. Para los casos en los que calcular una estrategia \u00f3ptima con la que comprometerse es NP-dif\u00edcil, tambi\u00e9n podemos estudiar el c\u00e1lculo de estrategias aproximadamente \u00f3ptimas con las que comprometerse. Tambi\u00e9n se pueden estudiar modelos en los que varios jugadores -LRB- pero no todos -RRB- se comprometen al mismo tiempo. Otra direcci\u00f3n interesante a seguir es ver si calcular estrategias mixtas \u00f3ptimas con las que comprometernos puede ayudarnos o arrojar luz sobre el c\u00e1lculo de los equilibrios de Nash. A menudo, las estrategias mixtas \u00f3ptimas a las que comprometerse son tambi\u00e9n estrategias de equilibrio de Nash -LRB- por ejemplo, en juegos de dos jugadores de suma cero esto siempre es cierto -RRB-, aunque no siempre es as\u00ed -LRB- por ejemplo, como Como ya hemos se\u00f1alado, a veces la estrategia \u00f3ptima con la que comprometerse es una estrategia estrictamente dominada, que nunca puede ser una estrategia de equilibrio de Nash -RRB-.el ``l\u00edder'' es el primero. -RRB- La investigaci\u00f3n futura puede tomar varias direcciones. Tambi\u00e9n podemos estudiar el c\u00e1lculo de estrategias \u00f3ptimas para comprometernos en otras1 representaciones concisas de juegos de forma normal, por ejemplo, en juegos gr\u00e1ficos -LSB- 10 -RSB- o juegos de gr\u00e1ficos de acci\u00f3n/efecto local -LSB- 14, 1. -RSB-. Para los casos en los que calcular una estrategia \u00f3ptima con la que comprometerse es NP-dif\u00edcil, tambi\u00e9n podemos estudiar el c\u00e1lculo de estrategias aproximadamente \u00f3ptimas con las que comprometerse. Tambi\u00e9n se pueden estudiar modelos en los que varios jugadores -LRB- pero no todos -RRB- se comprometen al mismo tiempo. Otra direcci\u00f3n interesante a seguir es ver si calcular estrategias mixtas \u00f3ptimas con las que comprometernos puede ayudarnos o arrojar luz sobre el c\u00e1lculo de los equilibrios de Nash. A menudo, las estrategias mixtas \u00f3ptimas a las que comprometerse son tambi\u00e9n estrategias de equilibrio de Nash -LRB- por ejemplo, en juegos de dos jugadores de suma cero esto siempre es cierto -RRB-, aunque no siempre es as\u00ed -LRB- por ejemplo, como Como ya hemos se\u00f1alado, a veces la estrategia \u00f3ptima con la que comprometerse es una estrategia estrictamente dominada, que nunca puede ser una estrategia de equilibrio de Nash -RRB-.", "keyphrases": ["estrategia optima", "sistema multiag", "manera simult\u00e1nea", "modelo stackelberg", "modelo de liderazgo", "pura estrategia", "mezclar estrategias", "juego en forma normal", "juego bayesiano", "equilibrio de Nash", "np-duro"]}
{"file_name": "H-13", "text": "La influencia de las caracter\u00edsticas de los subt\u00edtulos en los patrones de clics en la b\u00fasqueda web RESUMEN Los motores de b\u00fasqueda web presentan listas de subt\u00edtulos, que comprenden t\u00edtulo, fragmento y URL, para ayudar a los usuarios a decidir qu\u00e9 resultados de b\u00fasqueda visitar. Comprender la influencia de las caracter\u00edsticas de estos subt\u00edtulos en el comportamiento de b\u00fasqueda en la Web puede ayudar a validar algoritmos y pautas para su generaci\u00f3n mejorada. En este art\u00edculo desarrollamos una metodolog\u00eda para utilizar registros de clics de un motor de b\u00fasqueda comercial para estudiar el comportamiento del usuario al interactuar con los t\u00edtulos de los resultados de b\u00fasqueda. Los hallazgos de nuestro estudio sugieren que las caracter\u00edsticas de los subt\u00edtulos relativamente simples, como la presencia de todos los t\u00e9rminos de consulta, la legibilidad del fragmento y la longitud de la URL que se muestra en el t\u00edtulo, pueden influir significativamente en el comportamiento de b\u00fasqueda web de los usuarios. 1. INTRODUCCI\u00d3N Los principales motores de b\u00fasqueda web comerciales presentan sus resultados de forma muy parecida. Cada resultado de b\u00fasqueda se describe mediante un breve t\u00edtulo, que comprende la URL de la p\u00e1gina web asociada, un t\u00edtulo y un breve resumen -LRB- o ``snippet'' -RRB- que describe el contenido de la p\u00e1gina. A menudo, el fragmento se extrae de la propia p\u00e1gina web, pero tambi\u00e9n se puede tomar de fuentes externas, como los res\u00famenes generados por humanos que se encuentran en los directorios web. La Figura 1 muestra una b\u00fasqueda web t\u00edpica, con subt\u00edtulos para los tres resultados principales. Si bien los tres t\u00edtulos comparten lo mismo, el fragmento del tercer t\u00edtulo es casi el doble de largo que el del primero, mientras que el fragmento falta por completo en el segundo t\u00edtulo. El t\u00edtulo del tercer t\u00edtulo contiene todos los t\u00e9rminos de consulta en orden, mientras que los t\u00edtulos del primer y segundo t\u00edtulo contienen solo dos de los tres t\u00e9rminos. Uno de los t\u00e9rminos de consulta se repite en el primer t\u00edtulo. Todos los t\u00e9rminos de consulta aparecen en la URL del tercer t\u00edtulo, mientras que ninguno aparece en la URL del primer t\u00edtulo. Si bien estas diferencias pueden parecer menores, tambi\u00e9n pueden tener un impacto sustancial en el comportamiento del usuario. Una motivaci\u00f3n principal para proporcionar un t\u00edtulo es ayudar al usuario a determinar la relevancia de la p\u00e1gina asociada sin tener que hacer clic para acceder al resultado. En el caso de una consulta de navegaci\u00f3n, especialmente cuando el destino es bien conocido, la URL por s\u00ed sola puede ser suficiente para identificar la p\u00e1gina deseada. Pero en el caso de una consulta informativa, el t\u00edtulo y el fragmento pueden ser necesarios para guiar al usuario en la selecci\u00f3n de una p\u00e1gina para un estudio m\u00e1s profundo, y puede juzgar la relevancia de una p\u00e1gina bas\u00e1ndose \u00fanicamente en el t\u00edtulo. Cuando este juicio es correcto, puede acelerar el proceso de b\u00fasqueda al permitir al usuario evitar material no deseado. Cuando falla, el usuario puede perder el tiempo haciendo clic en un resultado inapropiado y escaneando una p\u00e1gina que contiene poco o nada de inter\u00e9s. Peor a\u00fan, el usuario puede ser enga\u00f1ado y saltarse una p\u00e1gina que contiene la informaci\u00f3n deseada. Los tres resultados de la figura 1 son relevantes, con algunas limitaciones. El primer resultado enlaza con el sitio principal de Yahoo Kids! p\u00e1gina principal,pero luego es necesario seguir un enlace en un men\u00fa para encontrar la p\u00e1gina principal de los juegos. A pesar de las apariencias, el segundo resultado enlaza con una colecci\u00f3n sorprendentemente grande de juegos en l\u00ednea, principalmente con temas ambientales. Desafortunadamente, estas caracter\u00edsticas de la p\u00e1gina no se reflejan completamente en los t\u00edtulos. En este art\u00edculo, examinamos la influencia de las caracter\u00edsticas de los subt\u00edtulos en el comportamiento de b\u00fasqueda web del usuario, utilizando clics extra\u00eddos de los registros de los motores de b\u00fasqueda como nuestra principal herramienta de investigaci\u00f3n. Comprender esta influencia puede ayudar a validar algoritmos y pautas para la generaci\u00f3n mejorada de Figura 1: Tres resultados principales de la consulta: juegos infantiles en l\u00ednea. los propios subt\u00edtulos. Adem\u00e1s, estas caracter\u00edsticas pueden desempe\u00f1ar un papel en el proceso de inferir juicios de relevancia a partir del comportamiento del usuario -LSB- 1 -RSB-. Al comprender mejor su influencia, pueden resultar mejores juicios. Diferentes algoritmos de generaci\u00f3n de subt\u00edtulos pueden seleccionar fragmentos de diferentes longitudes de diferentes \u00e1reas de una p\u00e1gina. Los fragmentos se pueden generar de forma independiente de la consulta, proporcionando un resumen de la p\u00e1gina en su conjunto, o de forma dependiente de la consulta, proporcionando un resumen de c\u00f3mo la p\u00e1gina se relaciona con los t\u00e9rminos de la consulta. La elecci\u00f3n correcta del fragmento puede depender de aspectos tanto de la consulta como de la p\u00e1gina de resultados. Para los enlaces que redireccionan, es posible mostrar URL alternativas. Adem\u00e1s, para las p\u00e1ginas que figuran en directorios web editados por humanos, como Open Directory Project, es posible mostrar t\u00edtulos alternativos y fragmentos derivados de estos listados. Cuando estos fragmentos, t\u00edtulos y URL alternativos est\u00e9n disponibles, la selecci\u00f3n de una combinaci\u00f3n adecuada para su visualizaci\u00f3n puede guiarse por sus caracter\u00edsticas. Un fragmento de un directorio web puede constar de oraciones completas y ser menos fragmentario que un fragmento extra\u00eddo. Un t\u00edtulo extra\u00eddo del cuerpo puede proporcionar una mayor cobertura de los t\u00e9rminos de la consulta. El trabajo presentado en este art\u00edculo se llev\u00f3 a cabo en el context del motor de b\u00fasqueda de Windows Live. Los experimentos informados en secciones posteriores se basan en registros de consultas de Windows Live, p\u00e1ginas de resultados y juicios de relevancia recopilados como parte de una investigaci\u00f3n en curso sobre el rendimiento del motor de b\u00fasqueda -LSB- 1, 2 -RSB-. No obstante, dada la similitud de los formatos de subt\u00edtulos en los principales motores de b\u00fasqueda web, creemos que los resultados son aplicables a estos otros motores. La consulta en ` www.dmoz.org figura 1 produce resultados con relevancia similar en los otros motores de b\u00fasqueda principales. Esta y otras consultas producen t\u00edtulos que presentan variaciones similares. Adem\u00e1s, creemos que nuestra metodolog\u00eda puede generalizarse a otras aplicaciones de b\u00fasqueda cuando haya suficientes datos de clics disponibles. 2. TRABAJO RELACIONADO Si bien los motores de b\u00fasqueda web comerciales han seguido enfoques similares para la visualizaci\u00f3n de subt\u00edtulos desde su g\u00e9nesis, se ha publicado relativamente poca investigaci\u00f3n sobre m\u00e9todos para generar estos subt\u00edtulos y evaluar su impacto en el comportamiento del usuario.La mayor\u00eda de las investigaciones sobre la visualizaci\u00f3n de resultados web han propuesto cambios sustanciales en la interfaz, en lugar de abordar los detalles de las interfaces existentes. 2.1 Visualizaci\u00f3n de resultados web Varadarajan y Hristidis -LSB- 16 -RSB- se encuentran entre los pocos que han intentado mejorar directamente los fragmentos generados por los sistemas de b\u00fasqueda comerciales, sin introducir cambios adicionales en la interfaz. Generaron fragmentos a partir de \u00e1rboles de gr\u00e1ficos de documentos y compararon experimentalmente estos fragmentos con los fragmentos generados para los mismos documentos por el sistema de b\u00fasqueda de escritorio de Google y el sistema de b\u00fasqueda de escritorio de MSN. Evaluaron su m\u00e9todo pidiendo a los usuarios que compararan fragmentos de diversas fuentes. 6. CONCLUSIONES Las inversiones de clic constituyen una herramienta adecuada para evaluar la influencia de las caracter\u00edsticas de los subt\u00edtulos. Utilizando inversiones de clic, hemos demostrado que las funciones de subt\u00edtulos relativamente simples pueden influir significativamente en el comportamiento del usuario. Hasta donde sabemos, esta es la primera metodolog\u00eda validada para evaluar la calidad de los subt\u00edtulos web a trav\u00e9s de retroalimentaci\u00f3n impl\u00edcita. Tambi\u00e9n esperamos abordar directamente el objetivo de predecir la relevancia a partir de los clics y otra informaci\u00f3n presente en los registros de los motores de b\u00fasqueda.", "keyphrases": ["patr\u00f3n de clics", "caracter\u00edstica de subt\u00edtulos", "comportamiento de b\u00fasqueda web", "Factor humano", "extraer resumen", "retazo", "registro de consultas", "queri reformul", "palabra significativa", "clic inverso", "coincidencia de t\u00e9rminos de consulta"]}
{"file_name": "I-5", "text": "Hacia una asignaci\u00f3n de recursos basada en agentes autoorganizada en un entorno multiservidor RESUMEN Las aplicaciones distribuidas requieren t\u00e9cnicas distribuidas para una asignaci\u00f3n eficiente de recursos. Estas t\u00e9cnicas deben tener en cuenta la heterogeneidad y la posible falta de fiabilidad de los recursos y de los consumidores de recursos en entornos distribuidos. En este art\u00edculo proponemos un algoritmo distribuido que resuelve el problema de asignaci\u00f3n de recursos en sistemas distribuidos multiagente. Nuestra soluci\u00f3n se basa en la autoorganizaci\u00f3n de los agentes, que no requiere ning\u00fan facilitador ni capa de gesti\u00f3n. La asignaci\u00f3n de recursos en el sistema es un efecto puramente emergente. Presentamos los resultados del mecanismo de asignaci\u00f3n de recursos propuesto en el entorno multiservidor est\u00e1tico y din\u00e1mico simulado. 1. INTRODUCCI\u00d3N En este sentido, cada agente es un consumidor de recursos que adquiere una determinada cantidad de recursos para la ejecuci\u00f3n de sus tareas. Es dif\u00edcil para un mecanismo central de asignaci\u00f3n de recursos recopilar y gestionar la informaci\u00f3n sobre todos los recursos compartidos y los consumidores de recursos para realizar de manera efectiva la asignaci\u00f3n de recursos. Por lo tanto, se requieren soluciones distribuidas al problema de asignaci\u00f3n de recursos. Los investigadores han reconocido estos requisitos -LSB- 10 -RSB- y han propuesto t\u00e9cnicas para la asignaci\u00f3n distribuida de recursos. Un tipo prometedor de enfoques distribuidos se basa en modelos de mercado econ\u00f3mico -LSB- 4 -RSB-, inspirados en principios de los mercados de valores reales. Incluso si esos enfoques se distribuyen, generalmente requieren un facilitador para fijar precios, descubrir recursos y enviar trabajos a los recursos -LSB- 5, 9 -RSB-. Otro problema mayormente no resuelto de estos enfoques es el ajuste de las restricciones presupuestarias de precio y tiempo para permitir una asignaci\u00f3n eficiente de recursos en sistemas grandes y din\u00e1micos -LSB- 22 -RSB-. En este art\u00edculo proponemos una soluci\u00f3n distribuida al problema de asignaci\u00f3n de recursos basada en la autoorganizaci\u00f3n de los consumidores de recursos en un sistema con recursos limitados. En nuestro enfoque, los agentes asignan tareas din\u00e1micamente a servidores que proporcionan una cantidad limitada de recursos. En nuestro enfoque, los agentes seleccionan de forma aut\u00f3noma la plataforma de ejecuci\u00f3n para la tarea en lugar de pedirle a un intermediario de recursos que haga la asignaci\u00f3n. Todo el control necesario para nuestro algoritmo se distribuye entre los agentes del sistema. Optimizan el proceso de asignaci\u00f3n de recursos continuamente a lo largo de su vida ante cambios en la disponibilidad de recursos compartidos aprendiendo de decisiones de asignaci\u00f3n pasadas. La \u00fanica informaci\u00f3n disponible para todos los agentes es la carga de recursos y la informaci\u00f3n de \u00e9xito de la asignaci\u00f3n de asignaciones de recursos anteriores. No se difunde informaci\u00f3n adicional sobre la carga de recursos sobre los servidores. El mecanismo propuesto no requiere una autoridad de control central, una capa de gesti\u00f3n de recursos ni introducir comunicaci\u00f3n adicional entre agentes para decidir qu\u00e9 tarea se asigna en qu\u00e9 servidor.Demostramos que este mecanismo funciona bien en sistemas din\u00e1micos con una gran cantidad de tareas y se puede adaptar f\u00e1cilmente a varios tama\u00f1os de sistemas. Adem\u00e1s, el rendimiento general del sistema no se ve afectado en caso de que los agentes o servidores fallen o dejen de estar disponibles. El enfoque propuesto proporciona una manera f\u00e1cil de implementar la asignaci\u00f3n distribuida de recursos y tiene en cuenta las tendencias de los sistemas multiagente hacia la autonom\u00eda, la heterogeneidad y la falta de confiabilidad de los recursos y agentes. Esta t\u00e9cnica propuesta puede complementarse f\u00e1cilmente con t\u00e9cnicas para poner en cola o rechazar solicitudes de asignaci\u00f3n de recursos de los agentes -LSB-11-RSB-. Estas capacidades de autogesti\u00f3n de los agentes de software permiten una asignaci\u00f3n confiable de recursos incluso en un entorno con proveedores de recursos poco confiables. Esto se puede lograr mediante las interacciones mutuas entre agentes aplicando t\u00e9cnicas de la teor\u00eda de sistemas complejos. La autoorganizaci\u00f3n de todos los agentes conduce a una autoorganizaci\u00f3n de los 2. TRABAJOS RELACIONADOS La asignaci\u00f3n de recursos es un problema importante en el \u00e1rea de la inform\u00e1tica. En t\u00e9rminos generales, la asignaci\u00f3n de recursos es un mecanismo o pol\u00edtica para la gesti\u00f3n eficiente y efectiva del acceso a un recurso o conjunto de recursos limitado por parte de sus consumidores. En el caso m\u00e1s simple, los consumidores de recursos solicitan a un intermediario o despachador central los recursos disponibles donde se asignar\u00e1 el consumidor de recursos. El corredor suele tener pleno conocimiento de todos los recursos del sistema. En esos enfoques, el consumidor de recursos no puede influir en el proceso de decisi\u00f3n de asignaci\u00f3n. El equilibrio de carga -LSB- 3 -RSB- es un caso especial del problema de asignaci\u00f3n de recursos que utiliza un intermediario que intenta ser justo con todos los recursos equilibrando la carga del sistema por igual entre todos los proveedores de recursos. Este mecanismo funciona mejor en un sistema homog\u00e9neo. Una t\u00e9cnica distribuida simple para la gesti\u00f3n de recursos es la planificaci\u00f3n de la capacidad rechazando o poniendo en cola a los agentes entrantes para evitar la sobrecarga de recursos -LSB- 11 -RSB-. Desde la perspectiva del propietario del recurso, esta t\u00e9cnica es importante para evitar la sobrecarga del recurso, pero no es suficiente para una asignaci\u00f3n eficaz de los recursos. Esta t\u00e9cnica s\u00f3lo puede proporcionar un buen complemento para los mecanismos de asignaci\u00f3n de recursos distribuidos. Estos coordinadores normalmente necesitan tener conocimiento global sobre el estado de todos los recursos del sistema. Un ejemplo de algoritmo de asignaci\u00f3n din\u00e1mica de recursos es el proyecto Cactus -LSB- 1 -RSB- para la asignaci\u00f3n de trabajos computacionales muy costosos. El valor de las soluciones distribuidas para el problema de asignaci\u00f3n de recursos ha sido reconocido por la investigaci\u00f3n -LSB-10-RSB-. Inspir\u00e1ndose en los principios de los mercados de valores, se han desarrollado modelos de mercado econ\u00f3mico para negociar recursos para regular la oferta y la demanda en la red. Los usuarios intentan comprar los recursos baratos necesarios para ejecutar el trabajo, mientras que los proveedores intentan obtener la mayor cantidad de ganancias posible y operar los recursos disponibles a plena capacidad.En Clearwater -LSB- 10 -RSB- se presenta una colecci\u00f3n de diferentes t\u00e9cnicas de asignaci\u00f3n de recursos distribuidos basadas en modelos de mercado. Buyya et al. desarroll\u00f3 un marco de asignaci\u00f3n de recursos basado en la regulaci\u00f3n de la oferta y la demanda -LSB- 4 -RSB- para Nimrod-G -LSB- 6 -RSB- con el enfoque principal en los plazos de trabajo y las restricciones presupuestarias. El modelo de asignaci\u00f3n de recursos basado en agentes -LRB- ARAM -RRB- para grids est\u00e1 dise\u00f1ado para programar trabajos computacionales costosos utilizando agentes. El inconveniente de este modelo es el uso extensivo del intercambio de mensajes entre agentes para el monitoreo peri\u00f3dico y el intercambio de informaci\u00f3n dentro de la estructura jer\u00e1rquica. Las subtareas de un trabajo migran a trav\u00e9s de la red hasta encontrar un recurso que cumpla con las restricciones de precio. El itinerario de migraci\u00f3n de los trabajos est\u00e1 determinado por los recursos para conectarlos en diferentes topolog\u00edas -LSB- 17 -RSB-. El mecanismo propuesto en este documento elimina la necesidad de intercambio peri\u00f3dico de informaci\u00f3n sobre cargas de recursos y no necesita una topolog\u00eda de conexi\u00f3n entre los recursos. En los \u00faltimos a\u00f1os se ha publicado un trabajo considerable sobre t\u00e9cnicas de asignaci\u00f3n descentralizada de recursos utilizando la teor\u00eda de juegos. Es un problema de decisi\u00f3n mal definido que supone y modela el razonamiento inductivo. En este juego de decisiones repetitivas, un n\u00famero impar de agentes tiene que elegir entre dos recursos bas\u00e1ndose en informaci\u00f3n de \u00e9xitos pasados, tratando de ubicarse en el recurso con la minor\u00eda. Galstyan et al. -LSB- 14 -RSB- estudi\u00f3 una variaci\u00f3n con m\u00e1s de dos recursos, cambiando las capacidades de recursos y la informaci\u00f3n de los agentes vecinos. Demostraron que los agentes pueden adaptarse eficazmente a las capacidades cambiantes en este entorno utilizando un conjunto de tablas de b\u00fasqueda simples -LRB- estrategias -RRB- por agente. Otra t\u00e9cnica distribuida que se emplea para resolver el problema de asignaci\u00f3n de recursos se basa en el aprendizaje por refuerzo -LSB- 18 -RSB-. De manera similar a nuestro enfoque, un conjunto de agentes compite por una cantidad limitada de recursos bas\u00e1ndose \u00fanicamente en la experiencia individual previa. En este documento, el objetivo del sistema es maximizar el rendimiento del sistema y al mismo tiempo garantizar la equidad con los recursos, medido como el tiempo promedio de procesamiento por unidad de trabajo. En -LSB-16-RSB- se presenta un enfoque de asignaci\u00f3n de recursos para redes de sensores basado en t\u00e9cnicas de autoorganizaci\u00f3n y aprendizaje por refuerzo, centr\u00e1ndose principalmente en la optimizaci\u00f3n del consumo de energ\u00eda de los nodos de la red. Nosotros, LSB-19-RSB, propusimos un enfoque de equilibrio de carga autoorganizado para un \u00fanico servidor centrado en optimizar los costos de comunicaci\u00f3n de los agentes m\u00f3viles. Un agente m\u00f3vil rechazar\u00e1 una migraci\u00f3n a un servidor de agente remoto si espera que el servidor de destino ya est\u00e9 sobrecargado por otros agentes o tareas del servidor. Los propios agentes toman sus decisiones bas\u00e1ndose en previsiones de utilizaci\u00f3n del servidor. En este art\u00edculo se presenta una soluci\u00f3n para un entorno multiservidor sin considerar los costos de comunicaci\u00f3n o migraci\u00f3n. 6.CONCLUSIONES Y TRABAJO FUTURO En este art\u00edculo se present\u00f3 una t\u00e9cnica de asignaci\u00f3n de recursos distribuida autoorganizada para sistemas multiagente. Permitimos que los agentes seleccionen ellos mismos la plataforma de ejecuci\u00f3n para sus tareas antes de cada ejecuci\u00f3n en tiempo de ejecuci\u00f3n. En nuestro enfoque, los agentes compiten por una asignaci\u00f3n en una de las Figura 5: Los resultados del experimento 2 en un entorno de servidor din\u00e1mico promediaron m\u00e1s de 100 repeticiones. recurso compartido disponible. Los agentes perciben el entorno de su servidor y adoptan sus acciones para competir de manera m\u00e1s eficiente en el nuevo entorno creado. Este proceso es adaptativo y tiene una fuerte retroalimentaci\u00f3n ya que las decisiones de asignaci\u00f3n influyen indirectamente en las decisiones de otros agentes. La asignaci\u00f3n de recursos es un efecto puramente emergente. Nuestro mecanismo demuestra que la asignaci\u00f3n de recursos puede realizarse mediante la competencia efectiva de agentes individuales y aut\u00f3nomos. Tampoco necesitan coordinaci\u00f3n ni informaci\u00f3n de una autoridad superior ni se requiere una comunicaci\u00f3n directa adicional entre agentes. Este mecanismo se inspir\u00f3 en el razonamiento inductivo y los principios de racionalidad limitada que permite a los agentes adaptar sus estrategias para competir eficazmente en un entorno din\u00e1mico. En el caso de que un servidor no est\u00e9 disponible, los agentes pueden adaptarse r\u00e1pidamente a esta nueva situaci\u00f3n explorando nuevos recursos o permanecer en el servidor local si no es posible una asignaci\u00f3n. Especialmente en entornos din\u00e1micos y escalables, como los sistemas grid, se requiere un mecanismo robusto y distribuido para la asignaci\u00f3n de recursos. Nuestro enfoque de asignaci\u00f3n de recursos autoorganizado se evalu\u00f3 con una serie de experimentos de simulaci\u00f3n en un entorno din\u00e1mico de agentes y recursos del servidor. Los resultados presentados para este nuevo enfoque para la optimizaci\u00f3n de la migraci\u00f3n estrat\u00e9gica son muy prometedores y justifican una mayor investigaci\u00f3n en un entorno real de sistema multiagente. Es una pol\u00edtica distribuida, escalable y f\u00e1cil de entender para la regulaci\u00f3n de la oferta y la demanda de recursos. Todo el control se implementa en los agentes. Un mecanismo de decisi\u00f3n simple basado en diferentes creencias del agente crea un comportamiento emergente que conduce a una asignaci\u00f3n efectiva de recursos. Este enfoque puede ampliarse o respaldarse f\u00e1cilmente mediante mecanismos de equilibrio/cola de recursos proporcionados por los recursos. Nuestro enfoque se adapta a los cambios del entorno pero no es evolutivo. No hay descubrimiento de nuevas estrategias por parte de los agentes. investigado en el futuro. En un futuro pr\u00f3ximo, investigaremos si es posible una adaptaci\u00f3n autom\u00e1tica de la tasa de decadencia de la informaci\u00f3n hist\u00f3rica de nuestro algoritmo y si puede mejorar el rendimiento de la asignaci\u00f3n de recursos. Una gran cantidad de recursos compartidos requiere informaci\u00f3n hist\u00f3rica m\u00e1s antigua para evitar una exploraci\u00f3n de recursos con demasiada frecuencia. Por el contrario, un entorno din\u00e1mico con capacidades variables requiere informaci\u00f3n m\u00e1s actualizada para hacer predicciones m\u00e1s confiables.Somos conscientes de la larga fase de aprendizaje en entornos con una gran cantidad de recursos compartidos conocidos por cada agente. En el caso de que los agentes soliciten m\u00e1s recursos que los recursos compartidos proporcionados por todos los servidores, todos los agentes explorar\u00e1n aleatoriamente todos los servidores conocidos. Este proceso de adquirir informaci\u00f3n de carga de recursos sobre todos los servidores puede llevar mucho tiempo en caso de que no se proporcionen suficientes recursos compartidos para todas las tareas. En esta situaci\u00f3n, es dif\u00edcil para un agente recopilar de manera eficiente informaci\u00f3n hist\u00f3rica sobre todos los servidores remotos. Este tema necesita m\u00e1s investigaci\u00f3n en el futuro.", "keyphrases": ["sistema multiagente", "agente", "asignaci\u00f3n de recursos", "algoritmo de distribuci\u00f3n", "tarea de asignaci\u00f3n din\u00e1mica", "red de servidor", "utilidades del servidor", "proceso de adaptaci\u00f3n", "competir", "vaticinador"]}
{"file_name": "J-14", "text": "Calcular buenos equilibrios de Nash en juegos gr\u00e1ficos * RESUMEN Este art\u00edculo aborda el problema de la selecci\u00f3n justa de equilibrios en juegos gr\u00e1ficos. Nuestro enfoque se basa en la estructura de datos denominada pol\u00edtica de mejor respuesta, propuesta por Kearns et al. -LSB- 13 -RSB- como forma de representar todos los equilibrios de Nash de un juego gr\u00e1fico. En -LSB-9-RSB-, se demostr\u00f3 que la pol\u00edtica de mejor respuesta tiene tama\u00f1o polin\u00f3mico siempre que el gr\u00e1fico subyacente sea una ruta. En este art\u00edculo, mostramos que si el gr\u00e1fico subyacente es un \u00e1rbol de grados acotados y la pol\u00edtica de mejor respuesta tiene tama\u00f1o polin\u00f3mico, entonces existe un algoritmo eficiente que construye un equilibrio de Nash que garantiza ciertos pagos a todos los participantes. Otro concepto de soluci\u00f3n atractivo es un equilibrio de Nash que maximiza el bienestar social. Mostramos que, si bien calcular exactamente este \u00faltimo es inviable -LRB-, demostramos que resolver este problema puede involucrar n\u00fameros algebraicos de un grado arbitrariamente alto -RRB-, existe un FPTAS para encontrar dicho equilibrio siempre que se haya implementado la mejor pol\u00edtica de respuesta. Tama\u00f1o del polinomio. Estos dos algoritmos se pueden combinar para producir equilibrios de Nash que satisfacen varios criterios de equidad. 1. INTRODUCCI\u00d3N Esta es la intuici\u00f3n detr\u00e1s de los juegos gr\u00e1ficos, que fueron introducidas por Kearns, Littman y Singh en -LSB- 13 -RSB- como un esquema de representaci\u00f3n compacto para juegos con muchos jugadores. En un juego gr\u00e1fico de n jugadores, cada jugador est\u00e1 asociado con un v\u00e9rtice de un gr\u00e1fico subyacente G, y los pagos de cada jugador dependen de su acci\u00f3n as\u00ed como de las acciones de sus vecinos en el gr\u00e1fico. Si el grado m\u00e1ximo de G es \u0394, y cada jugador tiene dos acciones disponibles, entonces el juego se puede representar usando n2\u0394 +1 n\u00fameros. Por el contrario, necesitamos n2n n\u00fameros para representar un juego general de n jugadores y 2 acciones, lo cual s\u00f3lo es pr\u00e1ctico para valores peque\u00f1os de n. Para juegos gr\u00e1ficos con \u0394 constante, el tama\u00f1o del juego es lineal en n. Uno de los problemas m\u00e1s naturales de un juego gr\u00e1fico es el de encontrar un equilibrio de Nash, cuya existencia se deriva del c\u00e9lebre teorema de Nash -LRB-, ya que los juegos gr\u00e1ficos son s\u00f3lo un caso especial de juegos de n jugadores -RRB-. El primer intento de abordar este problema se realiz\u00f3 en -LSB-13-RSB-, donde los autores consideran juegos gr\u00e1ficos con dos acciones por jugador en los que el gr\u00e1fico subyacente es un \u00e1rbol de grados acotados. Proponen un algoritmo gen\u00e9rico para encontrar equilibrios de Nash que puede especializarse de dos maneras: un algoritmo de tiempo exponencial para encontrar un equilibrio de Nash -LRB- exacto -RRB-, y un esquema de aproximaci\u00f3n de tiempo totalmente polinomial -LRB- FPTAS -RRB- para encontrar una aproximaci\u00f3n al equilibrio de Nash. Para cualquier e > 0, este algoritmo genera un equilibrio e-Nash, que es un perfil de estrategia en el que ning\u00fan jugador puede mejorar su pago en m\u00e1s de e cambiando unilateralmente su estrategia. Si bien los equilibrios de e-Nash suelen ser m\u00e1s f\u00e1ciles de calcular que los equilibrios de Nash exactos, este concepto de soluci\u00f3n tiene varios inconvenientes. Primero,Los jugadores pueden ser sensibles a una peque\u00f1a p\u00e9rdida en los pagos, por lo que el perfil de estrategia que es un equilibrio e-Nash no ser\u00e1 estable. En segundo lugar, los perfiles de estrategia que est\u00e1n cerca de ser equilibrios de Nash pueden ser mucho mejores con respecto a las propiedades bajo consideraci\u00f3n que los equilibrios de Nash exactos. Por lo tanto, la aproximaci\u00f3n -LRB- al valor -RRB- de la mejor soluci\u00f3n que corresponde a un equilibrio de e-Nash puede no ser indicativa de lo que se puede lograr bajo un equilibrio de Nash exacto. Esto es especialmente importante si el prop\u00f3sito de la soluci\u00f3n aproximada es proporcionar un buen punto de referencia para un sistema de agentes ego\u00edstas, ya que el punto de referencia impl\u00edcito en un equilibrio e-Nash puede ser poco realista. Por estas razones, en este art\u00edculo nos centramos en el problema de calcular los equilibrios exactos de Nash. Bas\u00e1ndose en las ideas de -LSB- 14 -RSB-, Elkind et al. -LSB- 9 -RSB- mostr\u00f3 c\u00f3mo encontrar un -LRB- exacto -RRB- equilibrio de Nash en tiempo polinomial cuando el equilibrio de Nash subyacente. Por el contrario, encontrar un equilibrio de Nash en un gr\u00e1fico general acotado en grados parece ser computacionalmente intratable: ha sido mostrado -LRB- ver -LSB- 5, 12, 7 -RSB- -RRB- para estar completo para la clase de complejidad PPAD. -LSB- 9 -RSB- extiende este resultado de dureza al caso en el que el gr\u00e1fico subyacente tiene un ancho de ruta limitado. Un juego gr\u00e1fico puede no tener un equilibrio de Nash \u00fanico; de hecho, puede tener muchos equilibrios exponenciales. Adem\u00e1s, algunos equilibrios de Nash son m\u00e1s deseables que otros. En lugar de tener un algoritmo que simplemente encuentre alg\u00fan equilibrio de Nash, nos gustar\u00eda tener algoritmos para encontrar equilibrios de Nash con varias propiedades socialmente deseables, como maximizar la rentabilidad general o distribuir las ganancias de manera justa. Una propiedad \u00fatil de la estructura de datos de -LSB- 13 -RSB- es que representa simult\u00e1neamente el conjunto de todos los equilibrios de Nash del juego subyacente. Si esta representaci\u00f3n tiene tama\u00f1o polin\u00f3mico -LRB- como es el caso de los caminos, como se muestra en -LSB- 9 -RSB- -RRB-, se puede esperar extraer de ella un equilibrio de Nash con las propiedades deseadas. De hecho, en -LSB- 13 -RSB- los autores mencionan que esto s\u00ed es posible si uno est\u00e1 interesado en encontrar un equilibrio -LRB- aproximado -RRB- a-Nash. El objetivo de este art\u00edculo es extender esto a los equilibrios exactos de Nash. 1.1 Nuestros resultados En este art\u00edculo, estudiamos juegos gr\u00e1ficos de 2 acciones para n jugadores en \u00e1rboles de grados acotados para los cuales la estructura de datos de -LSB- 13 -RSB- tiene un tama\u00f1o poli -LRB- n -RRB-. Nos centramos en el problema de encontrar equilibrios de Nash exactos con ciertas propiedades socialmente deseables. En particular, mostramos c\u00f3mo encontrar un equilibrio de Nash que -LRB- casi -RRB- maximice el bienestar social, es decir, la suma de los pagos de los jugadores, y mostramos c\u00f3mo encontrar un equilibrio de Nash que -LRB- casi -RRB - Satisface los l\u00edmites de pago prescritos para todos los jugadores. Los juegos gr\u00e1ficos sobre \u00e1rboles de grados acotados tienen una estructura algebraica simple. Una caracter\u00edstica atractiva, que se desprende de -LSB- 13 -RSB-,es que cada juego de este tipo tiene un equilibrio de Nash en el que la estrategia de cada jugador es un n\u00famero racional. La secci\u00f3n 3 estudia la estructura algebraica de aquellos equilibrios de Nash que maximizan el bienestar social. Mostramos -LRB- Teoremas 1 y 2 -RRB- que, sorprendentemente, el conjunto de equilibrios de Nash que maximizan el bienestar social es m\u00e1s complejo. Parece ser una caracter\u00edstica novedosa del escenario que consideramos aqu\u00ed, que un equilibrio de Nash \u00f3ptimo es dif\u00edcil de representar, en una situaci\u00f3n en la que es f\u00e1cil encontrar y representar un equilibrio de Nash. Como el equilibrio de Nash que maximiza el bienestar social puede ser dif\u00edcil de representar eficientemente, tenemos que conformarnos con una aproximaci\u00f3n. Sin embargo, la diferencia crucial entre nuestro enfoque y el de art\u00edculos anteriores -LSB- 13, 16, 19 -RSB- es que requerimos que nuestro algoritmo genere un equilibrio de Nash exacto, aunque no necesariamente el \u00f3ptimo con respecto a nuestros criterios. En la Secci\u00f3n 4, describimos un algoritmo que satisface este requisito. Es decir, proponemos un algoritmo que para cualquier e > 0 encuentra un equilibrio de Nash cuyo pago total est\u00e1 dentro del \u00f3ptimo. Datta -LSB- 8 -RSB- obtuvo un resultado m\u00e1s relacionado con pre1A en un context diferente, quien muestra que los juegos de n jugadores y 2 acciones son universales en el sentido de que cualquier variedad algebraica real puede representarse como el conjunto de Nash totalmente mixto. equilibrios de tales juegos. Mostramos -LRB- Secci\u00f3n 4.1 -RRB- que bajo algunas restricciones en las matrices de pagos, el algoritmo se puede transformar en un algoritmo de tiempo polinomial -LRB- verdaderamente -RRB- que genera un equilibrio de Nash cuyo pago total est\u00e1 dentro de un 1 \u2212 e factor del \u00f3ptimo. En la secci\u00f3n 5, consideramos el problema de encontrar un equilibrio de Nash en el que el pago esperado de cada jugador Vi exceda un umbral prescrito Ti. Usando la idea de la Secci\u00f3n 4 damos -LRB- Teorema 5 -RRB- un esquema de aproximaci\u00f3n temporal totalmente polinomial para este problema. El tiempo de ejecuci\u00f3n del algoritmo est\u00e1 limitado por un polinomio en n, Pmax y E. Si la instancia tiene un equilibrio de Nash que satisface los umbrales prescritos, entonces el algoritmo construye un equilibrio de Nash en el que el pago esperado de cada jugador Vi es al menos Ti. \u2212 E. En la Secci\u00f3n 6, introducimos otros criterios naturales para seleccionar un equilibrio de Nash \"bueno\" y mostramos que los algoritmos descritos en las dos secciones anteriores pueden usarse como bloques de construcci\u00f3n para encontrar equilibrios de Nash que satisfagan estos criterios. En particular, en la secci\u00f3n 6.1 mostramos c\u00f3mo encontrar un equilibrio de Nash que se aproxime al bienestar social m\u00e1ximo, garantizando al mismo tiempo que cada pago individual est\u00e9 cerca de un umbral prescrito. En la secci\u00f3n 6.2 mostramos c\u00f3mo encontrar un equilibrio de Nash que -LRB- casi -RRB- maximice el pago individual m\u00ednimo. Finalmente, en la secci\u00f3n 6.3 mostramos c\u00f3mo encontrar un equilibrio de Nash en el que los pagos individuales de los jugadores sean cercanos entre s\u00ed. 1.2 Trabajo relacionado Nuestro esquema de aproximaci\u00f3n -LRB- Teorema 3 y Teorema 4 -RRB- muestra un contraste entre los juegos que estudiamos y los juegos de n-acci\u00f3n para dos jugadores, para los cuales los problemas correspondientes suelen ser intratables. Para juegos de n acciones de dos jugadores, el problema de encontrar equilibrios de Nash con propiedades especiales suele ser NP-dif\u00edcil. En particular, este es el caso de los equilibrios de Nash que maximizan el bienestar social -LSB- 11, 6 -RSB-. Adem\u00e1s, es probable que sea dif\u00edcil incluso aproximarse a tales equilibrios. En particular, Chen, Deng y Teng -LSB- 4 -RSB- muestran que existe alg\u00fan e, polinomio inverso en n, para el cual calcular un equilibrio e-Nash en juegos de 2 jugadores con n acciones por jugador es PPAD-completo. Lipton y Markakis -LSB- 15 -RSB- estudian las propiedades algebraicas de los equilibrios de Nash y se\u00f1alan que se pueden utilizar algoritmos est\u00e1ndar de eliminaci\u00f3n de cuantificadores para resolverlos. Tenga en cuenta que estos algoritmos no son de tiempo polinomial en general. Los juegos que estudiamos en este art\u00edculo tienen equilibrios de Nash computables en tiempo polinomial en los que todas las estrategias mixtas son n\u00fameros racionales, pero un equilibrio de Nash \u00f3ptimo puede necesariamente incluir estrategias mixtas con un alto grado algebraico. Cualquier equilibrio de Nash es un CE, pero lo contrario no se cumple en general. A diferencia de los equilibrios de Nash, se pueden encontrar equilibrios correlacionados para juegos gr\u00e1ficos de bajo grado -LRB- as\u00ed como para otras clases de juegos multijugador representados de forma concisa -RRB- en tiempo polin\u00f3mico -LSB- 17 -RSB-. Pero, para los juegos gr\u00e1ficos es NP-dif\u00edcil encontrar un equilibrio correlacionado que maximice el pago total -LSB- 18 -RSB-. Sin embargo, los resultados de dureza NP se aplican a juegos m\u00e1s generales que el que consideramos aqu\u00ed; en particular, los gr\u00e1ficos no son \u00e1rboles. A partir de -LSB- 2 -RSB- tambi\u00e9n se sabe que existen juegos de 2 jugadores y 2 acciones para los cuales el pago total esperado del mejor equilibrio correlacionado es mayor que el mejor equilibrio de Nash, y analizamos este tema con m\u00e1s detalle en la Secci\u00f3n 7. 7. CONCLUSIONES Hemos estudiado el problema de la selecci\u00f3n del equilibrio en juegos gr\u00e1ficos sobre \u00e1rboles de grados acotados. Consideramos varios criterios para seleccionar un equilibrio de Nash, como maximizar el bienestar social, asegurar un l\u00edmite inferior en el pago esperado de cada jugador, etc. Primero, nos concentramos en la complejidad algebraica de un equilibrio de Nash que maximiza el bienestar social, y demostr\u00f3 fuertes resultados negativos para ese problema. Es decir, demostramos que incluso para juegos gr\u00e1ficos sobre trayectorias, cualquier n\u00famero algebraico \u03b1 E -LSB- 0, 1 -RSB- puede ser la \u00fanica estrategia disponible para alg\u00fan jugador en todos los equilibrios de Nash que maximizan el bienestar social. Esto contrasta marcadamente con el hecho de que los juegos gr\u00e1ficos sobre \u00e1rboles siempre poseen un equilibrio de Nash en el que las estrategias de todos los jugadores son n\u00fameros racionales. Luego proporcionamos algoritmos de aproximaci\u00f3n para seleccionar equilibrios de Nash con propiedades especiales. Si bien el problema de encontrar equilibrios de Nash aproximados para varias clases de juegos ha recibido mucha atenci\u00f3n en los \u00faltimos a\u00f1os,la mayor parte del trabajo existente tiene como objetivo encontrar equilibrios E-Nash que satisfagan -LRB- o que est\u00e9n E-cerca de satisfacer -RRB- ciertas propiedades. Nuestro enfoque es diferente en el sentido de que insistimos en generar un equilibrio de Nash exacto, que est\u00e9 E-cerca de satisfacer un requisito dado. Como se argument\u00f3 en la introducci\u00f3n, hay varias razones para preferir una soluci\u00f3n que constituya un equilibrio de Nash exacto. Si bien probamos nuestros resultados para juegos en un camino, se pueden generalizar a cualquier \u00e1rbol para el cual las pol\u00edticas de mejor respuesta tengan representaciones compactas como uniones de rect\u00e1ngulos. En la versi\u00f3n completa del art\u00edculo describimos nuestros algoritmos para el caso general. Un trabajo adicional en este sentido podr\u00eda incluir extensiones a los tipos de garant\u00edas buscadas para los equilibrios de Nash, como garantizar pagos totales para subconjuntos de jugadores, seleccionar equilibrios en los que algunos jugadores reciban pagos significativamente m\u00e1s altos que sus pares, etc. Sin embargo, por el momento , quiz\u00e1s sea m\u00e1s importante investigar si los equilibrios de Nash de los juegos gr\u00e1ficos pueden calcularse de manera descentralizada, en contraste con los algoritmos que hemos introducido aqu\u00ed. Es natural preguntarse si nuestros resultados o los de -LSB- 9 -RSB- pueden generalizarse a juegos de tres o m\u00e1s acciones. Sin embargo, parece que esto dificultar\u00e1 significativamente el an\u00e1lisis. En particular, cabe se\u00f1alar que se pueden ver los juegos con pagos acotados como un caso especial muy limitado de juegos con tres acciones por jugador. Es decir, dado un juego de dos acciones con l\u00edmites de pagos, considere un juego en el que cada jugador Vi tiene una tercera acci\u00f3n que le garantiza un pago de Ti sin importar lo que hagan los dem\u00e1s. Entonces, comprobar si existe un equilibrio de Nash en el que ninguno de los jugadores asigna una probabilidad distinta de cero a su tercera acci\u00f3n es equivalente a comprobar si existe un equilibrio de Nash que satisfaga los l\u00edmites de pago en el juego original, y la secci\u00f3n 5.1 muestra que encontrar un equilibrio de Nash exacto La soluci\u00f3n a este problema requiere nuevas ideas. Alternativamente, puede ser interesante buscar resultados similares en el context de equilibrios correlacionados -LRB- CE -RRB-, especialmente porque el mejor CE puede tener un valor mayor -LRB- de pago total esperado -RRB- que el mejor NE. Se sabe por -LSB- 1 -RSB- que el valor de mediaci\u00f3n de los juegos de 2 jugadores, 2 acciones con pagos no negativos es como m\u00e1ximo 43, y exhiben un juego de 3 jugadores para el cual es infinito.En la versi\u00f3n completa del art\u00edculo describimos nuestros algoritmos para el caso general. Un trabajo adicional en este sentido podr\u00eda incluir extensiones a los tipos de garant\u00edas buscadas para los equilibrios de Nash, como garantizar pagos totales para subconjuntos de jugadores, seleccionar equilibrios en los que algunos jugadores reciban pagos significativamente m\u00e1s altos que sus pares, etc. Sin embargo, por el momento , quiz\u00e1s sea m\u00e1s importante investigar si los equilibrios de Nash de los juegos gr\u00e1ficos pueden calcularse de manera descentralizada, en contraste con los algoritmos que hemos introducido aqu\u00ed. Es natural preguntarse si nuestros resultados o los de -LSB- 9 -RSB- pueden generalizarse a juegos de tres o m\u00e1s acciones. Sin embargo, parece que esto dificultar\u00e1 significativamente el an\u00e1lisis. En particular, cabe se\u00f1alar que se pueden ver los juegos con pagos acotados como un caso especial muy limitado de juegos con tres acciones por jugador. Es decir, dado un juego de dos acciones con l\u00edmites de pagos, considere un juego en el que cada jugador Vi tiene una tercera acci\u00f3n que le garantiza un pago de Ti sin importar lo que hagan los dem\u00e1s. Entonces, comprobar si existe un equilibrio de Nash en el que ninguno de los jugadores asigna una probabilidad distinta de cero a su tercera acci\u00f3n es equivalente a comprobar si existe un equilibrio de Nash que satisfaga los l\u00edmites de pago en el juego original, y la secci\u00f3n 5.1 muestra que encontrar un equilibrio de Nash exacto La soluci\u00f3n a este problema requiere nuevas ideas. Alternativamente, puede ser interesante buscar resultados similares en el context de equilibrios correlacionados -LRB- CE -RRB-, especialmente porque el mejor CE puede tener un valor mayor -LRB- de pago total esperado -RRB- que el mejor NE. Se sabe por -LSB- 1 -RSB- que el valor de mediaci\u00f3n de los juegos de 2 jugadores, 2 acciones con pagos no negativos es como m\u00e1ximo 43, y exhiben un juego de 3 jugadores para el cual es infinito.En la versi\u00f3n completa del art\u00edculo describimos nuestros algoritmos para el caso general. Un trabajo adicional en este sentido podr\u00eda incluir extensiones a los tipos de garant\u00edas buscadas para los equilibrios de Nash, como garantizar pagos totales para subconjuntos de jugadores, seleccionar equilibrios en los que algunos jugadores reciban pagos significativamente m\u00e1s altos que sus pares, etc. Sin embargo, por el momento , quiz\u00e1s sea m\u00e1s importante investigar si los equilibrios de Nash de los juegos gr\u00e1ficos pueden calcularse de manera descentralizada, en contraste con los algoritmos que hemos introducido aqu\u00ed. Es natural preguntarse si nuestros resultados o los de -LSB- 9 -RSB- pueden generalizarse a juegos de tres o m\u00e1s acciones. Sin embargo, parece que esto dificultar\u00e1 significativamente el an\u00e1lisis. En particular, cabe se\u00f1alar que se pueden ver los juegos con pagos acotados como un caso especial muy limitado de juegos con tres acciones por jugador. Es decir, dado un juego de dos acciones con l\u00edmites de pagos, considere un juego en el que cada jugador Vi tiene una tercera acci\u00f3n que le garantiza un pago de Ti sin importar lo que hagan los dem\u00e1s. Entonces, comprobar si existe un equilibrio de Nash en el que ninguno de los jugadores asigna una probabilidad distinta de cero a su tercera acci\u00f3n es equivalente a comprobar si existe un equilibrio de Nash que satisfaga los l\u00edmites de pago en el juego original, y la secci\u00f3n 5.1 muestra que encontrar un equilibrio de Nash exacto La soluci\u00f3n a este problema requiere nuevas ideas. Alternativamente, puede ser interesante buscar resultados similares en el context de equilibrios correlacionados -LRB- CE -RRB-, especialmente porque el mejor CE puede tener un valor mayor -LRB- de pago total esperado -RRB- que el mejor NE. Se sabe por -LSB- 1 -RSB- que el valor de mediaci\u00f3n de los juegos de 2 jugadores, 2 acciones con pagos no negativos es como m\u00e1ximo 43, y exhiben un juego de 3 jugadores para el cual es infinito.Entonces, comprobar si existe un equilibrio de Nash en el que ninguno de los jugadores asigna una probabilidad distinta de cero a su tercera acci\u00f3n es equivalente a comprobar si existe un equilibrio de Nash que satisfaga los l\u00edmites de pago en el juego original, y la secci\u00f3n 5.1 muestra que encontrar un equilibrio de Nash exacto La soluci\u00f3n a este problema requiere nuevas ideas. Alternativamente, puede ser interesante buscar resultados similares en el context de equilibrios correlacionados -LRB- CE -RRB-, especialmente porque el mejor CE puede tener un valor mayor -LRB- de pago total esperado -RRB- que el mejor NE. Se sabe por -LSB- 1 -RSB- que el valor de mediaci\u00f3n de los juegos de 2 jugadores, 2 acciones con pagos no negativos es como m\u00e1ximo 43, y exhiben un juego de 3 jugadores para el cual es infinito.Entonces, comprobar si existe un equilibrio de Nash en el que ninguno de los jugadores asigna una probabilidad distinta de cero a su tercera acci\u00f3n es equivalente a comprobar si existe un equilibrio de Nash que satisfaga los l\u00edmites de pago en el juego original, y la secci\u00f3n 5.1 muestra que encontrar un equilibrio de Nash exacto La soluci\u00f3n a este problema requiere nuevas ideas. Alternativamente, puede ser interesante buscar resultados similares en el context de equilibrios correlacionados -LRB- CE -RRB-, especialmente porque el mejor CE puede tener un valor mayor -LRB- de pago total esperado -RRB- que el mejor NE. Se sabe por -LSB- 1 -RSB- que el valor de mediaci\u00f3n de los juegos de 2 jugadores, 2 acciones con pagos no negativos es como m\u00e1ximo 43, y exhiben un juego de 3 jugadores para el cual es infinito.", "keyphrases": ["juego grafico", "equilibrio de Nash", "esquema aproximado", "algoritmo de tiempo exponencial", "aproximado", "varias propiedades socialmente deseadas", "recompensa general", "distribuir ganancias", "bienestar social", "juego gr\u00e1fico de pago integral g", "cortar el inconveniente", "perfil estrat\u00e9gico", "gr\u00e1fico de grados"]}
{"file_name": "I-22", "text": "Modelado de carga cognitiva realista para mejorar los modelos mentales compartidos en la colaboraci\u00f3n entre humanos y agentes RESUMEN Los miembros del equipo humano a menudo desarrollan expectativas compartidas para predecir las necesidades de los dem\u00e1s y coordinar sus comportamientos. En este art\u00edculo se propone el concepto ``Mapa de Creencias Compartidas'' como base para desarrollar expectativas compartidas realistas entre un equipo de Pares Humano-Agente -LRB-HAPs-RRB-. El establecimiento de mapas de creencias compartidas se basa en el intercambio de informaci\u00f3n entre agentes, cuya eficacia depende en gran medida de las cargas de procesamiento de los agentes y de las cargas cognitivas instant\u00e1neas de sus socios humanos. Investigamos modelos de carga cognitiva basados \u200b\u200ben HMM para facilitar que los miembros del equipo \"compartan la informaci\u00f3n correcta con la parte adecuada en el momento adecuado\". El concepto de mapa de creencias compartidas y los modelos de carga cognitiva/de procesamiento se han implementado en una arquitectura de agente cognitivo: SMMall. Se llevaron a cabo una serie de experimentos para evaluar el concepto, los modelos y sus impactos en la evoluci\u00f3n de modelos mentales compartidos de los equipos HAP. 1. INTRODUCCI\u00d3N El trabajo en equipo multiagente centrado en el ser humano ha atra\u00eddo cada vez m\u00e1s atenci\u00f3n en el campo de los sistemas multiagente -LSB- 2, 10, 4 -RSB-. Humanos y aut\u00f3nomos En resumen, los humanos y los agentes pueden unirse para lograr un mejor desempe\u00f1o, dado que podr\u00edan establecer cierta conciencia mutua para coordinar sus actividades de iniciativa mixta. Sin embargo, la base de la colaboraci\u00f3n entre humanos y agentes sigue siendo cuestionada debido a modelos poco realistas de conciencia mutua del estado de las cosas. En particular, pocos investigadores van m\u00e1s all\u00e1 para evaluar los principios del modelado de construcciones mentales compartidas entre un ser humano y su agente asistente. Adem\u00e1s, las relaciones entre humanos y agentes pueden ir m\u00e1s all\u00e1 de los socios y convertirse en equipos. Por lo tanto, existe una clara demanda de investigaciones que ampl\u00eden y profundicen nuestra comprensi\u00f3n de los principios del modelado mental compartido entre miembros de un equipo mixto humano-agente. Existen l\u00edneas de investigaci\u00f3n sobre el trabajo en equipo multiagente, tanto de forma te\u00f3rica como emp\u00edrica. Por ejemplo, Joint Intention -LSB- 3 -RSB- y SharedPlans -LSB- 5 -RSB- son dos marcos te\u00f3ricos para especificar colaboraciones de agentes. Uno de los inconvenientes es que, aunque ambos tienen una profunda ra\u00edz filos\u00f3fica y cognitiva, no se adaptan al modelado de los miembros del equipo humano. Los estudios cognitivos sugirieron que se espera que los equipos que han compartido modelos mentales tengan expectativas comunes de la tarea y del equipo, lo que les permite predecir el comportamiento y las necesidades de recursos de los miembros del equipo con mayor precisi\u00f3n -LSB- 14, 6 -RSB-. Cannon-Bowers et al. -LSB- 14 -RSB- argumentan expl\u00edcitamente que los miembros del equipo deben tener modelos compatibles que conduzcan a \"expectativas\" comunes. Estamos de acuerdo en esto y creemos que el establecimiento de expectativas compartidas entre los miembros del equipo humano y de agentes es un paso cr\u00edtico para avanzar en la investigaci\u00f3n del trabajo en equipo centrado en el ser humano.Cabe se\u00f1alar que el concepto de expectativa compartida puede incluir en t\u00e9rminos generales la asignaci\u00f3n de roles y su din\u00e1mica, esquemas y progresos del trabajo en equipo, patrones e intenciones de comunicaci\u00f3n, etc. Si bien el objetivo a largo plazo de nuestra investigaci\u00f3n es comprender c\u00f3mo las estructuras cognitivas compartidas pueden 6. CONCLUSI\u00d3N La atenci\u00f3n de la investigaci\u00f3n reciente sobre el trabajo en equipo centrado en el ser humano exige en gran medida el dise\u00f1o de sistemas de agentes como ayudas cognitivas que puedan modelar y explotar a los socios humanos. capacidades cognitivas para ofrecer ayuda de forma discreta. En este art\u00edculo, investigamos varios factores que rodean el desafiante problema de la evoluci\u00f3n de modelos mentales compartidos de equipos compuestos por pares humano-agente. La principal contribuci\u00f3n de esta investigaci\u00f3n incluye -LRB-1-RRB- Se propusieron modelos de carga basados \u200b\u200ben HMM para que un agente estime la carga cognitiva de su compa\u00f1ero humano y las cargas de procesamiento de otros compa\u00f1eros de equipo HAP; -LRB- 2 -RRB- Se introdujo e implement\u00f3 el concepto de mapa de creencias compartidas. Permite a los miembros del grupo representar y razonar eficazmente sobre modelos mentales compartidos; -LRB- 3 -RRB- Se realizaron experimentos para evaluar los modelos de carga cognitiva/de procesamiento basados \u200b\u200ben HMM y los impactos de la comunicaci\u00f3n multipartita en la evoluci\u00f3n de los SMM de equipo. Durante los experimentos tambi\u00e9n se demostr\u00f3 la utilidad de los mapas de creencias compartidas.", "keyphrases": ["compartir mapa de creencias", "trabajo en equipo multiag", "heurista", "raz\u00f3n", "resoluci\u00f3n de problemas", "colaborar", "trabajo en equipo", "esperar", "esquema de trabajo en equipo", "equipo humano-agente realiza", "teor\u00eda de la carga cognitiva", "actuaci\u00f3n humana", "asignaci\u00f3n de recursos", "tarea realizada", "compartir informaci\u00f3n", "comuna multipartidista"]}
{"file_name": "J-23", "text": "Ratios de frugalidad y mecanismos veraces mejorados para la cobertura de Vertex * En las subastas del sistema establecido, hay varios equipos de agentes superpuestos y una tarea que puede ser completada por cualquiera de estos equipos. El objetivo del subastador es contratar un equipo y pagar lo menos posible. Ejemplos de esta configuraci\u00f3n incluyen subastas de ruta m\u00e1s corta y subastas de cobertura de v\u00e9rtices. Recientemente, Karlin, Kempe y Tamir introdujeron una nueva definici\u00f3n de ratio de frugalidad para este problema. Informalmente, el `` ratio de frugalidad '' es el ratio entre el pago total de un mecanismo y un l\u00edmite de pago deseado. La relaci\u00f3n captura el grado en que el mecanismo paga de m\u00e1s, en relaci\u00f3n con el costo justo percibido en una subasta veraz. En este art\u00edculo, proponemos una nueva subasta veraz en tiempo polinomial para el problema de cobertura de v\u00e9rtices y limitamos su \u00edndice de frugalidad. Mostramos que la calidad de la soluci\u00f3n tiene un factor constante \u00f3ptimo y el \u00edndice de frugalidad est\u00e1 dentro de un factor constante del mejor l\u00edmite posible en el peor de los casos; Esta es la primera subasta de este problema que tiene estas propiedades. Adem\u00e1s, mostramos c\u00f3mo transformar cualquier subasta veraz en una frugal preservando al mismo tiempo el ratio de aproximaci\u00f3n. Adem\u00e1s, consideramos dos modificaciones naturales de la definici\u00f3n de Karlin et al., y analizamos las propiedades de los l\u00edmites de pago resultantes, como la monotonicidad, la dureza computacional y la robustez con respecto a la regla de resoluci\u00f3n de sorteo. Estudiamos las relaciones entre los diferentes l\u00edmites de pago, tanto para sistemas de conjuntos generales como para subastas de sistemas de conjuntos espec\u00edficos, como las subastas de ruta y las subastas de cobertura de v\u00e9rtices. Usamos estas nuevas definiciones en la prueba de nuestro resultado principal para subastas de cobertura de v\u00e9rtices mediante una t\u00e9cnica de arranque, que puede ser de inter\u00e9s independiente. 1. INTRODUCCI\u00d3N En una subasta de sistema fijo hay un \u00fanico comprador y muchos vendedores que pueden prestar diversos servicios. Se supone que los requisitos del comprador pueden ser satisfechos por varios subconjuntos de proveedores; estos subconjuntos se denominan conjuntos factibles. Suponemos que cada vendedor tiene un costo por brindar sus servicios, pero posiblemente presenta una oferta mayor al subastador. Con base en estas ofertas, el subastador selecciona un subconjunto factible de proveedores y realiza pagos a los proveedores de este subconjunto. Cada proveedor seleccionado disfruta de una ganancia del pago menos el costo. Los vendedores quieren maximizar las ganancias, mientras que el comprador quiere minimizar la cantidad que paga. Un objetivo natural en este context es dise\u00f1ar una subasta veraz, en la que los vendedores tengan un incentivo para ofertar su costo real. Esto se puede lograr pagando a cada proveedor seleccionado una prima por encima de su oferta, de tal manera que el proveedor no tenga incentivos para sobrepujar. Una cuesti\u00f3n interesante en el dise\u00f1o de mecanismos es cu\u00e1nto tendr\u00e1 que pagar de m\u00e1s el subastador para garantizar ofertas veraces. En el context de las subastas de rutas, este tema fue abordado por primera vez por Archer y Tardos -LSB- 1 -RSB-.Definen el ratio de frugalidad de un mecanismo como el ratio entre su pago total y el coste del camino m\u00e1s barato separado del camino seleccionado por el mecanismo. Muestran que, para una gran clase de mecanismos veraces para este problema, la relaci\u00f3n de frugalidad es tan grande como el n\u00famero de aristas en el camino m\u00e1s corto. Talwar -LSB- 21 -RSB- extiende esta definici\u00f3n de \u00edndice de frugalidad a sistemas de conjuntos generales y estudia el \u00edndice de frugalidad del mecanismo VCG cl\u00e1sico -LSB- 22, 4, 14 -RSB- para muchos sistemas de conjuntos espec\u00edficos, como la expansi\u00f3n m\u00ednima. Arboles y cobertores. Si bien la definici\u00f3n de ratio de frugalidad propuesta por -LSB- 1 -RSB- est\u00e1 bien motivada y ha sido fundamental para estudiar mecanismos veraces para sistemas de conjuntos, no es completamente satisfactoria. Considere, por ejemplo, el gr\u00e1fico de la Figura 1 con los costos CAB = CBC = Figura 1: El gr\u00e1fico de diamantes Este gr\u00e1fico tiene dos conexiones y el pago VCG al camino ganador ABCD est\u00e1 acotado. Sin embargo, el gr\u00e1fico no contiene ning\u00fan camino A - D que sea separado de ABCD y, por lo tanto, la relaci\u00f3n de frugalidad de VCG en este gr\u00e1fico permanece indefinida. Al mismo tiempo, no existe un monopolio, es decir, no existe un proveedor que aparezca en todos los conjuntos factibles. Para abordar este problema, Karlin et al. -LSB- 16 -RSB- sugieren un mejor punto de referencia, que se define para cualquier sistema de conjuntos libre de monopolios. Con base en esta nueva definici\u00f3n, los autores construyen nuevos mecanismos para el problema del camino m\u00e1s corto y muestran que el sobrepago de estos mecanismos est\u00e1 dentro de un factor \u00f3ptimo constante. 1.1 Nuestros resultados Subastas de cobertura de v\u00e9rtices Proponemos una subasta veraz en tiempo polinomial para la cobertura de v\u00e9rtices que genera una soluci\u00f3n cuyo costo est\u00e1 dentro de un factor de 2 del \u00f3ptimo, y cuyo \u00edndice de frugalidad es como m\u00e1ximo 2\u0394, donde \u0394 es el grado m\u00e1ximo del gr\u00e1fico -LRB- Teorema 4 -RRB-. Complementamos este resultado demostrando -LRB- Teorema 5 -RRB- que para cualquier \u0394 y n, existen gr\u00e1ficas de grado m\u00e1ximo \u0394 y tama\u00f1o \u0398 -LRB- n -RRB- para las cuales cualquier mecanismo veraz tiene una relaci\u00f3n de frugalidad al menos \u0394 / 2. Esto significa que la calidad de la soluci\u00f3n de nuestra subasta es \u00f3ptima con un factor de 2 y el \u00edndice de frugalidad est\u00e1 dentro de un factor de 4 del mejor l\u00edmite posible para las entradas del peor caso. Hasta donde sabemos, esta es la primera subasta de este problema que disfruta de estas propiedades. Adem\u00e1s, mostramos c\u00f3mo transformar cualquier mecanismo veraz para el problema de cobertura de v\u00e9rtices en uno frugal preservando al mismo tiempo la relaci\u00f3n de aproximaci\u00f3n. Razones de frugalidad Nuestros resultados de cobertura de v\u00e9rtices naturalmente sugieren dos modificaciones de la definici\u00f3n de \u03bd en -LSB- 16 -RSB-. Estas modificaciones se pueden realizar de forma independiente entre s\u00ed, lo que da como resultado cuatro l\u00edmites de pago diferentes TUmax, TUmin, NTUmax y NTUmin, donde NTUmin es igual al l\u00edmite de pago original \u03bd de en -LSB- 16 -RSB-. Si bien nuestro principal resultado sobre las subastas de cobertura de v\u00e9rtices -LRB- Teorema 4 -RRB- es con respecto a NTUmin = \u03bd, hacemos uso de las nuevas definiciones comparando primero el pago de nuestro mecanismo con un NTUmax l\u00edmite m\u00e1s d\u00e9bil,y luego arrancando desde este resultado para obtener el l\u00edmite deseado. Inspir\u00e1ndonos en esta aplicaci\u00f3n, nos embarcamos en un estudio m\u00e1s detallado de estos l\u00edmites de pago. Nuestros resultados aqu\u00ed son los siguientes: 1. Observamos -LRB- Proposici\u00f3n 1 -RRB- que los cuatro l\u00edmites de pago siempre obedecen a un orden particular que es independiente de la elecci\u00f3n del sistema establecido y del vector de costos, es decir, TUmin < NTUmin < NTUm\u00e1x < TUm\u00e1x. Proporcionamos ejemplos -LRB- Proposici\u00f3n 5 y Corolarios 1 y 2 -RRB- que muestran que para el problema de cobertura de v\u00e9rtices, dos l\u00edmites consecutivos cualesquiera pueden diferir en un factor de n \u2212 2, donde n es el n\u00famero de agentes. Luego mostramos -LRB- Teorema 2 -RRB- que esta separaci\u00f3n es casi mejor posible para sistemas de conjuntos generales demostrando que para cualquier sistema de conjuntos TUmax/TUmin < n. Por el contrario, demostramos -LRB- Teorema 3 -RRB- que para subastas de ruta TUmax/TUmin < 2. Proporcionamos ejemplos -LRB- Proposiciones 2, 3 y 4 -RRB- que muestran que este l\u00edmite es ajustado. Vemos esto como un argumento para el estudio de las subastas de cobertura de v\u00e9rtices, ya que parecen ser m\u00e1s representativas del problema general de selecci\u00f3n del equipo que las subastas de ruta ampliamente estudiadas. 2. Esta observaci\u00f3n sugiere que los cuatro l\u00edmites de pago deber\u00edan estudiarse en un marco unificado; adem\u00e1s, nos lleva a creer que la t\u00e9cnica de arranque del Teorema 4 puede tener otras aplicaciones. 3. Evaluamos los l\u00edmites de pago introducidos aqu\u00ed con respecto a una lista de verificaci\u00f3n de caracter\u00edsticas deseables. Esto puede verse como un argumento a favor del uso de l\u00edmites NTUmax y TUmax m\u00e1s d\u00e9biles pero computables de manera eficiente. Trabajo relacionado Las subastas Vertex-cover han sido estudiadas en el pasado por Talwar -LSB- 21 -RSB- y Calinescu -LSB- 5 -RSB-. Ambos art\u00edculos se basan en la definici\u00f3n de \u00edndice de frugalidad utilizada en -LSB- 1 -RSB-; Como se mencion\u00f3 anteriormente, esto significa que sus resultados solo se aplican a gr\u00e1ficos bipartitos. Talwar -LSB- 21 -RSB- muestra que el ratio de frugalidad de VCG es como m\u00e1ximo \u0394. Sin embargo, dado que encontrar la cobertura de v\u00e9rtices m\u00e1s barata es un problema NP-dif\u00edcil, el mecanismo VCG es computacionalmente inviable. El primer art\u00edculo -LRB- y, hasta donde sabemos, el \u00fanico -RRB- para investigar mecanismos veraces en tiempo polinomial para la cobertura de v\u00e9rtices es -LSB- 5 -RSB-. Este art\u00edculo estudia una subasta que se basa en el algoritmo de asignaci\u00f3n codiciosa, que tiene una relaci\u00f3n de aproximaci\u00f3n de log n. Si bien el enfoque principal de -LSB- 5 -RSB- es el problema m\u00e1s general de cobertura de conjuntos, los resultados de -LSB- 5 -RSB- implican una relaci\u00f3n de frugalidad de 2\u03942 para la cobertura de v\u00e9rtices. 2. PRELIMINARES En la mayor parte de este art\u00edculo, analizamos las subastas para sistemas de conjuntos. En las subastas del sistema de conjuntos, cada elemento e del conjunto de terreno es propiedad de un agente independiente y tiene asociado un coste ce no negativo. El objetivo del centro es seleccionar -LRB- comprar -RRB- un conjunto factible. Cada elemento e del conjunto seleccionado tiene un coste de ce. Los elementos que no sean seleccionados no suponen ning\u00fan coste. La subasta se desarrolla de la siguiente manera: todos los elementos del terreno hacen sus ofertas,el centro selecciona un conjunto factible bas\u00e1ndose en las ofertas y realiza pagos a los agentes. Formalmente, una subasta se define mediante una regla de asignaci\u00f3n A : R '' _, F y una regla de pago P : R '' _, R ''. La regla de asignaci\u00f3n toma como entrada un vector de ofertas y decide cu\u00e1l de los conjuntos en F debe seleccionarse. La regla de pago tambi\u00e9n toma como entrada un vector de ofertas y decide cu\u00e1nto pagar a cada agente. Los requisitos est\u00e1ndar son racionalidad individual, es decir, el pago a cada agente debe ser al menos tan alto como su costo incurrido -LRB- 0 para agentes que no est\u00e1n en el conjunto seleccionado y ce para agentes en el conjunto seleccionado -RRB- y compatibilidad de incentivos. o veracidad, es decir, la estrategia dominante de cada agente es ofrecer su coste real. Una regla de asignaci\u00f3n es mon\u00f3tona si un agente no puede aumentar sus posibilidades de ser seleccionado aumentando su oferta. Dada una regla de asignaci\u00f3n mon\u00f3tona A y un vector de oferta b, la oferta umbral te de un agente e EA -LRB- b -RRB- es la oferta m\u00e1s alta de este agente que a\u00fan gana la subasta, dado que las ofertas de otros participantes siguen siendo las m\u00e1s altas. mismo. Es bien sabido -LRB- ver, por ejemplo -LSB- 19, 13 -RSB- -RRB- que cualquier subasta que tenga una regla de asignaci\u00f3n mon\u00f3tona y pague a cada agente su oferta umbral es veraz; por el contrario, cualquier subasta veraz tiene una regla de asignaci\u00f3n mon\u00f3tona. El mecanismo VCG es un mecanismo veraz que maximiza el \"bienestar social\" y paga 0 a los agentes perdedores. Para las subastas de sistemas de conjuntos, esto simplemente significa elegir el conjunto factible m\u00e1s barato, pagar a cada agente del conjunto seleccionado su oferta umbral y pagar 0 a todos los dem\u00e1s agentes. Tenga en cuenta, sin embargo, que el mecanismo VCG puede ser dif\u00edcil de implementar, ya que encontrar un conjunto factible m\u00e1s barato puede resultar dif\u00edcil. Si U es un conjunto de agentes, c -LRB- U -RRB- denota Ew \u2208 U cw. De manera similar, b -LRB- U -RRB- denota Ew \u2208 U bw.13 -RSB- -RRB- que cualquier subasta que tenga una regla de asignaci\u00f3n mon\u00f3tona y pague a cada agente su oferta umbral es veraz; por el contrario, cualquier subasta veraz tiene una regla de asignaci\u00f3n mon\u00f3tona. El mecanismo VCG es un mecanismo veraz que maximiza el \"bienestar social\" y paga 0 a los agentes perdedores. Para las subastas de sistemas de conjuntos, esto simplemente significa elegir el conjunto factible m\u00e1s barato, pagar a cada agente del conjunto seleccionado su oferta umbral y pagar 0 a todos los dem\u00e1s agentes. Tenga en cuenta, sin embargo, que el mecanismo VCG puede ser dif\u00edcil de implementar, ya que encontrar un conjunto factible m\u00e1s barato puede resultar dif\u00edcil. Si U es un conjunto de agentes, c -LRB- U -RRB- denota Ew \u2208 U cw. De manera similar, b -LRB- U -RRB- denota Ew \u2208 U bw.13 -RSB- -RRB- que cualquier subasta que tenga una regla de asignaci\u00f3n mon\u00f3tona y pague a cada agente su oferta umbral es veraz; por el contrario, cualquier subasta veraz tiene una regla de asignaci\u00f3n mon\u00f3tona. El mecanismo VCG es un mecanismo veraz que maximiza el \"bienestar social\" y paga 0 a los agentes perdedores. Para las subastas de sistemas de conjuntos, esto simplemente significa elegir el conjunto factible m\u00e1s barato, pagar a cada agente del conjunto seleccionado su oferta umbral y pagar 0 a todos los dem\u00e1s agentes. Tenga en cuenta, sin embargo, que el mecanismo VCG puede ser dif\u00edcil de implementar, ya que encontrar un conjunto factible m\u00e1s barato puede resultar dif\u00edcil. Si U es un conjunto de agentes, c -LRB- U -RRB- denota Ew \u2208 U cw. De manera similar, b -LRB- U -RRB- denota Ew \u2208 U bw.", "keyphrases": ["relaci\u00f3n frugal", "t\u00e9cnica de arranque", "subasta de cobertura de v\u00e9rtices", "utilidad de transferencia", "pago consecutivo obligado", "regla de asignaci\u00f3n mon\u00f3tona", "cobre", "polinomi-tiempo", "no mon\u00f3tono"]}
{"file_name": "I-11", "text": "Caracterizaci\u00f3n y predicci\u00f3n de agentes en tiempo real RESUMEN Razonar sobre los agentes que observamos en el mundo es un desaf\u00edo. Nuestra informaci\u00f3n disponible a menudo se limita a observaciones del comportamiento externo del agente en el pasado y en el presente. Para comprender estas acciones es necesario deducir el estado interno del agente, que incluye no s\u00f3lo elementos racionales -LRB- como las intenciones y planes -RRB-, sino tambi\u00e9n emotivos -LRB- como el miedo -RRB-. Adem\u00e1s, a menudo queremos predecir las acciones futuras del agente, que est\u00e1n limitadas no s\u00f3lo por estas caracter\u00edsticas internas, sino tambi\u00e9n por la din\u00e1mica de la interacci\u00f3n del agente con su entorno. BEE -LRB- Evoluci\u00f3n y extrapolaci\u00f3n del comportamiento -RRB- utiliza un modelo del entorno basado en agentes m\u00e1s r\u00e1pido que en tiempo real para caracterizar el estado interno de los agentes mediante la evoluci\u00f3n frente al comportamiento observado y luego predecir su comportamiento futuro, teniendo en cuenta la din\u00e1mica de su interacci\u00f3n con el medio ambiente. 1. INTRODUCCI\u00d3N El razonamiento sobre los agentes que observamos en el mundo debe integrar dos niveles dispares. Nuestras observaciones a menudo se limitan al comportamiento externo del agente, que frecuentemente puede resumirse num\u00e9ricamente como una trayectoria en el espacio-tiempo -LRB- quiz\u00e1s puntuada por acciones de un vocabulario bastante limitado -RRB-. Sin embargo, este comportamiento est\u00e1 impulsado por el estado interno del agente, que -LRB- en el caso de un humano -RRB- puede involucrar conceptos psicol\u00f3gicos y cognitivos de alto nivel como intenciones y emociones. Un desaf\u00edo central en muchos dominios de aplicaciones es el razonamiento a partir de observaciones externas del comportamiento de los agentes hasta una estimaci\u00f3n de su estado interno. Este razonamiento est\u00e1 motivado por el deseo de predecir el comportamiento del agente. Este problema se ha abordado tradicionalmente bajo la r\u00fabrica de \"reconocimiento del plan\" o \"inferencia del plan\". ''Muchos problemas realistas se desv\u00edan de estas condiciones. \u2022 El aumento del n\u00famero de agentes conduce a una explosi\u00f3n combinatoria que puede hundir el an\u00e1lisis convencional. \u2022 La din\u00e1mica ambiental puede frustrar las intenciones de los agentes. \u2022 Los agentes muchas veces intentan ocultar sus intenciones -LRB- e incluso su presencia -RRB-, en lugar de compartir informaci\u00f3n intencionadamente. \u2022 El estado emocional de un agente puede ser al menos tan importante como su estado racional para determinar su comportamiento. BEE -LRB- Evoluci\u00f3n y extrapolaci\u00f3n del comportamiento -RRB- es un enfoque novedoso para reconocer el estado racional y emocional de m\u00faltiples agentes que interact\u00faan bas\u00e1ndose \u00fanicamente en su comportamiento, sin recurrir a comunicaciones intencionales por parte de ellos. Est\u00e1 inspirado en t\u00e9cnicas utilizadas para predecir el comportamiento de sistemas din\u00e1micos no lineales, en las que una representaci\u00f3n del sistema se ajusta continuamente a su comportamiento pasado reciente. Para sistemas din\u00e1micos no lineales, la representaci\u00f3n es una ecuaci\u00f3n matem\u00e1tica de forma cerrada. En BEE, es un conjunto de par\u00e1metros que gobiernan el comportamiento de los agentes de software que representan a los individuos que se analizan.La versi\u00f3n actual de BEE caracteriza y predice el comportamiento de los agentes que representan a los soldados en combate urbano -LSB- 8 -RSB-. La secci\u00f3n 2 revisa trabajos previos relevantes. La secci\u00f3n 3 describe la arquitectura de BEE. La secci\u00f3n 4 informa los resultados de los experimentos con el sistema. La secci\u00f3n 5 concluye. 2. TRABAJO ANTERIOR BEE admite comparaci\u00f3n con investigaciones previas en IA -LRB- reconocimiento de planos -RRB-, Modelos Ocultos de Markov y sistemas de din\u00e1mica no lineal -LRB- predicci\u00f3n de trayectorias -RRB-. 2.1 Reconocimiento de planes en IA La teor\u00eda del agente com\u00fanmente describe el estado cognitivo de un agente en t\u00e9rminos de sus creencias, deseos e intenciones -LRB- el llamado modelo ``BDI'' -LSB- 5, 20 -RSB- -RRB- . Las creencias de un agente son proposiciones sobre el estado del mundo que considera verdaderas, en funci\u00f3n de sus percepciones. Sus deseos son proposiciones sobre el mundo que le gustar\u00eda que fueran ciertas. Los deseos no son necesariamente consistentes entre s\u00ed: un agente podr\u00eda desear ser rico y no trabajar al mismo tiempo. Las intenciones u objetivos de un agente son un subconjunto de sus deseos que ha seleccionado, en funci\u00f3n de sus creencias, para guiar sus acciones futuras. A diferencia de los deseos, las metas deben ser consistentes entre s\u00ed -LRB- o al menos creer que son consistentes por el agente -RRB-. Los objetivos de un agente gu\u00edan sus acciones. As\u00ed, uno deber\u00eda poder aprender algo sobre los objetivos de un agente observando sus acciones pasadas, y el conocimiento de los objetivos del agente, a su vez, permite sacar conclusiones sobre lo que el agente puede hacer en el futuro. Este proceso de razonamiento desde las acciones de un agente hasta sus objetivos se conoce como \"reconocimiento del plan\" o \"inferencia del plan\". El reconocimiento del plan rara vez se busca por s\u00ed mismo. Por lo general, admite una funci\u00f3n de nivel superior. Por ejemplo, en interfaces hombre-computadora, reconocer el plan de un usuario puede permitir que el sistema proporcione informaci\u00f3n y opciones m\u00e1s apropiadas para la acci\u00f3n del usuario. En un sistema de tutor\u00eda, inferir el plan del estudiante es un primer paso para identificar planes con errores y proporcionar la soluci\u00f3n adecuada. En muchos casos, la funci\u00f3n de nivel superior predice probables acciones futuras de la entidad cuyo plan se infiere. Nos centramos en el reconocimiento de planes en apoyo de la predicci\u00f3n. El plan de un agente es un insumo necesario para predecir su comportamiento futuro, pero no es suficiente. Es necesario tener en cuenta al menos otras dos influencias, una interna y otra externa. La influencia externa es la din\u00e1mica del entorno, que puede incluir otros agentes. La din\u00e1mica del mundo real impone limitaciones importantes. \u2022 El entorno puede interferir con los deseos del agente -LSB- 4, 10 -RSB-. \u2022 La mayor\u00eda de las interacciones entre agentes, y entre los agentes y el mundo, no son lineales. Un an\u00e1lisis racional de los objetivos de un agente puede permitirnos predecir lo que intentar\u00e1, pero cualquier plan no trivial con varios pasos depender\u00e1 sensiblemente en cada paso de la reacci\u00f3n del entorno.y nuestra predicci\u00f3n debe tener en cuenta tambi\u00e9n esta reacci\u00f3n. La simulaci\u00f3n real de futuros es una forma -LRB- la \u00fanica que conocemos ahora -RRB- de abordar el impacto de la din\u00e1mica ambiental sobre las acciones de un agente. Los agentes humanos tambi\u00e9n est\u00e1n sujetos a una influencia interna. El estado emocional del agente puede modular su proceso de decisi\u00f3n y su foco de atenci\u00f3n -LRB- y por tanto su percepci\u00f3n del entorno -RRB-. En casos extremos, la emoci\u00f3n puede llevar a un agente a elegir acciones que desde el punto de vista de un an\u00e1lisis l\u00f3gico pueden parecer irracionales. El trabajo actual sobre el reconocimiento de planes para la predicci\u00f3n se centra en el plan racional y no tiene en cuenta ni las influencias ambientales externas ni los sesgos emocionales internos. BEE integra los tres elementos en sus predicciones. 2.2 Modelos ocultos de Markov BEE es superficialmente similar a los modelos ocultos de Markov -LRB- HMM -LSB- 19 -RSB- -RRB-. BEE ofrece dos beneficios importantes sobre HMM. En primer lugar, las variables ocultas de un \u00fanico agente no satisfacen la propiedad de Markov. Es decir, sus valores en t + 1 dependen no s\u00f3lo de sus valores en t, sino tambi\u00e9n de las variables ocultas de otros agentes. Se podr\u00eda evitar esta limitaci\u00f3n construyendo un \u00fanico HMM sobre el espacio de estados conjunto de todos los agentes, pero este enfoque es combinatoriamente prohibitivo. BEE combina la eficiencia de modelar de forma independiente agentes individuales con la realidad de tener en cuenta las interacciones entre ellos. En segundo lugar, los modelos de Markov suponen que las probabilidades de transici\u00f3n son estacionarias. El proceso evolutivo de BEE actualiza continuamente las personalidades de los agentes bas\u00e1ndose en observaciones reales y, por lo tanto, toma en cuenta autom\u00e1ticamente los cambios en las personalidades de los agentes. 2.3 Ajuste de sistemas no lineales en tiempo real Muchos sistemas de inter\u00e9s pueden describirse mediante un vector de n\u00fameros reales que cambia en funci\u00f3n del tiempo. Las dimensiones del vector definen el espacio de estados del sistema. La predicci\u00f3n a largo plazo de tal sistema es imposible. Sin embargo, a menudo resulta \u00fatil anticipar el comportamiento del sistema a una corta distancia en el futuro. Este proceso se repite constantemente, proporcionando al usuario una visi\u00f3n limitada del futuro. Este enfoque es s\u00f3lido y se aplica ampliamente, pero requiere sistemas que puedan describirse de manera eficiente con ecuaciones matem\u00e1ticas. BEE extiende este enfoque a los comportamientos de los agentes, que ajusta al comportamiento observado mediante un algoritmo gen\u00e9tico. 5. CONCLUSIONES En muchos dominios, es importante razonar a partir del comportamiento observado de una entidad hasta una estimaci\u00f3n de su estado interno, y luego extrapolar esa estimaci\u00f3n para predecir el comportamiento futuro de la entidad. BEE realiza esta tarea utilizando una simulaci\u00f3n de enjambres de agentes m\u00e1s r\u00e1pida que en tiempo real, coordinada a trav\u00e9s de feromonas digitales. Esta simulaci\u00f3n integra el conocimiento de las regiones amenazadas, un an\u00e1lisis cognitivo de las creencias, deseos e intenciones del agente, un modelo de la disposici\u00f3n y el estado emocional del agente,y la din\u00e1mica de las interacciones con el medio ambiente. Al hacer evolucionar a los agentes en este rico entorno, podemos adaptar su estado interno a su comportamiento observado. En los juegos de guerra realistas, el sistema detecta con \u00e9xito emociones deliberadamente jugadas y hace predicciones razonables sobre el comportamiento futuro de las entidades. BEE solo puede modelar variables de estado internas que impactan el comportamiento externo del agente. No se pueden ajustar variables que el agente no manifiesta externamente, ya que la base del ciclo evolutivo es una comparaci\u00f3n del comportamiento externo del agente simulado con el de la entidad real. Esta limitaci\u00f3n es grave si nuestro prop\u00f3sito es comprender el estado interno de la entidad por s\u00ed mismo. Si nuestro prop\u00f3sito al adaptar agentes es predecir su comportamiento posterior, la limitaci\u00f3n es mucho menos grave. Las variables de estado que no impactan el comportamiento, si bien son invisibles para un an\u00e1lisis basado en el comportamiento, son irrelevantes para una predicci\u00f3n conductual. \u2022 Nuestro limitado repertorio inicial de emociones es un peque\u00f1o subconjunto de aquellos que han sido distinguidos por los psic\u00f3logos y que podr\u00edan ser \u00fatiles para comprender y proyectar la conducta. Esperamos ampliar el conjunto de emociones y disposiciones de apoyo que BEE puede detectar. \u2022 El mapeo entre el estado psicol\u00f3gico -LRB- cognitivo y emocional -RRB- de un agente y su comportamiento externo no es uno a uno. Varios estados internos diferentes podr\u00edan ser consistentes con un determinado comportamiento observado bajo un conjunto de condiciones ambientales, pero podr\u00edan producir comportamientos distintos bajo otras condiciones. Si el entorno del pasado reciente confunde estados internos tan distintos, seremos incapaces de distinguirlos. Mientras el entorno permanezca en este estado, nuestras predicciones ser\u00e1n precisas, cualquiera que sea el estado interno que asignemos al agente. Si luego el entorno cambia a uno en el que los diferentes estados internos conducen a diferentes comportamientos, utilizar el estado interno previamente elegido producir\u00e1 predicciones inexactas. Una forma de abordar estas preocupaciones es sondear el mundo real, perturb\u00e1ndolo de maneras que estimulen comportamientos distintos de entidades cuyo estado psicol\u00f3gico es de otro modo indistinguible. Este tipo de sondeo es una importante t\u00e9cnica de inteligencia. La simulaci\u00f3n de BEE, m\u00e1s r\u00e1pida que en tiempo real, puede permitirnos identificar acciones de sondeo apropiadas, aumentando en gran medida la eficacia de los esfuerzos de inteligencia.ya que la base del ciclo evolutivo es una comparaci\u00f3n del comportamiento exterior del agente simulado con el de la entidad real. Esta limitaci\u00f3n es grave si nuestro prop\u00f3sito es comprender el estado interno de la entidad por s\u00ed mismo. Si nuestro prop\u00f3sito al adaptar agentes es predecir su comportamiento posterior, la limitaci\u00f3n es mucho menos grave. Las variables de estado que no impactan el comportamiento, si bien son invisibles para un an\u00e1lisis basado en el comportamiento, son irrelevantes para una predicci\u00f3n conductual. \u2022 Nuestro limitado repertorio inicial de emociones es un peque\u00f1o subconjunto de aquellos que han sido distinguidos por los psic\u00f3logos y que podr\u00edan ser \u00fatiles para comprender y proyectar la conducta. Esperamos ampliar el conjunto de emociones y disposiciones de apoyo que BEE puede detectar. \u2022 El mapeo entre el estado psicol\u00f3gico -LRB- cognitivo y emocional -RRB- de un agente y su comportamiento externo no es uno a uno. Varios estados internos diferentes podr\u00edan ser consistentes con un determinado comportamiento observado bajo un conjunto de condiciones ambientales, pero podr\u00edan producir comportamientos distintos bajo otras condiciones. Si el entorno del pasado reciente confunde estados internos tan distintos, seremos incapaces de distinguirlos. Mientras el entorno permanezca en este estado, nuestras predicciones ser\u00e1n precisas, cualquiera que sea el estado interno que asignemos al agente. Si luego el entorno cambia a uno en el que los diferentes estados internos conducen a diferentes comportamientos, utilizar el estado interno previamente elegido producir\u00e1 predicciones inexactas. Una forma de abordar estas preocupaciones es sondear el mundo real, perturb\u00e1ndolo de maneras que estimulen comportamientos distintos de entidades cuyo estado psicol\u00f3gico es de otro modo indistinguible. Este tipo de sondeo es una importante t\u00e9cnica de inteligencia. La simulaci\u00f3n de BEE, m\u00e1s r\u00e1pida que en tiempo real, puede permitirnos identificar acciones de sondeo apropiadas, aumentando en gran medida la eficacia de los esfuerzos de inteligencia.ya que la base del ciclo evolutivo es una comparaci\u00f3n del comportamiento exterior del agente simulado con el de la entidad real. Esta limitaci\u00f3n es grave si nuestro prop\u00f3sito es comprender el estado interno de la entidad por s\u00ed mismo. Si nuestro prop\u00f3sito al adaptar agentes es predecir su comportamiento posterior, la limitaci\u00f3n es mucho menos grave. Las variables de estado que no impactan el comportamiento, si bien son invisibles para un an\u00e1lisis basado en el comportamiento, son irrelevantes para una predicci\u00f3n conductual. \u2022 Nuestro limitado repertorio inicial de emociones es un peque\u00f1o subconjunto de aquellos que han sido distinguidos por los psic\u00f3logos y que podr\u00edan ser \u00fatiles para comprender y proyectar la conducta. Esperamos ampliar el conjunto de emociones y disposiciones de apoyo que BEE puede detectar. \u2022 El mapeo entre el estado psicol\u00f3gico -LRB- cognitivo y emocional -RRB- de un agente y su comportamiento externo no es uno a uno. Varios estados internos diferentes podr\u00edan ser consistentes con un determinado comportamiento observado bajo un conjunto de condiciones ambientales, pero podr\u00edan producir comportamientos distintos bajo otras condiciones. Si el entorno del pasado reciente confunde estados internos tan distintos, seremos incapaces de distinguirlos. Mientras el entorno permanezca en este estado, nuestras predicciones ser\u00e1n precisas, cualquiera que sea el estado interno que asignemos al agente. Si luego el entorno cambia a uno en el que los diferentes estados internos conducen a diferentes comportamientos, utilizar el estado interno previamente elegido producir\u00e1 predicciones inexactas. Una forma de abordar estas preocupaciones es sondear el mundo real, perturb\u00e1ndolo de maneras que estimulen comportamientos distintos de entidades cuyo estado psicol\u00f3gico es de otro modo indistinguible. Este tipo de sondeo es una importante t\u00e9cnica de inteligencia. La simulaci\u00f3n de BEE, m\u00e1s r\u00e1pida que en tiempo real, puede permitirnos identificar acciones de sondeo apropiadas, aumentando en gran medida la eficacia de los esfuerzos de inteligencia.Si el entorno del pasado reciente confunde estados internos tan distintos, seremos incapaces de distinguirlos. Mientras el entorno permanezca en este estado, nuestras predicciones ser\u00e1n precisas, cualquiera que sea el estado interno que asignemos al agente. Si luego el entorno cambia a uno en el que los diferentes estados internos conducen a diferentes comportamientos, utilizar el estado interno previamente elegido producir\u00e1 predicciones inexactas. Una forma de abordar estas preocupaciones es sondear el mundo real, perturb\u00e1ndolo de maneras que estimulen comportamientos distintos de entidades cuyo estado psicol\u00f3gico es de otro modo indistinguible. Este tipo de sondeo es una importante t\u00e9cnica de inteligencia. La simulaci\u00f3n de BEE, m\u00e1s r\u00e1pida que en tiempo real, puede permitirnos identificar acciones de sondeo apropiadas, aumentando en gran medida la eficacia de los esfuerzos de inteligencia.Si el entorno del pasado reciente confunde estados internos tan distintos, seremos incapaces de distinguirlos. Mientras el entorno permanezca en este estado, nuestras predicciones ser\u00e1n precisas, cualquiera que sea el estado interno que asignemos al agente. Si luego el entorno cambia a uno en el que los diferentes estados internos conducen a diferentes comportamientos, utilizar el estado interno previamente elegido producir\u00e1 predicciones inexactas. Una forma de abordar estas preocupaciones es sondear el mundo real, perturb\u00e1ndolo de maneras que estimulen comportamientos distintos de entidades cuyo estado psicol\u00f3gico es de otro modo indistinguible. Este tipo de sondeo es una importante t\u00e9cnica de inteligencia. La simulaci\u00f3n de BEE, m\u00e1s r\u00e1pida que en tiempo real, puede permitirnos identificar acciones de sondeo apropiadas, aumentando en gran medida la eficacia de los esfuerzos de inteligencia.", "keyphrases": ["raz\u00f3n del agente", "comportamiento externo", "estado interno", "predecir el comportamiento del agente", "comportamiento evolut y extrapol", "sistema din\u00e1mico no lineal", "objetivo del agente", "emocionado", "sabor a feromonas", "disponer", "comportamiento futuro"]}
{"file_name": "J-9", "text": "Computaci\u00f3n en un mercado de informaci\u00f3n distribuida \u2217 RESUMEN Seg\u00fan la teor\u00eda econ\u00f3mica, respaldada por evidencia emp\u00edrica y de laboratorio, el precio de equilibrio de un t\u00edtulo financiero refleja toda la informaci\u00f3n relativa al valor del t\u00edtulo. Investigamos el proceso computacional en el camino hacia el equilibrio, donde la informaci\u00f3n distribuida entre los comerciantes se revela paso a paso a lo largo del tiempo y se incorpora al precio de mercado. Desarrollamos un modelo simplificado de un mercado de informaci\u00f3n, junto con estrategias comerciales, para formalizar las propiedades computacionales del proceso. Mostramos que no se garantiza que los valores cuyos pagos no pueden expresarse como funciones de umbral ponderadas de bits de entrada distribuidos converjan al equilibrio adecuado predicho por la teor\u00eda econ\u00f3mica. Por otro lado, se garantiza que los valores cuyos pagos son funciones de umbral converger\u00e1n, para todas las distribuciones de probabilidad anteriores. Adem\u00e1s, estos valores umbral convergen como m\u00e1ximo en n rondas, donde n es el n\u00famero de bits de informaci\u00f3n distribuida. Tambi\u00e9n demostramos un l\u00edmite inferior, que muestra un tipo de umbral de seguridad que requiere al menos n/2 rondas para converger en el peor de los casos. \u2217 Este trabajo fue apoyado por la Iniciativa de Investigaci\u00f3n Universitaria del Departamento de Defensa -LRB- URI -RRB- administrada por la Oficina de Investigaci\u00f3n Naval bajo la subvenci\u00f3n N00014-01-1-0795. \u2020 Respaldado en parte por la subvenci\u00f3n ONR N00014-01-0795 y las subvenciones NSF CCR-0105337, CCR-TC-0208972, ANI-0207399 e ITR-0219018. \u2021 Este trabajo se realiz\u00f3 en NEC Laboratories America, Princeton, Nueva Jersey. 1. INTRODUCCI\u00d3N La forma fuerte de la hip\u00f3tesis de los mercados eficientes establece que los precios de mercado incorporan casi instant\u00e1neamente toda la informaci\u00f3n disponible para todos los comerciantes. Como resultado, los precios de mercado codifican los mejores pron\u00f3sticos de resultados futuros dada toda la informaci\u00f3n, incluso si esa informaci\u00f3n se distribuye entre muchas fuentes. El proceso de incorporaci\u00f3n de informaci\u00f3n es, en esencia, un c\u00f3mputo distribuido. Cada comerciante comienza con su propia informaci\u00f3n. A medida que se realizan transacciones, la informaci\u00f3n resumida se revela a trav\u00e9s de los precios de mercado. Los comerciantes aprenden o infieren qu\u00e9 informaci\u00f3n es probable que otros tengan al observar los precios y luego actualizan sus propias creencias en funci\u00f3n de sus observaciones. Con el tiempo, si el proceso funciona como se anuncia, toda la informaci\u00f3n se revela y todos los comerciantes convergen al mismo estado de informaci\u00f3n. En este punto, el mercado se encuentra en lo que se llama un equilibrio de expectativas racionales -LSB- 11, 16, 19 -RSB-. Toda la informaci\u00f3n disponible para todos los comerciantes ahora se refleja en los precios vigentes y no es deseable realizar m\u00e1s operaciones hasta que haya nueva informaci\u00f3n disponible. Si bien la mayor\u00eda de los mercados no est\u00e1n dise\u00f1ados con la agregaci\u00f3n de informaci\u00f3n como motivaci\u00f3n principal (por ejemplo, los derivados). En este art\u00edculo, investigamos la naturaleza del proceso computacional mediante el cual la informaci\u00f3n distribuida se revela y combina con el tiempo en los precios en los mercados de informaci\u00f3n. Para ello, en la Secci\u00f3n 3,Proponemos un modelo de mercado de informaci\u00f3n que es manejable para el an\u00e1lisis te\u00f3rico y, creemos, captura gran parte de la esencia importante de los mercados de informaci\u00f3n reales. Demostramos que s\u00f3lo los valores booleanos cuyos pagos pueden expresarse como funciones de umbral de los bits de informaci\u00f3n de entrada distribuidos tienen la garant\u00eda de converger como lo predice la teor\u00eda de las expectativas racionales. Es posible que los valores booleanos con pagos m\u00e1s complejos no converjan en algunas distribuciones anteriores. Tambi\u00e9n proporcionamos l\u00edmites superior e inferior sobre el tiempo de convergencia para estos valores umbral. Mostramos que, para todas las distribuciones anteriores, el precio de un valor umbral converge a su precio de equilibrio de expectativas racionales en como m\u00e1ximo n rondas, donde n es el n\u00famero de bits de informaci\u00f3n distribuida. Mostramos que este l\u00edmite del peor de los casos es ajustado dentro de un factor de dos ilustrando una situaci\u00f3n en la que un umbral de seguridad requiere n/2 rondas para converger.", "keyphrases": ["teor\u00eda econ\u00f3mica", "empir y laboratorios evid", "precio de equilibrio", "finanzas seguras", "valor de seguridad", "proceso computacional", "camino hacia el equilibrio", "comerciante", "precio de mercado", "modelo simplificado", "estrategia comercial", "propiedades de c\u00e1lculo del proceso", "asegurar", "saldar", "funci\u00f3n umbral", "distribuci\u00f3n probable", "redondo", "n\u00famero de bits", "distribuir informar", "l\u00edmite inferior", "peor de los casos", "informar al mercado"]}
{"file_name": "H-19", "text": "An\u00e1lisis de trayectorias de caracter\u00edsticas para la detecci\u00f3n de eventos RESUMEN Consideramos el problema de analizar trayectorias de palabras tanto en el dominio del tiempo como de la frecuencia, con el objetivo espec\u00edfico de identificar palabras peri\u00f3dicas y aperi\u00f3dicas importantes y menos informadas. Se puede agrupar un conjunto de palabras con tendencias id\u00e9nticas para reconstruir un evento sin ninguna supervisi\u00f3n. La frecuencia del documento de cada palabra a lo largo del tiempo se trata como una serie de tiempo, donde cada elemento es la puntuaci\u00f3n de la frecuencia del documento - frecuencia inversa del documento -LRB- DFIDF -RRB- en un momento dado. En este art\u00edculo, 1 -RRB- aplicamos por primera vez el an\u00e1lisis espectral para categorizar caracter\u00edsticas de diferentes eventos: importantes y menos reportados, peri\u00f3dicos y aperi\u00f3dicos; 2 -RRB- model\u00f3 caracter\u00edsticas aperi\u00f3dicas con densidad gaussiana y caracter\u00edsticas peri\u00f3dicas con densidades de mezcla gaussianas, y posteriormente detect\u00f3 el estallido de cada caracter\u00edstica mediante el enfoque gaussiano truncado; 3 -RRB- propuso un algoritmo de detecci\u00f3n de eventos codiciosos no supervisados \u200b\u200bpara detectar eventos peri\u00f3dicos y aperi\u00f3dicos. Todos los m\u00e9todos anteriores se pueden aplicar a datos de series de tiempo en general. Evaluamos exhaustivamente nuestros m\u00e9todos en el Reuters News Corpus -LSB- 3 -RSB- de 1 a\u00f1o y demostramos que pod\u00edan descubrir eventos peri\u00f3dicos y aperi\u00f3dicos significativos. 1. INTRODUCCI\u00d3N Hay m\u00e1s de 4.000 fuentes de noticias en l\u00ednea en el mundo. Monitorearlos manualmente para detectar eventos importantes se ha vuelto dif\u00edcil o pr\u00e1cticamente imposible. De hecho, la comunidad de detecci\u00f3n y seguimiento de temas -LRB-TDT-RRB- lleva muchos a\u00f1os intentando encontrar una soluci\u00f3n pr\u00e1ctica que ayude a las personas a seguir las noticias de forma eficaz. las soluciones propuestas para la detecci\u00f3n de eventos -LSB- 20, 5, 17, 4, 21, 7, 14, 10 -RSB- son demasiado simplistas -LRB- basadas en la similitud de cosenos -LSB- 5 -RSB- -RRB- o poco pr\u00e1cticas debido a la necesidad de sintonizar un gran n\u00famero de par\u00e1metros -LSB- 9 -RSB-. Por lo tanto, en este art\u00edculo analizamos las noticias y las tendencias destacadas desde la perspectiva del an\u00e1lisis de una se\u00f1al de palabra de una serie temporal. Trabajos anteriores como -LSB- 9 -RSB- han intentado reconstruir un evento con sus caracter\u00edsticas representativas. Sin embargo, en muchas tareas de detecci\u00f3n predictiva de eventos -LRB- es decir, detecci\u00f3n retrospectiva de eventos -RRB-, existe un vasto conjunto de caracter\u00edsticas potenciales s\u00f3lo para un conjunto fijo de observaciones -LRB- es decir, las r\u00e1fagas obvias -RRB-. De estas caracter\u00edsticas, a menudo se espera que s\u00f3lo una peque\u00f1a cantidad sean \u00fatiles. En particular, estudiamos el nuevo problema de analizar trayectorias de caracter\u00edsticas para la detecci\u00f3n de eventos, tomando prestada una t\u00e9cnica bien conocida del procesamiento de se\u00f1ales: identificar correlaciones distributivas entre todas las caracter\u00edsticas mediante an\u00e1lisis espectral. Para evaluar nuestro m\u00e9todo, posteriormente proponemos un algoritmo de detecci\u00f3n de eventos no supervisados \u200b\u200bpara flujos de noticias. Figura 1: Correlaci\u00f3n de caracter\u00edsticas -LRB- DFIDF: tiempo -RRB- entre a -RRB- Semana Santa y abril b -RRB- No auditado y finalizado. Como ejemplo ilustrativo, consideremos la correlaci\u00f3n entre las palabras Semana Santa y Abril del Corpus de Reuters.En la gr\u00e1fica de su DFIDF normalizado en la Figura 1 -LRB- a -RRB-, observamos la fuerte superposici\u00f3n entre las dos palabras alrededor del 04/1997, lo que significa que probablemente ambas pertenecen al mismo evento durante ese tiempo -LRB- Fiesta de Pascua. -RRB-. En este ejemplo, el evento oculto Fiesta de Pascua es un evento aperi\u00f3dico importante t\u00edpico en datos de 1 a\u00f1o. Otro ejemplo se muestra en la Figura 1 -LRB- b -RRB-, donde las palabras No auditado y Finalizado ` Reuters Corpus son el conjunto de datos predeterminado para todos los ejemplos. exhiben un comportamiento similar durante per\u00edodos de 3 meses. Estas dos palabras en realidad se originaron en el mismo evento peri\u00f3dico: los informes de p\u00e9rdidas de ingresos netos, que las empresas que cotizan en bolsa publican trimestralmente. Otras observaciones extra\u00eddas de la Figura 1 son: 1 -RRB- el per\u00edodo de r\u00e1fagas de abril es mucho m\u00e1s largo que Semana Santa, lo que sugiere que abril puede existir en otros eventos durante el mismo per\u00edodo; 2 -RRB- No auditado tiene un valor DFIDF promedio m\u00e1s alto que Finalizado, lo que indica que No auditado es m\u00e1s representativo del evento subyacente. Estos dos ejemplos no son m\u00e1s que la punta del iceberg entre todas las tendencias y correlaciones de palabras ocultas en una corriente de noticias como Reuters. Si se logra descubrir un gran n\u00famero de ellos, podr\u00eda ayudar significativamente a las tareas de la TDT. En particular, indica la importancia de extraer caracter\u00edsticas de correlaci\u00f3n para detectar eventos correspondientes. En resumen, postulamos que: 1 -RRB- Un evento se describe por sus caracter\u00edsticas representativas. Con base en estas observaciones, podemos extraer caracter\u00edsticas representativas de un evento dado o detectar un evento a partir de una lista de caracter\u00edsticas altamente correlacionadas. En este art\u00edculo, nos centramos en esto \u00faltimo, es decir, en c\u00f3mo se pueden descubrir caracter\u00edsticas correlacionadas para formar un evento de manera no supervisada. 1.1 Contribuciones Este art\u00edculo tiene tres contribuciones principales: 9 Hasta donde sabemos, nuestro enfoque es el primero en categorizar caracter\u00edsticas de palabras para eventos heterog\u00e9neos. 9 Proponemos un enfoque simple y eficaz basado en la densidad de la mezcla para modelar y detectar explosiones de caracter\u00edsticas. 9 Creamos un algoritmo de detecci\u00f3n de eventos no supervisados \u200b\u200bpara detectar eventos peri\u00f3dicos y aperi\u00f3dicos. Nuestro algoritmo ha sido evaluado en un flujo de noticias real para demostrar su eficacia. 2. TRABAJO RELACIONADO Adem\u00e1s, la mayor\u00eda de las investigaciones TDT hasta ahora se han centrado en agrupar/clasificar documentos en tipos de temas, identificar oraciones novedosas -LSB- 6 -RSB- para nuevos eventos, etc., sin prestar mucha atenci\u00f3n al an\u00e1lisis de la palabra trayectoria con respecto al tiempo. Swan y Allan -LSB- 18 -RSB- intentaron por primera vez utilizar t\u00e9rminos coexistentes para construir un evento. Sin embargo, s\u00f3lo consideraron entidades nombradas y pares de sintagmas nominales, sin considerar sus periodicidades. Por el contrario, nuestro art\u00edculo considera todo lo anterior. Recientemente, ha habido un gran inter\u00e9s en modelar un evento en flujos de text como una \"explosi\u00f3n de actividades\" mediante la incorporaci\u00f3n de informaci\u00f3n temporal. Sin embargo, ninguno de los trabajos existentes identific\u00f3 espec\u00edficamente caracter\u00edsticas de eventos, excepto Fung et al. -LSB- 9 -RSB-,quien agrup\u00f3 rasgos tetonas para identificar varios eventos explosivos. Nuestro trabajo se diferencia de -LSB- 9 -RSB- en varios aspectos: 1 -RRB- analizamos cada caracter\u00edstica, no solo las caracter\u00edsticas en r\u00e1fagas; 2 -RRB- clasificamos caracter\u00edsticas seg\u00fan dos dimensiones categ\u00f3ricas -LRB- periodicidad y potencia -RRB-, lo que produce en total cinco tipos de caracter\u00edsticas principales; 3 -RRB- no restringimos que cada caracter\u00edstica pertenezca exclusivamente a un solo evento. Vlachos et al. han utilizado previamente t\u00e9cnicas de an\u00e1lisis espectral. -LSB- 19 -RSB- para identificar periodicidades y r\u00e1fagas de registros de consultas. Su atenci\u00f3n se centr\u00f3 en detectar m\u00faltiples periodicidades a partir del gr\u00e1fico del espectro de potencia, que luego se utilizaron para indexar palabras para la b\u00fasqueda \"consulta por r\u00e1faga\". En este art\u00edculo, utilizamos el an\u00e1lisis espectral para clasificar caracter\u00edsticas de palabras seg\u00fan dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos de r\u00e1fagas tanto peri\u00f3dicas como aperi\u00f3dicas. 8. CONCLUSIONES Este art\u00edculo adopt\u00f3 una perspectiva completamente nueva al analizar las trayectorias de caracter\u00edsticas como se\u00f1ales en el dominio del tiempo. Al considerar las frecuencias de los documentos de palabras tanto en el dominio del tiempo como de la frecuencia, pudimos derivar muchas caracter\u00edsticas nuevas sobre los flujos de noticias que antes se desconoc\u00edan, por ejemplo, las diferentes distribuciones de palabras vac\u00edas durante los d\u00edas laborables y los fines de semana. Por primera vez en el \u00e1rea de la TDT, aplicamos un enfoque sistem\u00e1tico para detectar autom\u00e1ticamente eventos peri\u00f3dicos y aperi\u00f3dicos importantes y menos reportados. La idea clave de nuestro trabajo radica en las observaciones de que -LRB- a -RRB- los eventos peri\u00f3dicos tienen -LRB- a -RRB- caracter\u00edsticas representativas peri\u00f3dicas y -LRB- un -RRB- los eventos importantes tienen -LRB- en -RRB- activo caracter\u00edsticas representativas, diferenciadas por sus espectros de potencia y periodos de tiempo. Para abordar el problema de detecci\u00f3n de eventos reales, se utiliz\u00f3 un enfoque simple y eficaz basado en la densidad de la mezcla para identificar r\u00e1fagas de caracter\u00edsticas y sus per\u00edodos de r\u00e1faga asociados. Tambi\u00e9n dise\u00f1amos un algoritmo codicioso no supervisado para detectar eventos peri\u00f3dicos y aperi\u00f3dicos, que logr\u00f3 detectar eventos reales como se muestra en la evaluaci\u00f3n de un flujo de noticias real. Aunque no hemos realizado ninguna comparaci\u00f3n comparativa con otro enfoque, simplemente porque no existe ning\u00fan trabajo previo en el problema abordado. Sin embargo, creemos que nuestro m\u00e9todo simple y eficaz ser\u00e1 \u00fatil para todos los profesionales de la TDT, y ser\u00e1 especialmente \u00fatil para el an\u00e1lisis exploratorio inicial de los flujos de noticias.Su atenci\u00f3n se centr\u00f3 en detectar m\u00faltiples periodicidades a partir del gr\u00e1fico del espectro de potencia, que luego se utilizaron para indexar palabras para la b\u00fasqueda \"consulta por r\u00e1faga\". En este art\u00edculo, utilizamos el an\u00e1lisis espectral para clasificar caracter\u00edsticas de palabras seg\u00fan dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos de r\u00e1fagas tanto peri\u00f3dicas como aperi\u00f3dicas. 8. CONCLUSIONES Este art\u00edculo adopt\u00f3 una perspectiva completamente nueva al analizar las trayectorias de caracter\u00edsticas como se\u00f1ales en el dominio del tiempo. Al considerar las frecuencias de los documentos de palabras tanto en el dominio del tiempo como de la frecuencia, pudimos derivar muchas caracter\u00edsticas nuevas sobre los flujos de noticias que antes se desconoc\u00edan, por ejemplo, las diferentes distribuciones de palabras vac\u00edas durante los d\u00edas laborables y los fines de semana. Por primera vez en el \u00e1rea de la TDT, aplicamos un enfoque sistem\u00e1tico para detectar autom\u00e1ticamente eventos peri\u00f3dicos y aperi\u00f3dicos importantes y menos reportados. La idea clave de nuestro trabajo radica en las observaciones de que -LRB- a -RRB- los eventos peri\u00f3dicos tienen -LRB- a -RRB- caracter\u00edsticas representativas peri\u00f3dicas y -LRB- un -RRB- los eventos importantes tienen -LRB- en -RRB- activo caracter\u00edsticas representativas, diferenciadas por sus espectros de potencia y periodos de tiempo. Para abordar el problema de detecci\u00f3n de eventos reales, se utiliz\u00f3 un enfoque simple y eficaz basado en la densidad de la mezcla para identificar r\u00e1fagas de caracter\u00edsticas y sus per\u00edodos de r\u00e1faga asociados. Tambi\u00e9n dise\u00f1amos un algoritmo codicioso no supervisado para detectar eventos peri\u00f3dicos y aperi\u00f3dicos, que logr\u00f3 detectar eventos reales como se muestra en la evaluaci\u00f3n de un flujo de noticias real. Aunque no hemos realizado ninguna comparaci\u00f3n comparativa con otro enfoque, simplemente porque no existe ning\u00fan trabajo previo en el problema abordado. Sin embargo, creemos que nuestro m\u00e9todo simple y eficaz ser\u00e1 \u00fatil para todos los profesionales de la TDT, y ser\u00e1 especialmente \u00fatil para el an\u00e1lisis exploratorio inicial de los flujos de noticias.Su atenci\u00f3n se centr\u00f3 en detectar m\u00faltiples periodicidades a partir del gr\u00e1fico del espectro de potencia, que luego se utilizaron para indexar palabras para la b\u00fasqueda \"consulta por r\u00e1faga\". En este art\u00edculo, utilizamos el an\u00e1lisis espectral para clasificar caracter\u00edsticas de palabras seg\u00fan dos dimensiones, a saber, periodicidad y espectro de potencia, con el objetivo final de identificar eventos de r\u00e1fagas tanto peri\u00f3dicas como aperi\u00f3dicas. 8. CONCLUSIONES Este art\u00edculo adopt\u00f3 una perspectiva completamente nueva al analizar las trayectorias de caracter\u00edsticas como se\u00f1ales en el dominio del tiempo. Al considerar las frecuencias de los documentos de palabras tanto en el dominio del tiempo como de la frecuencia, pudimos derivar muchas caracter\u00edsticas nuevas sobre los flujos de noticias que antes se desconoc\u00edan, por ejemplo, las diferentes distribuciones de palabras vac\u00edas durante los d\u00edas laborables y los fines de semana. Por primera vez en el \u00e1rea de la TDT, aplicamos un enfoque sistem\u00e1tico para detectar autom\u00e1ticamente eventos peri\u00f3dicos y aperi\u00f3dicos importantes y menos reportados. La idea clave de nuestro trabajo radica en las observaciones de que -LRB- a -RRB- los eventos peri\u00f3dicos tienen -LRB- a -RRB- caracter\u00edsticas representativas peri\u00f3dicas y -LRB- un -RRB- los eventos importantes tienen -LRB- en -RRB- activo caracter\u00edsticas representativas, diferenciadas por sus espectros de potencia y periodos de tiempo. Para abordar el problema de detecci\u00f3n de eventos reales, se utiliz\u00f3 un enfoque simple y eficaz basado en la densidad de la mezcla para identificar r\u00e1fagas de caracter\u00edsticas y sus per\u00edodos de r\u00e1faga asociados. Tambi\u00e9n dise\u00f1amos un algoritmo codicioso no supervisado para detectar eventos peri\u00f3dicos y aperi\u00f3dicos, que logr\u00f3 detectar eventos reales como se muestra en la evaluaci\u00f3n de un flujo de noticias real. Aunque no hemos realizado ninguna comparaci\u00f3n comparativa con otro enfoque, simplemente porque no existe ning\u00fan trabajo previo en el problema abordado. Sin embargo, creemos que nuestro m\u00e9todo simple y eficaz ser\u00e1 \u00fatil para todos los profesionales de la TDT, y ser\u00e1 especialmente \u00fatil para el an\u00e1lisis exploratorio inicial de los flujos de noticias.Para abordar el problema de detecci\u00f3n de eventos reales, se utiliz\u00f3 un enfoque simple y eficaz basado en la densidad de la mezcla para identificar r\u00e1fagas de caracter\u00edsticas y sus per\u00edodos de r\u00e1faga asociados. Tambi\u00e9n dise\u00f1amos un algoritmo codicioso no supervisado para detectar eventos peri\u00f3dicos y aperi\u00f3dicos, que logr\u00f3 detectar eventos reales como se muestra en la evaluaci\u00f3n de un flujo de noticias real. Aunque no hemos realizado ninguna comparaci\u00f3n comparativa con otro enfoque, simplemente porque no existe ning\u00fan trabajo previo en el problema abordado. Sin embargo, creemos que nuestro m\u00e9todo simple y eficaz ser\u00e1 \u00fatil para todos los profesionales de la TDT, y ser\u00e1 especialmente \u00fatil para el an\u00e1lisis exploratorio inicial de los flujos de noticias.Para abordar el problema de detecci\u00f3n de eventos reales, se utiliz\u00f3 un enfoque simple y eficaz basado en la densidad de la mezcla para identificar r\u00e1fagas de caracter\u00edsticas y sus per\u00edodos de r\u00e1faga asociados. Tambi\u00e9n dise\u00f1amos un algoritmo codicioso no supervisado para detectar eventos peri\u00f3dicos y aperi\u00f3dicos, que logr\u00f3 detectar eventos reales como se muestra en la evaluaci\u00f3n de un flujo de noticias real. Aunque no hemos realizado ninguna comparaci\u00f3n comparativa con otro enfoque, simplemente porque no existe ning\u00fan trabajo previo en el problema abordado. Sin embargo, creemos que nuestro m\u00e9todo simple y eficaz ser\u00e1 \u00fatil para todos los profesionales de la TDT, y ser\u00e1 especialmente \u00fatil para el an\u00e1lisis exploratorio inicial de los flujos de noticias.", "keyphrases": ["detecci\u00f3n de eventos", "palabra trayectoria", "evento de periodo", "evento de periodo", "se\u00f1al de palabra", "an\u00e1lisis espectral", "detectar tema", "pista de tema", "flujo de text", "nueva corriente", "serie de tiempo"]}
{"file_name": "H-3", "text": "Uso de contexts de consulta en la recuperaci\u00f3n de informaci\u00f3n RESUMEN La consulta del usuario es un elemento que especifica una necesidad de informaci\u00f3n, pero no es el \u00fanico. Los estudios en la literatura han encontrado muchos factores contextuales que influyen fuertemente en la interpretaci\u00f3n de una consulta. Estudios recientes han intentado tener en cuenta los intereses del usuario mediante la creaci\u00f3n de un perfil de usuario. Sin embargo, un \u00fanico perfil para un usuario puede no ser suficiente para una variedad de consultas del usuario. En este estudio, proponemos utilizar contexts espec\u00edficos de consulta en lugar de contexts centrados en el usuario, incluido el context alrededor de la consulta y el context dentro de la consulta. El primero especifica el entorno de una consulta, como el dominio de inter\u00e9s, mientras que el segundo se refiere a palabras de context dentro de la consulta, lo que resulta particularmente \u00fatil para la selecci\u00f3n de relaciones de t\u00e9rminos relevantes. En este art\u00edculo, ambos tipos de context se integran en un modelo de RI basado en el modelado del lenguaje. Nuestros experimentos en varias colecciones de TREC muestran que cada uno de los factores contextuales aporta mejoras significativas en la efectividad de la recuperaci\u00f3n. 1. INTRODUCCI\u00d3N Las consultas, especialmente las consultas breves, no proporcionan una especificaci\u00f3n completa de la informaci\u00f3n necesaria. Muchos t\u00e9rminos relevantes pueden faltar en las consultas y los t\u00e9rminos incluidos pueden ser ambiguos. Estas cuestiones han sido abordadas en un gran n\u00famero de estudios previos. Sin embargo, en estos estudios se ha asumido generalmente que la consulta es el \u00fanico elemento disponible sobre las necesidades de informaci\u00f3n del usuario. En realidad, la consulta siempre se formula en un context de b\u00fasqueda. Estos factores incluyen, entre muchos otros, el dominio de inter\u00e9s, conocimientos, preferencias, etc. del usuario. Todos estos elementos especifican las 8. CONCLUSIONES Los enfoques tradicionales de RI suelen considerar la consulta como el \u00fanico elemento disponible para satisfacer las necesidades de informaci\u00f3n del usuario. Muchos estudios previos han investigado la integraci\u00f3n de algunos factores contextuales en los modelos de IR, normalmente incorporando un perfil de usuario. De manera similar a algunos estudios anteriores, proponemos modelar dominios tem\u00e1ticos en lugar del usuario. Investigaciones anteriores sobre el context se centraron en factores relacionados con la consulta. En este art\u00edculo mostramos que los factores dentro de la consulta tambi\u00e9n son importantes: ayudan a seleccionar las relaciones de t\u00e9rminos apropiadas para aplicar en la expansi\u00f3n de la consulta. Hemos integrado los factores contextuales anteriores, junto con el modelo de retroalimentaci\u00f3n, en un modelo de lenguaje \u00fanico. Nuestros resultados experimentales confirman firmemente el beneficio de utilizar contexts en RI. Este trabajo tambi\u00e9n muestra que el marco de modelado del lenguaje es apropiado para integrar muchos factores contextuales. Este trabajo se puede mejorar a\u00fan m\u00e1s en varios aspectos, incluidos otros m\u00e9todos para extraer relaciones de t\u00e9rminos, integrar m\u00e1s palabras de context en condiciones e identificar dominios de consulta. Tambi\u00e9n ser\u00eda interesante probar el m\u00e9todo en la b\u00fasqueda web utilizando el historial de b\u00fasqueda del usuario.", "keyphrases": ["perfil de usuario", "context espec\u00edfico de consulta", "centrado en el usuario", "dominio de inter\u00e9s", "factor de context", "palabra sentido desambiguo", "informar necesidad", "context de b\u00fasqueda", "conocimiento del dominio", "utilidad del conocimiento genero", "problema del conocimiento ambiguo", "independiente del context", "context informar", "modelo de dominio", "soluci\u00f3n radical", "busqueda de persona en google"]}
{"file_name": "C-28", "text": "PackageBLAST: un servicio de cuadr\u00edcula adaptativo de pol\u00edticas m\u00faltiples para la comparaci\u00f3n de secuencias biol\u00f3gicas * RESUMEN En este art\u00edculo, proponemos un marco de asignaci\u00f3n de tareas adaptativo para realizar b\u00fasquedas BLAST en un entorno de cuadr\u00edcula contra segmentos de bases de datos de secuencias. El marco, llamado PackageBLAST, proporciona una infraestructura para elegir o incorporar estrategias de asignaci\u00f3n de tareas. Adem\u00e1s, proponemos un mecanismo para calcular el peso de ejecuci\u00f3n de los nodos de la red, adaptando la pol\u00edtica de asignaci\u00f3n elegida a la potencia computacional actual de los nodos. Nuestros resultados presentan muy buenas aceleraciones y tambi\u00e9n muestran que ninguna estrategia de asignaci\u00f3n es capaz de lograr los tiempos de ejecuci\u00f3n m\u00e1s bajos para todos los escenarios. 1. INTRODUCCI\u00d3N SW -LSB- 14 -RSB- es un algoritmo exacto que encuentra la mejor alineaci\u00f3n local entre dos secuencias de tama\u00f1o n en tiempo y espacio cuadr\u00e1ticos. Por esta raz\u00f3n, se propusieron heur\u00edsticas como BLAST -LSB- 3 -RSB- para reducir el tiempo de ejecuci\u00f3n. CLS. Apoyado por ACM. La programaci\u00f3n de recursos es uno de los componentes m\u00e1s importantes de un sistema de red. La elecci\u00f3n de los mejores recursos para una aplicaci\u00f3n particular se llama asignaci\u00f3n de tareas, que es un problema NP-Complete. Las aplicaciones Grid no suelen tener altas velocidades de comunicaci\u00f3n y muchas de ellas siguen el modelo maestro/esclavo -LSB- 13 -RSB-. Para programar aplicaciones maestro/esclavo se propusieron muchas pol\u00edticas de asignaci\u00f3n de tareas, como Self Scheduling -LSB- 15 -RSB- y FAC2 -LSB- 8 -RSB-. La elecci\u00f3n de la mejor pol\u00edtica de asignaci\u00f3n depende del patr\u00f3n de acceso a la aplicaci\u00f3n y del entorno en el que se ejecuta -LSB- 13 -RSB-. En este art\u00edculo, proponemos PackageBLAST, un servicio de grilla adaptativo de pol\u00edticas m\u00faltiples para ejecutar b\u00fasquedas BLAST en grillas compuestas por bases de datos gen\u00e9ticas segmentadas. PackageBLAST se ejecuta en Globus 3 -LSB- 4 -RSB- y, hasta ahora, proporciona cinco pol\u00edticas de asignaci\u00f3n. Adem\u00e1s, proponemos un mecanismo adaptativo para asignar pesos a los nodos de la red, teniendo en cuenta su carga de trabajo actual. Hasta donde sabemos, este es el primer servicio grid que ejecuta BLAST con pol\u00edticas de m\u00faltiples tareas con una base de datos segmentada en una plataforma heterog\u00e9nea no dedicada. Este art\u00edculo est\u00e1 organizado de la siguiente forma: La secci\u00f3n 2 presenta el problema de comparaci\u00f3n de secuencias y el algoritmo BLAST. La Secci\u00f3n 3 describe las pol\u00edticas de asignaci\u00f3n de redes. La secci\u00f3n 4 analiza el trabajo relacionado. La Secci\u00f3n 5 presenta el dise\u00f1o de PackageBLAST. Los resultados experimentales se analizan en la secci\u00f3n 6. La secci\u00f3n 7 concluye el art\u00edculo. 4. TRABAJOS RELACIONADOS En primer lugar, se segmenta la base de datos gen\u00e9tica. Luego, las consultas se distribuyen uniformemente entre los nodos. Si el nodo no tiene un fragmento de base de datos, se realiza una copia local. Se propone un m\u00e9todo que asocia fragmentos de datos a nodos, intentando minimizar el n\u00famero de copias. BLAST + + -LSB- 10 -RSB- agrupa m\u00faltiples secuencias para reducir el n\u00famero de accesos a la base de datos. Se utiliza un enfoque maestro/esclavo que asigna las consultas a los esclavos de acuerdo con la pol\u00edtica fija -LRB- secci\u00f3n 3.3 -RRB-. Cada trabajador ejecuta BLAST++ de forma independiente y, finalmente,los resultados son recopilados y combinados por el maestro. GridBlast -LSB- 9 -RSB- es una aplicaci\u00f3n de grilla maestra/esclava que utiliza Globus 2. Distribuye secuencias entre los nodos de la grilla usando dos pol\u00edticas de asignaci\u00f3n: FCFS y minmax. Sin embargo, para utilizar minmax, se debe conocer el tiempo total de ejecuci\u00f3n de cada tarea BLAST. Habiendo decidido qu\u00e9 secuencias comparar\u00e1 cada nodo, GridBlast env\u00eda las secuencias, los archivos ejecutables y toda la base de datos al nodo elegido. Cuando finaliza la b\u00fasqueda, los resultados se compactan y se env\u00edan al maestro. Grid Blast Toolkit -LRB- GBTK -RRB- -LSB- 12 -RSB- es un portal web para ejecutar b\u00fasquedas BLAST en Globus 3. Todas las bases de datos gen\u00e9ticas se colocan est\u00e1ticamente en los nodos del grid -LRB- sin replicaci\u00f3n -RRB-. GBTK es una aplicaci\u00f3n maestro/esclavo que recibe las secuencias y el nombre de la base de datos gen\u00e9tica. Luego verifica si el nodo que contiene la base de datos est\u00e1 disponible. Si el nodo no est\u00e1 disponible, se elige el nodo menos cargado y se copia en \u00e9l la base de datos. La base de datos se replica en los nodos, pero solo una parte se procesa en cada nodo. Figura 2: Mecanismo de segmentaci\u00f3n y distribuci\u00f3n de PackageBLAST. 7. CONCLUSI\u00d3N En este art\u00edculo, propusimos y evaluamos PackageBLAST, un servicio grid adaptable de pol\u00edticas m\u00faltiples para ejecutar b\u00fasquedas BLAST maestro/esclavo. PackageBLAST contiene un marco donde el usuario puede elegir o incorporar pol\u00edticas de asignaci\u00f3n. Tambi\u00e9n definimos una estrategia, PSS, que adapta la pol\u00edtica elegida a un entorno de red heterog\u00e9neo y no dedicado. Los resultados recopilados al ejecutar PackageBLAST con 5 pol\u00edticas de asignaci\u00f3n en un banco de pruebas de grid fueron muy buenos. Para comparar una secuencia de ADN real de 10KBP con la base de datos gen\u00e9tica nr, pudimos reducir el tiempo de ejecuci\u00f3n de 30,88 min a 2,11 min. Adem\u00e1s, demostramos que, en nuestro banco de pruebas, no existe una pol\u00edtica de asignaci\u00f3n que siempre logre el mejor rendimiento y eso hace evidente la importancia de proporcionar m\u00faltiples pol\u00edticas. Adem\u00e1s, demostramos que la introducci\u00f3n del PSS gener\u00f3 muy buenos avances en el desempe\u00f1o de algunas pol\u00edticas. Como trabajo futuro, pretendemos ejecutar PackageBLAST en una red geogr\u00e1ficamente dispersa, para evaluar el impacto de las altas latencias de la red en las pol\u00edticas de asignaci\u00f3n y en PSS. Adem\u00e1s, pretendemos brindar soporte para la sincronizaci\u00f3n de bases de datos gen\u00f3micas y operaciones din\u00e1micas de entrada/salida para esclavos.Todas las bases de datos gen\u00e9ticas se colocan est\u00e1ticamente en los nodos de la grilla -LRB- sin replicaci\u00f3n -RRB-. GBTK es una aplicaci\u00f3n maestro/esclavo que recibe las secuencias y el nombre de la base de datos gen\u00e9tica. Luego verifica si el nodo que contiene la base de datos est\u00e1 disponible. Si el nodo no est\u00e1 disponible, se elige el nodo menos cargado y se copia en \u00e9l la base de datos. La base de datos se replica en los nodos, pero solo una parte se procesa en cada nodo. Figura 2: Mecanismo de segmentaci\u00f3n y distribuci\u00f3n de PackageBLAST. 7. CONCLUSI\u00d3N En este art\u00edculo, propusimos y evaluamos PackageBLAST, un servicio grid adaptable de pol\u00edticas m\u00faltiples para ejecutar b\u00fasquedas BLAST maestro/esclavo. PackageBLAST contiene un marco donde el usuario puede elegir o incorporar pol\u00edticas de asignaci\u00f3n. Tambi\u00e9n definimos una estrategia, PSS, que adapta la pol\u00edtica elegida a un entorno de red heterog\u00e9neo y no dedicado. Los resultados recopilados al ejecutar PackageBLAST con 5 pol\u00edticas de asignaci\u00f3n en un banco de pruebas de grid fueron muy buenos. Para comparar una secuencia de ADN real de 10KBP con la base de datos gen\u00e9tica nr, pudimos reducir el tiempo de ejecuci\u00f3n de 30,88 min a 2,11 min. Adem\u00e1s, demostramos que, en nuestro banco de pruebas, no existe una pol\u00edtica de asignaci\u00f3n que siempre logre el mejor rendimiento y eso hace evidente la importancia de proporcionar m\u00faltiples pol\u00edticas. Adem\u00e1s, demostramos que la introducci\u00f3n del PSS gener\u00f3 muy buenos avances en el desempe\u00f1o de algunas pol\u00edticas. Como trabajo futuro, pretendemos ejecutar PackageBLAST en una red geogr\u00e1ficamente dispersa, para evaluar el impacto de las altas latencias de la red en las pol\u00edticas de asignaci\u00f3n y en PSS. Adem\u00e1s, pretendemos brindar soporte para la sincronizaci\u00f3n de bases de datos gen\u00f3micas y operaciones din\u00e1micas de entrada/salida para esclavos.Todas las bases de datos gen\u00e9ticas se colocan est\u00e1ticamente en los nodos de la grilla -LRB- sin replicaci\u00f3n -RRB-. GBTK es una aplicaci\u00f3n maestro/esclavo que recibe las secuencias y el nombre de la base de datos gen\u00e9tica. Luego verifica si el nodo que contiene la base de datos est\u00e1 disponible. Si el nodo no est\u00e1 disponible, se elige el nodo menos cargado y se copia en \u00e9l la base de datos. La base de datos se replica en los nodos, pero solo una parte se procesa en cada nodo. Figura 2: Mecanismo de segmentaci\u00f3n y distribuci\u00f3n de PackageBLAST. 7. CONCLUSI\u00d3N En este art\u00edculo, propusimos y evaluamos PackageBLAST, un servicio grid adaptable de pol\u00edticas m\u00faltiples para ejecutar b\u00fasquedas BLAST maestro/esclavo. PackageBLAST contiene un marco donde el usuario puede elegir o incorporar pol\u00edticas de asignaci\u00f3n. Tambi\u00e9n definimos una estrategia, PSS, que adapta la pol\u00edtica elegida a un entorno de red heterog\u00e9neo y no dedicado. Los resultados recopilados al ejecutar PackageBLAST con 5 pol\u00edticas de asignaci\u00f3n en un banco de pruebas de grid fueron muy buenos. Para comparar una secuencia de ADN real de 10KBP con la base de datos gen\u00e9tica nr, pudimos reducir el tiempo de ejecuci\u00f3n de 30,88 min a 2,11 min. Adem\u00e1s, demostramos que, en nuestro banco de pruebas, no existe una pol\u00edtica de asignaci\u00f3n que siempre logre el mejor rendimiento y eso hace evidente la importancia de proporcionar m\u00faltiples pol\u00edticas. Adem\u00e1s, demostramos que la introducci\u00f3n del PSS gener\u00f3 muy buenos avances en el desempe\u00f1o de algunas pol\u00edticas. Como trabajo futuro, pretendemos ejecutar PackageBLAST en una red geogr\u00e1ficamente dispersa, para evaluar el impacto de las altas latencias de la red en las pol\u00edticas de asignaci\u00f3n y en PSS. Adem\u00e1s, pretendemos brindar soporte para la sincronizaci\u00f3n de bases de datos gen\u00f3micas y operaciones din\u00e1micas de entrada/salida para esclavos.Demostramos que la introducci\u00f3n del PSS gener\u00f3 muy buenos avances en el desempe\u00f1o de algunas pol\u00edticas. Como trabajo futuro, pretendemos ejecutar PackageBLAST en una red geogr\u00e1ficamente dispersa, para evaluar el impacto de las altas latencias de la red en las pol\u00edticas de asignaci\u00f3n y en PSS. Adem\u00e1s, pretendemos brindar soporte para la sincronizaci\u00f3n de bases de datos gen\u00f3micas y operaciones din\u00e1micas de entrada/salida para esclavos.Demostramos que la introducci\u00f3n del PSS gener\u00f3 muy buenos avances en el desempe\u00f1o de algunas pol\u00edticas. Como trabajo futuro, pretendemos ejecutar PackageBLAST en una red geogr\u00e1ficamente dispersa, para evaluar el impacto de las altas latencias de la red en las pol\u00edticas de asignaci\u00f3n y en PSS. Adem\u00e1s, pretendemos brindar soporte para la sincronizaci\u00f3n de bases de datos gen\u00f3micas y operaciones din\u00e1micas de entrada/salida para esclavos.", "keyphrases": ["comparaci\u00f3n de secuencia biol\u00f3gica", "adaptar el servicio de red multipol\u00edtica", "asignaci\u00f3n de tareas", "b\u00fasqueda de explosi\u00f3n", "explosi\u00f3n de paquete", "bioinformaci\u00f3n", "computaci\u00f3n en red", "biolog\u00eda inform\u00e1tica", "proyecto genoma", "base de datos de gineta segmentada", "plataforma heterog\u00e9nea no dedicada", "entorno de red", "pss", "peso del paquete adaptar autoprogramaci\u00f3n"]}
{"file_name": "C-14", "text": "Estrategia de implementaci\u00f3n de sensores para la detecci\u00f3n de objetivos RESUMEN Para monitorear una regi\u00f3n para el cruce del tr\u00e1fico, se pueden implementar sensores para realizar una detecci\u00f3n colaborativa de objetivos. Una red de sensores de este tipo alcanza un cierto nivel de rendimiento de detecci\u00f3n con un coste de implementaci\u00f3n asociado. Este art\u00edculo aborda este problema proponiendo la exposici\u00f3n de la ruta como una medida de la bondad de una implementaci\u00f3n y presenta un enfoque para la implementaci\u00f3n secuencial en pasos. Ilustra que el costo de implementaci\u00f3n se puede minimizar para lograr el rendimiento de detecci\u00f3n deseado eligiendo adecuadamente la cantidad de sensores implementados en cada paso. 1. INTRODUCCI\u00d3N Una red de este tipo se puede utilizar para monitorear el entorno, detectar, clasificar y localizar eventos espec\u00edficos y rastrear objetivos en una regi\u00f3n espec\u00edfica. El despliegue de redes de sensores var\u00eda seg\u00fan la aplicaci\u00f3n considerada. Puede ser predeterminado cuando el entorno es suficientemente conocido y est\u00e1 bajo control, en cuyo caso los sensores pueden colocarse estrat\u00e9gicamente a mano. Este art\u00edculo investiga estrategias de implementaci\u00f3n para redes de sensores que realizan la detecci\u00f3n de objetivos en una regi\u00f3n de inter\u00e9s. Dado que las observaciones locales realizadas por los sensores dependen de su posici\u00f3n, el rendimiento del algoritmo de detecci\u00f3n es funci\u00f3n del despliegue. Una posible medida de la bondad del despliegue para la detecci\u00f3n de objetivos se denomina exposici\u00f3n de trayectoria. Es una medida de la probabilidad de detectar un objetivo que atraviesa la regi\u00f3n siguiendo un camino determinado. Cuanto mayor sea la exposici\u00f3n de la ruta, mejor ser\u00e1 el despliegue. El conjunto de caminos a considerar puede verse limitado por el entorno. Por ejemplo, si se espera que el objetivo siga una carretera, s\u00f3lo se deben considerar los caminos que consisten en las carreteras. En este estudio, se supone que el despliegue es aleatorio, lo que corresponde a muchas aplicaciones pr\u00e1cticas donde la regi\u00f3n a monitorear no es accesible para la colocaci\u00f3n precisa de sensores. El objetivo de este art\u00edculo es determinar la cantidad de sensores que se implementar\u00e1n para llevar a cabo la detecci\u00f3n de objetivos en una regi\u00f3n de inter\u00e9s. Las compensaciones se encuentran entre el rendimiento de la red, el costo de los sensores implementados y el costo de implementar los sensores. Este art\u00edculo est\u00e1 organizado de la siguiente forma: En la secci\u00f3n 2, se propone una definici\u00f3n de exposici\u00f3n del camino y se desarrolla un m\u00e9todo para evaluar la exposici\u00f3n de un camino determinado. En la secci\u00f3n 3, se formula el problema del despliegue aleatorio y se presentan varias soluciones. El art\u00edculo concluye con la secci\u00f3n 7. 7. CONCLUSI\u00d3N Este art\u00edculo aborda el problema del despliegue de sensores en una regi\u00f3n que debe ser monitoreada para detectar intrusiones en objetivos. Se propone y analiza un mecanismo de colaboraci\u00f3n de sensores para realizar la detecci\u00f3n de objetivos para evaluar la exposici\u00f3n de los caminos a trav\u00e9s de la regi\u00f3n. La exposici\u00f3n m\u00ednima se utiliza como medida de la bondad del despliegue, siendo el objetivo maximizar la exposici\u00f3n del camino menos expuesto en la regi\u00f3n. En el caso de que los sensores se coloquen aleatoriamente en una regi\u00f3n a monitorear,Se desarrolla un mecanismo para el despliegue secuencial en pasos. La estrategia consiste en desplegar un n\u00famero limitado de sensores a la vez hasta conseguir la exposici\u00f3n m\u00ednima deseada. La funci\u00f3n de costo utilizada en este estudio depende de la cantidad de sensores implementados en cada paso y del costo de cada implementaci\u00f3n. Mediante simulaci\u00f3n, se evalu\u00f3 la distribuci\u00f3n de la exposici\u00f3n m\u00ednima obtenida mediante el despliegue aleatorio para un n\u00famero variable de sensores desplegados. Estos resultados se utilizaron para evaluar el costo de implementaci\u00f3n de un n\u00famero variable de sensores implementados en cada paso. Descubrimos que la cantidad \u00f3ptima de sensores implementados en cada paso var\u00eda con el costo relativo asignado a la implementaci\u00f3n y los sensores. Los resultados de este estudio se pueden extender a regiones m\u00e1s grandes con diferentes par\u00e1metros objetivo. La soluci\u00f3n propuesta en este art\u00edculo tambi\u00e9n se puede mejorar considerando la implementaci\u00f3n de un n\u00famero variable de sensores en cada paso y este problema de m\u00faltiples variables requiere m\u00e1s investigaci\u00f3n.", "keyphrases": ["detectar objetivo", "red de sensores", "exposici\u00f3n del camino", "n\u00famero de sensores", "despliegue secuencial", "exposici\u00f3n m\u00ednima", "colocaci\u00f3n aleatoria del sensor", "campo sensor", "objetivo decai"]}
{"file_name": "C-6", "text": "Dise\u00f1o e implementaci\u00f3n de un sistema de gesti\u00f3n de contenido distribuido RESUMEN La convergencia de los avances en tecnolog\u00edas de almacenamiento, codificaci\u00f3n y redes nos ha llevado a un entorno donde se almacenan e intercambian rutinariamente enormes cantidades de contenido multimedia continuo entre dispositivos habilitados para la red. Realizar un seguimiento de -LRB- o gestionar -RRB- dicho contenido sigue siendo un desaf\u00edo debido al gran volumen de datos. El almacenamiento de medios continuos ``en vivo'' -LRB- tales como contenido de TV o radio -RRB- se suma a la complejidad en el sentido de que este contenido no tiene un comienzo o un final bien definido y, por lo tanto, es engorroso de manejar. El almacenamiento en red permite que el contenido que l\u00f3gicamente se considera parte de la misma colecci\u00f3n se distribuya a trav\u00e9s de una red, lo que hace que la tarea de gesti\u00f3n de contenidos sea casi imposible de realizar sin un sistema de gesti\u00f3n de contenidos. En este art\u00edculo presentamos el dise\u00f1o y la implementaci\u00f3n del sistema de gesti\u00f3n de contenidos Spectrum, que se ocupa del contenido multimedia enriquecido de forma eficaz en este entorno. Spectrum tiene una arquitectura modular que permite su aplicaci\u00f3n tanto en escenarios independientes como en varios escenarios en red. Un aspecto \u00fanico de Spectrum es que requiere que se apliquen una pol\u00edtica de retenci\u00f3n -LRB- o m\u00e1s -RRB- a cada contenido almacenado en el sistema. Esto significa que no existen pol\u00edticas de desalojo. El contenido al que ya no se le aplica una pol\u00edtica de retenci\u00f3n simplemente se elimina del sistema. Se pueden aplicar f\u00e1cilmente diferentes pol\u00edticas de retenci\u00f3n al mismo contenido, lo que facilita naturalmente el intercambio sin duplicaciones. Este enfoque tambi\u00e9n permite a Spectrum aplicar f\u00e1cilmente al contenido pol\u00edticas basadas en el tiempo, que son componentes b\u00e1sicos necesarios para lidiar con el almacenamiento de medios continuos en vivo. No solo describimos los detalles de la arquitectura Spectrum sino que tambi\u00e9n brindamos casos de uso t\u00edpicos. 1. INTRODUCCI\u00d3N La manipulaci\u00f3n y gesti\u00f3n de contenidos es y siempre ha sido una de las funciones principales de una computadora. Las aplicaciones inform\u00e1ticas iniciales incluyen formateadores de text y compiladores de programas. Inicialmente, el contenido se gestionaba mediante la interacci\u00f3n expl\u00edcita del usuario mediante el uso de archivos y sistemas de archivos. A medida que la tecnolog\u00eda ha avanzado, tanto los tipos de contenido como la forma en que las personas desean utilizarlo han cambiado enormemente. Nuevos tipos de contenido, como flujos multimedia continuos, se han vuelto comunes debido a la convergencia de avances en tecnolog\u00edas de almacenamiento, codificaci\u00f3n y redes. Otro ejemplo es la combinaci\u00f3n de codificaci\u00f3n y tecnolog\u00eda de redes de banda ancha. Esta combinaci\u00f3n ha permitido a los usuarios acceder y compartir contenido multimedia en redes de \u00e1rea local y remota, actuando la propia red como un enorme dep\u00f3sito de datos. La proliferaci\u00f3n de contenido de alta calidad habilitada por estos avances en tecnolog\u00eda de almacenamiento, codificaci\u00f3n y redes crea la necesidad de nuevas formas de manipular y administrar los datos.El objetivo de nuestro trabajo es el almacenamiento de contenido rico en medios y, en particular, el almacenamiento de contenido multimedia continuo, ya sea en formato preempaquetado o \"en vivo\". \u2022 Si bien esto es cierto para todo tipo de contenido, el almacenamiento de contenido multimedia continuo es especialmente problem\u00e1tico. En primer lugar, el contenido multimedia continuo sigue siendo muy exigente en t\u00e9rminos de recursos de almacenamiento, lo que significa que un enfoque sin pol\u00edticas para almacenarlo no funcionar\u00e1 para todos los sistemas excepto para los m\u00e1s peque\u00f1os. En segundo lugar, el almacenamiento de contenido \"en vivo\", como televisi\u00f3n o radio, es inherentemente problem\u00e1tico ya que estas se\u00f1ales son flujos continuos sin puntos finales. Esto significa que antes de que uno pueda siquiera pensar en gestionar dicho contenido, es necesario abstraerlo y convertirlo en algo que pueda manipularse y gestionarse. . Cuando se trata de medios continuos almacenados, existe la necesidad de gestionar dicho contenido tanto a nivel detallado como agregado. Por ejemplo, un usuario individual de PVR que desee conservar s\u00f3lo los aspectos m\u00e1s destacados de un evento deportivo en particular no deber\u00eda tener que almacenar el contenido perteneciente al evento completo. . Como se indic\u00f3 anteriormente, intentar realizar un seguimiento del contenido en un sistema independiente sin un sistema de gesti\u00f3n de contenidos es muy dif\u00edcil. Sin embargo, cuando los dispositivos de almacenamiento reales se distribuyen a trav\u00e9s de una red, la tarea de realizar un seguimiento del contenido es casi imposible. Este escenario es cada vez m\u00e1s com\u00fan en los sistemas de distribuci\u00f3n de contenidos basados \u200b\u200ben redes y es probable que tambi\u00e9n adquiera importancia en escenarios de redes dom\u00e9sticas. Parecer\u00eda claro entonces que se necesita un sistema de gesti\u00f3n de contenidos que pueda manejar eficientemente contenido rico en medios y al mismo tiempo explotar la capacidad de conexi\u00f3n en red de los dispositivos de almacenamiento. Este sistema deber\u00eda permitir el almacenamiento eficiente y el acceso al contenido a trav\u00e9s de dispositivos de almacenamiento en red heterog\u00e9neos seg\u00fan las preferencias del usuario. El sistema de gesti\u00f3n de contenidos debe traducir las preferencias del usuario en pol\u00edticas apropiadas de almacenamiento de bajo nivel y debe permitir que esas preferencias se expresen con un nivel fino de granularidad -LRB- sin requerirlo en general -RRB-. El sistema de gesti\u00f3n de contenidos debe permitir al usuario manipular y razonar sobre -LRB-, es decir, cambiar la pol\u00edtica de almacenamiento asociada con -RRB- el almacenamiento de -LRB- partes de -RRB- contenido multimedia continuo. Abordar este problema de gesti\u00f3n de contenido distribuido es dif\u00edcil debido a la cantidad de requisitos impuestos al sistema. Por ejemplo :. El sistema de gesti\u00f3n de contenidos debe operar en una gran cantidad de sistemas heterog\u00e9neos. En algunos casos, el sistema puede estar administrando contenido almacenado en un sistema de archivos local, mientras que en otros, el contenido puede estar almacenado en un dispositivo de almacenamiento de red independiente. El administrador de contenido puede ser responsable de implementar las pol\u00edticas que utiliza para hacer referencia al contenido o esa funci\u00f3n puede delegarse a una computadora separada. Se necesita una interfaz de programa de aplicaci\u00f3n -LRB- API -RRB- y protocolos de red asociados para que el sistema de gesti\u00f3n de contenidos proporcione una interfaz uniforme. .El sistema de gesti\u00f3n de contenidos debe ser flexible y poder manejar diferentes requisitos para las pol\u00edticas de gesti\u00f3n de contenidos. Estas pol\u00edticas reflejan qu\u00e9 contenido se debe obtener, cu\u00e1ndo se debe recuperar, cu\u00e1nto tiempo se debe conservar y bajo qu\u00e9 circunstancias se debe descartar. Esto significa que el sistema de gesti\u00f3n de contenidos deber\u00eda permitir que m\u00faltiples aplicaciones hagan referencia a contenidos con un amplio conjunto de pol\u00edticas y que todas deber\u00edan funcionar juntas sin problemas. . El sistema de gesti\u00f3n de contenidos debe poder monitorear las referencias de contenido y utilizar esa informaci\u00f3n para colocar el contenido en la ubicaci\u00f3n correcta de la red para un acceso eficiente a las aplicaciones. . El sistema de gesti\u00f3n de contenido debe manejar la interacci\u00f3n entre la poblaci\u00f3n de contenido impl\u00edcito y expl\u00edcito en el borde de la red. . El sistema de contenidos debe poder gestionar de manera eficiente grandes conjuntos de contenidos, incluidos flujos continuos. Debe poder empaquetar este contenido de tal manera que sea conveniente para los usuarios acceder a \u00e9l. Para abordar estos problemas, hemos dise\u00f1ado e implementado la arquitectura del sistema de gesti\u00f3n de contenidos Spectrum. Permite que m\u00faltiples aplicaciones hagan referencia a contenido utilizando diferentes pol\u00edticas. N\u00f3tese que la arquitectura Spectrum supone la existencia de una red de distribuci\u00f3n de contenidos -LRB- CDN -RRB- que puede facilitar la distribuci\u00f3n eficiente de contenidos -LRB- por ejemplo, la arquitectura PRISM CDN -LSB- 2 -RSB- -RRB-. La secci\u00f3n 2 describe la arquitectura de nuestro sistema de gesti\u00f3n de contenidos. En la Secci\u00f3n 3 describimos nuestra implementaci\u00f3n de la arquitectura Spectrum y ejemplos de su uso. 4. TRABAJOS RELACIONADOS Varios autores han abordado el problema de la gesti\u00f3n de contenidos en redes distribuidas. Gran parte del trabajo se centra en el aspecto de gesti\u00f3n de pol\u00edticas. Por ejemplo, en -LSB- 5 -RSB-, se considera el problema de servir contenido multimedia a trav\u00e9s de servidores distribuidos. El contenido se distribuye entre los recursos del servidor en proporci\u00f3n a la demanda de los usuarios mediante un protocolo de difusi\u00f3n de demanda. El rendimiento del esquema se compara mediante simulaci\u00f3n. En -LSB- 1 -RSB- el contenido se distribuye entre subcach\u00e9s. La base de conocimientos de cach\u00e9 permite emplear pol\u00edticas sofisticadas. La simulaci\u00f3n se utiliza para comparar el esquema propuesto con algoritmos de reemplazo conocidos. Nuestro trabajo se diferencia en que estamos considerando m\u00e1s que los aspectos de gesti\u00f3n de pol\u00edticas del problema. Despu\u00e9s de considerar cuidadosamente la funcionalidad requerida para implementar la gesti\u00f3n de contenido en el entorno de red, hemos dividido el sistema en tres funciones simples, a saber, administrador de contenido, administrador de pol\u00edticas y administrador de almacenamiento. Esto nos ha permitido implementar y experimentar f\u00e1cilmente con un sistema prototipo. Otro trabajo relacionado implica los llamados sistemas de recomendaci\u00f3n de TV que se utilizan en PVR para seleccionar autom\u00e1ticamente contenido para los usuarios, por ejemplo -LSB-6-RSB-. Finalmente, en el entorno CDN comercial los proveedores -LRB-, por ejemploCisco y Netapp -RRB- han desarrollado e implementado productos y herramientas de gesti\u00f3n de contenidos. 5. CONCLUSI\u00d3N Y TRABAJO FUTURO En este art\u00edculo presentamos el dise\u00f1o e implementaci\u00f3n de la arquitectura de gesti\u00f3n de contenidos de Spectrum. Spectrum permite aplicar pol\u00edticas de almacenamiento a grandes vol\u00famenes de contenido para facilitar un almacenamiento eficiente. En concreto, el sistema permite aplicar diferentes pol\u00edticas al mismo contenido sin replicaci\u00f3n. Spectrum tambi\u00e9n puede aplicar pol\u00edticas que tengan en cuenta el tiempo y que se ocupen eficazmente del almacenamiento de contenido multimedia continuo. Finalmente, el dise\u00f1o modular de la arquitectura Spectrum permite realizaciones tanto independientes como distribuidas para que el sistema pueda implementarse en una variedad de aplicaciones. Hay una serie de cuestiones abiertas que requerir\u00e1n trabajo futuro. Algunos de estos problemas incluyen: \u2022 Prevemos que Spectrum pueda administrar contenido en sistemas que van desde grandes CDN hasta dispositivos m\u00e1s peque\u00f1os como TiVO -LSB- 8 -RSB-. Para que estos sistemas m\u00e1s peque\u00f1os sean compatibles con Spectrum, necesitar\u00e1n redes y una API externa. Cuando esa API est\u00e9 disponible, tendremos que descubrir c\u00f3mo encajarla en la arquitectura de Spectrum. \u2022 Spectrum nombra el contenido por URL, pero intencionalmente no hemos definido el formato de las URL de Spectrum, c\u00f3mo se relacionan con el nombre real del contenido o c\u00f3mo se deben presentar los nombres y las URL al usuario. \u2022 En este art\u00edculo nos hemos centrado en la gesti\u00f3n de contenidos para objetos de medios continuos. \u2022 Cualquier proyecto que ayude a permitir que el contenido multimedia se comparta f\u00e1cilmente a trav\u00e9s de Internet tendr\u00e1 que superar obst\u00e1culos legales antes de que pueda lograr una aceptaci\u00f3n generalizada. Adaptar Spectrum para cumplir con los requisitos legales probablemente requerir\u00e1 m\u00e1s trabajo t\u00e9cnico.c\u00f3mo se relacionan con el nombre real del contenido, o c\u00f3mo se deben presentar los nombres y las URL al usuario. \u2022 En este art\u00edculo nos hemos centrado en la gesti\u00f3n de contenidos para objetos de medios continuos. \u2022 Cualquier proyecto que ayude a permitir que el contenido multimedia se comparta f\u00e1cilmente a trav\u00e9s de Internet tendr\u00e1 que superar obst\u00e1culos legales antes de que pueda lograr una aceptaci\u00f3n generalizada. Adaptar Spectrum para cumplir con los requisitos legales probablemente requerir\u00e1 m\u00e1s trabajo t\u00e9cnico.c\u00f3mo se relacionan con el nombre real del contenido, o c\u00f3mo se deben presentar los nombres y las URL al usuario. \u2022 En este art\u00edculo nos hemos centrado en la gesti\u00f3n de contenidos para objetos de medios continuos. \u2022 Cualquier proyecto que ayude a permitir que el contenido multimedia se comparta f\u00e1cilmente a trav\u00e9s de Internet tendr\u00e1 que superar obst\u00e1culos legales antes de que pueda lograr una aceptaci\u00f3n generalizada. Adaptar Spectrum para cumplir con los requisitos legales probablemente requerir\u00e1 m\u00e1s trabajo t\u00e9cnico.", "keyphrases": ["sistema de gesti\u00f3n de contenido del espectro", "almacenamiento continuo de medios", "escenario de red dom\u00e9stica", "interfaz de programa de aplicaci\u00f3n", "red de distribuci\u00f3n de contenidos", "ubicaci\u00f3n uniforme de recursos", "gesti\u00f3n pol\u00edtica", "dvr de habilitaci\u00f3n de red", "sistema de bases de datos de alto rendimiento", "gesti\u00f3n del espectro de nivel de operador"]}
{"file_name": "H-11", "text": "Dise\u00f1o \u00f3ptimo laplaciano para la recuperaci\u00f3n de im\u00e1genes RESUMEN La retroalimentaci\u00f3n de relevancia es una t\u00e9cnica poderosa para mejorar el rendimiento de la recuperaci\u00f3n de im\u00e1genes basada en contenido -LRB- CBIR -RRB-. Solicita al usuario juicios de relevancia sobre las im\u00e1genes recuperadas devueltas por los sistemas CBIR. Luego, el etiquetado del usuario se utiliza para aprender un clasificador para distinguir entre im\u00e1genes relevantes e irrelevantes. Sin embargo, es posible que las im\u00e1genes m\u00e1s encontradas no sean las m\u00e1s informativas. Por lo tanto, el desaf\u00edo es determinar qu\u00e9 im\u00e1genes sin etiquetar ser\u00edan las m\u00e1s informativas -LRB- es decir, mejorar\u00edan m\u00e1s el clasificador -RRB- si fueran etiquetadas y utilizadas como muestras de entrenamiento. En este art\u00edculo, proponemos un novedoso algoritmo de aprendizaje activo, llamado Dise\u00f1o \u00d3ptimo Laplaciano -LRB-LOD-RRB-, para la recuperaci\u00f3n de im\u00e1genes con retroalimentaci\u00f3n de relevancia. Nuestro algoritmo se basa en un modelo de regresi\u00f3n que minimiza el error de m\u00ednimos cuadrados en las im\u00e1genes medidas -LRB- o etiquetadas -RRB- y simult\u00e1neamente preserva la estructura geom\u00e9trica local del espacio de la imagen. Espec\u00edficamente, asumimos que si dos im\u00e1genes est\u00e1n lo suficientemente cerca entre s\u00ed, entonces sus medidas -LRB- o sus etiquetas -RRB- tambi\u00e9n lo estar\u00e1n. Al construir un gr\u00e1fico vecino m\u00e1s cercano, la estructura geom\u00e9trica del espacio de la imagen se puede describir mediante el gr\u00e1fico laplaciano. Discutimos c\u00f3mo los resultados del campo del dise\u00f1o experimental \u00f3ptimo pueden usarse para guiar nuestra selecci\u00f3n de un subconjunto de im\u00e1genes que nos brinde la mayor cantidad de informaci\u00f3n. Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisi\u00f3n en la recuperaci\u00f3n de im\u00e1genes de retroalimentaci\u00f3n de relevancia. 1. INTRODUCCI\u00d3N En muchas tareas de aprendizaje autom\u00e1tico y recuperaci\u00f3n de informaci\u00f3n, no faltan datos sin etiquetar, pero las etiquetas son caras. Por lo tanto, el desaf\u00edo es determinar qu\u00e9 muestras sin etiquetar ser\u00edan las m\u00e1s informativas -LRB- es decir, mejorar\u00edan m\u00e1s el clasificador -RRB- si fueran etiquetadas y utilizadas como muestras de entrenamiento. Este problema suele denominarse aprendizaje activo -LSB- 4 -RSB-. Muchas aplicaciones del mundo real se pueden integrar en un marco de aprendizaje activo. En particular, consideramos el problema de la recuperaci\u00f3n de im\u00e1genes basada en contenido impulsada por retroalimentaci\u00f3n de relevancia -LRB- CBIR -RRB- -LSB- 13 -RSB-. La recuperaci\u00f3n de im\u00e1genes basada en contenido ha atra\u00eddo importantes intereses en la \u00faltima d\u00e9cada -LSB- 13 -RSB-. Est\u00e1 motivado por el r\u00e1pido crecimiento de las bases de datos de im\u00e1genes digitales que, a su vez, requieren esquemas de b\u00fasqueda eficientes. En lugar de describir una imagen utilizando text, en estos sistemas una consulta de imagen se describe utilizando una o m\u00e1s im\u00e1genes de ejemplo. Las caracter\u00edsticas visuales de bajo nivel -LRB- color, textura, forma, etc. -RRB- se extraen autom\u00e1ticamente para representar las im\u00e1genes. Para reducir la brecha sem\u00e1ntica, se introduce retroalimentaci\u00f3n de relevancia en CBIR -LSB- 12 -RSB-. En muchos de los sistemas CBIR actuales basados \u200b\u200ben retroalimentaci\u00f3n de relevancia, se requiere que el usuario proporcione sus juicios de relevancia sobre las im\u00e1genes principales devueltas por el sistema.Luego, las im\u00e1genes etiquetadas se utilizan para entrenar un clasificador para separar las im\u00e1genes que coinciden con el concepto de consulta de aquellas que no. Sin embargo, en general, las im\u00e1genes m\u00e1s devueltas pueden no ser las m\u00e1s informativas. En el peor de los casos, todas las im\u00e1genes principales etiquetadas por el usuario pueden ser positivas y, por lo tanto, las t\u00e9cnicas de clasificaci\u00f3n est\u00e1ndar no se pueden aplicar debido a la falta de ejemplos negativos. A diferencia de los problemas de clasificaci\u00f3n est\u00e1ndar en los que las muestras etiquetadas est\u00e1n predeterminadas, en la recuperaci\u00f3n de im\u00e1genes con retroalimentaci\u00f3n de relevancia el sistema puede seleccionar activamente las im\u00e1genes para etiquetar. De este modo, el aprendizaje activo puede introducirse de forma natural en la recuperaci\u00f3n de im\u00e1genes. A pesar de muchas t\u00e9cnicas de aprendizaje activo existentes, Support Vector Machine -LRB- SVM -RRB- aprendizaje activo -LSB- 14 -RSB- y aprendizaje activo basado en regresi\u00f3n -LSB- 1 -RSB- han recibido el mayor inter\u00e9s. La principal desventaja del aprendizaje activo SVM es que el l\u00edmite estimado puede no ser lo suficientemente preciso. Adem\u00e1s, no podr\u00e1 aplicarse al inicio de la recuperaci\u00f3n cuando no haya im\u00e1genes etiquetadas. Algunos otros algoritmos de aprendizaje activo basados \u200b\u200ben SVM se pueden encontrar en -LSB- 7 -RSB-, -LSB- 9 -RSB-. En estad\u00edstica, el problema de seleccionar muestras para etiquetar se suele denominar dise\u00f1o experimental. La muestra x se denomina experimento y su etiqueta y se denomina medici\u00f3n. El estudio del dise\u00f1o experimental \u00f3ptimo -LRB- OED -RRB- -LSB- 1 -RSB- se ocupa del dise\u00f1o de experimentos que se espera minimicen las varianzas de un modelo parametrizado. La intenci\u00f3n del dise\u00f1o experimental \u00f3ptimo suele ser maximizar la confianza en un modelo determinado, minimizar las variaciones de los par\u00e1metros para la identificaci\u00f3n del sistema o minimizar la variaci\u00f3n de salida del modelo. Los enfoques de dise\u00f1o experimental cl\u00e1sicos incluyen el dise\u00f1o \u00f3ptimo A, el dise\u00f1o \u00f3ptimo D y el dise\u00f1o \u00f3ptimo E. Todos estos enfoques se basan en un modelo de regresi\u00f3n de m\u00ednimos cuadrados. En comparaci\u00f3n con los algoritmos de aprendizaje activo basados \u200b\u200ben SVM, los enfoques de dise\u00f1o experimental son mucho m\u00e1s eficientes en el c\u00e1lculo. Sin embargo, este tipo de enfoques solo toma en cuenta los datos medidos -LRB- o etiquetados -RRB- en su funci\u00f3n objetivo, mientras que los datos no medidos -LRB- o no etiquetados -RRB- se ignoran. Benefici\u00e1ndose de los avances recientes en el dise\u00f1o experimental \u00f3ptimo y el aprendizaje semisupervisado, en este art\u00edculo proponemos un novedoso algoritmo de aprendizaje activo para la recuperaci\u00f3n de im\u00e1genes, llamado Dise\u00f1o \u00d3ptimo Laplaciano -LRB-LOD-RRB-. A diferencia de los m\u00e9todos de dise\u00f1o experimental tradicionales cuyas funciones de p\u00e9rdida solo se definen en los puntos medidos, la funci\u00f3n de p\u00e9rdida de nuestro algoritmo LOD propuesto se define tanto en los puntos medidos como en los no medidos. Espec\u00edficamente, introducimos un regularizador que preserva la localidad en la funci\u00f3n de p\u00e9rdida est\u00e1ndar basada en el error de m\u00ednimos cuadrados. La nueva funci\u00f3n de p\u00e9rdida tiene como objetivo encontrar un clasificador que sea localmente lo m\u00e1s fluido posible. En otras palabras, si dos puntos est\u00e1n suficientemente cerca entre s\u00ed en el espacio de entrada, se espera que compartan la misma etiqueta.Una vez definida la funci\u00f3n de p\u00e9rdida, podemos seleccionar los puntos de datos m\u00e1s informativos que se presentan al usuario para su etiquetado. Ser\u00eda importante tener en cuenta que las im\u00e1genes m\u00e1s informativas pueden no ser las im\u00e1genes m\u00e1s devueltas. El resto del documento est\u00e1 organizado de la siguiente manera. En la Secci\u00f3n 2, proporcionamos una breve descripci\u00f3n del trabajo relacionado. Nuestro algoritmo de dise\u00f1o \u00f3ptimo laplaciano propuesto se presenta en la Secci\u00f3n 3. En la Secci\u00f3n 4, comparamos nuestro algoritmo con los algoritmos m\u00e1s modernos y presentamos los resultados experimentales sobre la recuperaci\u00f3n de im\u00e1genes. Finalmente, proporcionamos algunos comentarios finales y sugerencias para trabajos futuros en la Secci\u00f3n 5. 2. TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresi\u00f3n. El trabajo m\u00e1s relacionado es el dise\u00f1o experimental \u00f3ptimo -LSB- 1 -RSB-, incluyendo A-Optimal Design, D-Optimal Design y EOptimal Design. En esta secci\u00f3n, damos una breve descripci\u00f3n de estos enfoques. 2.1 El problema del aprendizaje activo El problema gen\u00e9rico del aprendizaje activo es el siguiente. En otras palabras, los puntos zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- pueden mejorar m\u00e1s el clasificador si se etiquetan y utilizan como puntos de entrenamiento. 2.2 Dise\u00f1o Experimental \u00d3ptimo Consideramos un modelo de regresi\u00f3n lineal. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales \u03c32. Por lo tanto, la estimaci\u00f3n de m\u00e1xima verosimilitud para el vector de peso, \u02c6w, es la que minimiza el error de suma al cuadrado. Las tres medidas escalares m\u00e1s comunes del tama\u00f1o de la matriz de covarianza de par\u00e1metros en el dise\u00f1o experimental \u00f3ptimo son: \u2022 Dise\u00f1o D-\u00f3ptimo: determinante de Hsse . \u2022 Dise\u00f1o A-\u00f3ptimo: traza de Hsse. \u2022 Dise\u00f1o E-\u00f3ptimo: valor propio m\u00e1ximo de Hsse. Dado que el c\u00e1lculo del determinante y los valores propios de una matriz es mucho m\u00e1s costoso que el c\u00e1lculo de la traza de la matriz, el dise\u00f1o A-\u00f3ptimo es m\u00e1s eficiente que los otros dos. Algunos trabajos recientes sobre dise\u00f1o experimental se pueden encontrar en -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONES Y TRABAJO FUTURO Este art\u00edculo describe un novedoso algoritmo de aprendizaje activo, llamado Dise\u00f1o \u00d3ptimo Laplaciano, para permitir una recuperaci\u00f3n de im\u00e1genes con retroalimentaci\u00f3n de relevancia m\u00e1s efectiva. Nuestro algoritmo se basa en una funci\u00f3n objetivo que simult\u00e1neamente minimiza el error emp\u00edrico y preserva la estructura geom\u00e9trica local del espacio de datos. Utilizando t\u00e9cnicas de dise\u00f1o experimental, nuestro algoritmo encuentra las im\u00e1genes m\u00e1s informativas para etiquetar. Estas im\u00e1genes etiquetadas y las im\u00e1genes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semisupervisado pueden mejorar significativamente el rendimiento de la recuperaci\u00f3n. En este art\u00edculo, consideramos el problema de recuperaci\u00f3n de im\u00e1genes en datos de im\u00e1genes peque\u00f1as, est\u00e1ticas y de dominio cerrado. Para la b\u00fasqueda de im\u00e1genes web, es posible recopilar una gran cantidad de informaci\u00f3n sobre los clics del usuario. Esta informaci\u00f3n se puede utilizar de forma natural para construir el gr\u00e1fico de afinidad en nuestro algoritmo.Podemos seleccionar los puntos de datos m\u00e1s informativos que se presentan al usuario para su etiquetado. Ser\u00eda importante tener en cuenta que las im\u00e1genes m\u00e1s informativas pueden no ser las im\u00e1genes m\u00e1s devueltas. El resto del documento est\u00e1 organizado de la siguiente manera. En la Secci\u00f3n 2, proporcionamos una breve descripci\u00f3n del trabajo relacionado. Nuestro algoritmo de dise\u00f1o \u00f3ptimo laplaciano propuesto se presenta en la Secci\u00f3n 3. En la Secci\u00f3n 4, comparamos nuestro algoritmo con los algoritmos m\u00e1s modernos y presentamos los resultados experimentales sobre la recuperaci\u00f3n de im\u00e1genes. Finalmente, proporcionamos algunos comentarios finales y sugerencias para trabajos futuros en la Secci\u00f3n 5. 2. TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresi\u00f3n. El trabajo m\u00e1s relacionado es el dise\u00f1o experimental \u00f3ptimo -LSB- 1 -RSB-, incluyendo A-Optimal Design, D-Optimal Design y EOptimal Design. En esta secci\u00f3n, damos una breve descripci\u00f3n de estos enfoques. 2.1 El problema del aprendizaje activo El problema gen\u00e9rico del aprendizaje activo es el siguiente. En otras palabras, los puntos zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- pueden mejorar m\u00e1s el clasificador si se etiquetan y utilizan como puntos de entrenamiento. 2.2 Dise\u00f1o Experimental \u00d3ptimo Consideramos un modelo de regresi\u00f3n lineal. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales \u03c32. Por lo tanto, la estimaci\u00f3n de m\u00e1xima verosimilitud para el vector de peso, \u02c6w, es la que minimiza el error de suma al cuadrado. Las tres medidas escalares m\u00e1s comunes del tama\u00f1o de la matriz de covarianza de par\u00e1metros en el dise\u00f1o experimental \u00f3ptimo son: \u2022 Dise\u00f1o D-\u00f3ptimo: determinante de Hsse . \u2022 Dise\u00f1o A-\u00f3ptimo: traza de Hsse. \u2022 Dise\u00f1o E-\u00f3ptimo: valor propio m\u00e1ximo de Hsse. Dado que el c\u00e1lculo del determinante y los valores propios de una matriz es mucho m\u00e1s costoso que el c\u00e1lculo de la traza de la matriz, el dise\u00f1o A-\u00f3ptimo es m\u00e1s eficiente que los otros dos. Algunos trabajos recientes sobre dise\u00f1o experimental se pueden encontrar en -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONES Y TRABAJO FUTURO Este art\u00edculo describe un novedoso algoritmo de aprendizaje activo, llamado Dise\u00f1o \u00d3ptimo Laplaciano, para permitir una recuperaci\u00f3n de im\u00e1genes con retroalimentaci\u00f3n de relevancia m\u00e1s efectiva. Nuestro algoritmo se basa en una funci\u00f3n objetivo que simult\u00e1neamente minimiza el error emp\u00edrico y preserva la estructura geom\u00e9trica local del espacio de datos. Utilizando t\u00e9cnicas de dise\u00f1o experimental, nuestro algoritmo encuentra las im\u00e1genes m\u00e1s informativas para etiquetar. Estas im\u00e1genes etiquetadas y las im\u00e1genes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semisupervisado pueden mejorar significativamente el rendimiento de la recuperaci\u00f3n. En este art\u00edculo, consideramos el problema de recuperaci\u00f3n de im\u00e1genes en datos de im\u00e1genes peque\u00f1as, est\u00e1ticas y de dominio cerrado. Para la b\u00fasqueda de im\u00e1genes web, es posible recopilar una gran cantidad de informaci\u00f3n sobre los clics del usuario. Esta informaci\u00f3n se puede utilizar de forma natural para construir el gr\u00e1fico de afinidad en nuestro algoritmo.Podemos seleccionar los puntos de datos m\u00e1s informativos que se presentan al usuario para su etiquetado. Ser\u00eda importante tener en cuenta que las im\u00e1genes m\u00e1s informativas pueden no ser las im\u00e1genes m\u00e1s devueltas. El resto del documento est\u00e1 organizado de la siguiente manera. En la Secci\u00f3n 2, proporcionamos una breve descripci\u00f3n del trabajo relacionado. Nuestro algoritmo de dise\u00f1o \u00f3ptimo laplaciano propuesto se presenta en la Secci\u00f3n 3. En la Secci\u00f3n 4, comparamos nuestro algoritmo con los algoritmos m\u00e1s modernos y presentamos los resultados experimentales sobre la recuperaci\u00f3n de im\u00e1genes. Finalmente, proporcionamos algunos comentarios finales y sugerencias para trabajos futuros en la Secci\u00f3n 5. 2. TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresi\u00f3n. El trabajo m\u00e1s relacionado es el dise\u00f1o experimental \u00f3ptimo -LSB- 1 -RSB-, incluyendo A-Optimal Design, D-Optimal Design y EOptimal Design. En esta secci\u00f3n, damos una breve descripci\u00f3n de estos enfoques. 2.1 El problema del aprendizaje activo El problema gen\u00e9rico del aprendizaje activo es el siguiente. En otras palabras, los puntos zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- pueden mejorar m\u00e1s el clasificador si se etiquetan y utilizan como puntos de entrenamiento. 2.2 Dise\u00f1o Experimental \u00d3ptimo Consideramos un modelo de regresi\u00f3n lineal. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales \u03c32. Por lo tanto, la estimaci\u00f3n de m\u00e1xima verosimilitud para el vector de peso, \u02c6w, es la que minimiza el error de suma al cuadrado. Las tres medidas escalares m\u00e1s comunes del tama\u00f1o de la matriz de covarianza de par\u00e1metros en el dise\u00f1o experimental \u00f3ptimo son: \u2022 Dise\u00f1o D-\u00f3ptimo: determinante de Hsse . \u2022 Dise\u00f1o A-\u00f3ptimo: traza de Hsse. \u2022 Dise\u00f1o E-\u00f3ptimo: valor propio m\u00e1ximo de Hsse. Dado que el c\u00e1lculo del determinante y los valores propios de una matriz es mucho m\u00e1s costoso que el c\u00e1lculo de la traza de la matriz, el dise\u00f1o A-\u00f3ptimo es m\u00e1s eficiente que los otros dos. Algunos trabajos recientes sobre dise\u00f1o experimental se pueden encontrar en -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONES Y TRABAJO FUTURO Este art\u00edculo describe un novedoso algoritmo de aprendizaje activo, llamado Dise\u00f1o \u00d3ptimo Laplaciano, para permitir una recuperaci\u00f3n de im\u00e1genes con retroalimentaci\u00f3n de relevancia m\u00e1s efectiva. Nuestro algoritmo se basa en una funci\u00f3n objetivo que simult\u00e1neamente minimiza el error emp\u00edrico y preserva la estructura geom\u00e9trica local del espacio de datos. Utilizando t\u00e9cnicas de dise\u00f1o experimental, nuestro algoritmo encuentra las im\u00e1genes m\u00e1s informativas para etiquetar. Estas im\u00e1genes etiquetadas y las im\u00e1genes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semisupervisado pueden mejorar significativamente el rendimiento de la recuperaci\u00f3n. En este art\u00edculo, consideramos el problema de recuperaci\u00f3n de im\u00e1genes en datos de im\u00e1genes peque\u00f1as, est\u00e1ticas y de dominio cerrado. Para la b\u00fasqueda de im\u00e1genes web, es posible recopilar una gran cantidad de informaci\u00f3n sobre los clics del usuario. Esta informaci\u00f3n se puede utilizar de forma natural para construir el gr\u00e1fico de afinidad en nuestro algoritmo.El resto del documento est\u00e1 organizado de la siguiente manera. En la Secci\u00f3n 2, proporcionamos una breve descripci\u00f3n del trabajo relacionado. Nuestro algoritmo de dise\u00f1o \u00f3ptimo laplaciano propuesto se presenta en la Secci\u00f3n 3. En la Secci\u00f3n 4, comparamos nuestro algoritmo con los algoritmos m\u00e1s modernos y presentamos los resultados experimentales sobre la recuperaci\u00f3n de im\u00e1genes. Finalmente, proporcionamos algunos comentarios finales y sugerencias para trabajos futuros en la Secci\u00f3n 5. 2. TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresi\u00f3n. El trabajo m\u00e1s relacionado es el dise\u00f1o experimental \u00f3ptimo -LSB- 1 -RSB-, incluyendo A-Optimal Design, D-Optimal Design y EOptimal Design. En esta secci\u00f3n, damos una breve descripci\u00f3n de estos enfoques. 2.1 El problema del aprendizaje activo El problema gen\u00e9rico del aprendizaje activo es el siguiente. En otras palabras, los puntos zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- pueden mejorar m\u00e1s el clasificador si se etiquetan y utilizan como puntos de entrenamiento. 2.2 Dise\u00f1o Experimental \u00d3ptimo Consideramos un modelo de regresi\u00f3n lineal. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales \u03c32. Por lo tanto, la estimaci\u00f3n de m\u00e1xima verosimilitud para el vector de peso, \u02c6w, es la que minimiza el error de suma al cuadrado. Las tres medidas escalares m\u00e1s comunes del tama\u00f1o de la matriz de covarianza de par\u00e1metros en el dise\u00f1o experimental \u00f3ptimo son: \u2022 Dise\u00f1o D-\u00f3ptimo: determinante de Hsse . \u2022 Dise\u00f1o A-\u00f3ptimo: traza de Hsse. \u2022 Dise\u00f1o E-\u00f3ptimo: valor propio m\u00e1ximo de Hsse. Dado que el c\u00e1lculo del determinante y los valores propios de una matriz es mucho m\u00e1s costoso que el c\u00e1lculo de la traza de la matriz, el dise\u00f1o A-\u00f3ptimo es m\u00e1s eficiente que los otros dos. Algunos trabajos recientes sobre dise\u00f1o experimental se pueden encontrar en -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONES Y TRABAJO FUTURO Este art\u00edculo describe un novedoso algoritmo de aprendizaje activo, llamado Dise\u00f1o \u00d3ptimo Laplaciano, para permitir una recuperaci\u00f3n de im\u00e1genes con retroalimentaci\u00f3n de relevancia m\u00e1s efectiva. Nuestro algoritmo se basa en una funci\u00f3n objetivo que simult\u00e1neamente minimiza el error emp\u00edrico y preserva la estructura geom\u00e9trica local del espacio de datos. Utilizando t\u00e9cnicas de dise\u00f1o experimental, nuestro algoritmo encuentra las im\u00e1genes m\u00e1s informativas para etiquetar. Estas im\u00e1genes etiquetadas y las im\u00e1genes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semisupervisado pueden mejorar significativamente el rendimiento de la recuperaci\u00f3n. En este art\u00edculo, consideramos el problema de recuperaci\u00f3n de im\u00e1genes en datos de im\u00e1genes peque\u00f1as, est\u00e1ticas y de dominio cerrado. Para la b\u00fasqueda de im\u00e1genes web, es posible recopilar una gran cantidad de informaci\u00f3n sobre los clics del usuario. Esta informaci\u00f3n se puede utilizar de forma natural para construir el gr\u00e1fico de afinidad en nuestro algoritmo.El resto del documento est\u00e1 organizado de la siguiente manera. En la Secci\u00f3n 2, proporcionamos una breve descripci\u00f3n del trabajo relacionado. Nuestro algoritmo de dise\u00f1o \u00f3ptimo laplaciano propuesto se presenta en la Secci\u00f3n 3. En la Secci\u00f3n 4, comparamos nuestro algoritmo con los algoritmos m\u00e1s modernos y presentamos los resultados experimentales sobre la recuperaci\u00f3n de im\u00e1genes. Finalmente, proporcionamos algunos comentarios finales y sugerencias para trabajos futuros en la Secci\u00f3n 5. 2. TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresi\u00f3n. El trabajo m\u00e1s relacionado es el dise\u00f1o experimental \u00f3ptimo -LSB- 1 -RSB-, incluyendo A-Optimal Design, D-Optimal Design y EOptimal Design. En esta secci\u00f3n, damos una breve descripci\u00f3n de estos enfoques. 2.1 El problema del aprendizaje activo El problema gen\u00e9rico del aprendizaje activo es el siguiente. En otras palabras, los puntos zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- pueden mejorar m\u00e1s el clasificador si se etiquetan y utilizan como puntos de entrenamiento. 2.2 Dise\u00f1o Experimental \u00d3ptimo Consideramos un modelo de regresi\u00f3n lineal. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales \u03c32. Por lo tanto, la estimaci\u00f3n de m\u00e1xima verosimilitud para el vector de peso, \u02c6w, es la que minimiza el error de suma al cuadrado. Las tres medidas escalares m\u00e1s comunes del tama\u00f1o de la matriz de covarianza de par\u00e1metros en el dise\u00f1o experimental \u00f3ptimo son: \u2022 Dise\u00f1o D-\u00f3ptimo: determinante de Hsse . \u2022 Dise\u00f1o A-\u00f3ptimo: traza de Hsse. \u2022 Dise\u00f1o E-\u00f3ptimo: valor propio m\u00e1ximo de Hsse. Dado que el c\u00e1lculo del determinante y los valores propios de una matriz es mucho m\u00e1s costoso que el c\u00e1lculo de la traza de la matriz, el dise\u00f1o A-\u00f3ptimo es m\u00e1s eficiente que los otros dos. Algunos trabajos recientes sobre dise\u00f1o experimental se pueden encontrar en -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONES Y TRABAJO FUTURO Este art\u00edculo describe un novedoso algoritmo de aprendizaje activo, llamado Dise\u00f1o \u00d3ptimo Laplaciano, para permitir una recuperaci\u00f3n de im\u00e1genes con retroalimentaci\u00f3n de relevancia m\u00e1s efectiva. Nuestro algoritmo se basa en una funci\u00f3n objetivo que simult\u00e1neamente minimiza el error emp\u00edrico y preserva la estructura geom\u00e9trica local del espacio de datos. Utilizando t\u00e9cnicas de dise\u00f1o experimental, nuestro algoritmo encuentra las im\u00e1genes m\u00e1s informativas para etiquetar. Estas im\u00e1genes etiquetadas y las im\u00e1genes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semisupervisado pueden mejorar significativamente el rendimiento de la recuperaci\u00f3n. En este art\u00edculo, consideramos el problema de recuperaci\u00f3n de im\u00e1genes en datos de im\u00e1genes peque\u00f1as, est\u00e1ticas y de dominio cerrado. Para la b\u00fasqueda de im\u00e1genes web, es posible recopilar una gran cantidad de informaci\u00f3n sobre los clics del usuario. Esta informaci\u00f3n se puede utilizar de forma natural para construir el gr\u00e1fico de afinidad en nuestro algoritmo.Comparamos nuestro algoritmo con los algoritmos m\u00e1s modernos y presentamos los resultados experimentales sobre la recuperaci\u00f3n de im\u00e1genes. Finalmente, proporcionamos algunos comentarios finales y sugerencias para trabajos futuros en la Secci\u00f3n 5. 2. TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresi\u00f3n. El trabajo m\u00e1s relacionado es el dise\u00f1o experimental \u00f3ptimo -LSB- 1 -RSB-, incluyendo A-Optimal Design, D-Optimal Design y EOptimal Design. En esta secci\u00f3n, damos una breve descripci\u00f3n de estos enfoques. 2.1 El problema del aprendizaje activo El problema gen\u00e9rico del aprendizaje activo es el siguiente. En otras palabras, los puntos zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- pueden mejorar m\u00e1s el clasificador si se etiquetan y utilizan como puntos de entrenamiento. 2.2 Dise\u00f1o Experimental \u00d3ptimo Consideramos un modelo de regresi\u00f3n lineal. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales \u03c32. Por lo tanto, la estimaci\u00f3n de m\u00e1xima verosimilitud para el vector de peso, \u02c6w, es la que minimiza el error de suma al cuadrado. Las tres medidas escalares m\u00e1s comunes del tama\u00f1o de la matriz de covarianza de par\u00e1metros en el dise\u00f1o experimental \u00f3ptimo son: \u2022 Dise\u00f1o D-\u00f3ptimo: determinante de Hsse . \u2022 Dise\u00f1o A-\u00f3ptimo: traza de Hsse. \u2022 Dise\u00f1o E-\u00f3ptimo: valor propio m\u00e1ximo de Hsse. Dado que el c\u00e1lculo del determinante y los valores propios de una matriz es mucho m\u00e1s costoso que el c\u00e1lculo de la traza de la matriz, el dise\u00f1o A-\u00f3ptimo es m\u00e1s eficiente que los otros dos. Algunos trabajos recientes sobre dise\u00f1o experimental se pueden encontrar en -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONES Y TRABAJO FUTURO Este art\u00edculo describe un novedoso algoritmo de aprendizaje activo, llamado Dise\u00f1o \u00d3ptimo Laplaciano, para permitir una recuperaci\u00f3n de im\u00e1genes con retroalimentaci\u00f3n de relevancia m\u00e1s efectiva. Nuestro algoritmo se basa en una funci\u00f3n objetivo que simult\u00e1neamente minimiza el error emp\u00edrico y preserva la estructura geom\u00e9trica local del espacio de datos. Utilizando t\u00e9cnicas de dise\u00f1o experimental, nuestro algoritmo encuentra las im\u00e1genes m\u00e1s informativas para etiquetar. Estas im\u00e1genes etiquetadas y las im\u00e1genes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semisupervisado pueden mejorar significativamente el rendimiento de la recuperaci\u00f3n. En este art\u00edculo, consideramos el problema de recuperaci\u00f3n de im\u00e1genes en datos de im\u00e1genes peque\u00f1as, est\u00e1ticas y de dominio cerrado. Para la b\u00fasqueda de im\u00e1genes web, es posible recopilar una gran cantidad de informaci\u00f3n sobre los clics del usuario. Esta informaci\u00f3n se puede utilizar de forma natural para construir el gr\u00e1fico de afinidad en nuestro algoritmo.Comparamos nuestro algoritmo con los algoritmos m\u00e1s modernos y presentamos los resultados experimentales sobre la recuperaci\u00f3n de im\u00e1genes. Finalmente, proporcionamos algunos comentarios finales y sugerencias para trabajos futuros en la Secci\u00f3n 5. 2. TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresi\u00f3n. El trabajo m\u00e1s relacionado es el dise\u00f1o experimental \u00f3ptimo -LSB- 1 -RSB-, incluyendo A-Optimal Design, D-Optimal Design y EOptimal Design. En esta secci\u00f3n, damos una breve descripci\u00f3n de estos enfoques. 2.1 El problema del aprendizaje activo El problema gen\u00e9rico del aprendizaje activo es el siguiente. En otras palabras, los puntos zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- pueden mejorar m\u00e1s el clasificador si se etiquetan y utilizan como puntos de entrenamiento. 2.2 Dise\u00f1o Experimental \u00d3ptimo Consideramos un modelo de regresi\u00f3n lineal. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales \u03c32. Por lo tanto, la estimaci\u00f3n de m\u00e1xima verosimilitud para el vector de peso, \u02c6w, es la que minimiza el error de suma al cuadrado. Las tres medidas escalares m\u00e1s comunes del tama\u00f1o de la matriz de covarianza de par\u00e1metros en el dise\u00f1o experimental \u00f3ptimo son: \u2022 Dise\u00f1o D-\u00f3ptimo: determinante de Hsse . \u2022 Dise\u00f1o A-\u00f3ptimo: traza de Hsse. \u2022 Dise\u00f1o E-\u00f3ptimo: valor propio m\u00e1ximo de Hsse. Dado que el c\u00e1lculo del determinante y los valores propios de una matriz es mucho m\u00e1s costoso que el c\u00e1lculo de la traza de la matriz, el dise\u00f1o A-\u00f3ptimo es m\u00e1s eficiente que los otros dos. Algunos trabajos recientes sobre dise\u00f1o experimental se pueden encontrar en -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONES Y TRABAJO FUTURO Este art\u00edculo describe un novedoso algoritmo de aprendizaje activo, llamado Dise\u00f1o \u00d3ptimo Laplaciano, para permitir una recuperaci\u00f3n de im\u00e1genes con retroalimentaci\u00f3n de relevancia m\u00e1s efectiva. Nuestro algoritmo se basa en una funci\u00f3n objetivo que simult\u00e1neamente minimiza el error emp\u00edrico y preserva la estructura geom\u00e9trica local del espacio de datos. Utilizando t\u00e9cnicas de dise\u00f1o experimental, nuestro algoritmo encuentra las im\u00e1genes m\u00e1s informativas para etiquetar. Estas im\u00e1genes etiquetadas y las im\u00e1genes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semisupervisado pueden mejorar significativamente el rendimiento de la recuperaci\u00f3n. En este art\u00edculo, consideramos el problema de recuperaci\u00f3n de im\u00e1genes en datos de im\u00e1genes peque\u00f1as, est\u00e1ticas y de dominio cerrado. Para la b\u00fasqueda de im\u00e1genes web, es posible recopilar una gran cantidad de informaci\u00f3n sobre los clics del usuario. Esta informaci\u00f3n se puede utilizar de forma natural para construir el gr\u00e1fico de afinidad en nuestro algoritmo.los puntos zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- pueden mejorar m\u00e1s el clasificador si se etiquetan y utilizan como puntos de entrenamiento. 2.2 Dise\u00f1o Experimental \u00d3ptimo Consideramos un modelo de regresi\u00f3n lineal. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales \u03c32. Por lo tanto, la estimaci\u00f3n de m\u00e1xima verosimilitud para el vector de peso, \u02c6w, es la que minimiza el error de suma al cuadrado. Las tres medidas escalares m\u00e1s comunes del tama\u00f1o de la matriz de covarianza de par\u00e1metros en el dise\u00f1o experimental \u00f3ptimo son: \u2022 Dise\u00f1o D-\u00f3ptimo: determinante de Hsse . \u2022 Dise\u00f1o A-\u00f3ptimo: traza de Hsse. \u2022 Dise\u00f1o E-\u00f3ptimo: valor propio m\u00e1ximo de Hsse. Dado que el c\u00e1lculo del determinante y los valores propios de una matriz es mucho m\u00e1s costoso que el c\u00e1lculo de la traza de la matriz, el dise\u00f1o A-\u00f3ptimo es m\u00e1s eficiente que los otros dos. Algunos trabajos recientes sobre dise\u00f1o experimental se pueden encontrar en -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONES Y TRABAJO FUTURO Este art\u00edculo describe un novedoso algoritmo de aprendizaje activo, llamado Dise\u00f1o \u00d3ptimo Laplaciano, para permitir una recuperaci\u00f3n de im\u00e1genes con retroalimentaci\u00f3n de relevancia m\u00e1s efectiva. Nuestro algoritmo se basa en una funci\u00f3n objetivo que simult\u00e1neamente minimiza el error emp\u00edrico y preserva la estructura geom\u00e9trica local del espacio de datos. Utilizando t\u00e9cnicas de dise\u00f1o experimental, nuestro algoritmo encuentra las im\u00e1genes m\u00e1s informativas para etiquetar. Estas im\u00e1genes etiquetadas y las im\u00e1genes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semisupervisado pueden mejorar significativamente el rendimiento de la recuperaci\u00f3n. En este art\u00edculo, consideramos el problema de recuperaci\u00f3n de im\u00e1genes en datos de im\u00e1genes peque\u00f1as, est\u00e1ticas y de dominio cerrado. Para la b\u00fasqueda de im\u00e1genes web, es posible recopilar una gran cantidad de informaci\u00f3n sobre los clics del usuario. Esta informaci\u00f3n se puede utilizar de forma natural para construir el gr\u00e1fico de afinidad en nuestro algoritmo.los puntos zi -LRB- i = 1, \u00b7 \u00b7 \u00b7, k -RRB- pueden mejorar m\u00e1s el clasificador si se etiquetan y utilizan como puntos de entrenamiento. 2.2 Dise\u00f1o Experimental \u00d3ptimo Consideramos un modelo de regresi\u00f3n lineal. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales \u03c32. Por lo tanto, la estimaci\u00f3n de m\u00e1xima verosimilitud para el vector de peso, \u02c6w, es la que minimiza el error de suma al cuadrado. Las tres medidas escalares m\u00e1s comunes del tama\u00f1o de la matriz de covarianza de par\u00e1metros en el dise\u00f1o experimental \u00f3ptimo son: \u2022 Dise\u00f1o D-\u00f3ptimo: determinante de Hsse . \u2022 Dise\u00f1o A-\u00f3ptimo: traza de Hsse. \u2022 Dise\u00f1o E-\u00f3ptimo: valor propio m\u00e1ximo de Hsse. Dado que el c\u00e1lculo del determinante y los valores propios de una matriz es mucho m\u00e1s costoso que el c\u00e1lculo de la traza de la matriz, el dise\u00f1o A-\u00f3ptimo es m\u00e1s eficiente que los otros dos. Algunos trabajos recientes sobre dise\u00f1o experimental se pueden encontrar en -LSB- 6 -RSB-, -LSB- 16 -RSB-. 7. CONCLUSIONES Y TRABAJO FUTURO Este art\u00edculo describe un novedoso algoritmo de aprendizaje activo, llamado Dise\u00f1o \u00d3ptimo Laplaciano, para permitir una recuperaci\u00f3n de im\u00e1genes con retroalimentaci\u00f3n de relevancia m\u00e1s efectiva. Nuestro algoritmo se basa en una funci\u00f3n objetivo que simult\u00e1neamente minimiza el error emp\u00edrico y preserva la estructura geom\u00e9trica local del espacio de datos. Utilizando t\u00e9cnicas de dise\u00f1o experimental, nuestro algoritmo encuentra las im\u00e1genes m\u00e1s informativas para etiquetar. Estas im\u00e1genes etiquetadas y las im\u00e1genes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semisupervisado pueden mejorar significativamente el rendimiento de la recuperaci\u00f3n. En este art\u00edculo, consideramos el problema de recuperaci\u00f3n de im\u00e1genes en datos de im\u00e1genes peque\u00f1as, est\u00e1ticas y de dominio cerrado. Para la b\u00fasqueda de im\u00e1genes web, es posible recopilar una gran cantidad de informaci\u00f3n sobre los clics del usuario. Esta informaci\u00f3n se puede utilizar de forma natural para construir el gr\u00e1fico de afinidad en nuestro algoritmo.Nuestro algoritmo se basa en una funci\u00f3n objetivo que simult\u00e1neamente minimiza el error emp\u00edrico y preserva la estructura geom\u00e9trica local del espacio de datos. Utilizando t\u00e9cnicas de dise\u00f1o experimental, nuestro algoritmo encuentra las im\u00e1genes m\u00e1s informativas para etiquetar. Estas im\u00e1genes etiquetadas y las im\u00e1genes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semisupervisado pueden mejorar significativamente el rendimiento de la recuperaci\u00f3n. En este art\u00edculo, consideramos el problema de recuperaci\u00f3n de im\u00e1genes en datos de im\u00e1genes peque\u00f1as, est\u00e1ticas y de dominio cerrado. Para la b\u00fasqueda de im\u00e1genes web, es posible recopilar una gran cantidad de informaci\u00f3n sobre los clics del usuario. Esta informaci\u00f3n se puede utilizar de forma natural para construir el gr\u00e1fico de afinidad en nuestro algoritmo.Nuestro algoritmo se basa en una funci\u00f3n objetivo que simult\u00e1neamente minimiza el error emp\u00edrico y preserva la estructura geom\u00e9trica local del espacio de datos. Utilizando t\u00e9cnicas de dise\u00f1o experimental, nuestro algoritmo encuentra las im\u00e1genes m\u00e1s informativas para etiquetar. Estas im\u00e1genes etiquetadas y las im\u00e1genes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semisupervisado pueden mejorar significativamente el rendimiento de la recuperaci\u00f3n. En este art\u00edculo, consideramos el problema de recuperaci\u00f3n de im\u00e1genes en datos de im\u00e1genes peque\u00f1as, est\u00e1ticas y de dominio cerrado. Para la b\u00fasqueda de im\u00e1genes web, es posible recopilar una gran cantidad de informaci\u00f3n sobre los clics del usuario. Esta informaci\u00f3n se puede utilizar de forma natural para construir el gr\u00e1fico de afinidad en nuestro algoritmo.", "keyphrases": ["retroalimentaci\u00f3n relevante", "imagen representa", "recuperaci\u00f3n de im\u00e1genes de contentbas", "aprendizaje activo", "modelo de regresi\u00f3n de m\u00ednimos cuadrados", "dise\u00f1o de experimento \u00f3ptimo", "imagen de retorno superior", "tasa precisa", "estructura geom\u00e9trica intr\u00ednseca", "reconocer patten", "etiqueta"]}
{"file_name": "J-27", "text": "Aprendiendo de la preferencia revelada RESUMEN Una secuencia de precios y demandas es racionalizable si existe una funci\u00f3n de utilidad c\u00f3ncava, continua y mon\u00f3tona tal que las demandas sean los maximizadores de la funci\u00f3n de utilidad sobre el conjunto presupuestario correspondiente al precio. Afriat -LSB- 1 -RSB- present\u00f3 condiciones necesarias y suficientes para que una secuencia finita fuera racionalizable. Varian -LSB- 20 -RSB- y posteriormente Blundell et al. -LSB- 3, 4 -RSB- continu\u00f3 esta l\u00ednea de trabajo estudiando m\u00e9todos no param\u00e9tricos para pronosticar la demanda. Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no llegan a dar un grado general de confianza en el pron\u00f3stico. El presente art\u00edculo complementa esta l\u00ednea de investigaci\u00f3n al introducir un modelo estad\u00edstico y una medida de complejidad a trav\u00e9s de la cual podemos estudiar la capacidad de aprendizaje de clases de funciones de demanda y derivar un grado de confianza en los pron\u00f3sticos. Nuestros resultados muestran que la clase de todas las funciones de demanda tiene una complejidad ilimitada y, por lo tanto, no se puede aprender, pero que existen clases interesantes y potencialmente \u00fatiles que se pueden aprender a partir de muestras finitas. Tambi\u00e9n presentamos un algoritmo de aprendizaje que es una adaptaci\u00f3n de una nueva demostraci\u00f3n del teorema de Afriat debida a Teo y Vohra -LSB- 17 -RSB-. 1. INTRODUCCI\u00d3N La relaci\u00f3n de preferencia es, por tanto, el factor clave para comprender el comportamiento del consumidor. Uno de los supuestos comunes en esta teor\u00eda es que la relaci\u00f3n de preferencia est\u00e1 representada por una funci\u00f3n de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricci\u00f3n presupuestaria. Este patr\u00f3n de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teor\u00eda del consumidor. Adem\u00e1s, como explicamos en la secci\u00f3n 2, las observaciones b\u00e1sicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de utilidad son mon\u00f3tonas y c\u00f3ncavas. Esto nos lleva a la pregunta, planteada por primera vez por Samuelson -LSB- 18 -RSB-, \u00bfhasta qu\u00e9 punto es refutable esta teor\u00eda? Dadas las observaciones de precio y demanda, \u00bfbajo qu\u00e9 circunstancias podemos concluir que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una funci\u00f3n de utilidad c\u00f3ncava mon\u00f3tona y sujeto a una restricci\u00f3n presupuestaria? Samuelson dio una condici\u00f3n necesaria pero insuficiente sobre la preferencia subyacente conocida como el axioma d\u00e9bil de la preferencia revelada. Uzawa -LSB- 16 -RSB- y Mas-Colell -LSB- 10, 11 -RSB- introdujeron una noci\u00f3n de ingreso-Lipschitz y demostraron que las funciones de demanda con esta propiedad son racionalizables. Estas propiedades no requieren ning\u00fan supuesto param\u00e9trico y son t\u00e9cnicamente refutables, pero suponen el conocimiento de toda la funci\u00f3n de demanda y dependen en gran medida de las propiedades diferenciales de las funciones de demanda. Por tanto, se necesita una cantidad infinita de informaci\u00f3n para refutar la teor\u00eda. A menudo ocurre que, adem\u00e1s de las observaciones de la demanda, hay informaci\u00f3n adicional sobre el sistema y es sensato hacer suposiciones param\u00e9tricas, a saber,estipular alguna forma funcional de utilidad. La coherencia con la maximizaci\u00f3n de la utilidad depender\u00eda entonces de fijar los par\u00e1metros de la funci\u00f3n de utilidad para que sean coherentes con las observaciones y con un conjunto de ecuaciones llamadas ecuaciones de Slutski. Si tales par\u00e1metros existen, concluimos que la forma de utilidad estipulada es consistente con las observaciones. Este enfoque es \u00fatil cuando hay razones para hacer estas estipulaciones; proporciona una funci\u00f3n de utilidad expl\u00edcita que puede usarse para hacer pron\u00f3sticos precisos sobre la demanda de precios no observados. La desventaja de este enfoque es que los datos de la vida real a menudo son inconsistentes con las formas funcionales convenientes. Adem\u00e1s, si las observaciones son inconsistentes, no est\u00e1 claro si se trata de una refutaci\u00f3n de la forma funcional estipulada o de una maximizaci\u00f3n de la utilidad. Pregunta cu\u00e1ndo se puede determinar que un conjunto finito de observaciones es consistente con la maximizaci\u00f3n de la utilidad sin hacer suposiciones param\u00e9tricas. Muestra que la racionalizabilidad de un conjunto finito de observaciones es equivalente al axioma fuerte de la preferencia revelada. Richter -LSB- 15 -RSB- muestra que el axioma fuerte de preferencia revelada es equivalente a la racionalizabilidad mediante una funci\u00f3n de utilidad mon\u00f3tona estrictamente c\u00f3ncava. Afriat -LSB- 1 -RSB- proporciona otro conjunto de condiciones de racionalizaci\u00f3n que las observaciones deben satisfacer. Varian -LSB- 20 -RSB- introduce el axioma generalizado de preferencia revelada -LRB- GARP -RRB-, una forma equivalente de la condici\u00f3n de consistencia de Afriat que es m\u00e1s f\u00e1cil de verificar computacionalmente. Afriat -LSB- 1 -RSB- demostr\u00f3 su teorema mediante la construcci\u00f3n expl\u00edcita de una funci\u00f3n de utilidad que atestigua la coherencia. Varian -LSB- 20 -RSB- dio un paso m\u00e1s y pas\u00f3 de la coherencia a la previsi\u00f3n. El algoritmo de pron\u00f3stico de Varian b\u00e1sicamente descarta los paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP. Adem\u00e1s, introduce la \"m\u00e9trica monetaria\" de Samuelson como una funci\u00f3n de utilidad can\u00f3nica y proporciona funciones de utilidad envolvente superior e inferior para la m\u00e9trica monetaria. Knoblauch -LSB- 9 -RSB- muestra que estas envolventes se pueden calcular de manera eficiente. Blundell et al. presentan un enfoque diferente. -LSB- 3, 4 -RSB-. Estos art\u00edculos presentan un modelo en el que un agente observa los precios y las curvas de Engel para estos precios. Esto mejora los l\u00edmites originales de Varian, aunque la idea b\u00e1sica sigue siendo descartar las demandas que se revelan inferiores. Este modelo es en cierto sentido un h\u00edbrido entre los enfoques de Mas-Colell y Afriat. El primero requiere informaci\u00f3n completa para todos los precios, el segundo para un n\u00famero finito de precios. Por otro lado, el enfoque adoptado por Blundell et al. requiere informaci\u00f3n completa s\u00f3lo sobre un n\u00famero finito de trayectorias de precios. Diferentes segmentos de la poblaci\u00f3n enfrentan los mismos precios con diferentes presupuestos, y por mucho que los datos agregados puedan atestiguar sobre las preferencias individuales,Muestre c\u00f3mo var\u00eda la demanda con el presupuesto. Aplicando m\u00e9todos estad\u00edsticos no param\u00e9tricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y la utilizan para obtener l\u00edmites m\u00e1s estrictos. Lo m\u00e1s probable es que ambos m\u00e9todos proporcionen un buen pron\u00f3stico para una funci\u00f3n de demanda fija despu\u00e9s de un n\u00famero suficiente de observaciones, suponiendo que estuvieran distribuidas de manera razonable. Sin embargo, estos m\u00e9todos no consideran la complejidad de las funciones de demanda y no utilizan ning\u00fan modelo probabil\u00edstico de las observaciones. Por lo tanto, no pueden proporcionar ninguna estimaci\u00f3n del n\u00famero de observaciones que ser\u00edan suficientes para un buen pron\u00f3stico o del grado de confianza en dicho pron\u00f3stico. En este art\u00edculo examinamos la viabilidad de pronosticar la demanda con un alto grado de confianza utilizando las condiciones de Afriat. Formulamos la pregunta en t\u00e9rminos de si la clase de funciones de demanda derivadas de utilidades c\u00f3ncavas mon\u00f3tonas se puede aprender de manera eficiente mediante PAC. Nuestro primer resultado es negativo. Demostramos, al calcular la dimensi\u00f3n de destrucci\u00f3n de grasa, que sin ning\u00fan supuesto previo, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad c\u00f3ncavas mon\u00f3tonas es demasiado rico para poder aprenderlo de manera eficiente mediante PAC. Sin embargo, bajo algunos supuestos previos sobre el conjunto de funciones de demanda, mostramos que la dimensi\u00f3n de destrucci\u00f3n de grasa es finita y, por lo tanto, los conjuntos correspondientes se pueden aprender mediante PAC. En la secci\u00f3n 2 analizamos brevemente los supuestos b\u00e1sicos de la teor\u00eda de la demanda y sus implicaciones. En la secci\u00f3n 3 presentamos una nueva prueba del teorema de Afriat que incorpora un algoritmo para generar eficientemente una funci\u00f3n de pron\u00f3stico debido a Teo y Vohra -LSB- 17 -RSB-. Mostramos que este algoritmo es computacionalmente eficiente y puede usarse como algoritmo de aprendizaje. En la secci\u00f3n 4 damos una breve introducci\u00f3n al aprendizaje de PAC que incluye varias modificaciones para aprender funciones con valores vectoriales reales. Tambi\u00e9n dibujamos resultados en los l\u00edmites superiores. En la secci\u00f3n 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensi\u00f3n destructiva de la clase de todas las funciones de demanda y una clase de funciones de demanda de Lipschitz de ingreso con una constante de Lipschitz de ingreso global acotada.Formulamos la pregunta en t\u00e9rminos de si la clase de funciones de demanda derivadas de utilidades c\u00f3ncavas mon\u00f3tonas se puede aprender de manera eficiente mediante PAC. Nuestro primer resultado es negativo. Demostramos, al calcular la dimensi\u00f3n de destrucci\u00f3n de grasa, que sin ning\u00fan supuesto previo, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad c\u00f3ncavas mon\u00f3tonas es demasiado rico para poder aprenderlo de manera eficiente mediante PAC. Sin embargo, bajo algunos supuestos previos sobre el conjunto de funciones de demanda, mostramos que la dimensi\u00f3n de destrucci\u00f3n de grasa es finita y, por lo tanto, los conjuntos correspondientes se pueden aprender mediante PAC. En la secci\u00f3n 2 analizamos brevemente los supuestos b\u00e1sicos de la teor\u00eda de la demanda y sus implicaciones. En la secci\u00f3n 3 presentamos una nueva prueba del teorema de Afriat que incorpora un algoritmo para generar eficientemente una funci\u00f3n de pron\u00f3stico debido a Teo y Vohra -LSB- 17 -RSB-. Mostramos que este algoritmo es computacionalmente eficiente y puede usarse como algoritmo de aprendizaje. En la secci\u00f3n 4 damos una breve introducci\u00f3n al aprendizaje de PAC que incluye varias modificaciones para aprender funciones con valores vectoriales reales. Tambi\u00e9n dibujamos resultados en l\u00edmites superiores. En la secci\u00f3n 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensi\u00f3n destructiva de la clase de todas las funciones de demanda y una clase de funciones de demanda de Lipschitz de ingreso con una constante de Lipschitz de ingreso global acotada.Formulamos la pregunta en t\u00e9rminos de si la clase de funciones de demanda derivadas de utilidades c\u00f3ncavas mon\u00f3tonas se puede aprender de manera eficiente mediante PAC. Nuestro primer resultado es negativo. Demostramos, al calcular la dimensi\u00f3n de destrucci\u00f3n de grasa, que sin ning\u00fan supuesto previo, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad c\u00f3ncavas mon\u00f3tonas es demasiado rico para poder aprenderlo de manera eficiente mediante PAC. Sin embargo, bajo algunos supuestos previos sobre el conjunto de funciones de demanda, mostramos que la dimensi\u00f3n de destrucci\u00f3n de grasa es finita y, por lo tanto, los conjuntos correspondientes se pueden aprender mediante PAC. En la secci\u00f3n 2 analizamos brevemente los supuestos b\u00e1sicos de la teor\u00eda de la demanda y sus implicaciones. En la secci\u00f3n 3 presentamos una nueva prueba del teorema de Afriat que incorpora un algoritmo para generar eficientemente una funci\u00f3n de pron\u00f3stico debido a Teo y Vohra -LSB- 17 -RSB-. Mostramos que este algoritmo es computacionalmente eficiente y puede usarse como algoritmo de aprendizaje. En la secci\u00f3n 4 damos una breve introducci\u00f3n al aprendizaje de PAC que incluye varias modificaciones para aprender funciones con valores vectoriales reales. Tambi\u00e9n dibujamos resultados en l\u00edmites superiores. En la secci\u00f3n 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensi\u00f3n destructiva de la clase de todas las funciones de demanda y una clase de funciones de demanda de Lipschitz de ingreso con una constante de Lipschitz de ingreso global acotada.", "keyphrases": ["aprender de revelar preferir", "problema complejo", "pron\u00f3stico", "probablemente aproximadamente correcto", "funci\u00f3n \u00fatil c\u00f3ncava mon\u00f3tona", "funci\u00f3n de demanda", "racionalizar", "conjunto finito de observaciones", "incom-lipschitz", "dimensiones de grasa destrozada"]}
{"file_name": "C-18", "text": "Un an\u00e1lisis inicial y una presentaci\u00f3n de malware que exhibe un comportamiento similar al de un enjambre RESUMEN Se observ\u00f3 que Slammer, que actualmente es el gusano inform\u00e1tico m\u00e1s r\u00e1pido registrado en la historia, infecta el 90 por ciento de todos los hosts vulnerables de Internet en 10 minutos. Aunque la acci\u00f3n principal que realiza el gusano Slammer es una replicaci\u00f3n relativamente sencilla de s\u00ed mismo, a\u00fan as\u00ed se propaga tan r\u00e1pidamente que la respuesta humana fue ineficaz. La mayor\u00eda de las estrategias de contramedidas propuestas se basan principalmente en algoritmos de detecci\u00f3n y limitaci\u00f3n de tasas. Sin embargo, se est\u00e1n dise\u00f1ando y desarrollando estrategias de este tipo para contener eficazmente gusanos cuyo comportamiento es similar al de Slammer. En nuestro trabajo, planteamos la hip\u00f3tesis de que los gusanos de la pr\u00f3xima generaci\u00f3n ser\u00e1n radicalmente diferentes y que, potencialmente, dichas t\u00e9cnicas resultar\u00e1n ineficaces. Espec\u00edficamente, proponemos estudiar una nueva generaci\u00f3n de gusanos llamados ''Swarm Worms'', cuyo comportamiento se basa en el concepto de ''inteligencia emergente''. La Inteligencia Emergente es el comportamiento de sistemas, muy parecido a los sistemas biol\u00f3gicos como las hormigas o las abejas, donde interacciones locales simples de miembros aut\u00f3nomos, con acciones primitivas simples, dan lugar a un comportamiento global complejo e inteligente. En este manuscrito presentaremos los principios b\u00e1sicos detr\u00e1s de la idea de '' Gusanos de enjambre '', as\u00ed como la estructura b\u00e1sica requerida para ser considerado un '' Gusano de enjambre ''. Adem\u00e1s, presentaremos resultados preliminares sobre las velocidades de propagaci\u00f3n de uno de esos gusanos enjambre, llamado gusano ZachiK. Demostraremos que ZachiK es capaz de propagarse a un ritmo 2 \u00f3rdenes de magnitud m\u00e1s r\u00e1pido que gusanos similares sin capacidad de enjambre. 1. INTRODUCCI\u00d3N Y TRABAJOS ANTERIORES En las primeras horas de la ma\u00f1ana -LRB- 05:30 GMT -RRB- del 25 de enero de 2003 el gusano inform\u00e1tico m\u00e1s r\u00e1pido de la historia comenz\u00f3 a propagarse por Internet. Desde Slammer, los investigadores han explorado el comportamiento de los gusanos que se propagan r\u00e1pidamente y han dise\u00f1ado estrategias de contramedida basadas principalmente en algoritmos de limitaci\u00f3n y detecci\u00f3n de velocidad. Por ejemplo, Zou, et al., -LSB- 2 -RSB-, propusieron un esquema en el que se utiliza un filtro de Kalman para detectar la propagaci\u00f3n temprana de un gusano. Es decir, se est\u00e1n dise\u00f1ando y desarrollando sistemas para contener eficazmente gusanos cuyo comportamiento es similar al de Slammer. En el trabajo descrito aqu\u00ed, planteamos la hip\u00f3tesis de que los gusanos de la pr\u00f3xima generaci\u00f3n ser\u00e1n diferentes y, por lo tanto, dichas t\u00e9cnicas pueden tener algunas limitaciones importantes. Espec\u00edficamente, proponemos estudiar una nueva generaci\u00f3n de gusanos llamados ''Swarm Worms'', cuyo comportamiento se basa en el concepto de ''inteligencia emergente''. El concepto de inteligencia emergente se estudi\u00f3 por primera vez en asociaci\u00f3n con los sistemas biol\u00f3gicos. En tales estudios, los primeros investigadores descubrieron una variedad de comportamientos interesantes de insectos o animales en la naturaleza. Una bandada de p\u00e1jaros surca el cielo. En general,Este tipo de movimiento agregado se ha denominado \"comportamiento de enjambre\". '' Los bi\u00f3logos e inform\u00e1ticos en el campo de la inteligencia artificial han estudiado estos enjambres biol\u00f3gicos e intentaron crear modelos que expliquen c\u00f3mo los elementos de un enjambre interact\u00faan, logran objetivos y evolucionan. Los conceptos b\u00e1sicos que se han desarrollado durante la \u00faltima d\u00e9cada para explicar los \"enjambres y el comportamiento de los enjambres\" incluyen cuatro componentes b\u00e1sicos. Estos son: 1. Simplicidad de l\u00f3gica y acciones: un enjambre est\u00e1 compuesto por N agentes cuya inteligencia es limitada. Los agentes del enjambre utilizan reglas locales simples para gobernar sus acciones. Algunos modelos llamaron a esto acciones o comportamientos primitivos; 2. Mecanismos de comunicaci\u00f3n local: los agentes interact\u00faan con otros miembros del enjambre a trav\u00e9s de mecanismos de comunicaci\u00f3n \"locales\" simples. Por ejemplo, un p\u00e1jaro en una bandada detecta la posici\u00f3n del p\u00e1jaro adyacente y aplica una regla simple de evitar y seguir. 3. 4. ''Inteligencia emergente'': El comportamiento agregado de agentes aut\u00f3nomos da como resultado comportamientos ''inteligentes'' complejos; incluida la autoorganizaci\u00f3n ''. Para comprender completamente el comportamiento de tales enjambres es necesario construir un modelo que explique el comportamiento de lo que llamaremos gusanos gen\u00e9ricos. Este modelo, que ampl\u00eda el trabajo de Weaver -LSB- 5 -RSB-, se presenta aqu\u00ed en el apartado 2. Adem\u00e1s, pretendemos ampliar dicho modelo de tal forma que explique claramente los comportamientos de esta nueva clase de gusanos potencialmente peligrosos. llamados gusanos de enjambre. Los gusanos de enjambre se comportan de manera muy parecida a los enjambres biol\u00f3gicos y exhiben un alto grado de aprendizaje, comunicaci\u00f3n e inteligencia distribuida. Estos gusanos de enjambre son potencialmente m\u00e1s da\u00f1inos que sus hom\u00f3logos gen\u00e9ricos similares. Espec\u00edficamente, se cre\u00f3 la primera instancia, hasta donde sabemos, de un gusano de aprendizaje de este tipo, llamado ZachiK. ZachiK es un gusano enjambre sencillo para descifrar contrase\u00f1as que incorpora diferentes estrategias de aprendizaje e intercambio de informaci\u00f3n. Un gusano de enjambre de este tipo se implement\u00f3 en una red de \u00e1rea local de treinta hosts -LRB- 30 -RRB- y se simul\u00f3 en una topolog\u00eda de 10.000 nodos. Los resultados preliminares mostraron que estos gusanos son capaces de comprometer a sus hu\u00e9spedes a un ritmo hasta dos \u00f3rdenes de magnitud m\u00e1s r\u00e1pido que su contraparte gen\u00e9rica. El resto de este manuscrito est\u00e1 estructurado de la siguiente manera. En la secci\u00f3n 2 se presenta un modelo abstracto tanto de gusanos gen\u00e9ricos como de gusanos de enjambre. Este modelo se utiliza en la secci\u00f3n 2.6 para describir el primer caso de un gusano enjambre, ZachiK. En la secci\u00f3n 4 se presentan los resultados preliminares tanto de mediciones emp\u00edricas como de simulaci\u00f3n. Finalmente, en la secci\u00f3n 5 se presentan nuestras conclusiones y reflexiones sobre el trabajo futuro. 5. RESUMEN Y TRABAJO FUTURO En este manuscrito, hemos presentado un modelo abstracto, similar en algunos aspectos al de Weaver -LSB- 5 -RSB-, que ayuda a explicar la naturaleza gen\u00e9rica de los gusanos.El modelo presentado en la secci\u00f3n 2 se ampli\u00f3 para incorporar una nueva clase de gusanos potencialmente peligrosos llamados Swarm Worms. Los gusanos de enjambre se comportan de manera muy parecida a los enjambres biol\u00f3gicos y exhiben un alto grado de aprendizaje, comunicaci\u00f3n e inteligencia distribuida. Estos gusanos de enjambre son potencialmente m\u00e1s da\u00f1inos que sus hom\u00f3logos gen\u00e9ricos. Adem\u00e1s, hasta donde sabemos, se cre\u00f3 la primera instancia de un gusano de aprendizaje de este tipo, llamado ZachiK. ZachiK es un gusano enjambre sencillo para descifrar contrase\u00f1as que incorpora diferentes estrategias de aprendizaje e intercambio de informaci\u00f3n. Un gusano de enjambre de este tipo se implement\u00f3 en una red de \u00e1rea local de treinta hosts -LRB- 30 -RRB- y se simul\u00f3 en una topolog\u00eda de 10.000 nodos. Los resultados preliminares mostraron que estos gusanos son capaces de comprometer los hosts a un ritmo hasta 2 \u00f3rdenes de magnitud m\u00e1s r\u00e1pido que su contraparte gen\u00e9rica, manteniendo al mismo tiempo sus capacidades de sigilo. Este trabajo abre una nueva \u00e1rea de problemas interesantes. Algunos de los problemas m\u00e1s interesantes y apremiantes a considerar son los siguientes: \u2022 \u00bfEs posible aplicar algunos de los conceptos de aprendizaje desarrollados durante los \u00faltimos diez a\u00f1os en las \u00e1reas de inteligencia de enjambre, sistemas de agentes y control distribuido al dise\u00f1o de sistemas de enjambre sofisticados? gusanos de tal manera que se produzca un verdadero comportamiento emergente? \u2022 \u00bfLas t\u00e9cnicas actuales que se est\u00e1n desarrollando en el dise\u00f1o de sistemas de detecci\u00f3n y contramedidas de intrusiones y sistemas de supervivencia son efectivas contra esta nueva clase de gusanos? ; y \u2022 \u00bfQu\u00e9 t\u00e9cnicas, si es que hay alguna, pueden desarrollarse para crear defensas contra los gusanos de enjambre?\u00bfSe puede desarrollar para crear defensas contra los gusanos de enjambre?\u00bfSe puede desarrollar para crear defensas contra los gusanos de enjambre?", "keyphrases": ["malwar", "gusano enjambre", "inteligencia emergente", "gusano portazo", "mec\u00e1nico comunal local", "zachik", "m\u00e9todo prng", "lista de objetivos pregenerados", "distribuir inteligencia", "detecci\u00f3n de intrusos", "sistema de contramedidas"]}
{"file_name": "J-26", "text": "Agencia combinatoria RESUMEN Muchas investigaciones recientes se refieren a sistemas, como Internet, cuyos componentes pertenecen y son operados por diferentes partes, cada una con su propio objetivo \"ego\u00edsta\". El campo del Dise\u00f1o de Mecanismos Algor\u00edtmicos maneja la cuesti\u00f3n de la informaci\u00f3n privada en poder de las diferentes partes en dichos entornos computacionales. Este art\u00edculo aborda un problema complementario en tales contexts: el manejo de las ``acciones ocultas'' que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del problema cl\u00e1sico del agente principal de la teor\u00eda econ\u00f3mica. En nuestro entorno, un director debe motivar a un equipo de agentes estrat\u00e9gicos para que realicen esfuerzos costosos en su nombre, pero sus acciones le son ocultas. Nos centramos en casos en los que combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes ofreci\u00e9ndoles un conjunto de contratos, que en conjunto colocan a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un an\u00e1lisis de algunas cuestiones b\u00e1sicas, pero dejamos muchas preguntas abiertas. 1. INTRODUCCI\u00d3N 1.1 Antecedentes Una de las caracter\u00edsticas m\u00e1s sorprendentes de las redes inform\u00e1ticas modernas (en particular Internet) es que diferentes partes de ellas pertenecen a diferentes individuos, empresas y organizaciones y son operadas por ellos. Por lo tanto, el an\u00e1lisis y dise\u00f1o de protocolos para este entorno naturalmente necesita tener en cuenta los diferentes intereses econ\u00f3micos \"ego\u00edstas\" de los diferentes participantes. En particular, el campo del dise\u00f1o de mecanismos algor\u00edtmicos -LSB-6-RSB- utiliza incentivos apropiados para ``extraer'' la informaci\u00f3n privada de los participantes. Este art\u00edculo aborda el desconocimiento complementario, el de las acciones ocultas. En muchos casos, los comportamientos reales (acciones) de los diferentes participantes est\u00e1n \"ocultos\" para los dem\u00e1s y s\u00f3lo influyen indirectamente en el resultado final. \u00bfC\u00f3mo podemos garantizar que los diferentes servidores realicen realmente la combinaci\u00f3n correcta de asignaciones? Una clase relacionada de ejemplos se refiere a cuestiones de seguridad: cada `` enlace '' en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger alguna propiedad de seguridad deseada del sistema. \u00bfC\u00f3mo podemos asegurar que se alcance el nivel deseado de 5. ASPECTOS ALGOR\u00cdTMICOS Nuestro an\u00e1lisis a lo largo del art\u00edculo arroja algo de luz sobre los aspectos algor\u00edtmicos del c\u00e1lculo del mejor contrato. En esta secci\u00f3n exponemos estas implicaciones -LRB- para las pruebas ver -LSB- 2 -RSB- -RRB-. Primero consideramos el modelo general donde la funci\u00f3n tecnol\u00f3gica est\u00e1 dada por una funci\u00f3n mon\u00f3tona arbitraria t -LRB- con valores racionales -RRB-, y luego consideramos el caso de tecnolog\u00edas estructuradas dadas por una representaci\u00f3n de red de la funci\u00f3n booleana subyacente. 5.1 Tecnolog\u00edas de acci\u00f3n binaria de resultado binario Aqu\u00ed asumimos que se nos da una tecnolog\u00eda y un valor v como entrada, y nuestra salida debe ser el contrato \u00f3ptimo, es decirel conjunto S* de agentes a contratar y el contrato pi para cada i ES*. En el caso general, la funci\u00f3n de \u00e9xito t es de tama\u00f1o exponencial en n, el n\u00famero de agentes, y tendremos que ocuparnos de eso. En el caso especial de tecnolog\u00edas an\u00f3nimas, la descripci\u00f3n de t es s\u00f3lo los n +1 n\u00fameros t0,..., tn, y en este caso nuestro an\u00e1lisis en la secci\u00f3n 3 es completamente suficiente para calcular el contrato \u00f3ptimo. \u2022 La \u00f3rbita de la tecnolog\u00eda tanto en el caso de agencia como en los casos no estrat\u00e9gicos. \u2022 Un contrato \u00f3ptimo para cualquier valor v dado, tanto para el caso de agencia como para el caso no estrat\u00e9gico. \u2022 El precio de la irresponsabilidad POU -LRB- t,~c -RRB-. PRUEBA. Probamos las afirmaciones para el caso no an\u00f3nimo, la prueba para el caso an\u00f3nimo es similar. Primero mostramos c\u00f3mo construir la \u00f3rbita de la tecnolog\u00eda -LRB-, se aplica el mismo procedimiento en ambos casos -RRB-. Para construir la \u00f3rbita encontramos todos los puntos de transici\u00f3n y los conjuntos que est\u00e1n en la \u00f3rbita. El contrato vac\u00edo siempre es \u00f3ptimo para v = 0. Supongamos que hemos calculado los contratos \u00f3ptimos y los puntos de transici\u00f3n hasta alg\u00fan punto de transici\u00f3n v para el cual S es un contrato \u00f3ptimo con la mayor probabilidad de \u00e9xito. Mostramos c\u00f3mo calcular el siguiente punto de transici\u00f3n y el siguiente contrato \u00f3ptimo. Seg\u00fan el Lema 3, el siguiente contrato en la \u00f3rbita -LRB- para valores m\u00e1s altos -RRB- tiene una mayor probabilidad de \u00e9xito -LRB-, no hay dos conjuntos con la misma probabilidad de \u00e9xito en la \u00f3rbita -RRB-. Calculamos el siguiente contrato \u00f3ptimo mediante el siguiente procedimiento. Repasamos todos los conjuntos T tales que t -LRB- T -RRB- > t -LRB- S -RRB-, y calculamos el valor para el cual el principal es indiferente entre contratar con T y contratar con S. El valor m\u00ednimo de indiferencia es el siguiente punto de transici\u00f3n y el contrato que tiene el valor m\u00ednimo de indiferencia es el siguiente contrato \u00f3ptimo. La linealidad de la utilidad en el valor y la monotonicidad de la probabilidad de \u00e9xito de los contratos \u00f3ptimos aseguran que lo anterior funcione. Claramente, el c\u00e1lculo anterior es polin\u00f3mico en el tama\u00f1o de entrada. Una vez que tenemos la \u00f3rbita, est\u00e1 claro que se puede calcular un contrato \u00f3ptimo para cualquier valor v dado. Encontramos el punto de transici\u00f3n m\u00e1s grande que no es mayor que el valor v, y el contrato \u00f3ptimo en v es el conjunto con mayor probabilidad de \u00e9xito en este punto de transici\u00f3n. Finalmente, como podemos calcular la \u00f3rbita de la tecnolog\u00eda tanto en el caso de agencia como en el no estrat\u00e9gico en tiempo polin\u00f3mico, podemos encontrar el precio de la falta de rendici\u00f3n de cuentas en tiempo polin\u00f3mico. Seg\u00fan el Lema 1, el precio de la falta de rendici\u00f3n de cuentas POU -LRB- t -RRB- se obtiene en alg\u00fan punto de transici\u00f3n, por lo que s\u00f3lo necesitamos repasar todos los puntos de transici\u00f3n y encontrar aquel que tenga el \u00edndice de bienestar social m\u00e1ximo. Una pregunta m\u00e1s interesante es si, dada la funci\u00f3n t como una caja negra, podemos calcular el contrato \u00f3ptimo en el tiempo que sea polin\u00f3mico en n. Podemos demostrar que, en general, este no es el caso: TEOREMA 5.Dado como entrada una caja negra para una funci\u00f3n de \u00e9xito t -LRB- cuando los costos son id\u00e9nticos -RRB-, y un valor v, el n\u00famero de consultas que se necesitan, en el peor de los casos, para encontrar el contrato \u00f3ptimo es exponencial en n . PRUEBA. Considere la siguiente familia de tecnolog\u00edas. Para algunos peque\u00f1os e > 0 y k = -LSB- n/2 -RSB- definimos la probabilidad de \u00e9xito para un conjunto T dado de la siguiente manera. Si el algoritmo consulta como m\u00e1ximo -LRB- n -RRB- -- 2 conjuntos fin/2 -RSB- de tama\u00f1o k, entonces no siempre puede determinar el contrato \u00f3ptimo -LRB- como cualquiera de los conjuntos que no ha consultado. podr\u00eda ser el \u00f3ptimo -RRB-. Concluimos que -LRB- n -RRB- -- 1 consultas fin/2 -RSB- son necesarias para determinar el contrato \u00f3ptimo, y esto es exponencial en n. 5.2 Tecnolog\u00edas estructuradas En esta secci\u00f3n consideraremos la representaci\u00f3n natural de redes de lectura \u00fanica para la funci\u00f3n booleana subyacente. Por lo tanto, el problema que abordaremos ser\u00e1: El problema del contrato \u00f3ptimo para redes de lectura \u00fanica: Entrada: Una red de lectura \u00fanica G = -LRB- V, E -RRB-, con dos v\u00e9rtices espec\u00edficos s, t; valores racionales - ye, \u03b4e para cada jugador e \u2208 E -LRB- y ce = 1 -RRB-, y un valor racional v. Salida: Un conjunto S de agentes que deber\u00edan contratarse en un contrato \u00f3ptimo. Sea t -LRB- E -RRB- la probabilidad de \u00e9xito cuando cada arista tiene \u00e9xito con probabilidad \u03b4e. Primero notamos que incluso calcular el valor t -LRB- E -RRB- es un problema dif\u00edcil: se llama problema de confiabilidad de la red y se sabe que es #P \u2212 dif\u00edcil -LSB- 8 -RSB-. Un peque\u00f1o esfuerzo revelar\u00e1 que nuestro problema no es m\u00e1s f\u00e1cil: TEOREMA 6. El problema del contrato \u00f3ptimo para redes de lectura \u00fanica es #P - dif\u00edcil -LRB- bajo reducciones de Turing -RRB-. PRUEBA. Demostraremos que se puede utilizar un algoritmo para este problema para resolver el problema de confiabilidad de la red. Dada una instancia de un problema de confiabilidad de red < G, -LCB- -LRB- e -RCB- eEE > -LRB- donde -LRB- e denota la probabilidad de \u00e9xito de e -RRB-, definimos una instancia del contrato \u00f3ptimo problema de la siguiente manera: primero defina un nuevo gr\u00e1fico G ' que se obtiene '' Y '' haciendo G con un nuevo jugador x, con - yx muy cerca de 21 y \u03b4x = 1 \u2212 - yx. Una vez que encontramos dicho valor, elegimos - yx st c 1 -- 2\u03b3x es mayor que ese valor -RRB-. Denotemos \u03b2x = 1 \u2212 2-yx. El valor cr\u00edtico de v donde el jugador x ingresa el contrato \u00f3ptimo de G', se puede encontrar usando b\u00fasqueda binaria sobre el algoritmo que supuestamente encuentra el contrato \u00f3ptimo para cualquier red y cualquier valor. Tenga en cuenta que en este valor cr\u00edtico v, el principal es indiferente entre el conjunto E y E \u222a -LCB- x -RCB-. por tanto, si siempre podemos encontrar el contrato \u00f3ptimo, tambi\u00e9n podremos calcular el valor de t -LRB- E -RRB-. En conclusi\u00f3n, calcular el contrato \u00f3ptimo en general es dif\u00edcil. Estos resultados sugieren dos direcciones naturales de investigaci\u00f3n. La primera v\u00eda es estudiar familias de tecnolog\u00edas cuyos contratos \u00f3ptimos puedan calcularse en tiempo polinomial.La segunda v\u00eda es explorar algoritmos de aproximaci\u00f3n para el problema del contrato \u00f3ptimo. Un posible candidato para la primera direcci\u00f3n es la familia de redes serie-paralelas, para las cuales el problema de confiabilidad de la red -LRB- que calcula el valor de t -RRB- es polin\u00f3mico.", "keyphrases": ["conjunto \u00f3ptimo de contrato", "cl\u00e1sico agente-principio", "calidad de servicio", "agencia combinatoria", "equilibrio de Nash", "acci\u00f3n contractual", "\u00f3rbita k", "tecnolog\u00eda an\u00f3nima", "red seri-paralela", "precio de no cuenta"]}
{"file_name": "J-11", "text": "Redes comerciales con agentes que fijan precios RESUMEN En una amplia gama de mercados, los compradores y vendedores individuales a menudo comercian a trav\u00e9s de intermediarios, quienes determinan los precios mediante consideraciones estrat\u00e9gicas. Normalmente, no todos los compradores y vendedores tienen acceso a los mismos intermediarios y comercian a precios correspondientemente diferentes que reflejan sus cantidades relativas de poder en el mercado. Modelamos este fen\u00f3meno utilizando un juego en el que compradores, vendedores y comerciantes realizan transacciones comerciales en un gr\u00e1fico que representa el acceso que cada comprador y vendedor tiene a los comerciantes. En este modelo, los comerciantes fijan los precios estrat\u00e9gicamente y luego los compradores y vendedores reaccionan a los precios que se les ofrecen. Mostramos que el juego resultante siempre tiene un equilibrio de Nash perfecto en subjuegos, y que todos los equilibrios conducen a una asignaci\u00f3n de bienes eficiente -LRB-, es decir, socialmente \u00f3ptima -RRB-. Extendemos estos resultados a un tipo m\u00e1s general de mercado de emparejamiento, como el que se encuentra en el emparejamiento de solicitantes de empleo y empleadores. Finalmente, consideramos c\u00f3mo las ganancias obtenidas por los comerciantes dependen del gr\u00e1fico subyacente: aproximadamente, un comerciante puede obtener una ganancia positiva si y s\u00f3lo si tiene una conexi\u00f3n \"esencial\" en la estructura de la red, proporcionando as\u00ed un gr\u00e1fico. base te\u00f3rica para cuantificar la cantidad de competencia entre comerciantes. Nuestro trabajo difiere de estudios recientes sobre c\u00f3mo el precio se ve afectado por la estructura de la red a trav\u00e9s de nuestro modelado de la fijaci\u00f3n de precios como una actividad estrat\u00e9gica llevada a cabo por un subconjunto de agentes en el sistema, en lugar de estudiar los precios fijados a trav\u00e9s del equilibrio competitivo o mediante un mecanismo veraz. 1. INTRODUCCI\u00d3N En una variedad de entornos donde los mercados median las interacciones de compradores y vendedores, se observan varias propiedades recurrentes: los compradores y vendedores individuales a menudo comercian a trav\u00e9s de intermediarios, no todos los compradores y vendedores tienen acceso a los mismos intermediarios, y no todos los compradores y los vendedores comercian al mismo precio. Un ejemplo de este escenario es el comercio de productos agr\u00edcolas en los pa\u00edses en desarrollo. Dadas las redes de transporte inadecuadas y el acceso limitado de los agricultores pobres al capital, muchos agricultores no tienen otra alternativa que comerciar con intermediarios en mercados locales ineficientes. Un pa\u00eds en desarrollo puede tener muchos de estos mercados parcialmente superpuestos junto con mercados modernos y eficientes -LSB- 2 -RSB-. Los mercados financieros ofrecen un ejemplo diferente de un entorno con estas caracter\u00edsticas generales. En estos mercados, gran parte del comercio entre compradores y vendedores est\u00e1 intermediado por una variedad de agentes que van desde corredores hasta creadores de mercado y sistemas de comercio electr\u00f3nico. Para muchos activos no existe un mercado \u00fanico; El comercio de un solo activo puede ocurrir simult\u00e1neamente en el piso de una bolsa, en redes cruzadas, en bolsas electr\u00f3nicas y en mercados de otros pa\u00edses. Algunos compradores y vendedores tienen acceso a muchos o todos estos centros de negociaci\u00f3n; otros tienen acceso s\u00f3lo a uno o algunos de ellos. El precio al que se negocia el activo puede diferir entre estos centros de negociaci\u00f3n.De hecho, no existe un \"precio\", ya que diferentes comerciantes pagan o reciben precios diferentes. En muchos entornos tambi\u00e9n existe una brecha entre el precio que un comprador paga por un activo, el precio de venta, y el precio que un vendedor recibe por el activo, el precio de oferta. Los diferenciales, definidos como la diferencia entre los precios de oferta y demanda, difieren significativamente entre estos mercados, aunque se negocie el mismo activo en los dos mercados. En este art\u00edculo, desarrollamos un marco en el que tales fen\u00f3menos emergen de un modelo de comercio basado en la teor\u00eda de juegos, en el que compradores, vendedores y comerciantes interact\u00faan en una red. Los bordes de la red conectan a los comerciantes con los compradores y vendedores y, por lo tanto, representan el acceso que los diferentes participantes del mercado tienen entre s\u00ed. Los comerciantes act\u00faan como intermediarios en un juego comercial de dos etapas: eligen estrat\u00e9gicamente los precios de oferta y demanda para ofrecer a los vendedores y compradores con los que est\u00e1n conectados; Luego, los vendedores y compradores reaccionan a los precios que enfrentan. As\u00ed, la red codifica el poder relativo en las posiciones estructurales de los participantes del mercado, incluidos los niveles impl\u00edcitos de competencia entre los comerciantes. Mostramos que este juego siempre tiene un equilibrio de Nash perfecto en subjuegos, y que todos los equilibrios conducen a una asignaci\u00f3n de bienes eficiente -LRB-, es decir, socialmente \u00f3ptima -RRB-. Tambi\u00e9n analizamos c\u00f3mo las ganancias de los comerciantes dependen de la estructura de la red, caracterizando esencialmente en t\u00e9rminos de teor\u00eda de gr\u00e1ficos c\u00f3mo la rentabilidad de un comerciante est\u00e1 determinada por la cantidad de competencia que experimenta con otros comerciantes. Al desarrollar un modelo de red que incluya expl\u00edcitamente a los comerciantes como agentes que fijan los precios, en un sistema junto con compradores y vendedores, podemos capturar la formaci\u00f3n de precios en un entorno de red como un proceso estrat\u00e9gico llevado a cabo por intermediarios, en lugar de como el resultado de un mecanismo controlado centralmente o ex\u00f3geno. El modelo b\u00e1sico: bienes indistinguibles. Nuestro objetivo al formular el modelo es expresar el proceso de fijaci\u00f3n de precios en mercados como los analizados anteriormente, donde no todos los participantes tienen acceso uniforme entre s\u00ed. Tenemos un conjunto B de compradores, un conjunto S de vendedores y un conjunto T de comerciantes. Hay un gr\u00e1fico no dirigido G que indica qui\u00e9n puede comerciar con qui\u00e9n. Esto refleja las limitaciones de que todas las transacciones comprador-vendedor pasen a trav\u00e9s de comerciantes como intermediarios. En la versi\u00f3n m\u00e1s b\u00e1sica del modelo, consideramos productos id\u00e9nticos, de los cuales inicialmente cada vendedor posee una copia. Tanto los compradores como los vendedores tienen cada uno un valor por una copia del bien, y suponemos que estos valores son de conocimiento com\u00fan. Posteriormente generalizaremos esto a un entorno en el que los bienes son distinguibles, los compradores pueden valorar diferentes bienes de manera diferente y, potencialmente, los vendedores tambi\u00e9n pueden valorar las transacciones con diferentes compradores de manera diferente. Tener diferentes valoraciones de los compradores refleja situaciones como la compra de una vivienda; agregar diferentes valoraciones de vendedores tambi\u00e9n captura mercados coincidentes, por ejemplo,vendedores como solicitantes de empleo y compradores como empleadores, preocup\u00e1ndose ambos por qui\u00e9n termina con qu\u00e9 \"bien\" -LRB- y con los comerciantes actuando como servicios que intermedian en la b\u00fasqueda de empleo -RRB-. As\u00ed, para empezar con el modelo b\u00e1sico, existe un solo tipo de bien; el bien viene en unidades indivisibles; y cada vendedor posee inicialmente una unidad del bien. Los tres tipos de agentes valoran el dinero al mismo ritmo; y cada i EBUS valora adicionalmente una copia del bien en \u03b8i unidades de dinero. Ning\u00fan agente quiere m\u00e1s de una copia del bien, por lo que las copias adicionales se valoran en 0. Cada agente tiene una dotaci\u00f3n inicial de dinero mayor que cualquier valoraci\u00f3n individual \u03b8i; el efecto de esto es garantizar que cualquier comprador que termine sin una copia del bien haya sido excluido del mercado debido a su valoraci\u00f3n y posici\u00f3n en la red, no a una falta de fondos. Imaginamos que cada bien que se vende fluye a lo largo de una secuencia de dos aristas: de un vendedor a un comerciante, y luego del comerciante a un comprador. La forma particular en que fluyen las mercanc\u00edas est\u00e1 determinada por el siguiente juego. En primer lugar, cada comerciante ofrece un precio de oferta a cada vendedor con el que est\u00e1 conectado y un precio de venta a cada comprador con el que est\u00e1 conectado. Luego, los vendedores y compradores eligen entre las ofertas que les presentan los comerciantes. Si varios comerciantes proponen el mismo precio a un vendedor o comprador, entonces no existe una mejor respuesta estricta para el vendedor o comprador. Finalmente, cada comerciante compra una copia del bien a cada vendedor que acepta su oferta y vende una copia del bien a cada comprador que acepta su oferta. Si un comerciante en particular descubre que m\u00e1s compradores que vendedores aceptan sus ofertas, entonces se ha comprometido a proporcionar m\u00e1s copias del bien de las que ha recibido, y diremos que esto resulta en una gran penalizaci\u00f3n para el comerciante por incumplimiento; El efecto de esto es que, en equilibrio, ning\u00fan operador elegir\u00e1 precios de oferta y demanda que resulten en un incumplimiento. M\u00e1s precisamente, una estrategia para cada comerciante t es una especificaci\u00f3n de un precio de oferta 3ti para cada vendedor i al que t est\u00e1 conectado, y un precio de venta \u03b1tj para cada comprador j al que t est\u00e1 conectado. -LRB- Tambi\u00e9n podemos manejar un modelo en el que un comerciante puede optar por no hacer una oferta a ciertos de sus vendedores o compradores adyacentes. -RRB- Cada vendedor o comprador elige entonces como m\u00e1ximo una arista de incidencia, indicando el comerciante con el que realizar\u00e1 la transacci\u00f3n, al precio indicado. -LRB- La elecci\u00f3n de una \u00fanica ventaja refleja el hecho de que los vendedores -LRB- a -RRB- inicialmente tienen cada uno solo una copia del bien, y los compradores -LRB- b -RRB- cada uno solo quiere una copia del bien. -RRB- Los pagos son los siguientes: Para cada vendedor i, el pago por seleccionar el comerciante t es 3ti, mientras que el beneficio por no seleccionar ning\u00fan comerciante es \u03b8i. -LRB- En el primer caso, el vendedor recibe 3ti unidades de dinero, mientras que en el segundo conserva su copia del bien, que valora en \u03b8i. -RRB- Para cada comprador j, el beneficio de seleccionar el comerciante t es \u03b8j -- \u03b1tj, mientras que el beneficio de no seleccionar ning\u00fan comerciante es 0.-LRB- En el primer caso, el comprador recibe el bien pero renuncia a \u03b1tj unidades de dinero. -RRB- Para cada comerciante t, con ofertas aceptadas de los vendedores i1,..., is y de los compradores j1,..., jb, el pago es Pr \u03b1tjr -- Pr 3tir, menos una penalizaci\u00f3n \u03c0 si b > s. La penalizaci\u00f3n se elige para que sea lo suficientemente grande como para que un operador nunca incurra en ella en equilibrio y, por lo tanto, generalmente no nos preocuparemos por la penalizaci\u00f3n. Esto define los elementos b\u00e1sicos del juego. El concepto de equilibrio que utilizamos es el equilibrio de Nash perfecto en subjuegos. Algunos ejemplos. Para ayudar a pensar en el modelo, ahora describimos tres ejemplos ilustrativos, representados en la Figura 1. Todos los vendedores en los ejemplos tendr\u00e1n valoraciones del bien iguales a 0; la valoraci\u00f3n de cada comprador se dibuja dentro de su c\u00edrculo; y el precio de oferta o demanda en cada borde se dibuja encima del borde. En la Figura 1 -LRB- a -RRB-, mostramos c\u00f3mo una subasta est\u00e1ndar de segundo precio surge naturalmente de nuestro modelo. Supongamos que las valoraciones de los compradores de arriba a abajo son w > x > y > z. Los precios de oferta y demanda mostrados son consistentes con un equilibrio en el que i1 y j1 aceptan las ofertas del comerciante t1, y ning\u00fan otro comprador acepta la oferta de su comerciante adyacente: por lo tanto, el comerciante t1 recibe el bien con un precio de oferta de x, y genera w -- x vendiendo el bien al comprador j1 por w. De esta manera, podemos considerar este caso particular como una subasta de un solo bien en la que los comerciantes act\u00faan como \"representantes\" de sus compradores adyacentes. El comprador con la valoraci\u00f3n m\u00e1s alta del bien termina con \u00e9l y el excedente se divide entre el vendedor y el comerciante asociado. Tenga en cuenta que se puede construir una subasta de k unidades con f > k compradores con la misma facilidad, construyendo un gr\u00e1fico bipartito completo sobre k vendedores y f comerciantes, y luego vinculando cada comerciante a un \u00fanico comprador distinto. En la Figura 1 -LRB- b -RRB-, mostramos c\u00f3mo los nodos con diferentes posiciones en la topolog\u00eda de la red pueden lograr diferentes beneficios, incluso cuando todos Figura 1 : -LRB- a -RRB- Una subasta, mediada por comerciantes, en la que el El comprador con la valoraci\u00f3n m\u00e1s alta del bien termina con \u00e9l. -LRB- b -RRB- Una red en la que el vendedor y el comprador intermedios se benefician de la competencia perfecta entre los comerciantes, mientras que los otros vendedores y compradores no tienen poder debido a su posici\u00f3n en la red. -LRB- c -RRB- Una forma de competencia perfecta impl\u00edcita: todos los diferenciales de oferta y demanda ser\u00e1n cero en equilibrio, incluso aunque ning\u00fan operador ``compita'' directamente con ning\u00fan otro operador por el mismo par comprador-vendedor. Las valoraciones de los compradores son num\u00e9ricamente las mismas. Espec\u00edficamente, el vendedor i2 y el comprador j2 ocupan posiciones poderosas, porque los dos comerciantes compiten por su negocio; Por otro lado, los dem\u00e1s vendedores y compradores se encuentran en posiciones d\u00e9biles, porque cada uno s\u00f3lo tiene una opci\u00f3n. Y, de hecho, en todo equilibrio existe un n\u00famero real x E -LSB- 0, 1 -RSB- tal que ambos operadores ofrecen precios de compra y venta de x a i2 y j2 respectivamente,mientras ofrecen ofertas de 0 y solicitudes de 1 a los dem\u00e1s vendedores y compradores. Por lo tanto, este ejemplo ilustra algunos ingredientes cruciales que identificaremos a un nivel m\u00e1s general en breve. Espec\u00edficamente, i2 y j2 experimentan los beneficios de la competencia perfecta, en el sentido de que los dos operadores reducen los diferenciales entre oferta y demanda a 0 al competir por su negocio. Por otro lado, los otros vendedores y compradores experimentan las desventajas del monopolio: no reciben ning\u00fan pago ya que solo tienen una \u00fanica opci\u00f3n para comerciar, y el comerciante correspondiente obtiene todas las ganancias. Obs\u00e9rvese adem\u00e1s c\u00f3mo este comportamiento natural surge del hecho de que los comerciantes son capaces de ofrecer diferentes precios a diferentes agentes, capturando el hecho de que no hay un \"precio\" fijo en los tipos de mercados que motivan el modelo, sino diferentes precios. Los precios reflejan el poder relativo de los diferentes agentes involucrados. El ejemplo anterior muestra quiz\u00e1s la forma m\u00e1s natural en la que el beneficio de un operador en una transacci\u00f3n particular puede caer a 0: cuando hay otro operador que puede replicar su funci\u00f3n con precisi\u00f3n. -LRB- En ese ejemplo, dos comerciantes ten\u00edan cada uno la capacidad de mover una copia del bien de i2 a j2. -RRB- Pero, como lo mostrar\u00e1n nuestros resultados posteriores, los operadores generalmente no obtienen ganancias debido a razones globales y de teor\u00eda de gr\u00e1ficos. El ejemplo de la Figura 1 -LRB- c -RRB- da una indicaci\u00f3n inicial de esto: se puede demostrar que para cada equilibrio, existe un ay E -LSB- 0, 1 -RSB- tal que cada precio de oferta y cada precio de venta son iguales. juguete. En otras palabras, todos los comerciantes obtienen cero ganancias, independientemente de que una copia del bien pase a trav\u00e9s de ellos o no, y, sin embargo, no hay dos comerciantes que tengan rutas entre vendedor y comprador en com\u00fan. Los diferenciales de precios han sido llevados a cero por una restricci\u00f3n global impuesta por el ciclo largo a trav\u00e9s de todos los agentes; Este es un ejemplo de competencia perfecta impl\u00edcita determinada por la topolog\u00eda de la red. Ampliaci\u00f3n del modelo a bienes distinguibles. Ampliamos el modelo b\u00e1sico a un entorno con bienes distinguibles, como sigue. Una estrategia para un comerciante ahora consiste en ofrecer una oferta a cada vendedor que especifica tanto un precio como un comprador, y ofrecer una demanda a cada comprador que especifica tanto un precio como un vendedor. -LRB- Tambi\u00e9n podemos manejar un modelo en el que un comerciante ofrece ofertas -LRB- respectivamente, pide -RRB- en forma de vectores, especificando esencialmente un `` men\u00fa '' con un precio adjunto a cada comprador -LRB- resp. vendedor -RRB-. -RRB- Cada comprador y vendedor selecciona una oferta de un comerciante adyacente y los pagos a todos los agentes se determinan como antes. Aqu\u00ed los vendedores son solicitantes de empleo, los compradores son empleadores y los comerciantes son los agentes que median en el mercado laboral. Por supuesto, si se especifican valoraciones por pares para los compradores pero solo valoraciones individuales para los vendedores, modelamos un entorno en el que los compradores pueden distinguir entre los bienes, pero a los vendedores no les importa a qui\u00e9n venden; esto -LRB- aproximadamente -RRB- captura entornos como los mercados inmobiliarios. Nuestros resultados. Para hacerlos precisos,Nosotros introducimos la siguiente notaci\u00f3n. -LRB- Los vendedores que no aparecen en ning\u00fan triple conservan su copia del bien. -RRB- Decimos que el valor de la asignaci\u00f3n es igual a Pe \u2208 M \u03b8jeie -- \u03b8ieje. Sea \u03b8 \u2217 el valor m\u00e1ximo de cualquier asignaci\u00f3n M que sea factible dada la red. Demostramos que cada instancia de nuestro juego tiene un equilibrio, y que en cada uno de esos equilibrios, la asignaci\u00f3n tiene un valor \u03b8 \u2217; en otras palabras, logra el mejor valor posible. Por lo tanto, los equilibrios en este modelo son siempre eficientes, en el sentido de que el mercado permite que el conjunto \"correcto\" de personas obtenga el bien, sujeto a las restricciones de la red. Establecemos la existencia y eficiencia de equilibrios construyendo un programa lineal para capturar el flujo de bienes a trav\u00e9s de la red; el dual de este programa lineal contiene suficiente informaci\u00f3n para extraer precios de equilibrio. Seg\u00fan la definici\u00f3n del juego, el valor de la asignaci\u00f3n de equilibrio se divide en pagos a los agentes, y es interesante preguntarse c\u00f3mo se distribuye este valor; en particular, cu\u00e1nta ganancia puede obtener un operador en funci\u00f3n de su posici\u00f3n. en la red. Encontramos que, aunque todos los equilibrios tienen el mismo valor, el pago de un operador determinado puede variar entre diferentes equilibrios. Tambi\u00e9n obtenemos resultados para la suma de todas las ganancias de los comerciantes. Trabajo relacionado. El enfoque de referencia est\u00e1ndar para analizar la interacci\u00f3n de compradores y vendedores es el modelo walrasiano en el que compradores y vendedores an\u00f3nimos intercambian un bien a un precio \u00fanico de equilibrio de mercado. Esta forma reducida de comercio, construida sobre la idealizaci\u00f3n de un precio de mercado, es un modelo poderoso que ha llevado a muchas ideas. Pero no es un buen modelo para examinar de d\u00f3nde provienen los precios o exactamente c\u00f3mo comercian entre s\u00ed los compradores y los vendedores. La dificultad es que en el modelo walrasiano no hay ning\u00fan agente que fije el precio y los agentes en realidad no comercian entre s\u00ed. De hecho, no hay mercado, en el sentido cotidiano de la palabra, en el modelo walrasiano. Es decir, no existe un lugar f\u00edsico o virtual donde compradores y vendedores interact\u00faen para comerciar y fijar precios. As\u00ed, en este modelo simple, todos los compradores y vendedores son uniformes y comercian al mismo precio, y tampoco hay papel para los intermediarios. Hay varias publicaciones en econom\u00eda y finanzas que examinan c\u00f3mo se fijan los precios en lugar de limitarse a determinar los precios de equilibrio. La literatura sobre competencia imperfecta es quiz\u00e1s la m\u00e1s antigua de ellas. Aqu\u00ed un monopolista, o un grupo de oliogopolistas, eligen precios para maximizar sus ganancias -LRB- ver -LSB- 14 -RSB- para el tratamiento est\u00e1ndar de estos mercados en los libros de text -RRB-. Un monopolista utiliza su conocimiento de la demanda del mercado para elegir un precio, o un conjunto de precios, si discrimina. Los oligopolistas juegan un juego en el que sus beneficios dependen de la demanda del mercado y de las acciones de sus competidores. En esta literatura hay agentes que fijan los precios, pero se mantiene la ficci\u00f3n de un mercado \u00fanico. En la literatura de b\u00fasqueda de equilibrio,las empresas fijan los precios y los consumidores los buscan -LRB- ver -LSB- 3 -RSB- -RRB-. Los consumidores terminan pagando precios diferentes, pero todos los consumidores tienen acceso a todas las empresas y no hay intermediarios. En la literatura sobre equilibrio general ha habido varios intentos de introducir la determinaci\u00f3n de precios. Una t\u00e9cnica de prueba est\u00e1ndar de la existencia de equilibrio competitivo implica un mecanismo de ajuste de precios en el que los precios responden al exceso de demanda. Se han introducido procesos m\u00e1s sofisticados para estudiar la estabilidad de los precios de equilibrio o la informaci\u00f3n necesaria para calcularlos. Pero, una vez m\u00e1s, aqu\u00ed no hay agentes que fijen los precios. En la literatura financiera, el trabajo sobre la microestructura del mercado tiene agentes que fijan precios -LRB- especialistas -RRB-, partes del mismo determinan precios de oferta y demanda por separado, y diferentes agentes reciben diferentes precios por el mismo activo -LRB- ver -LSB - 12 -RSB- para un tratamiento de la teor\u00eda de la microestructura -RRB-. El trabajo en econom\u00eda de la informaci\u00f3n ha identificado fen\u00f3menos similares -LRB- ver, por ejemplo, -LSB- 7 -RSB- -RRB-. Pero hay poca investigaci\u00f3n en estas publicaciones que examinen el efecto de las restricciones sobre qui\u00e9n puede comerciar con qui\u00e9n. Ha habido varios enfoques para estudiar c\u00f3mo la estructura de la red determina los precios. Estos han postulado la determinaci\u00f3n de los precios a trav\u00e9s de definiciones basadas en el equilibrio competitivo o el n\u00facleo, o mediante el uso de mecanismos veraces. Al revisar brevemente este trabajo, notaremos el contraste con nuestro enfoque, en el sentido de que modelamos los precios como si surgieran del comportamiento estrat\u00e9gico de los agentes en el sistema. En un trabajo reciente, Kakade et al. -LSB- 8 -RSB- han estudiado la distribuci\u00f3n de precios en equilibrio competitivo en un gr\u00e1fico bipartito sobre compradores y vendedores, generado mediante un modelo probabil\u00edstico capaz de producir distribuciones de grados de cola pesada -LSB- 11 -RSB-. Incluso-Dar et al. -LSB- 6 -RSB- se basa en esto para considerar los aspectos estrat\u00e9gicos de la formaci\u00f3n de redes cuando los precios surgen del equilibrio competitivo. Leonard estudia los precios de VCG en este context; Babaioff et al. y Chu y Shen proporcionan adem\u00e1s un mecanismo de equilibrio presupuestario. Por el contrario, nuestro modelo tiene valoraciones y precios conocidos que surgen del comportamiento estrat\u00e9gico de los comerciantes. Demange, Gale y Sotomayor -LSB- 5 -RSB-, y Kranton y Minehart -LSB- 9 -RSB-, analizan los precios a los que se produce el comercio en una red, trabajando en el marco del dise\u00f1o de mecanismos. Kranton y Minehart utilizan un gr\u00e1fico bipartito con v\u00ednculos directos entre compradores y vendedores, y luego utilizan un mecanismo de subasta ascendente, en lugar de intermediarios estrat\u00e9gicos, para determinar los precios. Su subasta tiene propiedades de equilibrio deseables, pero, como se\u00f1alan Kranton y Minehart, es una abstracci\u00f3n de c\u00f3mo se asignan los bienes y se determinan los precios que es similar en esp\u00edritu a la abstracci\u00f3n del subastador walrasiano.pero todos los consumidores tienen acceso a todas las empresas y no hay intermediarios. En la literatura sobre equilibrio general ha habido varios intentos de introducir la determinaci\u00f3n de precios. Una t\u00e9cnica de prueba est\u00e1ndar de la existencia de equilibrio competitivo implica un mecanismo de ajuste de precios en el que los precios responden al exceso de demanda. Se han introducido procesos m\u00e1s sofisticados para estudiar la estabilidad de los precios de equilibrio o la informaci\u00f3n necesaria para calcularlos. Pero, una vez m\u00e1s, aqu\u00ed no hay agentes que fijen los precios. En la literatura financiera, el trabajo sobre la microestructura del mercado tiene agentes que fijan precios -LRB- especialistas -RRB-, partes del mismo determinan precios de oferta y demanda por separado, y diferentes agentes reciben diferentes precios por el mismo activo -LRB- ver -LSB - 12 -RSB- para un tratamiento de la teor\u00eda de la microestructura -RRB-. El trabajo en econom\u00eda de la informaci\u00f3n ha identificado fen\u00f3menos similares -LRB- ver, por ejemplo, -LSB- 7 -RSB- -RRB-. Pero hay poca investigaci\u00f3n en estas publicaciones que examinen el efecto de las restricciones sobre qui\u00e9n puede comerciar con qui\u00e9n. Ha habido varios enfoques para estudiar c\u00f3mo la estructura de la red determina los precios. Estos han postulado la determinaci\u00f3n de los precios a trav\u00e9s de definiciones basadas en el equilibrio competitivo o el n\u00facleo, o mediante el uso de mecanismos veraces. Al revisar brevemente este trabajo, notaremos el contraste con nuestro enfoque, en el sentido de que modelamos los precios como si surgieran del comportamiento estrat\u00e9gico de los agentes en el sistema. En un trabajo reciente, Kakade et al. -LSB- 8 -RSB- han estudiado la distribuci\u00f3n de precios en equilibrio competitivo en un gr\u00e1fico bipartito sobre compradores y vendedores, generado mediante un modelo probabil\u00edstico capaz de producir distribuciones de grados de cola pesada -LSB- 11 -RSB-. Incluso-Dar et al. -LSB- 6 -RSB- se basa en esto para considerar los aspectos estrat\u00e9gicos de la formaci\u00f3n de redes cuando los precios surgen del equilibrio competitivo. Leonard estudia los precios de VCG en este context; Babaioff et al. y Chu y Shen proporcionan adem\u00e1s un mecanismo de equilibrio presupuestario. Por el contrario, nuestro modelo tiene valoraciones y precios conocidos que surgen del comportamiento estrat\u00e9gico de los comerciantes. Demange, Gale y Sotomayor -LSB- 5 -RSB-, y Kranton y Minehart -LSB- 9 -RSB-, analizan los precios a los que se produce el comercio en una red, trabajando en el marco del dise\u00f1o de mecanismos. Kranton y Minehart utilizan un gr\u00e1fico bipartito con v\u00ednculos directos entre compradores y vendedores, y luego utilizan un mecanismo de subasta ascendente, en lugar de intermediarios estrat\u00e9gicos, para determinar los precios. Su subasta tiene propiedades de equilibrio deseables, pero, como se\u00f1alan Kranton y Minehart, es una abstracci\u00f3n de c\u00f3mo se asignan los bienes y se determinan los precios que es similar en esp\u00edritu a la abstracci\u00f3n del subastador walrasiano.pero todos los consumidores tienen acceso a todas las empresas y no hay intermediarios. En la literatura sobre equilibrio general ha habido varios intentos de introducir la determinaci\u00f3n de precios. Una t\u00e9cnica de prueba est\u00e1ndar de la existencia de equilibrio competitivo implica un mecanismo de ajuste de precios en el que los precios responden al exceso de demanda. Se han introducido procesos m\u00e1s sofisticados para estudiar la estabilidad de los precios de equilibrio o la informaci\u00f3n necesaria para calcularlos. Pero, una vez m\u00e1s, aqu\u00ed no hay agentes que fijen los precios. En la literatura financiera, el trabajo sobre la microestructura del mercado tiene agentes que fijan precios -LRB- especialistas -RRB-, partes del mismo determinan precios de oferta y demanda por separado, y diferentes agentes reciben diferentes precios por el mismo activo -LRB- ver -LSB - 12 -RSB- para un tratamiento de la teor\u00eda de la microestructura -RRB-. El trabajo en econom\u00eda de la informaci\u00f3n ha identificado fen\u00f3menos similares -LRB- ver, por ejemplo, -LSB- 7 -RSB- -RRB-. Pero hay poca investigaci\u00f3n en estas publicaciones que examinen el efecto de las restricciones sobre qui\u00e9n puede comerciar con qui\u00e9n. Ha habido varios enfoques para estudiar c\u00f3mo la estructura de la red determina los precios. Estos han postulado la determinaci\u00f3n de los precios a trav\u00e9s de definiciones basadas en el equilibrio competitivo o el n\u00facleo, o mediante el uso de mecanismos veraces. Al revisar brevemente este trabajo, notaremos el contraste con nuestro enfoque, en el sentido de que modelamos los precios como si surgieran del comportamiento estrat\u00e9gico de los agentes en el sistema. En un trabajo reciente, Kakade et al. -LSB- 8 -RSB- han estudiado la distribuci\u00f3n de precios en equilibrio competitivo en un gr\u00e1fico bipartito sobre compradores y vendedores, generado mediante un modelo probabil\u00edstico capaz de producir distribuciones de grados de cola pesada -LSB- 11 -RSB-. Incluso-Dar et al. -LSB- 6 -RSB- se basa en esto para considerar los aspectos estrat\u00e9gicos de la formaci\u00f3n de redes cuando los precios surgen del equilibrio competitivo. Leonard estudia los precios de VCG en este context; Babaioff et al. y Chu y Shen proporcionan adem\u00e1s un mecanismo de equilibrio presupuestario. Por el contrario, nuestro modelo tiene valoraciones y precios conocidos que surgen del comportamiento estrat\u00e9gico de los comerciantes. Demange, Gale y Sotomayor -LSB- 5 -RSB-, y Kranton y Minehart -LSB- 9 -RSB-, analizan los precios a los que se produce el comercio en una red, trabajando en el marco del dise\u00f1o de mecanismos. Kranton y Minehart utilizan un gr\u00e1fico bipartito con v\u00ednculos directos entre compradores y vendedores, y luego utilizan un mecanismo de subasta ascendente, en lugar de intermediarios estrat\u00e9gicos, para determinar los precios. Su subasta tiene propiedades de equilibrio deseables, pero, como se\u00f1alan Kranton y Minehart, es una abstracci\u00f3n de c\u00f3mo se asignan los bienes y se determinan los precios que es similar en esp\u00edritu a la abstracci\u00f3n del subastador walrasiano.Se han introducido procesos m\u00e1s sofisticados para estudiar la estabilidad de los precios de equilibrio o la informaci\u00f3n necesaria para calcularlos. Pero, una vez m\u00e1s, aqu\u00ed no hay agentes que fijen los precios. En la literatura financiera, el trabajo sobre la microestructura del mercado tiene agentes que fijan precios -LRB- especialistas -RRB-, partes del mismo determinan precios de oferta y demanda por separado, y diferentes agentes reciben diferentes precios por el mismo activo -LRB- ver -LSB - 12 -RSB- para un tratamiento de la teor\u00eda de la microestructura -RRB-. El trabajo en econom\u00eda de la informaci\u00f3n ha identificado fen\u00f3menos similares -LRB- ver, por ejemplo, -LSB- 7 -RSB- -RRB-. Pero hay poca investigaci\u00f3n en estas publicaciones que examinen el efecto de las restricciones sobre qui\u00e9n puede comerciar con qui\u00e9n. Ha habido varios enfoques para estudiar c\u00f3mo la estructura de la red determina los precios. Estos han postulado la determinaci\u00f3n de los precios a trav\u00e9s de definiciones basadas en el equilibrio competitivo o el n\u00facleo, o mediante el uso de mecanismos veraces. Al revisar brevemente este trabajo, notaremos el contraste con nuestro enfoque, en el sentido de que modelamos los precios como si surgieran del comportamiento estrat\u00e9gico de los agentes en el sistema. En un trabajo reciente, Kakade et al. -LSB- 8 -RSB- han estudiado la distribuci\u00f3n de precios en equilibrio competitivo en un gr\u00e1fico bipartito sobre compradores y vendedores, generado mediante un modelo probabil\u00edstico capaz de producir distribuciones de grados de cola pesada -LSB- 11 -RSB-. Incluso-Dar et al. -LSB- 6 -RSB- se basa en esto para considerar los aspectos estrat\u00e9gicos de la formaci\u00f3n de redes cuando los precios surgen del equilibrio competitivo. Leonard estudia los precios de VCG en este context; Babaioff et al. y Chu y Shen proporcionan adem\u00e1s un mecanismo de equilibrio presupuestario. Por el contrario, nuestro modelo tiene valoraciones y precios conocidos que surgen del comportamiento estrat\u00e9gico de los comerciantes. Demange, Gale y Sotomayor -LSB- 5 -RSB-, y Kranton y Minehart -LSB- 9 -RSB-, analizan los precios a los que se produce el comercio en una red, trabajando en el marco del dise\u00f1o de mecanismos. Kranton y Minehart utilizan un gr\u00e1fico bipartito con v\u00ednculos directos entre compradores y vendedores, y luego utilizan un mecanismo de subasta ascendente, en lugar de intermediarios estrat\u00e9gicos, para determinar los precios. Su subasta tiene propiedades de equilibrio deseables, pero, como se\u00f1alan Kranton y Minehart, es una abstracci\u00f3n de c\u00f3mo se asignan los bienes y se determinan los precios que es similar en esp\u00edritu a la abstracci\u00f3n del subastador walrasiano.Se han introducido procesos m\u00e1s sofisticados para estudiar la estabilidad de los precios de equilibrio o la informaci\u00f3n necesaria para calcularlos. Pero, una vez m\u00e1s, aqu\u00ed no hay agentes que fijen los precios. En la literatura financiera, el trabajo sobre la microestructura del mercado tiene agentes que fijan precios -LRB- especialistas -RRB-, partes del mismo determinan precios de oferta y demanda por separado, y diferentes agentes reciben diferentes precios por el mismo activo -LRB- ver -LSB - 12 -RSB- para un tratamiento de la teor\u00eda de la microestructura -RRB-. El trabajo en econom\u00eda de la informaci\u00f3n ha identificado fen\u00f3menos similares -LRB- ver, por ejemplo, -LSB- 7 -RSB- -RRB-. Pero hay poca investigaci\u00f3n en estas publicaciones que examinen el efecto de las restricciones sobre qui\u00e9n puede comerciar con qui\u00e9n. Ha habido varios enfoques para estudiar c\u00f3mo la estructura de la red determina los precios. Estos han postulado la determinaci\u00f3n de los precios a trav\u00e9s de definiciones basadas en el equilibrio competitivo o el n\u00facleo, o mediante el uso de mecanismos veraces. Al revisar brevemente este trabajo, notaremos el contraste con nuestro enfoque, en el sentido de que modelamos los precios como si surgieran del comportamiento estrat\u00e9gico de los agentes en el sistema. En un trabajo reciente, Kakade et al. -LSB- 8 -RSB- han estudiado la distribuci\u00f3n de precios en equilibrio competitivo en un gr\u00e1fico bipartito sobre compradores y vendedores, generado mediante un modelo probabil\u00edstico capaz de producir distribuciones de grados de cola pesada -LSB- 11 -RSB-. Incluso-Dar et al. -LSB- 6 -RSB- se basa en esto para considerar los aspectos estrat\u00e9gicos de la formaci\u00f3n de redes cuando los precios surgen del equilibrio competitivo. Leonard estudia los precios de VCG en este context; Babaioff et al. y Chu y Shen proporcionan adem\u00e1s un mecanismo de equilibrio presupuestario. Por el contrario, nuestro modelo tiene valoraciones y precios conocidos que surgen del comportamiento estrat\u00e9gico de los comerciantes. Demange, Gale y Sotomayor -LSB- 5 -RSB-, y Kranton y Minehart -LSB- 9 -RSB-, analizan los precios a los que se produce el comercio en una red, trabajando en el marco del dise\u00f1o de mecanismos. Kranton y Minehart utilizan un gr\u00e1fico bipartito con v\u00ednculos directos entre compradores y vendedores, y luego utilizan un mecanismo de subasta ascendente, en lugar de intermediarios estrat\u00e9gicos, para determinar los precios. Su subasta tiene propiedades de equilibrio deseables, pero, como se\u00f1alan Kranton y Minehart, es una abstracci\u00f3n de c\u00f3mo se asignan los bienes y se determinan los precios que es similar en esp\u00edritu a la abstracci\u00f3n del subastador walrasiano.Pero hay poca investigaci\u00f3n en estas publicaciones que examinen el efecto de las restricciones sobre qui\u00e9n puede comerciar con qui\u00e9n. Ha habido varios enfoques para estudiar c\u00f3mo la estructura de la red determina los precios. Estos han postulado la determinaci\u00f3n de los precios a trav\u00e9s de definiciones basadas en el equilibrio competitivo o el n\u00facleo, o mediante el uso de mecanismos veraces. Al revisar brevemente este trabajo, notaremos el contraste con nuestro enfoque, en el sentido de que modelamos los precios como si surgieran del comportamiento estrat\u00e9gico de los agentes en el sistema. En un trabajo reciente, Kakade et al. -LSB- 8 -RSB- han estudiado la distribuci\u00f3n de precios en equilibrio competitivo en un gr\u00e1fico bipartito sobre compradores y vendedores, generado mediante un modelo probabil\u00edstico capaz de producir distribuciones de grados de cola pesada -LSB- 11 -RSB-. Incluso-Dar et al. -LSB- 6 -RSB- se basa en esto para considerar los aspectos estrat\u00e9gicos de la formaci\u00f3n de redes cuando los precios surgen del equilibrio competitivo. Leonard estudia los precios de VCG en este context; Babaioff et al. y Chu y Shen proporcionan adem\u00e1s un mecanismo de equilibrio presupuestario. Por el contrario, nuestro modelo tiene valoraciones y precios conocidos que surgen del comportamiento estrat\u00e9gico de los comerciantes. Demange, Gale y Sotomayor -LSB- 5 -RSB-, y Kranton y Minehart -LSB- 9 -RSB-, analizan los precios a los que se produce el comercio en una red, trabajando en el marco del dise\u00f1o de mecanismos. Kranton y Minehart utilizan un gr\u00e1fico bipartito con v\u00ednculos directos entre compradores y vendedores, y luego utilizan un mecanismo de subasta ascendente, en lugar de intermediarios estrat\u00e9gicos, para determinar los precios. Su subasta tiene propiedades de equilibrio deseables, pero, como se\u00f1alan Kranton y Minehart, es una abstracci\u00f3n de c\u00f3mo se asignan los bienes y se determinan los precios que es similar en esp\u00edritu a la abstracci\u00f3n del subastador walrasiano.Pero hay poca investigaci\u00f3n en estas publicaciones que examinen el efecto de las restricciones sobre qui\u00e9n puede comerciar con qui\u00e9n. Ha habido varios enfoques para estudiar c\u00f3mo la estructura de la red determina los precios. Estos han postulado la determinaci\u00f3n de los precios a trav\u00e9s de definiciones basadas en el equilibrio competitivo o el n\u00facleo, o mediante el uso de mecanismos veraces. Al revisar brevemente este trabajo, notaremos el contraste con nuestro enfoque, en el sentido de que modelamos los precios como si surgieran del comportamiento estrat\u00e9gico de los agentes en el sistema. En un trabajo reciente, Kakade et al. -LSB- 8 -RSB- han estudiado la distribuci\u00f3n de precios en equilibrio competitivo en un gr\u00e1fico bipartito sobre compradores y vendedores, generado mediante un modelo probabil\u00edstico capaz de producir distribuciones de grados de cola pesada -LSB- 11 -RSB-. Incluso-Dar et al. -LSB- 6 -RSB- se basa en esto para considerar los aspectos estrat\u00e9gicos de la formaci\u00f3n de redes cuando los precios surgen del equilibrio competitivo. Leonard estudia los precios de VCG en este context; Babaioff et al. y Chu y Shen proporcionan adem\u00e1s un mecanismo de equilibrio presupuestario. Por el contrario, nuestro modelo tiene valoraciones y precios conocidos que surgen del comportamiento estrat\u00e9gico de los comerciantes. Demange, Gale y Sotomayor -LSB- 5 -RSB-, y Kranton y Minehart -LSB- 9 -RSB-, analizan los precios a los que se produce el comercio en una red, trabajando en el marco del dise\u00f1o de mecanismos. Kranton y Minehart utilizan un gr\u00e1fico bipartito con v\u00ednculos directos entre compradores y vendedores, y luego utilizan un mecanismo de subasta ascendente, en lugar de intermediarios estrat\u00e9gicos, para determinar los precios. Su subasta tiene propiedades de equilibrio deseables, pero, como se\u00f1alan Kranton y Minehart, es una abstracci\u00f3n de c\u00f3mo se asignan los bienes y se determinan los precios que es similar en esp\u00edritu a la abstracci\u00f3n del subastador walrasiano.Analizar los precios a los que se produce el comercio en una red, trabajando en el marco del dise\u00f1o de mecanismos. Kranton y Minehart utilizan un gr\u00e1fico bipartito con v\u00ednculos directos entre compradores y vendedores, y luego utilizan un mecanismo de subasta ascendente, en lugar de intermediarios estrat\u00e9gicos, para determinar los precios. Su subasta tiene propiedades de equilibrio deseables, pero, como se\u00f1alan Kranton y Minehart, es una abstracci\u00f3n de c\u00f3mo se asignan los bienes y se determinan los precios que es similar en esp\u00edritu a la abstracci\u00f3n del subastador walrasiano.Analizar los precios a los que se produce el comercio en una red, trabajando en el marco del dise\u00f1o de mecanismos. Kranton y Minehart utilizan un gr\u00e1fico bipartito con v\u00ednculos directos entre compradores y vendedores, y luego utilizan un mecanismo de subasta ascendente, en lugar de intermediarios estrat\u00e9gicos, para determinar los precios. Su subasta tiene propiedades de equilibrio deseables, pero, como se\u00f1alan Kranton y Minehart, es una abstracci\u00f3n de c\u00f3mo se asignan los bienes y se determinan los precios que es similar en esp\u00edritu a la abstracci\u00f3n del subastador walrasiano.", "keyphrases": ["teor\u00eda de juegos de algoritmos", "mercado", "red comercial", "interacci\u00f3n del comprador y el vendedor", "dotaci\u00f3n inicial de dinero", "precio de oferta", "competencia perfecta", "beneficio", "importe m\u00e1ximo y m\u00ednimo", "econom\u00eda y finanzas", "comportamiento estrat\u00e9gico del comerciante", "holgura complementaria", "monopolio"]}
{"file_name": "I-15", "text": "B\u00fasqueda e intercambio de informaci\u00f3n en redes din\u00e1micas a gran escala RESUMEN Encontrar los agentes adecuados en una red grande y din\u00e1mica para proporcionar los recursos necesarios de manera oportuna es un problema de larga data. Este art\u00edculo presenta un m\u00e9todo para buscar e compartir informaci\u00f3n que combina \u00edndices de enrutamiento con m\u00e9todos basados \u200b\u200ben tokens. El m\u00e9todo propuesto permite a los agentes realizar b\u00fasquedas de forma eficaz adquiriendo los intereses de sus vecinos, publicitando sus capacidades de suministro de informaci\u00f3n y manteniendo \u00edndices para enrutar consultas, de forma integrada. Espec\u00edficamente, el art\u00edculo demuestra a trav\u00e9s de experimentos de rendimiento c\u00f3mo las redes est\u00e1ticas y din\u00e1micas de agentes pueden \"sintonizarse\" para responder consultas de manera efectiva mientras re\u00fanen evidencia de los intereses y las capacidades de suministro de informaci\u00f3n de otros, sin alterar la topolog\u00eda ni imponer una estructura superpuesta a la red. de conocidos. 1. INTRODUCCI\u00d3N redes de agentes asociados. Por otro lado, existe mucha investigaci\u00f3n sobre redes de b\u00fasqueda sem\u00e1ntica peer to peer y redes sociales -LSB- 1,5,6,8,9,10,16,18,19 -RSB- muchas de las cuales tratan sobre tuning una red de pares para buscar e intercambiar informaci\u00f3n de forma eficaz. Lo hacen principalmente imponiendo estructuras superpuestas l\u00f3gicas y sem\u00e1nticas. Sin embargo, hasta donde sabemos, no existe ning\u00fan trabajo que demuestre la efectividad de un proceso de ajuste gradual en redes din\u00e1micas a gran escala que estudie el impacto de la informaci\u00f3n recopilada por los agentes a medida que se emiten y atienden m\u00e1s y m\u00e1s consultas en sesiones concurrentes en el sistema. red. La cuesti\u00f3n principal de este art\u00edculo se refiere a \"ajustar\" una red de agentes, cada uno con una experiencia espec\u00edfica, para buscar e intercambiar informaci\u00f3n de manera eficiente y eficaz, sin alterar la topolog\u00eda ni imponer una estructura superpuesta mediante agrupaciones, introducci\u00f3n de \u00edndices abreviados o re- alambrado. `Tuning' es la tarea de compartir y recopilar el conocimiento necesario para que los agentes propaguen solicitudes a los conocidos adecuados, minimizando el esfuerzo de b\u00fasqueda, aumentando la eficiencia y el beneficio del sistema. Espec\u00edficamente, este art\u00edculo propone un m\u00e9todo para buscar e intercambiar informaci\u00f3n en redes din\u00e1micas y de gran escala, que combina \u00edndices de enrutamiento con m\u00e9todos basados \u200b\u200ben tokens para compartir informaci\u00f3n en sistemas multiagente de gran escala. Este art\u00edculo est\u00e1 estructurado de la siguiente manera: la Secci\u00f3n 2 presenta el trabajo relacionado y motiva el m\u00e9todo propuesto. La secci\u00f3n 3 establece el problema y la secci\u00f3n 4 presenta en detalle las t\u00e9cnicas individuales y el m\u00e9todo general propuesto. La secci\u00f3n 5 presenta la configuraci\u00f3n experimental y los resultados, y la secci\u00f3n 6 concluye el art\u00edculo, esbozando el trabajo futuro. 2. TRABAJO RELACIONADO La provisi\u00f3n y el intercambio de informaci\u00f3n pueden considerarse como un proceso de decisi\u00f3n de Markov descentralizado y parcialmente observable -LSB- 3,4,11,14 -RSB-. En el caso general, el control descentralizado de sistemas din\u00e1micos a gran escala de agentes cooperativos es un problema dif\u00edcil. Las soluciones \u00f3ptimas s\u00f3lo pueden aproximarse mediante heur\u00edsticas,por relajaciones del problema original o por soluciones centralizadas. Sin embargo, en un sistema din\u00e1mico a gran escala con control descentralizado es muy dif\u00edcil para los agentes poseer vistas parciales precisas del entorno, y es a\u00fan m\u00e1s dif\u00edcil para los agentes poseer una visi\u00f3n global del entorno. Adem\u00e1s, las observaciones de los agentes no pueden asumirse como independientes, ya que las acciones de un agente pueden afectar las observaciones de otros: por ejemplo, cuando un agente se une o abandona el sistema, esto puede afectar la evaluaci\u00f3n de otros agentes de las capacidades de suministro de informaci\u00f3n de los vecinos. . Considerando actividades y observaciones independientes, los autores de -LSB- 4 -RSB- proponen una soluci\u00f3n te\u00f3rica de decisi\u00f3n que trata la acci\u00f3n est\u00e1ndar y el intercambio de informaci\u00f3n como elecciones expl\u00edcitas que el tomador de decisiones debe tomar. Se aproximan a la soluci\u00f3n utilizando un algoritmo miope. Su trabajo difiere del reportado aqu\u00ed en los siguientes aspectos: primero, apunta a optimizar la comunicaci\u00f3n, mientras que el objetivo aqu\u00ed es sintonizar la red para compartir informaci\u00f3n de manera efectiva, reducir la comunicaci\u00f3n y aumentar los beneficios del sistema. En tercer lugar, consideran que las transiciones y observaciones realizadas por los agentes son independientes, lo que, como ya se ha comentado, no es cierto en el caso general. Por \u00faltimo, a diferencia de su enfoque en el que los agentes transmiten mensajes, aqu\u00ed los agentes deciden no s\u00f3lo cu\u00e1ndo comunicarse, sino tambi\u00e9n a qui\u00e9n enviar un mensaje. Los enfoques basados \u200b\u200ben tokens son prometedores para ampliar la coordinaci\u00f3n y, por lo tanto, el suministro e intercambio de informaci\u00f3n a sistemas a gran escala de manera efectiva. En -LSB-11-RSB- los autores proporcionan un marco matem\u00e1tico para enrutar tokens, proporcionando tambi\u00e9n una aproximaci\u00f3n para resolver el problema original en el caso de actividades de agentes independientes. El m\u00e9todo propuesto requiere un gran volumen de c\u00e1lculos que los autores pretenden reducir restringiendo su aplicaci\u00f3n a equipos l\u00f3gicos est\u00e1ticos de agentes asociados. De acuerdo con este enfoque, en -LSB- 12,13,14 -RSB-, el intercambio de informaci\u00f3n se considera solo para redes est\u00e1ticas y no se demuestra el autoajuste de las redes. Como se mostrar\u00e1 en la secci\u00f3n 5, nuestros experimentos muestran que aunque estos enfoques pueden manejar el intercambio de informaci\u00f3n en redes din\u00e1micas, requieren una mayor cantidad de mensajes en comparaci\u00f3n con el enfoque propuesto aqu\u00ed y no pueden ajustar la red para un intercambio de informaci\u00f3n eficiente. La comunicaci\u00f3n proactiva se ha propuesto en -LSB- 17 -RSB- como resultado de una determinaci\u00f3n te\u00f3rica de decisiones din\u00e1micas de las estrategias de comunicaci\u00f3n. Este enfoque se basa en la especificaci\u00f3n de los agentes como \"proveedores\" y \"necesarios\": esto se hace mediante un c\u00e1lculo previo basado en un plan de las necesidades de informaci\u00f3n y las capacidades de provisi\u00f3n de los agentes. Sin embargo, este enfoque no puede ampliarse a redes grandes y din\u00e1micas, ya que ser\u00eda muy ineficiente para cada agente calcular y determinar sus necesidades potenciales y capacidades de suministro de informaci\u00f3n dada su interacci\u00f3n potencial con cientos de otros agentes.Al considerar la recuperaci\u00f3n de informaci\u00f3n en sistemas peer-to-peer desde una perspectiva de sistema multiagente, el enfoque propuesto en -LSB-18-RSB- se basa en un modelo de lenguaje de recopilaci\u00f3n de documentos de agentes. Al explotar los modelos de otros agentes en la red, los agentes construyen su visi\u00f3n de la red que se utiliza para tomar decisiones de enrutamiento. Inicialmente, los agentes construyen sus puntos de vista utilizando los modelos de sus vecinos. Luego, el sistema se reorganiza formando grupos de agentes con contenidos similares. Los cl\u00fasteres se explotan durante la recuperaci\u00f3n de informaci\u00f3n utilizando un enfoque kNN y un esquema de b\u00fasqueda de gradiente. Si bien este trabajo apunta a sintonizar una red para el suministro eficiente de informaci\u00f3n -LRB- a trav\u00e9s de su reorganizaci\u00f3n -RRB-, no demuestra la efectividad del enfoque con respecto a este tema. Adem\u00e1s, aunque durante la reorganizaci\u00f3n y la recuperaci\u00f3n miden la similitud de contenido entre agentes, se necesita un enfoque m\u00e1s detallado que permita a los agentes medir similitudes de elementos de informaci\u00f3n o subcolecciones de elementos de informaci\u00f3n. Bas\u00e1ndose en su trabajo en sistemas peer-to-peer, H.Zhand y V.Lesser en -LSB-19-RSB- estudian sesiones de b\u00fasqueda simult\u00e1neas. Teniendo en cuenta la investigaci\u00f3n en sistemas sem\u00e1nticos peer-to-peer1, la mayor\u00eda de los enfoques explotan lo que puede denominarse vagamente un \"\u00edndice de enrutamiento\". Una cuesti\u00f3n importante relativa a la b\u00fasqueda de informaci\u00f3n es \"qu\u00e9 informaci\u00f3n debe compartirse entre pares, cu\u00e1ndo y qu\u00e9 ajustes deben realizarse para que las consultas se dirijan a fuentes de informaci\u00f3n confiables de la manera m\u00e1s efectiva y eficiente\". RECORDATORIO -LSB- 10 -RSB- los pares recopilan informaci\u00f3n sobre las consultas que han sido respondidas exitosamente por otros pares, para posteriormente seleccionar pares a los que reenviar solicitudes: Este es un enfoque de aprendizaje lento que no implica publicidad del suministro de informaci\u00f3n entre pares. habilidades. Esto da como resultado un proceso de ajuste en el que la recuperaci\u00f3n general aumenta con el tiempo, mientras que la cantidad de mensajes por consulta permanece aproximadamente igual. Aqu\u00ed, los agentes anuncian activamente sus capacidades de suministro de informaci\u00f3n en funci\u00f3n de los intereses evaluados de sus pares: esto da como resultado una cantidad mucho menor de mensajes por consulta que los reportados en REMINDIN '. En -LSB- 5,6 -RSB- los pares, utilizando una ontolog\u00eda com\u00fan, anuncian su experiencia, que se explota para la formaci\u00f3n de una red sem\u00e1ntica superpuesta: las consultas se propagan en esta red dependiendo de su similitud con la experiencia de los pares. Seg\u00fan nuestro enfoque, los agentes anuncian selectivamente sus capacidades de suministro de informaci\u00f3n sobre temas espec\u00edficos a sus vecinos con intereses informativos similares -LRB- y s\u00f3lo a estos -RRB-. Sin embargo, esto se hace a medida que pasa el tiempo y mientras los agentes reciben solicitudes de sus pares. Generan una sobrecarga sustancial en entornos altamente din\u00e1micos, donde los nodos se unen o abandonan el sistema. 248 La Sexta Internacional. Conf. Conjunta.Los agentes anuncian sus capacidades de suministro de informaci\u00f3n teniendo en cuenta los intereses de sus vecinos. Dado el \u00e9xito de este m\u00e9todo, estudiaremos c\u00f3mo la adici\u00f3n de rutas l\u00f3gicas y la evoluci\u00f3n gradual de la topolog\u00eda de la red pueden aumentar a\u00fan m\u00e1s la efectividad del m\u00e9todo propuesto. 6. CONCLUSIONES Este art\u00edculo presenta un m\u00e9todo para el procesamiento de consultas sem\u00e1nticas en grandes redes de agentes que combina \u00edndices de enrutamiento con m\u00e9todos de intercambio de informaci\u00f3n. El m\u00e9todo presentado permite a los agentes mantener registros de los intereses de sus conocidos, anunciar sus capacidades de suministro de informaci\u00f3n a aquellos que tienen un gran inter\u00e9s en ellos y mantener \u00edndices para enrutar consultas a aquellos agentes que tienen las capacidades de suministro de informaci\u00f3n solicitadas. Espec\u00edficamente, el art\u00edculo demuestra a trav\u00e9s de extensos experimentos de rendimiento: -LRB- a -RRB- C\u00f3mo se pueden \"sintonizar\" las redes de agentes para proporcionar la informaci\u00f3n solicitada de manera efectiva, aumentando el beneficio y la eficiencia del sistema. -LRB- b -RRB- C\u00f3mo los diferentes tipos de conocimiento local -LRB- n\u00famero, repositorios de informaci\u00f3n local, porcentaje, intereses y capacidades de provisi\u00f3n de informaci\u00f3n de los conocidos -RRB- pueden guiar a los agentes para responder consultas de manera efectiva, equilibrando eficiencia y eficacia. -LRB- c -RRB- Que la tarea de ``tuning'' propuesta logre incrementar la eficiencia en la b\u00fasqueda e intercambio de informaci\u00f3n en redes de gran tama\u00f1o y alta din\u00e1mica. -LRB- d -RRB- Que la informaci\u00f3n recopilada y mantenida por los agentes respalde la b\u00fasqueda e intercambio de informaci\u00f3n eficiente y eficaz: la informaci\u00f3n inicial sobre las capacidades de provisi\u00f3n de informaci\u00f3n de los conocidos no es necesaria y un peque\u00f1o porcentaje de conocidos es suficiente. El trabajo adicional se refiere a experimentar con datos y ontolog\u00edas reales, diferencias en ontolog\u00edas entre agentes, cambios en la experiencia y la construcci\u00f3n paralela de estructuras superpuestas.Los intereses y las capacidades de suministro de informaci\u00f3n de los conocidos (RRB) pueden guiar a los agentes a responder consultas de manera efectiva, equilibrando la eficiencia y la eficacia. -LRB- c -RRB- Que la tarea de ``tuning'' propuesta logre incrementar la eficiencia en la b\u00fasqueda e intercambio de informaci\u00f3n en redes de gran tama\u00f1o y alta din\u00e1mica. -LRB- d -RRB- Que la informaci\u00f3n recopilada y mantenida por los agentes respalde la b\u00fasqueda e intercambio de informaci\u00f3n eficiente y eficaz: la informaci\u00f3n inicial sobre las capacidades de provisi\u00f3n de informaci\u00f3n de los conocidos no es necesaria y un peque\u00f1o porcentaje de conocidos es suficiente. El trabajo adicional se refiere a experimentar con datos y ontolog\u00edas reales, diferencias en ontolog\u00edas entre agentes, cambios en la experiencia y la construcci\u00f3n paralela de estructuras superpuestas.Los intereses y las capacidades de suministro de informaci\u00f3n de los conocidos (RRB) pueden guiar a los agentes a responder consultas de manera efectiva, equilibrando la eficiencia y la eficacia. -LRB- c -RRB- Que la tarea de ``tuning'' propuesta logre incrementar la eficiencia en la b\u00fasqueda e intercambio de informaci\u00f3n en redes de gran tama\u00f1o y alta din\u00e1mica. -LRB- d -RRB- Que la informaci\u00f3n recopilada y mantenida por los agentes respalde la b\u00fasqueda e intercambio de informaci\u00f3n eficiente y eficaz: la informaci\u00f3n inicial sobre las capacidades de provisi\u00f3n de informaci\u00f3n de los conocidos no es necesaria y un peque\u00f1o porcentaje de conocidos es suficiente. El trabajo adicional se refiere a experimentar con datos y ontolog\u00edas reales, diferencias en ontolog\u00edas entre agentes, cambios en la experiencia y la construcci\u00f3n paralela de estructuras superpuestas.", "keyphrases": ["informar buscar y compartir", "red social", "agente de cobre", "red de b\u00fasqueda de igual a igual", "sistema de igual a igual", "Red din\u00e1mica y de gran escala.", "proceso de decis de observaci\u00f3n parcial decente de markov", "control descentrador", "algoritmo miope", "enfoque knn", "esquema de b\u00fasqueda de gradiente"]}
{"file_name": "J-1", "text": "Mecanismos generalizados de reducci\u00f3n del comercio RESUMEN Al dise\u00f1ar un mecanismo hay varias propiedades deseables que mantener, como la compatibilidad de incentivos -LRB- IC -RRB-, la racionalidad individual -LRB- IR -RRB- y el equilibrio presupuestario -LRB- BB -RRB-. Es bien sabido -LSB- 15 -RSB- que es imposible que un mecanismo maximice el bienestar social siendo al mismo tiempo IR, IC y BB. Ha habido varios intentos de eludir -LSB- 15 -RSB- intercambiando bienestar por BB, por ejemplo, en dominios como subastas bilaterales -LSB- 13 -RSB-, mercados distribuidos -LSB- 3 -RSB- y cadena de suministro. problemas -LSB- 2, 4 -RSB-. En este art\u00edculo proporcionamos un procedimiento llamado Reducci\u00f3n Comercial Generalizada -LRB- GTR -RRB- para jugadores de un solo valor, que dado un mecanismo de IR e IC, genera un mecanismo que es IR, IC y BB con una p\u00e9rdida de bienestar. Limitamos el bienestar logrado mediante nuestro procedimiento a una amplia gama de \u00e1mbitos. En particular, nuestros resultados mejoran las soluciones existentes para problemas como mercados bilaterales con bienes homog\u00e9neos, mercados distribuidos y varios tipos de cadenas de suministro. Adem\u00e1s, nuestra soluci\u00f3n proporciona mecanismos de equilibrio presupuestario para varios problemas abiertos, como subastas combinatorias de doble cara y mercados distribuidos con ventajas de transporte estrat\u00e9gicas. 1. INTRODUCCI\u00d3N Al dise\u00f1ar un mecanismo, hay varias propiedades clave que es deseable mantener. En muchos de los mecanismos, la funci\u00f3n objetivo que el dise\u00f1ador de un mecanismo intenta maximizar es el bienestar social: el beneficio total para la sociedad. Sin embargo, es bien sabido por -LSB-15-RSB- que cualquier mecanismo que maximice el bienestar social manteniendo al mismo tiempo la racionalidad individual y la compatibilidad de incentivos genera necesariamente un d\u00e9ficit, es decir, no est\u00e1 presupuestariamente equilibrado. Para mantener la propiedad BB en un mecanismo IR e IC es necesario comprometerse con la optimizaci\u00f3n del bienestar social. 1.1 Trabajo relacionado y soluciones espec\u00edficas Ha habido varios intentos de dise\u00f1ar mecanismos de equilibrio presupuestario para dominios particulares2. En el problema de los mercados distribuidos -LRB- y en problemas estrechamente relacionados -RRB- los bienes se transportan entre ubicaciones geogr\u00e1ficas incurriendo en alg\u00fan costo constante por el transporte. -LSB- 16, 9, 3 -RSB- presentan mecanismos que se aproximan al bienestar social logrando un mecanismo de IR, IC y BB. Para problemas de la cadena de suministro -LSB- 2, 4 -RSB- limita la p\u00e9rdida de bienestar social que es necesario infligir al mecanismo para lograr la combinaci\u00f3n deseada de IR, IC y BB. A pesar de los trabajos discutidos anteriormente, la cuesti\u00f3n de c\u00f3mo dise\u00f1ar un mecanismo general que logre IR, IC y BB independientemente del dominio del problema permanece abierta. Adem\u00e1s, hay varios \u00e1mbitos en los que la cuesti\u00f3n de c\u00f3mo dise\u00f1ar un mecanismo de IR, CI y BB que se aproxime al bienestar social sigue siendo un problema abierto. Por ejemplo,En el importante \u00e1mbito de las subastas combinatorias de doble cara no se conoce ning\u00fan resultado que limite la p\u00e9rdida de bienestar social necesaria para lograr el equilibrio presupuestario. Otro ejemplo interesante es la pregunta abierta que dej\u00f3 -LSB- 3 -RSB-: \u00bfC\u00f3mo se puede limitar la p\u00e9rdida de bienestar social que se necesita para lograr el equilibrio presupuestario en un mercado distribuido de IR e IC donde las ventajas del transporte son estrat\u00e9gicas? Naturalmente, una respuesta al mercado distribuido de BB con ventajas estrat\u00e9gicas tiene enormes implicaciones pr\u00e1cticas, por ejemplo para las redes de transporte. 1.2 Nuestra Contribuci\u00f3n En este art\u00edculo unificamos todos los problemas discutidos anteriormente -LRB- tanto los resueltos como los abiertos -RRB- en un solo procedimiento de concepto de soluci\u00f3n. El procedimiento de soluci\u00f3n se denomin\u00f3 Reducci\u00f3n Comercial Generalizada -LRB-GTR-RRB-. GTR acepta un mecanismo IR e IC para jugadores de un solo valor y genera un mecanismo IR, IC y BB. El mecanismo de producci\u00f3n puede sufrir cierta p\u00e9rdida de bienestar como compensaci\u00f3n por lograr BB. Hay casos problem\u00e1ticos en los que no es necesaria una p\u00e9rdida de bienestar, pero por -LSB- 15 -RSB- hay casos problem\u00e1ticos en los que s\u00ed hay p\u00e9rdida de bienestar. Sin embargo, para una amplia clase de problemas podemos limitar la p\u00e9rdida de bienestar. Un caso particularmente interesante es aquel en el que el mecanismo de entrada es una asignaci\u00f3n eficiente. Adem\u00e1s de unificar muchos de los problemas de BB bajo un concepto de soluci\u00f3n \u00fanica, el procedimiento GTR mejora los resultados existentes y resuelve varios problemas abiertos en la literatura. Las soluciones existentes que mejora nuestro procedimiento GTR son subastas homog\u00e9neas de doble cara, mercados distribuidos -LSB- 3 -RSB- y cadena de suministro -LSB- 2, 4 -RSB-. Para las subastas homog\u00e9neas de doble cara, el procedimiento de soluci\u00f3n GTR mejora la conocida soluci\u00f3n -LSB-13-RSB- al permitir algunos casos en los que no se reduce el comercio en absoluto. Para los mercados distribuidos -LSB- 3 -RSB- y la cadena de suministro -LSB- 2, 4 -RSB- el procedimiento de soluci\u00f3n GTR mejora el l\u00edmite de p\u00e9rdidas de bienestar, es decir, permite lograr un mecanismo IR, IC y BB con menor p\u00e9rdida para el bienestar social. Recientemente tambi\u00e9n supimos que el procedimiento GTR permite convertir el modelo reci\u00e9n presentado -LSB- 6 -RSB- en un mecanismo BB. Adem\u00e1s de la contribuci\u00f3n principal descrita anteriormente, este art\u00edculo tambi\u00e9n define una clasificaci\u00f3n importante de dominios de problemas. Definimos dominios basados \u200b\u200ben clases y dominios basados \u200b\u200ben clases de adquisici\u00f3n. Las definiciones anteriores se basan en los diferentes \"poderes\" de competencia de los jugadores en mecanismos llamados competencia interna y externa.2 Nuestra Contribuci\u00f3n En este art\u00edculo unificamos todos los problemas discutidos anteriormente -LRB- tanto los resueltos como los abiertos -RRB- en un solo procedimiento de concepto de soluci\u00f3n. El procedimiento de soluci\u00f3n se denomin\u00f3 Reducci\u00f3n Comercial Generalizada -LRB-GTR-RRB-. GTR acepta un mecanismo IR e IC para jugadores de un solo valor y genera un mecanismo IR, IC y BB. El mecanismo de producci\u00f3n puede sufrir cierta p\u00e9rdida de bienestar como compensaci\u00f3n por lograr BB. Hay casos problem\u00e1ticos en los que no es necesaria una p\u00e9rdida de bienestar, pero por -LSB- 15 -RSB- hay casos problem\u00e1ticos en los que s\u00ed hay p\u00e9rdida de bienestar. Sin embargo, para una amplia clase de problemas podemos limitar la p\u00e9rdida de bienestar. Un caso particularmente interesante es aquel en el que el mecanismo de entrada es una asignaci\u00f3n eficiente. Adem\u00e1s de unificar muchos de los problemas de BB bajo un concepto de soluci\u00f3n \u00fanica, el procedimiento GTR mejora los resultados existentes y resuelve varios problemas abiertos en la literatura. Las soluciones existentes que mejora nuestro procedimiento GTR son subastas homog\u00e9neas de doble cara, mercados distribuidos -LSB- 3 -RSB- y cadena de suministro -LSB- 2, 4 -RSB-. Para las subastas homog\u00e9neas de doble cara, el procedimiento de soluci\u00f3n GTR mejora la conocida soluci\u00f3n -LSB-13-RSB- al permitir algunos casos en los que no se reduce el comercio en absoluto. Para los mercados distribuidos -LSB- 3 -RSB- y la cadena de suministro -LSB- 2, 4 -RSB- el procedimiento de soluci\u00f3n GTR mejora el l\u00edmite de p\u00e9rdidas de bienestar, es decir, permite lograr un mecanismo IR, IC y BB con menor p\u00e9rdida para el bienestar social. Recientemente tambi\u00e9n supimos que el procedimiento GTR permite convertir el modelo reci\u00e9n presentado -LSB- 6 -RSB- en un mecanismo BB. Adem\u00e1s de la contribuci\u00f3n principal descrita anteriormente, este art\u00edculo tambi\u00e9n define una clasificaci\u00f3n importante de dominios de problemas. Definimos dominios basados \u200b\u200ben clases y dominios basados \u200b\u200ben clases de adquisici\u00f3n. Las definiciones anteriores se basan en los diferentes \"poderes\" de competencia de los jugadores en mecanismos llamados competencia interna y externa.2 Nuestra Contribuci\u00f3n En este art\u00edculo unificamos todos los problemas discutidos anteriormente -LRB- tanto los resueltos como los abiertos -RRB- en un solo procedimiento de concepto de soluci\u00f3n. El procedimiento de soluci\u00f3n se denomin\u00f3 Reducci\u00f3n Comercial Generalizada -LRB-GTR-RRB-. GTR acepta un mecanismo IR e IC para jugadores de un solo valor y genera un mecanismo IR, IC y BB. El mecanismo de producci\u00f3n puede sufrir cierta p\u00e9rdida de bienestar como compensaci\u00f3n por lograr BB. Hay casos problem\u00e1ticos en los que no es necesaria una p\u00e9rdida de bienestar, pero por -LSB- 15 -RSB- hay casos problem\u00e1ticos en los que s\u00ed hay p\u00e9rdida de bienestar. Sin embargo, para una amplia clase de problemas podemos limitar la p\u00e9rdida de bienestar. Un caso particularmente interesante es aquel en el que el mecanismo de entrada es una asignaci\u00f3n eficiente. Adem\u00e1s de unificar muchos de los problemas de BB bajo un concepto de soluci\u00f3n \u00fanica, el procedimiento GTR mejora los resultados existentes y resuelve varios problemas abiertos en la literatura. Las soluciones existentes que mejora nuestro procedimiento GTR son subastas homog\u00e9neas de doble cara, mercados distribuidos -LSB- 3 -RSB- y cadena de suministro -LSB- 2, 4 -RSB-. Para las subastas homog\u00e9neas de doble cara, el procedimiento de soluci\u00f3n GTR mejora la conocida soluci\u00f3n -LSB-13-RSB- al permitir algunos casos en los que no se reduce el comercio en absoluto. Para los mercados distribuidos -LSB- 3 -RSB- y la cadena de suministro -LSB- 2, 4 -RSB- el procedimiento de soluci\u00f3n GTR mejora el l\u00edmite de p\u00e9rdidas de bienestar, es decir, permite lograr un mecanismo IR, IC y BB con menor p\u00e9rdida para el bienestar social. Recientemente tambi\u00e9n supimos que el procedimiento GTR permite convertir el modelo reci\u00e9n presentado -LSB- 6 -RSB- en un mecanismo BB. Adem\u00e1s de la contribuci\u00f3n principal descrita anteriormente, este art\u00edculo tambi\u00e9n define una clasificaci\u00f3n importante de dominios de problemas. Definimos dominios basados \u200b\u200ben clases y dominios basados \u200b\u200ben clases de adquisici\u00f3n. Las definiciones anteriores se basan en los diferentes \"poderes\" de competencia de los jugadores en mecanismos llamados competencia interna y externa.Para las subastas homog\u00e9neas de doble cara, el procedimiento de soluci\u00f3n GTR mejora la conocida soluci\u00f3n -LSB-13-RSB- al permitir algunos casos en los que no se reduce el comercio en absoluto. Para los mercados distribuidos -LSB- 3 -RSB- y la cadena de suministro -LSB- 2, 4 -RSB- el procedimiento de soluci\u00f3n GTR mejora el l\u00edmite de p\u00e9rdidas de bienestar, es decir, permite lograr un mecanismo IR, IC y BB con menor p\u00e9rdida para el bienestar social. Recientemente tambi\u00e9n supimos que el procedimiento GTR permite convertir el modelo reci\u00e9n presentado -LSB- 6 -RSB- en un mecanismo BB. Adem\u00e1s de la contribuci\u00f3n principal descrita anteriormente, este art\u00edculo tambi\u00e9n define una clasificaci\u00f3n importante de dominios de problemas. Definimos dominios basados \u200b\u200ben clases y dominios basados \u200b\u200ben clases de adquisici\u00f3n. Las definiciones anteriores se basan en los diferentes \"poderes\" de competencia de los jugadores en mecanismos llamados competencia interna y externa.Para las subastas homog\u00e9neas de doble cara, el procedimiento de soluci\u00f3n GTR mejora la conocida soluci\u00f3n -LSB-13-RSB- al permitir algunos casos en los que no se reduce el comercio en absoluto. Para los mercados distribuidos -LSB- 3 -RSB- y la cadena de suministro -LSB- 2, 4 -RSB- el procedimiento de soluci\u00f3n GTR mejora el l\u00edmite de p\u00e9rdidas de bienestar, es decir, permite lograr un mecanismo IR, IC y BB con menor p\u00e9rdida para el bienestar social. Recientemente tambi\u00e9n supimos que el procedimiento GTR permite convertir el modelo reci\u00e9n presentado -LSB- 6 -RSB- en un mecanismo BB. Adem\u00e1s de la contribuci\u00f3n principal descrita anteriormente, este art\u00edculo tambi\u00e9n define una clasificaci\u00f3n importante de dominios de problemas. Definimos dominios basados \u200b\u200ben clases y dominios basados \u200b\u200ben clases de adquisici\u00f3n. Las definiciones anteriores se basan en los diferentes \"poderes\" de competencia de los jugadores en mecanismos llamados competencia interna y externa.", "keyphrases": ["reducci\u00f3n comercial", "saldo presupuestario", "competencia interna", "competencia externa", "eficiente", "poder del jugador", "reducci\u00f3n del comercio de g\u00e9nero", "gtr", "optimo", "desigualdad en bienestar", "jugador multimente", "mecanismo de equilibrio presupuestario", "homog\u00e9neo bueno", "mercado de distribuci\u00f3n espacial"]}
{"file_name": "H-24", "text": "Investigaci\u00f3n del comportamiento de consulta y navegaci\u00f3n de los usuarios de motores de b\u00fasqueda avanzados RESUMEN Una forma de ayudar a todos los usuarios de motores de b\u00fasqueda web comerciales a tener m\u00e1s \u00e9xito en sus b\u00fasquedas es comprender mejor lo que hacen los usuarios con mayor experiencia en b\u00fasquedas y utilizar este conocimiento para beneficiar a todos. . En este art\u00edculo estudiamos los registros de interacci\u00f3n de los usuarios de motores de b\u00fasqueda avanzados -LRB- y de aquellos no tan avanzados -RRB- para comprender mejor c\u00f3mo realizan b\u00fasquedas estos grupos de usuarios. Los resultados muestran que existen marcadas diferencias en las consultas, los clics en los resultados, la navegaci\u00f3n posterior a la consulta y el \u00e9xito de la b\u00fasqueda de los usuarios que clasificamos como avanzados -LRB- en funci\u00f3n de su uso de operadores de consulta -RRB-, en relaci\u00f3n con los clasificados como no avanzado. Nuestros hallazgos tienen implicaciones sobre c\u00f3mo se debe apoyar a los usuarios avanzados durante sus b\u00fasquedas y c\u00f3mo sus interacciones podr\u00edan usarse para ayudar a los buscadores de todos los niveles de experiencia a encontrar informaci\u00f3n m\u00e1s relevante y aprender estrategias de b\u00fasqueda mejoradas. 1. INTRODUCCI\u00d3N La formulaci\u00f3n de declaraciones de consulta que capturen los aspectos m\u00e1s destacados de las necesidades de informaci\u00f3n y que sean significativas para los sistemas de recuperaci\u00f3n de informaci\u00f3n -LRB- IR -RRB- plantea un desaf\u00edo para muchos buscadores -LSB- 3 -RSB-. Estas t\u00e9cnicas pueden ser \u00fatiles para mejorar la precisi\u00f3n de los resultados, pero, adem\u00e1s de mediante an\u00e1lisis de registros -LRB-, por ejemplo, -LSB- 15 -RSB- -LSB- 27 -RSB- -RRB-, la comunidad investigadora generalmente las ha pasado por alto en sus intentos. para mejorar la calidad de los resultados de b\u00fasqueda. La investigaci\u00f3n de RI generalmente se ha centrado en formas alternativas para que los usuarios especifiquen sus necesidades en lugar de aumentar la adopci\u00f3n de sintaxis avanzada. En los \u00faltimos a\u00f1os se ha intensificado la investigaci\u00f3n sobre t\u00e9cnicas pr\u00e1cticas para complementar la tecnolog\u00eda de b\u00fasqueda existente y ayudar a los usuarios -LRB- por ejemplo -LSB- 18 -RSB- -LSB- 34 -RSB- -RRB-. Sin embargo, implementar estas t\u00e9cnicas a gran escala con latencias tolerables resulta complicado. Las consultas t\u00edpicas enviadas a los motores de b\u00fasqueda web toman la forma de una serie de tokens separados por espacios. Generalmente hay un operador booleano AND impl\u00edcito entre tokens que restringe los resultados de b\u00fasqueda a documentos que contienen todos los t\u00e9rminos de consulta. De Lima y Pedersen -LSB- 7 -RSB- investigaron el efecto del an\u00e1lisis, el reconocimiento de frases y la expansi\u00f3n en las consultas de b\u00fasqueda web. Demostraron que el reconocimiento autom\u00e1tico de frases en consultas puede mejorar la precisi\u00f3n de los resultados en la b\u00fasqueda web. Sin embargo, el valor de la sintaxis avanzada para los buscadores t\u00edpicos generalmente ha sido limitado, ya que la mayor\u00eda de los usuarios no conocen la sintaxis avanzada o no entienden c\u00f3mo usarla -LSB- 15 -RSB-. En este art\u00edculo exploramos el uso de operadores de consulta con m\u00e1s detalle y proponemos aplicaciones alternativas que no requieren que todos los usuarios utilicen expl\u00edcitamente sintaxis avanzada. Nuestra hip\u00f3tesis es que los buscadores que utilizan sintaxis de consulta avanzada demuestran un grado de experiencia en b\u00fasquedas que la mayor\u00eda de la poblaci\u00f3n de usuarios no tiene; afirmaci\u00f3n respaldada por investigaciones previas -LSB- 13 -RSB-.Estudiar el comportamiento de estos usuarios de motores de b\u00fasqueda avanzados puede arrojar informaci\u00f3n importante sobre la b\u00fasqueda y la exploraci\u00f3n de resultados de la que otros pueden beneficiarse. Utilizando registros recopilados de una gran cantidad de usuarios que dieron su consentimiento, investigamos las diferencias entre el comportamiento de b\u00fasqueda de aquellos que usan sintaxis avanzada y los que no, y las diferencias en la informaci\u00f3n a la que apuntan esos usuarios. Nos interesa responder tres preguntas de investigaci\u00f3n: -LRB- i -RRB- \u00bfExiste una relaci\u00f3n entre el uso de sintaxis avanzada y otras caracter\u00edsticas de una b\u00fasqueda? -LRB- ii -RRB- \u00bfExiste una relaci\u00f3n entre el uso de sintaxis avanzada y los comportamientos de navegaci\u00f3n posteriores a la consulta? -LRB- iii -RRB- \u00bfExiste una relaci\u00f3n entre el uso de sintaxis avanzada y las medidas de \u00e9xito de la b\u00fasqueda? A trav\u00e9s de un estudio y an\u00e1lisis experimental, ofrecemos posibles respuestas para cada una de estas preguntas. Una relaci\u00f3n entre el uso de sintaxis avanzada y cualquiera de estas caracter\u00edsticas podr\u00eda respaldar el dise\u00f1o de sistemas adaptados a los usuarios de motores de b\u00fasqueda avanzados, o utilizar las interacciones de los usuarios avanzados para ayudar a los usuarios no avanzados a tener m\u00e1s \u00e9xito en sus b\u00fasquedas. Describimos el trabajo relacionado en la Secci\u00f3n 2, los datos que utilizamos en este estudio basado en registros en la Secci\u00f3n 3, las caracter\u00edsticas de b\u00fasqueda en las que centramos nuestro an\u00e1lisis en la Secci\u00f3n 4 y los hallazgos de este an\u00e1lisis en la Secci\u00f3n 5. 2. Factores de TRABAJO RELACIONADO tales como la falta de conocimiento del dominio, la mala comprensi\u00f3n de la colecci\u00f3n de documentos que se busca y una necesidad de informaci\u00f3n poco desarrollada pueden influir en la calidad de las consultas que los usuarios env\u00edan a los sistemas IR -LRB- -LSB- 24 -RSB-, -LSB- 28 -RSB- -RRB-. Se han realizado diversas investigaciones sobre diferentes formas de ayudar a los usuarios a especificar sus necesidades de informaci\u00f3n de manera m\u00e1s efectiva. Belkin et al. -LSB- 4 -RSB- experiment\u00f3 proporcionando espacio adicional para que los usuarios escriban una descripci\u00f3n m\u00e1s detallada de sus necesidades de informaci\u00f3n. Kelly et al. intentaron un enfoque similar. -LSB- 18 -RSB-, quienes utilizaron formularios de aclaraci\u00f3n para obtener informaci\u00f3n adicional sobre el context de b\u00fasqueda de los usuarios. Se ha demostrado que estos enfoques son eficaces en los sistemas de recuperaci\u00f3n de mejores coincidencias, donde las consultas m\u00e1s largas generalmente conducen a resultados de b\u00fasqueda m\u00e1s relevantes -LSB- 4 -RSB-. Sin embargo, en la b\u00fasqueda web, donde muchos de los sistemas se basan en un modelo de recuperaci\u00f3n booleano extendido, las consultas m\u00e1s largas pueden en realidad afectar el rendimiento de la recuperaci\u00f3n, lo que lleva a que se recupere una peque\u00f1a cantidad de resultados potencialmente irrelevantes. No basta simplemente con solicitar m\u00e1s informaci\u00f3n a los usuarios; esta informaci\u00f3n debe ser de mejor calidad. La retroalimentaci\u00f3n de relevancia -LRB- RF -RRB- -LSB- 22 -RSB- y la expansi\u00f3n de consultas interactivas -LSB- 9 -RSB- son t\u00e9cnicas populares que se han utilizado para mejorar la calidad de la informaci\u00f3n que los usuarios brindan a los sistemas de IR con respecto a sus necesidades de informaci\u00f3n. . En el caso de RF, el usuario presenta al sistema ejemplos de informaci\u00f3n relevante que luego se utilizan para formular una consulta mejorada o recuperar un nuevo conjunto de documentos.Ha resultado dif\u00edcil lograr que los usuarios utilicen RF en el dominio web debido a la dificultad para transmitir el significado y el beneficio de RF a los usuarios t\u00edpicos -LSB- 17 -RSB-. Las sugerencias de consultas que se ofrecen en funci\u00f3n de los registros de consultas tienen el potencial de mejorar el rendimiento de la recuperaci\u00f3n con una carga limitada para el usuario. Este enfoque se limita a volver a ejecutar consultas populares y los buscadores a menudo ignoran las sugerencias que se les presentan -LSB- 1 -RSB-. Adem\u00e1s, ambas t\u00e9cnicas no ayudan a los usuarios a aprender a generar consultas m\u00e1s efectivas. La mayor\u00eda de los motores de b\u00fasqueda comerciales proporcionan una sintaxis de consulta avanzada que permite a los usuarios especificar sus necesidades de informaci\u00f3n con m\u00e1s detalle. Los operadores booleanos -LRB- AND, OR y NOT -RRB- pueden unir t\u00e9rminos y frases, y se pueden usar modificadores como ``sitio:'' y ``enlace:'' para restringir el espacio de b\u00fasqueda. Las consultas creadas con estas t\u00e9cnicas pueden ser poderosas. El an\u00e1lisis basado en registros de las interacciones de los usuarios con los motores de b\u00fasqueda Excite y AltaVista ha demostrado que s\u00f3lo entre el 10 y el 20 % de las consultas conten\u00edan alguna sintaxis avanzada -LSB- 14 -RSB- -LSB- 25 -RSB-. Este an\u00e1lisis puede ser una forma \u00fatil de capturar las caracter\u00edsticas de los usuarios que interact\u00faan con los sistemas IR. La investigaci\u00f3n sobre modelado de usuarios -LSB- 6 -RSB- y personalizaci\u00f3n -LSB- 30 -RSB- ha demostrado que recopilar m\u00e1s informaci\u00f3n sobre los usuarios puede mejorar la efectividad de las b\u00fasquedas, pero requiere m\u00e1s informaci\u00f3n sobre los usuarios de la que normalmente est\u00e1 disponible \u00fanicamente en los registros de interacci\u00f3n. A menos que se combine con una t\u00e9cnica cualitativa, como un cuestionario posterior a la sesi\u00f3n -LSB- 23 -RSB-, puede resultar dif\u00edcil asociar las interacciones con las caracter\u00edsticas del usuario. En nuestro estudio conjeturamos que, dada la dificultad para ubicar funciones de b\u00fasqueda avanzada dentro de la interfaz de b\u00fasqueda t\u00edpica y los problemas potenciales para comprender la sintaxis, aquellos usuarios que usan sintaxis avanzada regularmente representan una clase distinta de buscadores que exhibir\u00e1n otros comportamientos de b\u00fasqueda comunes. . Otros estudios sobre los comportamientos de b\u00fasqueda de los buscadores avanzados han intentado comprender mejor el conocimiento estrat\u00e9gico que han adquirido. No obstante, pueden brindar informaci\u00f3n valiosa sobre los comportamientos de los usuarios con experiencia en dominios, sistemas o b\u00fasquedas que excede la del usuario promedio. El comportamiento de consulta en particular se ha estudiado ampliamente para comprender mejor a los usuarios -LSB- 31 -RSB- y ayudar a otros usuarios -LSB- 16 -RSB-. En este art\u00edculo estudiamos otras caracter\u00edsticas de b\u00fasqueda de los usuarios de sintaxis avanzada en un intento de determinar si hay algo diferente en c\u00f3mo buscan estos usuarios de motores de b\u00fasqueda, y si sus b\u00fasquedas pueden usarse para beneficiar a aquellos que no hacen uso de las funciones avanzadas. de los motores de b\u00fasqueda. Para ello utilizamos registros de interacci\u00f3n recopilados de un gran conjunto de usuarios que dan su consentimiento durante un per\u00edodo prolongado. En la siguiente secci\u00f3n describimos los datos que utilizamos para estudiar el comportamiento de los usuarios que utilizan sintaxis avanzada, en relaci\u00f3n con aquellos que no utilizan esta sintaxis. Sesi\u00f3n 11 de actas de SIGIR 2007:Comportamiento de interacci\u00f3n, como consultas, clics en resultados, navegaci\u00f3n posterior a la consulta y \u00e9xito de la b\u00fasqueda. La clasificaci\u00f3n cruda de los usuarios basada en una sola caracter\u00edstica que se puede extraer f\u00e1cilmente del flujo de consultas arroja resultados notables sobre el comportamiento de interacci\u00f3n de los usuarios que no usan la sintaxis y los que s\u00ed la usan. Como hemos sugerido, los sistemas de b\u00fasqueda pueden aprovechar las interacciones de estos usuarios para mejorar la clasificaci\u00f3n de documentos, la recomendaci\u00f3n de p\u00e1ginas o incluso la capacitaci\u00f3n de los usuarios.", "keyphrases": ["motor de b\u00fasqueda", "pregunta", "informar relevante", "estrategia de b\u00fasqueda", "tolerante al latencia", "sintaxis avanzada", "comportamiento de navegaci\u00f3n", "comportamiento de b\u00fasqueda", "\u00e9xito de b\u00fasqueda", "retroalimentaci\u00f3n relevante", "relevante"]}
{"file_name": "J-8", "text": "Fuerte equilibrio en juegos de conexi\u00f3n con costos compartidos * RESUMEN En este trabajo estudiamos los juegos de conexi\u00f3n con costos compartidos, donde cada jugador tiene una fuente y un sumidero que le gustar\u00eda conectar, y el costo de los bordes se comparte equitativamente -LRB- juegos de conexi\u00f3n justa - RRB- o de forma arbitraria -LRB- juegos generales de conexi\u00f3n -RRB-. Se estudian las topolog\u00edas de grafos que garantizan la existencia de un equilibrio fuerte -LRB- donde ninguna coalici\u00f3n puede mejorar el coste de cada uno de sus miembros -RRB- independientemente de los costes espec\u00edficos en los bordes. Nuestros principales resultados de existencia son los siguientes: -LRB- 1 -RRB- Para una \u00fanica fuente y sumidero mostramos que siempre hay un equilibrio fuerte -LRB- tanto para juegos de conexi\u00f3n justos como generales -RRB-. -LRB- 2 -RRB- Para una sola fuente y m\u00faltiples sumideros mostramos que para un gr\u00e1fico paralelo en serie siempre existe un equilibrio fuerte -LRB- tanto para juegos de conexi\u00f3n justos como para juegos de conexi\u00f3n general -RRB-. -LRB- 3 -RRB- Para fuentes m\u00faltiples y sumidero mostramos que un gr\u00e1fico paralelo de extensi\u00f3n siempre admite un equilibrio fuerte en juegos de conexi\u00f3n justa. En cuanto a la calidad del equilibrio fuerte, mostramos que en cualquier juego de conexi\u00f3n justa el costo de un equilibrio fuerte es \u0398 -LRB- log n -RRB- de la soluci\u00f3n \u00f3ptima, donde n es el n\u00famero de jugadores. -LRB- Esto debe contrastarse con el precio \u03a9 -LRB- n -RRB- de la anarqu\u00eda para el mismo escenario. -RRB- Para juegos de conexi\u00f3n general de fuente \u00fanica y juegos de conexi\u00f3n justa de fuente \u00fanica, demostramos que un equilibrio fuerte es siempre una soluci\u00f3n \u00f3ptima. * Investigaci\u00f3n financiada en parte por una subvenci\u00f3n de la Fundaci\u00f3n de Ciencias de Israel, la Fundaci\u00f3n Binacional de Ciencias -LRB- BSF -RRB-, la Fundaci\u00f3n Alemana-Israel\u00ed -LRB- GIF -RRB-, la Beca Lady Davis, un premio de la facultad de IBM y el Programa IST de la Comunidad Europea, bajo la Red de Excelencia PASCAL, IST-2002-506778. Esta publicaci\u00f3n s\u00f3lo refleja las opiniones de los autores. 1. INTRODUCCI\u00d3N La teor\u00eda de juegos computacional ha introducido la cuesti\u00f3n de los incentivos en muchos de los problemas cl\u00e1sicos de optimizaci\u00f3n combinatoria. Considere los problemas cl\u00e1sicos de enrutamiento y transporte, como los problemas de multidifusi\u00f3n o de m\u00faltiples productos, que muchas veces se ven de la siguiente manera. Se nos proporciona un gr\u00e1fico con los costos de borde y las demandas de conectividad entre nodos, y nuestro objetivo es encontrar una soluci\u00f3n de costo m\u00ednimo. El punto de vista de la teor\u00eda de juegos asumir\u00eda que cada demanda individual est\u00e1 controlada por un jugador que optimiza su propia utilidad, y el resultado resultante podr\u00eda estar lejos de la soluci\u00f3n \u00f3ptima. Al considerar los incentivos individuales es necesario discutir el concepto de soluci\u00f3n apropiado. Gran parte de la investigaci\u00f3n en teor\u00eda de juegos computacional se ha centrado en el equilibrio cl\u00e1sico de Nash como concepto de soluci\u00f3n primaria. De hecho el equilibrio de Nash tiene muchos beneficios, y lo m\u00e1s importante es que siempre existe -LRB- en estrategias mixtas -RRB-. Sin embargo, el concepto de soluci\u00f3n del equilibrio de Nash s\u00f3lo es resistente a desviaciones unilaterales, mientras que en realidad los jugadores pueden coordinar sus acciones.Un equilibrio fuerte -LSB- 4 -RSB- es un estado del cual ninguna coalici\u00f3n -LRB- de cualquier tama\u00f1o -RRB- puede desviarse y mejorar la utilidad de cada miembro de la coalici\u00f3n -LRB- al tiempo que posiblemente reduce la utilidad de los jugadores fuera de la coalici\u00f3n. coalici\u00f3n -RRB-. Esta resiliencia a las desviaciones de las coaliciones de los jugadores es muy atractiva, y uno puede esperar que una vez que se alcance un equilibrio fuerte, sea muy probable que se mantenga. Desde el punto de vista de la teor\u00eda de juegos computacional, un beneficio adicional de un equilibrio fuerte es que tiene el potencial de reducir la distancia entre la soluci\u00f3n \u00f3ptima y la soluci\u00f3n obtenida como resultado de un comportamiento ego\u00edsta. El precio fuerte de la anarqu\u00eda -LRB- SPoA -RRB-, introducido en -LSB- 1 -RSB-, es la relaci\u00f3n entre el coste del peor equilibrio fuerte y el coste de una soluci\u00f3n \u00f3ptima. Obviamente, el SPoA s\u00f3lo tiene sentido en aquellos casos en los que existe un equilibrio fuerte. Una desventaja importante del equilibrio fuerte es que la mayor\u00eda de los juegos no admiten ning\u00fan equilibrio fuerte. Incluso los juegos cl\u00e1sicos simples como el dilema del prisionero no poseen ning\u00fan equilibrio fuerte -LRB-, lo que tambi\u00e9n es un ejemplo de un juego de congesti\u00f3n que no posee equilibrios fuertes -RRB-. Este desafortunado hecho ha reducido la concentraci\u00f3n en equilibrio fuerte, a pesar de sus propiedades altamente atractivas. En este trabajo nos concentramos en los juegos de conexi\u00f3n de costos compartidos, introducidos por -LSB- 3, 2 -RSB-. En un juego de este tipo, hay un gr\u00e1fico dirigido subyacente con costos de borde, y los usuarios individuales tienen demandas de conectividad -LRB- entre una fuente y un sumidero -RRB-. Consideramos dos modelos. El modelo de conexi\u00f3n de coste justo -LSB- 2 -RSB- permite a cada jugador seleccionar un camino desde la fuente hasta el sumidero2. En este juego, el costo de una ventaja se comparte equitativamente entre todos los jugadores que seleccionaron la ventaja, y el costo del jugador es la suma de sus costos en las ventajas que seleccion\u00f3. El juego de conexi\u00f3n general -LSB- 3 -RSB- permite a cada jugador ofrecer precios por las ventajas. En este juego se compra una ventaja si la suma de las ofertas cubre al menos su coste, y el coste del jugador es la suma de sus ofertas en las ventajas compradas -LRB- en ambos juegos asumimos que el jugador tiene que garantizar la ventaja. conectividad entre su fuente y su sumidero -RRB-. En este trabajo nos centramos en dos cuestiones importantes. El primero es identificar bajo qu\u00e9 condiciones se garantiza la existencia de un equilibrio fuerte, y el segundo es la calidad de los equilibrios fuertes. Para la parte de existencia, identificamos familias de topolog\u00edas de gr\u00e1ficos que poseen un equilibrio fuerte para cualquier asignaci\u00f3n de costos de borde. Se puede ver esta separaci\u00f3n entre la topolog\u00eda del gr\u00e1fico y los costos de los bordes, como una separaci\u00f3n entre la infraestructura subyacente y los costos que los jugadores observan para comprar bordes. Si bien se espera que la infraestructura sea estable durante largos per\u00edodos de tiempo, los costos que observan los jugadores pueden modificarse f\u00e1cilmente en per\u00edodos cortos. Nuestros resultados son los siguientes.Para el caso de un solo bien -LRB- todos los jugadores tienen la misma fuente y sumidero -RRB-, existe un fuerte equilibrio en cualquier gr\u00e1fico -LRB- tanto para juegos de conexi\u00f3n justos como generales -RRB-. Adem\u00e1s, el equilibrio fuerte tambi\u00e9n lo es, mientras que se sabe que cualquier juego de congesti\u00f3n admite al menos un equilibrio de Nash en estrategias puras -LSB- 16 -RSB-. 2El esquema justo de reparto de costos tambi\u00e9n es atractivo desde el punto de vista del dise\u00f1o del mecanismo, ya que es un mecanismo de reparto de costos a prueba de estrategias -LSB- 14 -RSB-. la soluci\u00f3n \u00f3ptima -LRB- es decir, los jugadores comparten un camino m\u00e1s corto desde la fuente com\u00fan hasta el sumidero com\u00fan -RRB-. Para el caso de una \u00fanica fuente y m\u00faltiples sumideros -LRB-, por ejemplo, en un \u00e1rbol de multidifusi\u00f3n -RRB-, mostramos que en un juego de conexi\u00f3n justa existe un equilibrio fuerte si el gr\u00e1fico subyacente es un gr\u00e1fico en serie paralela, y mostramos un ejemplo de una gr\u00e1fica paralela que no es de serie y que no tiene un equilibrio fuerte. Para el caso de m\u00faltiples productos -LRB-, m\u00faltiples fuentes y sumideros -RRB-, mostramos que en un juego de conexi\u00f3n justa si el gr\u00e1fico es un gr\u00e1fico paralelo de extensi\u00f3n entonces siempre hay un equilibrio fuerte, y mostramos un ejemplo de una serie. gr\u00e1fica paralela que no tiene un equilibrio fuerte. Hasta donde sabemos, somos los primeros en proporcionar una caracterizaci\u00f3n topol\u00f3gica de la existencia de equilibrio en juegos en red de m\u00faltiples productos y de una sola fuente. Para cualquier juego de conexi\u00f3n justo mostramos que si existe un equilibrio fuerte, es como m\u00e1ximo un factor de \u0398 -LRB- log n -RRB- de la soluci\u00f3n \u00f3ptima, donde n es el n\u00famero de jugadores. Esto debe contrastarse con el l\u00edmite \u0398 -LRB- n -RRB- que existe para el precio de la anarqu\u00eda -LSB- 2 -RSB-. Para juegos de conexi\u00f3n general de fuente \u00fanica, mostramos que cualquier gr\u00e1fico paralelo en serie posee un equilibrio fuerte y mostramos un ejemplo de un gr\u00e1fico que no tiene un equilibrio fuerte. En este caso tambi\u00e9n demostramos que cualquier equilibrio fuerte es \u00f3ptimo. Trabajo relacionado Recientemente se han proporcionado caracterizaciones topol\u00f3gicas para juegos en red de un solo producto para varias propiedades de equilibrio, incluida la existencia de equilibrio -LSB- 12, 7, 8 -RSB-, la unicidad del equilibrio -LSB- 10 -RSB- y la eficiencia del equilibrio -LSB- 17. , 11 -RSB-. En -LSB-12-RSB- se estudi\u00f3 la existencia de un equilibrio de Nash puro en juegos de congesti\u00f3n de redes de un solo producto con costos o ponderaciones espec\u00edficos para cada jugador. La existencia de un equilibrio fuerte se estudi\u00f3 tanto en juegos de congesti\u00f3n de utilidad decreciente -LRB-, por ejemplo, enrutamiento -RRB- como de utilidad creciente -LRB-, por ejemplo, reparto justo de costos -RRB-. -LSB- 7, 8 -RSB- han proporcionado una caracterizaci\u00f3n topol\u00f3gica completa para la existencia de un SE en juegos de congesti\u00f3n decrecientes de utilidad de un solo bien, y han demostrado que un SE siempre existe si y s\u00f3lo si el gr\u00e1fico subyacente es paralelo a la extensi\u00f3n. -LSB- 19 -RSB- han demostrado que en los juegos de congesti\u00f3n que aumentan la utilidad de un solo bien, la caracterizaci\u00f3n topol\u00f3gica es esencialmente equivalente a enlaces paralelos. Adem\u00e1s,han demostrado que estos resultados tambi\u00e9n son v\u00e1lidos para equilibrios fuertes correlacionados -LRB- en contraste con el entorno decreciente, donde los equilibrios fuertes correlacionados podr\u00edan no existir en absoluto -RRB-. Si bien los juegos de costo compartido justo que estudiamos son juegos de utilidad que aumentan la congesti\u00f3n de la red, derivamos una caracterizaci\u00f3n diferente a -LSB- 19 -RSB- debido a las diferentes suposiciones con respecto a las acciones de los jugadores.3 4. JUEGOS DE CONEXI\u00d3N GENERAL En esta secci\u00f3n, derivar nuestros resultados para juegos de conexi\u00f3n generales. 4.1 Existencia de un equilibrio fuerte Comenzamos con una caracterizaci\u00f3n de la existencia de un equilibrio fuerte en juegos de conexi\u00f3n general sim\u00e9tricos. Similar al Teorema 3.1 -LRB- usando una demostraci\u00f3n similar -RRB- establecemos, TEOREMA 4.1. En todo juego sim\u00e9trico de conexi\u00f3n justa existe un equilibrio fuerte. Si bien cada juego de conexi\u00f3n general de una sola fuente posee un equilibrio de Nash puro -LSB- 3 -RSB-, no necesariamente admite alg\u00fan equilibrio fuerte.11 el juego de conexi\u00f3n justa inspir\u00f3 este ejemplo. TEOREMA 4.2. Existe un juego de conexi\u00f3n general de fuente \u00fanica que no admite ning\u00fan equilibrio fuerte. PRUEBA. Considere un juego de conexi\u00f3n general de fuente \u00fanica con 3 jugadores en el gr\u00e1fico que se muestra en la Figura 4. Mostramos que ninguno de los NE es SE y, por lo tanto, el juego no posee ning\u00fan SE. A continuaci\u00f3n mostramos que para la clase de gr\u00e1ficos paralelos en serie, siempre hay un equilibrio fuerte en el caso de una sola fuente. PRUEBA. Sea \u039b un juego de conexi\u00f3n general de fuente \u00fanica en un SPG G = -LRB- V, E -RRB- con fuente sy sumidero t. Primero consideramos el siguiente orden parcial entre los jugadores. Para los jugadores i y j, tenemos que i \u2192 j si hay un camino dirigido de ti a tj. El algoritmo COMPUTE-SE, considera a los jugadores en orden creciente, comenzando con el jugador 1. Cada jugador i comprar\u00e1 completamente un subconjunto de los bordes, y cualquier jugador j > i considerar\u00e1 el costo de aquellos -LRB- comprados -RRB- bordes como cero. Cuando COMPUTE-SE considera al jugador j, el costo de las aristas que los jugadores 1 a j \u2212 1 han comprado se establece en cero, y el jugador j compra por completo un camino m\u00e1s corto Qj de s a tj. Es decir, para cada arista e G Qj \\ Ui < jQi tenemos pj -LRB- e -RRB- = ce y en caso contrario pj -LRB- e -RRB- = 0. A continuaci\u00f3n mostramos que el algoritmo COMPUTESE calcula un SE. Supongamos a modo de contradicci\u00f3n que el perfil p no es un SE. Entonces, existe una coalici\u00f3n que puede mejorar los costos de todos sus jugadores mediante una desviaci\u00f3n. Sea \u0393 una coalici\u00f3n de tama\u00f1o m\u00ednimo y sea el jugador i = max -LCB- j G \u0393 -RCB-. Para un jugador j G \u0393, sean \u00af Qj y \u00af pj el camino y el pago del jugador j despu\u00e9s de la desviaci\u00f3n, respectivamente. Sea Q ' un camino desde el sumidero del jugador i, es decir, ti, hasta el sumidero de G, es decir, entonces Q = \u00af Qi UQ ' es un camino desde la fuente s hasta el sumidero t. Para cualquier jugador j < i, sea yj el v\u00e9rtice de intersecci\u00f3n de Q y tj -LRB- seg\u00fan el Lema 2.1, se garantiza que existe -RRB-. Sea y el v\u00e9rtice m\u00e1s alejado del camino Q tal que y = yj para alg\u00fan j < i.El camino desde la fuente s al nodo y fue pagado en su totalidad por los jugadores j < i en p -LRB- antes de la desviaci\u00f3n -RRB-. Hay dos casos que consideramos. caso a: Despu\u00e9s de la desviaci\u00f3n, el jugador i no paga por las aristas en U j \u2208 \u0393 \\ -LCB- i -RCB- \u00af Qj. Antes de la desviaci\u00f3n de la coalici\u00f3n \u0393, los jugadores j < i pagaron \u00edntegramente un camino de s a y. A continuaci\u00f3n mostramos que ning\u00fan jugador k > i paga por ninguna ventaja en ning\u00fan camino desde sa ti. Considere un jugador k > i y sea Q0k = Qk U Q00k, donde Q00k es un camino que conecta tk con t. Sea yk el v\u00e9rtice de intersecci\u00f3n de Q0k y ti. Dado que existe un camino de s a yk que fue pagado en su totalidad por los jugadores j < k antes de la desviaci\u00f3n, en particular el camino Qis, yk, el jugador k no pagar\u00e1 por ninguna ventaja en ning\u00fan camino que conecte s e yk. Por lo tanto, el jugador i paga completamente por todas las aristas del camino \u00af Qiy, ti, es decir, \u00af pi -LRB- e -RRB- = ce para todas las aristas e E \u00af Qiy, ti. Ahora considere el algoritmo COMPUTAR en el paso en el que el jugador i selecciona el camino m\u00e1s corto desde la fuente s hasta su sumidero ti y determina su pago pi. En este punto, el jugador i podr\u00eda comprar el camino \u00af Qiy, ti, ya que los jugadores j < i ya pagaron un camino de s a y. Por lo tanto, ci -LRB- \u00af p -RRB- > ci -LRB- p -RRB-. Esto contradice el hecho de que el jugador i mejor\u00f3 su costo y por lo tanto no todos los jugadores de \u0393 reducen su costo. Esto implica que p es un equilibrio fuerte. 4.2 El alto precio de la anarqu\u00eda Si bien para cada juego de conexi\u00f3n general de fuente \u00fanica se cumple que PoS = 1 -LSB- 3 -RSB-, el precio de la anarqu\u00eda puede ser tan grande como n, incluso para dos bordes paralelos. Aqu\u00ed mostramos que cualquier equilibrio fuerte en juegos de conexi\u00f3n general de fuente \u00fanica produce el costo \u00f3ptimo. PRUEBA. Sea p = -LRB- p1,..., pn -RRB- un equilibrio fuerte, y sea T \u2217 el \u00e1rbol de Steiner de costo m\u00ednimo para todos los jugadores, arraigado en las fuentes -LRB- \u00fanicas -RRB-. Sea Te \u2217 el sub\u00e1rbol de T \u2217 desconectado de s cuando se elimina el borde e. Sea \u0393 -LRB- Te -RRB- el conjunto de jugadores que tienen sumideros en Te. Para un conjunto de aristas E, sea c -LRB- E -RRB- = Ee \u2208 E ce. Supongamos a modo de contradicci\u00f3n que c -LRB- p -RRB- > c -LRB- T \u2217 -RRB-. Demostraremos que existe un sub\u00e1rbol T0 de T \u2217, que conecta un subconjunto de jugadores \u0393 C _ N, y un nuevo conjunto de pagos \u00af p, tal que para cada i E \u0393, ci -LRB- \u00af p - RRB- < ci -LRB- p -RRB-. Esto contradice el supuesto de que p es un equilibrio fuerte. Primero mostramos c\u00f3mo encontrar un sub\u00e1rbol T0 de T \u2217, tal que para cualquier arista e, los pagos de los jugadores con sumideros en Te \u2217 sean mayores que el costo de Te \u2217 U -LCB- e -RCB-. Para construir T0, defina una ventaja e como mala si el costo de Te \u2217 U -LCB- e -RCB- es al menos los pagos de los jugadores con sumideros en Te \u2217, es decir, c -LRB- Te \u2217 U -LCB - e -RCB- -RRB- > P -LRB- Te \u2217 -RRB-. Sea B el conjunto de aristas malas. Por lo tanto, en T0 para cada arista e, tenemos que c -LRB- Te0 U -LCB- e -RCB- -RRB- < P -LRB- T0e -RRB-.Lo que queda es encontrar pagos p \u00af para los jugadores en \u0393 -LRB- T0 -RRB- de modo que comprar\u00e1n el \u00e1rbol T0 y cada jugador en \u0393 -LRB- T0 -RRB- reducir\u00e1 su costo, es decir, ci -LRB- p -RRB- > ci -LRB- \u00af p -RRB- para i E \u0393 -LRB- T0 -RRB-. -LRB- Recordemos que los pagos tienen la restricci\u00f3n de que el jugador i solo puede pagar por las aristas en el camino de s a ti. -RRB- Ahora definiremos los pagos de la coalici\u00f3n \u00af p. Sean ci -LRB- \u00af p, T0 e \u2208 Te \u00af pi -LRB- e -RRB- los pagos del jugador i por el sub\u00e1rbol T0e. Considere el siguiente proceso ascendente que define \u00af p. Asignamos los pagos del borde e en T0, luego asignamos pagos a todos los bordes en T0e. Por lo tanto, podemos actualizar los pagos p \u00af de los jugadores i E \u0393 -LRB- T0e -RRB-, estableciendo d\u00f3nde usamos el hecho de que E e -RRB-.", "keyphrases": ["juego de conexi\u00f3n de costos compartidos", "numero de jugador", "fuente \u00fanica y fregadero", "fregadero m\u00faltiple de fuente \u00fanica", "fuente m\u00faltiple y fregadero", "costo del edg", "juego de conexi\u00f3n justa", "juego de conexi\u00f3n de g\u00e9nero", "topolog\u00eda gr\u00e1fica", "equilibrio fuerte", "carbonita", "costo espec\u00edfico", "gr\u00e1fico paralelo extendido", "soluci\u00f3n \u00f3ptima"]}
{"file_name": "C-3", "text": "Aplicaciones autoadaptativas en la cuadr\u00edcula Resumen Las cuadr\u00edculas son inherentemente heterog\u00e9neas y din\u00e1micas. Un problema importante en la computaci\u00f3n grid es la selecci\u00f3n de recursos, es decir, encontrar un conjunto de recursos apropiado para la aplicaci\u00f3n. Otro problema es la adaptaci\u00f3n a las caracter\u00edsticas cambiantes del entorno de la red. Las soluciones existentes a estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicaci\u00f3n. Sin embargo, construir tales modelos es una tarea compleja. En este art\u00edculo, investigamos un enfoque que no requiere modelos de desempe\u00f1o. Iniciamos una aplicaci\u00f3n sobre cualquier conjunto de recursos. Durante la ejecuci\u00f3n de la aplicaci\u00f3n, recopilamos peri\u00f3dicamente estad\u00edsticas sobre la ejecuci\u00f3n de la aplicaci\u00f3n y deducimos los requisitos de la aplicaci\u00f3n a partir de estas estad\u00edsticas. Luego, ajustamos el conjunto de recursos para que se ajuste mejor a las necesidades de la aplicaci\u00f3n. Este enfoque nos permite evitar cuellos de botella en el rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos y, por lo tanto, puede generar mejoras de rendimiento significativas. Evaluamos nuestro enfoque en una serie de escenarios t\u00edpicos del Grid. 1. Introducci\u00f3n En los \u00faltimos a\u00f1os, la computaci\u00f3n grid se ha convertido en una alternativa real a la computaci\u00f3n paralela tradicional. Una red proporciona mucha potencia computacional y, por lo tanto, ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en m\u00faltiples sitios al mismo tiempo -LRB- 7; 15 ; 20 -RRB-. Sin embargo, la complejidad de los entornos Grid tambi\u00e9n es muchas veces mayor que la de las m\u00e1quinas paralelas tradicionales como clusters y supercomputadoras. Un problema importante es la selecci\u00f3n de recursos: seleccionar un conjunto de nodos inform\u00e1ticos de modo que la aplicaci\u00f3n alcance un buen rendimiento. En un entorno de red, este problema es a\u00fan m\u00e1s dif\u00edcil debido a la heterogeneidad de los recursos: los nodos de computaci\u00f3n tienen varios Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red var\u00edan con el tiempo: los enlaces de red o los nodos de computaci\u00f3n pueden sobrecargarse, o Los nodos de computaci\u00f3n pueden dejar de estar disponibles debido a fallas o porque han sido reclamados por una aplicaci\u00f3n de mayor prioridad. Adem\u00e1s, es posible que est\u00e9n disponibles nuevos y mejores recursos. Por lo tanto, para mantener un nivel de rendimiento razonable, la aplicaci\u00f3n debe adaptarse a las condiciones cambiantes. El problema de adaptaci\u00f3n se puede reducir al problema de selecci\u00f3n de recursos: la fase de selecci\u00f3n de recursos se puede repetir durante la ejecuci\u00f3n de la aplicaci\u00f3n, ya sea a intervalos regulares, o cuando se detecta un problema de rendimiento, o cuando hay nuevos recursos disponibles. Este enfoque ha sido adoptado por varios sistemas -LRB- 5 ; 14; 18 -RRB-. Para la selecci\u00f3n de recursos, se estima el tiempo de ejecuci\u00f3n de la aplicaci\u00f3n para algunos conjuntos de recursos y se selecciona para su ejecuci\u00f3n el conjunto que produce el tiempo de ejecuci\u00f3n m\u00e1s corto. Sin embargo, predecir el tiempo de ejecuci\u00f3n de la aplicaci\u00f3n en un conjunto determinado de recursos requiere conocimiento sobre la aplicaci\u00f3n. Normalmente, se utiliza un modelo de rendimiento anal\u00edtico,pero construir un modelo de este tipo es intr\u00ednsecamente dif\u00edcil y requiere una experiencia que los programadores de aplicaciones tal vez no tengan. En este art\u00edculo, presentamos y evaluamos un enfoque alternativo para la adaptaci\u00f3n de aplicaciones y la selecci\u00f3n de recursos que no necesita un modelo de rendimiento. Iniciamos una aplicaci\u00f3n sobre cualquier conjunto de recursos. Durante la ejecuci\u00f3n de la aplicaci\u00f3n, recopilamos peri\u00f3dicamente informaci\u00f3n sobre los tiempos de comunicaci\u00f3n y los tiempos de inactividad de los procesadores. Utilizamos estas estad\u00edsticas para estimar autom\u00e1ticamente los requisitos de recursos de la aplicaci\u00f3n. A continuaci\u00f3n, ajustamos el conjunto de recursos en el que se ejecuta la aplicaci\u00f3n agregando o eliminando nodos inform\u00e1ticos o incluso cl\u00fasteres completos. Se agregan o eliminan procesadores para permanecer entre los umbrales, adapt\u00e1ndose as\u00ed autom\u00e1ticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de las aplicaciones en muchas situaciones diferentes que son t\u00edpicas de la computaci\u00f3n grid. Maneja todos los casos siguientes: Nuestro trabajo supone que la aplicaci\u00f3n es maleable y puede ejecutarse -LRB- de manera eficiente -RRB- en m\u00faltiples sitios de una red -LRB- es decir, utilizando la asignaci\u00f3n conjunta -LRB- 15 -RRB- -RRB- . latencias de \u00e1rea. Hemos aplicado nuestras ideas a aplicaciones de divide y vencer\u00e1s que satisfacen estos requisitos. Se ha demostrado que divide y vencer\u00e1s es un paradigma atractivo para la programaci\u00f3n de aplicaciones grid -LRB- 4; 20 -RRB-. Creemos que nuestro enfoque puede extenderse a otras clases de aplicaciones con los supuestos dados. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de divide y vencer\u00e1s habilitadas para grid -LRB- 20 -RRB-. El resto del art\u00edculo se estructura de la siguiente manera. En la Secci\u00f3n 2, explicamos qu\u00e9 suposiciones hacemos sobre las aplicaciones y los recursos de la red. En la Secci\u00f3n 3, presentamos nuestra estrategia de selecci\u00f3n y adaptaci\u00f3n de recursos. En la Secci\u00f3n 4, describimos su implementaci\u00f3n en el marco Satin. En la Secci\u00f3n 5, evaluamos nuestro enfoque en varios escenarios de red. En la Secci\u00f3n 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Secci\u00f3n 7, concluimos y describimos el trabajo futuro. 2. Antecedentes y suposiciones En esta secci\u00f3n, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se ejecutan en varios sitios al mismo tiempo, donde los sitios son cl\u00fasteres o supercomputadoras. Los procesadores que pertenecen a un sitio est\u00e1n conectados mediante una LAN r\u00e1pida con baja latencia y gran ancho de banda. Los diferentes sitios est\u00e1n conectados por una WAN. La comunicaci\u00f3n entre sitios sufre de altas latencias. Estudiamos el problema de la adaptaci\u00f3n en el context de aplicaciones de divide y vencer\u00e1s. Sin embargo, creemos que nuestra metodolog\u00eda tambi\u00e9n se puede utilizar para otros tipos de aplicaciones. En esta secci\u00f3n resumimos los supuestos sobre las aplicaciones que son importantes para nuestro enfoque. La primera suposici\u00f3n que hacemos es que la aplicaci\u00f3n es maleable, es decir,es capaz de manejar procesadores que se unen y salen del c\u00e1lculo en curso. En -LRB-23-RRB-, mostramos c\u00f3mo las aplicaciones de divide y vencer\u00e1s pueden hacerse tolerantes a fallas y maleables. Los procesadores se pueden agregar o quitar en cualquier punto del c\u00e1lculo con poca sobrecarga. La segunda suposici\u00f3n es que la aplicaci\u00f3n puede ejecutarse de manera eficiente en procesadores con diferentes velocidades. Esto se puede lograr mediante el uso de una estrategia de equilibrio de carga din\u00e1mica, como el robo de trabajo utilizado por las aplicaciones de divide y vencer\u00e1s -LRB- 19 -RRB-. Adem\u00e1s, las aplicaciones master-worker suelen utilizar estrategias din\u00e1micas de equilibrio de carga -LRB-, por ejemplo, MW, un marco para escribir aplicaciones master-worker habilitadas para grid -LRB- 12 -RRB- -RRB-. Consideramos que es una suposici\u00f3n razonable para una aplicaci\u00f3n grid, ya que las aplicaciones para las cuales el procesador m\u00e1s lento se convierte en un cuello de botella no podr\u00e1n utilizar eficientemente los recursos de la grid. Finalmente, la aplicaci\u00f3n debe ser insensible a las latencias de \u00e1rea amplia, para que pueda ejecutarse eficientemente en una grilla de \u00e1rea amplia -LRB-16; 17 -RRB-. 6. Trabajo relacionado Varios proyectos Grid abordan la cuesti\u00f3n de la selecci\u00f3n y adaptaci\u00f3n de recursos. En GrADS -LRB- 18 -RRB- y ASSIST -LRB- 1 -RRB-, la selecci\u00f3n y adaptaci\u00f3n de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecuci\u00f3n de las aplicaciones. En la fase de selecci\u00f3n de recursos, se examina una cantidad de conjuntos de recursos posibles y se selecciona el conjunto de recursos con el tiempo de ejecuci\u00f3n previsto m\u00e1s corto. Si se detecta una degradaci\u00f3n del rendimiento durante el c\u00e1lculo, se repite la fase de selecci\u00f3n de recursos. GrADS utiliza la relaci\u00f3n entre los tiempos de ejecuci\u00f3n previstos -LRB- de determinadas fases de la aplicaci\u00f3n -RRB- y los tiempos de ejecuci\u00f3n reales como indicador del rendimiento de la aplicaci\u00f3n. ASSIST utiliza el n\u00famero de iteraciones por unidad de tiempo -LRB- para aplicaciones iterativas -RRB- o el n\u00famero de tareas por unidad de tiempo -LRB- para aplicaciones regulares de maestro-trabajador -RRB- como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de desempe\u00f1o. La principal ventaja es que una vez conocido el modelo de rendimiento, el sistema puede tomar decisiones de migraci\u00f3n m\u00e1s precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento no se adapta con la adaptaci\u00f3n, se conoce el problema de encontrar un conjunto de recursos \u00f3ptimo -LRB-, es decir, el conjunto de recursos con el tiempo de ejecuci\u00f3n m\u00ednimo. RRB- es NP-completo. A medida que aumenta el n\u00famero de recursos de red disponibles, la precisi\u00f3n de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que pueden examinarse en un tiempo razonable se vuelve m\u00e1s peque\u00f1o. Otra desventaja de estos sistemas es que la detecci\u00f3n de degradaci\u00f3n del rendimiento es adecuada s\u00f3lo para aplicaciones iterativas o regulares. Cactus -LRB- 2 -RRB- y GridWay -LRB- 14 -RRB- no utilizan modelos de rendimiento. Sin embargo, estos marcos solo son adecuados para aplicaciones secuenciales -LRB- GridWay -RRB- o de un solo sitio -LRB- Cactus -RRB-.En ese caso, el problema de selecci\u00f3n de recursos se reduce a seleccionar la m\u00e1quina o el cl\u00faster m\u00e1s r\u00e1pido. La velocidad del reloj del procesador, la carga promedio y la cantidad de procesadores en un cl\u00faster -LRB- Cactus -RRB- se utilizan para clasificar los recursos y se selecciona el recurso con el rango m\u00e1s alto. La aplicaci\u00f3n se migra si se detecta una degradaci\u00f3n del rendimiento o se descubren mejores recursos. Tanto Cactus como GridWay utilizan el n\u00famero de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitaci\u00f3n de esta metodolog\u00eda es que es adecuada s\u00f3lo para aplicaciones secuenciales o de un solo sitio. Adem\u00e1s, la selecci\u00f3n de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detecci\u00f3n de degradaci\u00f3n del rendimiento es adecuada s\u00f3lo para aplicaciones iterativas y no puede usarse para c\u00e1lculos irregulares como problemas de b\u00fasqueda y optimizaci\u00f3n. El problema de la selecci\u00f3n de recursos tambi\u00e9n fue estudiado por el proyecto AppLeS -LRB- 5 -RRB-. En el context de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Sobre la base de dicho modelo, se construye un agente de programaci\u00f3n que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y la mejor programaci\u00f3n de aplicaciones en este conjunto. Los agentes de programaci\u00f3n de AppleS se escriben caso por caso y no se pueden reutilizar para otra aplicaci\u00f3n. Tambi\u00e9n se desarrollaron dos plantillas reutilizables para clases espec\u00edficas de aplicaciones, a saber, aplicaciones master-worker -LRB- plantilla AMWAT -RRB- y barrido de par\u00e1metros -LRB- plantilla APST -RRB-. 2 de cada 9 cl\u00fasteres comenzaron a fallar agregando nodos. Se alcanzaron 96 nodos. En -LRB- 13 -RRB-, se estudia el problema de programar aplicaciones maestro-trabajador. Por tanto, el problema se reduce a encontrar el n\u00famero adecuado de trabajadores. El enfoque aqu\u00ed es similar al nuestro en el sentido de que no se utiliza ning\u00fan modelo de desempe\u00f1o. En cambio, el sistema intenta deducir los requisitos de la aplicaci\u00f3n en tiempo de ejecuci\u00f3n y ajusta la cantidad de trabajadores para acercarse al n\u00famero ideal. 7. Conclusiones y trabajo futuro En este art\u00edculo, investigamos el problema de la selecci\u00f3n y adaptaci\u00f3n de recursos en entornos de red. Los enfoques existentes para estos problemas normalmente suponen la existencia de un modelo de rendimiento que permite predecir tiempos de ejecuci\u00f3n de aplicaciones en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es intr\u00ednsecamente dif\u00edcil y requiere conocimientos sobre la aplicaci\u00f3n. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicaci\u00f3n. Iniciamos la aplicaci\u00f3n en un conjunto arbitrario de recursos y monitoreamos su rendimiento. La supervisi\u00f3n del rendimiento nos permite conocer ciertos requisitos de la aplicaci\u00f3n, como la cantidad de procesadores que necesita la aplicaci\u00f3n o los requisitos de ancho de banda de la aplicaci\u00f3n. Usamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no da como resultado el conjunto de recursos \u00f3ptimo, sino un conjunto de recursos razonable, es decirun conjunto libre de diversos cuellos de botella de rendimiento, como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque tambi\u00e9n permite que la aplicaci\u00f3n se adapte a las condiciones cambiantes de la red. Si la eficiencia promedio ponderada cae por debajo de cierto nivel, el coordinador de adaptaci\u00f3n comienza a eliminar los nodos \"peores\". Si la eficiencia promedio ponderada supera un cierto nivel, se agregan nuevos nodos. La aplicaci\u00f3n se adapta de forma totalmente autom\u00e1tica a las condiciones cambiantes. El trabajo futuro implicar\u00e1 ampliar nuestra estrategia de adaptaci\u00f3n para apoyar la migraci\u00f3n oportunista. Sin embargo, esto requiere programadores grid con una funcionalidad m\u00e1s sofisticada que la que existe actualmente. Tambi\u00e9n se necesita m\u00e1s investigaci\u00f3n para reducir los gastos generales de evaluaci\u00f3n comparativa. Otra l\u00ednea de investigaci\u00f3n que deseamos investigar es el uso del control de retroalimentaci\u00f3n para refinar la estrategia de adaptaci\u00f3n durante la ejecuci\u00f3n de la aplicaci\u00f3n. Finalmente, la implementaci\u00f3n centralizada del coordinador de adaptaci\u00f3n podr\u00eda convertirse en un cuello de botella para aplicaciones que se ejecutan en un n\u00famero muy grande de nodos -LRB-, cientos o miles -RRB-.", "keyphrases": ["computaci\u00f3n en red", "selecci\u00f3n de recursos", "entorno de red", "computaci\u00f3n paralela", "entorno paralelo homog\u00e9neo", "heterogeno de recursos", "red de \u00e1rea local de gran ancho de banda", "red de \u00e1rea amplia de menor ancho de banda", "enlace de red", "tiempo comun", "tiempo de inactividad del procesador", "grado de paralelo", "sobrecarga de recursos", "divide y vencer\u00e1s"]}
{"file_name": "I-19", "text": "Oferta \u00f3ptima en subastas simult\u00e1neas de segundo precio de bienes perfectamente sustituibles RESUMEN Derivamos estrategias de oferta \u00f3ptimas para un agente de oferta global que participa en m\u00faltiples subastas simult\u00e1neas de segundo precio con sustitutos perfectos. Primero consideramos un modelo en el que todos los dem\u00e1s postores son locales y participan en una \u00fanica subasta. Para este caso, demostramos que, asumiendo la libre disposici\u00f3n, el postor global siempre debe realizar ofertas distintas de cero en todas las subastas disponibles, independientemente de la distribuci\u00f3n de valoraci\u00f3n de los postores locales. Adem\u00e1s, para distribuciones de valoraci\u00f3n no decrecientes, demostramos que el problema de encontrar las ofertas \u00f3ptimas se reduce a dos dimensiones. Estos resultados son v\u00e1lidos tanto en el caso en que se conoce el n\u00famero de postores locales como cuando este n\u00famero est\u00e1 determinado por una distribuci\u00f3n de Poisson. Este an\u00e1lisis se extiende a los mercados en l\u00ednea donde, normalmente, las subastas ocurren de forma simult\u00e1nea y secuencial. Adem\u00e1s, al combinar resultados anal\u00edticos y de simulaci\u00f3n, demostramos que se obtienen resultados similares en el caso de varios postores globales, siempre que el mercado est\u00e9 formado por postores globales y locales. Finalmente, abordamos la eficiencia del mercado en general y mostramos que la informaci\u00f3n sobre el n\u00famero de postores locales es un determinante importante de la forma en que un postor global afecta la eficiencia. 1. INTRODUCCI\u00d3N El reciente aumento del inter\u00e9s en las subastas en l\u00ednea ha resultado en un n\u00famero cada vez mayor de subastas que ofrecen art\u00edculos muy similares o. En eBay, por ejemplo, a menudo hay cientos o incluso miles de subastas simult\u00e1neas en todo el mundo que venden art\u00edculos sustituibles1. En este context, es esencial desarrollar estrategias de licitaci\u00f3n que los agentes aut\u00f3nomos puedan utilizar para operar de manera efectiva en una amplia cantidad de subastas. Sin embargo, como mostraremos, este an\u00e1lisis tambi\u00e9n es relevante en un context m\u00e1s amplio en el que las subastas se realizan de forma secuencial y simult\u00e1nea. Por el contrario, aqu\u00ed consideramos estrategias de oferta para mercados con m\u00faltiples subastas simult\u00e1neas y sustitutos perfectos. En particular, nos centramos en Vickrey o subastas de oferta sellada de segundo precio. Sin embargo, nuestros resultados se generalizan a entornos con subastas en ingl\u00e9s, ya que \u00e9stas son estrat\u00e9gicamente equivalentes a las subastas de segundo precio. Dentro de este entorno, podemos caracterizar, por primera vez, la estrategia de maximizaci\u00f3n de la utilidad de un postor para ofertar simult\u00e1neamente en cualquier n\u00famero de subastas y para cualquier tipo de distribuci\u00f3n de valoraci\u00f3n del postor. Con m\u00e1s detalle, primero consideramos un mercado en el que un \u00fanico postor, llamado postor global, puede ofertar en cualquier n\u00famero de subastas, mientras que se supone que los otros postores, llamados postores locales, ofertan s\u00f3lo en una \u00fanica subasta. Para este caso, encontramos los siguientes resultados: \u2022 Mientras que en el caso de una subasta \u00fanica de segundo precio la mejor estrategia de un postor es ofertar su valor real, la mejor estrategia para un postor global es ofertar por debajo de \u00e9l. \u2022 Podemos demostrar que,Incluso si un postor global requiere solo un art\u00edculo, la utilidad esperada se maximiza al participar en todas las subastas que venden el art\u00edculo deseado. \u2022 Encontrar la oferta \u00f3ptima para cada subasta puede ser una tarea ardua si se consideran todas las combinaciones posibles. 2. TRABAJOS RELACIONADOS La investigaci\u00f3n en el \u00e1rea de subastas simult\u00e1neas se puede segmentar seg\u00fan dos l\u00edneas generales. Estos an\u00e1lisis se suelen utilizar cuando el formato de subasta empleado en las subastas concurrentes es el mismo -LRB-, por ejemplo, hay M subastas Vickrey o M subastas de primer precio -RRB-. Este art\u00edculo adopta el primer enfoque al estudiar un mercado de M subastas Vickrey simult\u00e1neas, ya que este enfoque produce estrategias de oferta demostrablemente \u00f3ptimas. Su trabajo analiza un mercado formado por parejas con valoraciones iguales que quieren pujar por una c\u00f3moda. Por lo tanto, el espacio de oferta de la pareja puede contener como m\u00e1ximo dos ofertas, ya que el marido y la mujer pueden estar como m\u00e1ximo en dos subastas distribuidas geogr\u00e1ficamente simult\u00e1neamente. Deducen un equilibrio de Nash de estrategia mixta para el caso especial en el que el n\u00famero de compradores es grande. Nuestro an\u00e1lisis se diferencia del de ellos en que estudiamos subastas concurrentes en las que los postores tienen valoraciones diferentes y el postor global puede pujar en todas las subastas al mismo tiempo -LRB- lo cual es totalmente posible dados agentes aut\u00f3nomos -RRB-. A continuaci\u00f3n, -LSB- 7 -RSB- estudi\u00f3 el caso de subastas simult\u00e1neas con bienes complementarios. Analizan el caso de los postores locales y globales y caracterizan las ofertas de los compradores y la eficiencia del mercado resultante. La configuraci\u00f3n proporcionada en -LSB- 7 -RSB- se extiende a\u00fan m\u00e1s al caso de valores comunes en -LSB- 9 -RSB-. Sin embargo, ninguno de estos trabajos se extiende f\u00e1cilmente al caso de bienes sustituibles que consideramos. Para este caso especial se deriva el espacio de estrategias de equilibrio mixto sim\u00e9trico, pero nuevamente nuestro resultado es m\u00e1s general. Finalmente, -LSB- 11 -RSB- considera el caso de subastas inglesas concurrentes, en las que desarrolla algoritmos de puja para compradores con diferentes actitudes de riesgo. Sin embargo, obliga a que las ofertas sean las mismas en todas las subastas, lo que mostramos en este documento no siempre es \u00f3ptimo. 7. CONCLUSIONES En este art\u00edculo, derivamos estrategias de maximizaci\u00f3n de la utilidad para ofertar en m\u00faltiples subastas simult\u00e1neas de segundo precio. Primero analizamos el caso en el que un \u00fanico postor global puja en todas las subastas, mientras que todos los dem\u00e1s postores son locales y pujan en una \u00fanica subasta. Para esta configuraci\u00f3n, encontramos el resultado contrario a la intuici\u00f3n de que es \u00f3ptimo realizar ofertas distintas de cero en todas las subastas que venden el art\u00edculo deseado, incluso cuando un postor solo requiere un art\u00edculo y no obtiene ning\u00fan beneficio adicional por tener m\u00e1s. Por tanto, un comprador potencial puede lograr un beneficio considerable participando en m\u00faltiples subastas y empleando una estrategia de oferta \u00f3ptima. Para una serie de distribuciones de valoraci\u00f3n comunes, mostramos anal\u00edticamente que el problema de encontrar ofertas \u00f3ptimas se reduce a dos dimensiones.Esto simplifica considerablemente el problema de optimizaci\u00f3n original y, por tanto, puede utilizarse en la pr\u00e1ctica para calcular las ofertas \u00f3ptimas para cualquier n\u00famero de subastas. Adem\u00e1s, investigamos un entorno con m\u00faltiples postores globales combinando soluciones anal\u00edticas con un enfoque de simulaci\u00f3n. Encontramos que la estrategia de un postor global no se estabiliza cuando s\u00f3lo hay postores globales presentes en el mercado, sino que s\u00f3lo converge cuando tambi\u00e9n hay postores locales. Sostenemos, sin embargo, que es probable que los mercados del mundo real contengan postores tanto locales como globales. Los resultados convergentes son entonces muy similares al escenario con un \u00fanico postor global, y encontramos que un postor se beneficia al ofertar de manera \u00f3ptima en m\u00faltiples subastas. Para entornos m\u00e1s complejos con m\u00faltiples postores globales, la simulaci\u00f3n se puede utilizar para encontrar estas ofertas para casos espec\u00edficos. Finalmente, comparamos la eficiencia de un mercado con m\u00faltiples subastas simult\u00e1neas con y sin un postor global. Mostramos que, si el postor puede predecir con precisi\u00f3n el n\u00famero de postores locales en cada subasta, la eficiencia aumenta ligeramente. Por el contrario, si hay mucha incertidumbre, la eficiencia disminuye significativamente a medida que aumenta el n\u00famero de subastas debido a la mayor probabilidad de que un postor global gane m\u00e1s de dos art\u00edculos. Estos resultados muestran que la forma en que un postor global afecta la eficiencia y, por tanto, el bienestar social, depende de la informaci\u00f3n de que dispone ese postor global. En trabajos futuros, pretendemos extender los resultados a sustitutos imperfectos -LRB-, es decir, cuando un postor global gana al ganar art\u00edculos adicionales -RRB-, y a entornos donde las subastas ya no son id\u00e9nticas. Esto \u00faltimo surge, por ejemplo, cuando el n\u00famero de postores locales -LRB- promedio -RRB- difiere por subasta o las subastas tienen diferentes configuraciones para par\u00e1metros como el precio de reserva.la eficiencia disminuye significativamente a medida que aumenta el n\u00famero de subastas debido a la mayor probabilidad de que un postor global gane m\u00e1s de dos art\u00edculos. Estos resultados muestran que la forma en que un postor global afecta la eficiencia y, por tanto, el bienestar social, depende de la informaci\u00f3n de que dispone ese postor global. En trabajos futuros, pretendemos extender los resultados a sustitutos imperfectos -LRB-, es decir, cuando un postor global gana al ganar art\u00edculos adicionales -RRB-, y a entornos donde las subastas ya no son id\u00e9nticas. Esto \u00faltimo surge, por ejemplo, cuando el n\u00famero de postores locales -LRB- promedio -RRB- difiere por subasta o las subastas tienen diferentes configuraciones para par\u00e1metros como el precio de reserva.la eficiencia disminuye significativamente a medida que aumenta el n\u00famero de subastas debido a la mayor probabilidad de que un postor global gane m\u00e1s de dos art\u00edculos. Estos resultados muestran que la forma en que un postor global afecta la eficiencia y, por tanto, el bienestar social, depende de la informaci\u00f3n de que dispone ese postor global. En trabajos futuros, pretendemos extender los resultados a sustitutos imperfectos -LRB-, es decir, cuando un postor global gana al ganar art\u00edculos adicionales -RRB-, y a entornos donde las subastas ya no son id\u00e9nticas. Esto \u00faltimo surge, por ejemplo, cuando el n\u00famero de postores locales -LRB- promedio -RRB- difiere por subasta o las subastas tienen diferentes configuraciones para par\u00e1metros como el precio de reserva.", "keyphrases": ["estrategia de oferta \u00f3ptima", "agente de ofertas globales", "subasta simult\u00e1nea de segundo precio", "distribuci\u00f3n de valor no decreciente", "mercado en l\u00ednea", "sistema multiag", "eficiencia del mercado", "sustituto perfecto", "subasta vickrei", "ciencias sociales y del comportamiento", "utilitariomaximis strategi"]}
{"file_name": "J-2", "text": "Redistribuci\u00f3n \u00f3ptima de los pagos de VCG en el peor de los casos en subastas de art\u00edculos heterog\u00e9neos con demanda unitaria RESUMEN Muchos problemas importantes en los sistemas multiagente implican la asignaci\u00f3n de m\u00faltiples recursos entre los agentes. Para los problemas de asignaci\u00f3n de recursos, el conocido mecanismo VCG satisface una lista de propiedades deseadas, que incluyen eficiencia, idoneidad estrat\u00e9gica, racionalidad individual y propiedad de no d\u00e9ficit. Sin embargo, el VCG generalmente no tiene un equilibrio presupuestario. En el caso del VCG, los agentes pagan los pagos del VCG, lo que reduce el bienestar social. Para compensar la p\u00e9rdida de bienestar social debido a los pagos del VCG, se introdujeron mecanismos de redistribuci\u00f3n del VCG. Estos mecanismos tienen como objetivo redistribuir la mayor cantidad posible de pagos de VCG a los agentes, manteniendo al mismo tiempo las propiedades deseadas antes mencionadas del mecanismo de VCG. Continuamos la b\u00fasqueda de mecanismos \u00f3ptimos de redistribuci\u00f3n de VCG en el peor de los casos: mecanismos que maximicen la fracci\u00f3n del pago total de VCG redistribuido en el peor de los casos. Anteriormente, un mecanismo de redistribuci\u00f3n de VCG \u00f3ptimo en el peor de los casos -LRB- denotado por la OMA -RRB- se caracterizaba para subastas de unidades m\u00faltiples con valores marginales no crecientes -LSB- 7 -RSB-. Posteriormente, WCO se generaliz\u00f3 a entornos que involucraban \u00edtems heterog\u00e9neos -LSB- 4 -RSB-, dando como resultado el mecanismo HETERO. -LSB- 4 -RSB- conjetur\u00f3 que HETERO es factible y \u00f3ptimo en el peor de los casos para subastas de art\u00edculos heterog\u00e9neos con demanda unitaria. En este art\u00edculo, proponemos una forma m\u00e1s natural de generalizar el mecanismo de la OMA. Probamos que nuestro mecanismo generalizado, aunque representado de manera diferente, en realidad coincide con HETERO. Con base en esta nueva representaci\u00f3n de HETERO, demostramos que HETERO es efectivamente factible y \u00f3ptimo en el peor de los casos en subastas de art\u00edculos heterog\u00e9neos con demanda unitaria. Finalmente, conjeturamos que HETERO sigue siendo factible y \u00f3ptimo en el peor de los casos en el entorno a\u00fan m\u00e1s general de subastas combinatorias con sustitutos brutos. 1. INTRODUCCI\u00d3N 1.1 Mecanismos de redistribuci\u00f3n de VCG Muchos problemas importantes en sistemas multiagente implican la asignaci\u00f3n de m\u00faltiples recursos entre los agentes. Para problemas de asignaci\u00f3n de recursos, el conocido mecanismo VCG satisface la siguiente lista de propiedades deseadas: \u2022 Eficiencia: la asignaci\u00f3n maximiza la valoraci\u00f3n total de los agentes -LRB- sin considerar los pagos -RRB-. \u2022 Resistencia a la estrategia: para cualquier agente, informar con veracidad es una estrategia dominante, independientemente del tipo de los dem\u00e1s agentes. \u2022 -LRB- Ex post -RRB- racionalidad individual: La utilidad final de cada agente -LRB- despu\u00e9s de deducir su pago -RRB- siempre es no negativa. \u2022 No deficitario: el pago total de los agentes no es negativo. Sin embargo, el VCG generalmente no tiene un equilibrio presupuestario. En el caso del VCG, los agentes pagan los pagos del VCG, lo que reduce el bienestar social. Para compensar la p\u00e9rdida de bienestar social debido a los pagos del VCG, se introdujeron mecanismos de redistribuci\u00f3n del VCG. Estos mecanismos a\u00fan asignan los recursos utilizando VCG. Adem\u00e1s de VCG,Estos mecanismos intentan redistribuir la mayor cantidad posible de pagos de VCG a los agentes. Requerimos que la redistribuci\u00f3n de un agente sea independiente de su propio tipo. Esto es suficiente para mantener la estrategia y la eficiencia -LRB- un agente no tiene control sobre su propia redistribuci\u00f3n -RRB-. Para dominios conectados sin problemas -LRB- que incluyen subastas de unidades m\u00faltiples con valores marginales no crecientes y subastas de art\u00edculos heterog\u00e9neos con demanda unitaria -RRB-, el requisito anterior tambi\u00e9n es necesario para mantener la eficacia y la eficacia de la estrategia -LSB- 8 -RSB-. Un mecanismo de redistribuci\u00f3n VCG es factible si mantiene todas las propiedades deseadas del mecanismo VCG. Es decir, tambi\u00e9n requerimos que el proceso de redistribuci\u00f3n mantenga la racionalidad individual y la propiedad no deficitaria. Sea n el n\u00famero de agentes. Dado que todos los mecanismos de redistribuci\u00f3n de VCG comienzan asignando de acuerdo con el mecanismo de VCG, un mecanismo de redistribuci\u00f3n de VCG se caracteriza por su esquema de redistribuci\u00f3n r ~ = -LRB- r1, r2,..., rn -RRB-. Seg\u00fan el mecanismo de redistribuci\u00f3n VCG ~ r, la redistribuci\u00f3n del agente i es igual a ri -LRB- 01,..., 0i \u2212 1, 0i +1,..., 0n -RRB-, donde 0j es el tipo del agente j. -LRB- No tenemos que diferenciar entre el tipo verdadero de un agente y su tipo informado, ya que todos los mecanismos de redistribuci\u00f3n de VCG son a prueba de estrategias. -RRB- Un mecanismo de redistribuci\u00f3n de VCG an\u00f3nimo se caracteriza por una \u00fanica funci\u00f3n r. Bajo el mecanismo de redistribuci\u00f3n -LRB- an\u00f3nimo -RRB- VCG r, la redistribuci\u00f3n del agente i es igual a r -LRB- 0 \u2212 i -RRB-, donde 0 \u2212 i es el conjunto m\u00faltiple de los tipos de agentes distintos de i. Usamos \u03b8 ~ para indicar el perfil de tipo. Sea V CG -LRB- ~ \u03b8 -RRB- el total. Organizamos los resultados existentes seg\u00fan su configuraci\u00f3n. Pago VCG para este tipo de perfil. Un mecanismo de redistribuci\u00f3n de VCG r satisface la propiedad no deficitaria si la redistribuci\u00f3n total nunca excede el pago total de VCG. Un mecanismo de redistribuci\u00f3n VCG r es -LRB- ex post -RRB- individualmente racional si la utilidad final de cada agente es siempre no negativa. Despu\u00e9s de la redistribuci\u00f3n, la utilidad del agente i es exactamente su redistribuci\u00f3n r -LRB- \u03b8 \u2212 i -RRB-. Queremos encontrar mecanismos de redistribuci\u00f3n de VCG que maximicen la fracci\u00f3n del pago total de VCG redistribuido en el peor de los casos. Este problema de dise\u00f1o de mecanismo es equivalente al siguiente modelo de optimizaci\u00f3n funcional: En este art\u00edculo, caracterizaremos anal\u00edticamente un mecanismo de redistribuci\u00f3n de VCG \u00f3ptimo en el peor de los casos para subastas de art\u00edculos heterog\u00e9neos con demanda unitaria.1 Concluimos esta subsecci\u00f3n con un ejemplo de mecanismo de redistribuci\u00f3n de VCG en la configuraci\u00f3n m\u00e1s sencilla de subastas de un solo art\u00edculo. En una subasta de un solo art\u00edculo, el tipo de agente es un n\u00famero real no negativo que representa su utilidad para ganar el art\u00edculo. En las subastas de un solo art\u00edculo, el mecanismo de redistribuci\u00f3n Bailey-Cavallo VCG -LSB- 2, 3 -RSB- funciona de la siguiente manera: \u2022 Asigna el art\u00edculo seg\u00fan VCG: el agente 1 gana el art\u00edculo y paga \u03b82. Los dem\u00e1s agentes no ganan nada y no pagan.\u2022 Cada agente recibe una redistribuci\u00f3n que es igual a n1 veces el segundo tipo m\u00e1s alto: los agentes 1 y 2 reciben cada uno n1 \u03b83. Los dem\u00e1s agentes reciben cada uno n1\u03b82. El mecanismo anterior obviamente mantiene la eficacia y la eficacia de la estrategia -LRB-. La redistribuci\u00f3n de un agente no depende de su propio tipo -RRB-. Tambi\u00e9n mantiene la racionalidad individual porque todas las redistribuciones no son negativas. La redistribuci\u00f3n total es igual a 2n \u03b83 + el mecanismo anterior mantiene la propiedad no deficitaria. Finalmente, la redistribuci\u00f3n total de 2 n subastas de art\u00edculos, la fracci\u00f3n de redistribuci\u00f3n del peor caso de este mecanismo de ejemplo es n \u2212 2 n 1.2 Investigaciones previas sobre mecanismos de redistribuci\u00f3n de VCG \u00f3ptimos en el peor de los casos En esta subsecci\u00f3n, revisamos los resultados existentes sobre el VCG \u00f3ptimo en el peor de los casos. mecanismos de redistribuci\u00f3n. Redistribuci\u00f3n \u00f3ptima en el peor de los casos en subastas de unidades m\u00faltiples con demanda unitaria -LSB- 7, 12 -RSB-: En subastas de unidades m\u00faltiples con demanda unitaria, los art\u00edculos a la venta son id\u00e9nticos. Cada agente quiere como m\u00e1ximo una copia del art\u00edculo. -LRB- Las subastas de un solo art\u00edculo son casos especiales de subastas de unidades m\u00faltiples con demanda unitaria. -RRB- Sea m el n\u00famero de elementos. A lo largo de este art\u00edculo, s\u00f3lo consideramos casos en los que m \u2264 n \u2212 2.2 Aqu\u00ed, el tipo de un agente es un n\u00famero real no negativo que representa su valoraci\u00f3n por ganar una copia del art\u00edculo. -LSB- 7 -RSB- tambi\u00e9n caracteriz\u00f3 un mecanismo de redistribuci\u00f3n de VCG para subastas multiunitarias con demanda unitaria, llamado mecanismo de la OMA.3 La fracci\u00f3n de redistribuci\u00f3n del peor caso de la OMA es exactamente \u03b1 \u2217. Es decir, es el peor de los casos \u00f3ptimo. La OMA se obtuvo optimizando dentro de la familia de mecanismos de redistribuci\u00f3n lineal de VCG. Un mecanismo de redistribuci\u00f3n lineal de VCG r toma la siguiente forma: Aqu\u00ed, los ci son constantes. -LRB- S\u00f3lo consideramos los ci que corresponden a mecanismos de redistribuci\u00f3n de VCG factibles. -RRB- -LSB- \u03b8 \u2212 i -RSB- j es el j-\u00e9simo tipo m\u00e1s alto entre \u03b8 \u2212 i. El mecanismo lineal r se caracteriza por los valores de ci. Los valores \u00f3ptimos de ci son los siguientes: La caracterizaci\u00f3n de OMA es la siguiente: Redistribuci\u00f3n \u00f3ptima en el peor de los casos en subastas de unidades m\u00faltiples con valores marginales no crecientes -LSB- 7 -RSB-: Subastas de unidades m\u00faltiples con valores no 2 -LSB- 7 -RSB - demostr\u00f3 que para subastas de unidades m\u00faltiples con demanda unitaria, cuando m = n \u2212 1, la fracci\u00f3n de redistribuci\u00f3n del peor caso -LRB- de cualquier mecanismo de redistribuci\u00f3n de VCG factible -RRB- es como m\u00e1ximo 0. Dado que el escenario estudiado en este art\u00edculo es En subastas m\u00e1s generales -LRB- de art\u00edculos heterog\u00e9neos con demanda unitaria -RRB-, tambi\u00e9n tenemos que la fracci\u00f3n de redistribuci\u00f3n en el peor de los casos es como m\u00e1ximo 0 cuando m = n \u2212 1. Dado que las subastas de art\u00edculos heterog\u00e9neos con x unidades son casos especiales de subastas heterog\u00e9neas -subastas de art\u00edculos con x + 1 unidades, tenemos que para nuestra configuraci\u00f3n la fracci\u00f3n de redistribuci\u00f3n en el peor de los casos es como m\u00e1ximo 0 cuando m \u2265 n \u2212 1. Es decir, no redistribuir nada es \u00f3ptimo en el peor de los casos cuando m \u2265 n \u2212 1. Adem\u00e1s, para el objetivo de -LSB- 12 -RSB-, el mecanismo \u00f3ptimo coincide con la OMA s\u00f3lo cuando se aplica la restricci\u00f3n de racionalidad individual.Los valores marginales crecientes son m\u00e1s generales que las subastas de unidades m\u00faltiples con demanda unitaria. En este entorno m\u00e1s general, los art\u00edculos siguen siendo id\u00e9nticos, pero un agente puede exigir m\u00e1s de una copia del art\u00edculo. La valoraci\u00f3n de un agente por ganar la primera copia del art\u00edculo se denomina valor marginal inicial/primer. De manera similar, la valoraci\u00f3n adicional de un agente por ganar la i-\u00e9sima copia del art\u00edculo se llama su i-\u00e9simo valor marginal. El tipo de agente contiene m n\u00fameros reales no negativos -LRB- i-\u00e9simo valor marginal para i = 1,..., m -RRB-. En este context, se supone adem\u00e1s que los valores marginales no aumentan. Como se analiz\u00f3 anteriormente, en este entorno m\u00e1s general, la fracci\u00f3n de redistribuci\u00f3n del peor caso de cualquier mecanismo de redistribuci\u00f3n VCG todav\u00eda est\u00e1 limitada por arriba por \u03b1 *. -LSB- 7 -RSB- generaliz\u00f3 la OMA a este escenario y demostr\u00f3 que su fracci\u00f3n de redistribuci\u00f3n en el peor de los casos sigue siendo la misma. Por lo tanto, la OMA -LRB- despu\u00e9s de la generalizaci\u00f3n -RRB- tambi\u00e9n es \u00f3ptima en el peor de los casos para subastas de unidades m\u00faltiples con valores marginales no crecientes. La definici\u00f3n original de OMA no se generaliza directamente a subastas de unidades m\u00faltiples con valores marginales no crecientes. Cuando se trata de subastas de unidades m\u00faltiples con valores marginales no crecientes, el tipo de agente ya no es un valor \u00fanico, lo que significa que no existe \"el j-\u00e9simo tipo m\u00e1s alto entre \u03b8_i\". Abusamos de la notaci\u00f3n al no diferenciar los agentes y sus tipos. Por ejemplo, \u03b8_i es equivalente al conjunto de agentes distintos de i. Sea S un conjunto de agentes. yo \u2212 1 -RRB-. Aqu\u00ed, U -LRB- S, j -RRB- es el nuevo conjunto de agentes, despu\u00e9s de eliminar de S el agente con el j-\u00e9simo valor marginal inicial m\u00e1s alto en S. La forma general de OMA es la siguiente: Peor caso \u00f3ptimo Redistribuci\u00f3n en Subastas de art\u00edculos heterog\u00e9neos con demanda unitaria -LSB- 4 -RSB-: En las subastas de art\u00edculos heterog\u00e9neos con demanda unitaria, los art\u00edculos a la venta son diferentes. Cada agente exige como m\u00e1ximo un art\u00edculo. Aqu\u00ed, el tipo de agente consta de m n\u00fameros reales no negativos -LRB- y su valoraci\u00f3n por el art\u00edculo ganador i para i = 1,..., m -RRB-. El foco principal de este art\u00edculo son las subastas de art\u00edculos heterog\u00e9neos con demanda unitaria. Dado que las subastas de art\u00edculos heterog\u00e9neos con demanda unitaria son m\u00e1s generales que las subastas de unidades m\u00faltiples con demanda unitaria, \u03b1 * sigue siendo un l\u00edmite superior en la fracci\u00f3n de redistribuci\u00f3n del peor caso. -LSB- 4 -RSB- propuso el mecanismo HETERO, generalizando la OMA. Los autores conjeturaron que HETERO es factible y tiene una fracci\u00f3n de redistribuci\u00f3n en el peor de los casos igual a \u03b1 *. Es decir, los autores conjeturaron que HETERO es el peor de los casos \u00f3ptimo en este entorno. La principal contribuci\u00f3n de este art\u00edculo es una prueba de esta conjetura. Redistribuci\u00f3n en Subastas Combinatorias con Sustitutos Brutos -LSB- 6 -RSB-: La condici\u00f3n de sustitutos brutos fue propuesta por primera vez en -LSB- 9 -RSB-. Al igual que la demanda unitaria, la condici\u00f3n de sustitutos brutos es una condici\u00f3n sobre el tipo de agente -LRB- que no depende del mecanismo en discusi\u00f3n -RRB-. En palabras,El tipo de agente satisface la condici\u00f3n de sustitutos brutos si su demanda de un art\u00edculo no disminuye cuando los precios de los otros art\u00edculos aumentan. Tanto las subastas multiunitarias con valores marginales no crecientes como las subastas de art\u00edculos heterog\u00e9neos con demanda unitaria son casos especiales de subastas combinatorias con sustitutos brutos -LSB- 5, 9 -RSB-. Los autores no encontraron un mecanismo \u00f3ptimo en el peor de los casos para esta configuraci\u00f3n. Al final de este art\u00edculo, conjeturamos que HETERO es \u00f3ptimo para subastas combinatorias con sustitutos brutos. Finalmente, Naroditskiy et al. -LSB- 13 -RSB- propuso una t\u00e9cnica num\u00e9rica para dise\u00f1ar mecanismos de redistribuci\u00f3n \u00f3ptimos en el peor de los casos. La t\u00e9cnica propuesta s\u00f3lo funciona para dominios de un solo par\u00e1metro. No se aplica a nuestra configuraci\u00f3n -LRB- dominio multiparam\u00e9trico -RRB-. 1.3 Nuestra contribuci\u00f3n Generalizamos la OMA a subastas de art\u00edculos heterog\u00e9neos con demanda unitaria. Probamos que el mecanismo generalizado, aunque representado de manera diferente, coincide con el mecanismo HETERO propuesto en -LSB- 4 -RSB-. Es decir, lo que propusimos no es un nuevo mecanismo, sino una nueva representaci\u00f3n de un mecanismo existente. Con base en nuestra nueva representaci\u00f3n de HETERO, demostramos que HETERO es efectivamente factible y \u00f3ptimo en el peor de los casos cuando se aplica a subastas de art\u00edculos heterog\u00e9neos con demanda unitaria, confirmando as\u00ed la conjetura planteada en -LSB- 4 -RSB-. Concluimos con una nueva conjetura de que HETERO sigue siendo factible y \u00f3ptimo en el peor de los casos en el entorno a\u00fan m\u00e1s general de subastas combinatorias con sustitutos brutos. 4. CONCLUSI\u00d3N Concluimos nuestro art\u00edculo con la siguiente conjetura: CONJECTURA 1. Los sustitutos brutos implican monoton\u00eda de redistribuci\u00f3n. Es decir, HETERO sigue siendo factible y \u00f3ptimo en el peor de los casos en subastas combinatorias con sustitutos brutos. La idea es que tanto las subastas de unidades m\u00faltiples con valores marginales no crecientes como las subastas de art\u00edculos heterog\u00e9neos con demanda unitaria satisfacen la monotonicidad de la redistribuci\u00f3n. Una conjetura natural es que la \"uni\u00f3n m\u00e1s restrictiva\" de estos dos entornos tambi\u00e9n satisface la monotonicidad de la redistribuci\u00f3n. Hay muchos entornos de subasta bien estudiados que contienen tanto subastas de unidades m\u00faltiples con valores marginales no crecientes como subastas de art\u00edculos heterog\u00e9neos con demanda unitaria -LRB-, cuya lista se puede encontrar en -LSB- 10 -RSB- -RRB-. Entre estos escenarios bien estudiados, las subastas combinatorias con sustitutos brutos son las m\u00e1s restrictivas.-LSB- 13 -RSB- propuso una t\u00e9cnica num\u00e9rica para dise\u00f1ar mecanismos de redistribuci\u00f3n \u00f3ptimos en el peor de los casos. La t\u00e9cnica propuesta s\u00f3lo funciona para dominios de un solo par\u00e1metro. No se aplica a nuestra configuraci\u00f3n -LRB- dominio multiparam\u00e9trico -RRB-. 1.3 Nuestra contribuci\u00f3n Generalizamos la OMA a subastas de art\u00edculos heterog\u00e9neos con demanda unitaria. Probamos que el mecanismo generalizado, aunque representado de manera diferente, coincide con el mecanismo HETERO propuesto en -LSB- 4 -RSB-. Es decir, lo que propusimos no es un nuevo mecanismo, sino una nueva representaci\u00f3n de un mecanismo existente. Con base en nuestra nueva representaci\u00f3n de HETERO, demostramos que HETERO es efectivamente factible y \u00f3ptimo en el peor de los casos cuando se aplica a subastas de art\u00edculos heterog\u00e9neos con demanda unitaria, confirmando as\u00ed la conjetura planteada en -LSB- 4 -RSB-. Concluimos con una nueva conjetura de que HETERO sigue siendo factible y \u00f3ptimo en el peor de los casos en el entorno a\u00fan m\u00e1s general de subastas combinatorias con sustitutos brutos. 4. CONCLUSI\u00d3N Concluimos nuestro art\u00edculo con la siguiente conjetura: CONJECTURA 1. Los sustitutos brutos implican monoton\u00eda de redistribuci\u00f3n. Es decir, HETERO sigue siendo factible y \u00f3ptimo en el peor de los casos en subastas combinatorias con sustitutos brutos. La idea es que tanto las subastas de unidades m\u00faltiples con valores marginales no crecientes como las subastas de art\u00edculos heterog\u00e9neos con demanda unitaria satisfacen la monotonicidad de la redistribuci\u00f3n. Una conjetura natural es que la \"uni\u00f3n m\u00e1s restrictiva\" de estos dos entornos tambi\u00e9n satisface la monotonicidad de la redistribuci\u00f3n. Hay muchos entornos de subasta bien estudiados que contienen tanto subastas de unidades m\u00faltiples con valores marginales no crecientes como subastas de art\u00edculos heterog\u00e9neos con demanda unitaria -LRB-, cuya lista se puede encontrar en -LSB- 10 -RSB- -RRB-. Entre estos escenarios bien estudiados, las subastas combinatorias con sustitutos brutos son las m\u00e1s restrictivas.-LSB- 13 -RSB- propuso una t\u00e9cnica num\u00e9rica para dise\u00f1ar mecanismos de redistribuci\u00f3n \u00f3ptimos en el peor de los casos. La t\u00e9cnica propuesta s\u00f3lo funciona para dominios de un solo par\u00e1metro. No se aplica a nuestra configuraci\u00f3n -LRB- dominio multiparam\u00e9trico -RRB-. 1.3 Nuestra contribuci\u00f3n Generalizamos la OMA a subastas de art\u00edculos heterog\u00e9neos con demanda unitaria. Probamos que el mecanismo generalizado, aunque representado de manera diferente, coincide con el mecanismo HETERO propuesto en -LSB- 4 -RSB-. Es decir, lo que propusimos no es un nuevo mecanismo, sino una nueva representaci\u00f3n de un mecanismo existente. Con base en nuestra nueva representaci\u00f3n de HETERO, demostramos que HETERO es efectivamente factible y \u00f3ptimo en el peor de los casos cuando se aplica a subastas de art\u00edculos heterog\u00e9neos con demanda unitaria, confirmando as\u00ed la conjetura planteada en -LSB- 4 -RSB-. Concluimos con una nueva conjetura de que HETERO sigue siendo factible y \u00f3ptimo en el peor de los casos en el entorno a\u00fan m\u00e1s general de subastas combinatorias con sustitutos brutos. 4. CONCLUSI\u00d3N Concluimos nuestro art\u00edculo con la siguiente conjetura: CONJECTURA 1. Los sustitutos brutos implican monoton\u00eda de redistribuci\u00f3n. Es decir, HETERO sigue siendo factible y \u00f3ptimo en el peor de los casos en subastas combinatorias con sustitutos brutos. La idea es que tanto las subastas de unidades m\u00faltiples con valores marginales no crecientes como las subastas de art\u00edculos heterog\u00e9neos con demanda unitaria satisfacen la monotonicidad de la redistribuci\u00f3n. Una conjetura natural es que la \"uni\u00f3n m\u00e1s restrictiva\" de estos dos entornos tambi\u00e9n satisface la monotonicidad de la redistribuci\u00f3n. Hay muchos entornos de subasta bien estudiados que contienen tanto subastas de unidades m\u00faltiples con valores marginales no crecientes como subastas de art\u00edculos heterog\u00e9neos con demanda unitaria -LRB-, cuya lista se puede encontrar en -LSB- 10 -RSB- -RRB-. Entre estos escenarios bien estudiados, las subastas combinatorias con sustitutos brutos son las m\u00e1s restrictivas.La idea es que tanto las subastas de unidades m\u00faltiples con valores marginales no crecientes como las subastas de art\u00edculos heterog\u00e9neos con demanda unitaria satisfacen la monotonicidad de la redistribuci\u00f3n. Una conjetura natural es que la \"uni\u00f3n m\u00e1s restrictiva\" de estos dos entornos tambi\u00e9n satisface la monotonicidad de la redistribuci\u00f3n. Hay muchos entornos de subasta bien estudiados que contienen tanto subastas de unidades m\u00faltiples con valores marginales no crecientes como subastas de art\u00edculos heterog\u00e9neos con demanda unitaria -LRB-, cuya lista se puede encontrar en -LSB- 10 -RSB- -RRB-. Entre estos escenarios bien estudiados, las subastas combinatorias con sustitutos brutos son las m\u00e1s restrictivas.La idea es que tanto las subastas de unidades m\u00faltiples con valores marginales no crecientes como las subastas de art\u00edculos heterog\u00e9neos con demanda unitaria satisfacen la monotonicidad de la redistribuci\u00f3n. Una conjetura natural es que la \"uni\u00f3n m\u00e1s restrictiva\" de estos dos entornos tambi\u00e9n satisface la monotonicidad de la redistribuci\u00f3n. Hay muchos entornos de subasta bien estudiados que contienen tanto subastas de unidades m\u00faltiples con valores marginales no crecientes como subastas de art\u00edculos heterog\u00e9neos con demanda unitaria -LRB-, cuya lista se puede encontrar en -LSB- 10 -RSB- -RRB-. Entre estos escenarios bien estudiados, las subastas combinatorias con sustitutos brutos son las m\u00e1s restrictivas.", "keyphrases": ["dise\u00f1o mec\u00e1nico", "vickrei-clark-grove", "pago de redistribuci\u00f3n", "Mecanismo eficiente", "a prueba de estrategias", "mecanismo de individuaci\u00f3n", "mec\u00e1nico", "mecanismo de redistribuci\u00f3n lineal vcg", "transformar a programa lineal", "personaje analista", "mecanismo optim en el peor de los casos"]}
{"file_name": "H-4", "text": "Hacia evaluaciones de gesti\u00f3n de informaci\u00f3n personal basadas en tareas RESUMEN La gesti\u00f3n de informaci\u00f3n personal -LRB- PIM -RRB- es un \u00e1rea de investigaci\u00f3n de r\u00e1pido crecimiento que se ocupa de c\u00f3mo las personas almacenan, gestionan y reencuentran informaci\u00f3n. Una caracter\u00edstica de la investigaci\u00f3n PIM es que muchos sistemas han sido dise\u00f1ados para ayudar a los usuarios a gestionar y reencontrar informaci\u00f3n, pero muy pocos han sido evaluados. Esto ha sido observado por varios estudiosos y explicado por las dificultades que implica realizar evaluaciones PIM. Las dificultades incluyen que las personas vuelven a encontrar informaci\u00f3n dentro de colecciones personales \u00fanicas; los investigadores saben poco sobre las tareas que hacen que las personas vuelvan a encontrar informaci\u00f3n; y numerosos problemas de privacidad relacionados con la informaci\u00f3n personal. En este documento pretendemos facilitar las evaluaciones de PIM abordando cada una de estas dificultades. En la primera parte, presentamos un estudio diario de tareas de reencuentro de informaci\u00f3n. El estudio examina el tipo de tareas que requieren que los usuarios vuelvan a encontrar informaci\u00f3n y produce una taxonom\u00eda de tareas de b\u00fasqueda para mensajes de correo electr\u00f3nico y p\u00e1ginas web. En la segunda parte, proponemos una metodolog\u00eda de evaluaci\u00f3n basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando dos m\u00e9todos diferentes de creaci\u00f3n de tareas. 1. INTRODUCCI\u00d3N La Gesti\u00f3n de Informaci\u00f3n Personal -LRB- PIM -RRB- es un \u00e1rea de investigaci\u00f3n en r\u00e1pido crecimiento que se ocupa de c\u00f3mo las personas almacenan, gestionan y reencuentran informaci\u00f3n. Los sistemas PIM (los m\u00e9todos y procedimientos mediante los cuales las personas manejan, categorizan y recuperan informaci\u00f3n en el d\u00eda a d\u00eda -LSB-18-RSB-) se est\u00e1n volviendo cada vez m\u00e1s populares. Sin embargo, la evaluaci\u00f3n de estos sistemas PIM es problem\u00e1tica. Una de las principales dificultades proviene del car\u00e1cter personal de PIM. Las personas recopilan informaci\u00f3n como consecuencia natural de realizar otras tareas. Esto significa que las colecciones que las personas generan son exclusivas de ellas y la informaci\u00f3n dentro de una colecci\u00f3n est\u00e1 intr\u00ednsecamente vinculada con las experiencias personales del propietario. Como las colecciones personales son \u00fanicas, no podemos crear tareas de evaluaci\u00f3n que sean aplicables a todos los participantes en una evaluaci\u00f3n. En segundo lugar, las colecciones personales pueden contener informaci\u00f3n que los participantes no se sienten c\u00f3modos compartiendo dentro de una evaluaci\u00f3n. La naturaleza precisa de esta informaci\u00f3n (qu\u00e9 informaci\u00f3n los individuos preferir\u00edan mantener privada) var\u00eda entre individuos, lo que dificulta basar las tareas de b\u00fasqueda en el contenido de colecciones individuales. Por lo tanto, los experimentadores enfrentan una serie de desaf\u00edos para realizar evaluaciones PIM realistas pero controladas. Sin embargo, recientemente los investigadores han comenzado a centrarse en formas de abordar el problema de la evaluaci\u00f3n PIM. Capra -LSB- 6 -RSB- tambi\u00e9n identifica la necesidad de evaluaciones controladas de laboratorio PIM para complementar otras t\u00e9cnicas de evaluaci\u00f3n, poniendo especial \u00e9nfasis en la necesidad de comprender el comportamiento de PIM a nivel de tarea. En este art\u00edculo, intentamos abordar las dificultades involucradas para facilitar evaluaciones PIM de laboratorio controladas.En la primera parte de este art\u00edculo presentamos un estudio diario de tareas de reencuentro de informaci\u00f3n. El estudio examina el tipo de tareas que requieren que los usuarios vuelvan a encontrar informaci\u00f3n y produce una taxonom\u00eda de tareas de b\u00fasqueda para mensajes de correo electr\u00f3nico y p\u00e1ginas web. Tambi\u00e9n analizamos las caracter\u00edsticas de las tareas que dificultan la reencontraci\u00f3n. En la segunda parte, proponemos una metodolog\u00eda de evaluaci\u00f3n basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando diferentes m\u00e9todos de creaci\u00f3n de tareas. Por lo tanto, este art\u00edculo ofrece dos contribuciones al campo: una mayor comprensi\u00f3n del comportamiento de PIM a nivel de tarea y un m\u00e9todo de evaluaci\u00f3n que facilitar\u00e1 futuras investigaciones. 2. TRABAJO RELACIONADO Hay una variedad de enfoques disponibles para estudiar PIM. Los enfoques naturalistas estudian a los participantes actuando de forma natural, completando sus propias tareas a medida que ocurren, dentro de entornos familiares. Estos enfoques permiten a los investigadores superar muchas de las dificultades causadas por la naturaleza personal de PIM. Como las tareas realizadas son \"reales\" y no simuladas, los participantes pueden utilizar sus propias experiencias, conocimientos previos y recopilaci\u00f3n de informaci\u00f3n para completar las tareas. Tanto los m\u00e9todos etnogr\u00e1ficos como los de trabajo de campo requieren la presencia de un experimentador para evaluar c\u00f3mo se realiza el PIM, lo que plantea una serie de cuestiones. En primer lugar, la evaluaci\u00f3n de este modo es costosa; tomar largos per\u00edodos de tiempo para estudiar un peque\u00f1o n\u00famero de participantes y estas peque\u00f1as muestras pueden no ser representativas del comportamiento de poblaciones m\u00e1s grandes. En segundo lugar, como los participantes no pueden ser observados continuamente, los experimentadores deben elegir cu\u00e1ndo observar y esto puede afectar los resultados. Una estrategia alternativa a la realizaci\u00f3n de evaluaciones naturalistas es utilizar el an\u00e1lisis de archivos de registro. Este enfoque utiliza software de registro que captura una amplia muestra de las actividades del usuario en el context del uso natural de un sistema. Esto revela la necesidad de complementar los estudios naturalistas con experimentos controlados donde el experimentador pueda relacionar el comportamiento de los participantes del estudio con objetivos asociados con tareas de b\u00fasqueda conocidas. Una dificultad para realizar este tipo de evaluaci\u00f3n es la obtenci\u00f3n de colecciones para evaluar. Kelly -LSB- 16 -RSB- propone la introducci\u00f3n de una colecci\u00f3n de pruebas compartida que proporcionar\u00eda conjuntos de datos, tareas y m\u00e9tricas reutilizables y compartibles para aquellos interesados \u200b\u200ben realizar investigaciones PIM. Sin embargo, una colecci\u00f3n compartida no ser\u00eda adecuada para estudios de usuarios porque no ser\u00eda posible incorporar los aspectos personales de PIM mientras se utiliza una colecci\u00f3n com\u00fan y desconocida. Un enfoque alternativo es pedir a los usuarios que proporcionen sus propias colecciones de informaci\u00f3n para simular entornos familiares dentro del laboratorio. Este enfoque se ha aplicado para estudiar la reencuentro de fotograf\u00edas personales -LSB- 11 -RSB-, mensajes de correo electr\u00f3nico -LSB- 20 -RSB- y marcadores web -LSB- 21 -RSB-. La utilidad de este enfoque depende de lo f\u00e1cil que sea transferir la colecci\u00f3n u obtener acceso remoto.Otra soluci\u00f3n es utilizar toda la web como una colecci\u00f3n al estudiar la reencontrada de p\u00e1ginas web -LSB- 4 -RSB-. Esto puede ser apropiado para estudiar la re-b\u00fasqueda de p\u00e1ginas web porque estudios previos han demostrado que las personas suelen utilizar motores de b\u00fasqueda web para este prop\u00f3sito -LSB- 5 -RSB-. Una segunda dificultad al realizar estudios de laboratorio PIM es crear tareas para que las realicen los participantes y que puedan resolverse buscando en una colecci\u00f3n compartida o personal. Las tareas se relacionan con la actividad que resulta en una necesidad de informaci\u00f3n -LSB- 14 -RSB- y se reconoce que son importantes para determinar el comportamiento del usuario -LSB- 26 -RSB-. Se ha llevado a cabo una gran cantidad de trabajo para comprender la naturaleza de las tareas y c\u00f3mo el tipo de tarea influye en el comportamiento de b\u00fasqueda de informaci\u00f3n del usuario. Por ejemplo, las tareas se han categorizado en t\u00e9rminos de complejidad creciente -LSB- 3 -RSB- y se ha sugerido que la complejidad de las tareas afecta c\u00f3mo los buscadores perciben sus necesidades de informaci\u00f3n -LSB- 25 -RSB- y c\u00f3mo intentan encontrar informaci\u00f3n -LSB- 3 -RSB-. Otros trabajos previos han proporcionado metodolog\u00edas que permiten la simulaci\u00f3n de tareas al estudiar el comportamiento de b\u00fasqueda de informaci\u00f3n -LSB- 2 -RSB-. Sin embargo, se sabe poco sobre los tipos de tareas que hacen que las personas busquen en sus tiendas personales o vuelvan a encontrar informaci\u00f3n que han visto antes. En consecuencia, es dif\u00edcil idear situaciones de tareas laborales simuladas para PIM. La excepci\u00f3n es el estudio de la gesti\u00f3n de fotograf\u00edas personales, donde el trabajo de Rodden sobre la categorizaci\u00f3n de las tareas de b\u00fasqueda de fotograf\u00edas personales ha facilitado la creaci\u00f3n de situaciones de tareas laborales simuladas -LSB- 22 -RSB-. Ha habido otras sugerencias sobre c\u00f3mo clasificar las tareas PIM. Si bien estas son propiedades interesantes que pueden afectar la forma en que se realizar\u00e1 una tarea, no brindan a los experimentadores suficiente margen para idear tareas. Las colecciones personales son una de las razones por las que la creaci\u00f3n de tareas es tan dif\u00edcil. La taxonom\u00eda de tareas fotogr\u00e1ficas de Rodden proporciona una soluci\u00f3n en este caso porque permite clasificar las tareas adaptadas a colecciones privadas. Luego, los sistemas se pueden comparar entre tipos de tareas para diferentes usuarios -LSB- 11 -RSB-. Desafortunadamente, no existe una taxonom\u00eda equivalente para otros tipos de objetos de informaci\u00f3n. Adem\u00e1s, otros tipos de objetos son m\u00e1s sensibles a la privacidad que las fotograf\u00edas; Es poco probable que los participantes se contenten con permitir que los investigadores exploren sus colecciones de correo electr\u00f3nico para crear tareas como lo hicieron con las fotograf\u00edas en -LSB- 11 -RSB-. Esto presenta un problema grave: \u00bfc\u00f3mo pueden los investigadores idear tareas que correspondan a colecciones privadas sin comprender los tipos de tareas que realizan las personas o sin poner en peligro la privacidad de los participantes del estudio? Se han propuesto algunos m\u00e9todos. Por ejemplo, -LSB-20-RSB- estudi\u00f3 la b\u00fasqueda de correo electr\u00f3nico pidiendo a los participantes que volvieran a encontrar los correos electr\u00f3nicos que se hab\u00edan enviado a todos los miembros de un departamento; permitiendo que se utilicen las mismas tareas para todos los participantes del estudio.Este enfoque asegur\u00f3 que se evitaran problemas de privacidad y que los participantes pudieran usar cosas que recordaran para completar las tareas. Sin embargo, los sistemas s\u00f3lo se probaron utilizando un tipo de tarea: se pidi\u00f3 a los participantes que encontraran correos electr\u00f3nicos individuales, cada uno de los cuales compart\u00eda propiedades comunes. En la secci\u00f3n 4 mostramos que las personas realizan una gama m\u00e1s amplia de tareas de b\u00fasqueda de correo electr\u00f3nico que esta. En -LSB- 4 -RSB-, las tareas de b\u00fasqueda gen\u00e9ricas se crearon artificialmente ejecutando evaluaciones en dos sesiones. En la primera sesi\u00f3n, se pidi\u00f3 a los participantes que completaran tareas de trabajo que implicaban encontrar informaci\u00f3n desconocida. En la segunda sesi\u00f3n, los participantes volvieron a completar las mismas tareas, lo que naturalmente implic\u00f3 alg\u00fan comportamiento de reencuentro. Las limitaciones de esta t\u00e9cnica son que no permite a los participantes explotar ninguna conexi\u00f3n personal con la informaci\u00f3n porque la informaci\u00f3n que buscan puede no corresponder a ning\u00fan otro aspecto de sus vidas. Nuestra revisi\u00f3n de los enfoques de evaluaci\u00f3n motiva la necesidad de realizar experimentos de laboratorio controlados que permitan probar aspectos estrechamente definidos de los sistemas o interfaces. Desafortunadamente, tambi\u00e9n se ha demostrado que existen dificultades al realizar este tipo de evaluaci\u00f3n: es dif\u00edcil encontrar colecciones e idear tareas que correspondan a colecciones privadas y, al mismo tiempo, proteger la privacidad de los participantes en el estudio. En la siguiente secci\u00f3n presentamos un estudio diario de tareas de b\u00fasqueda de correo electr\u00f3nico y p\u00e1ginas web. El resultado es una clasificaci\u00f3n de tareas similar a la ideada por Rodden para fotograf\u00edas personales -LSB- 22 -RSB-. En la secci\u00f3n 5 nos basamos en este trabajo examinando m\u00e9todos para crear tareas que no comprometan la privacidad de los participantes y discutimos c\u00f3mo nuestro trabajo puede facilitar las evaluaciones de usuarios de PIM basadas en tareas. Mostramos que al recopilar tareas utilizando diarios electr\u00f3nicos, no solo podemos aprender sobre las tareas que hacen que las personas vuelvan a encontrar informaci\u00f3n personal, sino que tambi\u00e9n podemos aprender sobre el contenido de colecciones privadas sin comprometer la privacidad de los participantes. Este conocimiento se puede utilizar luego para construir tareas que se utilizar\u00e1n en evaluaciones PIM. 6. CONCLUSIONES Este art\u00edculo se ha centrado en superar las dificultades que implica la realizaci\u00f3n de evaluaciones de PIM. La naturaleza personal de PIM significa que es dif\u00edcil construir experimentos equilibrados porque cada participante tiene sus propias colecciones \u00fanicas que se autogeneran al completar otras tareas. Sugerimos que para incorporar los aspectos personales de PIM en las evaluaciones, se deber\u00eda examinar el rendimiento de los sistemas o de los usuarios cuando los usuarios completan tareas en sus propias colecciones. Este enfoque en s\u00ed tiene problemas porque la creaci\u00f3n de tareas para colecciones personales es dif\u00edcil: los investigadores no saben mucho sobre los tipos de tareas de reencuentro que realizan las personas y no saben qu\u00e9 informaci\u00f3n se encuentra dentro de las colecciones personales individuales.En este art\u00edculo describimos formas de superar estos desaf\u00edos para facilitar las evaluaciones de usuarios de PIM basadas en tareas. En la primera parte del art\u00edculo realizamos un estudio diario que examinaba las tareas que hac\u00edan que las personas volvieran a encontrar mensajes de correo electr\u00f3nico y p\u00e1ginas web. Los datos recopilados incluyeron una amplia gama de tareas laborales y no laborales y, en base a los datos, creamos una taxonom\u00eda de tareas de reencuentro web y de correo electr\u00f3nico. Descubrimos que las personas realizan tres tipos principales de tareas de reencuentro: tareas que requieren informaci\u00f3n espec\u00edfica de un \u00fanico recurso, tareas que requieren un \u00fanico recurso completo y tareas que requieren que se recupere informaci\u00f3n de m\u00faltiples recursos. En la segunda parte del art\u00edculo, discutimos la importancia de la taxonom\u00eda con respecto a la evaluaci\u00f3n de PIM. Demostramos que se pueden realizar experimentos equilibrados comparando el rendimiento del sistema o del usuario en las categor\u00edas de tareas dentro de la taxonom\u00eda. Tambi\u00e9n sugerimos dos m\u00e9todos para crear tareas que se pueden completar en colecciones personales. Estos m\u00e9todos no comprometen la privacidad de los participantes del estudio. Examinamos las t\u00e9cnicas sugeridas, en primer lugar simulando una situaci\u00f3n experimental: se pidi\u00f3 a los participantes que volvieran a realizar sus propias tareas mientras las registraban y, en segundo lugar, en el context de una evaluaci\u00f3n completa. Realizar evaluaciones de esta manera permitir\u00e1 probar los sistemas que se han propuesto para mejorar la capacidad de los usuarios para administrar y volver a encontrar su informaci\u00f3n, de modo que podamos conocer las necesidades y deseos de los usuarios. Por lo tanto, este art\u00edculo ha ofrecido dos contribuciones al campo: una mayor comprensi\u00f3n del comportamiento de PIM a nivel de tarea y un m\u00e9todo de evaluaci\u00f3n que facilitar\u00e1 futuras investigaciones.Realizar evaluaciones de esta manera permitir\u00e1 probar los sistemas que se han propuesto para mejorar la capacidad de los usuarios para administrar y volver a encontrar su informaci\u00f3n, de modo que podamos conocer las necesidades y deseos de los usuarios. Por lo tanto, este art\u00edculo ha ofrecido dos contribuciones al campo: una mayor comprensi\u00f3n del comportamiento de PIM a nivel de tarea y un m\u00e9todo de evaluaci\u00f3n que facilitar\u00e1 futuras investigaciones.Realizar evaluaciones de esta manera permitir\u00e1 probar los sistemas que se han propuesto para mejorar la capacidad de los usuarios para administrar y volver a encontrar su informaci\u00f3n, de modo que podamos conocer las necesidades y deseos de los usuarios. Por lo tanto, este art\u00edculo ha ofrecido dos contribuciones al campo: una mayor comprensi\u00f3n del comportamiento de PIM a nivel de tarea y un m\u00e9todo de evaluaci\u00f3n que facilitar\u00e1 futuras investigaciones.", "keyphrases": ["persona informar a la gerencia", "medir", "experimento", "Factor humano", "volver a encontrar informar", "emisi\u00f3n privada", "taxonomi", "recogida individual", "mensaje de correo electr\u00f3nico", "enfoque naturalista", "estudio base de laboratorio"]}
{"file_name": "I-12", "text": "Compartir experiencias para aprender las caracter\u00edsticas del usuario en entornos din\u00e1micos con datos dispersos RESUMEN Este art\u00edculo investiga el problema de estimar el valor de los par\u00e1metros probabil\u00edsticos necesarios para la toma de decisiones en entornos en los que un agente, operando dentro de un sistema multiagente, no tiene informaci\u00f3n a priori sobre la estructura de la distribuci\u00f3n de los valores de los par\u00e1metros. El agente debe poder producir estimaciones incluso cuando haya realizado s\u00f3lo un peque\u00f1o n\u00famero de observaciones directas y, por tanto, debe poder operar con datos escasos. El art\u00edculo describe un mecanismo que permite al agente mejorar significativamente su estimaci\u00f3n al aumentar sus observaciones directas con las obtenidas por otros agentes con los que se est\u00e1 coordinando. Para evitar sesgos no deseados en entornos relativamente heterog\u00e9neos y al mismo tiempo utilizar datos relevantes para mejorar sus estimaciones, el mecanismo sopesa las contribuciones de las observaciones de otros agentes bas\u00e1ndose en una estimaci\u00f3n en tiempo real del nivel de similitud entre cada uno de estos agentes y \u00e9l mismo. El m\u00f3dulo de \"autonom\u00eda de coordinaci\u00f3n\" de un sistema de gesti\u00f3n de coordinaci\u00f3n proporcion\u00f3 un entorno emp\u00edrico para la evaluaci\u00f3n. Las evaluaciones basadas en simulaci\u00f3n demostraron que el mecanismo propuesto supera las estimaciones basadas exclusivamente en las propias observaciones de un agente, as\u00ed como las estimaciones basadas en un agregado no ponderado de las observaciones de todos los dem\u00e1s agentes. 1. INTRODUCCI\u00d3N En muchos escenarios del mundo real, los agentes aut\u00f3nomos necesitan operar en entornos din\u00e1micos e inciertos en los que s\u00f3lo tienen informaci\u00f3n incompleta sobre los resultados de sus acciones y las caracter\u00edsticas de otros agentes o personas con quienes necesitan cooperar o colaborar. En tales entornos, los agentes pueden beneficiarse al compartir la informaci\u00f3n que recopilan, agrupando sus experiencias individuales para mejorar sus estimaciones de par\u00e1metros desconocidos necesarios para razonar sobre acciones en condiciones de incertidumbre. Este art\u00edculo aborda el problema de aprender la distribuci\u00f3n de los valores de un par\u00e1metro probabil\u00edstico que representa una caracter\u00edstica de una persona que interact\u00faa con un agente inform\u00e1tico. La caracter\u00edstica a aprender es -LRB- o est\u00e1 claramente relacionada con -RRB-, un factor importante en la toma de decisiones del agente.1 El entorno b\u00e1sico que consideramos es aquel en el que un agente acumula observaciones sobre una caracter\u00edstica espec\u00edfica del usuario y las utiliza. producir una estimaci\u00f3n oportuna de alguna medida que depende de la distribuci\u00f3n de esa caracter\u00edstica. Normalmente, los agentes deben tomar decisiones en tiempo real, simult\u00e1neamente con la ejecuci\u00f3n de la tarea y en medio de una gran incertidumbre. En lo que resta de este art\u00edculo utilizaremos el t\u00e9rmino \"ritmo r\u00e1pido\" para referirnos a dichos entornos. En entornos acelerados, la recopilaci\u00f3n de informaci\u00f3n puede ser limitada y no es posible aprender fuera de l\u00ednea o esperar hasta que se recopilen grandes cantidades de datos antes de tomar decisiones. De este modo,El objetivo de los m\u00e9todos de estimaci\u00f3n presentados en este art\u00edculo es minimizar el error promedio a lo largo del tiempo, en lugar de determinar un valor exacto al final de un largo per\u00edodo de interacci\u00f3n. Es decir, se espera que el agente trabaje con el usuario durante un tiempo limitado e intenta minimizar el error general en sus estimaciones. En tales entornos, los datos adquiridos individualmente por un agente -LRB- y sus propias observaciones -RRB- son demasiado escasos para que pueda obtener buenas estimaciones en el marco de tiempo requerido. Dada la ausencia de restricciones estructurales en el entorno, los enfoques que dependen de distribuciones estructuradas pueden dar como resultado un sesgo de estimaci\u00f3n significativamente alto. Consideramos este problema en el context de un sistema distribuido de m\u00faltiples agentes en el que los agentes inform\u00e1ticos apoyan a las personas que realizan tareas complejas en un entorno din\u00e1mico. El hecho de que los agentes formen parte de un entorno de m\u00faltiples agentes, en el que otros agentes tambi\u00e9n pueden estar recopilando datos para estimar una caracter\u00edstica similar de sus usuarios, ofrece la posibilidad de que un agente aumente sus propias observaciones con las de otros agentes, mejorando as\u00ed la precisi\u00f3n de su proceso de aprendizaje. Adem\u00e1s, en los entornos que consideramos, los agentes suelen acumular datos a un ritmo relativamente similar. Sin embargo, la medida en que las observaciones de otros agentes ser\u00e1n \u00fatiles para un agente determinado depende de la medida en que las distribuciones de las caracter\u00edsticas de sus usuarios est\u00e9n correlacionadas con las del usuario de este agente. No hay garant\u00eda de que la distribuci\u00f3n de dos agentes diferentes est\u00e9 altamente correlacionada positivamente, y mucho menos de que sean iguales. Por lo tanto, para utilizar un enfoque de intercambio de datos, un mecanismo de aprendizaje debe ser capaz de identificar efectivamente el nivel de correlaci\u00f3n entre los datos recopilados por diferentes agentes y sopesar los datos compartidos dependiendo del nivel de correlaci\u00f3n. El dise\u00f1o de un m\u00f3dulo de autonom\u00eda de coordinaci\u00f3n -LRB- CA -RRB- dentro de un sistema de gesti\u00f3n de coordinaci\u00f3n -LRB- como parte del proyecto DARPA Coordinators -LSB- 18 -RSB- -RRB-, en el que los agentes apoyan una tarea de programaci\u00f3n distribuida, proporcion\u00f3 la motivaci\u00f3n inicial y un marco conceptual para este trabajo. Sin embargo, los mecanismos en s\u00ed son generales y pueden aplicarse no s\u00f3lo a otros dominios de ritmo r\u00e1pido, sino tambi\u00e9n en otros entornos de m\u00faltiples agentes en los que los agentes recopilan datos que se superponen hasta cierto punto, a velocidades aproximadamente similares, y en los que el entorno impone las restricciones de uso temprano, limitado y sin estructura definidas anteriormente -LRB-, por ejemplo, exploraci\u00f3n de planetas remotos -RRB-. En particular, nuestras t\u00e9cnicas ser\u00edan \u00fatiles en cualquier entorno en el que un grupo de agentes emprenda una tarea en un entorno nuevo, donde cada agente obtenga observaciones a un ritmo similar de los par\u00e1metros individuales que necesita para su toma de decisiones. En este art\u00edculo, presentamos un mecanismo que se utiliz\u00f3 para aprender caracter\u00edsticas clave del usuario en entornos de ritmo r\u00e1pido.El mecanismo proporciona estimaciones relativamente precisas en per\u00edodos de tiempo cortos al aumentar las observaciones directas de un agente individual con observaciones obtenidas por otros agentes con los que se est\u00e1 coordinando. En particular, nos centramos en los problemas relacionados de estimar el costo de interrumpir a una persona y estimar la probabilidad de que esa persona tenga la informaci\u00f3n requerida por el sistema. El mecanismo fue probado con \u00e9xito utilizando un sistema que simula un entorno de Coordinadores. La siguiente secci\u00f3n del art\u00edculo describe el problema de estimar par\u00e1metros relacionados con el usuario en dominios de ritmo r\u00e1pido. La Secci\u00f3n 3 proporciona una descripci\u00f3n general de los m\u00e9todos que desarrollamos. La implementaci\u00f3n, el entorno emp\u00edrico y los resultados se presentan en las Secciones 4 y 5. En la Secci\u00f3n 6 se ofrece una comparaci\u00f3n con m\u00e9todos relacionados y en la Secci\u00f3n 7 las conclusiones. 6. TRABAJO RELACIONADO Adem\u00e1s de la literatura sobre gesti\u00f3n de interrupciones revisada en la Secci\u00f3n 2, se han publicado varios otros Algunas \u00e1reas de trabajo previo son relevantes para el mecanismo de intercambio selectivo descrito en este documento. El filtrado colaborativo, que realiza predicciones -LRB- filtrado -RRB- sobre los intereses de un usuario -LSB- 7 -RSB-, funciona de forma similar al intercambio selectivo. Sin embargo, los sistemas de filtrado colaborativo presentan un rendimiento deficiente cuando no hay suficiente informaci\u00f3n sobre los usuarios y cuando no hay suficiente informaci\u00f3n sobre un nuevo usuario cuyo gusto el sistema intenta predecir -LSB- 7 -RSB-. El intercambio selectivo se basa en la capacidad de encontrar similitudes entre partes espec\u00edficas de la funci\u00f3n de distribuci\u00f3n de probabilidad asociada con una caracter\u00edstica de diferentes usuarios. Esta capacidad est\u00e1 estrechamente relacionada con la agrupaci\u00f3n y la clasificaci\u00f3n, un \u00e1rea ampliamente estudiada en el aprendizaje autom\u00e1tico. Dadas las consideraciones de espacio, nuestra revisi\u00f3n de esta \u00e1rea se limita a algunos enfoques representativos de agrupaci\u00f3n. De particular importancia es que la CA necesita encontrar similitudes entre funciones, definidas en un intervalo continuo, sin atributos predefinidos distintos. Una dificultad adicional es definir la medida de distancia. En la miner\u00eda de datos se han utilizado muchas t\u00e9cnicas de clustering -LSB- 2 -RSB-, con especial \u00e9nfasis en las actualizaciones incrementales del clustering, debido al gran tama\u00f1o de las bases de datos -LSB- 3 -RSB-. Sin embargo, la aplicabilidad de estos a dominios de ritmo r\u00e1pido es bastante limitada porque dependen de un gran conjunto de datos existentes. El m\u00e9todo m\u00e1s relevante para nuestros prop\u00f3sitos es el \u00edndice de entrop\u00eda relativa de Kullback-Leibler que se utiliza en teor\u00eda de la probabilidad y teor\u00eda de la informaci\u00f3n -LSB- 12 -RSB-. Sin embargo, el m\u00e9todo funcionar\u00e1 mal en escenarios en los que las funciones alternan entre diferentes niveles manteniendo la estructura y los momentos \"generales\". 208 La Sexta Internacional. Conf. Conjunta. sobre Agentes Aut\u00f3nomos y Sistemas Multi-Agente -LRB- AAMAS 07 -RRB-, mientras que nuestro enfoque basado en Wilcoxon les dar\u00e1 el rango m\u00e1s alto en t\u00e9rminos de similitud. Si bien la prueba de Wilcoxon es un procedimiento estad\u00edstico ampliamente utilizado -LSB- 22,14 -RSB-, generalmente se usa para comparar dos conjuntos de datos de una sola variable. Hasta donde sabemos, todav\u00eda no se ha intentado ampliar sus propiedades como infraestructura para determinar con qui\u00e9n y en qu\u00e9 medida se debe compartir la informaci\u00f3n, como se presenta en este documento. En estas aplicaciones, se utiliza principalmente como herramienta de identificaci\u00f3n y criterio de clasificaci\u00f3n.", "keyphrases": ["par\u00e1metro probabilista", "agente", "informar compartir", "tomar decisiones", "ambiente acelerado", "sistema de distribuci\u00f3n multiagente", "aprender mecanica", "seleccionar-compartir", "estimaci\u00f3n de par\u00e1metros"]}
{"file_name": "I-1", "text": "Abortar tareas en agentes BDI RESUMEN Los agentes inteligentes que est\u00e1n destinados a trabajar en entornos din\u00e1micos deben poder manejar con gracia tareas y planes fallidos. Adem\u00e1s, dichos agentes deber\u00edan poder tomar decisiones racionales sobre un curso de acci\u00f3n apropiado, que puede incluir abortar una tarea o plan, ya sea como resultado de las propias deliberaciones del agente o potencialmente a pedido de otro agente. En este art\u00edculo investigamos la incorporaci\u00f3n de abortos en una arquitectura estilo BDI. Discutimos algunas condiciones bajo las cuales es apropiado abortar una tarea o plan, y c\u00f3mo determinar las consecuencias de tal decisi\u00f3n. Aumentamos cada plan con un m\u00e9todo de cancelaci\u00f3n opcional, an\u00e1logo al m\u00e9todo de falla que se encuentra en algunos lenguajes de programaci\u00f3n de agentes. Proporcionamos una sem\u00e1ntica operativa para el ciclo de ejecuci\u00f3n en presencia de abortos en el lenguaje de agente abstracto CAN, que nos permite especificar un modelo de ejecuci\u00f3n basado en BDI sin limitar nuestra atenci\u00f3n a un sistema de agente en particular -LRB- como JACK, Jadex, Jason, o SPARK -RRB-. Un desaf\u00edo t\u00e9cnico clave que abordamos es la presencia de subprocesos de ejecuci\u00f3n paralelos y de subtareas, que requieren que el agente garantice que los m\u00e9todos de cancelaci\u00f3n para cada plan se lleven a cabo en una secuencia adecuada. 1. INTRODUCCI\u00d3N Los agentes inteligentes generalmente trabajan en entornos complejos y din\u00e1micos, como el control de tr\u00e1fico a\u00e9reo o la navegaci\u00f3n rob\u00f3tica, en los que no se puede garantizar el \u00e9xito de una determinada acci\u00f3n o plan -LSB- 13 -RSB-. En consecuencia, lidiar con las fallas es fundamental para la programaci\u00f3n de agentes y es un elemento importante de las caracter\u00edsticas del agente como robustez, flexibilidad y persistencia -LSB- 21 -RSB-. En las arquitecturas de agentes inspiradas en el modelo Creencia-Deseo-Intenci\u00f3n -LRB- BDI -RRB- -LSB- 16 -RSB-, estas propiedades a menudo se caracterizan por las interacciones entre creencias, metas y planes -LSB- 2 -RSB-. 1 En general, un agente que desea lograr un conjunto particular de tareas perseguir\u00e1 varios planes simult\u00e1neamente. Cuando se produzcan fallas, se revisar\u00e1 la elecci\u00f3n de planes. Esto puede implicar buscar planes alternativos para una tarea particular, reprogramar tareas para cumplir mejor con las limitaciones de recursos, descartar algunas tareas o alguna otra decisi\u00f3n que aumente la probabilidad de \u00e9xito -LSB- 12, 14 -RSB-. Dada esta necesidad de deliberaci\u00f3n sobre tareas o planes fallidos, la deliberaci\u00f3n sobre el fracaso suele estar integrada en el ciclo de ejecuci\u00f3n del agente. Adem\u00e1s de afrontar el fracaso, una capacidad importante de un agente inteligente es poder abortar una tarea o plan concreto. Abortar una tarea o plan es distinto de su fracaso. Por el contrario, abortar no dice nada sobre la capacidad de desempe\u00f1o; simplemente elimina la necesidad. El fracaso se propaga de abajo hacia arriba, mientras que el aborto se propaga de arriba hacia abajo. La posibilidad de ejecutar subplanes simult\u00e1neamente introduce diferentes complejidades para la interrupci\u00f3n y el fracaso. Para abortar,significa que es posible que sea necesario cancelar varios subplanes simult\u00e1neos a medida que la cancelaci\u00f3n se propaga hacia abajo. En caso de falla, significa que es posible que sea necesario cancelar los planes de hermanos paralelos a medida que la falla se propaga. Ha habido una cantidad considerable de trabajo sobre fallas de planes -LRB- como la detecci\u00f3n y resoluci\u00f3n de conflictos de recursos -LSB- 20, 10 -RSB- -RRB- y la mayor\u00eda de los sistemas de agentes incorporan alguna noci\u00f3n de manejo de fallas. Sin embargo, se ha trabajado relativamente poco en el desarrollo de t\u00e9cnicas de aborto m\u00e1s all\u00e1 de la simple eliminaci\u00f3n de los planes y tareas previstos actualmente, lo que no aborda la limpieza requerida. Como consecuencia, la mayor\u00eda de los sistemas de agentes son bastante limitados en su tratamiento de la situaci\u00f3n en la que una rama de un constructo paralelo puede considerar tanto las tareas a realizar como los objetivos para alcanzar un determinado estado del mundo. Una tarea puede considerarse una meta de lograr el estado de \"la tarea que se ha realizado\", y una meta puede considerarse una tarea de lograr ese estado del mundo. Adoptamos este \u00faltimo punto de vista y utilizamos \"tarea\" para referirnos tambi\u00e9n a los objetivos. falla -LRB- los enfoques comunes incluyen dejar que la otra rama se ejecute hasta su finalizaci\u00f3n sin obst\u00e1culos o eliminarla por completo -RRB-. En este art\u00edculo analizamos en detalle la incorporaci\u00f3n de m\u00e9todos de limpieza de abortos en el ciclo de ejecuci\u00f3n del agente, proporcionando un enfoque unificado para fallas y abortos. Una caracter\u00edstica clave de nuestro enfoque basado en procedimientos es que permitimos que cada plan ejecute alg\u00fan c\u00f3digo particular en caso de falla o aborto. Esto permite que un plan intente garantizar un estado estable y conocido y posiblemente recuperar algunos recursos y realizar una limpieza antes de salir. En consecuencia, un desaf\u00edo t\u00e9cnico central es gestionar la ejecuci\u00f3n ordenada del c\u00f3digo de limpieza apropiado. Mostramos c\u00f3mo los abortos se pueden introducir sin problemas en una arquitectura de estilo BDI y, por primera vez, brindamos una sem\u00e1ntica operativa para abortar en el lenguaje de agente abstracto CAN -LSB- 23, 17 -RSB-. Nuestro enfoque est\u00e1 en un agente \u00fanico, complementario al trabajo relacionado que considera el manejo de excepciones para sistemas de agente \u00fanico y multiagente -LRB-, por ejemplo, -LSB- 22, 5, 6 -RSB- -RRB-. Este art\u00edculo est\u00e1 organizado de la siguiente forma: En la Secci\u00f3n 2 damos un ejemplo de las consecuencias de abortar una tarea, y en la Secci\u00f3n 3 discutimos algunas circunstancias bajo las cuales deber\u00edan ocurrir los abortos y los procedimientos apropiados de representaci\u00f3n e invocaci\u00f3n. En la Secci\u00f3n 4 mostramos c\u00f3mo podemos usar CAN para especificar formalmente el comportamiento de un plan abortado. La Secci\u00f3n 5 analiza el trabajo relacionado y en la Secci\u00f3n 6 presentamos nuestras conclusiones y trabajo futuro. 5. La falla del plan de TRABAJO RELACIONADO se maneja en la versi\u00f3n extendida de AgentSpeak que se encuentra en el sistema Jason -LSB- 6 -RSB-. Los planes de \"limpieza\" fallidos se activan a partir de eventos de eliminaci\u00f3n de objetivos. gramo. En un plan de eliminaci\u00f3n de objetivos, el programador puede especificar cualquier acci\u00f3n de \"deshacer\" y si intentar alcanzar el objetivo nuevamente. Si no se proporciona ning\u00fan plan de eliminaci\u00f3n de objetivos,El comportamiento predeterminado de Jason es no volver a intentar alcanzar el objetivo. El manejo de fallas se aplica s\u00f3lo a los planes desencadenados por la adici\u00f3n de un logro o meta de prueba; en particular, los eventos de eliminaci\u00f3n de objetivos no se publican si falla un plan de eliminaci\u00f3n de objetivos. La implementaci\u00f3n de H\u00a8ubner et al. -LSB- 6 -RSB- requiere las acciones internas de Jason. Un requisito para implementar nuestro enfoque es una capacidad reflexiva en la implementaci\u00f3n del agente BDI. Los tres permiten m\u00e9todos de metanivel que se gu\u00edan por metaeventos, como la adopci\u00f3n de objetivos o el fracaso del plan, y ofrecen capacidades introspectivas sobre los estados de objetivos e intenciones. Estas instalaciones de metanivel tambi\u00e9n son requeridas por el enfoque de Unruh et al. -LSB- 21 -RSB-, quienes definen la compensaci\u00f3n sem\u00e1ntica basada en objetivos para un agente. Los objetivos de manejo de fallas se invocan de acuerdo con las reglas de la estrategia de manejo de fallas, mediante un componente de manejo de fallas del agente dedicado -LRB-FHC-RRB- que rastrea la ejecuci\u00f3n de la tarea. Estos objetivos los especifica el agente programador y se adjuntan a las tareas, de manera muy similar a nuestra construcci\u00f3n FAb -LRB- P, PF, PA -RRB- que asocia m\u00e9todos de falla y aborto con un plan P. Sin embargo, tenga en cuenta que, a diferencia de ambos, -LSB - 6 -RSB- y nuestra sem\u00e1ntica, -LSB- 21 -RSB- adjuntan el conocimiento de manejo de fallas al nivel de meta, no de plan. Sus objetivos de manejo de fallas pueden consistir en objetivos de estabilizaci\u00f3n que realizan una \"limpieza\" inmediata y localizada para restaurar el estado del agente a un estado conocido y estable, y objetivos de compensaci\u00f3n que realizan acciones de \"deshacer\". Los objetivos de compensaci\u00f3n se activan al abortar un objetivo y, por lo tanto, no necesariamente al fallar el objetivo -LRB-, es decir, si el FHC ordena al agente que reintente el objetivo fallido y el reintento tiene \u00e9xito -RRB-. Esto contrasta con el manejo simplista de fallas a nivel de plan en el que el qu\u00e9 y el c\u00f3mo se entremezclan en el conocimiento de la tarea del dominio. Si bien nuestro enfoque se define a nivel de plan, nuestra sem\u00e1ntica BDI extendida prev\u00e9 la separaci\u00f3n de la ejecuci\u00f3n y el manejo de fallas. Adem\u00e1s, el FHC mantiene expl\u00edcitamente estructuras de datos para rastrear la ejecuci\u00f3n del agente. Aprovechamos las estructuras de ejecuci\u00f3n existentes y la capacidad de autorreflexi\u00f3n de un agente BDI para lograr tanto el aborto como el manejo de fallas sin gastos generales adicionales. Las reglas de estrategia de manejo de fallas de FHC -LRB-, por ejemplo, si se debe volver a intentar un objetivo fallido -RRB-, se reemplazan por instrucciones en nuestros planes PF y PA, junto con controladores de fallas predeterminados de metanivel seg\u00fan la naturaleza del agente -LRB. - por ejemplo, comprometido ciegamente -RRB-. El enfoque FHC es independiente de la arquitectura del agente en s\u00ed, a diferencia de nuestro trabajo que est\u00e1 dedicado al formalismo BDI -LRB- aunque no est\u00e1 ligado a ning\u00fan sistema de agente en particular -RRB-. 14 La Sexta Conferencia Internacional. Conf. Conjunta. sobre Agentes Aut\u00f3nomos y Sistemas Multiagente -LRB- AAMAS 07 -RRB- un protocolo de base estatal. Este enfoque, junto con los puntos de control de estado, se utiliza para sistemas multiagente en -LSB-22-RSB-.La arquitectura resultante incorpora su enfoque de manejo de fallas dentro de una arquitectura de procesamiento de pares para la recuperaci\u00f3n de fallas del agente. Otro trabajo sobre el manejo de excepciones de m\u00faltiples agentes incluye los agentes de manejo de excepciones distribuidos de AOEX -LSB- 5 -RSB- y los centinelas similares de -LSB- 8 -RSB-. En ambos casos, la l\u00f3gica y el conocimiento para el manejo de fallas est\u00e1n desacoplados de los agentes; por el contrario, aunque separan el manejo de excepciones del conocimiento espec\u00edfico del dominio, Unruh et al. Tanto el FHC como nuestro enfoque conservan la l\u00f3gica de manejo de fallas dentro de un agente. 6. CONCLUSI\u00d3N Y TRABAJO FUTURO Las tareas y planes de un agente pueden no llegar a completarse con \u00e9xito, ya sea por la elecci\u00f3n del agente de abortarlos -LRB- quiz\u00e1s por petici\u00f3n de otro agente para hacerlo -RRB-, o por factores no solicitados que llevan al fracaso. En este art\u00edculo hemos presentado un enfoque basado en procedimientos que incorpora tareas y planes de aborto en el ciclo de deliberaci\u00f3n de un agente estilo BDI, proporcionando as\u00ed un enfoque unificado para el fracaso y el aborto. Nuestra principal contribuci\u00f3n es un an\u00e1lisis de los requisitos sobre la operaci\u00f3n del agente para abortar tareas y planes, y una sem\u00e1ntica operativa correspondiente para abortar en el lenguaje abstracto del agente CAN. Estamos planeando implementar una instancia de nuestro enfoque en el sistema de agente SPARK -LSB- 9 -RSB-; en particular, el trabajo de este documento ser\u00e1 la base para el mecanismo de manejo de abortos de SPARK. Un agente inteligente no s\u00f3lo manejar\u00e1 con gracia tareas y planes fallidos, sino que tambi\u00e9n deliberar\u00e1 sobre sus actitudes cognitivas para decidir su pr\u00f3ximo curso de acci\u00f3n. Hemos asumido el comportamiento predeterminado de un agente estilo BDI, seg\u00fan su naturaleza: por ejemplo, volver a intentar alternativas a un plan fallido hasta que uno tenga \u00e9xito o hasta que no queden planes alternativos -LRB-, en cuyo caso fallar la tarea -RRB- . El trabajo futuro es poner nuestro enfoque al servicio de un razonamiento de agentes m\u00e1s din\u00e1mico, como la introspecci\u00f3n que puede realizar un agente capaz de razonar sobre los efectos de la interacci\u00f3n de tareas y los requisitos de recursos -LSB- 19, 12 -RSB-. Relacionado con esto est\u00e1 determinar el costo de abortar una tarea o plan y utilizarlo como insumo para el proceso de deliberaci\u00f3n. Esto influir\u00eda en particular en el compromiso que tiene el agente hacia una tarea particular: cuanto mayor sea el costo, mayor ser\u00e1 el compromiso. Otro elemento de inter\u00e9s es ampliar nuestro enfoque de fallas y abortos a los objetivos de mantenimiento -LSB- 1 -RSB-. Para tales objetivos es necesaria una sem\u00e1ntica operativa diferente para el aborto que para los objetivos de logro, para igualar la diferencia en la sem\u00e1ntica de los propios objetivos.Tanto el FHC como nuestro enfoque conservan la l\u00f3gica de manejo de fallas dentro de un agente. 6. CONCLUSI\u00d3N Y TRABAJO FUTURO Las tareas y planes de un agente pueden no llegar a completarse con \u00e9xito, ya sea por la elecci\u00f3n del agente de abortarlos -LRB- quiz\u00e1s por petici\u00f3n de otro agente para hacerlo -RRB-, o por factores no solicitados que llevan al fracaso. En este art\u00edculo hemos presentado un enfoque basado en procedimientos que incorpora tareas y planes de aborto en el ciclo de deliberaci\u00f3n de un agente estilo BDI, proporcionando as\u00ed un enfoque unificado para el fracaso y el aborto. Nuestra principal contribuci\u00f3n es un an\u00e1lisis de los requisitos sobre la operaci\u00f3n del agente para abortar tareas y planes, y una sem\u00e1ntica operativa correspondiente para abortar en el lenguaje abstracto del agente CAN. Estamos planeando implementar una instancia de nuestro enfoque en el sistema de agente SPARK -LSB- 9 -RSB-; en particular, el trabajo de este documento ser\u00e1 la base para el mecanismo de manejo de abortos de SPARK. Un agente inteligente no s\u00f3lo manejar\u00e1 con gracia tareas y planes fallidos, sino que tambi\u00e9n deliberar\u00e1 sobre sus actitudes cognitivas para decidir su pr\u00f3ximo curso de acci\u00f3n. Hemos asumido el comportamiento predeterminado de un agente estilo BDI, seg\u00fan su naturaleza: por ejemplo, volver a intentar alternativas a un plan fallido hasta que uno tenga \u00e9xito o hasta que no queden planes alternativos -LRB-, en cuyo caso fallar la tarea -RRB- . El trabajo futuro es poner nuestro enfoque al servicio de un razonamiento de agentes m\u00e1s din\u00e1mico, como la introspecci\u00f3n que puede realizar un agente capaz de razonar sobre los efectos de la interacci\u00f3n de tareas y los requisitos de recursos -LSB- 19, 12 -RSB-. Relacionado con esto est\u00e1 determinar el costo de abortar una tarea o plan y utilizarlo como insumo para el proceso de deliberaci\u00f3n. Esto influir\u00eda en particular en el compromiso que tiene el agente hacia una tarea particular: cuanto mayor sea el costo, mayor ser\u00e1 el compromiso. Otro elemento de inter\u00e9s es ampliar nuestro enfoque de fallas y abortos a los objetivos de mantenimiento -LSB- 1 -RSB-. Para tales objetivos es necesaria una sem\u00e1ntica operativa diferente para el aborto que para los objetivos de logro, para igualar la diferencia en la sem\u00e1ntica de los propios objetivos.Tanto el FHC como nuestro enfoque conservan la l\u00f3gica de manejo de fallas dentro de un agente. 6. CONCLUSI\u00d3N Y TRABAJO FUTURO Las tareas y planes de un agente pueden no llegar a completarse con \u00e9xito, ya sea por la elecci\u00f3n del agente de abortarlos -LRB- quiz\u00e1s por petici\u00f3n de otro agente para hacerlo -RRB-, o por factores no solicitados que llevan al fracaso. En este art\u00edculo hemos presentado un enfoque basado en procedimientos que incorpora tareas y planes de aborto en el ciclo de deliberaci\u00f3n de un agente estilo BDI, proporcionando as\u00ed un enfoque unificado para el fracaso y el aborto. Nuestra principal contribuci\u00f3n es un an\u00e1lisis de los requisitos sobre la operaci\u00f3n del agente para abortar tareas y planes, y una sem\u00e1ntica operativa correspondiente para abortar en el lenguaje abstracto del agente CAN. Estamos planeando implementar una instancia de nuestro enfoque en el sistema de agente SPARK -LSB- 9 -RSB-; en particular, el trabajo de este documento ser\u00e1 la base para el mecanismo de manejo de abortos de SPARK. Un agente inteligente no s\u00f3lo manejar\u00e1 con gracia tareas y planes fallidos, sino que tambi\u00e9n deliberar\u00e1 sobre sus actitudes cognitivas para decidir su pr\u00f3ximo curso de acci\u00f3n. Hemos asumido el comportamiento predeterminado de un agente estilo BDI, seg\u00fan su naturaleza: por ejemplo, volver a intentar alternativas a un plan fallido hasta que uno tenga \u00e9xito o hasta que no queden planes alternativos -LRB-, en cuyo caso fallar la tarea -RRB- . El trabajo futuro es poner nuestro enfoque al servicio de un razonamiento de agentes m\u00e1s din\u00e1mico, como la introspecci\u00f3n que puede realizar un agente capaz de razonar sobre los efectos de la interacci\u00f3n de tareas y los requisitos de recursos -LSB- 19, 12 -RSB-. Relacionado con esto est\u00e1 determinar el costo de abortar una tarea o plan y utilizarlo como insumo para el proceso de deliberaci\u00f3n. Esto influir\u00eda en particular en el compromiso que tiene el agente hacia una tarea particular: cuanto mayor sea el costo, mayor ser\u00e1 el compromiso. Otro elemento de inter\u00e9s es ampliar nuestro enfoque de fallas y abortos a los objetivos de mantenimiento -LSB- 1 -RSB-. Para tales objetivos es necesaria una sem\u00e1ntica operativa diferente para el aborto que para los objetivos de logro, para igualar la diferencia en la sem\u00e1ntica de los propios objetivos.El trabajo de este documento ser\u00e1 la base para el mecanismo de manejo de abortos de SPARK. Un agente inteligente no s\u00f3lo manejar\u00e1 con gracia tareas y planes fallidos, sino que tambi\u00e9n deliberar\u00e1 sobre sus actitudes cognitivas para decidir su pr\u00f3ximo curso de acci\u00f3n. Hemos asumido el comportamiento predeterminado de un agente estilo BDI, seg\u00fan su naturaleza: por ejemplo, volver a intentar alternativas a un plan fallido hasta que uno tenga \u00e9xito o hasta que no queden planes alternativos -LRB-, en cuyo caso fallar la tarea -RRB- . El trabajo futuro es poner nuestro enfoque al servicio de un razonamiento de agentes m\u00e1s din\u00e1mico, como la introspecci\u00f3n que puede realizar un agente capaz de razonar sobre los efectos de la interacci\u00f3n de tareas y los requisitos de recursos -LSB- 19, 12 -RSB-. Relacionado con esto est\u00e1 determinar el costo de abortar una tarea o plan y utilizarlo como insumo para el proceso de deliberaci\u00f3n. Esto influir\u00eda en particular en el compromiso que tiene el agente hacia una tarea particular: cuanto mayor sea el costo, mayor ser\u00e1 el compromiso. Otro elemento de inter\u00e9s es ampliar nuestro enfoque de fallas y abortos a los objetivos de mantenimiento -LSB- 1 -RSB-. Para tales objetivos es necesaria una sem\u00e1ntica operativa diferente para el aborto que para los objetivos de logro, para igualar la diferencia en la sem\u00e1ntica de los propios objetivos.El trabajo de este documento ser\u00e1 la base para el mecanismo de manejo de abortos de SPARK. Un agente inteligente no s\u00f3lo manejar\u00e1 con gracia tareas y planes fallidos, sino que tambi\u00e9n deliberar\u00e1 sobre sus actitudes cognitivas para decidir su pr\u00f3ximo curso de acci\u00f3n. Hemos asumido el comportamiento predeterminado de un agente estilo BDI, seg\u00fan su naturaleza: por ejemplo, volver a intentar alternativas a un plan fallido hasta que uno tenga \u00e9xito o hasta que no queden planes alternativos -LRB-, en cuyo caso fallar la tarea -RRB- . El trabajo futuro es poner nuestro enfoque al servicio de un razonamiento de agentes m\u00e1s din\u00e1mico, como la introspecci\u00f3n que puede realizar un agente capaz de razonar sobre los efectos de la interacci\u00f3n de tareas y los requisitos de recursos -LSB- 19, 12 -RSB-. Relacionado con esto est\u00e1 determinar el costo de abortar una tarea o plan y utilizarlo como insumo para el proceso de deliberaci\u00f3n. Esto influir\u00eda en particular en el compromiso que tiene el agente hacia una tarea particular: cuanto mayor sea el costo, mayor ser\u00e1 el compromiso. Otro elemento de inter\u00e9s es ampliar nuestro enfoque de fallas y abortos a los objetivos de mantenimiento -LSB- 1 -RSB-. Para tales objetivos es necesaria una sem\u00e1ntica operativa diferente para el aborto que para los objetivos de logro, para igualar la diferencia en la sem\u00e1ntica de los propios objetivos.", "keyphrases": ["agente de inteligencia", "fracaso", "trato", "m\u00e9todo de limpieza", "m\u00e9todo de aborto", "sem\u00e1ntico de \u00f3pera", "tarea", "meta", "construcci\u00f3n de objetivos"]}
{"file_name": "I-9", "text": "L\u00f3gica lineal temporal como base para interacciones flexibles de agentes RESUMEN Las interacciones entre agentes en un sistema abierto como Internet requieren un grado significativo de flexibilidad. Un aspecto crucial del desarrollo de tales m\u00e9todos es la noci\u00f3n de compromisos, que proporciona un mecanismo para coordinar comportamientos interactivos entre agentes. En este art\u00edculo, investigamos un enfoque para modelar compromisos con una estrecha integraci\u00f3n con las acciones del protocolo. Esto significa que no hay necesidad de tener un mapeo expl\u00edcito de las acciones de los protocolos a las operaciones sobre los compromisos y un mecanismo externo para procesar y hacer cumplir los compromisos. Mostramos c\u00f3mo los agentes pueden razonar sobre compromisos y acciones de protocolo para lograr los resultados finales de los protocolos utilizando un sistema de razonamiento basado en l\u00f3gica lineal temporal, que incorpora razonamiento tanto temporal como sensible a los recursos. Tambi\u00e9n discutimos la aplicaci\u00f3n de este marco a escenarios como el comercio en l\u00ednea. 1. INTRODUCCI\u00d3N Y MOTIVACI\u00d3N El paradigma del agente se ha vuelto muy adecuado como met\u00e1fora de dise\u00f1o para tratar con sistemas complejos que comprenden muchos componentes, cada uno con su propio hilo de control y prop\u00f3sitos e involucrados en interacciones din\u00e1micas y complejas. En entornos de m\u00faltiples agentes, los agentes a menudo necesitan interactuar entre s\u00ed para cumplir sus objetivos. Los protocolos se utilizan para regular las interacciones. En los enfoques tradicionales de especificaci\u00f3n de protocolos, como aquellos que utilizan m\u00e1quinas de estados finitos o redes de Petri, los protocolos suelen ser secuencias legales predeterminadas de comportamientos interactivos. Por lo tanto, se requiere que los agentes adapten sus comportamientos interactivos para tener \u00e9xito y las interacciones entre agentes no deben construirse de manera r\u00edgida. Para lograr flexibilidad, como lo caracterizan Yolum y Singh en -LSB- 11 -RSB-, los protocolos de interacci\u00f3n deben garantizar que los agentes tengan autonom\u00eda sobre sus comportamientos interactivos y est\u00e9n libres de restricciones innecesarias. Adem\u00e1s, se debe permitir a los agentes ajustar sus acciones interactivas para aprovechar oportunidades o manejar excepciones que surjan durante la interacci\u00f3n. Por ejemplo, considere el siguiente escenario para las ventas en l\u00ednea. Cus tiene el objetivo de obtener de Mer un bate de cricket en alg\u00fan momento. Hay dos opciones para que Cus pague. Si Cus utiliza el pago con cr\u00e9dito, Mer necesita un banco Ebank para verificar el cr\u00e9dito de Cus. Si se aprueba el cr\u00e9dito de Cus, Ebank se encargar\u00e1 del pago del cr\u00e9dito. De lo contrario, Cus podr\u00e1 optar por pagar mediante PayPal. La interacci\u00f3n finaliza cuando se entregan los bienes y se realiza el pago. Un enfoque flexible para este ejemplo deber\u00eda incluir varias caracter\u00edsticas. En segundo lugar, no deber\u00eda haber restricciones innecesarias sobre el orden en que se realizan las acciones, como por ejemplo, qu\u00e9 hacer los pagos y enviar el bate de cr\u00edquet debe ser primero. En tercer lugar, la elecci\u00f3n de una secuencia de acciones interactivas debe basarse en un razonamiento sobre los significados intr\u00ednsecos de las acciones protocolarias, que se basan en la noci\u00f3n de compromiso, es decirque se refiere a una fuerte promesa a otro agente -LRB- s -RRB- de emprender algunos cursos de acci\u00f3n. Los enfoques actuales -LSB- 11, 12, 10, 1 -RSB- para lograr flexibilidades utilizando la noci\u00f3n de compromiso hacen uso de una capa abstracta de compromisos. Sin embargo, en estos enfoques, se debe proporcionar externamente un mapeo de las acciones del protocolo a las operaciones sobre compromisos, as\u00ed como a los mecanismos de manejo y cumplimiento de los compromisos. La ejecuci\u00f3n de acciones de protocolo tambi\u00e9n requiere la ejecuci\u00f3n simult\u00e1nea de operaciones sobre compromisos relacionados. Como resultado, la sobrecarga del procesamiento de la capa de compromiso hace que la especificaci\u00f3n y ejecuci\u00f3n de protocolos sea m\u00e1s complicada y propensa a errores. Tambi\u00e9n falta una l\u00f3gica para expresar con naturalidad aspectos de recursos, opciones internas y externas, as\u00ed como tiempos de protocolos. En lugar de crear otra capa de compromiso fuera de las acciones del protocolo, intentamos lograr un modelo de compromisos que est\u00e9 integrado con las acciones del protocolo. Entonces se puede razonar tanto los compromisos como las acciones protocolarias en un sistema consistente. Para lograrlo, especificamos los protocolos de manera declarativa, es decir, qu\u00e9 se debe lograr en lugar de c\u00f3mo deben interactuar los agentes. Una clave para esto es usar la l\u00f3gica. La l\u00f3gica temporal, en particular, es adecuada para describir y razonar sobre restricciones temporales, mientras que la l\u00f3gica lineal -LSB- 3 -RSB- es bastante adecuada para modelar recursos. Sugerimos utilizar una combinaci\u00f3n de l\u00f3gica lineal y l\u00f3gica temporal para construir un marco de interacci\u00f3n basado en el compromiso que permita un razonamiento tanto temporal como relacionado con los recursos para los protocolos de interacci\u00f3n. Esto proporciona un mecanismo natural de manipulaci\u00f3n y razonamiento, as\u00ed como mecanismos internos de cumplimiento de los compromisos basados \u200b\u200ben la b\u00fasqueda de pruebas. La secci\u00f3n 2 analiza los antecedentes de la l\u00f3gica lineal, la l\u00f3gica lineal temporal y los compromisos. La Secci\u00f3n 3 presenta nuestro marco de modelado y especificaci\u00f3n de protocolos. La Secci\u00f3n 4 analiza c\u00f3mo se puede utilizar nuestro marco para un ejemplo de interacciones de venta en l\u00ednea entre un comerciante, un banco y un cliente. Luego discutimos las ventajas y limitaciones de usar nuestro marco para modelar protocolos de interacci\u00f3n y lograr flexibilidad en la Secci\u00f3n 5. La Secci\u00f3n 6 presenta nuestras conclusiones y elementos de trabajo adicional. 2. ANTECEDENTES Para aumentar la autonom\u00eda de los agentes sobre sus comportamientos interactivos, los protocolos deben especificarse en t\u00e9rminos de lo que se debe lograr en lugar de c\u00f3mo deben actuar los agentes. En otras palabras, los protocolos deben especificarse de forma declarativa. El uso de la l\u00f3gica es fundamental para este proceso de especificaci\u00f3n. 2.1 L\u00f3gica lineal La l\u00f3gica se ha utilizado como formalismo para modelar y razonar sobre sistemas de agentes. La l\u00f3gica lineal -LSB- 3 -RSB- es conocida por modelar recursos y actualizar procesos. Se ha considerado en sistemas de agentes para apoyar la negociaci\u00f3n y planificaci\u00f3n de agentes mediante b\u00fasqueda de pruebas -LSB- 5, 8 -RSB-. En la vida real, se consumen recursos y se crean nuevos recursos.Sin embargo, en l\u00f3gicas como la cl\u00e1sica o temporal, la asignaci\u00f3n directa de recursos a f\u00f3rmulas resulta problem\u00e1tica. Si modelamos recursos como A como ``un d\u00f3lar'' y B como ``una barra de chocolate'', entonces A = *B en l\u00f3gica cl\u00e1sica se lee como ``con un d\u00f3lar podemos obtener una barra de chocolate''. Para resolver tales problemas de mapeo de recursos y f\u00f3rmulas, Girard propuso restricciones sobre qu\u00e9 f\u00f3rmulas se usar\u00e1n exactamente una vez y ya no se pueden agregar o eliminar libremente en las derivaciones y, por lo tanto, tratar las f\u00f3rmulas de l\u00f3gica lineal como recursos. Sin embargo, en l\u00f3gica lineal, una implicaci\u00f3n lineal A - B permite eliminar A despu\u00e9s de derivar B, lo que significa que el d\u00f3lar desaparece despu\u00e9s de usar un d\u00f3lar para comprar una barra de chocolate. La conjunci\u00f3n cl\u00e1sica -LRB- y -RRB- y la disyunci\u00f3n -LRB- o -RRB- se reformulan en diferentes usos de contexts: multiplicativo como combinaci\u00f3n y aditivo como compartir para generar cuatro conectivos. La capacidad de especificar opciones mediante conectivos aditivos es una caracter\u00edstica particularmente \u00fatil de la l\u00f3gica lineal. A & -LRB- conjunci\u00f3n aditiva -RRB- B, representa una elecci\u00f3n propia, ya sea de A o de B pero no de ambos. En los sistemas de agentes, esta dualidad entre elecciones internas y externas se manifiesta cuando un agente tiene el poder de elegir entre alternativas y el otro tiene que reaccionar ante cualquier elecci\u00f3n que se haga. Adem\u00e1s, durante la interacci\u00f3n, la capacidad de hacer coincidir el consumo y la oferta de recursos entre los agentes puede simplificar la especificaci\u00f3n de las asignaciones de recursos. La l\u00f3gica lineal es un mecanismo natural para proporcionar esta capacidad -LSB- 5 -RSB-. Adem\u00e1s, en -LSB-8-RSB- se enfatiza que la l\u00f3gica lineal se usa para modelar estados de agentes como conjuntos de recursos consumibles y, particularmente, la implicaci\u00f3n lineal se usa para modelar transiciones entre estados y capacidades de agentes. 2.2 L\u00f3gica lineal temporal Si bien la l\u00f3gica lineal proporciona ventajas para modelar y razonar sobre recursos, no aborda naturalmente las limitaciones de tiempo. La l\u00f3gica temporal, por otro lado, es un sistema formal que aborda la descripci\u00f3n y el razonamiento sobre los cambios de los valores de verdad de las expresiones l\u00f3gicas a lo largo del tiempo -LSB- 2 -RSB-. La l\u00f3gica temporal se puede utilizar para la especificaci\u00f3n y verificaci\u00f3n de programas concurrentes y reactivos -LSB- 2 -RSB-. La l\u00f3gica lineal temporal -LRB- TLL -RRB- -LSB- 6 -RSB- es el resultado de introducir la l\u00f3gica temporal en la l\u00f3gica lineal y, por lo tanto, tiene en cuenta los recursos y se ocupa del tiempo. Los operadores temporales utilizados son Q -LRB- siguiente -RRB-, \u2751 -LRB- en cualquier momento -RRB-, y O -LRB- en alg\u00fan momento -RRB- -LSB- 6 -RSB-. Se puede considerar que las f\u00f3rmulas sin operadores temporales est\u00e1n disponibles s\u00f3lo en la actualidad. Agregar Q a una f\u00f3rmula A, es decir, QA, significa que A s\u00f3lo se puede usar la pr\u00f3xima vez y exactamente una vez. De manera similar, \u2751 A significa que A puede usarse en cualquier momento y exactamente una vez. OA significa que A se puede usar una vez en alg\u00fan momento. Aunque tanto \u2751 como O se refieren a un momento en el tiempo, la elecci\u00f3n de qu\u00e9 momento es diferente. Respecto a \u2751, la elecci\u00f3n es una elecci\u00f3n interna,seg\u00fan corresponda a la propia capacidad. Con O, la elecci\u00f3n la deciden externamente otros. 2.3 Compromiso El concepto de compromiso social ha sido reconocido como fundamental para la interacci\u00f3n de los agentes. En efecto, el compromiso social proporciona significados intr\u00ednsecos a las acciones y estados protocolarios -LSB- 11 -RSB-. En particular, la persistencia en los compromisos introduce en la consideraci\u00f3n de los agentes un cierto nivel de previsibilidad de las acciones de otros agentes, lo cual es importante cuando los agentes abordan cuestiones de interdependencias, limitaciones globales o La Sexta Conferencia Internacional. intercambio de recursos -LSB- 7 -RSB-. Los enfoques basados \u200b\u200ben compromisos asocian las acciones de los protocolos con las operaciones sobre los compromisos y los estados de los protocolos con el conjunto de compromisos efectivos -LSB- 11 -RSB-. Completar el protocolo se realiza mediante el razonamiento de medios y fines en las operaciones de compromiso para llevar el estado actual a estados finales donde se resuelven todos los compromisos. A partir de entonces se determinan las correspondientes secuencias legales de acciones interactivas. Por lo tanto, los enfoques mejoran sistem\u00e1ticamente una variedad de c\u00f3mputos legales -LSB- 11 -RSB-. Los compromisos se pueden reducir a una forma m\u00e1s fundamental conocida como precompromisos. Un precompromiso aqu\u00ed se refiere a un compromiso potencial que especifica lo que el agente propietario est\u00e1 dispuesto a comprometer -LSB- 4 -RSB-, como realizar algunas acciones o lograr un estado particular. Los agentes pueden negociar sobre compromisos previos enviando propuestas de los mismos a otros. Una vez que se acuerda un precompromiso, se convierte en compromiso y el proceso pasa de la fase de negociaci\u00f3n a la fase de compromiso, en la que los agentes act\u00faan para cumplir sus compromisos.como realizar algunas acciones o alcanzar un estado particular. Los agentes pueden negociar sobre compromisos previos enviando propuestas de los mismos a otros. Una vez que se acuerda un precompromiso, se convierte en compromiso y el proceso pasa de la fase de negociaci\u00f3n a la fase de compromiso, en la que los agentes act\u00faan para cumplir sus compromisos.como realizar algunas acciones o alcanzar un estado particular. Los agentes pueden negociar sobre compromisos previos enviando propuestas de los mismos a otros. Una vez que se acuerda un precompromiso, se convierte en compromiso y el proceso pasa de la fase de negociaci\u00f3n a la fase de compromiso, en la que los agentes act\u00faan para cumplir sus compromisos.", "keyphrases": ["entorno multiagente", "interactuar comportamiento", "restricci\u00f3n de tiempo", "protocolo de interacci\u00f3n", "l\u00f3gica lineal", "conjunci\u00f3n m\u00faltiple", "conjunci\u00f3n cl\u00e1sica", "nivel de predicci\u00f3n", "pre cometido", "lineal impl\u00edcito", "protocolo emergente", "compromiso de condici\u00f3n", "solicitar mensaje", "relaci\u00f3n causal"]}
{"file_name": "J 3", "text": "Optimizaci\u00f3n del presupuesto en subastas de publicidad basada en b\u00fasquedas RESUMEN Las empresas de b\u00fasqueda en Internet venden espacios publicitarios basados \u200b\u200ben las consultas de b\u00fasqueda de los usuarios a trav\u00e9s de una subasta. Si bien ha habido trabajos previos sobre el proceso de subasta y sus aspectos de teor\u00eda de juegos, la mayor parte se centra en la empresa de Internet. En este trabajo, nos centramos en los anunciantes, quienes deben resolver un complejo problema de optimizaci\u00f3n para decidir c\u00f3mo realizar pujas por palabras clave para maximizar su retorno -LRB- el n\u00famero de clics de los usuarios en sus anuncios -RRB- para un presupuesto determinado. Modelamos todo el proceso y estudiamos este problema de optimizaci\u00f3n presupuestaria. Si bien la mayor\u00eda de las variantes son NP-hard, mostramos, quiz\u00e1s sorprendentemente, que la simple aleatorizaci\u00f3n entre dos estrategias uniformes que ofertan equitativamente por todas las palabras clave funciona bien. M\u00e1s precisamente, esta estrategia obtiene al menos una fracci\u00f3n de 1 \u2212 1/e del m\u00e1ximo de clics posibles. Como muestran nuestros experimentos preliminares, es probable que estas estrategias uniformes sean pr\u00e1cticas. Tambi\u00e9n presentamos resultados de inaproximabilidad y algoritmos \u00f3ptimos para variantes del problema de optimizaci\u00f3n presupuestaria. 1. INTRODUCCI\u00d3N La b\u00fasqueda en l\u00ednea es ahora omnipresente y las empresas de b\u00fasqueda en Internet como Google, Yahoo! y MSN permiten a las empresas y * Trabajo realizado durante su visita a Google, Inc., Nueva York, NY. los individuos anuncian bas\u00e1ndose en consultas de b\u00fasqueda planteadas por los usuarios. Los medios de comunicaci\u00f3n convencionales, como las estaciones de televisi\u00f3n o los peri\u00f3dicos, fijan el precio de sus espacios publicitarios individualmente y los anunciantes compran los que pueden pagar. Por el contrario, a las empresas de b\u00fasqueda en Internet les resulta dif\u00edcil fijar un precio expl\u00edcito para los anuncios que colocan en respuesta a las consultas de los usuarios. Por lo tanto, dependen del mercado para determinar los precios adecuados mediante subastas entre los anunciantes. Es un problema dif\u00edcil organizar la subasta para lograr un mercado estable en el que todas las partes -LRB-, los anunciantes, los usuarios y la empresa de b\u00fasqueda de Internet -RRB- est\u00e9n adecuadamente satisfechos. La perspectiva en este art\u00edculo no es la de la empresa de b\u00fasqueda en Internet que muestra los anuncios, sino la de los anunciantes. El desaf\u00edo desde el punto de vista de un anunciante es comprender e interactuar con el mecanismo de subasta. El anunciante determina un conjunto de palabras clave de su inter\u00e9s y luego debe crear anuncios, establecer las ofertas para cada palabra clave y proporcionar un presupuesto total -LRB-, a menudo diario -RRB-. Cuando un usuario plantea una consulta de b\u00fasqueda, la empresa de b\u00fasqueda de Internet determina los anunciantes cuyas palabras clave coinciden con la consulta y a quienes a\u00fan les queda presupuesto, realiza una subasta entre ellos y presenta el conjunto de anuncios correspondientes a los anunciantes que \"ganan\". la subasta. El anunciante cuyo anuncio aparece paga a la empresa de b\u00fasqueda de Internet si el usuario hace clic en el anuncio. El enfoque de este documento est\u00e1 en c\u00f3mo ofertan los anunciantes. Para la elecci\u00f3n particular de palabras clave de su inter\u00e9s1, un anunciante desea optimizar el efecto general de la campa\u00f1a publicitaria.Las empresas de b\u00fasqueda en Internet apoyan 1. La elecci\u00f3n de las palabras clave est\u00e1 relacionada con el conocimiento del dominio por parte del anunciante, el comportamiento del usuario y consideraciones estrat\u00e9gicas. Las empresas de b\u00fasqueda de Internet proporcionan a los anunciantes res\u00famenes del tr\u00e1fico de consultas, lo que les resulta \u00fatil para optimizar sus elecciones de palabras clave de forma interactiva. No abordamos directamente la elecci\u00f3n de palabras clave en este art\u00edculo, que se aborda en otra parte -LSB- 13 -RSB-. protege a los anunciantes y proporciona estad\u00edsticas sobre el historial de vol\u00famenes de clics y predicciones sobre el rendimiento futuro de varias palabras clave. 9 Existen interacciones complejas entre palabras clave porque una consulta de usuario puede coincidir con dos o m\u00e1s palabras clave, ya que el anunciante est\u00e1 tratando de cubrir todas las palabras clave posibles en alg\u00fan dominio. En efecto, el anunciante acaba compitiendo consigo mismo. Como resultado, los anunciantes se enfrentan a un dif\u00edcil problema de optimizaci\u00f3n. El objetivo de este art\u00edculo es resolver este problema de optimizaci\u00f3n. 1.1 El problema de la optimizaci\u00f3n del presupuesto Presentamos una breve discusi\u00f3n y formulaci\u00f3n del problema de optimizaci\u00f3n que enfrentan los anunciantes; encontrar\u00e1 una descripci\u00f3n m\u00e1s detallada en la Secci\u00f3n 2. Un anunciante determinado ve el estado de las subastas de publicidad basada en b\u00fasquedas de la siguiente manera. Existe un conjunto K de palabras clave de inter\u00e9s; en la pr\u00e1ctica, incluso los anunciantes peque\u00f1os suelen tener un conjunto K grande. Hay un conjunto Q de consultas planteadas por los usuarios. Para cada consulta q GQ, hay funciones que dan los clicsq -LRB- b -RRB- y el costoq -LRB- b -RRB- que resultan de ofertar una cantidad particular b en la subasta para esa consulta, que modelamos m\u00e1s formalmente en el Siguiente secci\u00f3n. Hay un gr\u00e1fico bipartito G en los dos conjuntos de v\u00e9rtices que representan K y Q. Para cualquier consulta q GQ, los vecinos de q en K son las palabras clave que se dice que \"coinciden\" con la consulta q. 2 El problema de optimizaci\u00f3n del presupuesto es el siguiente. Dado el gr\u00e1fico G junto con las funciones clicksq -LRB-. -RRB- y costoq -LRB-. -RRB- en las consultas, as\u00ed como un presupuesto U, determine las ofertas bk para cada palabra clave k GK de manera que Pq clicsq -LRB- bq -RRB- se maximice sujeto a Pq costoq -LRB- bq -RRB- < U, donde la `` oferta efectiva '' bq en una consulta es alguna funci\u00f3n de las ofertas de palabras clave en la vecindad de q. Si bien podemos considerar este problema como un problema de optimizaci\u00f3n tradicional, existen diferentes desaf\u00edos en la pr\u00e1ctica dependiendo del acceso del anunciante a la consulta y a la informaci\u00f3n del gr\u00e1fico y, de hecho, de la confiabilidad de esta informaci\u00f3n (LRB), por ejemplo, podr\u00eda basarse en datos inestables. datos hist\u00f3ricos -RRB-. Por lo tanto, es importante encontrar soluciones a este problema que no s\u00f3lo generen muchos clics, sino que tambi\u00e9n sean simples, s\u00f3lidas y menos dependientes de la informaci\u00f3n. En este art\u00edculo definimos la noci\u00f3n de estrategia \"uniforme\", que es esencialmente una estrategia que ofrece ofertas uniformes para todas las palabras clave. Dado que este tipo de estrategia evita la necesidad de saber algo sobre los detalles del gr\u00e1fico y agrega de manera efectiva las funciones de clic y costo en las consultas,es bastante robusto y, por tanto, deseable en la pr\u00e1ctica. Lo sorprendente es que la estrategia uniforme realmente funciona bien, como lo demostraremos. 1.2 Nuestros principales resultados y descripci\u00f3n t\u00e9cnica Presentamos resultados positivos y negativos para el problema de optimizaci\u00f3n del presupuesto. En particular, mostramos: 9 Casi todas las formulaciones del problema son NP-Duro. En casos ligeramente m\u00e1s generales que la formulaci\u00f3n anterior, donde los clics tienen pesos, el problema es inaproximable mejor que un factor de 1 - 1e, a menos que P = NP. 9 Damos un algoritmo de aproximaci\u00f3n -LRB- 1 -- 1/e -RRB- - para el problema de optimizaci\u00f3n presupuestaria. La estrategia encontrada por el algoritmo es una estrategia uniforme de dos ofertas, lo que significa que aleatoriza entre ofertar alg\u00fan valor b1 en todas las palabras clave y ofertar alg\u00fan otro valor b2 en todas las palabras clave hasta que se agote el presupuesto3. Mostramos que este ratio de aproximaci\u00f3n es ajustado para estrategias uniformes. Tambi\u00e9n proporcionamos un algoritmo de aproximaci\u00f3n -LRB- 1/2 -RRB- que ofrece una estrategia uniforme de oferta \u00fanica, utilizando solo un valor b1. -LRB- Esto es ajustado para estrategias uniformes de oferta \u00fanica. -RRB- Estas estrategias se pueden calcular en un tiempo casi lineal en JQJ + JKJ, el tama\u00f1o de entrada. Las estrategias uniformes pueden parecer ingenuas a primera vista porque las palabras clave var\u00edan significativamente en sus funciones de clic y costo, y puede haber una interacci\u00f3n compleja entre ellas cuando varias palabras clave son relevantes para una consulta. Despu\u00e9s de todo, lo \u00f3ptimo puede configurar ofertas arbitrarias para cada una de las palabras clave. Incluso para el caso simple en el que el gr\u00e1fico es una coincidencia, el algoritmo \u00f3ptimo implica realizar diferentes ofertas para diferentes palabras clave a trav\u00e9s de un embalaje similar a una mochila -LRB- Secci\u00f3n 2 -RRB-. Por lo tanto, podr\u00eda resultar sorprendente que una estrategia uniforme simple de dos ofertas sea un 63 % o m\u00e1s efectiva en comparaci\u00f3n con la \u00f3ptima. Nuestra prueba de la relaci\u00f3n de aproximaci\u00f3n 1 -- 1/e se basa en un an\u00e1lisis contradictorio. Definimos un LP revelador de factores -LRB- Secci\u00f3n 4 -RRB- donde las soluciones primarias corresponden a instancias posibles y las soluciones duales corresponden a distribuciones sobre estrategias de oferta. Hemos realizado simulaciones utilizando datos reales de subastas de Google. Los resultados de estas simulaciones, que se destacan al final de la Secci\u00f3n 4, sugieren que estrategias de licitaci\u00f3n uniformes podr\u00edan ser \u00fatiles en la pr\u00e1ctica. 8. COMENTARIOS FINALES Otra generalizaci\u00f3n interesante es considerar ponderaciones de los clics, que es una forma de modelar las conversiones. -LRB- Una conversi\u00f3n corresponde a una acci\u00f3n por parte del usuario que hizo clic en el sitio del anunciante; por ejemplo, una venta o el registro de una cuenta. -RRB- Finalmente, hemos visto este sistema como una caja negra que devuelve clics en funci\u00f3n de la oferta, cuando en realidad es un juego complejo y repetido que involucra a m\u00faltiples anunciantes. En -LSB- 3 -RSB-, se demostr\u00f3 que cuando un conjunto de anunciantes utiliza una estrategia similar a la que sugerimos aqu\u00ed, bajo una subasta de primer precio ligeramente modificada, los precios se acercan a un equilibrio de mercado bien entendido.Lo sorprendente es que la estrategia uniforme realmente funciona bien, como lo demostraremos. 1.2 Nuestros principales resultados y descripci\u00f3n t\u00e9cnica Presentamos resultados positivos y negativos para el problema de optimizaci\u00f3n del presupuesto. En particular, mostramos: 9 Casi todas las formulaciones del problema son NP-Duro. En casos ligeramente m\u00e1s generales que la formulaci\u00f3n anterior, donde los clics tienen pesos, el problema es inaproximable mejor que un factor de 1 - 1e, a menos que P = NP. 9 Damos un algoritmo de aproximaci\u00f3n -LRB- 1 -- 1/e -RRB- - para el problema de optimizaci\u00f3n presupuestaria. La estrategia encontrada por el algoritmo es una estrategia uniforme de dos ofertas, lo que significa que aleatoriza entre ofertar alg\u00fan valor b1 en todas las palabras clave y ofertar alg\u00fan otro valor b2 en todas las palabras clave hasta que se agote el presupuesto3. Mostramos que este ratio de aproximaci\u00f3n es ajustado para estrategias uniformes. Tambi\u00e9n proporcionamos un algoritmo de aproximaci\u00f3n -LRB- 1/2 -RRB- que ofrece una estrategia uniforme de oferta \u00fanica, utilizando solo un valor b1. -LRB- Esto es ajustado para estrategias uniformes de oferta \u00fanica. -RRB- Estas estrategias se pueden calcular en un tiempo casi lineal en JQJ + JKJ, el tama\u00f1o de entrada. Las estrategias uniformes pueden parecer ingenuas a primera vista porque las palabras clave var\u00edan significativamente en sus funciones de clic y costo, y puede haber una interacci\u00f3n compleja entre ellas cuando varias palabras clave son relevantes para una consulta. Despu\u00e9s de todo, lo \u00f3ptimo puede configurar ofertas arbitrarias para cada una de las palabras clave. Incluso para el caso simple en el que el gr\u00e1fico es una coincidencia, el algoritmo \u00f3ptimo implica realizar diferentes ofertas para diferentes palabras clave mediante un embalaje tipo mochila -LRB- Secci\u00f3n 2 -RRB-. Por lo tanto, podr\u00eda resultar sorprendente que una estrategia uniforme simple de dos ofertas sea un 63 % o m\u00e1s efectiva en comparaci\u00f3n con la \u00f3ptima. Nuestra prueba de la relaci\u00f3n de aproximaci\u00f3n 1 -- 1/e se basa en un an\u00e1lisis contradictorio. Definimos un LP revelador de factores -LRB- Secci\u00f3n 4 -RRB- donde las soluciones primarias corresponden a instancias posibles y las soluciones duales corresponden a distribuciones sobre estrategias de oferta. Hemos realizado simulaciones utilizando datos reales de subastas de Google. Los resultados de estas simulaciones, que se destacan al final de la Secci\u00f3n 4, sugieren que estrategias de licitaci\u00f3n uniformes podr\u00edan ser \u00fatiles en la pr\u00e1ctica. 8. COMENTARIOS FINALES Otra generalizaci\u00f3n interesante es considerar ponderaciones de los clics, que es una forma de modelar las conversiones. -LRB- Una conversi\u00f3n corresponde a una acci\u00f3n por parte del usuario que hizo clic en el sitio del anunciante; por ejemplo, una venta o el registro de una cuenta. -RRB- Finalmente, hemos visto este sistema como una caja negra que devuelve clics en funci\u00f3n de la oferta, cuando en realidad es un juego complejo y repetido que involucra a m\u00faltiples anunciantes. En -LSB- 3 -RSB-, se demostr\u00f3 que cuando un conjunto de anunciantes utiliza una estrategia similar a la que sugerimos aqu\u00ed, bajo una subasta de primer precio ligeramente modificada, los precios se acercan a un equilibrio de mercado bien entendido.Lo sorprendente es que la estrategia uniforme realmente funciona bien, como lo demostraremos. 1.2 Nuestros principales resultados y descripci\u00f3n t\u00e9cnica Presentamos resultados positivos y negativos para el problema de optimizaci\u00f3n del presupuesto. En particular, mostramos: 9 Casi todas las formulaciones del problema son NP-Duro. En casos ligeramente m\u00e1s generales que la formulaci\u00f3n anterior, donde los clics tienen pesos, el problema es inaproximable mejor que un factor de 1 - 1e, a menos que P = NP. 9 Damos un algoritmo de aproximaci\u00f3n -LRB- 1 -- 1/e -RRB- - para el problema de optimizaci\u00f3n presupuestaria. La estrategia encontrada por el algoritmo es una estrategia uniforme de dos ofertas, lo que significa que aleatoriza entre ofertar alg\u00fan valor b1 en todas las palabras clave y ofertar alg\u00fan otro valor b2 en todas las palabras clave hasta que se agote el presupuesto3. Mostramos que este ratio de aproximaci\u00f3n es ajustado para estrategias uniformes. Tambi\u00e9n proporcionamos un algoritmo de aproximaci\u00f3n -LRB- 1/2 -RRB- que ofrece una estrategia uniforme de oferta \u00fanica, utilizando solo un valor b1. -LRB- Esto es ajustado para estrategias uniformes de oferta \u00fanica. -RRB- Estas estrategias se pueden calcular en un tiempo casi lineal en JQJ + JKJ, el tama\u00f1o de entrada. Las estrategias uniformes pueden parecer ingenuas a primera vista porque las palabras clave var\u00edan significativamente en sus funciones de clic y costo, y puede haber una interacci\u00f3n compleja entre ellas cuando varias palabras clave son relevantes para una consulta. Despu\u00e9s de todo, lo \u00f3ptimo puede configurar ofertas arbitrarias para cada una de las palabras clave. Incluso para el caso simple en el que el gr\u00e1fico es una coincidencia, el algoritmo \u00f3ptimo implica realizar diferentes ofertas para diferentes palabras clave mediante un embalaje tipo mochila -LRB- Secci\u00f3n 2 -RRB-. Por lo tanto, podr\u00eda resultar sorprendente que una estrategia uniforme simple de dos ofertas sea un 63 % o m\u00e1s efectiva en comparaci\u00f3n con la \u00f3ptima. Nuestra prueba de la relaci\u00f3n de aproximaci\u00f3n 1 -- 1/e se basa en un an\u00e1lisis contradictorio. Definimos un LP revelador de factores -LRB- Secci\u00f3n 4 -RRB- donde las soluciones primarias corresponden a instancias posibles y las soluciones duales corresponden a distribuciones sobre estrategias de oferta. Hemos realizado simulaciones utilizando datos reales de subastas de Google. Los resultados de estas simulaciones, que se destacan al final de la Secci\u00f3n 4, sugieren que estrategias de licitaci\u00f3n uniformes podr\u00edan ser \u00fatiles en la pr\u00e1ctica. 8. COMENTARIOS FINALES Otra generalizaci\u00f3n interesante es considerar ponderaciones de los clics, que es una forma de modelar las conversiones. -LRB- Una conversi\u00f3n corresponde a una acci\u00f3n por parte del usuario que hizo clic en el sitio del anunciante; por ejemplo, una venta o el registro de una cuenta. -RRB- Finalmente, hemos visto este sistema como una caja negra que devuelve clics en funci\u00f3n de la oferta, cuando en realidad es un juego complejo y repetido que involucra a m\u00faltiples anunciantes. En -LSB- 3 -RSB-, se demostr\u00f3 que cuando un conjunto de anunciantes utiliza una estrategia similar a la que sugerimos aqu\u00ed, bajo una subasta de primer precio ligeramente modificada, los precios se acercan a un equilibrio de mercado bien entendido.2 Nuestros principales resultados y descripci\u00f3n t\u00e9cnica Presentamos resultados positivos y negativos para el problema de optimizaci\u00f3n del presupuesto. En particular, mostramos: 9 Casi todas las formulaciones del problema son NP-Duro. En casos ligeramente m\u00e1s generales que la formulaci\u00f3n anterior, donde los clics tienen pesos, el problema es inaproximable mejor que un factor de 1 - 1e, a menos que P = NP. 9 Damos un algoritmo de aproximaci\u00f3n -LRB- 1 -- 1/e -RRB- - para el problema de optimizaci\u00f3n presupuestaria. La estrategia encontrada por el algoritmo es una estrategia uniforme de dos ofertas, lo que significa que aleatoriza entre ofertar alg\u00fan valor b1 en todas las palabras clave y ofertar alg\u00fan otro valor b2 en todas las palabras clave hasta que se agote el presupuesto3. Mostramos que este ratio de aproximaci\u00f3n es ajustado para estrategias uniformes. Tambi\u00e9n proporcionamos un algoritmo de aproximaci\u00f3n -LRB- 1/2 -RRB- que ofrece una estrategia uniforme de oferta \u00fanica, utilizando solo un valor b1. -LRB- Esto es ajustado para estrategias uniformes de oferta \u00fanica. -RRB- Estas estrategias se pueden calcular en un tiempo casi lineal en JQJ + JKJ, el tama\u00f1o de entrada. Las estrategias uniformes pueden parecer ingenuas a primera vista porque las palabras clave var\u00edan significativamente en sus funciones de clic y costo, y puede haber una interacci\u00f3n compleja entre ellas cuando varias palabras clave son relevantes para una consulta. Despu\u00e9s de todo, lo \u00f3ptimo puede configurar ofertas arbitrarias para cada una de las palabras clave. Incluso para el caso simple en el que el gr\u00e1fico es una coincidencia, el algoritmo \u00f3ptimo implica realizar diferentes ofertas para diferentes palabras clave mediante un embalaje tipo mochila -LRB- Secci\u00f3n 2 -RRB-. Por lo tanto, podr\u00eda resultar sorprendente que una estrategia uniforme simple de dos ofertas sea un 63 % o m\u00e1s efectiva en comparaci\u00f3n con la \u00f3ptima. Nuestra prueba de la relaci\u00f3n de aproximaci\u00f3n 1 -- 1/e se basa en un an\u00e1lisis contradictorio. Definimos un LP revelador de factores -LRB- Secci\u00f3n 4 -RRB- donde las soluciones primarias corresponden a instancias posibles y las soluciones duales corresponden a distribuciones sobre estrategias de oferta. Hemos realizado simulaciones utilizando datos reales de subastas de Google. Los resultados de estas simulaciones, que se destacan al final de la Secci\u00f3n 4, sugieren que estrategias de licitaci\u00f3n uniformes podr\u00edan ser \u00fatiles en la pr\u00e1ctica. 8. COMENTARIOS FINALES Otra generalizaci\u00f3n interesante es considerar ponderaciones de los clics, que es una forma de modelar las conversiones. -LRB- Una conversi\u00f3n corresponde a una acci\u00f3n por parte del usuario que hizo clic en el sitio del anunciante; por ejemplo, una venta o el registro de una cuenta. -RRB- Finalmente, hemos visto este sistema como una caja negra que devuelve clics en funci\u00f3n de la oferta, cuando en realidad es un juego complejo y repetido que involucra a m\u00faltiples anunciantes. En -LSB- 3 -RSB-, se demostr\u00f3 que cuando un conjunto de anunciantes utiliza una estrategia similar a la que sugerimos aqu\u00ed, bajo una subasta de primer precio ligeramente modificada, los precios se acercan a un equilibrio de mercado bien entendido.2 Nuestros principales resultados y descripci\u00f3n t\u00e9cnica Presentamos resultados positivos y negativos para el problema de optimizaci\u00f3n del presupuesto. En particular, mostramos: 9 Casi todas las formulaciones del problema son NP-Duro. En casos ligeramente m\u00e1s generales que la formulaci\u00f3n anterior, donde los clics tienen pesos, el problema es inaproximable mejor que un factor de 1 - 1e, a menos que P = NP. 9 Damos un algoritmo de aproximaci\u00f3n -LRB- 1 -- 1/e -RRB- - para el problema de optimizaci\u00f3n presupuestaria. La estrategia encontrada por el algoritmo es una estrategia uniforme de dos ofertas, lo que significa que aleatoriza entre ofertar alg\u00fan valor b1 en todas las palabras clave y ofertar alg\u00fan otro valor b2 en todas las palabras clave hasta que se agote el presupuesto3. Mostramos que este ratio de aproximaci\u00f3n es ajustado para estrategias uniformes. Tambi\u00e9n proporcionamos un algoritmo de aproximaci\u00f3n -LRB- 1/2 -RRB- que ofrece una estrategia uniforme de oferta \u00fanica, utilizando solo un valor b1. -LRB- Esto es ajustado para estrategias uniformes de oferta \u00fanica. -RRB- Estas estrategias se pueden calcular en un tiempo casi lineal en JQJ + JKJ, el tama\u00f1o de entrada. Las estrategias uniformes pueden parecer ingenuas a primera vista porque las palabras clave var\u00edan significativamente en sus funciones de clic y costo, y puede haber una interacci\u00f3n compleja entre ellas cuando varias palabras clave son relevantes para una consulta. Despu\u00e9s de todo, lo \u00f3ptimo puede configurar ofertas arbitrarias para cada una de las palabras clave. Incluso para el caso simple en el que el gr\u00e1fico es una coincidencia, el algoritmo \u00f3ptimo implica realizar diferentes ofertas para diferentes palabras clave mediante un embalaje tipo mochila -LRB- Secci\u00f3n 2 -RRB-. Por lo tanto, podr\u00eda resultar sorprendente que una estrategia uniforme simple de dos ofertas sea un 63 % o m\u00e1s efectiva en comparaci\u00f3n con la \u00f3ptima. Nuestra prueba de la relaci\u00f3n de aproximaci\u00f3n 1 -- 1/e se basa en un an\u00e1lisis contradictorio. Definimos un LP revelador de factores -LRB- Secci\u00f3n 4 -RRB- donde las soluciones primarias corresponden a instancias posibles y las soluciones duales corresponden a distribuciones sobre estrategias de oferta. Hemos realizado simulaciones utilizando datos reales de subastas de Google. Los resultados de estas simulaciones, que se destacan al final de la Secci\u00f3n 4, sugieren que estrategias de licitaci\u00f3n uniformes podr\u00edan ser \u00fatiles en la pr\u00e1ctica. 8. COMENTARIOS FINALES Otra generalizaci\u00f3n interesante es considerar ponderaciones de los clics, que es una forma de modelar las conversiones. -LRB- Una conversi\u00f3n corresponde a una acci\u00f3n por parte del usuario que hizo clic en el sitio del anunciante; por ejemplo, una venta o el registro de una cuenta. -RRB- Finalmente, hemos visto este sistema como una caja negra que devuelve clics en funci\u00f3n de la oferta, cuando en realidad es un juego complejo y repetido que involucra a m\u00faltiples anunciantes. En -LSB- 3 -RSB-, se demostr\u00f3 que cuando un conjunto de anunciantes utiliza una estrategia similar a la que sugerimos aqu\u00ed, bajo una subasta de primer precio ligeramente modificada, los precios se acercan a un equilibrio de mercado bien entendido.En casos ligeramente m\u00e1s generales que la formulaci\u00f3n anterior, donde los clics tienen pesos, el problema es inaproximable mejor que un factor de 1 - 1e, a menos que P = NP. 9 Damos un algoritmo de aproximaci\u00f3n -LRB- 1 -- 1/e -RRB- - para el problema de optimizaci\u00f3n presupuestaria. La estrategia encontrada por el algoritmo es una estrategia uniforme de dos ofertas, lo que significa que aleatoriza entre ofertar alg\u00fan valor b1 en todas las palabras clave y ofertar alg\u00fan otro valor b2 en todas las palabras clave hasta que se agote el presupuesto3. Mostramos que este ratio de aproximaci\u00f3n es ajustado para estrategias uniformes. Tambi\u00e9n proporcionamos un algoritmo de aproximaci\u00f3n -LRB- 1/2 -RRB- que ofrece una estrategia uniforme de oferta \u00fanica, utilizando solo un valor b1. -LRB- Esto es ajustado para estrategias uniformes de oferta \u00fanica. -RRB- Estas estrategias se pueden calcular en un tiempo casi lineal en JQJ + JKJ, el tama\u00f1o de entrada. Las estrategias uniformes pueden parecer ingenuas a primera vista porque las palabras clave var\u00edan significativamente en sus funciones de clic y costo, y puede haber una interacci\u00f3n compleja entre ellas cuando varias palabras clave son relevantes para una consulta. Despu\u00e9s de todo, lo \u00f3ptimo puede configurar ofertas arbitrarias para cada una de las palabras clave. Incluso para el caso simple en el que el gr\u00e1fico es una coincidencia, el algoritmo \u00f3ptimo implica realizar diferentes ofertas para diferentes palabras clave mediante un embalaje tipo mochila -LRB- Secci\u00f3n 2 -RRB-. Por lo tanto, podr\u00eda resultar sorprendente que una estrategia uniforme simple de dos ofertas sea un 63 % o m\u00e1s efectiva en comparaci\u00f3n con la \u00f3ptima. Nuestra prueba de la relaci\u00f3n de aproximaci\u00f3n 1 -- 1/e se basa en un an\u00e1lisis contradictorio. Definimos un LP revelador de factores -LRB- Secci\u00f3n 4 -RRB- donde las soluciones primarias corresponden a instancias posibles y las soluciones duales corresponden a distribuciones sobre estrategias de oferta. Hemos realizado simulaciones utilizando datos reales de subastas de Google. Los resultados de estas simulaciones, que se destacan al final de la Secci\u00f3n 4, sugieren que estrategias de licitaci\u00f3n uniformes podr\u00edan ser \u00fatiles en la pr\u00e1ctica. 8. COMENTARIOS FINALES Otra generalizaci\u00f3n interesante es considerar ponderaciones de los clics, que es una forma de modelar las conversiones. -LRB- Una conversi\u00f3n corresponde a una acci\u00f3n por parte del usuario que hizo clic en el sitio del anunciante; por ejemplo, una venta o el registro de una cuenta. -RRB- Finalmente, hemos visto este sistema como una caja negra que devuelve clics en funci\u00f3n de la oferta, cuando en realidad es un juego complejo y repetido que involucra a m\u00faltiples anunciantes. En -LSB- 3 -RSB-, se demostr\u00f3 que cuando un conjunto de anunciantes utiliza una estrategia similar a la que sugerimos aqu\u00ed, bajo una subasta de primer precio ligeramente modificada, los precios se acercan a un equilibrio de mercado bien entendido.En casos ligeramente m\u00e1s generales que la formulaci\u00f3n anterior, donde los clics tienen pesos, el problema es inaproximable mejor que un factor de 1 - 1e, a menos que P = NP. 9 Damos un algoritmo de aproximaci\u00f3n -LRB- 1 -- 1/e -RRB- - para el problema de optimizaci\u00f3n presupuestaria. La estrategia encontrada por el algoritmo es una estrategia uniforme de dos ofertas, lo que significa que aleatoriza entre ofertar alg\u00fan valor b1 en todas las palabras clave y ofertar alg\u00fan otro valor b2 en todas las palabras clave hasta que se agote el presupuesto3. Mostramos que este ratio de aproximaci\u00f3n es ajustado para estrategias uniformes. Tambi\u00e9n proporcionamos un algoritmo de aproximaci\u00f3n -LRB- 1/2 -RRB- que ofrece una estrategia uniforme de oferta \u00fanica, utilizando solo un valor b1. -LRB- Esto es ajustado para estrategias uniformes de oferta \u00fanica. -RRB- Estas estrategias se pueden calcular en un tiempo casi lineal en JQJ + JKJ, el tama\u00f1o de entrada. Las estrategias uniformes pueden parecer ingenuas a primera vista porque las palabras clave var\u00edan significativamente en sus funciones de clic y costo, y puede haber una interacci\u00f3n compleja entre ellas cuando varias palabras clave son relevantes para una consulta. Despu\u00e9s de todo, lo \u00f3ptimo puede configurar ofertas arbitrarias para cada una de las palabras clave. Incluso para el caso simple en el que el gr\u00e1fico es una coincidencia, el algoritmo \u00f3ptimo implica realizar diferentes ofertas para diferentes palabras clave mediante un embalaje tipo mochila -LRB- Secci\u00f3n 2 -RRB-. Por lo tanto, podr\u00eda resultar sorprendente que una estrategia uniforme simple de dos ofertas sea un 63 % o m\u00e1s efectiva en comparaci\u00f3n con la \u00f3ptima. Nuestra prueba de la relaci\u00f3n de aproximaci\u00f3n 1 -- 1/e se basa en un an\u00e1lisis contradictorio. Definimos un LP revelador de factores -LRB- Secci\u00f3n 4 -RRB- donde las soluciones primarias corresponden a instancias posibles y las soluciones duales corresponden a distribuciones sobre estrategias de oferta. Hemos realizado simulaciones utilizando datos reales de subastas de Google. Los resultados de estas simulaciones, que se destacan al final de la Secci\u00f3n 4, sugieren que estrategias de licitaci\u00f3n uniformes podr\u00edan ser \u00fatiles en la pr\u00e1ctica. 8. COMENTARIOS FINALES Otra generalizaci\u00f3n interesante es considerar ponderaciones de los clics, que es una forma de modelar las conversiones. -LRB- Una conversi\u00f3n corresponde a una acci\u00f3n por parte del usuario que hizo clic en el sitio del anunciante; por ejemplo, una venta o el registro de una cuenta. -RRB- Finalmente, hemos visto este sistema como una caja negra que devuelve clics en funci\u00f3n de la oferta, cuando en realidad es un juego complejo y repetido que involucra a m\u00faltiples anunciantes. En -LSB- 3 -RSB-, se demostr\u00f3 que cuando un conjunto de anunciantes utiliza una estrategia similar a la que sugerimos aqu\u00ed, bajo una subasta de primer precio ligeramente modificada, los precios se acercan a un equilibrio de mercado bien entendido.y ofertar alg\u00fan otro valor b2 en todas las palabras clave hasta que se agote el presupuesto3. Mostramos que este ratio de aproximaci\u00f3n es ajustado para estrategias uniformes. Tambi\u00e9n proporcionamos un algoritmo de aproximaci\u00f3n -LRB- 1/2 -RRB- que ofrece una estrategia uniforme de oferta \u00fanica, utilizando solo un valor b1. -LRB- Esto es ajustado para estrategias uniformes de oferta \u00fanica. -RRB- Estas estrategias se pueden calcular en un tiempo casi lineal en JQJ + JKJ, el tama\u00f1o de entrada. Las estrategias uniformes pueden parecer ingenuas a primera vista porque las palabras clave var\u00edan significativamente en sus funciones de clic y costo, y puede haber una interacci\u00f3n compleja entre ellas cuando varias palabras clave son relevantes para una consulta. Despu\u00e9s de todo, lo \u00f3ptimo puede configurar ofertas arbitrarias para cada una de las palabras clave. Incluso para el caso simple en el que el gr\u00e1fico es una coincidencia, el algoritmo \u00f3ptimo implica realizar diferentes ofertas para diferentes palabras clave a trav\u00e9s de un embalaje similar a una mochila -LRB- Secci\u00f3n 2 -RRB-. Por lo tanto, podr\u00eda resultar sorprendente que una estrategia uniforme simple de dos ofertas sea un 63 % o m\u00e1s efectiva en comparaci\u00f3n con la \u00f3ptima. Nuestra prueba de la relaci\u00f3n de aproximaci\u00f3n 1 -- 1/e se basa en un an\u00e1lisis contradictorio. Definimos un LP revelador de factores -LRB- Secci\u00f3n 4 -RRB- donde las soluciones primarias corresponden a instancias posibles y las soluciones duales corresponden a distribuciones sobre estrategias de oferta. Hemos realizado simulaciones utilizando datos reales de subastas de Google. Los resultados de estas simulaciones, que se destacan al final de la Secci\u00f3n 4, sugieren que estrategias de licitaci\u00f3n uniformes podr\u00edan ser \u00fatiles en la pr\u00e1ctica. 8. COMENTARIOS FINALES Otra generalizaci\u00f3n interesante es considerar ponderaciones de los clics, que es una forma de modelar las conversiones. -LRB- Una conversi\u00f3n corresponde a una acci\u00f3n por parte del usuario que hizo clic en el sitio del anunciante; por ejemplo, una venta o el registro de una cuenta. -RRB- Finalmente, hemos visto este sistema como una caja negra que devuelve clics en funci\u00f3n de la oferta, cuando en realidad es un juego complejo y repetido que involucra a m\u00faltiples anunciantes. En -LSB- 3 -RSB-, se demostr\u00f3 que cuando un conjunto de anunciantes utiliza una estrategia similar a la que sugerimos aqu\u00ed, bajo una subasta de primer precio ligeramente modificada, los precios se acercan a un equilibrio de mercado bien entendido.y ofertar alg\u00fan otro valor b2 en todas las palabras clave hasta que se agote el presupuesto3. Mostramos que este ratio de aproximaci\u00f3n es ajustado para estrategias uniformes. Tambi\u00e9n proporcionamos un algoritmo de aproximaci\u00f3n -LRB- 1/2 -RRB- que ofrece una estrategia uniforme de oferta \u00fanica, utilizando solo un valor b1. -LRB- Esto es ajustado para estrategias uniformes de oferta \u00fanica. -RRB- Estas estrategias se pueden calcular en un tiempo casi lineal en JQJ + JKJ, el tama\u00f1o de entrada. Las estrategias uniformes pueden parecer ingenuas a primera vista porque las palabras clave var\u00edan significativamente en sus funciones de clic y costo, y puede haber una interacci\u00f3n compleja entre ellas cuando varias palabras clave son relevantes para una consulta. Despu\u00e9s de todo, lo \u00f3ptimo puede configurar ofertas arbitrarias para cada una de las palabras clave. Incluso para el caso simple en el que el gr\u00e1fico es una coincidencia, el algoritmo \u00f3ptimo implica realizar diferentes ofertas para diferentes palabras clave mediante un embalaje tipo mochila -LRB- Secci\u00f3n 2 -RRB-. Por lo tanto, podr\u00eda resultar sorprendente que una estrategia uniforme simple de dos ofertas sea un 63 % o m\u00e1s efectiva en comparaci\u00f3n con la \u00f3ptima. Nuestra prueba de la relaci\u00f3n de aproximaci\u00f3n 1 -- 1/e se basa en un an\u00e1lisis contradictorio. Definimos un LP revelador de factores -LRB- Secci\u00f3n 4 -RRB- donde las soluciones primarias corresponden a instancias posibles y las soluciones duales corresponden a distribuciones sobre estrategias de oferta. Hemos realizado simulaciones utilizando datos reales de subastas de Google. Los resultados de estas simulaciones, que se destacan al final de la Secci\u00f3n 4, sugieren que estrategias de licitaci\u00f3n uniformes podr\u00edan ser \u00fatiles en la pr\u00e1ctica. 8. COMENTARIOS FINALES Otra generalizaci\u00f3n interesante es considerar ponderaciones de los clics, que es una forma de modelar las conversiones. -LRB- Una conversi\u00f3n corresponde a una acci\u00f3n por parte del usuario que hizo clic en el sitio del anunciante; por ejemplo, una venta o el registro de una cuenta. -RRB- Finalmente, hemos visto este sistema como una caja negra que devuelve clics en funci\u00f3n de la oferta, cuando en realidad es un juego complejo y repetido que involucra a m\u00faltiples anunciantes. En -LSB- 3 -RSB-, se demostr\u00f3 que cuando un conjunto de anunciantes utiliza una estrategia similar a la que sugerimos aqu\u00ed, bajo una subasta de primer precio ligeramente modificada, los precios se acercan a un equilibrio de mercado bien entendido.el algoritmo \u00f3ptimo implica realizar diferentes ofertas para diferentes palabras clave mediante un embalaje similar a una mochila -LRB- Secci\u00f3n 2 -RRB-. Por lo tanto, podr\u00eda resultar sorprendente que una estrategia uniforme simple de dos ofertas sea un 63 % o m\u00e1s efectiva en comparaci\u00f3n con la \u00f3ptima. Nuestra prueba de la relaci\u00f3n de aproximaci\u00f3n 1 -- 1/e se basa en un an\u00e1lisis contradictorio. Definimos un LP revelador de factores -LRB- Secci\u00f3n 4 -RRB- donde las soluciones primarias corresponden a instancias posibles y las soluciones duales corresponden a distribuciones sobre estrategias de oferta. Hemos realizado simulaciones utilizando datos reales de subastas de Google. Los resultados de estas simulaciones, que se destacan al final de la Secci\u00f3n 4, sugieren que estrategias de licitaci\u00f3n uniformes podr\u00edan ser \u00fatiles en la pr\u00e1ctica. 8. COMENTARIOS FINALES Otra generalizaci\u00f3n interesante es considerar ponderaciones de los clics, que es una forma de modelar las conversiones. -LRB- Una conversi\u00f3n corresponde a una acci\u00f3n por parte del usuario que hizo clic en el sitio del anunciante; por ejemplo, una venta o el registro de una cuenta. -RRB- Finalmente, hemos visto este sistema como una caja negra que devuelve clics en funci\u00f3n de la oferta, cuando en realidad es un juego complejo y repetido que involucra a m\u00faltiples anunciantes. En -LSB- 3 -RSB-, se demostr\u00f3 que cuando un conjunto de anunciantes utiliza una estrategia similar a la que sugerimos aqu\u00ed, bajo una subasta de primer precio ligeramente modificada, los precios se acercan a un equilibrio de mercado bien entendido.el algoritmo \u00f3ptimo implica realizar diferentes ofertas para diferentes palabras clave mediante un embalaje similar a una mochila -LRB- Secci\u00f3n 2 -RRB-. Por lo tanto, podr\u00eda resultar sorprendente que una estrategia uniforme simple de dos ofertas sea un 63 % o m\u00e1s efectiva en comparaci\u00f3n con la \u00f3ptima. Nuestra prueba de la relaci\u00f3n de aproximaci\u00f3n 1 -- 1/e se basa en un an\u00e1lisis contradictorio. Definimos un LP revelador de factores -LRB- Secci\u00f3n 4 -RRB- donde las soluciones primarias corresponden a instancias posibles y las soluciones duales corresponden a distribuciones sobre estrategias de oferta. Hemos realizado simulaciones utilizando datos reales de subastas de Google. Los resultados de estas simulaciones, que se destacan al final de la Secci\u00f3n 4, sugieren que estrategias de licitaci\u00f3n uniformes podr\u00edan ser \u00fatiles en la pr\u00e1ctica. 8. COMENTARIOS FINALES Otra generalizaci\u00f3n interesante es considerar ponderaciones de los clics, que es una forma de modelar las conversiones. -LRB- Una conversi\u00f3n corresponde a una acci\u00f3n por parte del usuario que hizo clic en el sitio del anunciante; por ejemplo, una venta o el registro de una cuenta. -RRB- Finalmente, hemos visto este sistema como una caja negra que devuelve clics en funci\u00f3n de la oferta, cuando en realidad es un juego complejo y repetido que involucra a m\u00faltiples anunciantes. En -LSB- 3 -RSB-, se demostr\u00f3 que cuando un conjunto de anunciantes utiliza una estrategia similar a la que sugerimos aqu\u00ed, bajo una subasta de primer precio ligeramente modificada, los precios se acercan a un equilibrio de mercado bien entendido.", "keyphrases": ["optimaci\u00f3n presupuestaria", "subasta de publicidad basada en b\u00fasqueda", "Internet", "publicidad", "teor\u00eda de juegos", "heurista intrigante", "palabra clave", "estrategia de oferta uniforme", "vickrei clark grove", "lp", "gener segundo precio"]}
{"file_name": "I-18", "text": "Colaboraci\u00f3n entre un enjambre de sat\u00e9lites RESUMEN El art\u00edculo trata sobre la planificaci\u00f3n a bordo de un enjambre de sat\u00e9lites mediante comunicaci\u00f3n y negociaci\u00f3n. Nuestro objetivo es definir comportamientos individuales que resulten en un comportamiento global que cumpla con los requisitos de la misi\u00f3n. Presentaremos la formalizaci\u00f3n del problema, un protocolo de comunicaci\u00f3n, un m\u00e9todo de resoluci\u00f3n basado en reglas de decisi\u00f3n reactiva y primeros resultados. 1. INTRODUCCI\u00d3N Se han desarrollado arquitecturas multiagente para enjambres de sat\u00e9lites -LSB- 36, 38, 42 -RSB- pero se hacen fuertes suposiciones sobre las capacidades de deliberaci\u00f3n y comunicaci\u00f3n para construir un plan colectivo. En un context multiagente, los agentes que construyen un plan colectivo deben poder cambiar sus objetivos, reasignar recursos y reaccionar a los cambios del entorno y a las elecciones de los dem\u00e1s. Sin embargo, este paso necesita altas capacidades de comunicaci\u00f3n y computaci\u00f3n. Para relajar las restricciones de comunicaci\u00f3n se considera una coordinaci\u00f3n basada en normas y convenciones -LSB- 16 -RSB- o estrategias -LSB- 17 -RSB-. Las normas limitan a los agentes en sus decisiones de tal manera que se reducen las posibilidades de conflictos. Las estrategias son reglas de decisi\u00f3n privadas que permiten a un agente beneficiarse del mundo del conocimiento sin comunicaci\u00f3n. Sin embargo, a\u00fan es necesaria la comunicaci\u00f3n para compartir informaci\u00f3n y construir conjeturas y planes colectivos. La comunicaci\u00f3n se puede lograr mediante un enfoque estigm\u00e9rgico -LRB- a trav\u00e9s del entorno -RRB- o mediante intercambio de mensajes y un protocolo. Un protocolo define las interacciones entre agentes y no puede desvincularse de su objetivo, por ejemplo, intercambiar informaci\u00f3n, encontrar un equilibrio, asignar tareas, etc. Los protocolos pueden verse como una abstracci\u00f3n de una interacci\u00f3n -LSB- 9 -RSB-. Sin embargo, un agente no siempre puede comunicarse con otro agente o las posibilidades de comunicaci\u00f3n est\u00e1n restringidas a intervalos de tiempo cortos. A nivel individual, los agentes son deliberativos para crear un plan local, pero a nivel colectivo utilizan reglas de decisi\u00f3n normativa para coordinarse entre s\u00ed. Presentaremos las caracter\u00edsticas de nuestro problema, un protocolo de comunicaci\u00f3n, un m\u00e9todo para la asignaci\u00f3n de solicitudes y, finalmente, estrategias de colaboraci\u00f3n. 7. EXPERIMENTOS Se han implementado simulaciones de enjambre de sat\u00e9lites en JAVA con la plataforma JADE -LSB- 3 -RSB-. El planificador integrado se implementa con programaci\u00f3n lineal utilizando ILOG CPLEX -LSB- 1 -RSB-. El escenario de simulaci\u00f3n implementa 3 sat\u00e9lites en \u00f3rbitas de 6 horas. Se han considerado dos escenarios: el primero con un conjunto de 40 solicitudes con baja exclusi\u00f3n mutua y tasa de conflicto y el segundo con un conjunto de 74 solicitudes con alta exclusi\u00f3n mutua y tasa de conflicto. En el caso de baja exclusi\u00f3n mutua y tasa de conflicto -LRB- Tabla 1 -RRB-, las simulaciones centralizadas y aisladas conducen al mismo n\u00famero de observaciones, con las mismas prioridades promedio. El aislamiento que conduce a un menor coste se debe al elevado n\u00famero de despidos:muchos agentes realizan la misma solicitud a diferentes costos. La simulaci\u00f3n informada reduce el n\u00famero de despidos pero aumenta ligeramente el coste medio por el mismo motivo. Podemos notar que el uso de 5. Por ejemplo, el agente experto de rango 1 se retira debido a la estrategia altruista y el costo aumenta en el peor de los casos, luego el agente experto de rango 2 se retira debido a la estrategia altruista y el costo. aumenta en e en el peor de los casos. Por tanto, el coste ha aumentado 2e en el peor de los casos. 292 La Sexta Internacional. Conf. Conjunta. Tabla 1: Escenario 1: resultados de la simulaci\u00f3n de 40 solicitudes Tabla 2: Escenario 2: resultados de la simulaci\u00f3n de 74 solicitudes Las estrategias de colaboraci\u00f3n permiten reducir mucho m\u00e1s el n\u00famero de redundancias, pero el n\u00famero de observaciones disminuye debido a la restricci\u00f3n creada por los compromisos. Adem\u00e1s, el coste medio tambi\u00e9n aumenta. Sin embargo, cada redundancia evitada corresponde a recursos ahorrados para realizar las solicitudes generadas a bordo durante la simulaci\u00f3n. En el caso de una alta exclusi\u00f3n mutua y tasa de conflicto -LRB- Tabla 2 -RRB-, existen diferencias notables entre las simulaciones centralizadas y aisladas. Podemos notar que todas las simulaciones informadas -LRB- con o sin estrategias -RRB- permiten realizar m\u00e1s observaciones que los agentes aislados con menos redundancias. Asimismo, podemos notar que todas las pol\u00edticas reducen el costo promedio al contrario del primer escenario. La pol\u00edtica dr\u00e1stica es interesante porque no s\u00f3lo permite realizar m\u00e1s observaciones que los agentes aislados sino que permite reducir considerablemente el coste medio con el menor n\u00famero de redundancias. En cuanto al n\u00famero de mensajes intercambiados, durante las simulaciones se producen 12 encuentros entre 2 agentes. En el peor de los casos, en cada reuni\u00f3n cada agente env\u00eda N datos sobre las solicitudes m\u00e1s 3N datos sobre las intenciones de los agentes m\u00e1s 1 mensaje de fin de comunicaci\u00f3n, donde N es el n\u00famero total de solicitudes. En consecuencia, se intercambian 3864 mensajes en el peor de los casos para las simulaciones de 40 solicitudes y 7128 mensajes para las simulaciones de 74 solicitudes. Estas cifras son mucho mayores que la cantidad de mensajes que realmente se intercambian. Podemos observar que las simulaciones informadas, que comunican s\u00f3lo solicitudes, permiten una reducci\u00f3n mayor. En el caso general, el uso de comunicaci\u00f3n y estrategias permite reducir redundancias y ahorrar recursos pero aumenta el coste medio: si se realiza una petici\u00f3n, los agentes que la conocen no la planifican aunque su coste pueda reducirse posteriormente. No es el caso de los agentes aislados. El uso de estrategias en problemas poco restringidos, como el escenario 1, limita demasiado a los agentes y provoca un aumento de costos adicional. Las estrategias son m\u00e1s \u00fatiles en problemas altamente restringidos como el escenario 2. Aunque los agentes se limitan al n\u00famero de observaciones, el costo promedio se reduce ampliamente. 8.CONCLUSI\u00d3N Y TRABAJO FUTURO Un enjambre de sat\u00e9lites de observaci\u00f3n es un sistema cooperativo multiagente con fuertes limitaciones en t\u00e9rminos de capacidades de comunicaci\u00f3n y computaci\u00f3n. Para aumentar el resultado de la misi\u00f3n global, proponemos un enfoque h\u00edbrido: deliberativo para la planificaci\u00f3n individual y reactivo para la colaboraci\u00f3n. Los agentes razonan tanto sobre las solicitudes de realizaci\u00f3n como sobre las intenciones de los dem\u00e1s agentes -LRB- candidaturas -RRB-. Un protocolo de comunicaci\u00f3n epid\u00e9mica aprovecha todas las oportunidades de comunicaci\u00f3n para actualizar esta informaci\u00f3n. Reglas de decisi\u00f3n reactiva -LRB-, estrategias -RRB- se proponen para resolver conflictos que puedan surgir entre agentes. Mediante el ajuste de las estrategias -LRB- \u03b1, e y \u03bb -RRB- y su entrelazado pl\u00e1stico dentro del protocolo, es posible coordinar agentes sin comunicaci\u00f3n adicional: el n\u00famero de mensajes intercambiados sigue siendo casi el mismo entre simulaciones informadas y simulaciones que implementan estrategias. Se han realizado algunas simulaciones para validar experimentalmente estos protocolos y los primeros resultados son prometedores pero plantean muchas preguntas. \u00bfCu\u00e1l es el equilibrio entre la tasa de restricci\u00f3n del problema y la necesidad de estrategias? \u00bfEn qu\u00e9 medida el ajuste de las estrategias afecta el n\u00famero de despidos y el coste medio? Los trabajos futuros se centrar\u00e1n en nuevas estrategias para resolver nuevos conflictos, especialmente aquellos que surgen al relajar el supuesto de independencia entre las solicitudes. Un segundo punto es tener en cuenta la complejidad del problema de planificaci\u00f3n inicial. De hecho, el enfoque de planificaci\u00f3n elegido da como resultado una explosi\u00f3n combinatoria con grandes conjuntos de solicitudes: se debe considerar un enfoque en cualquier momento o completamente reactivo para problemas m\u00e1s complejos.especialmente los que surgen al relajar el supuesto de independencia entre las solicitudes. Un segundo punto es tener en cuenta la complejidad del problema de planificaci\u00f3n inicial. De hecho, el enfoque de planificaci\u00f3n elegido da como resultado una explosi\u00f3n combinatoria con grandes conjuntos de solicitudes: se debe considerar un enfoque en cualquier momento o totalmente reactivo para problemas m\u00e1s complejos.especialmente los que surgen al relajar el supuesto de independencia entre las solicitudes. Un segundo punto es tener en cuenta la complejidad del problema de planificaci\u00f3n inicial. De hecho, el enfoque de planificaci\u00f3n elegido da como resultado una explosi\u00f3n combinatoria con grandes conjuntos de solicitudes: se debe considerar un enfoque en cualquier momento o totalmente reactivo para problemas m\u00e1s complejos.", "keyphrases": ["plano a bordo", "enjambre de sat\u00e9lites", "com\u00fan y negociable", "regla reactiva decis", "informar aplicaci\u00f3n del sistema", "sistema multiag", "asignaci\u00f3n de tareas y recursos", "arquitectura de objetos", "equipo", "aderezo", "hormiga prospectiva"]}
{"file_name": "H-16", "text": "El impacto del almacenamiento en cach\u00e9 en los motores de b\u00fasqueda RESUMEN En este art\u00edculo estudiamos las ventajas y desventajas del dise\u00f1o de sistemas de almacenamiento en cach\u00e9 eficientes para los motores de b\u00fasqueda web. Exploramos el impacto de diferentes enfoques, como el almacenamiento en cach\u00e9 est\u00e1tico frente al din\u00e1mico, y el almacenamiento en cach\u00e9 de los resultados de las consultas frente al almacenamiento en cach\u00e9 de las listas de publicaciones. Utilizando un registro de consultas que abarca todo un a\u00f1o, exploramos las limitaciones del almacenamiento en cach\u00e9 y demostramos que el almacenamiento en cach\u00e9 de las listas de publicaciones puede lograr tasas de aciertos m\u00e1s altas que el almacenamiento en cach\u00e9 de las respuestas a las consultas. Proponemos un nuevo algoritmo para el almacenamiento en cach\u00e9 est\u00e1tico de listas de publicaciones, que supera a los m\u00e9todos anteriores. Tambi\u00e9n estudiamos el problema de encontrar la forma \u00f3ptima de dividir el cach\u00e9 est\u00e1tico entre respuestas y listas de publicaciones. Finalmente, medimos c\u00f3mo los cambios en el registro de consultas afectan la efectividad del almacenamiento en cach\u00e9 est\u00e1tico, dada nuestra observaci\u00f3n de que la distribuci\u00f3n de las consultas cambia lentamente con el tiempo. Nuestros resultados y observaciones son aplicables a diferentes niveles de la jerarqu\u00eda de acceso a datos, por ejemplo, para una capa de memoria/disco o una capa de intermediario/servidor remoto. 1. INTRODUCCI\u00d3N Diariamente se env\u00edan millones de consultas a los motores de b\u00fasqueda web y los usuarios tienen grandes expectativas sobre la calidad y velocidad de las respuestas. En tal entorno, para lograr un tiempo de respuesta r\u00e1pido y aumentar el rendimiento de la consulta, el uso de un cach\u00e9 es crucial. El almacenamiento en cach\u00e9 se puede aplicar en diferentes niveles con latencias de respuesta o requisitos de procesamiento crecientes. La decisi\u00f3n de qu\u00e9 almacenar en cach\u00e9 es fuera de l\u00ednea -LRB- est\u00e1tica -RRB- o en l\u00ednea -LRB- din\u00e1mica -RRB-. Un cach\u00e9 est\u00e1tico se basa en informaci\u00f3n hist\u00f3rica y se actualiza peri\u00f3dicamente. Un cach\u00e9 din\u00e1mico reemplaza las entradas seg\u00fan la secuencia de solicitudes. Cuando llega una nueva solicitud, el sistema de cach\u00e9 decide si expulsa alguna entrada del cach\u00e9 en caso de que se pierda el cach\u00e9. Estas decisiones en l\u00ednea se basan en una pol\u00edtica de cach\u00e9, y en el pasado se han estudiado varias pol\u00edticas diferentes. Para un motor de b\u00fasqueda, hay dos formas posibles de utilizar una memoria cach\u00e9: Almacenamiento en cach\u00e9 de respuestas: cuando el motor devuelve respuestas a una consulta particular, puede decidir almacenar estas respuestas para resolver consultas futuras. T\u00e9rminos de almacenamiento en cach\u00e9: a medida que el motor eval\u00faa una consulta en particular, puede decidir almacenar en la memoria las listas de publicaci\u00f3n de los t\u00e9rminos de consulta involucrados. A menudo, todo el conjunto de listas de publicaciones no cabe en la memoria y, en consecuencia, el motor tiene que seleccionar un peque\u00f1o conjunto para guardarlo en la memoria y acelerar el procesamiento de consultas. Devolver una respuesta a una consulta que ya existe en el cach\u00e9 es m\u00e1s eficiente que calcular la respuesta utilizando listas de publicaciones almacenadas en cach\u00e9. Por otro lado, las consultas no vistas anteriormente ocurren con m\u00e1s frecuencia que los t\u00e9rminos no vistos anteriormente, lo que implica una mayor tasa de errores en las respuestas almacenadas en cach\u00e9. El almacenamiento en cach\u00e9 de listas de publicaciones presenta desaf\u00edos adicionales. Como las listas de publicaci\u00f3n tienen un tama\u00f1o variable, almacenarlas en cach\u00e9 din\u00e1micamente no es muy eficiente, debido a la complejidad en t\u00e9rminos de eficiencia y espacio, y a la distribuci\u00f3n sesgada del flujo de consultas, como se muestra m\u00e1s adelante. El almacenamiento en cach\u00e9 est\u00e1tico de listas de publicaciones plantea a\u00fan m\u00e1s desaf\u00edos:Al decidir qu\u00e9 t\u00e9rminos almacenar en cach\u00e9, uno se enfrenta al equilibrio entre t\u00e9rminos consultados con frecuencia y t\u00e9rminos con listas de publicaci\u00f3n peque\u00f1as que ahorran espacio. Finalmente, antes de decidir adoptar una pol\u00edtica de almacenamiento en cach\u00e9 est\u00e1tica, se debe analizar el flujo de consultas para verificar que sus caracter\u00edsticas no cambien r\u00e1pidamente con el tiempo. Figura 1: Un nivel de almacenamiento en cach\u00e9 en una arquitectura de b\u00fasqueda distribuida. En este art\u00edculo exploramos las compensaciones en el dise\u00f1o de cada nivel de cach\u00e9, mostrando que el problema es el mismo y solo cambian unos pocos par\u00e1metros. En general, asumimos que cada nivel de almacenamiento en cach\u00e9 en una arquitectura de b\u00fasqueda distribuida es similar al que se muestra en la Figura 1. Usamos un registro de consultas que abarca un a\u00f1o completo para explorar las limitaciones del almacenamiento en cach\u00e9 din\u00e1mico de las respuestas de las consultas o de la publicaci\u00f3n de listas de t\u00e9rminos de consulta. M\u00e1s concretamente, nuestras principales conclusiones son las siguientes: \u2022 El almacenamiento en cach\u00e9 de las respuestas a las consultas da como resultado \u00edndices de aciertos m\u00e1s bajos en comparaci\u00f3n con el almacenamiento en cach\u00e9 de las listas de publicaciones para los t\u00e9rminos de la consulta, pero es m\u00e1s r\u00e1pido porque no hay necesidad de evaluar la consulta. Proporcionamos un marco para el an\u00e1lisis de la compensaci\u00f3n entre el almacenamiento en cach\u00e9 est\u00e1tico de respuestas a consultas y listas de publicaci\u00f3n; \u2022 El almacenamiento en cach\u00e9 est\u00e1tico de t\u00e9rminos puede ser m\u00e1s eficaz que el almacenamiento en cach\u00e9 din\u00e1mico con, por ejemplo, LRU. Proporcionamos algoritmos basados \u200b\u200ben el problema KNAPSACK para seleccionar las listas de publicaciones para colocar en un cach\u00e9 est\u00e1tico, y mostramos mejoras con respecto al trabajo anterior, logrando una tasa de aciertos superior al 90 %; \u2022 Los cambios en la distribuci\u00f3n de consultas a lo largo del tiempo tienen poco impacto en el almacenamiento en cach\u00e9 est\u00e1tico. Las secciones 2 y 3 resumen el trabajo relacionado y caracterizan los conjuntos de datos que utilizamos. La secci\u00f3n 4 analiza las limitaciones del almacenamiento en cach\u00e9 din\u00e1mico. Las secciones 5 y 6 presentan algoritmos para almacenar en cach\u00e9 listas de publicaciones y un marco te\u00f3rico para el an\u00e1lisis del almacenamiento en cach\u00e9 est\u00e1tico, respectivamente. La Secci\u00f3n 7 analiza el impacto de los cambios en la distribuci\u00f3n de consultas en el almacenamiento en cach\u00e9 est\u00e1tico y la Secci\u00f3n 8 proporciona comentarios finales. 2. TRABAJO RELACIONADO Existe una gran cantidad de trabajo dedicado a la optimizaci\u00f3n de consultas. Ejemplos m\u00e1s recientes demuestran que los k documentos principales para una consulta se pueden devolver sin la necesidad de evaluar el conjunto completo de listas de publicaci\u00f3n -LSB- 1, 4, 15 -RSB-. Aunque estos enfoques buscan mejorar la eficiencia del procesamiento de consultas, se diferencian de nuestro trabajo actual en que no consideran el almacenamiento en cach\u00e9. Markatos -LSB- 10 -RSB- muestra la existencia de localidad temporal en las consultas y compara el rendimiento de diferentes pol\u00edticas de almacenamiento en cach\u00e9. Fagni et al. Siga el trabajo de Markatos al mostrar que la combinaci\u00f3n de pol\u00edticas de almacenamiento en cach\u00e9 est\u00e1ticas y din\u00e1micas junto con una pol\u00edtica de captaci\u00f3n previa adaptativa logra una alta tasa de aciertos -LSB- 7 -RSB-. A diferencia de nuestro trabajo, consideran el almacenamiento en cach\u00e9 y la captaci\u00f3n previa de p\u00e1ginas de resultados. Saraiva et al. proponer una nueva arquitectura para motores de b\u00fasqueda web utilizando un sistema de almacenamiento en cach\u00e9 din\u00e1mico de dos niveles -LSB- 13 -RSB-. Su objetivo para dichos sistemas ha sido mejorar el tiempo de respuesta de los motores jer\u00e1rquicos. En su arquitectura, ambos niveles utilizan una pol\u00edtica de desalojo LRU.Encuentran que la cach\u00e9 de segundo nivel puede reducir eficazmente el tr\u00e1fico del disco, aumentando as\u00ed el rendimiento general. Long y Suel proponen un sistema de cach\u00e9 estructurado seg\u00fan tres niveles diferentes -LSB- 9 -RSB-. El nivel intermedio contiene pares de t\u00e9rminos que aparecen con frecuencia y almacena las intersecciones de las listas invertidas correspondientes. Estos dos \u00faltimos art\u00edculos est\u00e1n relacionados con el nuestro en que explotan diferentes estrategias de almacenamiento en cach\u00e9 en diferentes niveles de la jerarqu\u00eda de la memoria. Finalmente, nuestro algoritmo de almacenamiento en cach\u00e9 est\u00e1tico para publicar listas en la Secci\u00f3n 5 utiliza la relaci\u00f3n frecuencia/tama\u00f1o para evaluar la bondad de un elemento para almacenar en cach\u00e9. Se han utilizado ideas similares en el context del almacenamiento en cach\u00e9 de archivos -LSB- 17 -RSB-, el almacenamiento en cach\u00e9 web -LSB- 5 -RSB- e incluso el almacenamiento en cach\u00e9 de listas de publicaciones -LSB- 9 -RSB-, pero en todos los casos de forma din\u00e1mica. configuraci\u00f3n. Hasta donde sabemos, somos los primeros en utilizar este enfoque para el almacenamiento en cach\u00e9 est\u00e1tico de listas de publicaciones. 8. CONCLUSIONES El almacenamiento en cach\u00e9 es una t\u00e9cnica eficaz en los motores de b\u00fasqueda para mejorar el tiempo de respuesta, reducir la carga en los procesadores de consultas y mejorar la utilizaci\u00f3n del ancho de banda de la red. Presentamos resultados sobre el almacenamiento en cach\u00e9 tanto din\u00e1mico como est\u00e1tico. El almacenamiento en cach\u00e9 din\u00e1mico de consultas tiene una efectividad limitada debido a la gran cantidad de errores obligatorios causados \u200b\u200bpor la cantidad de consultas \u00fanicas o poco frecuentes. Nuestros resultados muestran que en nuestro registro del Reino Unido, la tasa m\u00ednima de fallos es del 50 % utilizando una estrategia de conjunto de trabajo. El almacenamiento en cach\u00e9 de t\u00e9rminos es m\u00e1s eficaz con respecto a la tasa de errores, alcanzando valores tan bajos como el 12 %. Tambi\u00e9n proponemos un nuevo algoritmo para el almacenamiento en cach\u00e9 est\u00e1tico de listas de publicaciones que supera a los algoritmos de almacenamiento en cach\u00e9 est\u00e1tico anteriores, as\u00ed como a los algoritmos din\u00e1micos como LRU y LFU, obteniendo valores de tasa de aciertos que son m\u00e1s de un 10 % m\u00e1s altos en comparaci\u00f3n con estas estrategias. Presentamos un marco para el an\u00e1lisis de la compensaci\u00f3n entre el almacenamiento en cach\u00e9 de los resultados de las consultas y el almacenamiento en cach\u00e9 de las listas de publicaciones, y simulamos diferentes tipos de arquitecturas. Nuestros resultados muestran que para entornos centralizados y LAN, existe una asignaci\u00f3n \u00f3ptima de los resultados de las consultas de almacenamiento en cach\u00e9 y del almacenamiento en cach\u00e9 de las listas de publicaciones, mientras que para escenarios WAN en los que prevalece el tiempo de la red es m\u00e1s importante almacenar en cach\u00e9 los resultados de las consultas. Figura 14: Impacto de los cambios de distribuci\u00f3n en el almacenamiento en cach\u00e9 est\u00e1tico de las listas de publicaciones.e incluso almacenamiento en cach\u00e9 de listas de publicaciones -LSB- 9 -RSB-, pero en todos los casos en un entorno din\u00e1mico. Hasta donde sabemos, somos los primeros en utilizar este enfoque para el almacenamiento en cach\u00e9 est\u00e1tico de listas de publicaciones. 8. CONCLUSIONES El almacenamiento en cach\u00e9 es una t\u00e9cnica eficaz en los motores de b\u00fasqueda para mejorar el tiempo de respuesta, reducir la carga en los procesadores de consultas y mejorar la utilizaci\u00f3n del ancho de banda de la red. Presentamos resultados sobre el almacenamiento en cach\u00e9 tanto din\u00e1mico como est\u00e1tico. El almacenamiento en cach\u00e9 din\u00e1mico de consultas tiene una efectividad limitada debido a la gran cantidad de errores obligatorios causados \u200b\u200bpor la cantidad de consultas \u00fanicas o poco frecuentes. Nuestros resultados muestran que en nuestro registro del Reino Unido, la tasa m\u00ednima de fallos es del 50 % utilizando una estrategia de conjunto de trabajo. El almacenamiento en cach\u00e9 de t\u00e9rminos es m\u00e1s eficaz con respecto a la tasa de errores, alcanzando valores tan bajos como el 12 %. Tambi\u00e9n proponemos un nuevo algoritmo para el almacenamiento en cach\u00e9 est\u00e1tico de listas de publicaciones que supera a los algoritmos de almacenamiento en cach\u00e9 est\u00e1tico anteriores, as\u00ed como a los algoritmos din\u00e1micos como LRU y LFU, obteniendo valores de tasa de aciertos que son m\u00e1s de un 10 % m\u00e1s altos en comparaci\u00f3n con estas estrategias. Presentamos un marco para el an\u00e1lisis de la compensaci\u00f3n entre el almacenamiento en cach\u00e9 de los resultados de las consultas y el almacenamiento en cach\u00e9 de las listas de publicaciones, y simulamos diferentes tipos de arquitecturas. Nuestros resultados muestran que para entornos centralizados y LAN, existe una asignaci\u00f3n \u00f3ptima de los resultados de las consultas de almacenamiento en cach\u00e9 y del almacenamiento en cach\u00e9 de las listas de publicaciones, mientras que para escenarios WAN en los que prevalece el tiempo de la red es m\u00e1s importante almacenar en cach\u00e9 los resultados de las consultas. Figura 14: Impacto de los cambios de distribuci\u00f3n en el almacenamiento en cach\u00e9 est\u00e1tico de las listas de publicaciones.e incluso almacenamiento en cach\u00e9 de listas de publicaciones -LSB- 9 -RSB-, pero en todos los casos en un entorno din\u00e1mico. Hasta donde sabemos, somos los primeros en utilizar este enfoque para el almacenamiento en cach\u00e9 est\u00e1tico de listas de publicaciones. 8. CONCLUSIONES El almacenamiento en cach\u00e9 es una t\u00e9cnica eficaz en los motores de b\u00fasqueda para mejorar el tiempo de respuesta, reducir la carga en los procesadores de consultas y mejorar la utilizaci\u00f3n del ancho de banda de la red. Presentamos resultados sobre el almacenamiento en cach\u00e9 tanto din\u00e1mico como est\u00e1tico. El almacenamiento en cach\u00e9 din\u00e1mico de consultas tiene una efectividad limitada debido a la gran cantidad de errores obligatorios causados \u200b\u200bpor la cantidad de consultas \u00fanicas o poco frecuentes. Nuestros resultados muestran que en nuestro registro del Reino Unido, la tasa m\u00ednima de fallos es del 50 % utilizando una estrategia de conjunto de trabajo. El almacenamiento en cach\u00e9 de t\u00e9rminos es m\u00e1s eficaz con respecto a la tasa de errores, alcanzando valores tan bajos como el 12 %. Tambi\u00e9n proponemos un nuevo algoritmo para el almacenamiento en cach\u00e9 est\u00e1tico de listas de publicaciones que supera a los algoritmos de almacenamiento en cach\u00e9 est\u00e1tico anteriores, as\u00ed como a los algoritmos din\u00e1micos como LRU y LFU, obteniendo valores de tasa de aciertos que son m\u00e1s de un 10 % m\u00e1s altos en comparaci\u00f3n con estas estrategias. Presentamos un marco para el an\u00e1lisis de la compensaci\u00f3n entre el almacenamiento en cach\u00e9 de los resultados de las consultas y el almacenamiento en cach\u00e9 de las listas de publicaciones, y simulamos diferentes tipos de arquitecturas. Nuestros resultados muestran que para entornos centralizados y LAN, existe una asignaci\u00f3n \u00f3ptima de los resultados de las consultas de almacenamiento en cach\u00e9 y del almacenamiento en cach\u00e9 de las listas de publicaciones, mientras que para escenarios WAN en los que prevalece el tiempo de la red es m\u00e1s importante almacenar en cach\u00e9 los resultados de las consultas. Figura 14: Impacto de los cambios de distribuci\u00f3n en el almacenamiento en cach\u00e9 est\u00e1tico de las listas de publicaciones.", "keyphrases": ["sistema de cach\u00e9 eficiente", "motor de b\u00fasqueda web", "cach\u00e9 est\u00e1tico", "cach\u00e9 din\u00e1mico", "resultado de la consulta de cach\u00e9", "lista de publicaciones en cach\u00e9", "cach\u00e9 est\u00e1tico", "lista de respuestas y publicaciones", "registro de consultas", "efecto del cach\u00e9 est\u00e1tico", "distribuci\u00f3n de la consulta", "jerarqu\u00eda de acceso a datos", "capa de disco", "capa de servidor remoto"]}
{"file_name": "J-32", "text": "Equilibrios de Nash en juegos gr\u00e1ficos sobre \u00e1rboles revisitados * Los juegos gr\u00e1ficos se han propuesto como un modelo de teor\u00eda de juegos de redes distribuidas a gran escala de agentes no cooperativos. Cuando el n\u00famero de jugadores es grande y el gr\u00e1fico subyacente tiene un grado bajo, proporcionan una forma concisa de representar los pagos de los jugadores. Recientemente se ha demostrado que el problema de encontrar equilibrios de Nash en un juego gr\u00e1fico general de grado 3 con dos acciones por jugador es completo para la clase de complejidad PPAD, lo que indica que es poco probable que exista alg\u00fan algoritmo de tiempo polinomial para este problema. En este art\u00edculo, estudiamos la complejidad de juegos gr\u00e1ficos con dos acciones por jugador en \u00e1rboles de grados acotados. Esta configuraci\u00f3n fue considerada por primera vez por Kearns, Littman y Singh, quienes propusieron un algoritmo basado en programaci\u00f3n din\u00e1mica que calcula todos los equilibrios de Nash de dichos juegos. El tiempo de ejecuci\u00f3n de su algoritmo es exponencial, aunque se pueden calcular equilibrios aproximados de manera eficiente. Posteriormente, Littman, Kearns y Singh propusieron una modificaci\u00f3n de este algoritmo que puede encontrar un \u00fanico equilibrio de Nash en tiempo polinomial. Mostramos que este algoritmo modificado es incorrecto: el resultado no siempre es un equilibrio de Nash. Luego proponemos un nuevo algoritmo que se basa en las ideas de Kearns et al. y calcula todos los equilibrios de Nash en tiempo cuadr\u00e1tico si el gr\u00e1fico de entrada es una trayectoria, y en tiempo polinomial si es un gr\u00e1fico arbitrario de grado m\u00e1ximo 2. Adem\u00e1s, nuestro algoritmo se puede utilizar para calcular equilibrios de Nash de juegos gr\u00e1ficos en \u00e1rboles arbitrarios, pero el tiempo de ejecuci\u00f3n puede ser exponencial, incluso cuando el \u00e1rbol tiene un grado acotado. Mostramos que esto es inevitable: cualquier algoritmo de este tipo tomar\u00e1 un tiempo exponencial, incluso en \u00e1rboles de grados acotados con ancho de ruta 2. Es una pregunta abierta si nuestro algoritmo se ejecuta en tiempo polin\u00f3mico en gr\u00e1ficos con ancho de ruta 1, pero demostramos que encontrar un equilibrio de Nash para un juego gr\u00e1fico de 2 acciones en el que el gr\u00e1fico subyacente tiene un grado m\u00e1ximo de 3 y el ancho de ruta constante es PPAD-completo -LRB-, por lo que es poco probable que sea manejable -RRB-. * Esta investigaci\u00f3n cuenta con el apoyo de las subvenciones de investigaci\u00f3n EPSRC `` Algor\u00edtmica de juegos compartidos en red '' y `` Comportamiento discontinuo en la complejidad de algoritmos aleatorios ''. 1. INTRODUCCI\u00d3N Los juegos gr\u00e1ficos se introdujeron en los art\u00edculos de Kearns et al. -LSB-8-RSB- y Littman et al. -LSB- 9 -RSB- como una representaci\u00f3n sucinta de juegos con un gran n\u00famero de jugadores. La representaci\u00f3n en forma normal cl\u00e1sica -LRB- o matricial -RRB- tiene un tama\u00f1o exponencial en el n\u00famero de jugadores, lo que la hace inadecuada para juegos distribuidos a gran escala. Un juego gr\u00e1fico asocia a cada jugador con un v\u00e9rtice de un gr\u00e1fico subyacente G, y el pago para ese jugador es funci\u00f3n de las acciones elegidas por \u00e9l mismo y sus vecinos en G; si G tiene un grado bajo, esta es una forma concisa de representar un juego con muchos jugadores. Los art\u00edculos -LSB- 8,9 -RSB- dan un algoritmo de programaci\u00f3n din\u00e1mica para encontrar equilibrios de Nash en juegos gr\u00e1ficos donde hay dos acciones por jugador y G es un \u00e1rbol. El primero de estos art\u00edculos describe un algoritmo gen\u00e9rico para este problema que puede especializarse de dos maneras: como un algoritmo que calcula aproximaciones a todos los equilibrios de Nash en tiempo polin\u00f3mico en el tama\u00f1o de entrada y la calidad de la aproximaci\u00f3n, o como un algoritmo de tiempo exponencial que permite el c\u00e1lculo exacto de todos los equilibrios de Nash en G. En -LSB- 9 -RSB-, los autores proponen una modificaci\u00f3n al \u00faltimo algoritmo que apunta a encontrar un \u00fanico equilibrio de Nash en tiempo polinomial. Esto no funciona del todo, como mostramos en la Secci\u00f3n 3, aunque introduce una idea \u00fatil. 1.1 Antecedentes El algoritmo gen\u00e9rico de -LSB- 8 -RSB- consta de dos fases a las que nos referiremos como paso ascendente y paso descendente; 1 el primero comienza en las hojas del \u00e1rbol y termina en la ra\u00edz, mientras que el segundo comienza en la ra\u00edz y termina en las hojas. existe un equilibrio de Nash en el juego gr\u00e1fico aguas abajo de V -LRB- inclusive -RRB- dado que W juega w -LRB- para una definici\u00f3n m\u00e1s t\u00e9cnica, se remite al lector a la Secci\u00f3n 2 -RRB-. El algoritmo gen\u00e9rico no aborda el problema de representar la mejor pol\u00edtica de respuesta; de hecho, la diferencia m\u00e1s importante entre las dos instancias del algoritmo gen\u00e9rico descrito en -LSB-8-RSB- est\u00e1 en su enfoque de este tema. El c\u00e1lculo se realiza de forma inductiva: la mejor pol\u00edtica de respuesta para V se calcula en funci\u00f3n de las mejores pol\u00edticas de respuesta de los hijos de V U1,..., Uk. Al final del paso ascendente, todos los hijos de la ra\u00edz han calculado sus mejores pol\u00edticas de respuesta. Al comienzo del paso r\u00edo abajo, la ra\u00edz selecciona su estrategia e informa a sus hijos sobre su elecci\u00f3n. Tambi\u00e9n selecciona una estrategia para cada ni\u00f1o. Una condici\u00f3n necesaria y suficiente para que el algoritmo funcione es que la estrategia de la ra\u00edz sea la mejor respuesta a las estrategias de sus hijos y, para cada hijo, la estrategia elegida sea una de las mejores respuestas potenciales precalculadas a la estrategia elegida. de la ra\u00edz. Luego, el equilibrio se propaga hacia abajo, y cada v\u00e9rtice selecciona las acciones de sus hijos. La acci\u00f3n del ni\u00f1o se elige como cualquier estrategia entre las mejores respuestas potenciales precalculadas y la estrategia elegida por el padre. Para limitar el tiempo de ejecuci\u00f3n de este algoritmo, el art\u00edculo -LSB-8-RSB- muestra que cualquier pol\u00edtica de mejor respuesta se puede representar como una uni\u00f3n de un n\u00famero exponencial de rect\u00e1ngulos; El algoritmo de aproximaci\u00f3n de tiempo polinomial se obtiene combinando esta representaci\u00f3n con una cuadr\u00edcula de tama\u00f1o polin\u00f3mico. 1.2 Nuestros Resultados Una de las principales contribuciones de nuestro art\u00edculo es mostrar que el algoritmo propuesto por -LSB-9-RSB- es incorrecto. En la Secci\u00f3n 3 describimos un ejemplo simple para el cual el algoritmo de -LSB- 9 -RSB- genera un vector de estrategias que no constituye un equilibrio de Nash del juego subyacente. En las secciones 4,5 y 6 mostramos c\u00f3mo arreglar el algoritmo de -LSB- 9 -RSB- para que siempre produzca una salida correcta. La secci\u00f3n 4 considera el caso en el que el gr\u00e1fico subyacente es un camino de longitud n. Para este caso, mostramos que el n\u00famero de rect\u00e1ngulos en cada una de las pol\u00edticas de mejor respuesta es O -LRB- n2 -RRB-. Esto nos da un algoritmo O -LRB- n3 -RRB- para encontrar un equilibrio de Nash y para calcular una representaci\u00f3n de todos los equilibrios de Nash. -LRB- Este algoritmo es un caso especial del algoritmo gen\u00e9rico de -LSB- 8 -RSB-. Mostramos que se ejecuta en tiempo polin\u00f3mico cuando el gr\u00e1fico subyacente es una ruta. -RRB- Podemos mejorar el tiempo de ejecuci\u00f3n del algoritmo gen\u00e9rico utilizando las ideas de -LSB- 9 -RSB-. En particular, damos un algoritmo O -LRB- n2 -RRB- para encontrar un equilibrio de Nash de un juego gr\u00e1fico en una trayectoria de longitud n. En lugar de almacenar pol\u00edticas de mejor respuesta, este algoritmo almacena subconjuntos adecuadamente definidos, que, siguiendo -LSB- 9 -RSB-, llamamos pol\u00edticas de punto de interrupci\u00f3n -LRB- modificando la definici\u00f3n seg\u00fan sea necesario -RRB-. Obtenemos el siguiente teorema TEOREMA 1. Existe un algoritmo O -LRB- n2 -RRB- que encuentra un equilibrio de Nash de un juego gr\u00e1fico con dos acciones por jugador en un camino de n-v\u00e9rtices. Existe un algoritmo O -LRB- n3 -RRB- que calcula una representaci\u00f3n de todos los equilibrios de Nash de dicho juego. En la Secci\u00f3n 5 ampliamos los resultados de la Secci\u00f3n 4 a gr\u00e1ficas generales de grado2, obteniendo el siguiente teorema. TEOREMA 2. Existe un algoritmo de tiempo polinomial que encuentra un equilibrio de Nash de un juego gr\u00e1fico con dos acciones por jugador en un gr\u00e1fico con grado m\u00e1ximo 2. En la Secci\u00f3n 6 ampliamos nuestro algoritmo para que pueda usarse para encontrar un equilibrio de Nash de un juego gr\u00e1fico en un \u00e1rbol arbitrario. Incluso cuando el \u00e1rbol tiene un grado acotado, el tiempo de ejecuci\u00f3n puede ser exponencial. Demostramos que esto es inevitable construyendo una familia de juegos gr\u00e1ficos en \u00e1rboles de grados acotados para los cuales las pol\u00edticas de mejor respuesta de algunos de los v\u00e9rtices tienen un tama\u00f1o exponencial, y cualquier algoritmo de dos pasos -LRB-, es decir, un algoritmo que sea similar en esp\u00edritu a ese. de -LSB- 8 -RSB- -RRB- tiene que almacenar casi todos los puntos de las pol\u00edticas de mejor respuesta. En particular, mostramos lo siguiente. TEOREMA 3. Existe una familia infinita de juegos gr\u00e1ficos en \u00e1rboles de grados acotados con ancho de ruta 2, de modo que cualquier algoritmo de dos pasos para encontrar equilibrios de Nash en estos \u00e1rboles requiere tiempo y espacio exponenciales. Es interesante observar que los \u00e1rboles utilizados en la demostraci\u00f3n del Teorema 3 tienen un ancho de camino 2, es decir, est\u00e1n muy cerca de ser caminos. Es una pregunta abierta si nuestro algoritmo se ejecuta en tiempo polin\u00f3mico para gr\u00e1ficas de ancho de ruta 1. Esta pregunta puede verse como una generalizaci\u00f3n de un problema de geometr\u00eda computacional muy natural; lo describimos con m\u00e1s detalle en la Secci\u00f3n 8. En la Secci\u00f3n 7, dar un resultado de intratabilidad te\u00f3rica de la complejidad para el problema de encontrar un equilibrio de Nash de un juego gr\u00e1fico en un gr\u00e1fico con un ancho de ruta peque\u00f1o. Probamos el siguiente teorema. TEOREMA 4.Considere el problema de encontrar un equilibrio de Nash para un juego gr\u00e1fico en el que el gr\u00e1fico subyacente tiene un grado m\u00e1ximo de 3 y un ancho de ruta k. Existe una constante k tal que este problema es PPAD completo. El teorema 4 limita el grado en que podemos explotar las propiedades \"similares a una trayectoria\" del gr\u00e1fico subyacente para encontrar equilibrios de Nash. Para probar el Teorema 4, utilizamos resultados recientes de completitud de PPAD para juegos, en particular los art\u00edculos -LSB- 7, 4 -RSB- que muestran que el problema de encontrar equilibrios de Nash en juegos gr\u00e1ficos de grado d -LRB- para d > 3 -RRB- es computacionalmente equivalente al problema de resolver juegos de forma normal de r jugadores -LRB- para r > 4 -RRB-, los cuales son PPAD completos. 8. PROBLEMAS ABIERTOS El problema m\u00e1s importante que deja abierto este art\u00edculo es si es posible encontrar un equilibrio de Nash de un juego gr\u00e1fico en un \u00e1rbol de grados acotados en tiempo polin\u00f3mico. Nuestra construcci\u00f3n muestra que cualquier algoritmo de dos pasos que almacene expl\u00edcitamente pol\u00edticas de puntos de interrupci\u00f3n necesita tiempo y espacio exponenciales. Sin embargo, no excluye la existencia de un algoritmo que se base en una idea similar, sino que, en lugar de calcular toda la pol\u00edtica de puntos de interrupci\u00f3n para cada v\u00e9rtice, utiliza una peque\u00f1a cantidad de pasos adicionales a trav\u00e9s del gr\u00e1fico para decidir qu\u00e9 -LRB- polinomio- Se deben calcular las partes de tama\u00f1o -RRB- de cada pol\u00edtica de punto de interrupci\u00f3n. En particular, dicho algoritmo puede basarse en el algoritmo de aproximaci\u00f3n de -LSB-8-RSB-, donde el valor de e se elige de forma adaptativa. Otra pregunta intrigante est\u00e1 relacionada con el hecho de que el gr\u00e1fico para el cual construimos una pol\u00edtica de punto de interrupci\u00f3n de tama\u00f1o exponencial tiene un ancho de ruta 2, mientras que nuestros resultados positivos son para una ruta, es decir, un gr\u00e1fico de ancho de ruta 1. No est\u00e1 claro si para cualquier ruta acotada -gr\u00e1fico de grados del ancho de ruta 1 el tiempo de ejecuci\u00f3n de -LRB- la versi\u00f3n basada en pol\u00edticas de punto de interrupci\u00f3n de -RRB- nuestro algoritmo ser\u00e1 polin\u00f3mico. En particular, es instructivo considerar un gr\u00e1fico ``oruga'', es decir, el gr\u00e1fico que se puede obtener de Tn eliminando los v\u00e9rtices S1,..., Sn. Esto implica que el problema de acotar el tama\u00f1o de la pol\u00edtica de mejor respuesta -LRB- o, alternativamente, la pol\u00edtica de punto de interrupci\u00f3n -RRB-, puede verse como una generalizaci\u00f3n del siguiente problema de geometr\u00eda computacional, que creemos puede ser de inter\u00e9s independiente: PROBLEMA 1. En caso afirmativo, \u00bfpuede darse el caso de que en este conjunto no exista ning\u00fan camino con un n\u00famero polin\u00f3mico de vueltas que conecte los puntos finales del segmento original? Esto implica que incluso para una oruga, la mejor pol\u00edtica de respuesta puede ser exponencialmente grande. Sin embargo, en nuestro ejemplo -LRB- que se omite en esta versi\u00f3n del art\u00edculo debido a limitaciones de espacio -RRB-, existe una ruta de tama\u00f1o polin\u00f3mico a trav\u00e9s de la pol\u00edtica de mejor respuesta, es decir, no prueba que la pol\u00edtica de punto de interrupci\u00f3n sea necesariamente exponencial en tama\u00f1o. Si se puede demostrar que este es siempre el caso,Quiz\u00e1s sea posible adaptar esta prueba para mostrar que puede haber una brecha exponencial entre los tama\u00f1os de las pol\u00edticas de mejor respuesta y las pol\u00edticas de punto de ruptura.", "keyphrases": ["juego grafico", "red de distribuci\u00f3n a gran escala", "equilibrio de Nash", "grado", "algoritmo basado en programa din\u00e1mico", "ppad-completo", "\u00e1rbol de grados enlazados", "algoritmo genero", "respuestas pol\u00edticas", "paso aguas abajo", "pol\u00edtica de punto de interrupci\u00f3n"]}
{"file_name": "I-16", "text": "Un agente de oferta avanzada para la selecci\u00f3n de publicidad en pantallas p\u00fablicas RESUMEN En este art\u00edculo presentamos un agente de oferta avanzada que participa en subastas de ofertas selladas de primer precio para asignar espacio publicitario en BluScreen, un sistema experimental de publicidad p\u00fablica que detecta a los usuarios a trav\u00e9s de la presencia de sus Dispositivos habilitados para Bluetooth. Nuestro agente de ofertas es capaz de construir modelos probabil\u00edsticos tanto del comportamiento de los usuarios que ven los anuncios como de las subastas en las que participa. Luego utiliza estos modelos para maximizar la exposici\u00f3n que reciben sus anuncios. Evaluamos la efectividad de este agente de licitaci\u00f3n mediante simulaci\u00f3n frente a una variedad de mecanismos de selecci\u00f3n alternativos que incluyen una estrategia de licitaci\u00f3n simple, asignaci\u00f3n aleatoria y una asignaci\u00f3n \u00f3ptima centralizada con previsi\u00f3n perfecta. Nuestro agente de oferta supera significativamente tanto la estrategia de oferta simple como la asignaci\u00f3n aleatoria, y en una poblaci\u00f3n mixta de agentes es capaz de exponer sus anuncios a un 25 % m\u00e1s de usuarios que la estrategia de oferta simple. Adem\u00e1s, su rendimiento se sit\u00faa dentro del 7,5 % del de la asignaci\u00f3n \u00f3ptima centralizada a pesar del entorno altamente incierto en el que debe operar. 1. INTRODUCCI\u00d3N Las pantallas electr\u00f3nicas se utilizan cada vez m\u00e1s en entornos p\u00fablicos, como aeropuertos, centros urbanos y tiendas minoristas, para anunciar productos comerciales o para entretener e informar a los transe\u00fantes. Se han propuesto exhibiciones p\u00fablicas interactivas. Como tal, estos sistemas suponen un conocimiento previo sobre el p\u00fablico objetivo y requieren que un \u00fanico usuario tenga acceso exclusivo a la pantalla o que los usuarios lleven dispositivos de seguimiento espec\u00edficos para que se pueda identificar su presencia -LSB- 6, 11 -RSB- . Sin embargo, estos enfoques no funcionan en espacios p\u00fablicos, donde no existe conocimiento previo sobre los usuarios que pueden ver la pantalla y donde dichas pantallas necesitan reaccionar ante la presencia de varios usuarios simult\u00e1neamente. Por el contrario, Payne et al. han desarrollado un sistema inteligente de visualizaci\u00f3n p\u00fablica, denominado BluScreen, que detecta y rastrea a los usuarios a trav\u00e9s de los dispositivos habilitados para Bluetooth que llevan consigo todos los d\u00edas -LSB- 8 -RSB-. Dentro de este sistema, se utiliza un mecanismo de subasta descentralizado de m\u00faltiples agentes para asignar de manera eficiente el tiempo publicitario en cada exhibici\u00f3n p\u00fablica. Cada anuncio est\u00e1 representado por un agente publicitario individual que mantiene un historial de usuarios que ya han estado expuestos al anuncio. Este agente busca entonces adquirir ciclos publicitarios -LRB- durante los cuales pueda exhibir su anuncio en los displays p\u00fablicos -RRB- presentando ofertas a un agente del mercado que implementa una subasta de ofertas en sobre cerrado. El valor de estas ofertas se basa en la cantidad de usuarios que est\u00e1n actualmente presentes frente a la pantalla, el historial de estos usuarios y una estimaci\u00f3n derivada externamente del valor de exponer un anuncio a un usuario. En este art\u00edculo, presentamos un agente de oferta avanzado que ampl\u00eda significativamente la sofisticaci\u00f3n de este enfoque.En particular, consideramos el escenario m\u00e1s general en el que es imposible determinar una valoraci\u00f3n a priori por exponer un anuncio a un usuario. Adem\u00e1s, es probable que tambi\u00e9n sea el caso de las nuevas instalaciones comerciales donde la experiencia limitada en el mercado hace imposible estimar una valoraci\u00f3n. El agente de publicidad simplemente tiene la tarea de utilizar este presupuesto al m\u00e1ximo efecto -LRB-, es decir, lograr la m\u00e1xima exposici\u00f3n publicitaria posible dentro de este per\u00edodo de tiempo -RRB-. Ahora bien, para lograr este objetivo, el agente publicitario debe ser capaz de modelar el comportamiento de los usuarios para predecir el n\u00famero de personas que estar\u00e1n presentes en cualquier ciclo publicitario futuro. Adem\u00e1s, tambi\u00e9n debe comprender el entorno de subastas en el que compite para poder aprovechar al m\u00e1ximo su limitado presupuesto. Por lo tanto, al desarrollar un agente de ofertas avanzado que logre esto, avanzamos en el estado del arte de cuatro maneras clave: 1. Permitimos a los agentes de publicidad modelar la llegada y salida de los usuarios como procesos de Poisson independientes y realizar estimaciones de m\u00e1xima verosimilitud. de las tasas de estos procesos en base a sus observaciones. Mostramos c\u00f3mo estos agentes pueden calcular el n\u00famero esperado de usuarios que estar\u00e1n presentes durante cualquier ciclo publicitario futuro. 2. Utilizando un enfoque te\u00f3rico de decisi\u00f3n, permitimos a los agentes publicitarios modelar la probabilidad de ganar una subasta determinada cuando se oferta una cantidad espec\u00edfica. Para representar esta probabilidad se utiliza la forma acumulada de la distribuci\u00f3n gamma, y \u200b\u200bsus par\u00e1metros se ajustan utilizando observaciones tanto del precio de cierre de subastas anteriores como de las ofertas que presenta el propio agente publicitario. 3. Mostramos que nuestra suposici\u00f3n expl\u00edcita de que el agente publicitario no obtiene ning\u00fan beneficio adicional al mostrar un anuncio a un solo usuario m\u00e1s de una vez, hace que la utilidad esperada de cada ciclo publicitario futuro dependa del resultado esperado de todas las subastas que lo preceden. \u00e9l. Por lo tanto, presentamos un algoritmo de optimizaci\u00f3n estoc\u00e1stica basado en recocido simulado que permite al agente publicitario calcular la secuencia \u00f3ptima de ofertas que maximiza su utilidad esperada. 4. El resto de este documento est\u00e1 organizado de la siguiente manera: la Secci\u00f3n 2 analiza el trabajo relacionado donde se utilizan agentes y mercados basados \u200b\u200ben subastas para asignar espacio publicitario. La Secci\u00f3n 3 describe el prototipo del sistema BluScreen que motiva nuestro trabajo. En la secci\u00f3n 4 presentamos una descripci\u00f3n detallada del mecanismo de asignaci\u00f3n de subastas, y en la secci\u00f3n 5 describimos nuestra estrategia de oferta avanzada para los agentes de publicidad. En la secci\u00f3n 6 presentamos una validaci\u00f3n emp\u00edrica de nuestro enfoque y, finalmente, concluimos en la secci\u00f3n 7. 2. TRABAJO RELACIONADO El atractivo comercial de la publicidad dirigida ha quedado ampliamente demostrado en Internet, donde los sistemas de recomendaci\u00f3n y los anuncios contextuales son la norma. LSB- 1 -RSB-. Los intentos de aplicar estos enfoques en el mundo real han sido mucho m\u00e1s limitados. Gerding et al.presentan un sistema simulado -LRB- CASy -RRB- mediante el cual se utiliza un mecanismo de subasta Vickrey para vender espacios publicitarios dentro de un centro comercial electr\u00f3nico modelado -LSB- 2 -RSB-. La subasta se utiliza para clasificar un conjunto de posibles anuncios proporcionados por diferentes puntos de venta minorista, y los anuncios mejor clasificados se seleccionan para presentarlos en exhibidores p\u00fablicos. La retroalimentaci\u00f3n se proporciona a trav\u00e9s de informaci\u00f3n de ventas posterior, lo que permite al modelo crear un perfil de las preferencias de un usuario. Sin embargo, a diferencia del BluScreen Figura 1: Un prototipo de BluScreen implementado. El sistema que consideramos aqu\u00ed no es adecuado para anunciar a muchos individuos simult\u00e1neamente, ya que requiere interacci\u00f3n expl\u00edcita con un solo usuario para adquirir sus preferencias. La identificaci\u00f3n del usuario se basa en tarjetas infrarrojas y sensores integrados en un entorno de oficina. Cuando varios usuarios pasan por la pantalla, un sistema centralizado compara los perfiles de los usuarios para identificar \u00e1reas de inter\u00e9s comunes y se muestra el contenido que coincide con este inter\u00e9s com\u00fan. As\u00ed, mientras CASy es un sistema simulado que permite a los anunciantes competir por la atenci\u00f3n de un solo usuario, GroupCast es un prototipo de sistema que detecta la presencia de grupos de usuarios y selecciona contenidos que se ajusten a sus perfiles. A pesar de sus similitudes, ninguno de los sistemas aborda la configuraci\u00f3n que nos interesa aqu\u00ed: c\u00f3mo asignar espacios publicitarios entre anunciantes competidores que se enfrentan a una audiencia de m\u00faltiples individuos sobre los cuales no existe informaci\u00f3n de perfil a priori. As\u00ed, en el siguiente apartado describimos el prototipo del sistema BluScreen que motiva nuestro trabajo. 7. CONCLUSIONES En este art\u00edculo, presentamos una estrategia de oferta avanzada para uso de agentes publicitarios dentro del sistema de publicidad BluScreen. Esta estrategia de oferta permiti\u00f3 a los agentes publicitarios modelar y predecir la llegada y salida de los usuarios, y tambi\u00e9n modelar su \u00e9xito dentro de una subasta de oferta sellada de primer precio, observando tanto las ofertas que ellos mismos presentaron como la oferta ganadora. El ex Sexto Internacional. Conf. Conjunta. Figura 8: Comparaci\u00f3n de una poblaci\u00f3n uniformemente mixta de agentes publicitarios que utilizan estrategias de oferta simples y avanzadas en una variedad de configuraciones de par\u00e1metros. Los resultados se promedian en 50 ejecuciones de simulaci\u00f3n y las barras de error indican el error est\u00e1ndar en la media. Figura 9: Comparaci\u00f3n de una poblaci\u00f3n mixta de agentes publicitarios que utilizan estrategias de oferta simples y avanzadas. Los resultados se promedian en 50 ejecuciones de simulaci\u00f3n y las barras de error indican el error est\u00e1ndar en la media. Se demostr\u00f3 que la utilidad esperada, medida como el n\u00famero de usuarios a los que el agente publicitario expone su anuncio, depende de estos factores, y dio lugar a una expresi\u00f3n compleja en la que la utilidad esperada de cada subasta depend\u00eda del \u00e9xito o no de subastas anteriores. Presentamos un algoritmo basado en recocido simulado para resolver la estrategia de oferta \u00f3ptima y, en la simulaci\u00f3n,Se demostr\u00f3 que esta estrategia de oferta supera significativamente a una estrategia de oferta simple que no ten\u00eda ninguna de estas caracter\u00edsticas. Su rendimiento se acerc\u00f3 mucho al de una asignaci\u00f3n \u00f3ptima central, con perfecto conocimiento de la llegada y salida de los usuarios, a pesar del entorno incierto en el que debe operar la estrategia. Este trabajo continuar\u00e1 realiz\u00e1ndose junto con la implementaci\u00f3n de m\u00e1s prototipos de BluScreen para obtener m\u00e1s experiencia en el mundo real.", "keyphrases": ["agente de oferta anticipada", "pantalla azul", "Experimentar el sistema de publicidad p\u00fablica.", "Bluetooth", "modelo probabilista", "asignaci\u00f3n \u00f3ptima de centralis", "distribuir inteligencia artificial", "mecanismo de subasta multiagente decentralis", "proceso de veneno independiente", "enfoque de la teor\u00eda decis", "algoritmo estochast optimis"]}
{"file_name": "J-18", "text": "Mediadores en subastas de posici\u00f3n RESUMEN Un mediador es una entidad confiable, que puede jugar en nombre de los agentes en un juego determinado. Sin embargo, un mediador no puede imponer el uso de sus servicios y cada agente es libre de participar directamente en el juego. En este art\u00edculo presentamos un estudio de mediadores para juegos con informaci\u00f3n incompleta y lo aplicamos al context de las subastas de posiciones, un tema central en el comercio electr\u00f3nico. Las subastas de posiciones VCG, que actualmente no se utilizan en la pr\u00e1ctica, poseen algunas propiedades te\u00f3ricas interesantes, como la optimizaci\u00f3n del excedente social y la existencia de estrategias dominantes. Es posible que estas propiedades no se satisfagan con las subastas de posiciones actuales y sus variantes. Por lo tanto, nos concentramos en la b\u00fasqueda de mediadores que permitan transformar las subastas de posiciones actuales en subastas de posiciones VCG. Requerimos que aceptar los servicios del mediador e informar honestamente al mediador forme un equilibrio ex post, que satisfaga la siguiente condici\u00f3n de racionalidad: la recompensa de un agente no puede ser negativa independientemente de las acciones tomadas por los agentes que no eligieron. los servicios del mediador, o por los agentes que reportan tipos falsos al mediador. Probamos la existencia de dichos mediadores deseados para las subastas de posiciones de precio siguiente -LRB- tipo Google -RRB-, as\u00ed como para una clase m\u00e1s rica de subastas de posiciones, incluidas todas las subastas de posiciones de k precio, k > 1. Para k = 1, la posici\u00f3n de autoprecio de la subasta, mostramos que la existencia de dicho mediador depende de la regla de desempate utilizada en la subasta. 1. INTRODUCCI\u00d3N Considere una interacci\u00f3n en un sistema multiagente, en el que cada jugador posee cierta informaci\u00f3n privada, que se denomina tipo de jugador. Por ejemplo, en una interacci\u00f3n de subasta el tipo de jugador es su valoraci\u00f3n o, en subastas m\u00e1s complejas, su funci\u00f3n de valoraci\u00f3n. Esta interacci\u00f3n se modela como un juego con informaci\u00f3n incompleta. Este juego se llama juego bayesiano, cuando se agrega al sistema una medida de probabilidad com\u00fanmente conocida en los perfiles de tipos. De lo contrario, se le llama juego pre-bayesiano. En este art\u00edculo nos ocuparemos \u00fanicamente de los juegos pre-bayesianos. Considere el siguiente ejemplo sencillo de un juego prebayesiano, que posee un equilibrio ex post. El juego se denota por H.", "keyphrases": ["subasta", "mediat", "equilibrio ex post", "agente", "subasta pospuesta", "comercio electr\u00f3nico", "clase m\u00e1s rica de subasta posit", "subasta de posici\u00f3n del siguiente precio", "sistema multiagente", "t-estrategia", "funci\u00f3n de resultado vcg", "subasta de posici\u00f3n de autoprecio"]}
{"file_name": "H-29", "text": "Estimaci\u00f3n y uso de la incertidumbre en la retroalimentaci\u00f3n de pseudorelevancia RESUMEN Los m\u00e9todos de retroalimentaci\u00f3n de pseudorelevancia existentes generalmente realizan un promedio de los documentos m\u00e1s recuperados, pero ignoran una dimensi\u00f3n estad\u00edstica importante: el riesgo o la variaci\u00f3n asociada con los modelos de documentos individuales o su combinaci\u00f3n. Al tratar el m\u00e9todo de retroalimentaci\u00f3n de referencia como una caja negra y el modelo de retroalimentaci\u00f3n de salida como una variable aleatoria, estimamos una distribuci\u00f3n posterior para el modelo de retroalimentaci\u00f3n remuestreando los documentos m\u00e1s recuperados de una consulta dada, usando la media o moda posterior como la variable mejorada. modelo de retroalimentaci\u00f3n. Luego realizamos una combinaci\u00f3n de modelos en varios modelos mejorados, cada uno basado en una consulta ligeramente modificada tomada de la consulta original. Descubrimos que el remuestreo de documentos ayuda a aumentar la precisi\u00f3n del modelo de retroalimentaci\u00f3n individual al eliminar los t\u00e9rminos de ruido, mientras que el muestreo de la consulta mejora la robustez -LRB- el rendimiento en el peor de los casos -RRB- al enfatizar los t\u00e9rminos relacionados con m\u00faltiples aspectos de la consulta. El resultado es un algoritmo de meta-retroalimentaci\u00f3n que es m\u00e1s robusto y m\u00e1s preciso que el m\u00e9todo de base s\u00f3lida original. 1. INTRODUCCI\u00d3N La incertidumbre es una caracter\u00edstica inherente a la recuperaci\u00f3n de informaci\u00f3n. Incluso si la consulta estuviera perfectamente especificada, el lenguaje en los documentos de la colecci\u00f3n es inherentemente complejo y ambiguo y hacer coincidir dicho lenguaje de manera efectiva es un problema formidable en s\u00ed mismo. De esta manera, los algoritmos de recuperaci\u00f3n pueden intentar cuantificar el riesgo o la incertidumbre asociados con sus clasificaciones de producci\u00f3n, o mejorar la estabilidad o precisi\u00f3n de sus c\u00e1lculos internos. Los algoritmos actuales para retroalimentaci\u00f3n de pseudo-relevancia -LRB-PRF-RRB- tienden a seguir el mismo m\u00e9todo b\u00e1sico ya sea que usemos algoritmos basados \u200b\u200ben espacio vectorial como la f\u00f3rmula de Rocchio -LSB- 16 -RSB-, o enfoques de modelado de lenguaje m\u00e1s recientes como como Modelos de Relevancia -LSB- 10 -RSB-. Primero, se obtiene un conjunto de documentos m\u00e1s recuperados a partir de una consulta inicial y se supone que se aproxima a un conjunto de documentos relevantes. A continuaci\u00f3n, se calcula un \u00fanico vector de modelo de retroalimentaci\u00f3n de acuerdo con alg\u00fan tipo de promedio, centroide o expectativa sobre el conjunto de modelos de documentos posiblemente relevantes. Por ejemplo, los vectores de documentos se pueden combinar con igual ponderaci\u00f3n, como en Rocchio, o mediante consulta de probabilidad, como se puede hacer usando el Modelo de Relevancia. El uso de una expectativa es razonable por razones pr\u00e1cticas y te\u00f3ricas, pero por s\u00ed solo ignora informaci\u00f3n potencialmente valiosa sobre el riesgo del modelo de retroalimentaci\u00f3n. Nuestra principal hip\u00f3tesis en este art\u00edculo es que estimar la incertidumbre en la retroalimentaci\u00f3n es \u00fatil y conduce a mejores modelos de retroalimentaci\u00f3n individual y modelos combinados m\u00e1s robustos. Por lo tanto, proponemos un m\u00e9todo para estimar la incertidumbre asociada con un modelo de retroalimentaci\u00f3n individual en t\u00e9rminos de una distribuci\u00f3n posterior sobre modelos ling\u00fc\u00edsticos. Para hacer esto, variamos sistem\u00e1ticamente las entradas al m\u00e9todo de retroalimentaci\u00f3n de referencia y ajustamos una distribuci\u00f3n de Dirichlet a la salida.Utilizamos la media o moda posterior como estimaci\u00f3n del modelo de retroalimentaci\u00f3n mejorado. Este proceso se muestra en la Figura 1. Como mostraremos m\u00e1s adelante, la media y la moda pueden variar significativamente del modelo de retroalimentaci\u00f3n \u00fanica propuesto por el m\u00e9todo de referencia. Tambi\u00e9n realizamos una combinaci\u00f3n de modelos utilizando varios modelos de lenguaje de retroalimentaci\u00f3n mejorados obtenidos mediante una peque\u00f1a cantidad de consultas nuevas tomadas de la consulta original. La ponderaci\u00f3n de un modelo combina dos factores complementarios: la probabilidad del modelo de generar la consulta y la varianza del modelo, donde los modelos de alta varianza obtienen una ponderaci\u00f3n menor. ` Por ejemplo, un vector de par\u00e1metros esperado condicionado a la observaci\u00f3n de la consulta se forma a partir de los documentos recuperados en la parte superior, que se tratan como cadenas de entrenamiento -LRB- ver -LSB- 10 -RSB-, p. 62 -RRB-. Figura 1: Estimaci\u00f3n de la incertidumbre del modelo de retroalimentaci\u00f3n para una sola consulta. 4. TRABAJO RELACIONADO Nuestro enfoque est\u00e1 relacionado con trabajos previos de varias \u00e1reas de recuperaci\u00f3n de informaci\u00f3n y aprendizaje autom\u00e1tico. Estos estudios utilizan la idea de crear m\u00faltiples subconsultas y luego examinar la naturaleza de la superposici\u00f3n en los documentos y/o t\u00e9rminos de expansi\u00f3n que resultan de cada subconsulta. La combinaci\u00f3n de modelos se realiza mediante heur\u00edsticas. En particular, los estudios de Amati et al. y Carpineto et al. investig\u00f3 la combinaci\u00f3n de t\u00e9rminos de m\u00e9todos de distribuci\u00f3n individuales utilizando una heur\u00edstica de combinaci\u00f3n de reclasificaci\u00f3n de t\u00e9rminos. En un conjunto de temas TREC encontraron una amplia variaci\u00f3n promedio en la distancia de clasificaci\u00f3n de los t\u00e9rminos de diferentes m\u00e9todos de expansi\u00f3n. Su m\u00e9todo combinado produjo modestas mejoras positivas en la precisi\u00f3n promedio. La idea de examinar la superposici\u00f3n entre listas de t\u00e9rminos sugeridos tambi\u00e9n se ha utilizado en los primeros enfoques de expansi\u00f3n de consultas. En lo que respecta a los documentos, un trabajo reciente de Zhou & Croft -LSB- 21 -RSB- explor\u00f3 la idea de agregar ruido a los documentos, volver a calificarlos y utilizar la estabilidad de las clasificaciones resultantes como una estimaci\u00f3n de la dificultad de la consulta. Esto est\u00e1 relacionado con nuestro uso del muestreo de documentos para estimar el riesgo del modelo de retroalimentaci\u00f3n creado a partir de los diferentes conjuntos de documentos m\u00e1s recuperados. Sakai et al. -LSB- 17 -RSB- propuso un enfoque para mejorar la solidez de la retroalimentaci\u00f3n de pseudorelevancia utilizando un m\u00e9todo que llaman muestreo selectivo. Greiff, Morgan y Ponte -LSB- 8 -RSB- exploraron el papel de la varianza en la ponderaci\u00f3n de los plazos. En una serie de simulaciones que simplificaron el problema a documentos de 2 caracter\u00edsticas, encontraron que la precisi\u00f3n promedio se degrada a medida que aumenta la variaci\u00f3n de la frecuencia del t\u00e9rmino (alto ruido). La reducci\u00f3n de ponderaci\u00f3n de los t\u00e9rminos con alta variaci\u00f3n result\u00f3 en una precisi\u00f3n promedio mejorada. Esto parece estar de acuerdo con nuestros propios hallazgos para modelos de retroalimentaci\u00f3n individuales. Recientemente se han utilizado estimaciones de la variaci\u00f3n de la producci\u00f3n para mejorar la clasificaci\u00f3n del text. Lee y cols. -LSB- 11 -RSB- utiliz\u00f3 estimaciones de varianza espec\u00edficas de la consulta de los resultados del clasificador para realizar una combinaci\u00f3n mejorada de modelos. En lugar de utilizar el muestreo,Pudieron derivar expresiones de forma cerrada para la varianza del clasificador asumiendo clasificadores base utilizando tipos simples de redes de inferencia. Ando y Zhang propusieron un m\u00e9todo al que llamaron retroalimentaci\u00f3n estructural -LSB- 3 -RSB- y mostraron c\u00f3mo aplicarlo a la expansi\u00f3n de consultas para TREC Genomics Track. Utilizaron r variaciones de consulta para obtener R conjuntos diferentes Sr de documentos mejor clasificados que se han cruzado con los documentos mejor clasificados obtenidos de la consulta original qorig. Para cada Si, se calcula el vector centroide normalizado \u02c6wi de los documentos. Luego se aplica el an\u00e1lisis de componentes principales -LRB- PCA -RRB- a \u02c6wi para obtener la matriz 4 -RRB- de H vectores singulares izquierdos \u03c6h que se utilizan para obtener la nueva consulta expandida. El uso de la varianza como medida de calidad del modelo de retroalimentaci\u00f3n. ocurre indirectamente a trav\u00e9s de la aplicaci\u00f3n de PCA. Ser\u00eda interesante estudiar las conexiones entre este enfoque y nuestro propio m\u00e9todo de ajuste de modelos. Finalmente, en los enfoques de modelado del lenguaje para la retroalimentaci\u00f3n, Tao y Zhai -LSB- 18 -RSB- describen un m\u00e9todo para una retroalimentaci\u00f3n m\u00e1s s\u00f3lida que permite que cada documento tenga una retroalimentaci\u00f3n \u03b1 diferente. Las ponderaciones de retroalimentaci\u00f3n se derivan autom\u00e1ticamente utilizando EM regularizado. Su condici\u00f3n de detenci\u00f3n de EM implica un equilibrio aproximadamente igual entre el modelo de consulta y expansi\u00f3n. Proponen adaptar el par\u00e1metro de parada \u03b7 en funci\u00f3n de alguna medida de calidad de los documentos de retroalimentaci\u00f3n. 5. CONCLUSIONES Hemos presentado un nuevo enfoque para la retroalimentaci\u00f3n de pseudo-relevancia basada en muestreo de documentos y consultas. Estas estimaciones de varianza, por ejemplo, pueden usarse naturalmente en un marco bayesiano para mejorar la estimaci\u00f3n y combinaci\u00f3n de modelos. Si bien nuestro estudio utiliza el enfoque de modelado del lenguaje como marco para experimentos, hacemos pocas suposiciones sobre el funcionamiento real del algoritmo de retroalimentaci\u00f3n. Creemos que es probable que cualquier algoritmo de retroalimentaci\u00f3n de referencia razonablemente eficaz se beneficie de nuestro enfoque. Nuestros resultados en colecciones TREC est\u00e1ndar muestran que nuestro marco mejora la solidez de un m\u00e9todo de retroalimentaci\u00f3n de referencia s\u00f3lido en una variedad de colecciones, sin sacrificar la precisi\u00f3n promedio. Tambi\u00e9n ofrece ganancias peque\u00f1as pero consistentes en la precisi\u00f3n de los 10 primeros. En trabajos futuros, prevemos una investigaci\u00f3n sobre c\u00f3mo la variaci\u00f3n del conjunto de m\u00e9todos de muestreo utilizados y el n\u00famero de muestras controla el equilibrio entre robustez, precisi\u00f3n y eficiencia.consulta ampliada El uso de la varianza como medida de calidad del modelo de retroalimentaci\u00f3n se produce indirectamente mediante la aplicaci\u00f3n de PCA. Ser\u00eda interesante estudiar las conexiones entre este enfoque y nuestro propio m\u00e9todo de ajuste de modelos. Finalmente, en los enfoques de modelado del lenguaje para la retroalimentaci\u00f3n, Tao y Zhai -LSB- 18 -RSB- describen un m\u00e9todo para una retroalimentaci\u00f3n m\u00e1s s\u00f3lida que permite que cada documento tenga una retroalimentaci\u00f3n \u03b1 diferente. Las ponderaciones de retroalimentaci\u00f3n se derivan autom\u00e1ticamente utilizando EM regularizado. Su condici\u00f3n de detenci\u00f3n de EM implica un equilibrio aproximadamente igual entre el modelo de consulta y expansi\u00f3n. Proponen adaptar el par\u00e1metro de parada \u03b7 en funci\u00f3n de alguna medida de calidad de los documentos de retroalimentaci\u00f3n. 5. CONCLUSIONES Hemos presentado un nuevo enfoque para la retroalimentaci\u00f3n de pseudo-relevancia basada en muestreo de documentos y consultas. Estas estimaciones de varianza, por ejemplo, pueden usarse naturalmente en un marco bayesiano para mejorar la estimaci\u00f3n y combinaci\u00f3n de modelos. Si bien nuestro estudio utiliza el enfoque de modelado del lenguaje como marco para experimentos, hacemos pocas suposiciones sobre el funcionamiento real del algoritmo de retroalimentaci\u00f3n. Creemos que es probable que cualquier algoritmo de retroalimentaci\u00f3n de referencia razonablemente eficaz se beneficie de nuestro enfoque. Nuestros resultados en colecciones TREC est\u00e1ndar muestran que nuestro marco mejora la solidez de un m\u00e9todo de retroalimentaci\u00f3n de referencia s\u00f3lido en una variedad de colecciones, sin sacrificar la precisi\u00f3n promedio. Tambi\u00e9n ofrece ganancias peque\u00f1as pero consistentes en la precisi\u00f3n de los 10 primeros. En trabajos futuros, prevemos una investigaci\u00f3n sobre c\u00f3mo la variaci\u00f3n del conjunto de m\u00e9todos de muestreo utilizados y el n\u00famero de muestras controla el equilibrio entre robustez, precisi\u00f3n y eficiencia.consulta ampliada El uso de la varianza como medida de calidad del modelo de retroalimentaci\u00f3n se produce indirectamente mediante la aplicaci\u00f3n de PCA. Ser\u00eda interesante estudiar las conexiones entre este enfoque y nuestro propio m\u00e9todo de ajuste de modelos. Finalmente, en los enfoques de modelado del lenguaje para la retroalimentaci\u00f3n, Tao y Zhai -LSB- 18 -RSB- describen un m\u00e9todo para una retroalimentaci\u00f3n m\u00e1s s\u00f3lida que permite que cada documento tenga una retroalimentaci\u00f3n \u03b1 diferente. Las ponderaciones de retroalimentaci\u00f3n se derivan autom\u00e1ticamente utilizando EM regularizado. Su condici\u00f3n de detenci\u00f3n de EM implica un equilibrio aproximadamente igual entre el modelo de consulta y expansi\u00f3n. Proponen adaptar el par\u00e1metro de parada \u03b7 en funci\u00f3n de alguna medida de calidad de los documentos de retroalimentaci\u00f3n. 5. CONCLUSIONES Hemos presentado un nuevo enfoque para la retroalimentaci\u00f3n de pseudo-relevancia basada en muestreo de documentos y consultas. Estas estimaciones de varianza, por ejemplo, pueden usarse naturalmente en un marco bayesiano para mejorar la estimaci\u00f3n y combinaci\u00f3n de modelos. Si bien nuestro estudio utiliza el enfoque de modelado del lenguaje como marco para experimentos, hacemos pocas suposiciones sobre el funcionamiento real del algoritmo de retroalimentaci\u00f3n. Creemos que es probable que cualquier algoritmo de retroalimentaci\u00f3n de referencia razonablemente eficaz se beneficie de nuestro enfoque. Nuestros resultados en colecciones TREC est\u00e1ndar muestran que nuestro marco mejora la solidez de un m\u00e9todo de retroalimentaci\u00f3n de referencia s\u00f3lido en una variedad de colecciones, sin sacrificar la precisi\u00f3n promedio. Tambi\u00e9n ofrece ganancias peque\u00f1as pero consistentes en la precisi\u00f3n de los 10 primeros. En trabajos futuros, prevemos una investigaci\u00f3n sobre c\u00f3mo la variaci\u00f3n del conjunto de m\u00e9todos de muestreo utilizados y el n\u00famero de muestras controla el equilibrio entre robustez, precisi\u00f3n y eficiencia.Nuestros resultados en colecciones TREC est\u00e1ndar muestran que nuestro marco mejora la solidez de un m\u00e9todo de retroalimentaci\u00f3n de referencia s\u00f3lido en una variedad de colecciones, sin sacrificar la precisi\u00f3n promedio. Tambi\u00e9n ofrece ganancias peque\u00f1as pero consistentes en la precisi\u00f3n de los 10 primeros. En trabajos futuros, prevemos una investigaci\u00f3n sobre c\u00f3mo la variaci\u00f3n del conjunto de m\u00e9todos de muestreo utilizados y el n\u00famero de muestras controla el equilibrio entre robustez, precisi\u00f3n y eficiencia.Nuestros resultados en colecciones TREC est\u00e1ndar muestran que nuestro marco mejora la solidez de un m\u00e9todo de retroalimentaci\u00f3n de referencia s\u00f3lido en una variedad de colecciones, sin sacrificar la precisi\u00f3n promedio. Tambi\u00e9n ofrece ganancias peque\u00f1as pero consistentes en la precisi\u00f3n de los 10 primeros. En trabajos futuros, prevemos una investigaci\u00f3n sobre c\u00f3mo la variaci\u00f3n del conjunto de m\u00e9todos de muestreo utilizados y el n\u00famero de muestras controla el equilibrio entre robustez, precisi\u00f3n y eficiencia.", "keyphrases": ["m\u00e9todo de retroalimentaci\u00f3n", "distribuci\u00f3n posterior", "mejorar el modelo de retroalimentaci\u00f3n", "informar recuperar", "la consulta se expande", "distribuci\u00f3n probable", "retroalimentaci\u00f3n pseudo-relevante", "algoritmo de base espacial vectorial", "riesgo", "modelo de retroalimentaci\u00f3n", "estimaci\u00f3n de incertidumbre", "modelo de lenguaje", "distribuci\u00f3n de retroalimentaci\u00f3n"]}
{"file_name": "H-20", "text": "Detecci\u00f3n de nuevos eventos basada en un \u00e1rbol de indexaci\u00f3n y una entidad nombrada RESUMEN La detecci\u00f3n de nuevos eventos -LRB- NED -RRB- tiene como objetivo detectar de uno o varios flujos de noticias cu\u00e1l se informa sobre un nuevo evento -LRB-, es decir, no se inform\u00f3 anteriormente - RRB-. Con el abrumador volumen de noticias disponible hoy en d\u00eda, existe una necesidad creciente de un sistema NED que sea capaz de detectar nuevos eventos de manera m\u00e1s eficiente y precisa. En este art\u00edculo proponemos un nuevo modelo NED para acelerar la tarea NED mediante el uso din\u00e1mico del \u00e1rbol de indexaci\u00f3n de noticias. Adem\u00e1s, bas\u00e1ndose en la observaci\u00f3n de que t\u00e9rminos de diferentes tipos tienen diferentes efectos para la tarea NED, se proponen dos enfoques de reponderaci\u00f3n de t\u00e9rminos para mejorar la precisi\u00f3n de NED. En el primer enfoque, proponemos ajustar din\u00e1micamente las ponderaciones de los t\u00e9rminos en funci\u00f3n de grupos de historias anteriores y, en el segundo enfoque, proponemos emplear estad\u00edsticas sobre datos de entrenamiento para aprender el modelo de reponderaci\u00f3n de entidades nombradas para cada clase de historias. Los resultados experimentales en dos conjuntos de datos TDT2 y TDT3 del Linguistic Data Consortium -LRB- LDC -RRB- muestran que el modelo propuesto puede mejorar significativamente tanto la eficiencia como la precisi\u00f3n de la tarea NED, en comparaci\u00f3n con el sistema de referencia y otros sistemas existentes. 1. INTRODUCCI\u00d3N La Detecci\u00f3n de Nuevos Eventos -LRB- NED -RRB- es una de las cinco tareas de la TDT. Un Tema se define como ``un evento o actividad fundamental, junto con eventos y actividades directamente relacionados'' -LSB- 2 -RSB-. Un Evento se define como ``algo -LRB- no trivial -RRB- que sucede en un determinado lugar en un determinado momento'' -LSB- 3 -RSB-. La informaci\u00f3n noticiosa \u00fatil suele estar oculta en una masa de datos que se generan todos los d\u00edas. Por lo tanto, los sistemas NED son muy \u00fatiles para las personas que necesitan detectar informaci\u00f3n novedosa a partir de un flujo de noticias en tiempo real. Estas necesidades de la vida real a menudo ocurren en \u00e1mbitos como los mercados financieros, el an\u00e1lisis de noticias y la recopilaci\u00f3n de inteligencia. En la mayor\u00eda de los sistemas -LRB- actualmente -RRB-NED de \u00faltima generaci\u00f3n, cada noticia disponible se compara con todas las noticias recibidas anteriormente. Si todas las similitudes entre ellos no superan un umbral, entonces la historia desencadena un nuevo evento. El problema central de NED es identificar si dos historias tratan sobre el mismo tema. Obviamente, estos sistemas no pueden aprovechar la informaci\u00f3n del tema. Otros sistemas organizan historias anteriores en grupos -LRB-, cada grupo corresponde a un tema -RRB-, y la nueva historia se compara con los grupos anteriores en lugar de historias. De esta manera se pueden reducir significativamente los tiempos de comparaci\u00f3n. Esto se debe a que a veces las historias dentro de un tema se alejan unas de otras, lo que podr\u00eda generar una baja similitud entre una historia y su tema. Por otro lado, algunos sistemas NED propuestos intentaron mejorar la precisi\u00f3n haciendo un mejor uso de las entidades nombradas -LSB- 10, 11, 12, 13 -RSB-. Sin embargo, ninguno de los sistemas ha considerado que t\u00e9rminos de diferentes tipos -LRB-, por ejemplo, sustantivo, verbo o nombre de persona -RRB-, tengan efectos diferentes para diferentes clases de historias a la hora de determinar si dos historias tratan sobre el mismo tema. Por ejemplo,los nombres de los candidatos electorales -LRB- Nombre de la persona -RRB- son muy importantes para las historias de clase electoral; las ubicaciones -LRB- Nombre de la ubicaci\u00f3n -RRB- donde ocurrieron los accidentes son importantes para las historias de la clase de accidentes. -LRB- 2 -RRB- \u00bfC\u00f3mo hacer un buen uso de la informaci\u00f3n del grupo -LRB- tema -RRB- para mejorar la precisi\u00f3n? -LRB- 3 -RRB- C\u00f3mo obtener una mejor representaci\u00f3n de las noticias mediante una mejor comprensi\u00f3n de las entidades nombradas. Impulsados \u200b\u200bpor estos problemas, hemos propuesto tres enfoques en este art\u00edculo. -LRB- 1 -RRB- Para agilizar el procedimiento de detecci\u00f3n, proponemos un nuevo procedimiento NED basado en un \u00e1rbol de indexaci\u00f3n de noticias creado din\u00e1micamente. El \u00e1rbol de indexaci\u00f3n de historias se crea ensamblando historias similares para formar grupos de noticias en diferentes jerarqu\u00edas seg\u00fan sus valores de similitud. Las comparaciones entre la historia actual y los grupos anteriores podr\u00edan ayudar a encontrar la historia m\u00e1s similar en menos tiempos de comparaci\u00f3n. El nuevo procedimiento puede reducir la cantidad de tiempos de comparaci\u00f3n sin perjudicar la precisi\u00f3n. -LRB- 2 -RRB- Utilizamos los grupos del primer piso en el \u00e1rbol de indexaci\u00f3n como temas de noticias, en los que las ponderaciones de los t\u00e9rminos se ajustan din\u00e1micamente seg\u00fan la distribuci\u00f3n de los t\u00e9rminos en los grupos. En este enfoque, la informaci\u00f3n del cl\u00faster -LRB- tema -RRB- se utiliza correctamente, por lo que se evita el problema de la descentralizaci\u00f3n del tema. -LRB- 3 -RRB- Con base en observaciones de las estad\u00edsticas obtenidas de los datos de entrenamiento, encontramos que t\u00e9rminos de diferentes tipos -LRB-, por ejemplo, sustantivo y verbo -RRB-, tienen diferentes efectos para diferentes clases de historias al determinar si dos historias est\u00e1n en el mismo tema. Y proponemos utilizar estad\u00edsticas para optimizar los pesos de los t\u00e9rminos de diferentes tipos en una historia seg\u00fan la clase de noticias a la que pertenece la historia. El resto del documento est\u00e1 organizado de la siguiente manera. Comenzamos este art\u00edculo resumiendo el trabajo previo en NED en la secci\u00f3n 2. La Secci\u00f3n 3 presenta el modelo b\u00e1sico para NED que utilizan la mayor\u00eda de los sistemas actuales. La secci\u00f3n 4 describe nuestro nuevo procedimiento de detecci\u00f3n basado en el \u00e1rbol de indexaci\u00f3n de noticias. En la secci\u00f3n 5, se proponen dos m\u00e9todos de reponderaci\u00f3n de t\u00e9rminos para mejorar la precisi\u00f3n del NED. La Secci\u00f3n 6 proporciona nuestros datos experimentales y m\u00e9tricas de evaluaci\u00f3n. Finalmente concluimos con los resultados experimentales en la Secci\u00f3n 7, y las conclusiones y el trabajo futuro en la Secci\u00f3n 8. 2. TRABAJO RELACIONADO Papka et al. propuesta de agrupaci\u00f3n de paso \u00fanico en NED -LSB- 6 -RSB-. Cuando se encontraba una nueva historia, se procesaba inmediatamente para extraer las caracter\u00edsticas del t\u00e9rmino y se creaba una representaci\u00f3n de consulta del contenido de la historia. Luego se compar\u00f3 con todas las consultas anteriores. Si el documento no gener\u00f3 ninguna consulta al exceder un umbral, se marc\u00f3 como un evento nuevo. Lam et al construyen representaciones de consultas previas de grupos de historias, cada una de las cuales corresponde a un tema -LSB- 7 -RSB-. De esta manera se realizan comparaciones entre historias y grupos. En los \u00faltimos a\u00f1os, la mayor parte del trabajo se centra en proponer mejores m\u00e9todos de comparaci\u00f3n de historias y representaci\u00f3n de documentos. Se observaron buenas mejoras en los benchmarks de TDT.Stokes et al. -LSB- 9 -RSB- utiliz\u00f3 una combinaci\u00f3n de evidencia de dos representaciones distintas del contenido de un documento. Una de las representaciones era el habitual vector de text libre, la otra hac\u00eda uso de cadenas l\u00e9xicas -LRB- creadas usando WordNet -RRB- para construir otro vector de t\u00e9rminos. Luego las dos representaciones se combinan de forma lineal. Se logr\u00f3 un aumento marginal de la eficacia cuando se utiliz\u00f3 la representaci\u00f3n combinada. Se han realizado algunos esfuerzos sobre c\u00f3mo utilizar entidades nombradas para mejorar NED. Yang et al. dio a la ubicaci\u00f3n entidades nombradas un peso cuatro veces mayor que otros t\u00e9rminos y entidades nombradas -LSB- 10 -RSB-. El grupo de investigaci\u00f3n DOREMI combin\u00f3 similitudes sem\u00e1nticas de nombres de personas, nombres de lugares y hora junto con similitudes textuales -LSB- 11 -RSB- -LSB- 12 -RSB-. El grupo de investigaci\u00f3n UMass -LSB- 13 -RSB- dividi\u00f3 la representaci\u00f3n de documentos en dos partes: entidades con nombre y entidades sin nombre. Y se descubri\u00f3 que algunas clases de noticias podr\u00edan lograr un mejor rendimiento utilizando la representaci\u00f3n de entidades con nombre, mientras que otras clases de noticias podr\u00edan lograr un mejor rendimiento utilizando la representaci\u00f3n de entidades sin nombre. Tanto -LSB- 10 -RSB- como -LSB- 13 -RSB- utilizaron la t\u00e9cnica de categorizaci\u00f3n de text para clasificar las noticias por adelantado. En -LSB- 13 -RSB- las noticias se clasifican autom\u00e1ticamente al principio y luego se prueban las sensibilidades de los nombres y t\u00e9rminos sin nombre para NED para cada clase. En -LSB- 10 -RSB- los t\u00e9rminos frecuentes para cada clase se eliminan de la representaci\u00f3n del documento. En su trabajo no se investiga la eficacia de diferentes tipos de nombres -LRB- o t\u00e9rminos con diferentes POS -RRB- para NED en diferentes clases de noticias. 8. CONCLUSI\u00d3N Hemos propuesto un procedimiento de detecci\u00f3n basado en un \u00e1rbol de indexaci\u00f3n de noticias en nuestro modelo. Reduce los tiempos de comparaci\u00f3n a aproximadamente una s\u00e9ptima parte del m\u00e9todo tradicional sin afectar la precisi\u00f3n del NED. Tambi\u00e9n hemos presentado dos extensiones del modelo b\u00e1sico TF-IDF. La primera extensi\u00f3n se realiza ajustando las ponderaciones de los t\u00e9rminos en funci\u00f3n de las distribuciones de t\u00e9rminos entre todo el corpus y un conjunto de historias de cl\u00faster. Y la segunda extensi\u00f3n al modelo b\u00e1sico TF-IDF es un mejor uso de los tipos de t\u00e9rminos -LRB-, tipos de entidades nombradas y parte de velocidad -RRB- seg\u00fan las categor\u00edas de noticias. Nuestros resultados experimentales en conjuntos de datos TDT2 y TDT3 muestran que ambas extensiones contribuyen significativamente a mejorar la precisi\u00f3n. Para el trabajo futuro, queremos recopilar un conjunto de noticias que abarquen un per\u00edodo m\u00e1s largo de Internet e integrar informaci\u00f3n de tiempo en la tarea NED. Dado que el tema es un grupo de noticias relativamente grueso, tambi\u00e9n queremos refinar la granularidad del grupo a nivel de evento e identificar diferentes eventos y sus relaciones dentro de un tema.Se logr\u00f3 un aumento marginal de la eficacia cuando se utiliz\u00f3 la representaci\u00f3n combinada. Se han realizado algunos esfuerzos sobre c\u00f3mo utilizar entidades nombradas para mejorar NED. Yang et al. dio a la ubicaci\u00f3n entidades nombradas un peso cuatro veces mayor que otros t\u00e9rminos y entidades nombradas -LSB- 10 -RSB-. El grupo de investigaci\u00f3n DOREMI combin\u00f3 similitudes sem\u00e1nticas de nombres de personas, nombres de lugares y hora junto con similitudes textuales -LSB- 11 -RSB- -LSB- 12 -RSB-. El grupo de investigaci\u00f3n UMass -LSB- 13 -RSB- dividi\u00f3 la representaci\u00f3n de documentos en dos partes: entidades con nombre y entidades sin nombre. Y se descubri\u00f3 que algunas clases de noticias podr\u00edan lograr un mejor rendimiento utilizando la representaci\u00f3n de entidades con nombre, mientras que otras clases de noticias podr\u00edan lograr un mejor rendimiento utilizando la representaci\u00f3n de entidades sin nombre. Tanto -LSB- 10 -RSB- como -LSB- 13 -RSB- utilizaron la t\u00e9cnica de categorizaci\u00f3n de text para clasificar las noticias por adelantado. En -LSB- 13 -RSB- las noticias se clasifican autom\u00e1ticamente al principio y luego se prueban las sensibilidades de los nombres y t\u00e9rminos sin nombre para NED para cada clase. En -LSB- 10 -RSB- los t\u00e9rminos frecuentes para cada clase se eliminan de la representaci\u00f3n del documento. En su trabajo no se investiga la eficacia de diferentes tipos de nombres -LRB- o t\u00e9rminos con diferentes POS -RRB- para NED en diferentes clases de noticias. 8. CONCLUSI\u00d3N Hemos propuesto un procedimiento de detecci\u00f3n basado en un \u00e1rbol de indexaci\u00f3n de noticias en nuestro modelo. Reduce los tiempos de comparaci\u00f3n a aproximadamente una s\u00e9ptima parte del m\u00e9todo tradicional sin afectar la precisi\u00f3n del NED. Tambi\u00e9n hemos presentado dos extensiones del modelo b\u00e1sico TF-IDF. La primera extensi\u00f3n se realiza ajustando las ponderaciones de los t\u00e9rminos en funci\u00f3n de las distribuciones de t\u00e9rminos entre todo el corpus y un conjunto de historias de cl\u00faster. Y la segunda extensi\u00f3n al modelo b\u00e1sico TF-IDF es un mejor uso de los tipos de t\u00e9rminos -LRB-, tipos de entidades nombradas y parte de velocidad -RRB- seg\u00fan las categor\u00edas de noticias. Nuestros resultados experimentales en conjuntos de datos TDT2 y TDT3 muestran que ambas extensiones contribuyen significativamente a mejorar la precisi\u00f3n. Para el trabajo futuro, queremos recopilar un conjunto de noticias que abarquen un per\u00edodo m\u00e1s largo de Internet e integrar informaci\u00f3n de tiempo en la tarea NED. Dado que el tema es un grupo de noticias relativamente grueso, tambi\u00e9n queremos refinar la granularidad del grupo a nivel de evento e identificar diferentes eventos y sus relaciones dentro de un tema.Se logr\u00f3 un aumento marginal de la eficacia cuando se utiliz\u00f3 la representaci\u00f3n combinada. Se han realizado algunos esfuerzos sobre c\u00f3mo utilizar entidades nombradas para mejorar NED. Yang et al. dio a la ubicaci\u00f3n entidades nombradas un peso cuatro veces mayor que otros t\u00e9rminos y entidades nombradas -LSB- 10 -RSB-. El grupo de investigaci\u00f3n DOREMI combin\u00f3 similitudes sem\u00e1nticas de nombres de personas, nombres de lugares y hora junto con similitudes textuales -LSB- 11 -RSB- -LSB- 12 -RSB-. El grupo de investigaci\u00f3n UMass -LSB- 13 -RSB- dividi\u00f3 la representaci\u00f3n de documentos en dos partes: entidades con nombre y entidades sin nombre. Y se descubri\u00f3 que algunas clases de noticias podr\u00edan lograr un mejor rendimiento utilizando la representaci\u00f3n de entidades con nombre, mientras que otras clases de noticias podr\u00edan lograr un mejor rendimiento utilizando la representaci\u00f3n de entidades sin nombre. Tanto -LSB- 10 -RSB- como -LSB- 13 -RSB- utilizaron la t\u00e9cnica de categorizaci\u00f3n de text para clasificar las noticias por adelantado. En -LSB- 13 -RSB- las noticias se clasifican autom\u00e1ticamente al principio y luego se prueban las sensibilidades de los nombres y t\u00e9rminos sin nombre para NED para cada clase. En -LSB- 10 -RSB- los t\u00e9rminos frecuentes para cada clase se eliminan de la representaci\u00f3n del documento. En su trabajo no se investiga la eficacia de diferentes tipos de nombres -LRB- o t\u00e9rminos con diferentes POS -RRB- para NED en diferentes clases de noticias. 8. CONCLUSI\u00d3N Hemos propuesto un procedimiento de detecci\u00f3n basado en un \u00e1rbol de indexaci\u00f3n de noticias en nuestro modelo. Reduce los tiempos de comparaci\u00f3n a aproximadamente una s\u00e9ptima parte del m\u00e9todo tradicional sin afectar la precisi\u00f3n del NED. Tambi\u00e9n hemos presentado dos extensiones del modelo b\u00e1sico TF-IDF. La primera extensi\u00f3n se realiza ajustando las ponderaciones de los t\u00e9rminos en funci\u00f3n de las distribuciones de t\u00e9rminos entre todo el corpus y un conjunto de historias de cl\u00faster. Y la segunda extensi\u00f3n al modelo b\u00e1sico TF-IDF es un mejor uso de los tipos de t\u00e9rminos -LRB-, tipos de entidades nombradas y parte de velocidad -RRB- seg\u00fan las categor\u00edas de noticias. Nuestros resultados experimentales en conjuntos de datos TDT2 y TDT3 muestran que ambas extensiones contribuyen significativamente a mejorar la precisi\u00f3n. Para el trabajo futuro, queremos recopilar un conjunto de noticias que abarquen un per\u00edodo m\u00e1s largo de Internet e integrar informaci\u00f3n de tiempo en la tarea NED. Dado que el tema es un grupo de noticias relativamente grueso, tambi\u00e9n queremos refinar la granularidad del grupo a nivel de evento e identificar diferentes eventos y sus relaciones dentro de un tema.mientras que otras clases de noticias podr\u00edan lograr un mejor rendimiento utilizando la representaci\u00f3n de entidades sin nombre. Tanto -LSB- 10 -RSB- como -LSB- 13 -RSB- utilizaron la t\u00e9cnica de categorizaci\u00f3n de text para clasificar las noticias por adelantado. En -LSB- 13 -RSB- las noticias se clasifican autom\u00e1ticamente al principio y luego se prueban las sensibilidades de los nombres y t\u00e9rminos sin nombre para NED para cada clase. En -LSB- 10 -RSB- los t\u00e9rminos frecuentes para cada clase se eliminan de la representaci\u00f3n del documento. En su trabajo no se investiga la eficacia de diferentes tipos de nombres -LRB- o t\u00e9rminos con diferentes POS -RRB- para NED en diferentes clases de noticias. 8. CONCLUSI\u00d3N Hemos propuesto un procedimiento de detecci\u00f3n basado en un \u00e1rbol de indexaci\u00f3n de noticias en nuestro modelo. Reduce los tiempos de comparaci\u00f3n a aproximadamente una s\u00e9ptima parte del m\u00e9todo tradicional sin afectar la precisi\u00f3n del NED. Tambi\u00e9n hemos presentado dos extensiones del modelo b\u00e1sico TF-IDF. La primera extensi\u00f3n se realiza ajustando las ponderaciones de los t\u00e9rminos en funci\u00f3n de las distribuciones de t\u00e9rminos entre todo el corpus y un conjunto de historias de cl\u00faster. Y la segunda extensi\u00f3n al modelo b\u00e1sico TF-IDF es un mejor uso de los tipos de t\u00e9rminos -LRB-, tipos de entidades nombradas y parte de velocidad -RRB- seg\u00fan las categor\u00edas de noticias. Nuestros resultados experimentales en conjuntos de datos TDT2 y TDT3 muestran que ambas extensiones contribuyen significativamente a mejorar la precisi\u00f3n. Para el trabajo futuro, queremos recopilar un conjunto de noticias que abarquen un per\u00edodo m\u00e1s largo de Internet e integrar informaci\u00f3n de tiempo en la tarea NED. Dado que el tema es un grupo de noticias relativamente grueso, tambi\u00e9n queremos refinar la granularidad del grupo a nivel de evento e identificar diferentes eventos y sus relaciones dentro de un tema.mientras que otras clases de noticias podr\u00edan lograr un mejor rendimiento utilizando la representaci\u00f3n de entidades sin nombre. Tanto -LSB- 10 -RSB- como -LSB- 13 -RSB- utilizaron la t\u00e9cnica de categorizaci\u00f3n de text para clasificar las noticias por adelantado. En -LSB- 13 -RSB- las noticias se clasifican autom\u00e1ticamente al principio y luego se prueban las sensibilidades de los nombres y t\u00e9rminos sin nombre para NED para cada clase. En -LSB- 10 -RSB- los t\u00e9rminos frecuentes para cada clase se eliminan de la representaci\u00f3n del documento. En su trabajo no se investiga la eficacia de diferentes tipos de nombres -LRB- o t\u00e9rminos con diferentes POS -RRB- para NED en diferentes clases de noticias. 8. CONCLUSI\u00d3N Hemos propuesto un procedimiento de detecci\u00f3n basado en un \u00e1rbol de indexaci\u00f3n de noticias en nuestro modelo. Reduce los tiempos de comparaci\u00f3n a aproximadamente una s\u00e9ptima parte del m\u00e9todo tradicional sin afectar la precisi\u00f3n del NED. Tambi\u00e9n hemos presentado dos extensiones del modelo b\u00e1sico TF-IDF. La primera extensi\u00f3n se realiza ajustando las ponderaciones de los t\u00e9rminos en funci\u00f3n de las distribuciones de t\u00e9rminos entre todo el corpus y un conjunto de historias de cl\u00faster. Y la segunda extensi\u00f3n al modelo b\u00e1sico TF-IDF es un mejor uso de los tipos de t\u00e9rminos -LRB-, tipos de entidades nombradas y parte de velocidad -RRB- seg\u00fan las categor\u00edas de noticias. Nuestros resultados experimentales en conjuntos de datos TDT2 y TDT3 muestran que ambas extensiones contribuyen significativamente a mejorar la precisi\u00f3n. Para el trabajo futuro, queremos recopilar un conjunto de noticias que abarquen un per\u00edodo m\u00e1s largo de Internet e integrar informaci\u00f3n de tiempo en la tarea NED. Dado que el tema es un grupo de noticias relativamente grueso, tambi\u00e9n queremos refinar la granularidad del grupo a nivel de evento e identificar diferentes eventos y sus relaciones dentro de un tema.Dado que el tema es un grupo de noticias relativamente grueso, tambi\u00e9n queremos refinar la granularidad del grupo a nivel de evento e identificar diferentes eventos y sus relaciones dentro de un tema.Dado que el tema es un grupo de noticias relativamente grueso, tambi\u00e9n queremos refinar la granularidad del grupo a nivel de evento e identificar diferentes eventos y sus relaciones dentro de un tema.", "keyphrases": ["detecci\u00f3n de nuevo evento", "flujo de nuevas historias", "volumen de nuevo", "nuevo \u00e1rbol de \u00edndice", "enfoque de reponderaci\u00f3n de t\u00e9rminos", "ned precisi\u00f3n", "peso del t\u00e9rmino", "estad\u00edstico", "datos del tren", "nombre entidad modo de reponderaci\u00f3n", "clase de historia", "consorcio de datos ling\u00fc\u00edsticos", "sistema de base", "existe sistema"]}
{"file_name": "H-7", "text": "Modelado jer\u00e1rquico bayesiano eficiente de usuarios para sistemas de recomendaci\u00f3n RESUMEN Un sistema de recomendaci\u00f3n personalizado basado en contenido aprende perfiles espec\u00edficos de usuario a partir de los comentarios de los usuarios para poder entregar informaci\u00f3n adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un mejor perfil de usuario para un usuario nuevo, o un usuario con poca retroalimentaci\u00f3n, tomando prestada informaci\u00f3n de otros usuarios mediante el uso de un modelo jer\u00e1rquico bayesiano. Aprender los par\u00e1metros del modelo para optimizar la probabilidad de datos conjuntos de millones de usuarios es muy costoso desde el punto de vista computacional. El algoritmo EM com\u00fanmente utilizado converge muy lentamente debido a la escasez de datos en las aplicaciones de IR. Este art\u00edculo propone una nueva t\u00e9cnica de aprendizaje r\u00e1pido para aprender una gran cantidad de perfiles de usuarios individuales. La eficacia y eficiencia del algoritmo propuesto est\u00e1n justificadas por la teor\u00eda y demostradas con datos de usuarios reales de Netflix y MovieLens. 1. INTRODUCCI\u00d3N Por ejemplo, las tiendas en l\u00ednea, como Amazon y Netflix, brindan recomendaciones personalizadas para productos o servicios adicionales seg\u00fan el historial de un usuario. Un tema importante de personalizaci\u00f3n estudiado en la comunidad de recuperaci\u00f3n de informaci\u00f3n son los sistemas de recomendaci\u00f3n personal basados \u200b\u200ben contenido. Estos sistemas aprenden recomendaciones basadas en contenido profesional espec\u00edficas del usuario, tambi\u00e9n llamadas archivos de archivos adaptativos, a partir de los comentarios de los usuarios para que puedan recomendar informaci\u00f3n adaptada a los intereses de cada usuario individual sin necesidad de que el usuario realice una consulta expl\u00edcita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresi\u00f3n que indica qu\u00e9 tan relevante es un documento para el usuario. Uno de los principales desaf\u00edos de crear un sistema de recomendaci\u00f3n o personalizaci\u00f3n es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es peque\u00f1a. Esto se conoce como el problema del \"arranque en fr\u00edo\". Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente informaci\u00f3n de ese usuario para conocer un perfil de usuario confiable. Se han realizado muchas investigaciones sobre c\u00f3mo mejorar la precisi\u00f3n de la clasificaci\u00f3n cuando la cantidad de datos de entrenamiento etiquetados es peque\u00f1a. El enfoque de aprendizaje semisupervisado combina datos etiquetados y sin etiquetar para lograr este objetivo -LSB- 26 -RSB-. Otro enfoque es utilizar el conocimiento del dominio. El tercer enfoque consiste en tomar prestados datos de entrenamiento de otros recursos -LSB- 5 -RSB- -LSB- 7 -RSB-. La efectividad de estos diferentes enfoques es mixta, debido a qu\u00e9 tan bien se ajusta a los datos el supuesto subyacente del modelo. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendaciones para un usuario en particular es tomar prestada informaci\u00f3n de otros usuarios a trav\u00e9s de un enfoque de modelado jer\u00e1rquico bayesiano.Varios investigadores han demostrado que este enfoque equilibra eficazmente la informaci\u00f3n compartida y la informaci\u00f3n espec\u00edfica del usuario, aliviando as\u00ed el bajo rendimiento inicial de cada usuario -LSB- 27 -RSB- -LSB- 25 -RSB-. Para aprender un modelo jer\u00e1rquico bayesiano, el sistema normalmente intenta encontrar los par\u00e1metros del modelo m\u00e1s probables para los datos dados. Un sistema de recomendaci\u00f3n maduro suele funcionar para millones de usuarios. Es bien sabido que aprender los par\u00e1metros \u00f3ptimos de un modelo jer\u00e1rquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una t\u00e9cnica com\u00fanmente utilizada para el aprendizaje de par\u00e1metros debido a su simplicidad y garant\u00eda de convergencia. Sin embargo, un sistema de recomendaci\u00f3n basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento est\u00e1 representado por un vector muy disperso. Con un an\u00e1lisis cuidadoso del algoritmo EM en este escenario -LRB- Secci\u00f3n 4 -RRB-, encontramos que el filtrado EM, o filtrado colaborativo basado en elementos. En este art\u00edculo, las palabras \"filtrado\" y \"recomendaci\u00f3n\" se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de variables de entrada. Tambi\u00e9n encontramos que actualizar el par\u00e1metro del modelo en cada iteraci\u00f3n de EM tambi\u00e9n es costoso con una complejidad computacional de O -LRB- MK -RRB-, donde M es el n\u00famero de usuarios y K es el n\u00famero de dimensiones. Este art\u00edculo modifica el algoritmo EM est\u00e1ndar para crear un algoritmo de aprendizaje mejorado, al que llamamos \"algoritmo EM modificado\". '' Esto reduce en gran medida el c\u00e1lculo en una sola iteraci\u00f3n de EM y tambi\u00e9n tiene la ventaja de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La t\u00e9cnica propuesta no s\u00f3lo est\u00e1 bien respaldada por la teor\u00eda, sino tambi\u00e9n por resultados experimentales. La organizaci\u00f3n de las partes restantes de este art\u00edculo es la siguiente: La Secci\u00f3n 3 describe el marco de modelado de regresi\u00f3n lineal jer\u00e1rquica bayesiana utilizado para recomendaciones basadas en contenido. La Secci\u00f3n 4 describe c\u00f3mo aprender los par\u00e1metros del modelo usando el algoritmo EM est\u00e1ndar, junto con el uso de la nueva t\u00e9cnica propuesta en este art\u00edculo. El entorno experimental y los resultados utilizados para validar la t\u00e9cnica de aprendizaje propuesta se informan en las Secciones 5 y 6. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de RI desde los a\u00f1os 1970. Los enfoques que se han utilizado para resolver este problema se pueden clasificar a grandes rasgos en dos categor\u00edas principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendaci\u00f3n monitorea un flujo de documentos y env\u00eda documentos que coinciden con un perfil de usuario al usuario correspondiente. El filtrado colaborativo va m\u00e1s all\u00e1 del simple uso del contenido del documento para recomendar elementos a un usuario aprovechando la informaci\u00f3n de otros usuarios con gustos y preferencias similares en el pasado.Se han utilizado heur\u00edsticas basadas en memoria y enfoques basados \u200b\u200ben modelos en tareas de filtrado colaborativo -LSB- 15 -RSB- -LSB- 8 -RSB- -LSB- 2 -RSB- -LSB- 14 -RSB- -LSB- 12 -RSB- -LSB - 11 -RSB-. Este art\u00edculo contribuye a la investigaci\u00f3n de recomendaciones basadas en contenido mejorando la eficiencia y efectividad de los modelos lineales jer\u00e1rquicos bayesianos, que tienen una base te\u00f3rica s\u00f3lida y un buen desempe\u00f1o emp\u00edrico en tareas de recomendaci\u00f3n -LSB- 27 -RSB- -LSB- 25 -RSB-. Este art\u00edculo no pretende comparar el filtrado basado en contenido con el filtrado colaborativo ni afirmar cu\u00e1l es mejor. Creemos que cada uno complementa al otro y que el filtrado basado en contenido es extremadamente \u00fatil para manejar nuevos documentos/elementos con poca o ninguna respuesta de los usuarios. Al igual que algunos otros investigadores -LSB- 18 -RSB- -LSB- 1 -RSB- -LSB- 21 -RSB-, encontramos que un sistema de recomendaci\u00f3n ser\u00e1 m\u00e1s efectivo cuando se combinen ambas t\u00e9cnicas. 7. CONCLUSI\u00d3N El aprendizaje del perfil de usuario basado en contenido es un problema importante y es la clave para proporcionar recomendaciones personales a un usuario, especialmente para recomendar art\u00edculos nuevos con un n\u00famero peque\u00f1o de calificaciones. El enfoque de modelado jer\u00e1rquico bayesiano se est\u00e1 convirtiendo en un importante enfoque de aprendizaje de perfiles de usuario debido a su capacidad te\u00f3ricamente justificada para ayudar a un usuario a trav\u00e9s de la transferencia de informaci\u00f3n de otros usuarios a trav\u00e9s de hiperpriores. Este art\u00edculo examin\u00f3 la debilidad del popular enfoque de aprendizaje basado en EM para modelos lineales jer\u00e1rquicos bayesianos y propuso una mejor t\u00e9cnica de aprendizaje llamada EM modificada. Demostramos que la nueva t\u00e9cnica es te\u00f3ricamente m\u00e1s eficiente desde el punto de vista computacional que el algoritmo EM est\u00e1ndar. La evaluaci\u00f3n del conjunto de datos de Reuters mostr\u00f3 que la nueva t\u00e9cnica funciona de manera similar al algoritmo EM est\u00e1ndar cuando no se cumple la condici\u00f3n de escasez. Vale la pena mencionar que incluso si el espacio del problema original no es escaso, se puede crear escasez artificialmente cuando un sistema de recomendaci\u00f3n utiliza t\u00e9cnicas de selecci\u00f3n de caracter\u00edsticas espec\u00edficas del usuario para reducir el ruido y la complejidad del modelo de usuario. La t\u00e9cnica propuesta tambi\u00e9n se puede adaptar para mejorar el aprendizaje en tal escenario. Tambi\u00e9n demostramos que la t\u00e9cnica propuesta puede aprender medio mill\u00f3n de perfiles de usuario a partir de 100 millones de calificaciones en unas pocas horas con una sola CPU. Nuestro trabajo es un paso importante en el camino para hacer que los modelos lineales jer\u00e1rquicos bayesianos sean m\u00e1s pr\u00e1cticos. La nueva t\u00e9cnica propuesta se puede adaptar f\u00e1cilmente para ejecutarse en un grupo de m\u00e1quinas y as\u00ed acelerar a\u00fan m\u00e1s el proceso de aprendizaje para manejar un sistema de mayor escala con cientos de millones de usuarios. La investigaci\u00f3n tiene un gran potencial para beneficiar a las personas que utilizan el algoritmo EM en muchos otros problemas de IR, as\u00ed como en problemas de aprendizaje autom\u00e1tico. El algoritmo EM es una t\u00e9cnica de aprendizaje autom\u00e1tico de uso com\u00fan. Se utiliza para encontrar par\u00e1metros de modelo en muchos problemas de IR donde los datos de entrenamiento son muy escasos. Aunque nos centramos en los modelos lineales jer\u00e1rquicos bayesianos para recomendaci\u00f3n y filtrado,La nueva idea de utilizar una soluci\u00f3n anal\u00edtica en lugar de una soluci\u00f3n num\u00e9rica para pares de caracter\u00edsticas de usuario no relacionadas en el paso M podr\u00eda adaptarse a muchos otros problemas.", "keyphrases": ["modelo", "base de contenido", "recomendar sistema", "regresi\u00f3n lineal", "filtro de colaboraci\u00f3n", "par\u00e1metro", "aprender tecnica", "ir", "algoritmo em", "clasificado", "tasa"]}
{"file_name": "I-32", "text": "Un modelo de entorno adversario para agentes racionales limitados en interacciones de suma cero RESUMEN Los entornos multiagente a menudo no son cooperativos ni colaborativos; en muchos casos, los agentes tienen intereses contradictorios, lo que lleva a interacciones adversas. Este art\u00edculo presenta un modelo formal de entorno adversario para agentes racionales acotados que operan en un entorno de suma cero. En tales entornos, los intentos de utilizar m\u00e9todos de b\u00fasqueda cl\u00e1sicos basados \u200b\u200ben la utilidad pueden plantear una variedad de dificultades -LRB-, por ejemplo, modelar impl\u00edcitamente al oponente como un maximizador de utilidad omnisciente, en lugar de aprovechar un modelo de oponente expl\u00edcito y m\u00e1s matizado -RRB-. Definimos un entorno adversario describiendo los estados mentales de un agente en dicho entorno. Luego presentamos axiomas de comportamiento que pretenden servir como principios de dise\u00f1o para construir tales agentes adversarios. Exploramos la aplicaci\u00f3n de nuestro enfoque analizando archivos de registro de juegos Connect-Four completados y presentamos un an\u00e1lisis emp\u00edrico de la idoneidad de los axiomas. 1. INTRODUCCI\u00d3N Las primeras investigaciones en sistemas multiagente -LRB- MAS -RRB- consideraron grupos cooperativos de agentes; Sin embargo, debido a que los agentes individuales ten\u00edan investigaci\u00f3n MAS, pronto comenzaron a considerar agentes interactuantes con intereses individualizados, como representantes de diferentes humanos u organizaciones con intereses no id\u00e9nticos. Cuando ocurren este tipo de interacciones, los entornos requieren un comportamiento apropiado por parte de los agentes situados en ellos. A estos entornos los llamamos entornos adversarios y a los agentes en conflicto los llamamos adversarios. Los modelos de cooperaci\u00f3n y trabajo en equipo se han explorado ampliamente en MAS a trav\u00e9s de la axiomatizaci\u00f3n de estados mentales -LRB-, por ejemplo, -LSB- 8, 4, 5 -RSB- -RRB-. Sin embargo, ninguna de estas investigaciones abord\u00f3 los dominios adversarios y sus implicaciones para el comportamiento de los agentes. Nuestro art\u00edculo aborda esta cuesti\u00f3n proporcionando un modelo formal y axiomatizado de estado mental para un subconjunto de dominios adversarios, es decir, entornos adversarios simples de suma cero. Adem\u00e1s, los m\u00e9todos de b\u00fasqueda tradicionales -LRB- como Min-Max -RRB- no hacen uso de un modelo del oponente, lo que ha demostrado ser una valiosa adici\u00f3n a la planificaci\u00f3n adversarial -LSB- 9, 3, 11 -RSB-. En este art\u00edculo, desarrollamos un modelo formal y axiomatizado para agentes racionales acotados que se encuentran en un entorno adversario de suma cero. El modelo utiliza diferentes operadores de modalidad, y sus principales fundamentos son el modelo SharedPlans -LSB- 4 -RSB- de comportamiento colaborativo. Exploramos las propiedades del entorno y los estados mentales de los agentes para derivar axiomas de comportamiento; Estos axiomas de comportamiento constituyen un modelo formal que sirve como especificaci\u00f3n y gu\u00eda de dise\u00f1o para el dise\u00f1o de agentes en tales entornos. Luego investigamos emp\u00edricamente el comportamiento de nuestro modelo utilizando el juego de mesa Connect-Four. Mostramos que este juego se ajusta a la definici\u00f3n de nuestro entorno y analizamos el comportamiento de los jugadores utilizando un gran conjunto de registros de partidos completos 4. TRABAJO RELACIONADO Sin embargo,Todas estas teor\u00edas formales tratan del trabajo en equipo y la cooperaci\u00f3n de los agentes. Hasta donde sabemos, nuestro modelo es el primero en proporcionar un modelo formalizado para entornos adversarios expl\u00edcitos y el comportamiento de los agentes en ellos. El cl\u00e1sico algoritmo de b\u00fasqueda adversarial Min-Max fue el primer intento de integrar al oponente en el espacio de b\u00fasqueda con una suposici\u00f3n d\u00e9bil de un oponente que juega de manera \u00f3ptima. Desde entonces, se han realizado muchos esfuerzos para integrar el modelo del oponente en el procedimiento de decisi\u00f3n para predecir el comportamiento futuro. Willmott et al. realizaron un trabajo adicional de planificaci\u00f3n adversarial. -LSB- 13 -RSB-, que proporcion\u00f3 un enfoque de planificaci\u00f3n adversario para el juego de GO. La investigaci\u00f3n mencionada anteriormente abord\u00f3 la b\u00fasqueda adversarial y la integraci\u00f3n de modelos oponentes en m\u00e9todos cl\u00e1sicos de b\u00fasqueda basados \u200b\u200ben la utilidad. Ese trabajo muestra la importancia del modelado del oponente y la capacidad de explotarlo en beneficio de un agente. Sin embargo, todav\u00eda se aplican las limitaciones b\u00e1sicas de esos m\u00e9todos de b\u00fasqueda; Nuestro modelo intenta superar esas limitaciones presentando un modelo formal para una nueva especificaci\u00f3n adversarial basada en el estado mental. 5. CONCLUSIONES Presentamos un modelo de Entorno Adversario para un 2. Estos fueron posteriormente eliminados del an\u00e1lisis final. agente racional acotado que est\u00e1 situado en un entorno de suma cero y N jugadores. Utilizamos la formalizaci\u00f3n de SharedPlans para definir el modelo y los axiomas que los agentes pueden aplicar como pautas de comportamiento. El modelo est\u00e1 destinado a usarse como gu\u00eda para dise\u00f1ar agentes que necesiten operar en entornos tan conflictivos. Presentamos resultados emp\u00edricos, basados \u200b\u200ben el an\u00e1lisis de archivos de registro de ConnectFour, que ejemplifican el modelo y los axiomas para una instancia bilateral del entorno. Los resultados que presentamos son un primer paso hacia un modelo ampliado que cubrir\u00e1 todo tipo de entornos adversarios, por ejemplo, entornos que no son de suma cero y entornos que contienen agentes naturales que no forman parte del conflicto directo. Esos desaf\u00edos y m\u00e1s se abordar\u00e1n en futuras investigaciones.las limitaciones b\u00e1sicas de esos m\u00e9todos de b\u00fasqueda a\u00fan se aplican; Nuestro modelo intenta superar esas limitaciones presentando un modelo formal para una nueva especificaci\u00f3n adversarial basada en el estado mental. 5. CONCLUSIONES Presentamos un modelo de Entorno Adversario para un 2. Estos fueron posteriormente eliminados del an\u00e1lisis final. agente racional acotado que est\u00e1 situado en un entorno de suma cero y N jugadores. Utilizamos la formalizaci\u00f3n de SharedPlans para definir el modelo y los axiomas que los agentes pueden aplicar como pautas de comportamiento. El modelo est\u00e1 destinado a usarse como gu\u00eda para dise\u00f1ar agentes que necesiten operar en entornos tan conflictivos. Presentamos resultados emp\u00edricos, basados \u200b\u200ben el an\u00e1lisis de archivos de registro de ConnectFour, que ejemplifican el modelo y los axiomas para una instancia bilateral del entorno. Los resultados que presentamos son un primer paso hacia un modelo ampliado que cubrir\u00e1 todo tipo de entornos adversarios, por ejemplo, entornos que no son de suma cero y entornos que contienen agentes naturales que no forman parte del conflicto directo. Esos desaf\u00edos y m\u00e1s se abordar\u00e1n en futuras investigaciones.las limitaciones b\u00e1sicas de esos m\u00e9todos de b\u00fasqueda a\u00fan se aplican; Nuestro modelo intenta superar esas limitaciones presentando un modelo formal para una nueva especificaci\u00f3n adversarial basada en el estado mental. 5. CONCLUSIONES Presentamos un modelo de Entorno Adversario para un 2. Estos fueron posteriormente eliminados del an\u00e1lisis final. agente racional acotado que est\u00e1 situado en un entorno de suma cero y N jugadores. Utilizamos la formalizaci\u00f3n de SharedPlans para definir el modelo y los axiomas que los agentes pueden aplicar como pautas de comportamiento. El modelo est\u00e1 destinado a usarse como gu\u00eda para dise\u00f1ar agentes que necesiten operar en entornos tan conflictivos. Presentamos resultados emp\u00edricos, basados \u200b\u200ben el an\u00e1lisis de archivos de registro de ConnectFour, que ejemplifican el modelo y los axiomas para una instancia bilateral del entorno. Los resultados que presentamos son un primer paso hacia un modelo ampliado que cubrir\u00e1 todo tipo de entornos adversarios, por ejemplo, entornos que no son de suma cero y entornos que contienen agentes naturales que no forman parte del conflicto directo. Esos desaf\u00edos y m\u00e1s se abordar\u00e1n en futuras investigaciones.", "keyphrases": ["entorno multiag", "adversarios interact\u00faan", "entorno adversario", "axioma de comportamiento", "instantes bilaterales y m\u00faltiples", "funci\u00f3n de evaluaci\u00f3n", "acci\u00f3n beneficiosa", "juego de conectar cuatro", "estudio empir", "modelo axioma", "cuenta de suma cero", "grupo de tratamiento", "valor de evaluaci\u00f3n", "interactuar"]}
{"file_name": "I-29", "text": "Gesti\u00f3n distribuida de horarios flexibles RESUMEN Consideramos el problema de la gesti\u00f3n de horarios en un entorno incierto y distribuido. Asumimos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un cronograma preestablecido globalmente, pero ninguno posee una visi\u00f3n global ni del problema ni de la soluci\u00f3n. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecuci\u00f3n, eventos inesperados forzar\u00e1n cambios en algunas actividades prescritas y reducir\u00e1n la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que combina dos mecanismos b\u00e1sicos: -LRB- 1 -RRB- una representaci\u00f3n en `` tiempos flexibles '' de la programaci\u00f3n del agente -LRB- usando una red temporal simple -RRB- y -LRB - 2 -RRB- un procedimiento de reprogramaci\u00f3n incremental. El primero protege contra la incertidumbre temporal al permitir que la ejecuci\u00f3n proceda a partir de un conjunto de soluciones factibles, y el segundo act\u00faa para revisar el cronograma del agente cuando la ejecuci\u00f3n se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecuci\u00f3n reducen el valor esperado de esta soluci\u00f3n factible. Conjunto de soluciones. La coordinaci\u00f3n b\u00e1sica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Luego, cuando el tiempo lo permita, la infraestructura local central de resoluci\u00f3n de problemas se utiliza para impulsar un proceso de consulta y generaci\u00f3n de opciones entre agentes, destinado a identificar oportunidades para mejorar la soluci\u00f3n a trav\u00e9s del cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado \u00f3ptimo esperado -LRB- pero no escalable -RRB-. 1. INTRODUCCI\u00d3N Las limitaciones pr\u00e1cticas de muchos entornos de aplicaciones requieren una gesti\u00f3n distribuida de los planes y cronogramas de ejecuci\u00f3n. En este art\u00edculo, consideramos el problema de gestionar y ejecutar cronogramas en un entorno incierto y distribuido seg\u00fan lo definido por el programa Coordinadores DARPA. Asumimos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un cronograma preestablecido globalmente, pero ninguno posee una visi\u00f3n global ni del problema ni de la soluci\u00f3n. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados forzar\u00e1n cambios en las actividades preprogramadas y alterar\u00e1n la utilidad de ejecutar otras a medida que se desarrolle la ejecuci\u00f3n. Para proporcionar una base para la coordinaci\u00f3n distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente tambi\u00e9n se le proporciona un conjunto precalculado de opciones de contingencia local -LRB- de respaldo -RRB-. Un elemento central de nuestro enfoque para resolver este problema de m\u00faltiples agentes es un marco de programaci\u00f3n incremental de horarios flexibles. En una representaci\u00f3n de tiempos flexibles del cronograma de un agente, los intervalos de ejecuci\u00f3n asociados con las actividades programadas no son fijos.sino que se les permite flotar dentro de restricciones impuestas de tiempo y secuencia de actividades. Sin embargo, su uso en entornos de resoluci\u00f3n de problemas distribuidos ha sido bastante escaso -LRB- -LSB- 7 -RSB- es una excepci\u00f3n -RRB-, y enfoques anteriores para la programaci\u00f3n multiagente -LRB- por ejemplo, -LSB- 6, 13, 5 -RSB- -RRB- generalmente han operado con representaciones de horarios fijos de los horarios de los agentes. Definimos una arquitectura de agentes centrada en la gesti\u00f3n incremental de un horario flexible. El cambio local es ac Figura 1: Un problema C TAEMS de dos agentes. realizado por un programador incremental, dise\u00f1ado para maximizar la calidad mientras se intenta minimizar el cambio de cronograma. A esta infraestructura de gesti\u00f3n de horarios, agregamos dos mecanismos de coordinaci\u00f3n multiagente. La coordinaci\u00f3n b\u00e1sica con otros agentes se logra mediante la simple comunicaci\u00f3n de los cambios de horarios locales a otros agentes con actividades interdependientes. Sobre esto se encuentra un proceso de generaci\u00f3n y evaluaci\u00f3n de opciones no locales -LRB- similar en algunos aspectos a -LSB- 5 -RSB- -RRB-, dirigido a la identificaci\u00f3n de oportunidades de mejora global a trav\u00e9s de cambios conjuntos en los cronogramas de m\u00faltiples agentes. Comenzamos resumiendo brevemente el problema general de programaci\u00f3n distribuida de inter\u00e9s en nuestro trabajo. A continuaci\u00f3n, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y bosquejamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con m\u00e1s detalle, considerando a su vez cuestiones relacionadas con la ejecuci\u00f3n de cronogramas de agentes, la revisi\u00f3n incremental de cronogramas de agentes y la coordinaci\u00f3n de cambios de cronograma entre m\u00faltiples agentes. Luego damos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusi\u00f3n de los planes de investigaci\u00f3n actuales. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigaci\u00f3n actuales est\u00e1n dirigidos a ampliar las capacidades del agente del A\u00f1o 1 y ampliarlo a problemas significativamente mayores. Los objetivos de la evaluaci\u00f3n program\u00e1tica del a\u00f1o 2 exigen la resoluci\u00f3n de problemas del orden de 100 agentes y 10 000 m\u00e9todos. Esta escala impone exigencias computacionales mucho mayores a todos los componentes del agente. Recientemente completamos una reimplementaci\u00f3n del agente prototipo dise\u00f1ado para abordar algunos problemas de rendimiento reconocidos. Adem\u00e1s de verificar que el rendimiento en los problemas del a\u00f1o 1 coincida o supere, recientemente hemos realizado algunas pruebas exitosas con el agente en unos 100 problemas del agente. Para abordar plenamente diversas cuestiones de ampliaci\u00f3n, estamos investigando una serie de mecanismos de coordinaci\u00f3n m\u00e1s avanzados. Para proporcionar una perspectiva m\u00e1s global a las decisiones de programaci\u00f3n local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de los nodos remotos. Para abordar mejor el problema de establecer puntos de sincronizaci\u00f3n entre agentes, ampliamos el uso de propietarios de tareas y protocolos espec\u00edficos de qaf como medio para dirigir la actividad de coordinaci\u00f3n. Finalmente,Planeamos explorar el uso de mecanismos de coordinaci\u00f3n impulsados \u200b\u200bpor STN m\u00e1s avanzados, incluido el uso de desacoplamiento temporal -LSB- 7 -RSB- para aislar las acciones de agentes interdependientes y la introducci\u00f3n de programas de contingencia sensibles a la probabilidad.", "keyphrases": ["gestionar el cronograma", "entorno de distribuci\u00f3n", "agente arquitecto", "programar", "actividad interdependiente", "separaci\u00f3n geogr\u00e1fica", "tiempo flexible", "plano central", "administrar", "programar-ejecutar", "flojo", "algoritmo de ruta m\u00e1s corta", "asignaci\u00f3n activa", "enfoque impulsado por el conflicto", "sincronismo optimista", "coordinaci\u00f3n interagente", "llevar a cabo"]}
{"file_name": "C-30", "text": "Bullet: Difusi\u00f3n de datos de gran ancho de banda utilizando una malla superpuesta RESUMEN En los \u00faltimos a\u00f1os, las redes superpuestas se han convertido en una alternativa eficaz a la multidifusi\u00f3n IP para una comunicaci\u00f3n eficiente punto a multipunto a trav\u00e9s de Internet. Normalmente, los nodos se autoorganizan con el objetivo de formar un \u00e1rbol superpuesto eficiente, uno que cumpla los objetivos de rendimiento sin imponer una carga indebida a la red subyacente. En este art\u00edculo, nuestro objetivo es la distribuci\u00f3n de datos de gran ancho de banda desde una \u00fanica fuente a una gran cantidad de receptores. Las aplicaciones incluyen transferencias de archivos grandes y transmisi\u00f3n multimedia en tiempo real. Para estas aplicaciones, sostenemos que una malla superpuesta, en lugar de un \u00e1rbol, puede ofrecer un ancho de banda y una confiabilidad fundamentalmente mayores en relaci\u00f3n con las estructuras de \u00e1rbol t\u00edpicas. Este art\u00edculo presenta Bullet, un algoritmo escalable y distribuido que permite que los nodos distribuidos por Internet se autoorganicen en una malla superpuesta de gran ancho de banda. Construimos Bullet en torno a la idea de que los datos deben distribuirse de manera inconexa en puntos estrat\u00e9gicos de la red. Los receptores Bullet individuales son responsables de localizar y recuperar los datos desde m\u00faltiples puntos en paralelo. Las contribuciones clave de este trabajo incluyen: i -RRB- un algoritmo que env\u00eda datos a diferentes puntos en la superposici\u00f3n de modo que cualquier objeto de datos tenga la misma probabilidad de aparecer en cualquier nodo, ii -RRB- un algoritmo escalable y descentralizado que permite que los nodos ubiquen y recuperar elementos de datos faltantes, y iii -RRB- una implementaci\u00f3n y evaluaci\u00f3n completa de Bullet ejecut\u00e1ndose a trav\u00e9s de Internet y en un entorno de emulaci\u00f3n a gran escala revela mejoras de ancho de banda de hasta un factor dos en una variedad de circunstancias. Adem\u00e1s, encontramos que, en comparaci\u00f3n con las soluciones basadas en \u00e1rboles, Bullet reduce la necesidad de realizar costosos sondeos de ancho de banda. En un \u00e1rbol, es fundamental que el padre de un nodo entregue una alta tasa de datos de aplicaci\u00f3n a cada hijo. Sin embargo, en Bullet, los nodos reciben simult\u00e1neamente datos de m\u00faltiples fuentes en paralelo, lo que hace menos importante localizar una \u00fanica fuente capaz de sostener una alta velocidad de transmisi\u00f3n. 1. INTRODUCCI\u00d3N En este art\u00edculo, consideramos el siguiente problema general. Dado un remitente y un gran conjunto de receptores interesados \u200b\u200brepartidos por Internet, \u00bfc\u00f3mo podemos maximizar la cantidad de ancho de banda entregado a los receptores? Nuestro dominio problem\u00e1tico incluye software o distribuci\u00f3n de video y transmisi\u00f3n multimedia en tiempo real. Tradicionalmente, la multidifusi\u00f3n IP nativa ha sido el m\u00e9todo preferido para entregar contenido a un conjunto de receptores de forma escalable. Sin embargo, una serie de consideraciones, incluida la escala, la confiabilidad y el control de la congesti\u00f3n, han limitado el despliegue a gran escala de la multidifusi\u00f3n IP. Incluso si se abordaran todos estos problemas, la multidifusi\u00f3n IP no considera el ancho de banda al construir su \u00e1rbol de distribuci\u00f3n. M\u00e1s recientemente, las superposiciones han surgido como una alternativa prometedora a la multidifusi\u00f3n para la entrega de datos punto a multipunto eficiente en la red.Las estructuras de superposici\u00f3n t\u00edpicas intentan imitar la estructura de los \u00e1rboles de enrutamiento de multidifusi\u00f3n. Sin embargo, en la capa de red multidifusi\u00f3n, los nodos internos consisten en enrutadores de alta velocidad con capacidad de procesamiento y extensibilidad limitadas. Las superposiciones, por otro lado, utilizan hosts finales programables -LRB- y, por lo tanto, extensibles -RRB- como nodos interiores en el \u00e1rbol de superposici\u00f3n, y estos hosts act\u00faan como repetidores para m\u00faltiples hijos en el \u00e1rbol. Las superposiciones se han mostrado tremendamente prometedoras para aplicaciones de estilo multidifusi\u00f3n. Sin embargo, sostenemos que una estructura de \u00e1rbol tiene limitaciones fundamentales tanto para la multidifusi\u00f3n de gran ancho de banda como para una alta confiabilidad. Una dificultad con los \u00e1rboles es que se garantiza que el ancho de banda disminuir\u00e1 mon\u00f3tonamente al descender por el \u00e1rbol. Cualquier p\u00e9rdida en lo alto del \u00e1rbol reducir\u00e1 el ancho de banda disponible para los receptores que se encuentran m\u00e1s abajo en el \u00e1rbol. Se han propuesto varias t\u00e9cnicas para recuperarse de las p\u00e9rdidas y, por tanto, mejorar el ancho de banda disponible en un \u00e1rbol superpuesto -LSB- 2, 6 -RSB-. Sin embargo, fundamentalmente, el ancho de banda disponible para cualquier host est\u00e1 limitado por el ancho de banda disponible desde el \u00fanico padre de ese nodo en el \u00e1rbol. Por lo tanto, nuestro trabajo parte de la premisa de que se debe reexaminar el modelo para la difusi\u00f3n de datos de multidifusi\u00f3n de gran ancho de banda. En lugar de enviar copias id\u00e9nticas del mismo flujo de datos a todos los nodos de un \u00e1rbol y dise\u00f1ar un mecanismo escalable para recuperarse de una p\u00e9rdida, proponemos que los participantes en una superposici\u00f3n de multidifusi\u00f3n cooperen para transmitir estrat\u00e9gicamente conjuntos de datos separados a varios puntos de la red. Aqu\u00ed, el remitente divide los datos en bloques secuenciales. Los bloques se subdividen en objetos individuales que a su vez se transmiten a diferentes puntos de la red. Los nodos a\u00fan reciben un conjunto de objetos de sus padres, pero luego son responsables de localizar los pares que contienen objetos de datos faltantes. Utilizamos un algoritmo distribuido que tiene como objetivo hacer que la disponibilidad de elementos de datos se distribuya uniformemente entre todos los participantes superpuestos. De esta manera, evitamos el problema de localizar el `` \u00faltimo objeto '', que puede que s\u00f3lo est\u00e9 disponible en unos pocos nodos. Para ilustrar el comportamiento de Bullet, considere una superposici\u00f3n simple de tres nodos con una ra\u00edz R y dos hijos A y B. R tiene 1 Mbps de ancho de banda -LRB- compatible con TCP -RRB- disponible para cada uno de A y B. Sin embargo, hay Tambi\u00e9n hay 1 Mbps de ancho de banda disponible entre A y B. En este ejemplo, Bullet transmitir\u00eda un conjunto de datos separados a 1 Mbps a cada uno de A y B. Luego, A y B descubrir\u00edan independientemente la disponibilidad de datos separados en el punto remoto. se emparejan y comienzan a transmitir datos entre s\u00ed, logrando efectivamente una velocidad de recuperaci\u00f3n de 2 Mbps. Por otro lado, cualquier \u00e1rbol de superposici\u00f3n est\u00e1 restringido a entregar como m\u00e1ximo 1 Mbps incluso con una t\u00e9cnica escalable para recuperar datos perdidos. Cualquier soluci\u00f3n para lograr el modelo anterior debe mantener una serie de propiedades. Primero, debe ser compatible con TCP -LSB- 15 -RSB-. En segundo lugar, debe imponer bajos gastos generales de control. Hay muchas fuentes posibles de dichos gastos generales,incluyendo la b\u00fasqueda de ancho de banda disponible entre nodos, la localizaci\u00f3n de nodos apropiados con los que \"parecer\" para la recuperaci\u00f3n de datos y la recepci\u00f3n redundante de los mismos objetos de datos de m\u00faltiples fuentes. En tercer lugar, el algoritmo deber\u00eda ser descentralizado y escalable a miles de participantes. No se deber\u00eda exigir a ning\u00fan nodo que aprenda o mantenga conocimientos globales, por ejemplo, la pertenencia a un grupo global o el conjunto de objetos de datos actualmente disponibles en todos los nodos. Por \u00faltimo, el enfoque debe ser s\u00f3lido ante los fallos individuales. Por ejemplo, el fallo de un \u00fanico nodo deber\u00eda dar lugar s\u00f3lo a una reducci\u00f3n temporal del ancho de banda entregado a un peque\u00f1o subconjunto de participantes; ning\u00fan fallo aislado deber\u00eda provocar la p\u00e9rdida completa de datos de una fracci\u00f3n significativa de nodos, como podr\u00eda ser el caso de un fallo de un solo nodo \"en lo alto\" de un \u00e1rbol de superposici\u00f3n de multidifusi\u00f3n. En este context, este art\u00edculo presenta el dise\u00f1o y evaluaci\u00f3n de Bullet, un algoritmo para construir una malla superpuesta que intenta mantener las propiedades anteriores. Los nodos Bullet comienzan autoorganiz\u00e1ndose en un \u00e1rbol superpuesto, que puede construirse mediante cualquiera de las t\u00e9cnicas existentes -LSB- 1, 18, 21, 24, 34 -RSB-. Cada nodo Bullet, comenzando con la ra\u00edz del \u00e1rbol subyacente, luego transmite un conjunto disjunto de datos a cada uno de sus hijos, con el objetivo de mantener una representatividad uniforme de cada elemento de datos en todos los participantes. El nivel de desuni\u00f3n est\u00e1 determinado por el ancho de banda disponible para cada uno de sus hijos. Luego, Bullet emplea un algoritmo escalable y eficiente para permitir que los nodos ubiquen r\u00e1pidamente m\u00faltiples pares capaces de transmitir elementos de datos faltantes al nodo. Por lo tanto, Bullet coloca una malla de gran ancho de banda encima de un \u00e1rbol de superposici\u00f3n arbitrario. Finalmente, usamos TFRC -LSB- 15 -RSB- para transferir datos tanto hacia abajo en el \u00e1rbol de superposici\u00f3n como entre pares. Un beneficio importante de nuestro enfoque es que el ancho de banda entregado por la malla Bullet es en cierto modo independiente del ancho de banda disponible a trav\u00e9s del \u00e1rbol de superposici\u00f3n subyacente. Una limitaci\u00f3n importante para la creaci\u00f3n de \u00e1rboles superpuestos de gran ancho de banda es la sobrecarga asociada con el protocolo de construcci\u00f3n del \u00e1rbol. En estos \u00e1rboles, es fundamental que cada participante localice un padre mediante sondeo con un alto nivel de ancho de banda disponible porque recibe datos de una sola fuente -LRB- su padre -RRB-. Por lo tanto, incluso una vez construido el \u00e1rbol, los nodos deben continuar su sondeo para adaptarse a las condiciones de la red que cambian din\u00e1micamente. Si bien el sondeo del ancho de banda es un \u00e1rea activa de investigaci\u00f3n -LSB- 20, 35 -RSB-, los resultados precisos generalmente requieren la transferencia de una gran cantidad de datos para ganar confianza en los resultados. Nuestro enfoque con Bullet permite a los receptores obtener un gran ancho de banda en conjunto utilizando transferencias individuales de pares repartidos por todo el sistema. Por lo tanto, en Bullet, el ancho de banda disponible de cualquier par individual es mucho menos importante que en cualquier \u00e1rbol con ancho de banda optimizado. M\u00e1s,Todo el ancho de banda que normalmente se consumir\u00eda al buscar ancho de banda se puede reasignar para transmitir datos a trav\u00e9s de la malla Bullet. Hemos completado un prototipo de Bullet que se ejecuta sobre varios \u00e1rboles superpuestos. Nuestra evaluaci\u00f3n de una superposici\u00f3n de 1000 nodos que se ejecuta en una amplia variedad de topolog\u00edas de red emuladas de 20 000 nodos muestra que Bullet puede ofrecer hasta el doble de ancho de banda que un \u00e1rbol optimizado para ancho de banda -LRB- utilizando un algoritmo fuera de l\u00ednea e informaci\u00f3n de topolog\u00eda de red global -RRB- , todo ello sin dejar de ser compatible con TCP. Para estas ejecuciones de Internet en vivo, encontramos que Bullet puede ofrecer mejoras comparables en el rendimiento del ancho de banda. En ambos casos, la sobrecarga de mantener la malla Bullet y localizar los datos separados apropiados se limita a 30 Kbps por nodo, lo cual es aceptable para nuestros escenarios objetivo de gran ancho de banda y gran escala. El resto de este documento est\u00e1 organizado de la siguiente manera. La Secci\u00f3n 2 presenta los componentes del sistema de Bullet, incluidos RanSub, entrega de contenido informado y TFRC. Luego, la secci\u00f3n 3 detalla Bullet, un sistema de distribuci\u00f3n de datos eficiente para aplicaciones con uso intensivo de ancho de banda. La Secci\u00f3n 4 eval\u00faa el rendimiento de Bullet para una variedad de topolog\u00edas de red y lo compara con las t\u00e9cnicas de multidifusi\u00f3n existentes. La Secci\u00f3n 5 ubica nuestro trabajo en el context de esfuerzos relacionados y la Secci\u00f3n 6 presenta nuestras conclusiones. 5. TRABAJOS RELACIONADOS Snoeren et al. -LSB- 36 -RSB- utiliza una malla superpuesta para lograr una entrega confiable y oportuna de datos de misi\u00f3n cr\u00edtica. En este sistema, cada nodo elige n `` padres '' de los cuales recibir flujos de paquetes duplicados. Dado que su principal \u00e9nfasis es la confiabilidad, el sistema no intenta mejorar el ancho de banda entregado a los participantes superpuestos enviando datos separados en cada nivel. Adem\u00e1s, durante la recuperaci\u00f3n de una falla principal, limita la elecci\u00f3n de padres de un enrutador superpuesto a nodos con un n\u00famero de nivel menor que su propio n\u00famero de nivel. Los nodos Kazaa est\u00e1n organizados en una estructura jer\u00e1rquica escalable. Los usuarios individuales buscan el contenido deseado en la estructura y proceden a descargar simult\u00e1neamente piezas potencialmente inconexas de nodos que ya lo tienen. Dado que Kazaa no aborda el modelo de comunicaci\u00f3n de multidifusi\u00f3n, una gran fracci\u00f3n de usuarios que descargan el mismo archivo consumir\u00edan m\u00e1s ancho de banda que los nodos organizados en la estructura superpuesta de Bullet. BitTorrent -LSB- 3 -RSB- es otro ejemplo de un sistema de distribuci\u00f3n de archivos actualmente implementado en Internet. El rastreador plantea un l\u00edmite de escalabilidad, ya que actualiza continuamente la distribuci\u00f3n del archivo en todo el sistema. Al igual que Bullet, BitTorrent incorpora la noci\u00f3n de \"estrangulamiento\" en cada nodo con el objetivo de identificar los receptores que m\u00e1s se benefician al descargar desde esa fuente en particular. FastReplica -LSB- 11 -RSB- aborda el problema de la distribuci\u00f3n de archivos confiable y eficiente en redes de distribuci\u00f3n de contenido -LRB- CDNs -RRB-. En el algoritmo b\u00e1sico, los nodos se organizan en grupos de tama\u00f1o fijo -LRB- n -RRB-,con informaci\u00f3n completa de membres\u00eda del grupo en cada nodo. Para distribuir el archivo, un nodo lo divide en n porciones del mismo tama\u00f1o, env\u00eda las porciones a otros miembros del grupo y les indica que descarguen las piezas faltantes en paralelo desde otros miembros del grupo. Dado que s\u00f3lo se transmite una porci\u00f3n fija del archivo a lo largo de cada uno de los enlaces superpuestos, el impacto de la congesti\u00f3n es menor que en el caso de la distribuci\u00f3n en \u00e1rbol. Sin embargo, dado que trata todas las rutas por igual, FastReplica no aprovecha al m\u00e1ximo los enlaces superpuestos de alto ancho de banda en el sistema. Existen numerosos protocolos que tienen como objetivo agregar confiabilidad a la multidifusi\u00f3n IP. En Scalable Reliable Multicast -LRB- SRM -RRB- -LSB- 16 -RSB-, los nodos realizan solicitudes de retransmisi\u00f3n de multidifusi\u00f3n para paquetes perdidos. Bullet est\u00e1 estrechamente relacionado con los esfuerzos que utilizan t\u00e9cnicas de propagaci\u00f3n de datos epid\u00e9micos para recuperarse de las p\u00e9rdidas en el \u00e1rbol de multidifusi\u00f3n IP no confiable. En pbcast -LSB- 2 -RSB-, un nodo tiene membres\u00eda en un grupo global y peri\u00f3dicamente elige un subconjunto aleatorio de pares para enviar un resumen de los paquetes recibidos. Un nodo que recibe el resumen responde al remitente con los paquetes faltantes del modo \u00faltimo en entrar, primero en salir. Dado que lbpcast no requiere un \u00e1rbol subyacente para la distribuci\u00f3n de datos y se basa en el modelo push-chismoso, su sobrecarga de red puede ser bastante alta. En comparaci\u00f3n con los esfuerzos confiables de multidifusi\u00f3n, Bullet se comporta favorablemente en t\u00e9rminos de sobrecarga de la red porque los nodos no solicitan \"ciegamente\" retransmisiones de sus pares. En cambio, Bullet utiliza las vistas resumidas que obtiene a trav\u00e9s de RanSub para guiar sus acciones hacia nodos con contenido inconexo. Adem\u00e1s, un nodo Bullet divide la carga de retransmisi\u00f3n entre todos sus pares. Observamos que los nodos pbcast contienen un mecanismo para limitar la velocidad de los paquetes retransmitidos y enviar diferentes paquetes en respuesta al mismo resumen. Sin embargo, esto no garantiza que los paquetes recibidos en paralelo de varios pares no est\u00e9n duplicados. M\u00e1s importante a\u00fan, los m\u00e9todos de recuperaci\u00f3n de multidifusi\u00f3n est\u00e1n limitados por el ancho de banda a trav\u00e9s del \u00e1rbol, mientras que Bullet se esfuerza por proporcionar m\u00e1s ancho de banda a todos los receptores al separar deliberadamente los datos en todo el \u00e1rbol. Narada -LSB- 19 -RSB- construye una malla con retardo optimizado que interconecta todos los nodos participantes y mide activamente el ancho de banda disponible en enlaces superpuestos. Luego ejecuta un protocolo de enrutamiento est\u00e1ndar sobre la malla superpuesta para construir \u00e1rboles de reenv\u00edo utilizando cada nodo como posible fuente. Los nodos de Narada mantienen un conocimiento global sobre todos los participantes del grupo, lo que limita la escalabilidad del sistema a varias decenas de nodos. Adem\u00e1s, el ancho de banda disponible a trav\u00e9s de un \u00e1rbol Narada todav\u00eda est\u00e1 limitado al ancho de banda disponible de cada padre. Por otro lado, el objetivo fundamental de Bullet es aumentar el ancho de banda mediante la descarga de datos inconexos de m\u00faltiples pares. Overcast -LSB- 21 -RSB- es un ejemplo de un algoritmo de construcci\u00f3n de \u00e1rbol de superposici\u00f3n eficiente en ancho de banda. En este sistema,Todos los nodos se unen en la ra\u00edz y migran hasta el punto del \u00e1rbol donde todav\u00eda pueden mantener un nivel m\u00ednimo de ancho de banda. Se espera que Bullet sea m\u00e1s resistente a las salidas de nodos que cualquier \u00e1rbol, incluido Overcast. En lugar de que un nodo espere obtener los datos que perdi\u00f3 de un nuevo padre, un nodo puede comenzar a obtener datos de sus pares perpendiculares. El tiempo de convergencia nublado est\u00e1 limitado por sondas a hermanos y antepasados \u200b\u200binmediatos. Bullet puede proporcionar aproximadamente un ancho de banda objetivo sin tener un \u00e1rbol completamente convergente. Paralelamente a nuestro propio trabajo, SplitStream -LSB- 9 -RSB- tambi\u00e9n tiene el objetivo de lograr una difusi\u00f3n de datos de gran ancho de banda. Opera dividiendo el flujo de multidifusi\u00f3n en k franjas, transmitiendo cada franja a lo largo de un \u00e1rbol de multidifusi\u00f3n separado creado con Scribe -LSB- 34 -RSB-. Quiz\u00e1s lo m\u00e1s importante es que SplitStream supone que hay suficiente ancho de banda disponible para transportar cada franja en cada enlace del \u00e1rbol, incluidos los enlaces entre la fuente de datos y las ra\u00edces de los \u00e1rboles de franjas individuales elegidos de forma independiente por Scribe. Hasta cierto punto, Bullet y SplitStream son complementarios. Por ejemplo, Bullet podr\u00eda ejecutarse en cada una de las franjas para maximizar el ancho de banda entregado a cada nodo a lo largo de cada franja. CoopNet -LSB- 29 -RSB- considera la transmisi\u00f3n de contenido en vivo en un entorno peer-to-peer, sujeto a una alta rotaci\u00f3n de nodos. En consecuencia, el sistema favorece la resiliencia sobre la eficiencia de la red. En el caso de la transmisi\u00f3n bajo demanda, CoopNet -LSB-30-RSB- aborda el problema de la multitud flash en el servidor central redirigiendo a los clientes entrantes a una cantidad fija de nodos que previamente han recuperado partes del mismo contenido. En comparaci\u00f3n con CoopNet, Bullet proporciona a los nodos un subconjunto uniformemente aleatorio de la distribuci\u00f3n del archivo en todo el sistema. 6. CONCLUSIONES Normalmente, la transmisi\u00f3n de datos superpuestos de gran ancho de banda se realiza a trav\u00e9s de un \u00e1rbol de distribuci\u00f3n. En este art\u00edculo, sostenemos que, de hecho, una malla superpuesta es capaz de ofrecer un ancho de banda fundamentalmente mayor. Por supuesto, se deben superar una serie de desaf\u00edos dif\u00edciles para garantizar que los nodos de la malla no reciban repetidamente los mismos datos de sus pares. Este art\u00edculo presenta el dise\u00f1o y la implementaci\u00f3n de Bullet, un algoritmo de construcci\u00f3n de superposici\u00f3n eficiente y escalable que supera este desaf\u00edo para ofrecer mejoras significativas en el ancho de banda en relaci\u00f3n con las estructuras de \u00e1rbol tradicionales. Espec\u00edficamente, este art\u00edculo hace las siguientes contribuciones: 9 Presentamos el dise\u00f1o y an\u00e1lisis de Bullet, un algoritmo de construcci\u00f3n de superposici\u00f3n que crea una malla sobre cualquier \u00e1rbol de distribuci\u00f3n y permite a los participantes superpuestos lograr un mayor rendimiento de ancho de banda que la transmisi\u00f3n de datos tradicional. Como beneficio relacionado, eliminamos la sobrecarga necesaria para buscar el ancho de banda disponible en las t\u00e9cnicas tradicionales de construcci\u00f3n de \u00e1rboles distribuidos. 9 Proporcionamos una t\u00e9cnica para recuperar datos faltantes de pares de una manera escalable y eficiente.RanSub difunde peri\u00f3dicamente res\u00famenes de conjuntos de datos recibidos por un subconjunto cambiante y uniformemente aleatorio de participantes globales. 9 Proponemos un mecanismo para separar los datos y luego distribuirlos de una manera uniforme que haga que la probabilidad de encontrar un par que contenga datos faltantes sea igual para todos los nodos. 9 Una evaluaci\u00f3n a gran escala de 1.000 participantes superpuestos que se ejecutan en una topolog\u00eda de red emulada de 20.000 nodos, as\u00ed como la experimentaci\u00f3n en la parte superior del banco de pruebas de Internet PlanetLab, muestra que Bullet ejecut\u00e1ndose sobre un \u00e1rbol aleatorio puede lograr el doble de rendimiento que la transmisi\u00f3n a trav\u00e9s de un ancho de banda tradicional. \u00e1rbol.", "keyphrases": ["malla superpuesta", "difusi\u00f3n de datos", "red superpuesta", "multidifusi\u00f3n IP", "comun multipunto", "distribuci\u00f3n de datos de alto ancho de banda", "transferencia de archivos grandes", "flujo multimedia en tiempo real", "bala", "sonda de ancho de banda", "de igual a igual", "ransub", "entrega de contenidos", "tfrc"]}
{"file_name": "I-30", "text": "Asignaci\u00f3n distribuida de tareas en redes sociales RESUMEN Este art\u00edculo propone una nueva variante del problema de asignaci\u00f3n de tareas, donde los agentes est\u00e1n conectados en una red social y las tareas llegan a los agentes distribuidos en la red. Mostramos que la complejidad de este problema sigue siendo NPhard. Por otra parte, no se approximable dentro de alg\u00fan factor. Desarrollamos un algoritmo basado en el protocolo contract-net. Nuestro algoritmo est\u00e1 completamente distribuido y supone que los agentes solo tienen conocimiento local sobre tareas y recursos. Realizamos una serie de experimentos para evaluar el rendimiento y la escalabilidad del algoritmo propuesto en t\u00e9rminos de calidad de la soluci\u00f3n y tiempo de c\u00e1lculo. Se utilizan tres tipos diferentes de redes, a saber, redes de mundo peque\u00f1o, aleatorias y sin escala, para representar diversas relaciones sociales entre agentes en aplicaciones realistas. Los resultados demuestran que nuestro algoritmo funciona bien y se adapta bien a aplicaciones a gran escala. 1. INTRODUCCI\u00d3N En los \u00faltimos a\u00f1os se ha trabajado mucho en m\u00e9todos de asignaci\u00f3n de tareas y recursos, que potencialmente pueden aplicarse a muchas aplicaciones del mundo real. Sin embargo, algunas aplicaciones interesantes en las que las relaciones entre agentes desempe\u00f1an un papel requieren un modelo ligeramente m\u00e1s general. variedad de m\u00e9todos de asignaci\u00f3n de tareas. La pregunta es c\u00f3mo se deben componer y recomponer din\u00e1micamente los VO a partir de agentes individuales, cuando es necesario realizar diferentes tareas y subtareas. Esto se har\u00eda asign\u00e1ndolos a diferentes agentes, cada uno de los cuales podr\u00eda ser capaz de realizar diferentes subconjuntos de esas tareas. En este art\u00edculo, estudiamos el problema de la asignaci\u00f3n de tareas desde la perspectiva de una estructura interrelacionada tan compleja. Por lo tanto, consideramos espec\u00edficamente que los agentes est\u00e1n conectados entre s\u00ed en una red social. Adem\u00e1s de modelar la estructura interrelacionada entre socios comerciales, la red social presentada en este art\u00edculo tambi\u00e9n se puede utilizar para representar otros tipos de conexiones o restricciones entre entidades aut\u00f3nomas que surgen de otros dominios de aplicaci\u00f3n. La siguiente secci\u00f3n ofrece una descripci\u00f3n formal del problema de asignaci\u00f3n de tareas en las redes sociales. En la Secci\u00f3n 3, demostramos que la complejidad de este problema sigue siendo NP-dif\u00edcil. Luego procedemos a desarrollar un algoritmo distribuido en la Secci\u00f3n 4 y realizamos una serie de experimentos con este algoritmo, como se describe en la Secci\u00f3n 5. La Secci\u00f3n 6 analiza el trabajo relacionado y la Secci\u00f3n 7 concluye. 6. TRABAJO RELACIONADO La asignaci\u00f3n de tareas en sistemas multiagente ha sido investigada por muchos investigadores en los \u00faltimos a\u00f1os con diferentes suposiciones y \u00e9nfasis. Sin embargo, la mayor parte de la investigaci\u00f3n hasta la fecha sobre asignaci\u00f3n de tareas no considera las conexiones sociales entre agentes y estudia el problema de forma centralizada. sobre Agentes Aut\u00f3nomos y Sistemas Multi-Agente -LRB- AAMAS 07 -RRB- 505 Figura 6: La calidad del algoritmo GDAP para una distribuci\u00f3n de beneficios de tareas uniforme y sesgada relacionada con la proporci\u00f3n de recursos -LRB- el primer gr\u00e1fico -RRB-,y el grado de red -LRB- el segundo gr\u00e1fico -RRB-. configuraci\u00f3n. Por ejemplo, Kraus et al. -LSB- 12 -RSB- desarrollar un protocolo de subasta que permita a los agentes formar coaliciones con limitaciones de tiempo. Se supone que cada agente conoce las capacidades de todos los dem\u00e1s. El protocolo propuesto es centralizado, donde un gerente es responsable de asignar las tareas a todas las coaliciones. Manisterski y otros. -LSB- 14 -RSB- discuten las posibilidades de lograr asignaciones eficientes tanto en entornos cooperativos como no cooperativos. Proponen un algoritmo centralizado para encontrar la soluci\u00f3n \u00f3ptima. En contraste con este trabajo, tambi\u00e9n introducimos un protocolo eficiente y completamente distribuido que tiene en cuenta la red social. La asignaci\u00f3n de tareas tambi\u00e9n ha sido estudiada en entornos distribuidos, por ejemplo, por Shehory y Kraus -LSB- 18 -RSB- y por Lerman y Shehory -LSB- 13 -RSB-. Proponen algoritmos distribuidos con baja complejidad de comunicaci\u00f3n para formar coaliciones en sistemas multiagente a gran escala. Sin embargo, no asumen la existencia de ninguna red de agentes. El trabajo de Sander et al. -LSB- 16 -RSB- introduce algoritmos basados \u200b\u200ben geometr\u00eda computacional para la asignaci\u00f3n de tareas distribuidas en dominios geogr\u00e1ficos. Luego, a los agentes se les permite moverse y buscar activamente tareas, y la capacidad de los agentes para realizar tareas es homog\u00e9nea. Para aplicar su enfoque, los agentes necesitan tener cierto conocimiento sobre las posiciones geogr\u00e1ficas de las tareas y algunos otros agentes. Otro trabajo -LSB- 17 -RSB- propone un mecanismo de localizaci\u00f3n para sistemas abiertos multiagente para asignar tareas a agentes desconocidos. En este enfoque, cada agente almacena en cach\u00e9 una lista de agentes que conoce. El an\u00e1lisis de la complejidad de la comunicaci\u00f3n de este m\u00e9todo se basa en gr\u00e1ficos en forma de celos\u00eda, mientras investigamos c\u00f3mo resolver eficientemente la asignaci\u00f3n de tareas en una red social, cuya topolog\u00eda puede ser arbitraria. Las redes tambi\u00e9n se han empleado en el context de la asignaci\u00f3n de tareas en algunos otros trabajos, por ejemplo para limitar la Figura 8: La calidad del algoritmo GDAP en comparaci\u00f3n con el l\u00edmite superior. interacciones entre agentes y mediadores -LSB- 1 -RSB-. Los mediadores en este context son agentes que reciben la tarea y tienen conexiones con otros agentes. Dividen la tarea en subtareas y negocian con otros agentes para obtener compromisos para ejecutar estas subtareas. Su atenci\u00f3n se centra en modelar el proceso de decisi\u00f3n de un solo mediador. Otro enfoque es dividir la red en camarillas de nodos, que representan coaliciones que los agentes involucrados pueden utilizar como mecanismo de coordinaci\u00f3n -LSB- 20 -RSB-. El enfoque de ese trabajo es la formaci\u00f3n de coaliciones distribuidas entre agentes, pero en nuestro enfoque, no necesitamos que los agentes formen grupos antes de asignar tareas. Easwaran y Pitt -LSB- 6 -RSB- estudian `tareas complejas' que requieren `servicios' para su realizaci\u00f3n. El problema tiene que ver con la asignaci\u00f3n de subtareas a los proveedores de servicios en una cadena de suministro. Otro estudio de asignaci\u00f3n de tareas en cadenas de suministro es -LSB- 21 -RSB-,donde se sostiene que la caracter\u00edstica definitoria de la Formaci\u00f3n de la Cadena de Suministro es la descomposici\u00f3n jer\u00e1rquica de subtareas -LRB-HSD-RRB-. HSD se implementa utilizando redes de dependencia de tareas -LRB-TDN-RRB-, con agentes y bienes como nodos, y las relaciones de E/S entre ellos como bordes. Aqu\u00ed se da la red y el problema es seleccionar un subgrafo, para lo cual los autores proponen un algoritmo basado en el mercado, en particular, una serie de subastas. En comparaci\u00f3n con estos trabajos, nuestro enfoque es m\u00e1s general en el sentido de que podemos modelar diferentes tipos de conexiones o restricciones entre agentes para diferentes dominios de problemas adem\u00e1s de la formaci\u00f3n de la cadena de suministro. Finalmente, las redes sociales se han utilizado en el context de la formaci\u00f3n de equipos. Trabajos anteriores han demostrado c\u00f3mo aprender qu\u00e9 relaciones son m\u00e1s beneficiosas a largo plazo -LSB- 8 -RSB-, y adaptar la red social en consecuencia. Creemos que estos resultados tambi\u00e9n pueden transferirse al \u00e1mbito de la asignaci\u00f3n de tareas, dejando esto como tema para m\u00e1s estudios. Figura 7: El tiempo de ejecuci\u00f3n del algoritmo GDAP. 506 La Sexta Internacional. Conf. Conjunta. sobre Agentes Aut\u00f3nomos y Sistemas Multi-Agente -LRB- AAMAS 07 -RRB- 7. CONCLUSIONES En este trabajo estudiamos el problema de asignaci\u00f3n de tareas en una red social -LRB- STAP -RRB-, que puede verse como una nueva soluci\u00f3n m\u00e1s general. , variante del TAP. Creemos que tiene un gran potencial para problemas realistas. Proporcionamos resultados de complejidad sobre el c\u00e1lculo de la soluci\u00f3n eficiente para STAP, as\u00ed como un l\u00edmite sobre posibles algoritmos de aproximaci\u00f3n. A continuaci\u00f3n, presentamos un protocolo distribuido, relacionado con el protocolo contractnet. Tambi\u00e9n introdujimos un algoritmo exponencial para calcular la soluci\u00f3n \u00f3ptima, as\u00ed como un algoritmo r\u00e1pido de l\u00edmite superior. Los resultados presentados en este art\u00edculo muestran que el algoritmo distribuido funciona bien en redes aleatorias, de mundo peque\u00f1o y sin escala, y para muchos entornos diferentes. Tambi\u00e9n se realizaron otros experimentos -LRB-, por ejemplo, en redes grid -RRB- y estos resultados se mantuvieron en una gama m\u00e1s amplia de escenarios. Adem\u00e1s, demostramos que se adapta bien a redes grandes, tanto en t\u00e9rminos de calidad como de tiempo de c\u00e1lculo requerido. Los resultados tambi\u00e9n sugieren que las redes de mundos peque\u00f1os son ligeramente m\u00e1s adecuadas para la asignaci\u00f3n de tareas locales, porque no hay nodos con muy pocos vecinos. Hay muchas extensiones interesantes a nuestro trabajo actual. En este art\u00edculo, nos centramos en el aspecto computacional en el dise\u00f1o del algoritmo distribuido. En nuestro trabajo futuro, tambi\u00e9n nos gustar\u00eda abordar algunas de las cuestiones relacionadas con la teor\u00eda de juegos, como los agentes estrat\u00e9gicos, y mostrar las propiedades deseables de un protocolo distribuido en dicho context. En el algoritmo actual asumimos que los agentes s\u00f3lo pueden contactar a sus vecinos para solicitar recursos, lo que puede explicar por qu\u00e9 nuestro algoritmo no funciona tan bien en las redes sin escala como en las redes de mundo peque\u00f1o. Nuestro trabajo futuro puede permitir a los agentes reasignar tareas -LRB- sub -RRB-.Estamos interesados \u200b\u200ben ver c\u00f3mo dichas interacciones afectar\u00e1n el desempe\u00f1o de la asignaci\u00f3n de tareas en diferentes redes sociales. Un tercer tema interesante para seguir trabajando es la adici\u00f3n de informaci\u00f3n de reputaci\u00f3n entre los agentes. Esto puede ayudar a modelar las relaciones comerciales cambiantes e incentivar a los agentes a seguir el protocolo. Finalmente, ser\u00eda interesante estudiar casos de la vida real del problema de asignaci\u00f3n de tareas sociales y ver c\u00f3mo se relacionan con las redes generadas aleatoriamente de diferentes tipos estudiados en este art\u00edculo. Expresiones de gratitud.", "keyphrases": ["red social", "relaci\u00f3n social", "asignaci\u00f3n de tareas", "\u00fatil", "asignar", "algoritmo", "mensaje comun", "comportamiento", "sistema multiag", "agente estrat\u00e9gico", "interactuar"]}
{"file_name": "J-21", "text": "Un modelo estrat\u00e9gico para los mercados de informaci\u00f3n RESUMEN Los mercados de informaci\u00f3n, que est\u00e1n dise\u00f1ados espec\u00edficamente para agregar informaci\u00f3n de los comerciantes, se est\u00e1n volviendo cada vez m\u00e1s populares como medio para predecir eventos futuros. Investigaciones recientes en mercados de informaci\u00f3n han dado como resultado dos nuevos dise\u00f1os: reglas de puntuaci\u00f3n de mercado y mercados parimutuel din\u00e1micos. Desarrollamos un m\u00e9todo anal\u00edtico para guiar el dise\u00f1o y an\u00e1lisis estrat\u00e9gico de los mercados de informaci\u00f3n. Nuestra contribuci\u00f3n central es un nuevo juego de apuestas abstracto, el juego de proyecci\u00f3n, que sirve como modelo \u00fatil para los mercados de informaci\u00f3n. Demostramos que este juego puede servir como modelo estrat\u00e9gico de mercados din\u00e1micos de apuestas mutuas y tambi\u00e9n captura la esencia de las estrategias en las reglas de puntuaci\u00f3n del mercado. El juego de proyecci\u00f3n es f\u00e1cil de analizar y tiene una visualizaci\u00f3n geom\u00e9trica atractiva que hace que los movimientos estrat\u00e9gicos y las interacciones sean m\u00e1s transparentes. Lo utilizamos para demostrar varias propiedades estrat\u00e9gicas sobre el din\u00e1mico mercado de las apuestas mutuas. Tambi\u00e9n demostramos que una forma especial del juego de proyecci\u00f3n es estrat\u00e9gicamente equivalente a la regla de puntuaci\u00f3n esf\u00e9rica y es estrat\u00e9gicamente similar a otras reglas de puntuaci\u00f3n. Finalmente, ilustramos dos aplicaciones del modelo al an\u00e1lisis de escenarios estrat\u00e9gicos complejos: analizamos la precisi\u00f3n de un mercado en el que los comerciantes tienen inercia y un mercado en el que un comerciante puede obtener ganancias manipulando las creencias de otro comerciante. 1. INTRODUCCI\u00d3N Los mercados se han utilizado durante mucho tiempo como medio para el comercio. Como efecto secundario del comercio, los participantes en un mercado revelan algo sobre sus preferencias y creencias. Por ejemplo, en un mercado financiero, los agentes comprar\u00edan acciones que creen que est\u00e1n infravaloradas y vender\u00edan acciones que creen que est\u00e1n sobrevaloradas. Durante mucho tiempo se ha observado que, debido a que el precio de mercado est\u00e1 influenciado por todas las operaciones que tienen lugar, agrega la informaci\u00f3n privada de todos los comerciantes. Por lo tanto, en una situaci\u00f3n en la que los acontecimientos futuros son inciertos y cada operador puede tener un poco de informaci\u00f3n, la informaci\u00f3n agregada contenida en los precios de mercado se puede utilizar para predecir acontecimientos futuros. Esto ha motivado la creaci\u00f3n de mercados de informaci\u00f3n, que son mecanismos para agregar la informaci\u00f3n de los comerciantes sobre un evento incierto. Los mercados de informaci\u00f3n pueden modelarse como un juego en el que los participantes apuestan sobre una serie de resultados posibles, como los resultados de una elecci\u00f3n presidencial, comprando acciones de los resultados y recibiendo pagos cuando se materializa el resultado. Al igual que en los mercados financieros, los participantes buscan maximizar sus ganancias comprando barato y vendiendo caro. El beneficio de unos mercados de informaci\u00f3n bien dise\u00f1ados va m\u00e1s all\u00e1 de la agregaci\u00f3n de informaci\u00f3n; tambi\u00e9n pueden utilizarse como instrumento de cobertura, para permitir a los comerciantes asegurarse contra el riesgo. Recientemente, los investigadores se han centrado en el problema de dise\u00f1ar estructuras de mercado espec\u00edficamente para lograr mejores propiedades de agregaci\u00f3n de informaci\u00f3n que los mercados tradicionales. Se han propuesto dos dise\u00f1os para los mercados de informaci\u00f3n:el Mercado Din\u00e1mico de Parimutuel -LRB- DPM -RRB- de Pennock -LSB- 10 -RSB- y las Reglas de Puntuaci\u00f3n de Mercado -LRB- MSR -RRB- de Hanson -LSB- 6 -RSB-. Tanto el DPM como el MSR fueron dise\u00f1ados con el objetivo de brindar a los comerciantes informados un incentivo para comerciar y revelar su informaci\u00f3n lo antes posible, al mismo tiempo que se controla el subsidio que el dise\u00f1ador del mercado necesita para inyectar en el mercado. Se implement\u00f3 una versi\u00f3n del DPM en Yahoo! Buzz market -LSB- 8 -RSB- para probar experimentalmente las propiedades de predicci\u00f3n del mercado. La innovaci\u00f3n en el MSR es utilizar estas reglas de puntuaci\u00f3n como instrumentos que pueden negociarse, proporcionando as\u00ed a los comerciantes que tienen nueva informaci\u00f3n un incentivo para comerciar. El MSR iba a utilizarse en un mercado de an\u00e1lisis de pol\u00edticas en Oriente Medio -LSB-15-RSB-, que posteriormente fue retirado. Los mercados de informaci\u00f3n dependen de comerciantes informados que operan para su propio beneficio, por lo que es fundamental comprender las propiedades estrat\u00e9gicas de estos mercados. Esta no es una tarea f\u00e1cil, porque los mercados son complejos y los comerciantes pueden influir en las creencias de los dem\u00e1s a trav\u00e9s de sus operaciones y, por lo tanto, pueden lograr potencialmente ganancias a largo plazo manipulando el mercado. Por parte del DPM, no conocemos ning\u00fan an\u00e1lisis estrat\u00e9gico previo de esta naturaleza; de hecho, se descubri\u00f3 un agujero estrat\u00e9gico al probar el DPM en Yahoo! Mercado de rumores -LSB- 8 -RSB-. 1.1 Nuestros resultados En este documento, buscamos desarrollar un m\u00e9todo anal\u00edtico para guiar el dise\u00f1o y an\u00e1lisis estrat\u00e9gico de los mercados de informaci\u00f3n. Nuestra contribuci\u00f3n central es un nuevo juego de apuestas abstracto, el juego de proyecci\u00f3n 1, que sirve como modelo \u00fatil para los mercados de informaci\u00f3n. El juego de proyecci\u00f3n es conceptualmente m\u00e1s simple que el MSR y el DPM y, por tanto, es m\u00e1s f\u00e1cil de analizar. Adem\u00e1s cuenta con una atractiva visualizaci\u00f3n geom\u00e9trica, que hace m\u00e1s transparentes los movimientos e interacciones estrat\u00e9gicas. Presentamos un an\u00e1lisis de las estrategias y ganancias \u00f3ptimas en este juego. Luego llevamos a cabo un an\u00e1lisis de los costos y ganancias de los comerciantes en el din\u00e1mico mercado de apuestas mutuas. Sorprendentemente, encontramos que el costo de una secuencia de operaciones en el DPM es id\u00e9ntico al costo de los movimientos correspondientes en el juego de proyecci\u00f3n. Adem\u00e1s, si asumimos que las creencias de los comerciantes al final de la negociaci\u00f3n coinciden con la verdadera probabilidad de que se prediga el evento, los pagos y ganancias de los operadores en el DPM son id\u00e9nticos a sus pagos y ganancias en el juego de proyecci\u00f3n correspondiente. Usamos la equivalencia entre el DPM y el juego de proyecci\u00f3n para demostrar que el DPM est\u00e1 libre de arbitraje, deducir estrategias rentables en el DPM y demostrar que las restricciones a los intercambios de los agentes son necesarias para evitar un colapso estrat\u00e9gico. Tambi\u00e9n demostramos una equivalencia entre el juego de proyecci\u00f3n y el MSR: mostramos que jugar en el MSR es estrat\u00e9gicamente equivalente a jugar en un juego de proyecci\u00f3n restringida, al menos para estrategias miopes y peque\u00f1os intercambios. Esto nos permite utilizar el juego de proyecci\u00f3n como modelo conceptual para las reglas de puntuaci\u00f3n del mercado. M\u00e1s,Dado que el juego de proyecci\u00f3n restringida corresponde a un DPM con una restricci\u00f3n comercial natural, esto arroja luz sobre una conexi\u00f3n intrigante entre el MSR y el DPM. Por \u00faltimo, ilustramos c\u00f3mo se puede utilizar el modelo del juego de proyecci\u00f3n para analizar el potencial de manipulaci\u00f3n de los mercados de informaci\u00f3n para obtener ganancias a largo plazo.2 Presentamos un escenario de ejemplo en el que dicha manipulaci\u00f3n puede ocurrir y sugerimos reglas adicionales que podr\u00edan mitigar la posibilidad de manipulaci\u00f3n. Tambi\u00e9n ilustramos otra aplicaci\u00f3n para analizar c\u00f3mo un creador de mercado puede mejorar la precisi\u00f3n de la predicci\u00f3n de un mercado en el que los operadores no operar\u00e1n a menos que su beneficio esperado est\u00e9 por encima de un umbral. 1.2 Trabajos relacionados Numerosos estudios han demostrado emp\u00edricamente que los precios de mercado son buenos predictores de eventos futuros, y parecen agregar la sabidur\u00eda recopilada de todos los comerciantes -LSB- 2, 3, 12, 1, 5, 16 -RSB-. Varios estudios recientes han abordado el dise\u00f1o de la estructura del mercado y las reglas comerciales para los mercados de informaci\u00f3n, as\u00ed como el incentivo para participar y otras cuestiones estrat\u00e9gicas. Sin embargo, Mangold et al. tambi\u00e9n han estudiado cuestiones estrat\u00e9gicas en los mercados de la informaci\u00f3n. -LSB- 8 -RSB- y por Hanson, Oprea y Porter -LSB- 7 -RSB-. Un estudio de pr\u00f3xima publicaci\u00f3n, LSB-11-RSB, analiza las formulaciones de funciones de costos de los creadores de mercado automatizados. Organizaci\u00f3n del art\u00edculo El resto de este art\u00edculo est\u00e1 organizado de la siguiente manera: en la Secci\u00f3n 2, describimos el juego de proyecci\u00f3n y analizamos los costos, ganancias y estrategias \u00f3ptimas de los jugadores en este juego. En la Secci\u00f3n 3, estudiamos el mercado din\u00e1mico de apuestas mutuas y mostramos que el comercio en un DPM es equivalente a un juego de proyecci\u00f3n. Establecemos una conexi\u00f3n entre el juego de proyecci\u00f3n y el MSR en la Secci\u00f3n 4. En la Secci\u00f3n 5, ilustramos c\u00f3mo se puede utilizar el juego de proyecci\u00f3n para analizar acciones no miopes y potencialmente manipuladoras. Presentamos nuestras conclusiones y sugerencias para trabajos futuros en la Secci\u00f3n 6. 6. CONCLUSIONES Y TRABAJO FUTURO Hemos presentado un juego geom\u00e9trico simple, el juego de proyecci\u00f3n, que puede servir como modelo para el comportamiento estrat\u00e9gico en los mercados de informaci\u00f3n, as\u00ed como un herramienta para guiar el dise\u00f1o de nuevos mercados de informaci\u00f3n. Hemos utilizado este modelo para analizar el costo, las ganancias y las estrategias de un operador en un mercado din\u00e1mico de apuestas mutuas, y hemos demostrado que tanto el mercado din\u00e1mico de apuestas mutuas como la regla de puntuaci\u00f3n del mercado esf\u00e9rico son estrat\u00e9gicamente equivalentes al juego de proyecci\u00f3n restringida bajo una ligera distorsi\u00f3n del mercado. probabilidades previas. El an\u00e1lisis general se bas\u00f3 en el supuesto de que los comerciantes no intentan activamente enga\u00f1ar a otros comerciantes para obtener ganancias futuras. Sin embargo, en la secci\u00f3n 5 analizamos un peque\u00f1o mercado de ejemplo sin este supuesto. Demostramos que el juego de proyecci\u00f3n se puede utilizar para analizar las estrategias de los comerciantes en este escenario y, potencialmente, para ayudar a dise\u00f1ar mercados con mejores propiedades estrat\u00e9gicas. Nuestros resultados plantean varias preguntas abiertas muy interesantes. En primer lugar,Los beneficios del juego de proyecci\u00f3n no pueden implementarse directamente en situaciones en las que la verdadera probabilidad no se revela en \u00faltima instancia. Finalmente, la existencia de estrategias manipuladoras de largo plazo en los mercados de informaci\u00f3n es de gran inter\u00e9s. El ejemplo que estudiamos en la secci\u00f3n 5 apenas roza la superficie de esta \u00e1rea. Un estudio general de esta clase de manipulaciones, junto con una caracterizaci\u00f3n de los mercados en los que puede o no surgir, ser\u00eda de gran utilidad para el dise\u00f1o de mercados de informaci\u00f3n.", "keyphrases": ["informar al mercado", "mercado din\u00e1mico de apuestas mutuas", "modelo de juego del proyecto", "predecir el mercado", "regla de puntuaci\u00f3n de mercado", "regla de puntuaci\u00f3n esf\u00e9rica", "estrategias de manipulaci\u00f3n a largo plazo", "ciencia-econom\u00eda social y del comportamiento", "tiempo liquido"]}
{"file_name": "H-18", "text": "Segmentaci\u00f3n de temas con detecci\u00f3n de temas compartidos y alineaci\u00f3n de m\u00faltiples documentos RESUMEN La detecci\u00f3n y seguimiento de temas -LSB- 26 -RSB- y la segmentaci\u00f3n de temas -LSB- 15 -RSB- juegan un papel importante en la captura de la informaci\u00f3n local y secuencial de los documentos. El trabajo previo en esta \u00e1rea generalmente se centra en documentos \u00fanicos, aunque hay m\u00faltiples documentos similares disponibles en muchos dominios. En este art\u00edculo, presentamos un nuevo m\u00e9todo no supervisado para la detecci\u00f3n de temas compartidos y la segmentaci\u00f3n de temas de m\u00faltiples documentos similares basados \u200b\u200ben informaci\u00f3n mutua -LRB- MI -RRB- e informaci\u00f3n mutua ponderada -LRB- WMI -RRB- que es una combinaci\u00f3n de MI y ponderaciones de t\u00e9rminos. La idea b\u00e1sica es que la segmentaci\u00f3n \u00f3ptima maximiza MI -LRB- o WMI -RRB-. Nuestro enfoque puede detectar temas compartidos entre documentos. Puede encontrar los l\u00edmites \u00f3ptimos en un documento y alinear segmentos entre documentos al mismo tiempo. Tambi\u00e9n puede manejar la segmentaci\u00f3n de un solo documento como un caso especial de segmentaci\u00f3n y alineaci\u00f3n de varios documentos. Nuestros m\u00e9todos pueden identificar y fortalecer t\u00e9rminos clave que se pueden usar para la segmentaci\u00f3n y eliminar parcialmente las palabras vac\u00edas mediante el uso de ponderaciones de t\u00e9rminos basadas en la entrop\u00eda aprendida de m\u00faltiples documentos. Nuestros resultados experimentales muestran que nuestro algoritmo funciona bien para las tareas de segmentaci\u00f3n de un solo documento, detecci\u00f3n de temas compartidos y segmentaci\u00f3n de varios documentos. La utilizaci\u00f3n de informaci\u00f3n de m\u00faltiples documentos puede mejorar enormemente el rendimiento de la segmentaci\u00f3n de temas, y usar WMI es incluso mejor que usar MI para la segmentaci\u00f3n de m\u00faltiples documentos. 1. INTRODUCCI\u00d3N Muchos investigadores han trabajado en la detecci\u00f3n y seguimiento de temas -LRB- TDT -RRB- -LSB- 26 -RSB- y en la segmentaci\u00f3n de temas durante la \u00faltima d\u00e9cada. La segmentaci\u00f3n de temas tiene como objetivo identificar los l\u00edmites en un documento con el objetivo de capturar la estructura tem\u00e1tica latente. Las tareas de segmentaci\u00f3n de temas generalmente se dividen en dos categor\u00edas -LSB- 15 -RSB-: segmentaci\u00f3n de flujo de text donde se identifica la transici\u00f3n de temas y segmentaci\u00f3n de documentos coherente en la que los documentos se dividen en subtemas. Los enfoques tradicionales realizan la segmentaci\u00f3n de temas en los documentos uno a la vez -LSB- 15, 25, 6 -RSB-. La mayor\u00eda de ellos se desempe\u00f1an mal en tareas sutiles como la segmentaci\u00f3n coherente de documentos -LSB- 15 -RSB-. A menudo, los usuarios finales buscan documentos que tengan contenido similar. Con una granularidad m\u00e1s fina, es posible que los usuarios est\u00e9n buscando obtener secciones de un documento similares a una secci\u00f3n particular que presumiblemente trata un tema de inter\u00e9s de los usuarios. Por lo tanto, la extensi\u00f3n de la segmentaci\u00f3n de temas de documentos \u00fanicos a la identificaci\u00f3n de segmentos similares de m\u00faltiples documentos similares con el mismo tema es una direcci\u00f3n natural y necesaria, y se espera que la segmentaci\u00f3n de temas de m\u00faltiples documentos tenga un mejor desempe\u00f1o ya que se utiliza m\u00e1s informaci\u00f3n. Los enfoques tradicionales que utilizan la medici\u00f3n de similitud basada en la frecuencia de los t\u00e9rminos generalmente tienen la misma suposici\u00f3n de que el vocabulario similar tiende a estar en un segmento tem\u00e1tico coherente -LSB- 15, 25, 6 -RSB-. Sin embargo,Por lo general, sufren el problema de identificar palabras vac\u00edas. Por ejemplo, las palabras vac\u00edas adicionales dependientes del documento se eliminan junto con las palabras vac\u00edas gen\u00e9ricas en -LSB- 15 -RSB-. Hay dos motivos por los que no eliminamos las palabras vac\u00edas directamente. En primer lugar, identificar palabras vac\u00edas es otra cuesti\u00f3n -LSB- 12 -RSB- que requiere estimaci\u00f3n en cada dominio. Eliminar palabras vac\u00edas comunes puede provocar la p\u00e9rdida de informaci\u00f3n \u00fatil en un dominio espec\u00edfico. Empleamos una clasificaci\u00f3n suave utilizando ponderaciones de t\u00e9rminos. La alineaci\u00f3n de temas de varios documentos similares se puede lograr agrupando oraciones sobre el mismo tema en el mismo grupo. La segmentaci\u00f3n de temas de un solo documento es solo un caso especial del problema de alineaci\u00f3n y segmentaci\u00f3n de temas de varios documentos. Por lo general, los lectores humanos pueden identificar la transici\u00f3n de un tema bas\u00e1ndose en palabras clave y pueden ignorar las palabras vac\u00edas. Inspir\u00e1ndonos en esto, le damos a cada t\u00e9rmino -LRB- o grupo de t\u00e9rminos -RRB- un peso basado en la entrop\u00eda entre diferentes documentos y diferentes segmentos de documentos. Este enfoque no solo puede aumentar la contribuci\u00f3n de las palabras clave, sino que tambi\u00e9n puede disminuir el efecto de las palabras vac\u00edas comunes, las palabras ruidosas y las palabras vac\u00edas que dependen de documentos. Estas palabras son comunes en un documento. Muchos m\u00e9todos basados \u200b\u200ben la similitud de oraciones requieren que estas palabras se eliminen antes de poder realizar la segmentaci\u00f3n de temas -LSB- 15 -RSB-. Nuestros resultados en la Figura 3 muestran que las ponderaciones de t\u00e9rminos son \u00fatiles para la segmentaci\u00f3n y alineaci\u00f3n de temas de m\u00faltiples documentos. La principal contribuci\u00f3n de este art\u00edculo es que introduce un m\u00e9todo novedoso para la segmentaci\u00f3n de temas utilizando MI y muestra que este m\u00e9todo funciona mejor que los criterios utilizados anteriormente. Adem\u00e1s, hemos abordado el problema de la segmentaci\u00f3n y alineaci\u00f3n de temas en m\u00faltiples documentos, mientras que la mayor\u00eda de las investigaciones existentes se centraron en la segmentaci\u00f3n de documentos individuales. La segmentaci\u00f3n y alineaci\u00f3n de varios documentos puede utilizar informaci\u00f3n de documentos similares y mejora enormemente el rendimiento de la segmentaci\u00f3n de temas. Obviamente, nuestro enfoque puede manejar documentos \u00fanicos como un caso especial cuando no hay varios documentos disponibles. Puede detectar temas compartidos entre documentos para juzgar si son varios documentos sobre el mismo tema. Tambi\u00e9n presentamos el nuevo criterio de WMI basado en ponderaciones de t\u00e9rminos aprendidos de m\u00faltiples documentos similares, lo que puede mejorar a\u00fan m\u00e1s el rendimiento de la segmentaci\u00f3n de temas. Proponemos un algoritmo codicioso iterativo basado en programaci\u00f3n din\u00e1mica y demostramos que funciona bien en la pr\u00e1ctica. Parte de nuestro trabajo anterior se encuentra en -LSB- 24 -RSB-. El resto de este documento est\u00e1 organizado de la siguiente manera: en la Secci\u00f3n 2, revisamos el trabajo relacionado. La secci\u00f3n 3 contiene una formulaci\u00f3n del problema de la segmentaci\u00f3n de temas y la alineaci\u00f3n de m\u00faltiples documentos con agrupaci\u00f3n conjunta de t\u00e9rminos, una revisi\u00f3n del criterio de MI para la agrupaci\u00f3n y, finalmente, una introducci\u00f3n a WMI. En la Secci\u00f3n 4, primero proponemos el algoritmo codicioso iterativo de segmentaci\u00f3n y alineaci\u00f3n de temas con agrupaci\u00f3n conjunta de t\u00e9rminos, y luego describimos c\u00f3mo podemos optimizar el algoritmo Figura 1:Ilustraci\u00f3n de segmentaci\u00f3n y alineaci\u00f3n de varios documentos. programaci\u00f3n din\u00e1mica. En la Secci\u00f3n 5, se describen experimentos sobre segmentaci\u00f3n de un solo documento, detecci\u00f3n de temas compartidos y segmentaci\u00f3n de m\u00faltiples documentos, y se presentan y discuten los resultados para evaluar el rendimiento de nuestro algoritmo. Las conclusiones y algunas direcciones futuras del trabajo de investigaci\u00f3n se discuten en la Secci\u00f3n 6. 2. TRABAJO ANTERIOR El aprendizaje supervisado generalmente tiene un buen desempe\u00f1o, ya que aprende funciones de conjuntos de entrenamiento etiquetados. Sin embargo, a menudo obtener grandes conjuntos de capacitaci\u00f3n con etiquetas manuales en oraciones de documentos es prohibitivamente costoso, por lo que se desean enfoques no supervisados. Algunos enfoques tambi\u00e9n se centran en palabras clave como sugerencias de transiciones de tema -LSB- 11 -RSB-. Mientras que algunos m\u00e9todos existentes s\u00f3lo consideran informaci\u00f3n en documentos \u00fanicos -LSB- 6, 15 -RSB-, otros utilizan m\u00faltiples documentos -LSB- 16, 14 -RSB-. No hay muchos trabajos en la \u00faltima categor\u00eda, aunque se espera que el rendimiento de la segmentaci\u00f3n sea mejor con la utilizaci\u00f3n de informaci\u00f3n de m\u00faltiples documentos. Investigaciones anteriores estudiaron m\u00e9todos para encontrar temas compartidos -LSB- 16 -RSB- y segmentaci\u00f3n y resumen de temas entre solo un par de documentos -LSB- 14 -RSB-. La clasificaci\u00f3n y agrupaci\u00f3n de texts es un \u00e1rea de investigaci\u00f3n relacionada que clasifica documentos en grupos utilizando m\u00e9todos supervisados \u200b\u200b\u200b\u200bo no supervisados. Los criterios de estos enfoques se pueden utilizar en el tema de la segmentaci\u00f3n de temas. Algunos de esos m\u00e9todos se han extendido al \u00e1rea de segmentaci\u00f3n de temas, como PLSA -LSB- 5 -RSB- y entrop\u00eda m\u00e1xima -LSB- 7 -RSB-, pero hasta donde sabemos, no se ha estudiado el uso de MI para la segmentaci\u00f3n de temas. . 6. CONCLUSIONES Y TRABAJO FUTURO Propusimos un m\u00e9todo novedoso para la segmentaci\u00f3n y alineaci\u00f3n de temas de m\u00faltiples documentos basado en informaci\u00f3n mutua ponderada, que tambi\u00e9n puede manejar casos de un solo documento. Utilizamos programaci\u00f3n din\u00e1mica para optimizar nuestro algoritmo. Nuestro enfoque supera a todos los m\u00e9todos anteriores en casos de un solo documento. Adem\u00e1s, tambi\u00e9n demostramos que realizar la segmentaci\u00f3n entre varios documentos puede mejorar enormemente el rendimiento. Nuestros resultados tambi\u00e9n ilustraron que el uso de informaci\u00f3n mutua ponderada puede utilizar la informaci\u00f3n de m\u00faltiples documentos para alcanzar un mejor rendimiento. Solo probamos nuestro m\u00e9todo en conjuntos de datos limitados. Se deber\u00edan probar m\u00e1s conjuntos de datos, especialmente los complicados. Se deben comparar m\u00e1s m\u00e9todos anteriores. Adem\u00e1s, las segmentaciones naturales, como las de los p\u00e1rrafos, son sugerencias que pueden utilizarse para encontrar los l\u00edmites \u00f3ptimos. Tambi\u00e9n se puede considerar el aprendizaje supervisado.TRABAJO ANTERIOR El aprendizaje supervisado suele tener un buen rendimiento, ya que aprende funciones de conjuntos de entrenamiento etiquetados. Sin embargo, a menudo obtener grandes conjuntos de capacitaci\u00f3n con etiquetas manuales en oraciones de documentos es prohibitivamente costoso, por lo que se desean enfoques no supervisados. Algunos enfoques tambi\u00e9n se centran en palabras clave como sugerencias de transiciones de tema -LSB- 11 -RSB-. Mientras que algunos m\u00e9todos existentes s\u00f3lo consideran informaci\u00f3n en documentos \u00fanicos -LSB- 6, 15 -RSB-, otros utilizan m\u00faltiples documentos -LSB- 16, 14 -RSB-. No hay muchos trabajos en la \u00faltima categor\u00eda, aunque se espera que el rendimiento de la segmentaci\u00f3n sea mejor con la utilizaci\u00f3n de informaci\u00f3n de m\u00faltiples documentos. Investigaciones anteriores estudiaron m\u00e9todos para encontrar temas compartidos -LSB- 16 -RSB- y segmentaci\u00f3n y resumen de temas entre solo un par de documentos -LSB- 14 -RSB-. La clasificaci\u00f3n y agrupaci\u00f3n de texts es un \u00e1rea de investigaci\u00f3n relacionada que clasifica documentos en grupos utilizando m\u00e9todos supervisados \u200b\u200b\u200b\u200bo no supervisados. Los criterios de estos enfoques se pueden utilizar en el tema de la segmentaci\u00f3n de temas. Algunos de esos m\u00e9todos se han extendido al \u00e1rea de segmentaci\u00f3n de temas, como PLSA -LSB- 5 -RSB- y entrop\u00eda m\u00e1xima -LSB- 7 -RSB-, pero hasta donde sabemos, no se ha estudiado el uso de MI para la segmentaci\u00f3n de temas. . 6. CONCLUSIONES Y TRABAJO FUTURO Propusimos un m\u00e9todo novedoso para la segmentaci\u00f3n y alineaci\u00f3n de temas de m\u00faltiples documentos basado en informaci\u00f3n mutua ponderada, que tambi\u00e9n puede manejar casos de un solo documento. Utilizamos programaci\u00f3n din\u00e1mica para optimizar nuestro algoritmo. Nuestro enfoque supera a todos los m\u00e9todos anteriores en casos de un solo documento. Adem\u00e1s, tambi\u00e9n demostramos que realizar la segmentaci\u00f3n entre varios documentos puede mejorar enormemente el rendimiento. Nuestros resultados tambi\u00e9n ilustraron que el uso de informaci\u00f3n mutua ponderada puede utilizar la informaci\u00f3n de m\u00faltiples documentos para alcanzar un mejor rendimiento. Solo probamos nuestro m\u00e9todo en conjuntos de datos limitados. Se deber\u00edan probar m\u00e1s conjuntos de datos, especialmente los complicados. Se deben comparar m\u00e1s m\u00e9todos anteriores. Adem\u00e1s, las segmentaciones naturales, como las de los p\u00e1rrafos, son sugerencias que pueden utilizarse para encontrar los l\u00edmites \u00f3ptimos. Tambi\u00e9n se puede considerar el aprendizaje supervisado.TRABAJO ANTERIOR El aprendizaje supervisado suele tener un buen rendimiento, ya que aprende funciones de conjuntos de entrenamiento etiquetados. Sin embargo, a menudo obtener grandes conjuntos de capacitaci\u00f3n con etiquetas manuales en oraciones de documentos es prohibitivamente costoso, por lo que se desean enfoques no supervisados. Algunos enfoques tambi\u00e9n se centran en palabras clave como sugerencias de transiciones de tema -LSB- 11 -RSB-. Mientras que algunos m\u00e9todos existentes s\u00f3lo consideran informaci\u00f3n en documentos \u00fanicos -LSB- 6, 15 -RSB-, otros utilizan m\u00faltiples documentos -LSB- 16, 14 -RSB-. No hay muchos trabajos en la \u00faltima categor\u00eda, aunque se espera que el rendimiento de la segmentaci\u00f3n sea mejor con la utilizaci\u00f3n de informaci\u00f3n de m\u00faltiples documentos. Investigaciones anteriores estudiaron m\u00e9todos para encontrar temas compartidos -LSB- 16 -RSB- y segmentaci\u00f3n y resumen de temas entre solo un par de documentos -LSB- 14 -RSB-. La clasificaci\u00f3n y agrupaci\u00f3n de texts es un \u00e1rea de investigaci\u00f3n relacionada que clasifica documentos en grupos utilizando m\u00e9todos supervisados \u200b\u200b\u200b\u200bo no supervisados. Los criterios de estos enfoques se pueden utilizar en el tema de la segmentaci\u00f3n de temas. Algunos de esos m\u00e9todos se han extendido al \u00e1rea de segmentaci\u00f3n de temas, como PLSA -LSB- 5 -RSB- y entrop\u00eda m\u00e1xima -LSB- 7 -RSB-, pero hasta donde sabemos, no se ha estudiado el uso de MI para la segmentaci\u00f3n de temas. . 6. CONCLUSIONES Y TRABAJO FUTURO Propusimos un m\u00e9todo novedoso para la segmentaci\u00f3n y alineaci\u00f3n de temas de m\u00faltiples documentos basado en informaci\u00f3n mutua ponderada, que tambi\u00e9n puede manejar casos de un solo documento. Utilizamos programaci\u00f3n din\u00e1mica para optimizar nuestro algoritmo. Nuestro enfoque supera a todos los m\u00e9todos anteriores en casos de un solo documento. Adem\u00e1s, tambi\u00e9n demostramos que realizar la segmentaci\u00f3n entre varios documentos puede mejorar enormemente el rendimiento. Nuestros resultados tambi\u00e9n ilustraron que el uso de informaci\u00f3n mutua ponderada puede utilizar la informaci\u00f3n de m\u00faltiples documentos para alcanzar un mejor rendimiento. Solo probamos nuestro m\u00e9todo en conjuntos de datos limitados. Se deber\u00edan probar m\u00e1s conjuntos de datos, especialmente los complicados. Se deben comparar m\u00e1s m\u00e9todos anteriores. Adem\u00e1s, las segmentaciones naturales, como las de los p\u00e1rrafos, son sugerencias que pueden utilizarse para encontrar los l\u00edmites \u00f3ptimos. Tambi\u00e9n se puede considerar el aprendizaje supervisado.La clasificaci\u00f3n y agrupaci\u00f3n de texts es un \u00e1rea de investigaci\u00f3n relacionada que clasifica documentos en grupos utilizando m\u00e9todos supervisados \u200b\u200b\u200b\u200bo no supervisados. Los criterios de estos enfoques se pueden utilizar en el tema de la segmentaci\u00f3n de temas. Algunos de esos m\u00e9todos se han extendido al \u00e1rea de segmentaci\u00f3n de temas, como PLSA -LSB- 5 -RSB- y entrop\u00eda m\u00e1xima -LSB- 7 -RSB-, pero hasta donde sabemos, no se ha estudiado el uso de MI para la segmentaci\u00f3n de temas. . 6. CONCLUSIONES Y TRABAJO FUTURO Propusimos un m\u00e9todo novedoso para la segmentaci\u00f3n y alineaci\u00f3n de temas de m\u00faltiples documentos basado en informaci\u00f3n mutua ponderada, que tambi\u00e9n puede manejar casos de un solo documento. Utilizamos programaci\u00f3n din\u00e1mica para optimizar nuestro algoritmo. Nuestro enfoque supera a todos los m\u00e9todos anteriores en casos de un solo documento. Adem\u00e1s, tambi\u00e9n demostramos que realizar una segmentaci\u00f3n entre varios documentos puede mejorar enormemente el rendimiento. Nuestros resultados tambi\u00e9n ilustraron que el uso de informaci\u00f3n mutua ponderada puede utilizar la informaci\u00f3n de m\u00faltiples documentos para alcanzar un mejor rendimiento. Solo probamos nuestro m\u00e9todo en conjuntos de datos limitados. Se deber\u00edan probar m\u00e1s conjuntos de datos, especialmente los complicados. Se deben comparar m\u00e1s m\u00e9todos anteriores. Adem\u00e1s, las segmentaciones naturales, como las de los p\u00e1rrafos, son sugerencias que pueden utilizarse para encontrar los l\u00edmites \u00f3ptimos. Tambi\u00e9n se puede considerar el aprendizaje supervisado.La clasificaci\u00f3n y agrupaci\u00f3n de texts es un \u00e1rea de investigaci\u00f3n relacionada que clasifica documentos en grupos utilizando m\u00e9todos supervisados \u200b\u200b\u200b\u200bo no supervisados. Los criterios de estos enfoques se pueden utilizar en el tema de la segmentaci\u00f3n de temas. Algunos de esos m\u00e9todos se han extendido al \u00e1rea de segmentaci\u00f3n de temas, como PLSA -LSB- 5 -RSB- y entrop\u00eda m\u00e1xima -LSB- 7 -RSB-, pero hasta donde sabemos, no se ha estudiado el uso de MI para la segmentaci\u00f3n de temas. . 6. CONCLUSIONES Y TRABAJO FUTURO Propusimos un m\u00e9todo novedoso para la segmentaci\u00f3n y alineaci\u00f3n de temas de m\u00faltiples documentos basado en informaci\u00f3n mutua ponderada, que tambi\u00e9n puede manejar casos de un solo documento. Utilizamos programaci\u00f3n din\u00e1mica para optimizar nuestro algoritmo. Nuestro enfoque supera a todos los m\u00e9todos anteriores en casos de un solo documento. Adem\u00e1s, tambi\u00e9n demostramos que realizar la segmentaci\u00f3n entre varios documentos puede mejorar enormemente el rendimiento. Nuestros resultados tambi\u00e9n ilustraron que el uso de informaci\u00f3n mutua ponderada puede utilizar la informaci\u00f3n de m\u00faltiples documentos para alcanzar un mejor rendimiento. Solo probamos nuestro m\u00e9todo en conjuntos de datos limitados. Se deber\u00edan probar m\u00e1s conjuntos de datos, especialmente los complicados. Se deben comparar m\u00e1s m\u00e9todos anteriores. Adem\u00e1s, las segmentaciones naturales, como las de los p\u00e1rrafos, son sugerencias que pueden utilizarse para encontrar los l\u00edmites \u00f3ptimos. Tambi\u00e9n se puede considerar el aprendizaje supervisado.", "keyphrases": ["detectar tema", "pista", "segmento de tema", "informe local y secuencial del documento", "documento \u00fanico", "documento m\u00faltiple", "wmu", "compartir tema", "l\u00edmites \u00f3ptimos", "segmento de documento \u00fanico", "segmento de m\u00faltiples documentos", "t\u00e9rmino clave", "palabra parada", "peso del t\u00e9rmino", "realizaci\u00f3n del segmento tem\u00e1tico"]}
{"file_name": "I-6", "text": "Sem\u00e1ntica din\u00e1mica para lenguajes de comunicaci\u00f3n de agentes RESUMEN Este art\u00edculo propone la sem\u00e1ntica din\u00e1mica para lenguajes de comunicaci\u00f3n de agentes -LRB- ACLs -RRB- como un m\u00e9todo para abordar algunos de los problemas fundamentales asociados con la comunicaci\u00f3n de agentes en sistemas abiertos multiagente. Basado en la idea de proporcionar ``variantes'' sem\u00e1nticas alternativas para los actos de habla y reglas de transici\u00f3n entre ellos que dependen del comportamiento previo del agente, nuestro marco proporciona una noci\u00f3n mejorada de c\u00f3mo fundamentar la sem\u00e1ntica en la interacci\u00f3n en curso, un mecanismo simple para distinguir entre d\u00f3ciles y d\u00f3ciles. comportamiento esperado y una forma de especificar mecanismos de sanci\u00f3n y recompensa como parte de la propia ACL. Ampliamos un marco com\u00fan para la sem\u00e1ntica de ACL basada en compromisos para obtener estas propiedades, analizamos los deseos para el dise\u00f1o de sem\u00e1ntica din\u00e1mica concreta junto con ejemplos y analizamos sus propiedades. 1. INTRODUCCI\u00d3N El campo de la investigaci\u00f3n del lenguaje de comunicaci\u00f3n de agentes -LRB- ACL -RRB- ha estado plagado durante mucho tiempo de problemas de verificabilidad y conexi\u00f3n a tierra -LSB- 10, 13, 17 -RSB-. Incapaces de protegerse contra el abuso por parte de agentes maliciosos, enga\u00f1osos o que funcionan mal, la sem\u00e1ntica mentalista es inherentemente poco confiable e inapropiada para su uso en MAS abierto en el que agentes con objetivos potencialmente conflictivos podr\u00edan explotar deliberadamente las concepciones de la sem\u00e1ntica de mensajes de sus adversarios para provocar un determinado comportamiento. La sem\u00e1ntica basada en compromisos -LSB- 6, 8, 14 -RSB-, por otro lado, define el significado de los mensajes intercambiados entre agentes en t\u00e9rminos de compromisos p\u00fablicamente observables, es decir, promesas de provocar un estado de cosas o realizar ciertas acciones. . Esta sem\u00e1ntica resuelve el problema de la verificabilidad, ya que permite rastrear el estado de los compromisos existentes en cualquier momento dados los mensajes y acciones observados, de modo que cualquier observador pueda, por ejemplo, establecer si un agente ha realizado una acci\u00f3n prometida. Adem\u00e1s, esto implica que la especificaci\u00f3n sem\u00e1ntica no proporciona una interfaz para los mecanismos de deliberaci\u00f3n y planificaci\u00f3n de los agentes y, por lo tanto, no est\u00e1 claro c\u00f3mo los agentes racionales podr\u00edan decidir si suscribirse a una sem\u00e1ntica de ACL sugerida cuando se implemente. Finalmente, ninguno de los enfoques existentes permite que la ACL especifique c\u00f3mo responder a una violaci\u00f3n de su sem\u00e1ntica por parte de agentes individuales. En segundo lugar, los enfoques existentes no logran explotar las posibilidades de sancionar y recompensar ciertos comportamientos de una manera inherente a la comunicaci\u00f3n modificando el significado futuro de los mensajes pronunciados o recibidos por agentes complacientes/desviados. En este art\u00edculo, proponemos la sem\u00e1ntica din\u00e1mica -LRB- DSs -RRB- para ACL como soluci\u00f3n a estos problemas. Nuestra noci\u00f3n de DS se basa en la idea muy simple de definir diferentes alternativas para el significado de actos de habla individuales -LRB-, las llamadas variantes sem\u00e1nticas -RRB- en una especificaci\u00f3n sem\u00e1ntica de ACL, y reglas de transici\u00f3n entre estados sem\u00e1nticos -LRB- es decircolecciones de variantes para diferentes actos de habla -RRB- que describen el significado actual de la ACL. Estos elementos tomados en conjunto dan como resultado una vista similar a FSM de las especificaciones de ACL, donde cada estado individual proporciona una sem\u00e1ntica de ACL completa y las transiciones de estado se activan mediante el comportamiento observado del agente para -LRB- 1 -RRB- reflejar expectativas futuras basadas en experiencias de interacci\u00f3n previas. y -LRB- 2 -RRB- sancionar o recompensar ciertos tipos de comportamiento. Al definir un marco DS para ACL basadas en compromisos, este documento hace tres contribuciones: 1. Una extensi\u00f3n de la sem\u00e1ntica de ACL basada en compromisos para proporcionar una noci\u00f3n mejorada de los compromisos b\u00e1sicos en la interacci\u00f3n de agentes y permitir que las especificaciones de ACL se utilicen directamente para la planificaci\u00f3n. Toma de decisiones racional basada en 2. Una forma sencilla de distinguir entre comportamiento conforme y esperado con respecto a una especificaci\u00f3n de ACL que permite razonar sobre el comportamiento potencial de los agentes puramente desde una perspectiva sem\u00e1ntica de ACL. 3. Un mecanismo para especificar c\u00f3mo evoluciona el significado con el comportamiento del agente y c\u00f3mo esto puede usarse para describir mecanismos de sanci\u00f3n y recompensa inherentes a la comunicaci\u00f3n, esenciales para el dise\u00f1o de MAS abiertos. Adem\u00e1s, discutimos los desiderata para el dise\u00f1o de DS que pueden derivarse de nuestra marco, presentar ejemplos y analizar sus propiedades. El resto de este art\u00edculo est\u00e1 estructurado de la siguiente manera: La Secci\u00f3n 2 presenta un marco formal para la sem\u00e1ntica din\u00e1mica de ACL. En la secci\u00f3n 3 presentamos un an\u00e1lisis y discusi\u00f3n de este marco y discutimos los deseos para el dise\u00f1o de ACL con sem\u00e1ntica din\u00e1mica. La secci\u00f3n 4 revisa enfoques relacionados y la secci\u00f3n 5 concluye. 4. TRABAJOS RELACIONADOS El razonamiento basado en expectativas sobre la interacci\u00f3n fue propuesto por primera vez en -LSB- 2 -RSB-, considerando la evoluci\u00f3n de las expectativas descritas como expectativas probabil\u00edsticas de comunicaci\u00f3n y secuencias de acci\u00f3n. Los mismos autores sugirieron un marco m\u00e1s general para la sem\u00e1ntica de la comunicaci\u00f3n basada en expectativas -LSB- 9 -RSB-, y defienden una visi\u00f3n \"consecuencialista\" de la sem\u00e1ntica que se basa en definir el significado de los enunciados en t\u00e9rminos de sus consecuencias esperadas y actualizando estas expectativas con nuevas observaciones -LSB- 11 -RSB-. Sin embargo, su enfoque no utiliza una noci\u00f3n expl\u00edcita de compromisos que en nuestro marco media entre la comunicaci\u00f3n y la base basada en el comportamiento, y proporciona una distinci\u00f3n clara entre una noci\u00f3n normativa de cumplimiento y una noci\u00f3n m\u00e1s emp\u00edrica de expectativa. La base para la sem\u00e1ntica -LRB- mentalista -RRB- ACL se ha investigado en -LSB- 7 -RSB- donde la informaci\u00f3n fundamentada se ve como \"informaci\u00f3n que se expresa p\u00fablicamente y se acepta como verdadera por todos los agentes que participan en una conversaci\u00f3n\". .Al igual que -LSB- 1 -RSB- -LRB- que basa la noci\u00f3n de \"expresado p\u00fablicamente\" en roles m\u00e1s que en estados internos de los agentes -RRB-, la principal preocupaci\u00f3n de estos autores es proporcionar una base verificable para determinar la sem\u00e1ntica de lo expresado. estados mentales y compromisos. 11 En un sentido no trivial, es decir, cuando algunas transiciones iniciales son posibles en principio 106 The Sixth Intl.. Joint Conf. Nuestro marco tambi\u00e9n est\u00e1 relacionado con m\u00e9todos de\u00f3nticos para la especificaci\u00f3n de obligaciones, normas y sanciones. En esta \u00e1rea, -LSB- 16 -RSB- es el \u00fanico marco que conocemos que considera obligaciones, normas y sanciones din\u00e1micas. Sin embargo, como hemos descrito anteriormente, utilizamos \u00fanicamente la evoluci\u00f3n sem\u00e1ntica como mecanismo de sanci\u00f3n y recompensa, es decir, a diferencia de este trabajo, no asumimos que los agentes puedan ser castigados o recompensados \u200b\u200bdirectamente. 5. CONCLUSI\u00d3N Este art\u00edculo presenta la sem\u00e1ntica din\u00e1mica para las ACL como un m\u00e9todo para abordar algunos problemas fundamentales de la comunicaci\u00f3n de agentes en sistemas abiertos, siendo la idea subyacente simple que diferentes cursos de comportamiento de los agentes pueden dar lugar a diferentes interpretaciones del significado de los mensajes intercambiados entre ellos. agentes. Bas\u00e1ndonos en un marco com\u00fan de sem\u00e1ntica basada en compromisos, presentamos una noci\u00f3n de fundamento para los compromisos basada en nociones de comportamiento cumplido y esperado. Luego definimos la sem\u00e1ntica din\u00e1mica como sistemas de transici\u00f3n de estados sobre diferentes estados sem\u00e1nticos que pueden verse como diferentes \"versiones\" de la sem\u00e1ntica de ACL en el sentido tradicional, y pueden asociarse f\u00e1cilmente con una visi\u00f3n del razonamiento sobre la comunicaci\u00f3n basada en la planificaci\u00f3n. Por lo tanto, nuestro enfoque se centr\u00f3 en la simplicidad y en proporcionar mecanismos para rastrear la evoluci\u00f3n sem\u00e1ntica de una manera algor\u00edtmica \"con los pies en la tierra\" para garantizar la aplicabilidad a muchos dise\u00f1os de agentes diferentes. Discutimos las propiedades de nuestro marco que muestra c\u00f3mo se puede utilizar como un poderoso mecanismo inherente a la comunicaci\u00f3n para recompensar y sancionar el comportamiento de los agentes en sistemas abiertos sin comprometer la autonom\u00eda del agente, discutimos su integraci\u00f3n con los procesos de planificaci\u00f3n de los agentes, los problemas de complejidad y presentamos una lista. de desiderata para el dise\u00f1o de ACL con dicha sem\u00e1ntica.la simple idea subyacente es que diferentes cursos de comportamiento de los agentes pueden dar lugar a diferentes interpretaciones del significado de los mensajes intercambiados entre los agentes. Bas\u00e1ndonos en un marco com\u00fan de sem\u00e1ntica basada en compromisos, presentamos una noci\u00f3n de fundamento para los compromisos basada en nociones de comportamiento cumplido y esperado. Luego definimos la sem\u00e1ntica din\u00e1mica como sistemas de transici\u00f3n de estados sobre diferentes estados sem\u00e1nticos que pueden verse como diferentes \"versiones\" de la sem\u00e1ntica de ACL en el sentido tradicional, y pueden asociarse f\u00e1cilmente con una visi\u00f3n del razonamiento sobre la comunicaci\u00f3n basada en la planificaci\u00f3n. Por lo tanto, nuestro enfoque se centr\u00f3 en la simplicidad y en proporcionar mecanismos para rastrear la evoluci\u00f3n sem\u00e1ntica de una manera algor\u00edtmica \"con los pies en la tierra\" para garantizar la aplicabilidad a muchos dise\u00f1os de agentes diferentes. Discutimos las propiedades de nuestro marco que muestra c\u00f3mo se puede utilizar como un poderoso mecanismo inherente a la comunicaci\u00f3n para recompensar y sancionar el comportamiento de los agentes en sistemas abiertos sin comprometer la autonom\u00eda del agente, discutimos su integraci\u00f3n con los procesos de planificaci\u00f3n de los agentes, los problemas de complejidad y presentamos una lista. de desiderata para el dise\u00f1o de ACL con dicha sem\u00e1ntica.la simple idea subyacente es que diferentes cursos de comportamiento de los agentes pueden dar lugar a diferentes interpretaciones del significado de los mensajes intercambiados entre los agentes. Bas\u00e1ndonos en un marco com\u00fan de sem\u00e1ntica basada en compromisos, presentamos una noci\u00f3n de fundamento para los compromisos basada en nociones de comportamiento cumplido y esperado. Luego definimos la sem\u00e1ntica din\u00e1mica como sistemas de transici\u00f3n de estados sobre diferentes estados sem\u00e1nticos que pueden verse como diferentes \"versiones\" de la sem\u00e1ntica de ACL en el sentido tradicional, y pueden asociarse f\u00e1cilmente con una visi\u00f3n del razonamiento sobre la comunicaci\u00f3n basada en la planificaci\u00f3n. Por lo tanto, nuestro enfoque se centr\u00f3 en la simplicidad y en proporcionar mecanismos para rastrear la evoluci\u00f3n sem\u00e1ntica de una manera algor\u00edtmica \"con los pies en la tierra\" para garantizar la aplicabilidad a muchos dise\u00f1os de agentes diferentes. Discutimos las propiedades de nuestro marco que muestra c\u00f3mo se puede utilizar como un poderoso mecanismo inherente a la comunicaci\u00f3n para recompensar y sancionar el comportamiento de los agentes en sistemas abiertos sin comprometer la autonom\u00eda del agente, discutimos su integraci\u00f3n con los procesos de planificaci\u00f3n de los agentes, los problemas de complejidad y presentamos una lista. de desiderata para el dise\u00f1o de ACL con dicha sem\u00e1ntica.", "keyphrases": ["agente lenguaje com\u00fan", "sem\u00e1ntico din\u00e1mico", "raz\u00f3n social", "sem\u00e1ntico de base de compromiso", "sistema de tr\u00e1nsito estatal", "adaptar la base de reputaci\u00f3n", "mutuo de expectativa", "mecanico de recuperacion", "no redundante"]}
{"file_name": "J-13", "text": "Sobre la complejidad de las subastas combinatorias: gr\u00e1ficos de art\u00edculos estructurados y descomposiciones de hiper\u00e1rbol RESUMEN El problema de determinaci\u00f3n del ganador en las subastas combinatorias es el problema de determinar la asignaci\u00f3n de los art\u00edculos entre los postores que maximiza la suma de los precios de oferta aceptados. Si bien este problema es en general NPhard, se sabe que es factible en tiempo polin\u00f3mico en aquellas instancias cuyos gr\u00e1ficos de elementos asociados tienen un ancho de \u00e1rbol acotado -LRB- llamados gr\u00e1ficos de elementos estructurados -RRB-. Formalmente, un gr\u00e1fico de art\u00edculos es un gr\u00e1fico cuyos nodos est\u00e1n en correspondencia uno a uno con los art\u00edculos, y los bordes son tales que, para cualquier oferta, los art\u00edculos que aparecen en \u00e9l inducen un subgrafo conectado. Tenga en cuenta que muchos gr\u00e1ficos de art\u00edculos pueden estar asociados con una subasta combinatoria determinada, dependiendo de los bordes seleccionados para garantizar la conectividad. De hecho, la viabilidad de determinar si existe un gr\u00e1fico de elementos estructurado de un ancho de \u00e1rbol fijo -LRB- y, de ser as\u00ed, calcular uno -RRB- qued\u00f3 como un problema abierto crucial. En este art\u00edculo, resolvemos este problema demostrando que la existencia de un gr\u00e1fico de elementos estructurado es computacionalmente intratable, incluso para un ancho de \u00e1rbol de 3. Motivados por esta mala noticia, investigamos diferentes tipos de requisitos estructurales que pueden usarse para aislar clases manejables de combinatorios. subastas. Mostramos que la noci\u00f3n de descomposici\u00f3n de hiper\u00e1rbol, una medida recientemente introducida de la ciclicidad del hipergr\u00e1fico, resulta ser m\u00e1s \u00fatil aqu\u00ed. De hecho, mostramos que el problema de determinaci\u00f3n del ganador se puede resolver en tiempo polin\u00f3mico en instancias cuyas interacciones con el postor se pueden representar con hipergr\u00e1ficos -LRB- duales -RRB- que tienen un ancho de hiper\u00e1rbol acotado. A\u00fan m\u00e1s sorprendente, mostramos que la clase de instancias manejables identificadas mediante nuestro enfoque contiene adecuadamente la clase de instancias que tienen un gr\u00e1fico de elementos estructurado. 1. INTRODUCCI\u00d3N Subastas combinatorias. Las subastas combinatorias son mecanismos bien conocidos para la asignaci\u00f3n de recursos y tareas en los que los postores pueden ofertar simult\u00e1neamente por combinaciones de art\u00edculos. Esto es deseable cuando la valoraci\u00f3n de un postor de un conjunto de art\u00edculos no es igual a la suma de sus valoraciones de los art\u00edculos individuales. Un resultado para -LRB- Z, B -RRB- es un subconjunto b de B tal que el \u00edtem -LRB- Bi -RRB- n \u00edtem -LRB- Bj -RRB- = 0, para cada par Bi y Bj de ofertas en b con i = ~ j. El problema de la determinaci\u00f3n del ganador. Un problema crucial para las subastas combinatorias es determinar el resultado b \u2217 que maximice la suma de los precios de oferta aceptados -LRB- es decir, Bi \u2208 b \u2217 paga -LRB- Bi -RRB- -RRB- sobre todos los resultados posibles. Se sabe que este problema, llamado problema de determinaci\u00f3n del ganador -LRB-, por ejemplo, -LSB- 11 -RSB- -RRB-, es intratable, en realidad NP-dif\u00edcil -LSB- 17 -RSB-, e incluso no es aproximable en tiempo polinomial a menos que NP = ZPP -LSB- 19 -RSB-. Por lo tanto, no sorprende que se hayan realizado varios esfuerzos para dise\u00f1ar algoritmos pr\u00e1cticamente eficientes para subastas generales -LRB-, por ejemplo, -LSB- 20, 5, 2, 8,23 -RSB- -RRB- e identificar clases de instancias donde resolver el problema de determinaci\u00f3n del ganador es factible en tiempo polin\u00f3mico -LRB-, por ejemplo, -LSB- 15, 22, 12, 21 -RSB- -RRB-. De hecho, se demostr\u00f3 que restringir la interacci\u00f3n de los postores es \u00fatil para identificar clases de subastas combinatorias manejables. Gr\u00e1ficos de art\u00edculos. Actualmente, la clase m\u00e1s general de subastas combinatorias manejables se ha distinguido modelando las interacciones entre los postores con la noci\u00f3n de gr\u00e1fico de art\u00edculos, que es un gr\u00e1fico cuyos nodos est\u00e1n en correspondencia uno a uno con los art\u00edculos, y los bordes son tales que para cualquier Figura 1: Ejemplo de problema MaxWSP: -LRB- a -RRB- Hipergrafo H -LRB- Para, vaya -RRB- y un paquete h para ello; -LRB- b -RRB- Gr\u00e1fico primario para H -LRB- Para, vaya -RRB- ; y, -LRB- c, d -RRB- Gr\u00e1ficos de dos elementos para H -LRB- Para, vaya -RRB-. oferta, los elementos que aparecen en \u00e9l inducen un subgrafo conectado. De hecho, se demostr\u00f3 que el problema de determinaci\u00f3n del ganador puede resolverse en tiempo polin\u00f3mico si las interacciones entre los postores pueden representarse mediante un gr\u00e1fico de elementos estructurado, es decir, un \u00e1rbol o, m\u00e1s generalmente, un gr\u00e1fico con una estructura similar a un \u00e1rbol -LSB- 3 - RSB- -- ancho de \u00e1rbol formalmente delimitado -LSB- 16 -RSB-. Para tener alguna intuici\u00f3n sobre c\u00f3mo se pueden construir gr\u00e1ficos de art\u00edculos, observamos que la interacci\u00f3n del postor en una subasta combinatoria ~ I, B ~ se puede representar mediante un hipergr\u00e1fico H -LRB- T, g -RRB- tal que su conjunto de nodos N -LRB- H -LRB- T, g -RRB- -RRB- coincide con el conjunto de \u00edtems I, y donde sus aristas E -LRB- H -LRB- T, g -RRB- -RRB- son precisamente las pujas de los compradores -LCB- art\u00edculo -LRB- Bi -RRB- | Bi \u2208 B -RCB-. Un gr\u00e1fico de elemento especial para ~ I, B ~ es el gr\u00e1fico primario de H -LRB- T, g -RRB-, denotado por G -LRB- H -LRB- T, g -RRB- -RRB-, que contiene una arista entre cualquier par de nodos en alg\u00fan hiperborde de H -LRB- T, g -RRB-. Entonces, cualquier gr\u00e1fico de elementos para H -LRB- T, g -RRB- puede verse como una simplificaci\u00f3n de G -LRB- H -LRB- T, g -RRB- -RRB- obtenida eliminando algunos bordes, pero preservando la conectividad. condici\u00f3n en los nodos incluidos en cada hiperborde. EJEMPLO 1. El hipergrafo H -LRB- To, go -RRB- reportado en la Figura 1. -LRB- a -RRB- es una codificaci\u00f3n para una subasta combinatoria ~I0, B0~, donde I0 = -LCB- I1,.. ., I5 -RCB-, y el \u00edtem -LRB- Bi -RRB- = hi, para cada 1 \u2264 i \u2264 3. La gr\u00e1fica primaria para H -LRB- To, go -RRB- se reporta en la Figura 1. -LRB- b -RRB-, mientras que en la Figura 1 se muestran dos gr\u00e1ficos de elementos de ejemplo. -LRB- c -RRB- y -LRB- d -RRB-, donde los bordes necesarios para mantener la conectividad para h1 se representan en negrita. <Problema abierto: Calcular gr\u00e1ficos de elementos estructurados de manera eficiente. El resultado de trazabilidad mencionado anteriormente en gr\u00e1ficos de elementos estructurados resulta \u00fatil en la pr\u00e1ctica s\u00f3lo cuando se proporciona un gr\u00e1fico de elementos estructurados o se puede determinar de manera eficiente. Sin embargo, exponencialmente muchos gr\u00e1ficos de art\u00edculos podr\u00edan estar asociados con una subasta combinatoria, y no est\u00e1 claro c\u00f3mo determinar si existe un gr\u00e1fico de art\u00edculos estructurado de un determinado ancho de \u00e1rbol -LRB- constante -RRB- y, de ser as\u00ed,c\u00f3mo calcular eficientemente un gr\u00e1fico de elementos tan estructurado. Embalaje del juego ponderado. Notemos que la representaci\u00f3n hipergr\u00e1fica H -LRB- T, g -RRB- de una subasta combinatoria ~ I, B ~ tambi\u00e9n es \u00fatil para aclarar la analog\u00eda entre el problema de determinaci\u00f3n del ganador y el problema de empaquetamiento de conjuntos ponderados m\u00e1ximos en hipergraf\u00edas - LRB- por ejemplo, -LSB- 17 -RSB- -RRB-. Formalmente, un empaquetamiento h para un hipergrafo H es un conjunto de hiperbordes de H tal que para cada par h, h ' \u2208 h con h = ~ h ', se cumple que h \u2229 h ' = \u2205. Entonces, el conjunto de soluciones para el problema de empaquetamiento de conjuntos ponderados para H -LRB- T, g -RRB- wrt w -LRB- T, g -RRB- coincide con el conjunto de soluciones para el problema de determinaci\u00f3n del ganador en ~ I , B ~. EJEMPLO 2. Considere nuevamente el hipergrafo H -LRB- A, vaya -RRB- reportado en la Figura 1. -LRB- a -RRB-. Un ejemplo de empaque para H -LRB- To, go -RRB- es h = -LCB- h1 -RCB-, que intuitivamente corresponde a un resultado para ~I0, B0~, donde el subastador acept\u00f3 la oferta B1. De hecho, el embalaje Contribuciones El objetivo principal de este art\u00edculo es identificar grandes clases manejables para el problema de determinaci\u00f3n del ganador, que adem\u00e1s sean polin\u00f3micamente reconocibles. Con este objetivo, primero estudiamos gr\u00e1ficos de elementos estructurados y resolvemos el problema abierto en -LSB- 3 -RSB-. El resultado es una muy mala noticia: \u25ba Es NP completo comprobar si una subasta combinatoria tiene un gr\u00e1fico de elementos estructurado de ancho de \u00e1rbol 3. M\u00e1s formalmente, sea C -LRB- ig, k -RRB- la clase de todos los hipergr\u00e1ficos que tienen un \u00e1rbol de elementos de ancho de \u00e1rbol acotado por k, demostramos que decidir si un hipergrafo -LRB- asociado con un problema de subasta combinatoria -RRB- pertenece a C -LRB- ig, 3 -RRB- es NP-completo. A la luz de este resultado, era crucial evaluar si existen otros tipos de requisitos estructurales que puedan verificarse en tiempo polin\u00f3mico y que a\u00fan puedan usarse para aislar clases manejables del problema de empaquetamiento de conjunto ponderado m\u00e1ximo o, de manera equivalente, el ganador. problema de determinaci\u00f3n. E -LRB- H -RRB- -RCB- est\u00e1 en E. Mostramos que MaxWSP es manejable en la clase de aquellas instancias cuyos hipergrafos duales tienen un ancho de hiper\u00e1rbol -LSB- 7 -RSB- limitado por k -LRB- corto: clase C -LRB- hw, k -RRB- de hipergrafos -RRB-. Tenga en cuenta que una cuesti\u00f3n clave de la manejabilidad es considerar el ancho del hiper\u00e1rbol del hipergrafo dual H \u00af en lugar del hipergrafo de subasta H. De hecho, podemos demostrar que MaxWSP sigue siendo NP-duro incluso cuando H es ac\u00edclico -LRB-, es decir, cuando tiene un ancho de hiper\u00e1rbol 1 -RRB-, incluso cuando cada nodo est\u00e1 contenido en 3 hiperaristas como m\u00e1ximo. \u25ba Para algunas clases especiales relevantes de hipergr\u00e1ficos en C -LRB- hw, k -RRB-, dise\u00f1amos un algoritmo altamente paralelizable para MaxWSP. Recordemos, de hecho, que LOGCFL es la clase de problemas de decisi\u00f3n que son espacios de registro reducibles a lenguajes libres de context, y que LOGCFL C _ NC2 C _ P -LRB- v\u00e9ase, por ejemplo, -LSB- 9 -RSB- -RRB-. \u25ba Sorprendentemente,Mostramos que no se pierde nada en t\u00e9rminos de generalidad al considerar la descomposici\u00f3n en hiper\u00e1rbol de hipergr\u00e1ficos duales en lugar del ancho de \u00e1rbol de los gr\u00e1ficos de elementos. Por el contrario, el m\u00e9todo de descomposici\u00f3n basado en hiper\u00e1rbol propuesto es estrictamente m\u00e1s general que el m\u00e9todo de gr\u00e1ficos de elementos estructurados. De hecho, mostramos que clases de instancias estrictamente m\u00e1s grandes son manejables seg\u00fan nuestro nuevo enfoque que seg\u00fan el enfoque de gr\u00e1ficos de elementos estructurados. Intuitivamente, la dureza NP de reconocer gr\u00e1ficos de elementos estructurados de ancho acotado no se debe a su gran generalidad, sino a algunas peculiaridades en su definici\u00f3n. \u25ba La prueba de los resultados anteriores nos brinda una visi\u00f3n interesante de la noci\u00f3n de gr\u00e1fico de elementos estructurados. De hecho, mostramos que los gr\u00e1ficos de elementos estructurados est\u00e1n en correspondencia uno a uno con algunos tipos especiales de descomposici\u00f3n de hiper\u00e1rbol del hipergrafo dual, que llamamos descomposiciones de hiper\u00e1rbol estrictas. El resto del documento est\u00e1 organizado de la siguiente manera. La secci\u00f3n 2 analiza la intratabilidad de los gr\u00e1ficos de elementos estructurados. La Secci\u00f3n 3 presenta el algoritmo de tiempo polinomial para resolver MaxWSP en la clase de aquellas instancias cuyos hipergrafos duales tienen un ancho de hiper\u00e1rbol acotado, y analiza los casos en los que el algoritmo tambi\u00e9n es altamente paralelizable. La comparaci\u00f3n entre las clases C -LRB- ig, k -RRB- y C -LRB- hw, k -RRB- se analiza en la Secci\u00f3n 4. Finalmente, en la Secci\u00f3n 5 sacamos nuestras conclusiones al delinear tambi\u00e9n direcciones para futuras investigaciones. 5. CONCLUSIONES Hemos resuelto la cuesti\u00f3n abierta de determinar la complejidad de calcular un gr\u00e1fico de art\u00edculos estructurado asociado a un escenario de subasta combinatoria. El resultado es una mala noticia, ya que result\u00f3 que es NP-completo verificar si una subasta combinatoria tiene un gr\u00e1fico de art\u00edculos estructurado, incluso para un ancho de \u00e1rbol de 3. Motivados por este resultado, investigamos el uso de la descomposici\u00f3n de hiper\u00e1rbol -LRB- en el Hipergrafo dual asociado con el escenario -RRB- y demostramos que el problema es manejable en la clase de aquellas instancias cuyos hipergrafos duales tienen un ancho de hiper\u00e1rbol acotado. Para algunos casos especiales, aunque relevantes, tambi\u00e9n se analiza un algoritmo altamente paralelizable. Curiosamente, tambi\u00e9n surgi\u00f3 que la clase de gr\u00e1ficos de elementos estructurados est\u00e1 contenida adecuadamente en la clase de instancias que tienen un ancho de hiper\u00e1rbol acotado -LRB-, por lo tanto, la raz\u00f3n de su intratabilidad no es su generalidad -RRB-. En particular, este \u00faltimo resultado se establece mostrando una relaci\u00f3n precisa entre gr\u00e1ficos de elementos estructurados y formas restringidas de descomposiciones de hiper\u00e1rbol -LRB- en el hipergrafo dual -RRB-, llamadas descomposiciones de consulta -LRB- ver, por ejemplo, -LSB- 7 -RSB - -RRB-. A la luz de esta observaci\u00f3n, observamos que demostrar algunos resultados de aproximabilidad para gr\u00e1ficos de elementos estructurados requiere una comprensi\u00f3n profunda de la aproximabilidad de las descomposiciones de consultas, que actualmente falta en la literatura.El m\u00e9todo de descomposici\u00f3n basado en hiper\u00e1rbol propuesto es estrictamente m\u00e1s general que el m\u00e9todo de gr\u00e1ficos de elementos estructurados. De hecho, mostramos que clases de instancias estrictamente m\u00e1s grandes son manejables seg\u00fan nuestro nuevo enfoque que seg\u00fan el enfoque de gr\u00e1ficos de elementos estructurados. Intuitivamente, la dureza NP de reconocer gr\u00e1ficos de elementos estructurados de ancho acotado no se debe a su gran generalidad, sino a algunas peculiaridades en su definici\u00f3n. \u25ba La prueba de los resultados anteriores nos brinda una visi\u00f3n interesante de la noci\u00f3n de gr\u00e1fico de elementos estructurados. De hecho, mostramos que los gr\u00e1ficos de elementos estructurados est\u00e1n en correspondencia uno a uno con algunos tipos especiales de descomposici\u00f3n de hiper\u00e1rbol del hipergrafo dual, que llamamos descomposiciones de hiper\u00e1rbol estrictas. El resto del documento est\u00e1 organizado de la siguiente manera. La secci\u00f3n 2 analiza la intratabilidad de los gr\u00e1ficos de elementos estructurados. La Secci\u00f3n 3 presenta el algoritmo de tiempo polinomial para resolver MaxWSP en la clase de aquellas instancias cuyos hipergrafos duales tienen un ancho de hiper\u00e1rbol acotado, y analiza los casos en los que el algoritmo tambi\u00e9n es altamente paralelizable. La comparaci\u00f3n entre las clases C -LRB- ig, k -RRB- y C -LRB- hw, k -RRB- se analiza en la Secci\u00f3n 4. Finalmente, en la Secci\u00f3n 5 sacamos nuestras conclusiones al delinear tambi\u00e9n direcciones para futuras investigaciones. 5. CONCLUSIONES Hemos resuelto la cuesti\u00f3n abierta de determinar la complejidad de calcular un gr\u00e1fico de art\u00edculos estructurado asociado a un escenario de subasta combinatoria. El resultado es una mala noticia, ya que result\u00f3 que es NP-completo verificar si una subasta combinatoria tiene un gr\u00e1fico de art\u00edculos estructurado, incluso para un ancho de \u00e1rbol de 3. Motivados por este resultado, investigamos el uso de la descomposici\u00f3n de hiper\u00e1rbol -LRB- en el Hipergrafo dual asociado con el escenario -RRB- y demostramos que el problema es manejable en la clase de aquellas instancias cuyos hipergrafos duales tienen un ancho de hiper\u00e1rbol acotado. Para algunos casos especiales, aunque relevantes, tambi\u00e9n se analiza un algoritmo altamente paralelizable. Curiosamente, tambi\u00e9n surgi\u00f3 que la clase de gr\u00e1ficos de elementos estructurados est\u00e1 contenida adecuadamente en la clase de instancias que tienen un ancho de hiper\u00e1rbol acotado -LRB-, por lo tanto, la raz\u00f3n de su intratabilidad no es su generalidad -RRB-. En particular, este \u00faltimo resultado se establece mostrando una relaci\u00f3n precisa entre gr\u00e1ficos de elementos estructurados y formas restringidas de descomposiciones de hiper\u00e1rbol -LRB- en el hipergrafo dual -RRB-, llamadas descomposiciones de consulta -LRB- ver, por ejemplo, -LSB- 7 -RSB - -RRB-. A la luz de esta observaci\u00f3n, observamos que demostrar algunos resultados de aproximabilidad para gr\u00e1ficos de elementos estructurados requiere una comprensi\u00f3n profunda de la aproximabilidad de las descomposiciones de consultas, que actualmente falta en la literatura.El m\u00e9todo de descomposici\u00f3n basado en hiper\u00e1rbol propuesto es estrictamente m\u00e1s general que el m\u00e9todo de gr\u00e1ficos de elementos estructurados. De hecho, mostramos que clases de instancias estrictamente m\u00e1s grandes son manejables seg\u00fan nuestro nuevo enfoque que seg\u00fan el enfoque de gr\u00e1ficos de elementos estructurados. Intuitivamente, la dureza NP de reconocer gr\u00e1ficos de elementos estructurados de ancho acotado no se debe a su gran generalidad, sino a algunas peculiaridades en su definici\u00f3n. \u25ba La prueba de los resultados anteriores nos brinda una visi\u00f3n interesante de la noci\u00f3n de gr\u00e1fico de elementos estructurados. De hecho, mostramos que los gr\u00e1ficos de elementos estructurados est\u00e1n en correspondencia uno a uno con algunos tipos especiales de descomposici\u00f3n de hiper\u00e1rbol del hipergrafo dual, que llamamos descomposiciones de hiper\u00e1rbol estrictas. El resto del documento est\u00e1 organizado de la siguiente manera. La secci\u00f3n 2 analiza la intratabilidad de los gr\u00e1ficos de elementos estructurados. La Secci\u00f3n 3 presenta el algoritmo de tiempo polinomial para resolver MaxWSP en la clase de aquellas instancias cuyos hipergrafos duales tienen un ancho de hiper\u00e1rbol acotado, y analiza los casos en los que el algoritmo tambi\u00e9n es altamente paralelizable. La comparaci\u00f3n entre las clases C -LRB- ig, k -RRB- y C -LRB- hw, k -RRB- se analiza en la Secci\u00f3n 4. Finalmente, en la Secci\u00f3n 5 sacamos nuestras conclusiones al delinear tambi\u00e9n direcciones para futuras investigaciones. 5. CONCLUSIONES Hemos resuelto la cuesti\u00f3n abierta de determinar la complejidad de calcular un gr\u00e1fico de art\u00edculos estructurado asociado a un escenario de subasta combinatoria. El resultado es una mala noticia, ya que result\u00f3 que es NP-completo verificar si una subasta combinatoria tiene un gr\u00e1fico de art\u00edculos estructurado, incluso para un ancho de \u00e1rbol de 3. Motivados por este resultado, investigamos el uso de la descomposici\u00f3n de hiper\u00e1rbol -LRB- en el Hipergrafo dual asociado con el escenario -RRB- y demostramos que el problema es manejable en la clase de aquellas instancias cuyos hipergrafos duales tienen un ancho de hiper\u00e1rbol acotado. Para algunos casos especiales, aunque relevantes, tambi\u00e9n se analiza un algoritmo altamente paralelizable. Curiosamente, tambi\u00e9n surgi\u00f3 que la clase de gr\u00e1ficos de elementos estructurados est\u00e1 contenida adecuadamente en la clase de instancias que tienen un ancho de hiper\u00e1rbol acotado -LRB-, por lo tanto, la raz\u00f3n de su intratabilidad no es su generalidad -RRB-. En particular, este \u00faltimo resultado se establece mostrando una relaci\u00f3n precisa entre gr\u00e1ficos de elementos estructurados y formas restringidas de descomposiciones de hiper\u00e1rbol -LRB- en el hipergrafo dual -RRB-, llamadas descomposiciones de consulta -LRB- ver, por ejemplo, -LSB- 7 -RSB - -RRB-. A la luz de esta observaci\u00f3n, observamos que demostrar algunos resultados de aproximabilidad para gr\u00e1ficos de elementos estructurados requiere una comprensi\u00f3n profunda de la aproximabilidad de las descomposiciones de consultas, que actualmente falta en la literatura.Por lo tanto, la dureza NP de reconocer gr\u00e1ficos de elementos estructurados de ancho acotado no se debe a su gran generalidad, sino a algunas peculiaridades en su definici\u00f3n. \u25ba La prueba de los resultados anteriores nos brinda una visi\u00f3n interesante de la noci\u00f3n de gr\u00e1fico de elementos estructurados. De hecho, mostramos que los gr\u00e1ficos de elementos estructurados est\u00e1n en correspondencia uno a uno con algunos tipos especiales de descomposici\u00f3n de hiper\u00e1rbol del hipergrafo dual, que llamamos descomposiciones de hiper\u00e1rbol estrictas. El resto del documento est\u00e1 organizado de la siguiente manera. La secci\u00f3n 2 analiza la intratabilidad de los gr\u00e1ficos de elementos estructurados. La Secci\u00f3n 3 presenta el algoritmo de tiempo polinomial para resolver MaxWSP en la clase de aquellas instancias cuyos hipergrafos duales tienen un ancho de hiper\u00e1rbol acotado, y analiza los casos en los que el algoritmo tambi\u00e9n es altamente paralelizable. La comparaci\u00f3n entre las clases C -LRB- ig, k -RRB- y C -LRB- hw, k -RRB- se analiza en la Secci\u00f3n 4. Finalmente, en la Secci\u00f3n 5 sacamos nuestras conclusiones al delinear tambi\u00e9n direcciones para futuras investigaciones. 5. CONCLUSIONES Hemos resuelto la cuesti\u00f3n abierta de determinar la complejidad de calcular un gr\u00e1fico de art\u00edculos estructurado asociado a un escenario de subasta combinatoria. El resultado es una mala noticia, ya que result\u00f3 que es NP-completo verificar si una subasta combinatoria tiene un gr\u00e1fico de art\u00edculos estructurado, incluso para un ancho de \u00e1rbol de 3. Motivados por este resultado, investigamos el uso de la descomposici\u00f3n de hiper\u00e1rbol -LRB- en el Hipergrafo dual asociado con el escenario -RRB- y demostramos que el problema es manejable en la clase de aquellas instancias cuyos hipergrafos duales tienen un ancho de hiper\u00e1rbol acotado. Para algunos casos especiales, aunque relevantes, tambi\u00e9n se analiza un algoritmo altamente paralelizable. Curiosamente, tambi\u00e9n surgi\u00f3 que la clase de gr\u00e1ficos de elementos estructurados est\u00e1 contenida adecuadamente en la clase de instancias que tienen un ancho de hiper\u00e1rbol acotado -LRB-, por lo tanto, la raz\u00f3n de su intratabilidad no es su generalidad -RRB-. En particular, este \u00faltimo resultado se establece mostrando una relaci\u00f3n precisa entre gr\u00e1ficos de elementos estructurados y formas restringidas de descomposiciones de hiper\u00e1rbol -LRB- en el hipergrafo dual -RRB-, llamadas descomposiciones de consulta -LRB- ver, por ejemplo, -LSB- 7 -RSB - -RRB-. A la luz de esta observaci\u00f3n, observamos que demostrar algunos resultados de aproximabilidad para gr\u00e1ficos de elementos estructurados requiere una comprensi\u00f3n profunda de la aproximabilidad de las descomposiciones de consultas, que actualmente falta en la literatura.Por lo tanto, la dureza NP de reconocer gr\u00e1ficos de elementos estructurados de ancho acotado no se debe a su gran generalidad, sino a algunas peculiaridades en su definici\u00f3n. \u25ba La prueba de los resultados anteriores nos brinda una visi\u00f3n interesante de la noci\u00f3n de gr\u00e1fico de elementos estructurados. De hecho, mostramos que los gr\u00e1ficos de elementos estructurados est\u00e1n en correspondencia uno a uno con algunos tipos especiales de descomposici\u00f3n de hiper\u00e1rbol del hipergrafo dual, que llamamos descomposiciones de hiper\u00e1rbol estrictas. El resto del documento est\u00e1 organizado de la siguiente manera. La secci\u00f3n 2 analiza la intratabilidad de los gr\u00e1ficos de elementos estructurados. La Secci\u00f3n 3 presenta el algoritmo de tiempo polinomial para resolver MaxWSP en la clase de aquellas instancias cuyos hipergrafos duales tienen un ancho de hiper\u00e1rbol acotado, y analiza los casos en los que el algoritmo tambi\u00e9n es altamente paralelizable. La comparaci\u00f3n entre las clases C -LRB- ig, k -RRB- y C -LRB- hw, k -RRB- se analiza en la Secci\u00f3n 4. Finalmente, en la Secci\u00f3n 5 sacamos nuestras conclusiones al delinear tambi\u00e9n direcciones para futuras investigaciones. 5. CONCLUSIONES Hemos resuelto la cuesti\u00f3n abierta de determinar la complejidad de calcular un gr\u00e1fico de art\u00edculos estructurado asociado a un escenario de subasta combinatoria. El resultado es una mala noticia, ya que result\u00f3 que es NP-completo verificar si una subasta combinatoria tiene un gr\u00e1fico de art\u00edculos estructurado, incluso para un ancho de \u00e1rbol de 3. Motivados por este resultado, investigamos el uso de la descomposici\u00f3n de hiper\u00e1rbol -LRB- en el Hipergrafo dual asociado con el escenario -RRB- y demostramos que el problema es manejable en la clase de aquellas instancias cuyos hipergrafos duales tienen un ancho de hiper\u00e1rbol acotado. Para algunos casos especiales, aunque relevantes, tambi\u00e9n se analiza un algoritmo altamente paralelizable. Curiosamente, tambi\u00e9n surgi\u00f3 que la clase de gr\u00e1ficos de elementos estructurados est\u00e1 contenida adecuadamente en la clase de instancias que tienen un ancho de hiper\u00e1rbol acotado -LRB-, por lo tanto, la raz\u00f3n de su intratabilidad no es su generalidad -RRB-. En particular, este \u00faltimo resultado se establece mostrando una relaci\u00f3n precisa entre gr\u00e1ficos de elementos estructurados y formas restringidas de descomposiciones de hiper\u00e1rbol -LRB- en el hipergrafo dual -RRB-, llamadas descomposiciones de consulta -LRB- ver, por ejemplo, -LSB- 7 -RSB - -RRB-. A la luz de esta observaci\u00f3n, observamos que demostrar algunos resultados de aproximabilidad para gr\u00e1ficos de elementos estructurados requiere una comprensi\u00f3n profunda de la aproximabilidad de las descomposiciones de consultas, que actualmente falta en la literatura.La Secci\u00f3n 3 presenta el algoritmo de tiempo polinomial para resolver MaxWSP en la clase de aquellas instancias cuyos hipergrafos duales tienen un ancho de hiper\u00e1rbol acotado, y analiza los casos en los que el algoritmo tambi\u00e9n es altamente paralelizable. La comparaci\u00f3n entre las clases C -LRB- ig, k -RRB- y C -LRB- hw, k -RRB- se analiza en la Secci\u00f3n 4. Finalmente, en la Secci\u00f3n 5 sacamos nuestras conclusiones al delinear tambi\u00e9n direcciones para futuras investigaciones. 5. CONCLUSIONES Hemos resuelto la cuesti\u00f3n abierta de determinar la complejidad de calcular un gr\u00e1fico de art\u00edculos estructurado asociado a un escenario de subasta combinatoria. El resultado es una mala noticia, ya que result\u00f3 que es NP-completo verificar si una subasta combinatoria tiene un gr\u00e1fico de art\u00edculos estructurado, incluso para un ancho de \u00e1rbol de 3. Motivados por este resultado, investigamos el uso de la descomposici\u00f3n de hiper\u00e1rbol -LRB- en el Hipergrafo dual asociado con el escenario -RRB- y demostramos que el problema es manejable en la clase de aquellas instancias cuyos hipergrafos duales tienen un ancho de hiper\u00e1rbol acotado. Para algunos casos especiales, aunque relevantes, tambi\u00e9n se analiza un algoritmo altamente paralelizable. Curiosamente, tambi\u00e9n surgi\u00f3 que la clase de gr\u00e1ficos de elementos estructurados est\u00e1 contenida adecuadamente en la clase de instancias que tienen un ancho de hiper\u00e1rbol acotado -LRB-, por lo tanto, la raz\u00f3n de su intratabilidad no es su generalidad -RRB-. En particular, este \u00faltimo resultado se establece mostrando una relaci\u00f3n precisa entre gr\u00e1ficos de elementos estructurados y formas restringidas de descomposiciones de hiper\u00e1rbol -LRB- en el hipergrafo dual -RRB-, llamadas descomposiciones de consulta -LRB- ver, por ejemplo, -LSB- 7 -RSB - -RRB-. A la luz de esta observaci\u00f3n, observamos que demostrar algunos resultados de aproximabilidad para gr\u00e1ficos de elementos estructurados requiere una comprensi\u00f3n profunda de la aproximabilidad de las descomposiciones de consultas, que actualmente falta en la literatura.La Secci\u00f3n 3 presenta el algoritmo de tiempo polinomial para resolver MaxWSP en la clase de aquellas instancias cuyos hipergrafos duales tienen un ancho de hiper\u00e1rbol acotado, y analiza los casos en los que el algoritmo tambi\u00e9n es altamente paralelizable. La comparaci\u00f3n entre las clases C -LRB- ig, k -RRB- y C -LRB- hw, k -RRB- se analiza en la Secci\u00f3n 4. Finalmente, en la Secci\u00f3n 5 sacamos nuestras conclusiones al delinear tambi\u00e9n direcciones para futuras investigaciones. 5. CONCLUSIONES Hemos resuelto la cuesti\u00f3n abierta de determinar la complejidad de calcular un gr\u00e1fico de art\u00edculos estructurado asociado a un escenario de subasta combinatoria. El resultado es una mala noticia, ya que result\u00f3 que es NP-completo verificar si una subasta combinatoria tiene un gr\u00e1fico de art\u00edculos estructurado, incluso para un ancho de \u00e1rbol de 3. Motivados por este resultado, investigamos el uso de la descomposici\u00f3n de hiper\u00e1rbol -LRB- en el Hipergrafo dual asociado con el escenario -RRB- y demostramos que el problema es manejable en la clase de aquellas instancias cuyos hipergrafos duales tienen un ancho de hiper\u00e1rbol acotado. Para algunos casos especiales, aunque relevantes, tambi\u00e9n se analiza un algoritmo altamente paralelizable. Curiosamente, tambi\u00e9n surgi\u00f3 que la clase de gr\u00e1ficos de elementos estructurados est\u00e1 contenida adecuadamente en la clase de instancias que tienen un ancho de hiper\u00e1rbol acotado -LRB-, por lo tanto, la raz\u00f3n de su intratabilidad no es su generalidad -RRB-. En particular, este \u00faltimo resultado se establece mostrando una relaci\u00f3n precisa entre gr\u00e1ficos de elementos estructurados y formas restringidas de descomposiciones de hiper\u00e1rbol -LRB- en el hipergrafo dual -RRB-, llamadas descomposiciones de consulta -LRB- ver, por ejemplo, -LSB- 7 -RSB - -RRB-. A la luz de esta observaci\u00f3n, observamos que demostrar algunos resultados de aproximabilidad para gr\u00e1ficos de elementos estructurados requiere una comprensi\u00f3n profunda de la aproximabilidad de las descomposiciones de consultas, que actualmente falta en la literatura.Tambi\u00e9n surgi\u00f3 que la clase de gr\u00e1ficos de elementos estructurados est\u00e1 contenida adecuadamente en la clase de instancias que tienen un ancho de hiper\u00e1rbol acotado -LRB-, por lo tanto, la raz\u00f3n de su intratabilidad no es su generalidad -RRB-. En particular, este \u00faltimo resultado se establece mostrando una relaci\u00f3n precisa entre gr\u00e1ficos de elementos estructurados y formas restringidas de descomposiciones de hiper\u00e1rbol -LRB- en el hipergrafo dual -RRB-, llamadas descomposiciones de consulta -LRB- ver, por ejemplo, -LSB- 7 -RSB - -RRB-. A la luz de esta observaci\u00f3n, observamos que demostrar algunos resultados de aproximabilidad para gr\u00e1ficos de elementos estructurados requiere una comprensi\u00f3n profunda de la aproximabilidad de las descomposiciones de consultas, que actualmente falta en la literatura.Tambi\u00e9n surgi\u00f3 que la clase de gr\u00e1ficos de elementos estructurados est\u00e1 contenida adecuadamente en la clase de instancias que tienen un ancho de hiper\u00e1rbol acotado -LRB-, por lo tanto, la raz\u00f3n de su intratabilidad no es su generalidad -RRB-. En particular, este \u00faltimo resultado se establece mostrando una relaci\u00f3n precisa entre gr\u00e1ficos de elementos estructurados y formas restringidas de descomposiciones de hiper\u00e1rbol -LRB- en el hipergrafo dual -RRB-, llamadas descomposiciones de consulta -LRB- ver, por ejemplo, -LSB- 7 -RSB - -RRB-. A la luz de esta observaci\u00f3n, observamos que demostrar algunos resultados de aproximabilidad para gr\u00e1ficos de elementos estructurados requiere una comprensi\u00f3n profunda de la aproximabilidad de las descomposiciones de consultas, que actualmente falta en la literatura.", "keyphrases": ["hipergrafo", "subasta combinatoria", "descomposici\u00f3n hipertre", "Mecanismo conocido para la asignaci\u00f3n de recursos y tareas.", "m\u00e9todo de descomposici\u00f3n hipertre-base", "hipergrafo hg", "complejo de gr\u00e1fico de elementos de estructura", "simplificaci\u00f3n del grafo primal", "gr\u00e1fico de elementos de estructura", "arreglar el ancho del \u00e1rbol", "aceptar precio de oferta", "tiempo polinomial"]}
{"file_name": "C-33", "text": "Negociaci\u00f3n basada en recompensas para proporcionar informaci\u00f3n contextual RESUMEN C\u00f3mo proporcionar informaci\u00f3n contextual adecuada es un problema desafiante en la inform\u00e1tica consciente del context. La mayor\u00eda de los enfoques existentes utilizan un mecanismo de selecci\u00f3n centralizado para decidir qu\u00e9 informaci\u00f3n de context es apropiada. En este art\u00edculo, proponemos un enfoque novedoso basado en la negociaci\u00f3n con recompensas para resolver dicho problema. Los proveedores de context distribuido negocian entre s\u00ed para decidir qui\u00e9n puede proporcionar context y c\u00f3mo asignan los ingresos. Para respaldar nuestro enfoque, hemos dise\u00f1ado un modelo de negociaci\u00f3n concreto con recompensas. Tambi\u00e9n evaluamos nuestro enfoque y demostramos que efectivamente puede elegir un proveedor de context apropiado y asignar los ingresos de manera justa. 1. INTRODUCCI\u00d3N La conciencia del context es un concepto clave en la computaci\u00f3n ubicua. El context informa tanto el reconocimiento como el mapeo al proporcionar una visi\u00f3n estructurada y unificada del mundo en el que opera el sistema -LSB- 1 -RSB-. Las aplicaciones sensibles al context explotan informaci\u00f3n contextual, como la ubicaci\u00f3n, las preferencias de los usuarios, etc., para adaptar sus comportamientos en respuesta a los requisitos cambiantes de los usuarios y los entornos generalizados. Sin embargo, un tipo espec\u00edfico de context a menudo puede ser proporcionado por diferentes proveedores de context (LRB), sensores u otras fuentes de datos de informaci\u00f3n contextual (RRB) con diferentes niveles de calidad. Por ejemplo, debido a que las aplicaciones sensibles al context utilizan informaci\u00f3n contextual para adaptar sus comportamientos, la informaci\u00f3n contextual inapropiada puede conducir a un comportamiento inapropiado. Por lo tanto, deber\u00edamos dise\u00f1ar un mecanismo para proporcionar informaci\u00f3n de context adecuada para las aplicaciones actuales conscientes del context. En entornos generalizados, los proveedores de context, considerados entidades relativamente independientes, tienen sus propios intereses. Esperan obtener ganancias cuando proporcionen informaci\u00f3n de context. Sin embargo, la mayor\u00eda de los enfoques existentes consideran a los proveedores de context como entidades sin ning\u00fan inter\u00e9s personal y utilizan un \"\u00e1rbitro\" centralizado proporcionado por el middleware para decidir qui\u00e9n puede proporcionar el context apropiado. Por tanto, la carga del middleware es muy pesada y su decisi\u00f3n puede ser injusta y perjudicar los intereses de algunos proveedores. Adem\u00e1s, cuando dicho \"\u00e1rbitro\" se descompone, provocar\u00e1 graves consecuencias para las aplicaciones sensibles al context. En este art\u00edculo, dejamos que los propios proveedores de context distribuido decidan qui\u00e9n proporciona informaci\u00f3n de context. Dado que una alta reputaci\u00f3n podr\u00eda ayudar a los proveedores a obtener m\u00e1s oportunidades para brindar context y obtener m\u00e1s ingresos en el futuro, los proveedores intentan obtener el derecho de brindar un \"buen\" context para mejorar su reputaci\u00f3n. Para lograrlo, los proveedores de context pueden acordar compartir una parte de las ganancias con sus oponentes. Por lo tanto, los proveedores de context negocian entre s\u00ed para llegar a un acuerdo sobre qui\u00e9n puede proporcionar el context y c\u00f3mo asignan los ingresos. Nuestro enfoque tiene algunas ventajas espec\u00edficas: 1.No necesitamos un ``\u00e1rbitro'' proporcionado por el middleware de la computaci\u00f3n omnipresente para decidir qui\u00e9n proporciona el context. Por lo tanto, reducir\u00e1 la carga del middleware. 2. Es m\u00e1s razonable que los proveedores de context distribuido decidan qui\u00e9n proporciona el context, porque puede evitar las graves consecuencias causadas por una falla de un \"\u00e1rbitro\" centralizado. 3. Puede garantizar los intereses de los proveedores y proporcionar una asignaci\u00f3n justa de los ingresos cuando los proveedores negocian entre s\u00ed para llegar a un acuerdo sobre los problemas que les preocupan. 4. Este enfoque puede elegir autom\u00e1ticamente un proveedor adecuado. El modelo de negociaci\u00f3n que hemos dise\u00f1ado para respaldar nuestro enfoque es tambi\u00e9n un modelo novedoso en el \u00e1mbito de la negociaci\u00f3n. Este modelo puede ayudar a los negociadores a llegar a un acuerdo en el proceso de negociaci\u00f3n actual proporcionando algunas garant\u00edas sobre el resultado del pr\u00f3ximo proceso de negociaci\u00f3n -LRB-, es decir, recompensas -RRB-. Costar\u00e1 m\u00e1s tiempo llegar a un acuerdo. Tambi\u00e9n ampl\u00eda el espacio de negociaci\u00f3n considerado en el actual proceso de negociaci\u00f3n y, por tanto, proporciona m\u00e1s posibilidades para llegar a un mejor acuerdo. La secci\u00f3n 2 presenta algunos supuestos. La Secci\u00f3n 3 describe detalladamente nuestro enfoque basado en la negociaci\u00f3n, incluidas las funciones de utilidad, el protocolo de negociaci\u00f3n y las estrategias de los proveedores de context. La secci\u00f3n 4 eval\u00faa nuestro enfoque. En la secci\u00f3n 5 presentamos algunos trabajos relacionados y concluimos en la secci\u00f3n 6. 5. TRABAJO RELACIONADO En -LSB- 4 -RSB-, Huebscher y McCann han propuesto un dise\u00f1o de middleware adaptativo para aplicaciones sensibles al context. Su middleware adaptativo utiliza funciones de utilidad para elegir el mejor proveedor de context -LRB- dados los requisitos de QoC de las aplicaciones y el QoC de medios alternativos de adquisici\u00f3n de context -RRB-. En nuestro modelo de negociaci\u00f3n, el c\u00e1lculo de la funci\u00f3n de utilidad Uc se inspir\u00f3 en este enfoque. Henricksen e Indulska proponen un enfoque para modelar y utilizar informaci\u00f3n imperfecta en -LSB- 3 -RSB-. Caracterizan varios tipos y fuentes de informaci\u00f3n de context imperfecta y presentan un conjunto de construcciones novedosas de modelado de context. Tambi\u00e9n describen una infraestructura de software que respalda la gesti\u00f3n y el uso de informaci\u00f3n de context imperfecta. -LSB- 10 -RSB- presenta un marco para realizar una gesti\u00f3n din\u00e1mica de la coherencia del context. El marco admite la detecci\u00f3n de inconsistencias basada en una coincidencia sem\u00e1ntica y un modelo de activaci\u00f3n de inconsistencias, y la resoluci\u00f3n de inconsistencias con acciones proactivas para contextualizar las fuentes. La mayor\u00eda de los enfoques para proporcionar un context apropiado utilizan un \"\u00e1rbitro\" centralizado. En nuestro enfoque, dejamos que los propios proveedores de context distribuido decidan qui\u00e9n puede proporcionar informaci\u00f3n de context adecuada. Nuestro enfoque puede reducir la carga del middleware, porque no necesitamos que el middleware proporcione un mecanismo de selecci\u00f3n de context. Adem\u00e1s, puede garantizar los intereses de los proveedores de context. 6. CONCLUSI\u00d3N Y TRABAJO FUTURO C\u00f3mo proporcionar la informaci\u00f3n contextual adecuada es un problema desafiante en la computaci\u00f3n ubicua.En este art\u00edculo, hemos presentado un enfoque novedoso basado en la negociaci\u00f3n con recompensas para intentar resolver dicho problema. Los proveedores de context distribuido negocian entre s\u00ed para llegar a un acuerdo sobre qui\u00e9n puede proporcionar el context adecuado y c\u00f3mo asignan los ingresos. Los resultados de nuestros experimentos han demostrado que nuestro enfoque puede elegir un proveedor de context apropiado y tambi\u00e9n puede garantizar los intereses de los proveedores mediante una asignaci\u00f3n de ingresos relativamente justa. En este art\u00edculo, solo consideramos c\u00f3mo elegir un proveedor de context apropiado entre dos proveedores. En trabajos futuros, este modelo de negociaci\u00f3n se ampliar\u00e1 y m\u00e1s de dos proveedores de context podr\u00e1n negociar entre s\u00ed para decidir qui\u00e9n es el proveedor de context m\u00e1s apropiado. En el modelo de negociaci\u00f3n ampliado, c\u00f3mo dise\u00f1ar estrategias de negociaci\u00f3n eficientes ser\u00e1 un problema desafiante. Suponemos que el proveedor del context cumplir\u00e1 su promesa de recompensa en el pr\u00f3ximo proceso de negociaci\u00f3n. De hecho, el proveedor del context podr\u00eda enga\u00f1ar a su oponente y ofrecerle una promesa ilusoria. Deber\u00edamos resolver este problema en el futuro.", "keyphrases": ["consciente del context", "context proporcionado", "negociar", "Computaci\u00f3n contextual", "modelo de negociaci\u00f3n concreta", "distribuir aplicaci\u00f3n", "Computaci\u00f3n generalizada", "reputaci\u00f3n", "calidad de context", "argumento persuasivo"]}
{"file_name": "H-12", "text": "Generaci\u00f3n r\u00e1pida de fragmentos de resultados en la b\u00fasqueda web RESUMEN La presentaci\u00f3n de fragmentos de documentos sesgados en las consultas como parte de las p\u00e1ginas de resultados presentadas por los motores de b\u00fasqueda se ha convertido en una expectativa de los usuarios de los motores de b\u00fasqueda. En este art\u00edculo exploramos los algoritmos y las estructuras de datos necesarios como parte de un motor de b\u00fasqueda para permitir la generaci\u00f3n eficiente de fragmentos de consulta sesgados. Comenzamos proponiendo y analizando un m\u00e9todo de compresi\u00f3n de documentos que reduce el tiempo de generaci\u00f3n de fragmentos en un 58 % con respecto a una l\u00ednea base utilizando la biblioteca de compresi\u00f3n zlib. Estos experimentos revelan que encontrar documentos en el almacenamiento secundario domina el costo total de generar fragmentos y, por lo tanto, almacenar documentos en cach\u00e9 en la RAM es esencial para un proceso de generaci\u00f3n de fragmentos r\u00e1pido. Mediante simulaci\u00f3n, examinamos el rendimiento de la generaci\u00f3n de fragmentos para cach\u00e9s de RAM de diferentes tama\u00f1os. Finalmente, proponemos y analizamos la reordenaci\u00f3n y compactaci\u00f3n de documentos, revelando un esquema que aumenta el n\u00famero de visitas a la cach\u00e9 de documentos con solo un efecto marginal en la calidad de los fragmentos. Este esquema efectivamente duplica la cantidad de documentos que pueden caber en una cach\u00e9 de tama\u00f1o fijo. 1. INTRODUCCI\u00d3N Cada resultado de la lista de resultados de b\u00fasqueda proporcionada por los motores de b\u00fasqueda WWW actuales, como search.yahoo.com, google.com y search.msn.com, normalmente contiene el t\u00edtulo y la URL del documento real, enlaces a versiones activas y en cach\u00e9 de el documento y, a veces, una indicaci\u00f3n del tama\u00f1o y tipo de archivo. Adem\u00e1s, normalmente se presentan uno o m\u00e1s fragmentos, lo que proporciona al buscador una vista previa del contenido del documento. Los snippets son peque\u00f1os fragmentos de text extra\u00eddos del contenido del documento -LRB- o de sus metadatos -RRB-. Un fragmento sesgado por la consulta es aquel que se extrae selectivamente en funci\u00f3n de su relaci\u00f3n con la consulta del buscador. La adici\u00f3n de fragmentos informativos a los resultados de b\u00fasqueda puede aumentar sustancialmente su valor para los buscadores. Los fragmentos precisos permiten al buscador tomar buenas decisiones sobre qu\u00e9 resultados vale la pena acceder y cu\u00e1les pueden ignorarse. En el mejor de los casos, los fragmentos pueden evitar la necesidad de abrir cualquier documento al proporcionar directamente la respuesta a la necesidad de informaci\u00f3n real del buscador, como los datos de contacto de una persona u organizaci\u00f3n. La generaci\u00f3n de fragmentos sesgados por consultas por parte de motores de b\u00fasqueda web que indexan del orden de diez mil millones de p\u00e1ginas web y manejan cientos de millones de consultas de b\u00fasqueda por d\u00eda impone una carga computacional muy significativa -LRB-, recordando que cada b\u00fasqueda generalmente genera diez fragmentos -RRB-. El enfoque simplista de mantener una copia de cada documento en un archivo y generar fragmentos abriendo y escaneando archivos funciona cuando las tasas de consulta son bajas y las colecciones son peque\u00f1as, pero no escala al grado requerido. La sobrecarga de abrir y leer diez archivos por consulta adem\u00e1s de acceder a la estructura del \u00edndice para localizarlos ser\u00eda manifiestamente excesiva bajo una gran carga de consultas. Incluso almacenar diez mil millones de archivos y los correspondientes cientos de terabytes de datos est\u00e1 fuera del alcance de los sistemas de archivos tradicionales.Tenga en cuenta que la utilidad de los fragmentos no se limita en modo alguno a las aplicaciones de b\u00fasqueda en toda la Web. La generaci\u00f3n eficiente de fragmentos tambi\u00e9n es importante a escala de servicios de b\u00fasqueda para todo el gobierno, como www.firstgov.gov -LRB- c. 25 millones de p\u00e1ginas -RRB- y govsearch.australia.gov.au -LRB- c. 5 millones de p\u00e1ginas -RRB- y dentro de grandes empresas como IBM -LSB- 2 -RSB- -LRB- c. 50 millones de p\u00e1ginas -RRB-. Los fragmentos pueden ser incluso m\u00e1s \u00fatiles en aplicaciones de b\u00fasqueda de bases de datos o sistemas de archivos en las que no hay ninguna URL \u00fatil ni informaci\u00f3n de t\u00edtulo. Presentamos un nuevo algoritmo y una estructura compacta de un solo archivo dise\u00f1ado para la generaci\u00f3n r\u00e1pida de fragmentos de alta calidad y comparamos su rendimiento espacio/temporal con una l\u00ednea de base obvia basada en el compresor zlib en varios conjuntos de datos. Informamos la proporci\u00f3n de tiempo dedicado a b\u00fasquedas de disco, lecturas de disco y procesamiento de CPU; demostrando que el tiempo de localizaci\u00f3n de cada documento -LRB- y el tiempo de b\u00fasqueda -RRB- dominan, como se esperaba. Como el tiempo para procesar un documento en la RAM es peque\u00f1o en comparaci\u00f3n con localizar y leer el documento en la memoria, puede parecer que no se requiere compresi\u00f3n. Sin embargo, esto s\u00f3lo es cierto si no hay almacenamiento en cach\u00e9 de documentos en la RAM. Controlar la RAM de los sistemas f\u00edsicos para la experimentaci\u00f3n es dif\u00edcil, por lo que utilizamos la simulaci\u00f3n para demostrar que el almacenamiento en cach\u00e9 de documentos mejora dr\u00e1sticamente el rendimiento de la generaci\u00f3n de fragmentos. A su vez, cuantos m\u00e1s documentos se puedan comprimir, m\u00e1s caben en la cach\u00e9 y, por lo tanto, se pueden evitar m\u00e1s b\u00fasquedas en el disco: el cl\u00e1sico compromiso de compresi\u00f3n de datos que se explota en estructuras de archivos invertidas y en la computaci\u00f3n de listas de documentos clasificados -LSB- 24 -RSB -. Como acceder al cach\u00e9 de documentos es importante, examinamos los esquemas de compactaci\u00f3n de documentos, a diferencia de los de compresi\u00f3n, imponiendo un orden a priori de oraciones dentro de un documento y luego permitiendo solo oraciones iniciales en el cach\u00e9 para cada documento. Esto genera un mayor ahorro de tiempo, con un impacto solo marginal en la calidad de los fragmentos devueltos. 2. TRABAJO RELACIONADO La generaci\u00f3n de fragmentos es un tipo especial de resumen de documentos extractivos, en el que se seleccionan oraciones, o fragmentos de oraciones, para su inclusi\u00f3n en el resumen en funci\u00f3n del grado en que coinciden con la consulta de b\u00fasqueda. Los primeros motores de b\u00fasqueda web presentaban fragmentos independientes de la consulta que constaban de los primeros k bytes del documento de resultados. Generarlos es claramente mucho m\u00e1s simple y mucho menos costoso computacionalmente que procesar documentos para extraer res\u00famenes sesgados de consultas, ya que no es necesario buscar en el documento fragmentos de text que contengan t\u00e9rminos de consulta. Hasta donde sabemos, Google fue el primer motor de b\u00fasqueda web completo que proporcion\u00f3 res\u00famenes sesgados en las consultas, pero Brin y Page -LSB- 1 -RSB- enumeran el resumen s\u00f3lo bajo el t\u00edtulo de trabajo futuro. La mayor parte del trabajo experimental que utiliza el resumen sesgado por consultas se ha centrado en comparar su valor para los buscadores en relaci\u00f3n con otros tipos de resumen -LSB- 20, 21 -RSB-, en lugar de la generaci\u00f3n eficiente de res\u00famenes.A pesar de la importancia de la generaci\u00f3n eficiente de res\u00famenes en la b\u00fasqueda web, aparecen pocos algoritmos en la literatura. White et al -LSB-21-RSB- informan algunos tiempos experimentales de su sistema WebDocSum, pero los algoritmos de generaci\u00f3n de fragmentos en s\u00ed no est\u00e1n aislados, por lo que es dif\u00edcil inferir un tiempo de generaci\u00f3n de fragmentos comparable a los tiempos que informamos en este documento. N/M documentos. Por lo tanto, la cantidad total de RAM requerida por una sola m\u00e1quina ser\u00eda N/M -LRB- 8,192 + 10,24 + 8 -RRB- bytes. Suponiendo que cada m\u00e1quina tiene 8 Gb de RAM y que hay 20 mil millones de p\u00e1ginas para indexar en la Web, se necesitar\u00eda un total de M = 62 m\u00e1quinas para Snippet Engine. Estas m\u00e1quinas tambi\u00e9n necesitar\u00edan acceso a 37 Tb de disco para almacenar las representaciones de documentos comprimidos que no estaban en cach\u00e9. En este trabajo hemos evitado deliberadamente comprometernos con un m\u00e9todo de puntuaci\u00f3n particular para oraciones en documentos. M\u00e1s bien, hemos informado resultados de precisi\u00f3n en t\u00e9rminos de los cuatro componentes que previamente han demostrado ser importantes para determinar fragmentos \u00fatiles -LSB- 20 -RSB-. Sin embargo, las t\u00e9cnicas de compactaci\u00f3n de documentos que utilizan el reordenamiento de oraciones eliminan la relaci\u00f3n espacial entre oraciones y, por lo tanto, si una t\u00e9cnica de puntuaci\u00f3n se basa en la posici\u00f3n de una oraci\u00f3n dentro de un documento, las t\u00e9cnicas de compactaci\u00f3n agresivas que se describen aqu\u00ed no se pueden utilizar. Como el tiempo de b\u00fasqueda domina el proceso de generaci\u00f3n de fragmentos, en este documento no nos hemos centrado en detalle en esta parte de la generaci\u00f3n de fragmentos. Exploraremos esquemas de compresi\u00f3n alternativos en trabajos futuros.En este documento no nos hemos centrado en detalle en esta parte de la generaci\u00f3n de fragmentos. Exploraremos esquemas de compresi\u00f3n alternativos en trabajos futuros.En este documento no nos hemos centrado en detalle en esta parte de la generaci\u00f3n de fragmentos. Exploraremos esquemas de compresi\u00f3n alternativos en trabajos futuros.", "keyphrases": ["motor de b\u00fasqueda", "generaci\u00f3n de fragmentos", "cach\u00e9 de documentos", "medida del gr\u00e1fico de enlaces", "llevar a cabo", "resumen web", "sistema de archivos con fines especiales", "RAM", "documento compacto", "fragmento de text", "p\u00e1gina de resultados finales precalculada", "esquema de c\u00f3digo vbyte", "compresa semiest\u00e1tica"]}
{"file_name": "H-10", "text": "Agrupaci\u00f3n regularizada de documentos * RESUMEN En los \u00faltimos a\u00f1os, la agrupaci\u00f3n de documentos ha recibido cada vez m\u00e1s atenci\u00f3n como una t\u00e9cnica importante y fundamental para la organizaci\u00f3n de documentos no supervisada, la extracci\u00f3n autom\u00e1tica de temas y la r\u00e1pida recuperaci\u00f3n o filtrado de informaci\u00f3n. En este art\u00edculo, proponemos un m\u00e9todo novedoso para agrupar documentos mediante regularizaci\u00f3n. A diferencia de los m\u00e9todos tradicionales de agrupamiento regularizado globalmente, nuestro m\u00e9todo primero construye un predictor de etiqueta lineal regularizado local para cada vector de documento y luego combina todos esos regularizadores locales con un regularizador de suavidad global. Por eso llamamos a nuestro algoritmo Agrupaci\u00f3n con regularizaci\u00f3n local y global -LRB- CLGR -RRB-. Demostraremos que las pertenencias a grupos de documentos se pueden lograr mediante la descomposici\u00f3n de valores propios de una matriz sim\u00e9trica dispersa, que se puede resolver de manera eficiente mediante m\u00e9todos iterativos. Finalmente, se presentan nuestras evaluaciones experimentales en varios conjuntos de datos para mostrar las superioridades de CLGR sobre los m\u00e9todos tradicionales de agrupaci\u00f3n de documentos. 1. INTRODUCCI\u00d3N La agrupaci\u00f3n de documentos ha recibido cada vez m\u00e1s atenci\u00f3n como una t\u00e9cnica importante y fundamental para la organizaci\u00f3n de documentos no supervisados, la extracci\u00f3n autom\u00e1tica de temas y la r\u00e1pida recuperaci\u00f3n o filtrado de informaci\u00f3n. Un buen enfoque de agrupaci\u00f3n de documentos puede ayudar a las computadoras a organizar autom\u00e1ticamente el corpus de documentos en una jerarqu\u00eda de grupos significativa para una exploraci\u00f3n y navegaci\u00f3n eficientes, lo cual es muy valioso para complementar las deficiencias de las tecnolog\u00edas tradicionales de recuperaci\u00f3n de informaci\u00f3n. En tales casos, una navegaci\u00f3n eficiente a trav\u00e9s de una buena jerarqu\u00eda de cl\u00fasteres ser\u00e1 definitivamente \u00fatil. Generalmente, los m\u00e9todos de agrupaci\u00f3n de documentos se pueden clasificar principalmente en dos clases: m\u00e9todos jer\u00e1rquicos y m\u00e9todos de partici\u00f3n. Los m\u00e9todos jer\u00e1rquicos agrupan los puntos de datos en una estructura de \u00e1rbol jer\u00e1rquico utilizando enfoques ascendentes o descendentes. Por ejemplo, la agrupaci\u00f3n aglomerativa jer\u00e1rquica -LRB-HAC-RRB- -LSB- 13 -RSB- es un m\u00e9todo t\u00edpico de agrupaci\u00f3n jer\u00e1rquica ascendente. Para comenzar, toma cada punto de datos como un solo grupo y luego construye grupos cada vez m\u00e1s grandes agrupando puntos de datos similares hasta que todo el conjunto de datos se encapsula en un grupo final. Por otro lado, los m\u00e9todos de partici\u00f3n descomponen el conjunto de datos en una serie de grupos disjuntos que suelen ser \u00f3ptimos en t\u00e9rminos de algunas funciones de criterio predefinidas. Por ejemplo, K-means -LSB- 13 -RSB- es un m\u00e9todo de partici\u00f3n t\u00edpico que tiene como objetivo minimizar la suma de la distancia al cuadrado entre los puntos de datos y sus correspondientes centros de grupo. En este art\u00edculo, nos centraremos en los m\u00e9todos de partici\u00f3n. En las \u00faltimas d\u00e9cadas, se han propuesto muchos m\u00e9todos para superar los problemas anteriores de los m\u00e9todos de partici\u00f3n -LSB- 19 -RSB- -LSB- 28 -RSB-. Recientemente, otro tipo de m\u00e9todos de partici\u00f3n basados \u200b\u200ben la agrupaci\u00f3n en gr\u00e1ficos de datos ha despertado un inter\u00e9s considerable en la comunidad de aprendizaje autom\u00e1tico y miner\u00eda de datos.La idea b\u00e1sica detr\u00e1s de estos m\u00e9todos es modelar primero todo el conjunto de datos como un gr\u00e1fico ponderado, en el que los nodos del gr\u00e1fico representan los puntos de datos y los pesos en los bordes corresponden a las similitudes entre puntos por pares. Luego, las asignaciones de grupos del conjunto de datos se pueden lograr optimizando algunos criterios definidos en el gr\u00e1fico. Despu\u00e9s de algunas flexibilizaciones, estos criterios generalmente se pueden optimizar mediante descomposiciones propias, que se garantiza que ser\u00e1n \u00f3ptimas globalmente. De esta manera, la agrupaci\u00f3n espectral evita eficientemente los problemas de los m\u00e9todos de partici\u00f3n tradicionales que presentamos en el \u00faltimo p\u00e1rrafo. En este art\u00edculo, proponemos un nuevo algoritmo de agrupamiento de documentos que hereda la superioridad del agrupamiento espectral, es decir, los resultados finales del agrupamiento tambi\u00e9n se pueden obtener explotando la estructura propia de una matriz sim\u00e9trica. Por eso llamamos a nuestro m\u00e9todo Agrupaci\u00f3n con regularizaci\u00f3n local y global -LRB- CLGR -RRB-. La idea de incorporar informaci\u00f3n local y global en la predicci\u00f3n de etiquetas est\u00e1 inspirada en los trabajos recientes sobre aprendizaje semisupervisado -LSB- 31 -RSB-, y nuestras evaluaciones experimentales en varios conjuntos de datos de documentos reales muestran que CLGR funciona mejor que muchos estados de M\u00e9todos de agrupaci\u00f3n de \u00faltima generaci\u00f3n. El resto de este art\u00edculo est\u00e1 organizado de la siguiente manera: en la secci\u00f3n 2 presentaremos nuestro algoritmo CLGR en detalle. Los resultados experimentales en varios conjuntos de datos se presentan en la secci\u00f3n 3, seguidos de las conclusiones y discusiones en la secci\u00f3n 4. 4. CONCLUSIONES Y TRABAJOS FUTUROS En este art\u00edculo, derivamos un nuevo algoritmo de agrupamiento llamado agrupamiento con regularizaci\u00f3n local y global. Nuestro m\u00e9todo preserva el m\u00e9rito de los algoritmos de aprendizaje local y la agrupaci\u00f3n espectral. Nuestros experimentos muestran que el algoritmo propuesto supera a la mayor\u00eda de los algoritmos de \u00faltima generaci\u00f3n en muchos conjuntos de datos de referencia. En el futuro, nos centraremos en las cuestiones de selecci\u00f3n de par\u00e1metros y aceleraci\u00f3n del algoritmo CLGR.La idea de incorporar informaci\u00f3n local y global en la predicci\u00f3n de etiquetas est\u00e1 inspirada en los trabajos recientes sobre aprendizaje semisupervisado -LSB- 31 -RSB-, y nuestras evaluaciones experimentales en varios conjuntos de datos de documentos reales muestran que CLGR funciona mejor que muchos estados de M\u00e9todos de agrupaci\u00f3n de \u00faltima generaci\u00f3n. El resto de este art\u00edculo est\u00e1 organizado de la siguiente manera: en la secci\u00f3n 2 presentaremos nuestro algoritmo CLGR en detalle. Los resultados experimentales en varios conjuntos de datos se presentan en la secci\u00f3n 3, seguidos de las conclusiones y discusiones en la secci\u00f3n 4. 4. CONCLUSIONES Y TRABAJOS FUTUROS En este art\u00edculo, derivamos un nuevo algoritmo de agrupamiento llamado agrupamiento con regularizaci\u00f3n local y global. Nuestro m\u00e9todo preserva el m\u00e9rito de los algoritmos de aprendizaje local y la agrupaci\u00f3n espectral. Nuestros experimentos muestran que el algoritmo propuesto supera a la mayor\u00eda de los algoritmos de \u00faltima generaci\u00f3n en muchos conjuntos de datos de referencia. En el futuro, nos centraremos en las cuestiones de selecci\u00f3n de par\u00e1metros y aceleraci\u00f3n del algoritmo CLGR.La idea de incorporar informaci\u00f3n local y global en la predicci\u00f3n de etiquetas est\u00e1 inspirada en los trabajos recientes sobre aprendizaje semisupervisado -LSB- 31 -RSB-, y nuestras evaluaciones experimentales en varios conjuntos de datos de documentos reales muestran que CLGR funciona mejor que muchos estados de M\u00e9todos de agrupaci\u00f3n de \u00faltima generaci\u00f3n. El resto de este art\u00edculo est\u00e1 organizado de la siguiente manera: en la secci\u00f3n 2 presentaremos nuestro algoritmo CLGR en detalle. Los resultados experimentales en varios conjuntos de datos se presentan en la secci\u00f3n 3, seguidos de las conclusiones y discusiones en la secci\u00f3n 4. 4. CONCLUSIONES Y TRABAJOS FUTUROS En este art\u00edculo, derivamos un nuevo algoritmo de agrupamiento llamado agrupamiento con regularizaci\u00f3n local y global. Nuestro m\u00e9todo preserva el m\u00e9rito de los algoritmos de aprendizaje local y la agrupaci\u00f3n espectral. Nuestros experimentos muestran que el algoritmo propuesto supera a la mayor\u00eda de los algoritmos de \u00faltima generaci\u00f3n en muchos conjuntos de datos de referencia. En el futuro, nos centraremos en las cuestiones de selecci\u00f3n de par\u00e1metros y aceleraci\u00f3n del algoritmo CLGR.", "keyphrases": ["grupo de documentos", "regular", "regular mundial", "jerarqu\u00eda de cl\u00faster", "espectro", "b\u00fasqueda espec\u00edfica", "m\u00e9todo jer\u00e1rquico", "m\u00e9todo de partici\u00f3n", "etiqueta predecir", "estimaci\u00f3n de funci\u00f3n", "colector"]}
{"file_name": "C-32", "text": "BuddyCache: almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de gran coherencia en una WAN * RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea com\u00fan. Requieren una gran coherencia para los datos persistentes compartidos y un acceso eficiente a objetos detallados. Estas propiedades son dif\u00edciles de proporcionar en redes de \u00e1rea amplia debido a la alta latencia de la red. BuddyCache es un nuevo enfoque de almacenamiento en cach\u00e9 transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de gran coherencia en entornos de red de alta latencia. El desaf\u00edo es mejorar el rendimiento y al mismo tiempo proporcionar las propiedades de correcci\u00f3n y disponibilidad de un protocolo de almacenamiento en cach\u00e9 transaccional en presencia de fallas de nodos y pares lentos. Implementamos un prototipo de BuddyCache y evaluamos su rendimiento. Los resultados anal\u00edticos, confirmados por mediciones del prototipo BuddyCache utilizando el punto de referencia multiusuario 007, indican que para latencias t\u00edpicas de Internet, por ejemplo, entre 40 y 80 milisegundos de tiempo de ida y vuelta hasta el servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta en un 50 % la latencia de acceso a objetos compartidos en comparaci\u00f3n con el acceso directo a servidores remotos. 1. INTRODUCCI\u00d3N Sin embargo, las aplicaciones distribuidas pueden funcionar mal en entornos de redes de \u00e1rea amplia. Los problemas de ancho de banda de la red mejorar\u00e1n en el futuro previsible, pero la mejora en la latencia de la red es fundamentalmente limitada. BuddyCache es una nueva t\u00e9cnica de almacenamiento en cach\u00e9 de objetos que aborda el problema de latencia de red para aplicaciones colaborativas en entornos de red de \u00e1rea amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea com\u00fan, por ejemplo, un equipo de ingenieros que supervisan conjuntamente un proyecto de construcci\u00f3n. Las aplicaciones colaborativas de gran coherencia, por ejemplo los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso coherente a datos persistentes compartidos. Sin embargo, hasta ahora los usuarios rara vez se han planteado ejecutar sistemas de almacenamiento en red consistentes en redes de \u00e1rea amplia, ya que el rendimiento ser\u00eda inaceptable -LSB- 24 -RSB-. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones de la red de \u00e1rea amplia para mantener la coherencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de red de \u00e1rea amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento de consistencia m\u00e1s d\u00e9biles -LSB- 22 -RSB-. Adaptar una aplicaci\u00f3n para utilizar un sistema de almacenamiento de consistencia d\u00e9bil requiere un esfuerzo significativo, ya que la aplicaci\u00f3n debe reescribirse para manejar una sem\u00e1ntica de sistema de almacenamiento diferente. Si se pudiera acceder a objetos persistentes compartidos con baja latencia, se podr\u00eda abrir un nuevo campo de aplicaciones distribuidas de alta coherencia. Almacenamiento en cach\u00e9 web cooperativo -LSB- 10, 11,15 -RSB- es un enfoque bien conocido para reducir la interacci\u00f3n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Sin embargo, las t\u00e9cnicas de almacenamiento en cach\u00e9 web cooperativo no proporcionan dos propiedades importantes que necesitan las aplicaciones colaborativas: una coherencia s\u00f3lida y un acceso eficiente a objetos detallados. Los sistemas cooperativos de almacenamiento en cach\u00e9 de objetos -LSB- 2 -RSB- proporcionan estas propiedades. Sin embargo, dependen de la interacci\u00f3n con el servidor para proporcionar una coherencia de cach\u00e9 detallada que evite el problema del intercambio falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma p\u00e1gina f\u00edsica. La interacci\u00f3n con el servidor aumenta la latencia. La contribuci\u00f3n de este trabajo es ampliar las t\u00e9cnicas de almacenamiento en cach\u00e9 cooperativo para proporcionar una coherencia s\u00f3lida y un acceso eficiente a objetos de grano fino en entornos de \u00e1rea amplia. Los ingenieros utilizan una aplicaci\u00f3n CAD colaborativa para revisar y actualizar documentos de dise\u00f1o de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo que ejecutan clientes de repositorio. Las estaciones de trabajo est\u00e1n interconectadas mediante una Ethernet local r\u00e1pida, pero la conexi\u00f3n de red a los servidores del repositorio principal es lenta. Para mejorar la latencia de acceso, los clientes obtienen objetos de los servidores del repositorio y del cach\u00e9 y acceden a ellos localmente. Un protocolo de coherencia garantiza que las cach\u00e9s de los clientes permanezcan coherentes cuando se modifican los objetos. El problema de rendimiento al que se enfrenta la aplicaci\u00f3n colaborativa es la coordinaci\u00f3n con los servidores para el acceso constante a los objetos compartidos. Con BuddyCache, un grupo de clientes colaboradores cercanos, conectados al repositorio de almacenamiento a trav\u00e9s de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos, actualizaciones o informaci\u00f3n de coherencia necesarios est\u00e1n disponibles en alg\u00fan cliente del grupo. BuddyCache presenta dos desaf\u00edos t\u00e9cnicos principales. Un desaf\u00edo es c\u00f3mo proporcionar acceso eficiente a objetos detallados compartidos en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en cach\u00e9. El otro desaf\u00edo es respaldar la coherencia de la cach\u00e9 detallada en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de ''redirecci\u00f3n'' similar al utilizado en los sistemas cooperativos de almacenamiento en cach\u00e9 web -LSB-11-RSB-. Un servidor redirector, interpuesto entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la funci\u00f3n de los servidores remotos. Si la solicitud del cliente no se puede atender localmente, el redirector la reenv\u00eda a un servidor remoto. Cuando uno de los clientes del grupo recupera un objeto compartido del repositorio, es probable que otros clientes necesiten el objeto. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en cach\u00e9. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de inter\u00e9s potencial para todos los miembros del grupo.BuddyCache utiliza la redirecci\u00f3n para admitir la actualizaci\u00f3n entre pares, una t\u00e9cnica ligera de \"multidifusi\u00f3n a nivel de aplicaci\u00f3n\" que proporciona a los miembros del grupo acceso consistente a los nuevos datos confirmados dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirecci\u00f3n interfiere con la disponibilidad de objetos compartidos. Solo commit es una t\u00e9cnica de validaci\u00f3n utilizada por BuddyCache para evitar dependencias de clientes no deseadas que reducen la disponibilidad de objetos cuando algunos nodos de clientes en el grupo son lentos o los clientes fallan de forma independiente. Una caracter\u00edstica destacada del compromiso individual es admitir una validaci\u00f3n detallada utilizando informaci\u00f3n de coherencia de grano grueso y econ\u00f3mica. Dise\u00f1amos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios y costos de rendimiento utilizando modelos anal\u00edticos y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos c\u00f3mo la latencia de la red afecta el equilibrio costo-beneficio. Estas fuertes mejoras en el rendimiento podr\u00edan hacer que los sistemas de almacenamiento de objetos transaccionales sean m\u00e1s atractivos para aplicaciones colaborativas en entornos de \u00e1rea amplia. 2. TRABAJOS RELACIONADOS Las t\u00e9cnicas de almacenamiento en cach\u00e9 cooperativas -LSB- 20, 16, 13, 2, 28 -RSB- brindan acceso a las cach\u00e9s de los clientes para evitar una alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de \u00e1rea local r\u00e1pida. Estas t\u00e9cnicas utilizan el servidor para proporcionar redirecci\u00f3n y no consideran problemas de alta latencia de la red. Las t\u00e9cnicas cooperativas de almacenamiento en cach\u00e9 web, -LRB-, por ejemplo, -LSB- 11, 15 -RSB- -RRB-, investigan problemas relacionados con el mantenimiento de un directorio de objetos almacenados en cach\u00e9 en cach\u00e9s proxy cercanos en un entorno de \u00e1rea amplia, utilizando protocolos de directorio distribuidos para rastrear los cambios en el cach\u00e9. Este trabajo no considera problemas de actualizaciones simult\u00e1neas consistentes de objetos detallados compartidos. Esta soluci\u00f3n de nivel de transporte de multidifusi\u00f3n est\u00e1 orientada a la sem\u00e1ntica de un solo escritor de objetos web. Por el contrario, BuddyCache utiliza multidifusi\u00f3n \"a nivel de aplicaci\u00f3n\" y un protocolo de coherencia confiable para el remitente para proporcionar mejoras similares en la latencia de acceso para objetos transaccionales. Pendarakis, Shi y Verma describieron una soluci\u00f3n de multidifusi\u00f3n a nivel de aplicaci\u00f3n en un sistema middleware en -LSB-27-RSB-. El esquema admite peque\u00f1os grupos de m\u00faltiples remitentes apropiados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallas, pero no admite una coherencia s\u00f3lida ni un intercambio detallado. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallas y aprovecha los cach\u00e9s cercanos para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulaci\u00f3n para investigar problemas de latencia y tolerancia a fallas en un esquema de coherencia basado en evitaci\u00f3n jer\u00e1rquica. Por el contrario, nuestro trabajo utiliza la implementaci\u00f3n y el an\u00e1lisis para evaluar los costos y beneficios de la redirecci\u00f3n y las actualizaciones detalladas en un sistema optimista. anderson,Eastham y Vahdat en WebFS -LSB- 29 -RSB- presentan un protocolo de coherencia del sistema de archivos global que permite a los clientes elegir por archivo entre recibir actualizaciones o invalidaciones. Las actualizaciones e invalidaciones se multidifunden en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota m\u00e9todos espec\u00edficos de la aplicaci\u00f3n, por ejemplo, la pol\u00edtica del \u00faltimo escritor gana para aplicaciones de difusi\u00f3n, para tratar con actualizaciones simult\u00e1neas, pero se limita a los sistemas de archivos. BuddyCache proporciona mejoras similares en el ancho de banda cuando hay objetos disponibles en la cach\u00e9 del grupo. 7. CONCLUSI\u00d3N Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea com\u00fan. Requieren una gran coherencia para los datos persistentes compartidos y un acceso eficiente a objetos detallados. Estas propiedades son dif\u00edciles de proporcionar en una red de \u00e1rea amplia debido a la alta latencia de la red. Este art\u00edculo describe BuddyCache, una nueva t\u00e9cnica de almacenamiento en cach\u00e9 cooperativo transaccional -LSB- 20, 16, 13, 2, 28 -RSB- que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de fuerte consistencia en entornos de red de alta latencia. La t\u00e9cnica mejora el rendimiento pero proporciona s\u00f3lidas propiedades de correcci\u00f3n y disponibilidad en presencia de fallas de nodos y clientes lentos. Sin embargo, la redirecci\u00f3n puede interferir con la disponibilidad del objeto. El compromiso individual es una nueva t\u00e9cnica de validaci\u00f3n que permite a un cliente de un grupo comprometerse independientemente de pares lentos o fallidos. Proporciona una validaci\u00f3n detallada utilizando informaci\u00f3n de versi\u00f3n econ\u00f3mica de grano grueso. Hemos dise\u00f1ado e implementado el prototipo BuddyCache en el sistema distribuido de almacenamiento de objetos transaccionales Thor -LSB- 23 -RSB- y evaluamos los beneficios y costos del sistema en una variedad de latencias de red. acceso de gran consistencia y granularidad fina en entornos de alta latencia, 2. una implementaci\u00f3n del prototipo del sistema que produce fuertes ganancias de rendimiento sobre el sistema base, 3. evaluaci\u00f3n del rendimiento basada en an\u00e1lisis y mediciones de los costos y beneficios de las nuevas t\u00e9cnicas que capturan el Costo de rendimiento dominante, alta latencia de red.una nueva t\u00e9cnica de almacenamiento en cach\u00e9 cooperativo transaccional -LSB- 20, 16, 13, 2, 28 -RSB- que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de fuerte consistencia en entornos de red de alta latencia. La t\u00e9cnica mejora el rendimiento pero proporciona s\u00f3lidas propiedades de correcci\u00f3n y disponibilidad en presencia de fallas de nodos y clientes lentos. Sin embargo, la redirecci\u00f3n puede interferir con la disponibilidad del objeto. El compromiso individual es una nueva t\u00e9cnica de validaci\u00f3n que permite a un cliente de un grupo comprometerse independientemente de pares lentos o fallidos. Proporciona una validaci\u00f3n detallada utilizando informaci\u00f3n de versi\u00f3n econ\u00f3mica de grano grueso. Hemos dise\u00f1ado e implementado el prototipo BuddyCache en el sistema distribuido de almacenamiento de objetos transaccionales Thor -LSB- 23 -RSB- y evaluamos los beneficios y costos del sistema en una variedad de latencias de red. acceso de gran consistencia y granularidad fina en entornos de alta latencia, 2. una implementaci\u00f3n del prototipo del sistema que produce fuertes ganancias de rendimiento sobre el sistema base, 3. evaluaci\u00f3n del rendimiento basada en an\u00e1lisis y mediciones de los costos y beneficios de las nuevas t\u00e9cnicas que capturan el Costo de rendimiento dominante, alta latencia de red.una nueva t\u00e9cnica de almacenamiento en cach\u00e9 cooperativo transaccional -LSB- 20, 16, 13, 2, 28 -RSB- que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de fuerte consistencia en entornos de red de alta latencia. La t\u00e9cnica mejora el rendimiento pero proporciona s\u00f3lidas propiedades de correcci\u00f3n y disponibilidad en presencia de fallas de nodos y clientes lentos. Sin embargo, la redirecci\u00f3n puede interferir con la disponibilidad del objeto. El compromiso individual es una nueva t\u00e9cnica de validaci\u00f3n que permite a un cliente de un grupo comprometerse independientemente de pares lentos o fallidos. Proporciona una validaci\u00f3n detallada utilizando informaci\u00f3n de versi\u00f3n econ\u00f3mica de grano grueso. Hemos dise\u00f1ado e implementado el prototipo BuddyCache en el sistema distribuido de almacenamiento de objetos transaccionales Thor -LSB- 23 -RSB- y evaluamos los beneficios y costos del sistema en una variedad de latencias de red. acceso de gran consistencia y granularidad fina en entornos de alta latencia, 2. una implementaci\u00f3n del prototipo del sistema que produce fuertes ganancias de rendimiento sobre el sistema base, 3. evaluaci\u00f3n del rendimiento basada en an\u00e1lisis y mediciones de los costos y beneficios de las nuevas t\u00e9cnicas que capturan el Costo de rendimiento dominante, alta latencia de red.", "keyphrases": ["sistema de almacenamiento de objetos", "aplicaci\u00f3n de colaboraci\u00f3n fuerte y consistente", "red de \u00e1rea amplia", "cach\u00e9 web de cobre", "participaci\u00f3n de grano fino", "tramitar", "propiedad de tolerancia a fallos", "amigocach", "costo de ejecuci\u00f3n dominante", "sistema optimista", "b\u00fasqueda de pares", "punto de referencia oo7 multiusuario"]}
{"file_name": "J-17", "text": "Dise\u00f1o veraz de mecanismos para programaci\u00f3n multidimensional a trav\u00e9s de monotonicidad de ciclo RESUMEN Consideramos el problema de la minimizaci\u00f3n de makepan en m m\u00e1quinas no relacionadas en el context del dise\u00f1o de mecanismos algor\u00edtmicos, donde las m\u00e1quinas son los jugadores estrat\u00e9gicos. Este es un dominio de programaci\u00f3n multidimensional, y los \u00fanicos resultados positivos conocidos para la minimizaci\u00f3n de makepan en dicho dominio son O -LRB- m -RRB- - mecanismos veraces de aproximaci\u00f3n -LSB- 22, 20 -RSB-. Estudiamos un caso especial bien motivado de este problema, donde el tiempo de procesamiento de un trabajo en cada m\u00e1quina puede ser \"bajo\" o \"alto\", y los valores bajo y alto son p\u00fablicos y dependen del trabajo. Esto preserva la multidimensionalidad del dominio y generaliza la configuraci\u00f3n de m\u00e1quinas restringidas -LRB- es decir, -LCB- pj, \u221e -RCB- -RRB- en la programaci\u00f3n. Damos una t\u00e9cnica general para convertir cualquier algoritmo de aproximaci\u00f3n c en un mecanismo de aproximaci\u00f3n veraz en expectativas de 3. Este es uno de los pocos resultados conocidos que muestra c\u00f3mo exportar algoritmos de aproximaci\u00f3n para un problema multidimensional a mecanismos veraces en forma de caja negra. Cuando los valores alto y bajo son los mismos para todos los trabajos, dise\u00f1amos un mecanismo veraz determinista de 2 aproximaciones. Estos son los primeros mecanismos veraces con garant\u00edas de rendimiento no triviales para un dominio de programaci\u00f3n multidimensional. Nuestras construcciones son novedosas en dos aspectos. En primer lugar, no utilizamos ni nos basamos en definiciones de precios expl\u00edcitas para demostrar la veracidad; en lugar de ello, dise\u00f1amos algoritmos que satisfacen la monotonicidad del ciclo. La monotonicidad del ciclo -LSB- 23 -RSB- es una condici\u00f3n necesaria y suficiente para la veracidad, es una generalizaci\u00f3n de la monotonicidad del valor para dominios multidimensionales. Sin embargo, mientras que la monotonicidad de valores se ha utilizado extensamente y con \u00e9xito para dise\u00f1ar mecanismos veraces en dominios unidimensionales, el nuestro es el primer trabajo que aprovecha la monotonicidad del ciclo en un entorno multidimensional. En segundo lugar, nuestros mecanismos aleatorios se obtienen construyendo primero un mecanismo veraz fraccional para una relajaci\u00f3n fraccionaria del problema y luego convirti\u00e9ndolo en un mecanismo veraz en expectativa. Esto se basa en una t\u00e9cnica de -LSB- 16 -RSB- y muestra la utilidad de los mecanismos fraccionarios en el dise\u00f1o veraz de mecanismos. 1. INTRODUCCI\u00d3N El dise\u00f1o de mecanismos estudia construcciones algor\u00edtmicas bajo la presencia de actores estrat\u00e9gicos que contienen las entradas del algoritmo. El dise\u00f1o de mecanismos algor\u00edtmicos se ha centrado principalmente en entornos en los que el planificador o dise\u00f1ador social desea maximizar el bienestar social -LRB- o, equivalentemente, minimizar el coste social -RRB-, o en entornos de subastas donde el objetivo principal es la maximizaci\u00f3n de los ingresos. En este art\u00edculo, consideramos un objetivo alternativo en el context de la programaci\u00f3n de m\u00e1quinas, a saber, la minimizaci\u00f3n del makepan. Hay n trabajos o tareas que deben asignarse a m m\u00e1quinas, donde cada trabajo debe asignarse exactamente a una m\u00e1quina. Por lo tanto, abordamos el problema mediante el dise\u00f1o de mecanismos:el dise\u00f1ador social, que tiene el conjunto de tareas a asignar, debe especificar, adem\u00e1s de un cronograma, pagos adecuados a los jugadores para incentivarlos a revelar sus verdaderos tiempos de procesamiento. A este mecanismo se le llama mecanismo veraz. En cambio, corresponde a maximizar el bienestar m\u00ednimo y la noci\u00f3n de equidad m\u00e1ximo-m\u00ednimo, y parece ser un problema mucho m\u00e1s dif\u00edcil desde el punto de vista del dise\u00f1o del mecanismo. En particular, la c\u00e9lebre familia de mecanismos VCG -LSB- 26, 9, 10 -RSB- no se aplica aqu\u00ed, y necesitamos idear nuevas t\u00e9cnicas. La posibilidad de construir un mecanismo veraz para la minimizaci\u00f3n del makepan est\u00e1 fuertemente relacionada con las suposiciones sobre los tiempos de procesamiento de los jugadores, en particular, la ``dimensionalidad'' del dominio. Nisan y Ronen consideraron la configuraci\u00f3n de m\u00e1quinas no relacionadas donde los valores de pij pueden ser arbitrarios. Este es un dominio multidimensional, ya que el valor privado de un jugador es su vector completo de tiempos de procesamiento -LRB- pij -RRB- j. Se conocen muy pocos resultados positivos para dominios multidimensionales en general, y los \u00fanicos resultados positivos conocidos para la programaci\u00f3n multidimensional son O -LRB- m -RRB- - mecanismos veraces de aproximaci\u00f3n -LSB- 22, 20 -RSB-. Enfatizamos que, independientemente de las consideraciones computacionales, incluso la existencia de un mecanismo veraz con una relaci\u00f3n de aproximaci\u00f3n -LRB- que m -RRB- significativamente mejor no se conoce para ning\u00fan dominio de programaci\u00f3n de este tipo. En el lado negativo, -LSB- 22 -RSB- demostr\u00f3 que ning\u00fan mecanismo determinista verdadero puede lograr una relaci\u00f3n de aproximaci\u00f3n mejor que 2, y fortaleci\u00f3 este l\u00edmite inferior a m para dos clases espec\u00edficas de mecanismos deterministas. Recientemente, -LSB- 20 -RSB- ampli\u00f3 este l\u00edmite inferior a mecanismos aleatorios, y -LSB- 8 -RSB- mejor\u00f3 el l\u00edmite inferior determinista. En marcado contraste con la situaci\u00f3n anterior, se conocen resultados positivos mucho m\u00e1s fuertes -LRB- y muchos m\u00e1s -RRB- para un caso especial del problema de m\u00e1quinas no relacionadas, es decir, la configuraci\u00f3n de m\u00e1quinas relacionadas. Aqu\u00ed tenemos pij = pj/si para cada i, j, donde pj es de conocimiento p\u00fablico y la velocidad si es el \u00fanico par\u00e1metro privado de la m\u00e1quina i. Esta suposici\u00f3n hace que el dominio de los tipos de jugadores sea unidimensional. La veracidad en tales dominios es equivalente a una condici\u00f3n conveniente de monotonicidad de valores -LSB- 21, 3 -RSB-, que parece hacer que sea significativamente m\u00e1s f\u00e1cil dise\u00f1ar mecanismos veraces en tales dominios. Archer y Tardos -LSB- 3 -RSB- consideraron primero la configuraci\u00f3n de las m\u00e1quinas relacionadas y dieron un mecanismo aleatorio de 3 aproximaciones veraces en las expectativas. La brecha entre los dominios unidimensional y multidimensional quiz\u00e1s se ejemplifique mejor por el hecho de que -LSB- 3 -RSB- demostr\u00f3 que existe un mecanismo veraz que siempre genera un cronograma \u00f3ptimo. -LRB- Recuerde que en el entorno de m\u00e1quinas multidimensionales no relacionadas, es imposible obtener un mecanismo veraz con una relaci\u00f3n de aproximaci\u00f3n mejor que 2. -RRB- Varios resultados de seguimiento -LSB- 2,4, 1, 13 -RSB- han fortalecido la noci\u00f3n de veracidad y/o mejorado el ratio de aproximaci\u00f3n. Estas dificultades para pasar del entorno unidimensional al multidimensional tambi\u00e9n surgen en otros entornos de dise\u00f1o de mecanismos -LRB-, por ejemplo, las subastas combinatorias -RRB-. Por lo tanto, adem\u00e1s de la importancia espec\u00edfica de la programaci\u00f3n en entornos estrat\u00e9gicos, las ideas de la programaci\u00f3n multidimensional tambi\u00e9n pueden tener relevancia en el context m\u00e1s general del dise\u00f1o veraz de mecanismos para dominios multidimensionales. En este art\u00edculo, consideramos el problema de minimizaci\u00f3n de makepan para un caso especial de m\u00e1quinas no relacionadas, donde el tiempo de procesamiento de un trabajo es \"bajo\" o \"alto\" en cada m\u00e1quina. A este modelo lo llamamos el caso de \"dos valores dependientes del trabajo\". Este modelo generaliza la configuraci\u00f3n cl\u00e1sica de \"m\u00e1quinas restringidas\", donde pij \u2208 -LCB- Lj, \u221e -RCB- que ha sido bien estudiado algor\u00edtmicamente. Un caso especial de nuestro modelo es cuando Lj = L y Hj = H para todos los trabajos j, lo que denotamos simplemente como modelo de programaci\u00f3n de \"dos valores\". Nuestros dos dominios son multidimensionales, ya que las m\u00e1quinas no est\u00e1n relacionadas: un trabajo puede ser bajo en una m\u00e1quina y alto en la otra, mientras que otro trabajo puede seguir el patr\u00f3n opuesto. As\u00ed, la informaci\u00f3n privada de cada m\u00e1quina es un vector que especifica qu\u00e9 trabajos son bajos y altos en ella. Por lo tanto, conservan la propiedad central que subyace a la dureza del dise\u00f1o veraz de mecanismos para m\u00e1quinas no relacionadas, y al estudiar estas configuraciones especiales esperamos obtener algunas ideas que ser\u00e1n \u00fatiles para abordar el problema general. Nuestros resultados y t\u00e9cnicas Presentamos varios resultados positivos para nuestros dominios de programaci\u00f3n multidimensional. Nuestro primer resultado es un m\u00e9todo general para convertir cualquier algoritmo de aproximaci\u00f3n para la configuraci\u00f3n de dos valores dependientes del trabajo en un mecanismo de aproximaci\u00f3n 3c veraz en las expectativas. Este es uno de los pocos resultados conocidos que utiliza un algoritmo de aproximaci\u00f3n en forma de caja negra para obtener un mecanismo veraz para un problema multidimensional. Nuestro resultado implica que existe un mecanismo de expectativa veraz de 3 aproximaciones para el ajuste Lj-Hj. Nuestro segundo resultado se aplica al establecimiento de dos valores -LRB- Lj = L, Hj = H -RRB-, para lo cual mejoramos tanto la relaci\u00f3n de aproximaci\u00f3n como fortalecemos la noci\u00f3n de veracidad. Obtenemos un mecanismo veraz determinista de 2 aproximaciones -LRB- junto con los precios -RRB- para este problema. Estos son los primeros mecanismos veraces con garant\u00edas de rendimiento no triviales para un dominio de programaci\u00f3n multidimensional. Complementando esto, observamos que incluso esta configuraci\u00f3n aparentemente simple no admite mecanismos veraces que devuelvan un horario \u00f3ptimo -LRB- a diferencia del caso de m\u00e1quinas relacionadas -RRB-. Al explotar la multidimensionalidad del dominio, demostramos que ning\u00fan mecanismo determinista verdadero puede obtener una relaci\u00f3n de aproximaci\u00f3n mejor que 1,14 para el makepan -LRB-, independientemente de las consideraciones computacionales -RRB-.La t\u00e9cnica principal, y una de las novedades, que subyace a nuestras construcciones y pruebas, es que no nos basamos en especificaciones de precios expl\u00edcitas para demostrar la veracidad de nuestros mecanismos. En lugar de ello, explotamos ciertas condiciones de monotonicidad algor\u00edtmica que caracterizan la veracidad para dise\u00f1ar primero un algoritmo implementable, es decir, un algoritmo para el cual existen precios que garanticen la veracidad, y luego encontrar estos precios -LRB- profundizando m\u00e1s en la prueba de implementabilidad -RRB-. Este tipo de an\u00e1lisis ha sido el m\u00e9todo elegido en el dise\u00f1o de mecanismos veraces para dominios unidimensionales, donde la monotonicidad del valor produce una caracterizaci\u00f3n conveniente que permite concentrarse en el lado algor\u00edtmico del problema -LRB- ver, por ejemplo, -LSB- 3 , 7, 4, 1, 13 -RSB- -RRB-. Nuestro trabajo es el primero en aprovechar las condiciones de monotonicidad para un dise\u00f1o veraz de mecanismos en dominios arbitrarios. La condici\u00f3n de monotonicidad que utilizamos, que a veces se denomina monotonicidad de ciclo, fue propuesta por primera vez por Rochet -LSB- 23 -RSB- -LRB- v\u00e9ase tambi\u00e9n -LSB- 11 -RSB- -RRB-. Es una generalizaci\u00f3n de la monoton\u00eda de valores y caracteriza completamente la veracidad en todos los \u00e1mbitos. Nuestros m\u00e9todos y an\u00e1lisis demuestran los beneficios potenciales de esta caracterizaci\u00f3n y muestran que la monotonicidad del ciclo se puede utilizar de manera efectiva para dise\u00f1ar mecanismos veraces para dominios multidimensionales. Considere, por ejemplo, nuestro primer resultado que muestra que cualquier algoritmo de aproximaci\u00f3n c puede \"exportarse\" a un mecanismo veraz en expectativas de aproximaci\u00f3n 3c. En el nivel de generalidad de un algoritmo de aproximaci\u00f3n arbitraria, parece poco probable que se puedan obtener precios para demostrar la veracidad del mecanismo construido. Pero la monotonicidad del ciclo nos permite probar tal afirmaci\u00f3n. De hecho, alguna condici\u00f3n de este tipo basada \u00fanicamente en el algoritmo subyacente -LRB- y no en los precios -RRB- parece necesaria para probar tal afirmaci\u00f3n general. El m\u00e9todo para convertir algoritmos de aproximaci\u00f3n en mecanismos veraces implica otra idea novedosa. Nuestro mecanismo aleatorio se obtiene construyendo primero un mecanismo veraz que devuelva un programa fraccionario. Pasar a un dominio fraccionario nos permite \"integrar\" la veracidad en el algoritmo de aproximaci\u00f3n de una manera bastante simple, mientras perdemos un factor de 2 en la relaci\u00f3n de aproximaci\u00f3n. Luego utilizamos un procedimiento de redondeo aleatorio adecuado para convertir la asignaci\u00f3n fraccionaria en una asignaci\u00f3n integral aleatoria. Esto preserva la veracidad, pero perdemos otro factor aditivo igual a la relaci\u00f3n de aproximaci\u00f3n. Nuestra construcci\u00f3n utiliza y ampl\u00eda algunas observaciones de Lavi y Swamy -LSB- 16 -RSB-, y demuestra a\u00fan m\u00e1s los beneficios de los mecanismos fraccionarios en el dise\u00f1o veraz de mecanismos. Trabajo relacionado Nisan y Ronen -LSB- 22 -RSB- consideraron por primera vez el problema de minimizaci\u00f3n de makepan para m\u00e1quinas no relacionadas. Dieron un resultado positivo de aproximaci\u00f3n m y demostraron varios l\u00edmites inferiores. Esto se ha mejorado en -LSB- 2, 4,1, 13 -RSB- a: un mecanismo aleatorio de 2 aproximaciones -LSB- 2 -RSB-; un FPTAS para cualquier n\u00famero fijo de m\u00e1quinas dado por Andelman, Azar y Sorani -LSB- 1 -RSB-, y un mecanismo determinista de 3 aproximaciones por Kov \u00b4 acs -LSB- 13 -RSB-. El problema algor\u00edtmico -LRB- es decir, sin requerir veracidad -RRB- de la minimizaci\u00f3n de makepan en m\u00e1quinas no relacionadas se comprende bien y se conocen varios algoritmos de 2 aproximaciones. Lenstra, Shmoys y Tardos -LSB- 18 -RSB- dieron el primer algoritmo de este tipo. Shmoys y Tardos -LSB- 25 -RSB- posteriormente dieron un algoritmo de aproximaci\u00f3n 2 para el problema de asignaci\u00f3n generalizada, una generalizaci\u00f3n donde hay un costo cij por asignar un trabajo j a una m\u00e1quina i, y el objetivo es minimizar el costo sujeto a a atado en el makepan. Recientemente, Kumar, Marathe, Parthasarathy y Srinivasan -LSB- 14 -RSB- dieron un algoritmo de redondeo aleatorio que produce los mismos l\u00edmites. Usamos su procedimiento en nuestro mecanismo aleatorio. La caracterizaci\u00f3n de la veracidad para dominios arbitrarios en t\u00e9rminos de monotonicidad del ciclo parece haber sido observada por primera vez por Rochet -LSB- 23 -RSB- -LRB- v\u00e9ase tambi\u00e9n Gui et al. -LSB- 11 -RSB- -RRB-. Esto generaliza la condici\u00f3n de monotonicidad de valor para dominios unidimensionales dada por Myerson -LSB- 21 -RSB- y redescubierta por -LSB- 3 -RSB-. Como se mencion\u00f3 anteriormente, esta condici\u00f3n ha sido explotada en numerosas ocasiones para obtener mecanismos veraces para dominios unidimensionales -LSB- 3, 7, 4, 1, 13 -RSB-. Para dominios convexos -LRB- es decir, el conjunto de valores privados de cada jugador es convexo -RRB-, se sabe que la monotonicidad del ciclo est\u00e1 impl\u00edcita en una condici\u00f3n m\u00e1s simple, llamada monotonicidad d\u00e9bil -LSB- 15, 6, 24 -RSB-. Pero incluso esta condici\u00f3n m\u00e1s simple no ha encontrado mucha aplicaci\u00f3n en el dise\u00f1o veraz de mecanismos para problemas multidimensionales. Otros objetivos distintos de la maximizaci\u00f3n del bienestar social y la maximizaci\u00f3n de los ingresos han recibido muy poca atenci\u00f3n en el dise\u00f1o del mecanismo. En el context de las subastas combinatorias, se han estudiado brevemente los problemas de maximizar el valor m\u00ednimo recibido por un jugador y calcular una asignaci\u00f3n que minimice la envidia. Lavi, Mu'alem y Nisan -LSB- 15 -RSB- demostraron que el primer objetivo no puede implementarse sinceramente; Bezakova y Dani -LSB- 5 -RSB- dieron un mecanismo de aproximaci\u00f3n de 0,5 para dos jugadores con valoraciones aditivas. Estos l\u00edmites inferiores se reforzaron en -LSB- 20 -RSB-. 2. PRELIMINARES 2.1 El dominio de la programaci\u00f3n En nuestro problema de programaci\u00f3n, tenemos n trabajos y m m\u00e1quinas, y cada trabajo debe asignarse exactamente a una m\u00e1quina. En el entorno de m\u00e1quinas no relacionadas, cada m\u00e1quina i se caracteriza por un vector de tiempos de procesamiento -LRB- pij -RRB- j, donde pij ER \u2265 0 U -LCB- oo -RCB- denota el tiempo de procesamiento de i para el trabajo j con el valor oo especifica que no puedo procesar j. Consideramos dos casos especiales de este problema: 1. El caso de dos valores dependientes del trabajo, donde pij E -LCB- Lj, Hj -RCB- para cada i, j, con Lj < Hj, y los valores Lj, Hj son conocido.Esto generaliza el modelo cl\u00e1sico de programaci\u00f3n de m\u00e1quinas restringidas, donde Hj = oo. 2. Decimos que un trabajo j tiene poca m\u00e1quina i si pij = Lj, y alta si pij = Hj. Usaremos los t\u00e9rminos cronograma y asignaci\u00f3n indistintamente. Tambi\u00e9n consideraremos algoritmos aleatorios y algoritmos que devuelven una asignaci\u00f3n fraccionaria. Denotamos la carga de la m\u00e1quina i -LRB- bajo una asignaci\u00f3nj xijpij dada, y el makepan de un programa se define como la carga m\u00e1xima en cualquier m\u00e1quina, es decir, maxi li. El objetivo del problema de minimizaci\u00f3n del per\u00edodo de producci\u00f3n es asignar los trabajos a las m\u00e1quinas para minimizar el per\u00edodo de producci\u00f3n del cronograma. 2.2 Dise\u00f1o de mecanismos Consideramos el problema de minimizaci\u00f3n de makepan en los dominios de programaci\u00f3n anteriores en el context del dise\u00f1o de mecanismos. El dise\u00f1o de mecanismos estudia escenarios estrat\u00e9gicos donde el dise\u00f1ador social necesita asegurar la cooperaci\u00f3n de las diferentes entidades involucradas en el procedimiento algor\u00edtmico. Siguiendo el trabajo de Nisan y Ronen -LSB- 22 -RSB-, consideramos a las m\u00e1quinas como los actores o agentes estrat\u00e9gicos. El dise\u00f1ador social tiene el conjunto de trabajos que deben asignarse, pero no conoce los tiempos de procesamiento -LRB- verdadero -RRB- de estos trabajos en las diferentes m\u00e1quinas. Cada m\u00e1quina es una entidad ego\u00edsta, que en privado conoce su propio tiempo de procesamiento para cada trabajo. Consideramos mecanismos de revelaci\u00f3n directa: cada m\u00e1quina informa su -LRB- posiblemente falso -RRB- vector de tiempos de procesamiento, el mecanismo luego calcula un cronograma y reparte pagos a los jugadores -LRB- es decir, las m\u00e1quinas -RRB- para compensarlos por el costo en el que incurren al procesar sus trabajos asignados. Un mecanismo -LRB- de revelaci\u00f3n directa -RRB- consta as\u00ed de una tupla -LRB- x, P -RRB- : x especifica el cronograma y P = -LCB- Pi -RCB- especifica los pagos entregados a las m\u00e1quinas, donde tanto x como Pis son funciones de los tiempos de procesamiento informados p = -LRB- pij -RRB- i, j. Por lo tanto, el mecanismo debe incentivar a las m\u00e1quinas/jugadores a revelar verazmente sus tiempos de procesamiento a trav\u00e9s de los pagos. Esto se precisa utilizando la noci\u00f3n de veracidad de la estrategia dominante. Para decirlo con palabras, en un mecanismo veraz, ninguna m\u00e1quina puede mejorar su utilidad declarando un tiempo de procesamiento falso, sin importar lo que declaren las otras m\u00e1quinas. Tambi\u00e9n consideraremos mecanismos fraccionarios que devuelven una asignaci\u00f3n fraccionaria y mecanismos aleatorios a los que se les permite lanzar monedas y donde la asignaci\u00f3n y los pagos pueden ser variables aleatorias. La noci\u00f3n de veracidad para un mecanismo fraccionario es la misma que en la Definici\u00f3n 2.1, donde x1, x2 ahora son asignaciones fraccionarias. Para un mecanismo aleatorio, consideraremos la noci\u00f3n de veracidad en la expectativa -LSB- 3 -RSB-, lo que significa que una m\u00e1quina -LRB- jugador -RRB- maximiza su utilidad esperada al declarar su verdadero vector de tiempo de procesamiento. Para nuestros dos dominios de programaci\u00f3n, el supuesto informativo es que los valores Lj, Hj son p\u00fablicamente conocidos.La informaci\u00f3n privada de una m\u00e1quina es qu\u00e9 trabajos tienen el valor Lj -LRB- o L -RRB- y cu\u00e1les tienen el valor Hj -LRB- o H -RRB-. Hacemos hincapi\u00e9 en que nuestros dos dominios son multidimensionales, ya que cada m\u00e1quina i necesita especificar un vector que indique qu\u00e9 trabajos son bajos y altos en ella.", "keyphrases": ["dise\u00f1o mec\u00e1nico", "algoritmo aproximado", "programar", "programaci\u00f3n multidimensional", "ciclo mon\u00f3tono", "hace que la amplitud sea m\u00ednima", "algoritmo", "mecanismo aleatorio", "nosotros de fracci\u00f3n mec\u00e1nica", "dise\u00f1o mec\u00e1nico de la verdad", "dominio de fracci\u00f3n"]}
{"file_name": "I-26", "text": "Toma de decisiones secuencial en una b\u00fasqueda econ\u00f3mica bilateral paralela RESUMEN Este art\u00edculo presenta un modelo de b\u00fasqueda econ\u00f3mica bilateral en el que los agentes buscan asociaciones beneficiosas por pares. En cada etapa de b\u00fasqueda, cada uno de los agentes se empareja aleatoriamente con varios otros agentes en paralelo y toma la decisi\u00f3n de aceptar una posible asociaci\u00f3n con uno de ellos. La caracter\u00edstica distintiva del modelo propuesto es que los agentes no est\u00e1n restringidos a mantener un protocolo de decisi\u00f3n sincronizado -LRB- instant\u00e1neo -RRB- y pueden aceptar y rechazar secuencialmente asociaciones dentro de la misma etapa de b\u00fasqueda. Analizamos la din\u00e1mica que impulsa las estrategias de los agentes hacia un equilibrio estable en el nuevo modelo y mostramos que la estrategia de b\u00fasqueda propuesta domina d\u00e9bilmente la que actualmente se utiliza para el modelo de b\u00fasqueda econ\u00f3mica paralela bilateral. Al identificar varias caracter\u00edsticas \u00fanicas del equilibrio, logramos delimitar eficientemente el espacio de estrategias que debe ser explorado por los agentes y proponer un medio eficiente para extraer las estrategias de equilibrio distribuido en entornos comunes. 1. INTRODUCCI\u00d3N Una b\u00fasqueda econ\u00f3mica bilateral es un mecanismo distribuido para formar asociaciones por parejas de agentes -LSB- 5 -RSB-.1 En cada etapa del proceso, cada uno de los agentes se empareja aleatoriamente con otro agente 1. Observe que el concepto de ''b\u00fasqueda'' aqu\u00ed es muy diferente de la definici\u00f3n cl\u00e1sica de ''b\u00fasqueda'' en IA. Si bien la b\u00fasqueda por IA es un proceso activo en el que un agente encuentra una secuencia de acciones que lo llevar\u00e1n del estado inicial al estado objetivo, la b\u00fasqueda econ\u00f3mica se refiere a la identificaci\u00f3n del mejor agente con el que comprometerse en una asociaci\u00f3n. y los dos interact\u00faan bilateralmente para aprender el beneficio que se resume en una asociaci\u00f3n entre ellos. La interacci\u00f3n no implica negociaci\u00f3n, por lo que cada agente simplemente necesita elegir entre aceptar o rechazar la asociaci\u00f3n con el otro agente. Un mercado t\u00edpico en el que se realiza este tipo de b\u00fasqueda bilateral es el mercado matrimonial -LSB- 22 -RSB-. La literatura reciente sugiere varias aplicaciones basadas en agentes de software en las que se realiza una b\u00fasqueda distribuida bilateral -LRB-, es decir, sin mecanismos de coincidencia centralizados -RRB-. Una clase importante de tales aplicaciones incluye los mercados secundarios para el intercambio de recursos no explotados. Por ejemplo, mediante una b\u00fasqueda bilateral, los agentes, que representan a diferentes proveedores de servicios, pueden intercambiar ancho de banda no utilizado -LSB- 21 -RSB- y los sat\u00e9lites de comunicaciones pueden transferir comunicaciones con una mayor cobertura geogr\u00e1fica. La b\u00fasqueda bilateral basada en agentes tambi\u00e9n se puede encontrar en aplicaciones de compradores y vendedores en mercados electr\u00f3nicos y aplicaciones peer-to-peer. La naturaleza bilateral de la b\u00fasqueda sugiere que una asociaci\u00f3n entre un par de agentes s\u00f3lo se forma si es mutuamente aceptada. Al formar una sociedad, los agentes obtienen una utilidad inmediata y ponen fin a su b\u00fasqueda. Al reanudar la b\u00fasqueda,por otro lado, es posible que se encuentre un socio m\u00e1s adecuado, aunque ser\u00e1 necesario consumir algunos recursos para mantener el proceso de b\u00fasqueda. En este art\u00edculo nos centramos en una clase espec\u00edfica de problemas de b\u00fasqueda bilateral, en los que el desempe\u00f1o de la asociaci\u00f3n se aplica a ambas partes, es decir, ambas obtienen la misma utilidad -LSB- 13 -RSB-. El escenario de igualdad de utilidad suele ser aplicable en \u00e1mbitos donde los socios se benefician de la sinergia entre ellos. En todas estas aplicaciones, dos agentes cualesquiera pueden formar una sociedad y el desempe\u00f1o de cualquier sociedad determinada depende de las habilidades o caracter\u00edsticas de sus miembros. Adem\u00e1s, el escenario de igualdad de utilidad tambi\u00e9n puede ser v\u00e1lido siempre que exista una opci\u00f3n de pagos laterales y la utilidad general de la asociaci\u00f3n se divida equitativamente entre los dos agentes que la forman -LSB- 22 -RSB-. Si bien la literatura de b\u00fasqueda bilateral ofrece un an\u00e1lisis de equilibrio integral para varios modelos, supone que la b\u00fasqueda de los agentes se realiza de manera puramente secuencial: cada agente localiza e interact\u00faa con otro agente en su entorno a la vez -LSB- 5, 22 -RSB-. Sin embargo, cuando la b\u00fasqueda se asigna a agentes software aut\u00f3nomos se puede utilizar una mejor estrategia de b\u00fasqueda. Aqu\u00ed un agente puede aprovechar sus capacidades \u00fanicas inherentes de filtrado y procesamiento de informaci\u00f3n y su capacidad de mantener de manera eficiente -LRB- en comparaci\u00f3n con las personas -RRB- interacciones simult\u00e1neas con varios otros agentes en cada etapa de su b\u00fasqueda. Tal uso de interacciones paralelas en la b\u00fasqueda es favorable siempre que el costo promedio2 por interacci\u00f3n con otro agente, cuando se interact\u00faa en paralelo con un lote de otros agentes, es menor que el costo de mantener una interacci\u00f3n a la vez -LRB- es decir, ventaja de tama\u00f1o. -RRB-. Por ejemplo, el an\u00e1lisis de los costos asociados con la evaluaci\u00f3n de posibles asociaciones entre proveedores de servicios revela componentes tanto fijos como variables cuando se utiliza la b\u00fasqueda paralela, por lo que el costo promedio por interacci\u00f3n disminuye a medida que aumenta el n\u00famero de interacciones paralelas -LSB- 21 -RSB-. A pesar de las ventajas identificadas para las interacciones paralelas en dominios adyacentes -LRB-, por ejemplo, en la b\u00fasqueda econ\u00f3mica unilateral -LSB- 7, 16 -RSB- -RRB-, un primer intento de modelar un proceso repetido de emparejamiento por pares en el que los agentes son capaces de mantener la interacci\u00f3n con varios otros agentes a la vez se introdujo recientemente -LSB-21-RSB-. Sin embargo, los agentes en ese modelo fundamental deben sincronizar su proceso de toma de decisiones. As\u00ed, cada agente, al revisar las oportunidades disponibles en una determinada etapa de b\u00fasqueda, debe comunicar a todos los dem\u00e1s agentes su decisi\u00f3n de comprometerse con una asociaci\u00f3n -LRB- como m\u00e1ximo con uno de ellos -RRB- o rechazar la asociaci\u00f3n -LRB- con el resto -RRB-. Esta restricci\u00f3n inherente impone una limitaci\u00f3n significativa al comportamiento estrat\u00e9gico de los agentes. En nuestro modelo,los agentes son libres de notificar a los dem\u00e1s agentes sus decisiones de forma asincr\u00f3nica. El enfoque asincr\u00f3nico permite a los agentes reevaluar su estrategia, en funci\u00f3n de cada nueva respuesta que reciben de los agentes con los que interact\u00faan. El nuevo modelo es un modelo por pares mucho m\u00e1s realista y, como mostramos en la secci\u00f3n de an\u00e1lisis, siempre es el preferido por cualquier agente individual que participe en el proceso. En ausencia de otros modelos econ\u00f3micos de b\u00fasqueda paralela bilateral, utilizamos el modelo que se basa en un proceso de toma de decisiones instant\u00e1neo -LRB- sincr\u00f3nico -RRB- -LSB- 21 -RSB- -LRB- denotado I-DM durante el resto del el documento -RRB- como punto de referencia para evaluar la utilidad de nuestra estrategia de toma de decisiones secuencial -LRB- asincr\u00f3nica -RRB- propuesta -LRB- denotada S-DM -RRB-. Las principales contribuciones de este art\u00edculo son tres: primero, modelamos y analizamos formalmente un proceso de b\u00fasqueda bilateral en el que los agentes no tienen restricciones temporales en la toma de decisiones con respecto al rechazo o compromiso con asociaciones potenciales que encuentran en paralelo -LRB- la S. -Modelo DM -RRB-. Este modelo es un modelo de b\u00fasqueda general que se puede aplicar en varios dominios -LRB- no necesariamente basados \u200b\u200ben agentes de software -RRB-. En segundo lugar, demostramos que la estrategia SDM de los agentes domina d\u00e9bilmente la estrategia I-DM, por lo que cada agente tiene un incentivo para desviarse hacia la estrategia S-DM cuando todos los dem\u00e1s agentes est\u00e1n utilizando la estrategia I-DM. Finalmente, al utilizar una presentaci\u00f3n recursiva innovadora de las probabilidades de aceptaci\u00f3n de diferentes asociaciones potenciales, identificamos caracter\u00edsticas \u00fanicas de las estrategias de equilibrio en el nuevo modelo. Estos se utilizan para proporcionar un medio computacional apropiado que facilite el c\u00e1lculo de la estrategia de equilibrio de los agentes. Esta \u00faltima contribuci\u00f3n es que logramos extraer las nuevas estrategias de equilibrio de los agentes sin aumentar la complejidad computacional en comparaci\u00f3n con el modelo I-DM. A lo largo del art\u00edculo demostramos las diferentes propiedades del nuevo modelo y lo comparamos con el modelo I-DM utilizando un entorno sint\u00e9tico artificial. En la siguiente secci\u00f3n presentamos formalmente el modelo S-DM. En la Secci\u00f3n 3 se proporciona un an\u00e1lisis de equilibrio y medios computacionales para encontrar la estrategia de equilibrio. En la Secci\u00f3n 4 revisamos la literatura relacionada con la MAS y la teor\u00eda de b\u00fasqueda econ\u00f3mica. 4. TRABAJO RELACIONADO La b\u00fasqueda econ\u00f3mica bilateral de asociaciones en la literatura sobre IA es un subdominio de la formaci\u00f3n de coaliciones8. Como en el caso general 8El uso del t\u00e9rmino ''sociedad'' en este context se refiere al acuerdo entre dos agentes individuales para cooperar de una manera predefinida. Por ejemplo, en la aplicaci\u00f3n comprador-vendedor una sociedad se define como una transacci\u00f3n acordada entre las dos partes -LSB- 9 -RSB-. caso de formaci\u00f3n de coalici\u00f3n,los agentes tienen el incentivo de formar asociaciones cuando son incapaces de ejecutar una tarea por s\u00ed solos o cuando la asociaci\u00f3n puede mejorar sus utilidades individuales -LSB- 14 -RSB-. En la literatura se pueden encontrar diversos mecanismos de emparejamiento centralizado -LSB- 6, 2, 8 -RSB-. Sin embargo, en muchos entornos MAS, en ausencia de un mecanismo de comparaci\u00f3n central confiable, el proceso de comparaci\u00f3n est\u00e1 completamente distribuido. Si bien se reconoce que la b\u00fasqueda en entornos basados \u200b\u200ben agentes es costosa -LSB- 11, 21, 1 -RSB-, la mayor\u00eda de los mecanismos de formaci\u00f3n de coaliciones propuestos suponen que un agente puede explorar tantas oportunidades de asociaci\u00f3n en su entorno como sea necesario o tenga acceso a casadores centrales o agentes intermedios -LSB- 6 -RSB-. La incorporaci\u00f3n de la b\u00fasqueda costosa en este context es bastante rara -LSB- 21 -RSB- y hasta donde sabemos, hasta la fecha no se ha estudiado un modelo de b\u00fasqueda distribuida bilateral de socios similar al modelo S-DM. La teor\u00eda cl\u00e1sica de la b\u00fasqueda econ\u00f3mica -LRB- -LSB- 15, 17 -RSB-, y sus referencias -RRB- aborda ampliamente el problema de un buscador que opera en un entorno costoso, buscando maximizar su utilidad a largo plazo. En estos modelos, clasificados como de b\u00fasqueda unilateral, el foco est\u00e1 en establecer las estrategias \u00f3ptimas para el buscador, asumiendo que no hay actividades de b\u00fasqueda mutua -LRB-, es decir, que no hay influencia sobre el entorno -RRB-. Aqu\u00ed se aplica a menudo el procedimiento de b\u00fasqueda secuencial, lo que permite al buscador investigar una sola oportunidad -LSB- 15 -RSB- o m\u00faltiples -LSB- 7, 19 -RSB- a la vez. Si bien se ha demostrado que este \u00faltimo m\u00e9todo es beneficioso para el buscador, nunca se utiliz\u00f3 en los modelos de b\u00fasqueda '' bilateral '' que siguieron -LRB- donde se modelan actividades de b\u00fasqueda dual -RRB- -LSB- 22, 5, 18 -RSB-. Por tanto, en estos modelos las estrategias de equilibrio siempre se desarrollan partiendo del supuesto de que los agentes interact\u00faan con otros de forma secuencial -LRB- es decir, con un agente a la vez -RRB-. Un primer intento de integrar la b\u00fasqueda paralela en un modelo de b\u00fasqueda bilateral se da en -LSB-21-RSB-, como se detalla en la secci\u00f3n de introducci\u00f3n. Los modelos presentados en esta \u00e1rea no asocian el proceso de formaci\u00f3n de coaliciones con los costos de b\u00fasqueda, que es la esencia del an\u00e1lisis que la teor\u00eda de la b\u00fasqueda econ\u00f3mica pretende ofrecer. Adem\u00e1s, incluso en modelos repetidos de negociaci\u00f3n por pares -LSB- 10 -RSB-, los agentes siempre se limitan a iniciar una \u00fanica interacci\u00f3n de negociaci\u00f3n a la vez.La incorporaci\u00f3n de la b\u00fasqueda costosa en este context es bastante rara -LSB- 21 -RSB- y hasta donde sabemos, hasta la fecha no se ha estudiado un modelo de b\u00fasqueda distribuida bilateral de socios similar al modelo S-DM. La teor\u00eda cl\u00e1sica de la b\u00fasqueda econ\u00f3mica -LRB- -LSB- 15, 17 -RSB-, y sus referencias -RRB- aborda ampliamente el problema de un buscador que opera en un entorno costoso, buscando maximizar su utilidad a largo plazo. En estos modelos, clasificados como de b\u00fasqueda unilateral, el foco est\u00e1 en establecer las estrategias \u00f3ptimas para el buscador, asumiendo que no hay actividades de b\u00fasqueda mutua -LRB-, es decir, que no hay influencia sobre el entorno -RRB-. Aqu\u00ed se aplica a menudo el procedimiento de b\u00fasqueda secuencial, lo que permite al buscador investigar una sola oportunidad -LSB- 15 -RSB- o m\u00faltiples -LSB- 7, 19 -RSB- a la vez. Si bien se ha demostrado que este \u00faltimo m\u00e9todo es beneficioso para el buscador, nunca se utiliz\u00f3 en los modelos de b\u00fasqueda '' bilateral '' que siguieron -LRB- donde se modelan actividades de b\u00fasqueda dual -RRB- -LSB- 22, 5, 18 -RSB-. Por tanto, en estos modelos las estrategias de equilibrio siempre se desarrollan partiendo del supuesto de que los agentes interact\u00faan con otros de forma secuencial -LRB- es decir, con un agente a la vez -RRB-. Un primer intento de integrar la b\u00fasqueda paralela en un modelo de b\u00fasqueda bilateral se da en -LSB-21-RSB-, como se detalla en la secci\u00f3n de introducci\u00f3n. Los modelos presentados en esta \u00e1rea no asocian el proceso de formaci\u00f3n de coaliciones con los costos de b\u00fasqueda, que es la esencia del an\u00e1lisis que la teor\u00eda de la b\u00fasqueda econ\u00f3mica pretende ofrecer. Adem\u00e1s, incluso en modelos repetidos de negociaci\u00f3n por pares -LSB- 10 -RSB-, los agentes siempre se limitan a iniciar una \u00fanica interacci\u00f3n de negociaci\u00f3n a la vez.La incorporaci\u00f3n de la b\u00fasqueda costosa en este context es bastante rara -LSB- 21 -RSB- y hasta donde sabemos, hasta la fecha no se ha estudiado un modelo de b\u00fasqueda distribuida bilateral de socios similar al modelo S-DM. La teor\u00eda cl\u00e1sica de la b\u00fasqueda econ\u00f3mica -LRB- -LSB- 15, 17 -RSB-, y sus referencias -RRB- aborda ampliamente el problema de un buscador que opera en un entorno costoso, buscando maximizar su utilidad a largo plazo. En estos modelos, clasificados como de b\u00fasqueda unilateral, el foco est\u00e1 en establecer las estrategias \u00f3ptimas para el buscador, asumiendo que no hay actividades de b\u00fasqueda mutua -LRB-, es decir, que no hay influencia sobre el entorno -RRB-. Aqu\u00ed se aplica a menudo el procedimiento de b\u00fasqueda secuencial, lo que permite al buscador investigar una sola oportunidad -LSB- 15 -RSB- o m\u00faltiples -LSB- 7, 19 -RSB- a la vez. Si bien se ha demostrado que este \u00faltimo m\u00e9todo es beneficioso para el buscador, nunca se utiliz\u00f3 en los modelos de b\u00fasqueda '' bilateral '' que siguieron -LRB- donde se modelan actividades de b\u00fasqueda dual -RRB- -LSB- 22, 5, 18 -RSB-. Por tanto, en estos modelos las estrategias de equilibrio siempre se desarrollan partiendo del supuesto de que los agentes interact\u00faan con otros de forma secuencial -LRB- es decir, con un agente a la vez -RRB-. Un primer intento de integrar la b\u00fasqueda paralela en un modelo de b\u00fasqueda bilateral se da en -LSB-21-RSB-, como se detalla en la secci\u00f3n de introducci\u00f3n. Los modelos presentados en esta \u00e1rea no asocian el proceso de formaci\u00f3n de coaliciones con los costos de b\u00fasqueda, que es la esencia del an\u00e1lisis que la teor\u00eda de la b\u00fasqueda econ\u00f3mica pretende ofrecer. Adem\u00e1s, incluso en modelos repetidos de negociaci\u00f3n por pares -LSB- 10 -RSB-, los agentes siempre se limitan a iniciar una \u00fanica interacci\u00f3n de negociaci\u00f3n a la vez.Un primer intento de integrar la b\u00fasqueda paralela en un modelo de b\u00fasqueda bilateral se da en -LSB-21-RSB-, como se detalla en la secci\u00f3n de introducci\u00f3n. Los modelos presentados en esta \u00e1rea no asocian el proceso de formaci\u00f3n de coaliciones con los costos de b\u00fasqueda, que es la esencia del an\u00e1lisis que la teor\u00eda de la b\u00fasqueda econ\u00f3mica pretende ofrecer. Adem\u00e1s, incluso en modelos repetidos de negociaci\u00f3n por pares -LSB- 10 -RSB-, los agentes siempre se limitan a iniciar una \u00fanica interacci\u00f3n de negociaci\u00f3n a la vez.Un primer intento de integrar la b\u00fasqueda paralela en un modelo de b\u00fasqueda bilateral se da en -LSB-21-RSB-, como se detalla en la secci\u00f3n de introducci\u00f3n. Los modelos presentados en esta \u00e1rea no asocian el proceso de formaci\u00f3n de coaliciones con los costos de b\u00fasqueda, que es la esencia del an\u00e1lisis que la teor\u00eda de la b\u00fasqueda econ\u00f3mica pretende ofrecer. Adem\u00e1s, incluso en modelos repetidos de negociaci\u00f3n por pares -LSB- 10 -RSB-, los agentes siempre se limitan a iniciar una \u00fanica interacci\u00f3n de negociaci\u00f3n a la vez.", "keyphrases": ["asociaci\u00f3n de parejas", "decidir", "aplicaci\u00f3n de igual a igual", "informar proceso", "\u00fatil", "costo de b\u00fasqueda", "escenario de equilibrio m\u00faltiple", "estrategias de equilibrio", "interactuar en paralelo", "metodolog\u00eda encuadernada", "formato coalit", "formato de asociaci\u00f3n", "camarader\u00eda", "entorno costli", "realizar la b\u00fasqueda", "toma de decisi\u00f3n instant\u00e1nea", "tomar decisiones secuenciales", "b\u00fasqueda bilateral"]}
{"file_name": "H-8", "text": "Colecciones de pruebas s\u00f3lidas para la evaluaci\u00f3n de recuperaci\u00f3n RESUMEN Los m\u00e9todos de bajo costo para adquirir juicios de relevancia pueden ser una gran ayuda para los investigadores que necesitan evaluar nuevas tareas o temas de recuperaci\u00f3n pero no tienen los recursos para emitir miles de juicios. Si bien estos juicios son muy \u00fatiles para una evaluaci\u00f3n \u00fanica, no est\u00e1 claro que se pueda confiar en ellos cuando se reutilicen para evaluar nuevos sistemas. En este trabajo, definimos formalmente lo que significa que los juicios sean reutilizables: la confianza en una evaluaci\u00f3n de nuevos sistemas se puede evaluar con precisi\u00f3n a partir de un conjunto existente de juicios de relevancia. Luego presentamos un m\u00e9todo para aumentar un conjunto de juicios de relevancia con estimaciones de relevancia que no requieren esfuerzo adicional del evaluador. El uso de este m\u00e9todo pr\u00e1cticamente garantiza la reutilizaci\u00f3n: con tan solo cinco juicios por tema tomados de s\u00f3lo dos sistemas, podemos evaluar de manera confiable un conjunto m\u00e1s grande de diez sistemas. Incluso los conjuntos de juicios m\u00e1s peque\u00f1os pueden resultar \u00fatiles para la evaluaci\u00f3n de nuevos sistemas. 1. INTRODUCCI\u00d3N Considere un investigador de recuperaci\u00f3n de informaci\u00f3n que ha inventado una nueva tarea de recuperaci\u00f3n. Ha creado un sistema para realizar la tarea y quiere evaluarla. Dado que la tarea es nueva, es poco probable que existan juicios de relevancia. No tiene el tiempo ni los recursos para juzgar cada documento, ni siquiera cada documento recuperado. S\u00f3lo puede juzgar los documentos que le parecen m\u00e1s informativos y detenerse cuando tiene un grado razonable de confianza en sus conclusiones. Pero, \u00bfqu\u00e9 sucede cuando desarrolla un nuevo sistema y necesita evaluarlo? \u00bfO otro grupo de investigaci\u00f3n decide implementar un sistema para realizar la tarea? \u00bfPueden reutilizar de manera confiable las sentencias originales? \u00bfPueden evaluar sin m\u00e1s juicios de relevancia? La evaluaci\u00f3n es un aspecto importante de la investigaci\u00f3n de recuperaci\u00f3n de informaci\u00f3n, pero es s\u00f3lo un problema semi-resuelto: para la mayor\u00eda de las tareas de recuperaci\u00f3n, es imposible juzgar la relevancia de cada documento; simplemente hay demasiados. La soluci\u00f3n utilizada por NIST en TREC -LRB- Text REtrieval Conference -RRB- es el m\u00e9todo de agrupaci\u00f3n -LSB- 19, 20 -RSB-: todos los sistemas competidores aportan N documentos a un grupo, y cada documento en ese grupo se juzga. Este m\u00e9todo crea grandes conjuntos de juicios que son reutilizables para entrenar o evaluar nuevos sistemas que no contribuyeron al grupo -LSB- 21 -RSB-. Esta soluci\u00f3n no es adecuada para nuestro hipot\u00e9tico investigador. El m\u00e9todo de agrupaci\u00f3n ofrece miles de juicios de relevancia, pero requiere muchas horas de tiempo del anotador -LRB- pagado -RRB-. Como veremos, los juicios que producen estos m\u00e9todos pueden sesgar significativamente la evaluaci\u00f3n de un nuevo conjunto de sistemas. Volviendo a nuestra hipot\u00e9tica investigadora, \u00bfpuede reutilizar sus juicios de relevancia? Primero debemos definir formalmente qu\u00e9 significa ser ``reutilizable''. En trabajos anteriores, la reutilizaci\u00f3n se prob\u00f3 simplemente evaluando la precisi\u00f3n de un conjunto de juicios de relevancia al evaluar sistemas invisibles. Necesitamos una definici\u00f3n m\u00e1s cuidadosa de reutilizaci\u00f3n. Espec\u00edficamente,La cuesti\u00f3n de la reutilizaci\u00f3n no es la precisi\u00f3n con la que podemos evaluar nuevos sistemas. Un \"adversario malicioso\" siempre puede producir una nueva lista clasificada que no haya recuperado ninguno de los documentos evaluados. La verdadera pregunta es cu\u00e1nta confianza tenemos en nuestras evaluaciones y, m\u00e1s importante a\u00fan, si podemos confiar en nuestras estimaciones de confianza. Incluso si la confianza no es alta, siempre que podamos confiar en ella, podemos identificar qu\u00e9 sistemas necesitan m\u00e1s juicios para aumentar la confianza. Cualquier conjunto de juicios, por peque\u00f1o que sea, se vuelve reutilizable hasta cierto punto. Las colecciones de pruebas peque\u00f1as y reutilizables podr\u00edan tener un gran impacto en la investigaci\u00f3n de recuperaci\u00f3n de informaci\u00f3n. Los grupos de investigaci\u00f3n podr\u00edan compartir los juicios de relevancia que hayan realizado \"internamente\" para estudios piloto, nuevas tareas o nuevos temas. La cantidad de datos disponibles para los investigadores crecer\u00eda exponencialmente con el tiempo. 6. CONCLUSIONES Y TRABAJO FUTURO En este trabajo hemos ofrecido la primera definici\u00f3n formal de la idea com\u00fan de ``reusabilidad'' de una colecci\u00f3n de pruebas y hemos presentado un modelo que es capaz de lograr la reusabilidad con conjuntos muy peque\u00f1os de juicios de relevancia. Las estimaciones de confianza de RTC, adem\u00e1s de ser precisas, proporcionan una gu\u00eda para obtener juicios adicionales: c\u00e9ntrese en juzgar los documentos a partir de las comparaciones de menor confianza. A largo plazo, vemos peque\u00f1os conjuntos de juicios de relevancia. Tabla 5: Precisi\u00f3n, W, media \u03c4 y mediana del n\u00famero de juicios para los 8 conjuntos de pruebas. Los resultados son muy consistentes en todos los conjuntos de datos. Los investigadores comparten comentarios y cada grupo contribuye con algunos juicios m\u00e1s para ganar m\u00e1s confianza sobre sus sistemas particulares. A medida que pasa el tiempo, el n\u00famero de valoraciones crece hasta que hay un 100 % de confianza en cada evaluaci\u00f3n y hay una colecci\u00f3n de pruebas completa para la tarea. Podr\u00eda aplicarse a la evaluaci\u00f3n de una colecci\u00f3n de pruebas din\u00e1micas seg\u00fan lo definido por Soboroff -LSB-18-RSB-. El modelo que presentamos en la Secci\u00f3n 3 no es de ninguna manera la \u00fanica posibilidad para crear una colecci\u00f3n de pruebas s\u00f3lida. Adem\u00e1s de la agregaci\u00f3n de expertos, podr\u00edamos estimar probabilidades observando similitudes entre documentos. Esta es un \u00e1rea obvia para exploraci\u00f3n futura. Tenemos muchos m\u00e1s resultados experimentales para los que lamentablemente no ten\u00edamos espacio, pero que refuerzan la noci\u00f3n de que RTC es muy robusto: con s\u00f3lo unos pocos juicios por tema, podemos evaluar con precisi\u00f3n la confianza en cualquier comparaci\u00f3n de sistemas por pares.Las colecciones de pruebas peque\u00f1as y reutilizables podr\u00edan tener un gran impacto en la investigaci\u00f3n de recuperaci\u00f3n de informaci\u00f3n. Los grupos de investigaci\u00f3n podr\u00edan compartir los juicios de relevancia que hayan realizado \"internamente\" para estudios piloto, nuevas tareas o nuevos temas. La cantidad de datos disponibles para los investigadores crecer\u00eda exponencialmente con el tiempo. 6. CONCLUSIONES Y TRABAJO FUTURO En este trabajo hemos ofrecido la primera definici\u00f3n formal de la idea com\u00fan de ``reusabilidad'' de una colecci\u00f3n de pruebas y hemos presentado un modelo que es capaz de lograr la reusabilidad con conjuntos muy peque\u00f1os de juicios de relevancia. Las estimaciones de confianza de RTC, adem\u00e1s de ser precisas, proporcionan una gu\u00eda para obtener juicios adicionales: c\u00e9ntrese en juzgar los documentos a partir de las comparaciones de menor confianza. A largo plazo, vemos peque\u00f1os conjuntos de juicios de relevancia. Tabla 5: Precisi\u00f3n, W, media \u03c4 y mediana del n\u00famero de juicios para los 8 conjuntos de pruebas. Los resultados son muy consistentes en todos los conjuntos de datos. Los investigadores comparten comentarios y cada grupo contribuye con algunos juicios m\u00e1s para ganar m\u00e1s confianza sobre sus sistemas particulares. A medida que pasa el tiempo, el n\u00famero de valoraciones crece hasta que hay un 100 % de confianza en cada evaluaci\u00f3n y hay una colecci\u00f3n de pruebas completa para la tarea. Podr\u00eda aplicarse a la evaluaci\u00f3n de una colecci\u00f3n de pruebas din\u00e1micas seg\u00fan lo definido por Soboroff -LSB-18-RSB-. El modelo que presentamos en la Secci\u00f3n 3 no es de ninguna manera la \u00fanica posibilidad para crear una colecci\u00f3n de pruebas s\u00f3lida. Adem\u00e1s de la agregaci\u00f3n de expertos, podr\u00edamos estimar probabilidades observando similitudes entre documentos. Esta es un \u00e1rea obvia para exploraci\u00f3n futura. Tenemos muchos m\u00e1s resultados experimentales para los que lamentablemente no ten\u00edamos espacio, pero que refuerzan la noci\u00f3n de que RTC es muy robusto: con s\u00f3lo unos pocos juicios por tema, podemos evaluar con precisi\u00f3n la confianza en cualquier comparaci\u00f3n de sistemas por pares.Las colecciones de pruebas peque\u00f1as y reutilizables podr\u00edan tener un gran impacto en la investigaci\u00f3n de recuperaci\u00f3n de informaci\u00f3n. Los grupos de investigaci\u00f3n podr\u00edan compartir los juicios de relevancia que hayan realizado \"internamente\" para estudios piloto, nuevas tareas o nuevos temas. La cantidad de datos disponibles para los investigadores crecer\u00eda exponencialmente con el tiempo. 6. CONCLUSIONES Y TRABAJO FUTURO En este trabajo hemos ofrecido la primera definici\u00f3n formal de la idea com\u00fan de ``reusabilidad'' de una colecci\u00f3n de pruebas y hemos presentado un modelo que es capaz de lograr la reusabilidad con conjuntos muy peque\u00f1os de juicios de relevancia. Las estimaciones de confianza de RTC, adem\u00e1s de ser precisas, proporcionan una gu\u00eda para obtener juicios adicionales: c\u00e9ntrese en juzgar los documentos a partir de las comparaciones de menor confianza. A largo plazo, vemos peque\u00f1os conjuntos de juicios de relevancia. Tabla 5: Precisi\u00f3n, W, media \u03c4 y mediana del n\u00famero de juicios para los 8 conjuntos de pruebas. Los resultados son muy consistentes en todos los conjuntos de datos. Los investigadores comparten comentarios y cada grupo contribuye con algunos juicios m\u00e1s para ganar m\u00e1s confianza sobre sus sistemas particulares. A medida que pasa el tiempo, el n\u00famero de valoraciones crece hasta que hay un 100 % de confianza en cada evaluaci\u00f3n y hay una colecci\u00f3n de pruebas completa para la tarea. Podr\u00eda aplicarse a la evaluaci\u00f3n de una colecci\u00f3n de pruebas din\u00e1micas seg\u00fan lo definido por Soboroff -LSB-18-RSB-. El modelo que presentamos en la Secci\u00f3n 3 no es de ninguna manera la \u00fanica posibilidad para crear una colecci\u00f3n de pruebas s\u00f3lida. Adem\u00e1s de la agregaci\u00f3n de expertos, podr\u00edamos estimar probabilidades observando similitudes entre documentos. Esta es un \u00e1rea obvia para exploraci\u00f3n futura. Tenemos muchos m\u00e1s resultados experimentales para los que lamentablemente no ten\u00edamos espacio, pero que refuerzan la noci\u00f3n de que RTC es muy robusto: con s\u00f3lo unos pocos juicios por tema, podemos evaluar con precisi\u00f3n la confianza en cualquier comparaci\u00f3n de sistemas por pares.el n\u00famero de juicios crece hasta que hay un 100 % de confianza en cada evaluaci\u00f3n y hay una colecci\u00f3n de pruebas completa para la tarea. Podr\u00eda aplicarse a la evaluaci\u00f3n de una colecci\u00f3n de pruebas din\u00e1micas seg\u00fan lo definido por Soboroff -LSB- 18 -RSB-. El modelo que presentamos en la Secci\u00f3n 3 no es de ninguna manera la \u00fanica posibilidad para crear una colecci\u00f3n de pruebas s\u00f3lida. Adem\u00e1s de la agregaci\u00f3n de expertos, podr\u00edamos estimar probabilidades observando similitudes entre documentos. Esta es un \u00e1rea obvia para exploraci\u00f3n futura. Tenemos muchos m\u00e1s resultados experimentales para los que lamentablemente no ten\u00edamos espacio, pero que refuerzan la noci\u00f3n de que RTC es muy robusto: con s\u00f3lo unos pocos juicios por tema, podemos evaluar con precisi\u00f3n la confianza en cualquier comparaci\u00f3n de sistemas por pares.el n\u00famero de juicios crece hasta que hay un 100 % de confianza en cada evaluaci\u00f3n y hay una colecci\u00f3n de pruebas completa para la tarea. Podr\u00eda aplicarse a la evaluaci\u00f3n de una colecci\u00f3n de pruebas din\u00e1micas seg\u00fan lo definido por Soboroff -LSB-18-RSB-. El modelo que presentamos en la Secci\u00f3n 3 no es de ninguna manera la \u00fanica posibilidad para crear una colecci\u00f3n de pruebas s\u00f3lida. Adem\u00e1s de la agregaci\u00f3n de expertos, podr\u00edamos estimar probabilidades observando similitudes entre documentos. Esta es un \u00e1rea obvia para exploraci\u00f3n futura. Tenemos muchos m\u00e1s resultados experimentales para los que lamentablemente no ten\u00edamos espacio, pero que refuerzan la noci\u00f3n de que RTC es muy robusto: con s\u00f3lo unos pocos juicios por tema, podemos evaluar con precisi\u00f3n la confianza en cualquier comparaci\u00f3n de sistemas por pares.", "keyphrases": ["informar recuperar", "evaluar", "juicio relevante", "reutilizable", "comparaci\u00f3n de menor confianza", "mtc", "rtc", "esperar", "variaci\u00f3n", "distribuci\u00f3n de relev"]}
{"file_name": "H-21", "text": "Clasificaci\u00f3n robusta de consultas raras utilizando conocimiento web RESUMEN Proponemos una metodolog\u00eda para construir un sistema de clasificaci\u00f3n de consultas robusto y pr\u00e1ctico que pueda identificar miles de clases de consultas con precisi\u00f3n razonable, mientras maneja en tiempo real el volumen de consultas de un motor de b\u00fasqueda web comercial. Utilizamos una t\u00e9cnica de retroalimentaci\u00f3n ciega: dada una consulta, determinamos su tema clasificando los resultados de b\u00fasqueda web obtenidos por la consulta. Motivados por las necesidades de la publicidad en buscadores, nos centramos principalmente en consultas raras, que son las m\u00e1s dif\u00edciles desde el punto de vista del aprendizaje autom\u00e1tico, pero que en conjunto representan una fracci\u00f3n considerable del tr\u00e1fico de los motores de b\u00fasqueda. La evaluaci\u00f3n emp\u00edrica confirma que nuestra metodolog\u00eda produce una precisi\u00f3n de clasificaci\u00f3n considerablemente mayor que la informada anteriormente. Creemos que la metodolog\u00eda propuesta conducir\u00e1 a una mejor correspondencia de los anuncios en l\u00ednea con consultas poco frecuentes y, en general, a una mejor experiencia del usuario. 1. INTRODUCCI\u00d3N Sin embargo, una cosa permanece constante: la gente utiliza consultas muy breves. Varios estudios estiman la longitud media de una consulta de b\u00fasqueda entre 2,4 y 2,7 \u200b\u200bpalabras, que seg\u00fan todas las cuentas s\u00f3lo puede contener una peque\u00f1a cantidad de informaci\u00f3n. Los motores de b\u00fasqueda comerciales hacen un trabajo notablemente bueno al interpretar estas cadenas cortas, \u00a1pero a\u00fan no son -LRB-! -RRB- omnisciente. Por lo tanto, utilizar conocimiento externo adicional para aumentar las consultas puede ser de gran ayuda para mejorar los resultados de b\u00fasqueda y la experiencia del usuario. En este estudio presentamos una metodolog\u00eda para la clasificaci\u00f3n de consultas, donde nuestro objetivo es clasificar consultas en una taxonom\u00eda comercial de consultas web con aproximadamente 6000 nodos. Dadas estas clasificaciones, se pueden utilizar directamente para proporcionar mejores resultados de b\u00fasqueda, as\u00ed como anuncios m\u00e1s enfocados. El problema de la clasificaci\u00f3n de consultas es extremadamente dif\u00edcil debido a la brevedad de las consultas. Sin embargo, observe que en muchos casos un ser humano que analiza una consulta de b\u00fasqueda y sus resultados logra notablemente entenderla. Por supuesto, el gran volumen de consultas de b\u00fasqueda no se presta a la supervisi\u00f3n humana y, por lo tanto, necesitamos fuentes alternativas de conocimiento sobre el mundo. Los motores de b\u00fasqueda indexan cantidades colosales de informaci\u00f3n y, como tales, pueden considerarse dep\u00f3sitos de conocimiento muy completos. Siguiendo la heur\u00edstica descrita anteriormente, proponemos utilizar los propios resultados de la b\u00fasqueda para obtener informaci\u00f3n adicional para la interpretaci\u00f3n de la consulta. Con este fin, empleamos el paradigma de retroalimentaci\u00f3n de pseudo relevancia y asumimos que los principales resultados de b\u00fasqueda son relevantes para la consulta. Ciertamente, no todos los resultados son igualmente relevantes y, por lo tanto, utilizamos elaborados esquemas de votaci\u00f3n para obtener conocimientos confiables sobre la consulta. Para los fines de este estudio, primero enviamos la consulta dada a un motor de b\u00fasqueda web general y recopilamos varias de las URL con la puntuaci\u00f3n m\u00e1s alta. Rastreamos las p\u00e1ginas web se\u00f1aladas por estas URL y las clasificamos. Finalmente, utilizamos estas clasificaciones de p\u00e1ginas de resultados para clasificar la consulta original.Nuestra evaluaci\u00f3n emp\u00edrica confirma que el uso de los resultados de b\u00fasqueda web de esta manera produce mejoras sustanciales en la precisi\u00f3n de la clasificaci\u00f3n de las consultas. Tenga en cuenta que en una implementaci\u00f3n pr\u00e1ctica de nuestra metodolog\u00eda dentro de un motor de b\u00fasqueda comercial, todas las p\u00e1ginas indexadas se pueden preclasificar utilizando el proceso normal de indexaci\u00f3n y procesamiento de text. Por lo tanto, en tiempo de ejecuci\u00f3n s\u00f3lo necesitamos ejecutar el procedimiento de votaci\u00f3n, sin realizar ning\u00fan rastreo ni clasificaci\u00f3n. Esta sobrecarga adicional es m\u00ednima y, por lo tanto, el uso de los resultados de b\u00fasqueda para mejorar la clasificaci\u00f3n de las consultas es totalmente factible en tiempo de ejecuci\u00f3n. Otro aspecto importante de nuestro trabajo reside en la elecci\u00f3n de las consultas. El volumen de consultas en los motores de b\u00fasqueda actuales sigue la conocida ley de potencia, seg\u00fan la cual unas pocas consultas aparecen muy a menudo, mientras que la mayor\u00eda de las consultas aparecen s\u00f3lo unas pocas veces. Si bien las consultas individuales en esta larga cola son raras, juntas representan una masa considerable de todas las b\u00fasquedas. Sin embargo, las consultas ``tail'' simplemente no tienen suficientes ocurrencias para permitir el aprendizaje estad\u00edstico por consulta. Por lo tanto, necesitamos agregar dichas consultas de alguna manera y razonar a nivel de grupos de consultas agregadas. Una opci\u00f3n natural para dicha agregaci\u00f3n es clasificar las consultas en una taxonom\u00eda tem\u00e1tica. Saber qu\u00e9 nodos de taxonom\u00eda son m\u00e1s relevantes para la consulta determinada nos ayudar\u00e1 a brindar el mismo tipo de soporte para consultas poco frecuentes que para consultas frecuentes. En consecuencia, en este trabajo nos centramos en la clasificaci\u00f3n de consultas raras, cuya correcta clasificaci\u00f3n probablemente resulte especialmente beneficiosa. Los primeros estudios sobre interpretaci\u00f3n de consultas se centraron en el aumento de consultas mediante diccionarios externos -LSB- 22 -RSB-. Estudios m\u00e1s recientes -LSB- 18, 21 -RSB- tambi\u00e9n intentaron recopilar alg\u00fan conocimiento adicional de la Web. Espec\u00edficamente, trabajos anteriores en el campo utilizaron taxonom\u00edas de clasificaci\u00f3n de consultas muy peque\u00f1as de solo unas pocas docenas de nodos, que no permiten una amplia especificidad para la publicidad en l\u00ednea -LSB- 11 -RSB-. Primero, construimos el clasificador de consultas directamente para la taxonom\u00eda de destino, en lugar de utilizar una estructura auxiliar secundaria; esto simplifica enormemente el mantenimiento y desarrollo de la taxonom\u00eda. La taxonom\u00eda utilizada en este trabajo es dos \u00f3rdenes de magnitud mayor que la utilizada en estudios anteriores. La evaluaci\u00f3n emp\u00edrica demuestra que nuestra metodolog\u00eda de uso del conocimiento externo logra mayores mejoras que las reportadas anteriormente. Dado que nuestra taxonom\u00eda es considerablemente mayor, el problema de clasificaci\u00f3n que enfrentamos es mucho m\u00e1s dif\u00edcil, lo que hace que las mejoras que logramos sean particularmente notables. Tambi\u00e9n informamos los resultados de un estudio emp\u00edrico exhaustivo de diferentes esquemas de votaci\u00f3n y diferentes profundidades de conocimiento -LRB-, por ejemplo, utilizando res\u00famenes de b\u00fasqueda versus p\u00e1ginas completas rastreadas -RRB-. Descubrimos que rastrear los resultados de la b\u00fasqueda produce un conocimiento m\u00e1s profundo y conduce a mayores mejoras que los simples res\u00famenes. Este resultado contrasta con hallazgos anteriores en la clasificaci\u00f3n de consultas -LSB- 20 -RSB-,pero est\u00e1 respaldado por investigaciones en la clasificaci\u00f3n de texts convencionales -LSB- 5 -RSB-. 4. TRABAJO RELACIONADO Aunque la longitud promedio de las consultas de b\u00fasqueda aumenta constantemente con el tiempo, una consulta t\u00edpica todav\u00eda tiene menos de 3 palabras. En consecuencia, muchos investigadores estudiaron posibles formas de mejorar las consultas con informaci\u00f3n adicional. Una direcci\u00f3n importante para mejorar las consultas es mediante la expansi\u00f3n de consultas. Esto se puede hacer utilizando diccionarios y tesauros electr\u00f3nicos -LSB- 22 -RSB-, o mediante t\u00e9cnicas de retroalimentaci\u00f3n de relevancia que utilizan algunos resultados de b\u00fasqueda con la puntuaci\u00f3n m\u00e1s alta. Los primeros trabajos en recuperaci\u00f3n de informaci\u00f3n se concentraron en revisar manualmente los resultados devueltos -LSB- 16, 15 -RSB-. M\u00e1s recientemente, los estudios sobre el aumento de consultas se centraron en la clasificaci\u00f3n de consultas, asumiendo que dichas clasificaciones son beneficiosas para una interpretaci\u00f3n de consultas m\u00e1s enfocada. De hecho, Kowalczyk et al. -LSB- 10 -RSB- descubri\u00f3 que el uso de clases de consulta mejoraba el rendimiento de la recuperaci\u00f3n de documentos. Los estudios en el campo persiguen diferentes enfoques para obtener informaci\u00f3n adicional sobre las consultas. Beitzel et al. -LSB- 1 -RSB- utiliz\u00f3 aprendizaje semisupervisado as\u00ed como datos sin etiquetar -LSB- 2 -RSB-. Gravano et al. -LSB- 6 -RSB- clasifica las consultas con respecto a la localidad geogr\u00e1fica para determinar si su intenci\u00f3n es local o global. La Copa KDD 2005 sobre clasificaci\u00f3n de consultas web inspir\u00f3 otra l\u00ednea de investigaci\u00f3n, que se centr\u00f3 en enriquecer las consultas mediante buscadores y directorios web -LSB- 11, 18, 20, 9, 21 -RSB-. La especificaci\u00f3n de la tarea KDD proporcion\u00f3 una peque\u00f1a taxonom\u00eda -LRB- 67 nodos -RRB- junto con un conjunto de consultas etiquetadas, y plante\u00f3 un desaf\u00edo para usar estos datos de entrenamiento para construir un clasificador de consultas. Varios equipos utilizaron la Web para enriquecer las consultas y proporcionar m\u00e1s context para la clasificaci\u00f3n. Las principales preguntas de investigaci\u00f3n de este enfoque son -LRB- 1 -RRB- c\u00f3mo construir un clasificador de documentos, -LRB- 2 -RRB- c\u00f3mo traducir sus clasificaciones a la taxonom\u00eda objetivo y -LRB- 3 -RRB- c\u00f3mo determine la clase de consulta en funci\u00f3n de las clasificaciones de documentos. La soluci\u00f3n ganadora de la Copa KDD -LSB- 18 -RSB- propuso utilizar un conjunto de clasificadores junto con la b\u00fasqueda en m\u00faltiples motores de b\u00fasqueda. Para abordar el problema -LRB- 1 -RRB- anterior, su soluci\u00f3n utiliz\u00f3 el Proyecto Open Directory -LRB- ODP -RRB- para producir un clasificador de documentos basado en ODP. Luego, la jerarqu\u00eda ODP se mape\u00f3 en la taxonom\u00eda de destino utilizando coincidencias de palabras en nodos individuales. Se cre\u00f3 un clasificador de documentos para la taxonom\u00eda de destino utilizando las p\u00e1ginas de la taxonom\u00eda ODP que aparecen en los nodos asignados al nodo de destino en particular. Por lo tanto, los documentos web se clasificaron primero con respecto a la jerarqu\u00eda ODP y posteriormente sus clasificaciones se asignaron a la taxonom\u00eda de destino para la clasificaci\u00f3n de consultas. En comparaci\u00f3n con este enfoque, resolvimos el problema de la clasificaci\u00f3n de documentos directamente en la taxonom\u00eda de destino mediante el uso de consultas para producir un clasificador de documentos como se describe en la Secci\u00f3n 2.Esto simplifica el proceso y elimina la necesidad de realizar mapeos entre taxonom\u00edas. Esto tambi\u00e9n agiliza el mantenimiento y desarrollo de la taxonom\u00eda. Con este enfoque, pudimos lograr un buen rendimiento en una taxonom\u00eda a muy gran escala. Tambi\u00e9n evaluamos algunas alternativas sobre c\u00f3mo combinar clasificaciones de documentos individuales al clasificar la consulta. En un art\u00edculo de seguimiento -LSB-19-RSB-, Shen et al. propuso un marco para la clasificaci\u00f3n de consultas basado en un puente entre dos taxonom\u00edas. En este enfoque, el problema de no tener un clasificador de documentos para resultados web se resuelve utilizando un conjunto de entrenamiento disponible para documentos con una taxonom\u00eda diferente. Para ello se utiliza una taxonom\u00eda intermedia con un conjunto de entrenamiento -LRB- ODP -RRB-. A diferencia de esto, creamos un clasificador de documentos para la taxonom\u00eda de destino directamente, sin utilizar documentos de una taxonom\u00eda intermedia. Si bien no pudimos comparar directamente los resultados debido al uso de diferentes taxonom\u00edas (LRB), utilizamos una taxonom\u00eda mucho m\u00e1s grande (RRB), nuestra precisi\u00f3n y resultados de recuperaci\u00f3n son consistentemente mayores incluso en el conjunto de consultas m\u00e1s dif\u00edciles. 5. CONCLUSIONES La clasificaci\u00f3n de consultas es una importante tarea de recuperaci\u00f3n de informaci\u00f3n. Es probable que una clasificaci\u00f3n precisa de las consultas de b\u00fasqueda beneficie a una serie de tareas de nivel superior, como la b\u00fasqueda web y la coincidencia de anuncios. Dado que las consultas de b\u00fasqueda suelen ser breves, por s\u00ed solas suelen contener informaci\u00f3n insuficiente para una clasificaci\u00f3n adecuada y precisa. Para abordar este problema, propusimos una metodolog\u00eda para utilizar los resultados de b\u00fasqueda como fuente de conocimiento externo. Para ello enviamos la consulta a un motor de b\u00fasqueda y asumimos que varios de los resultados de b\u00fasqueda con la clasificaci\u00f3n m\u00e1s alta son relevantes para la consulta. Clasificar estos resultados nos permite clasificar la consulta original con una precisi\u00f3n sustancialmente mayor. Los resultados de nuestra evaluaci\u00f3n emp\u00edrica confirmaron definitivamente que utilizar la Web como dep\u00f3sito de conocimiento mundial aporta informaci\u00f3n valiosa sobre la consulta y ayuda a su correcta clasificaci\u00f3n. Adem\u00e1s, la taxonom\u00eda utilizada en este estudio es aproximadamente 2 \u00f3rdenes de magnitud mayor que la utilizada en trabajos anteriores. Cuando se utilizan resultados de b\u00fasqueda, se pueden utilizar s\u00f3lo res\u00famenes de los resultados proporcionados por 3. Dado que el campo de la clasificaci\u00f3n de consultas a\u00fan no cuenta con puntos de referencia establecidos y acordados, la comparaci\u00f3n directa de los resultados es ciertamente complicada. el motor de b\u00fasqueda, o incluso rastrear las p\u00e1ginas de resultados para obtener un conocimiento a\u00fan m\u00e1s profundo. En general, el rendimiento de la clasificaci\u00f3n de consultas fue mejor cuando se utilizaron las p\u00e1ginas rastreadas completas -LRB- Tabla 1 -RRB-. Estos resultados son consistentes con estudios anteriores -LSB-5-RSB-, que encontraron que usar p\u00e1ginas rastreadas completas es superior para la clasificaci\u00f3n de documentos que usar solo res\u00famenes breves. Nuestros hallazgos, sin embargo, son diferentes de los informados por Shen et al. -LSB- 19 -RSB-, quienes encontraron que los res\u00famenes arrojan mejores resultados.Atribuimos nuestras observaciones al uso de un esquema de votaci\u00f3n m\u00e1s elaborado entre las clasificaciones de resultados de b\u00fasqueda individuales, as\u00ed como al uso de un conjunto m\u00e1s dif\u00edcil de consultas raras. En este estudio utilizamos dos motores de b\u00fasqueda principales, A y B. Curiosamente, encontramos distinciones notables en la calidad de su producci\u00f3n. En particular, para el motor A los resultados generales fueron mejores cuando se utilizaron las p\u00e1ginas rastreadas completas de los resultados de b\u00fasqueda, mientras que para el motor B parece ser m\u00e1s beneficioso utilizar los res\u00famenes de resultados. Esto implica que, si bien la calidad de los resultados de b\u00fasqueda arrojados por el motor A es aparentemente mejor, el motor B hace un mejor trabajo al resumir las p\u00e1ginas. Tambi\u00e9n descubrimos que los mejores resultados se obtuvieron utilizando p\u00e1ginas rastreadas completas y realizando votaciones entre sus clasificaciones individuales. Por otro lado, para los propietarios de un motor de b\u00fasqueda, la clasificaci\u00f3n de p\u00e1ginas completas es mucho m\u00e1s eficiente, ya que es f\u00e1cil preprocesar todas las p\u00e1ginas indexadas clasific\u00e1ndolas una vez en la taxonom\u00eda -LRB- fija -RRB-. Luego, las clasificaciones de p\u00e1ginas se obtienen como parte de los metadatos asociados con cada resultado de b\u00fasqueda, y la clasificaci\u00f3n de las consultas puede ser casi instant\u00e1nea. Al utilizar res\u00famenes parece que se obtienen mejores resultados concatenando primero res\u00famenes individuales en un metadocumento y luego utilizando su clasificaci\u00f3n en su conjunto. De acuerdo con nuestra intuici\u00f3n, utilizar muy pocos resultados de b\u00fasqueda produce conocimientos \u00fatiles pero insuficientes, y utilizar demasiados resultados de b\u00fasqueda conduce a la inclusi\u00f3n de p\u00e1ginas web marginalmente relevantes. Los mejores resultados se obtuvieron al utilizar 40 resultados de b\u00fasqueda principales. En este trabajo, primero clasificamos los resultados de la b\u00fasqueda y luego usamos sus clasificaciones directamente para clasificar la consulta original. Alternativamente, se pueden utilizar las clasificaciones de los resultados de b\u00fasqueda como caracter\u00edsticas para aprender un clasificador de segundo nivel. Planeamos investigar m\u00e1s a fondo esta direcci\u00f3n en nuestro trabajo futuro. Si el motor de b\u00fasqueda clasifica las p\u00e1ginas rastreadas durante la indexaci\u00f3n, en el momento de la consulta solo necesitamos buscar estas clasificaciones y realizar la votaci\u00f3n. Para concluir, creemos que nuestra metodolog\u00eda para utilizar los resultados de b\u00fasqueda web es muy prometedora para mejorar sustancialmente la precisi\u00f3n de las consultas de b\u00fasqueda web. Creemos que nuestros hallazgos tendr\u00e1n aplicaciones inmediatas para mejorar el manejo de consultas raras, tanto para mejorar los resultados de b\u00fasqueda como para generar anuncios mejor coincidentes. En nuestra investigaci\u00f3n adicional tambi\u00e9n planeamos utilizar la informaci\u00f3n de la sesi\u00f3n para aprovechar el conocimiento sobre consultas anteriores para clasificar mejor las siguientes.Esto implica que, si bien la calidad de los resultados de b\u00fasqueda arrojados por el motor A es aparentemente mejor, el motor B hace un mejor trabajo al resumir las p\u00e1ginas. Tambi\u00e9n descubrimos que los mejores resultados se obtuvieron utilizando p\u00e1ginas rastreadas completas y realizando votaciones entre sus clasificaciones individuales. Por otro lado, para los propietarios de un motor de b\u00fasqueda, la clasificaci\u00f3n de p\u00e1ginas completas es mucho m\u00e1s eficiente, ya que es f\u00e1cil preprocesar todas las p\u00e1ginas indexadas clasific\u00e1ndolas una vez en la taxonom\u00eda -LRB- fija -RRB-. Luego, las clasificaciones de p\u00e1ginas se obtienen como parte de los metadatos asociados con cada resultado de b\u00fasqueda, y la clasificaci\u00f3n de las consultas puede ser casi instant\u00e1nea. Al utilizar res\u00famenes parece que se obtienen mejores resultados concatenando primero res\u00famenes individuales en un metadocumento y luego utilizando su clasificaci\u00f3n en su conjunto. De acuerdo con nuestra intuici\u00f3n, utilizar muy pocos resultados de b\u00fasqueda produce conocimientos \u00fatiles pero insuficientes, y utilizar demasiados resultados de b\u00fasqueda conduce a la inclusi\u00f3n de p\u00e1ginas web marginalmente relevantes. Los mejores resultados se obtuvieron al utilizar 40 resultados de b\u00fasqueda principales. En este trabajo, primero clasificamos los resultados de la b\u00fasqueda y luego usamos sus clasificaciones directamente para clasificar la consulta original. Alternativamente, se pueden utilizar las clasificaciones de los resultados de b\u00fasqueda como caracter\u00edsticas para aprender un clasificador de segundo nivel. Planeamos investigar m\u00e1s a fondo esta direcci\u00f3n en nuestro trabajo futuro. Si el motor de b\u00fasqueda clasifica las p\u00e1ginas rastreadas durante la indexaci\u00f3n, en el momento de la consulta solo necesitamos buscar estas clasificaciones y realizar la votaci\u00f3n. Para concluir, creemos que nuestra metodolog\u00eda para utilizar los resultados de b\u00fasqueda web es muy prometedora para mejorar sustancialmente la precisi\u00f3n de las consultas de b\u00fasqueda web. Creemos que nuestros hallazgos tendr\u00e1n aplicaciones inmediatas para mejorar el manejo de consultas raras, tanto para mejorar los resultados de b\u00fasqueda como para generar anuncios mejor coincidentes. En nuestra investigaci\u00f3n adicional tambi\u00e9n planeamos utilizar la informaci\u00f3n de la sesi\u00f3n para aprovechar el conocimiento sobre consultas anteriores para clasificar mejor las siguientes.Esto implica que, si bien la calidad de los resultados de b\u00fasqueda arrojados por el motor A es aparentemente mejor, el motor B hace un mejor trabajo al resumir las p\u00e1ginas. Tambi\u00e9n descubrimos que los mejores resultados se obtuvieron utilizando p\u00e1ginas rastreadas completas y realizando votaciones entre sus clasificaciones individuales. Por otro lado, para los propietarios de un motor de b\u00fasqueda, la clasificaci\u00f3n de p\u00e1ginas completas es mucho m\u00e1s eficiente, ya que es f\u00e1cil preprocesar todas las p\u00e1ginas indexadas clasific\u00e1ndolas una vez en la taxonom\u00eda -LRB- fija -RRB-. Luego, las clasificaciones de p\u00e1ginas se obtienen como parte de los metadatos asociados con cada resultado de b\u00fasqueda, y la clasificaci\u00f3n de las consultas puede ser casi instant\u00e1nea. Al utilizar res\u00famenes parece que se obtienen mejores resultados concatenando primero res\u00famenes individuales en un metadocumento y luego utilizando su clasificaci\u00f3n en su conjunto. De acuerdo con nuestra intuici\u00f3n, utilizar muy pocos resultados de b\u00fasqueda produce conocimientos \u00fatiles pero insuficientes, y utilizar demasiados resultados de b\u00fasqueda conduce a la inclusi\u00f3n de p\u00e1ginas web marginalmente relevantes. Los mejores resultados se obtuvieron al utilizar 40 resultados de b\u00fasqueda principales. En este trabajo, primero clasificamos los resultados de la b\u00fasqueda y luego usamos sus clasificaciones directamente para clasificar la consulta original. Alternativamente, se pueden utilizar las clasificaciones de los resultados de b\u00fasqueda como caracter\u00edsticas para aprender un clasificador de segundo nivel. Planeamos investigar m\u00e1s a fondo esta direcci\u00f3n en nuestro trabajo futuro. Si el motor de b\u00fasqueda clasifica las p\u00e1ginas rastreadas durante la indexaci\u00f3n, en el momento de la consulta solo necesitamos buscar estas clasificaciones y realizar la votaci\u00f3n. Para concluir, creemos que nuestra metodolog\u00eda para utilizar los resultados de b\u00fasqueda web es muy prometedora para mejorar sustancialmente la precisi\u00f3n de las consultas de b\u00fasqueda web. Creemos que nuestros hallazgos tendr\u00e1n aplicaciones inmediatas para mejorar el manejo de consultas raras, tanto para mejorar los resultados de b\u00fasqueda como para generar anuncios mejor coincidentes. En nuestra investigaci\u00f3n adicional tambi\u00e9n planeamos utilizar la informaci\u00f3n de la sesi\u00f3n para aprovechar el conocimiento sobre consultas anteriores para clasificar mejor las siguientes.y el uso de demasiados resultados de b\u00fasqueda conduce a la inclusi\u00f3n de p\u00e1ginas web marginalmente relevantes. Los mejores resultados se obtuvieron al utilizar 40 resultados de b\u00fasqueda principales. En este trabajo, primero clasificamos los resultados de la b\u00fasqueda y luego usamos sus clasificaciones directamente para clasificar la consulta original. Alternativamente, se pueden utilizar las clasificaciones de los resultados de b\u00fasqueda como caracter\u00edsticas para aprender un clasificador de segundo nivel. Planeamos investigar m\u00e1s a fondo esta direcci\u00f3n en nuestro trabajo futuro. Si el motor de b\u00fasqueda clasifica las p\u00e1ginas rastreadas durante la indexaci\u00f3n, en el momento de la consulta solo necesitamos buscar estas clasificaciones y realizar la votaci\u00f3n. Para concluir, creemos que nuestra metodolog\u00eda para utilizar los resultados de b\u00fasqueda web es muy prometedora para mejorar sustancialmente la precisi\u00f3n de las consultas de b\u00fasqueda web. Creemos que nuestros hallazgos tendr\u00e1n aplicaciones inmediatas para mejorar el manejo de consultas raras, tanto para mejorar los resultados de b\u00fasqueda como para generar anuncios mejor coincidentes. En nuestra investigaci\u00f3n adicional tambi\u00e9n planeamos utilizar la informaci\u00f3n de la sesi\u00f3n para aprovechar el conocimiento sobre consultas anteriores para clasificar mejor las siguientes.y el uso de demasiados resultados de b\u00fasqueda conduce a la inclusi\u00f3n de p\u00e1ginas web marginalmente relevantes. Los mejores resultados se obtuvieron al utilizar 40 resultados de b\u00fasqueda principales. En este trabajo, primero clasificamos los resultados de la b\u00fasqueda y luego usamos sus clasificaciones directamente para clasificar la consulta original. Alternativamente, se pueden utilizar las clasificaciones de los resultados de b\u00fasqueda como caracter\u00edsticas para aprender un clasificador de segundo nivel. Planeamos investigar m\u00e1s a fondo esta direcci\u00f3n en nuestro trabajo futuro. Si el motor de b\u00fasqueda clasifica las p\u00e1ginas rastreadas durante la indexaci\u00f3n, en el momento de la consulta solo necesitamos buscar estas clasificaciones y realizar la votaci\u00f3n. Para concluir, creemos que nuestra metodolog\u00eda para utilizar los resultados de b\u00fasqueda web es muy prometedora para mejorar sustancialmente la precisi\u00f3n de las consultas de b\u00fasqueda web. Creemos que nuestros hallazgos tendr\u00e1n aplicaciones inmediatas para mejorar el manejo de consultas raras, tanto para mejorar los resultados de b\u00fasqueda como para generar anuncios mejor coincidentes. En nuestra investigaci\u00f3n adicional tambi\u00e9n planeamos utilizar la informaci\u00f3n de la sesi\u00f3n para aprovechar el conocimiento sobre consultas anteriores para clasificar mejor las siguientes.", "keyphrases": ["consulta de clasificaci\u00f3n", "motor de b\u00fasqueda", "buscar publicidad", "aprendizaje autom\u00e1tico", "retroalimentaci\u00f3n relevante", "esquema de voto", "gatear", "taxonomi tematica", "puntuaci\u00f3n af\u00edn", "condici\u00f3n probable", "adaptar", "informar recuperar"]}
{"file_name": "C-4", "text": "Recuperaci\u00f3n y control de p\u00e9rdidas intraflujo para RESUMEN Las redes de conmutaci\u00f3n de paquetes de \"mejor esfuerzo\", como Internet, no ofrecen una transmisi\u00f3n confiable de paquetes a aplicaciones con limitaciones de tiempo real, como la voz. Por tanto, la p\u00e9rdida de paquetes perjudica la utilidad a nivel de aplicaci\u00f3n. Para la voz, esta degradaci\u00f3n de la utilidad es doble: por un lado, incluso r\u00e1fagas cortas de paquetes perdidos pueden disminuir significativamente la capacidad del receptor para ocultar la p\u00e9rdida de paquetes y la se\u00f1al de voz saliente se interrumpe. Por otro lado, algunos paquetes pueden ser particularmente sensibles a la p\u00e9rdida, ya que contienen informaci\u00f3n m\u00e1s importante en t\u00e9rminos de percepci\u00f3n del usuario que otros paquetes. Primero desarrollamos un modelo de extremo a extremo basado en longitudes de p\u00e9rdida con el que podemos describir la distribuci\u00f3n de p\u00e9rdidas dentro de un. Estas m\u00e9tricas a nivel de paquete luego se vinculan a m\u00e9tricas objetivas de calidad de voz a nivel de usuario. Utilizando este marco, encontramos que para c\u00f3decs basados \u200b\u200ben muestras de baja compresi\u00f3n -LRB-PCM-RRB- con ocultaci\u00f3n de p\u00e9rdidas, las p\u00e9rdidas de paquetes aisladas se pueden ocultar bien, mientras que las p\u00e9rdidas en r\u00e1fagas tienen un mayor impacto perceptivo. Para los c\u00f3decs basados \u200b\u200ben tramas de alta compresi\u00f3n -LRB- G. 729 -RRB-, por un lado, el impacto de la p\u00e9rdida se amplifica a trav\u00e9s de la propagaci\u00f3n de errores causada por las memorias de filtro del decodificador, aunque, por otro lado, dichos esquemas de codificaci\u00f3n ayudan a ocultar la p\u00e9rdida al extrapolaci\u00f3n del estado del decodificador. Sin embargo, a diferencia de los c\u00f3decs basados \u200b\u200ben muestras, mostramos que el rendimiento de ocultaci\u00f3n puede \"interrumpirse\" en las transiciones dentro de la se\u00f1al de voz. Luego proponemos mecanismos que diferencian entre paquetes dentro de datos de voz para minimizar el impacto de la p\u00e9rdida de paquetes. A estos m\u00e9todos los denominamos recuperaci\u00f3n y control de p\u00e9rdidas. A nivel de extremo a extremo se lleva a cabo la identificaci\u00f3n de los paquetes sensibles a la p\u00e9rdida -LRB- remitente -RRB- as\u00ed como la ocultaci\u00f3n de la p\u00e9rdida -LRB- receptor -RRB-. Los esquemas de soporte salto a salto permiten entonces -LRB- intercambiar estad\u00edsticamente -RRB- la p\u00e9rdida de un paquete, que se considera m\u00e1s importante, contra otro del mismo flujo que es de menor importancia. Como ambos ets requieren el mismo costo en t\u00e9rminos de transmisi\u00f3n de red, se puede obtener una ganancia en la percepci\u00f3n del usuario. Mostramos que se pueden lograr mejoras significativas en la calidad de la voz y se pueden evitar datos adicionales y demoras, manteniendo al mismo tiempo un servicio de red que es pr\u00e1cticamente id\u00e9ntico al mejor esfuerzo a largo plazo. 1. INTRODUCCI\u00d3N Teniendo en cuenta que un tiempo real puede experimentar cierta p\u00e9rdida de paquetes, el impacto de la p\u00e9rdida puede variar significativamente dependiendo de qu\u00e9 paquetes se pierdan dentro de un flujo. A continuaci\u00f3n distinguimos dos razones para una sensibilidad de p\u00e9rdida tan variable: Sensibilidad temporal: cuya p\u00e9rdida est\u00e1 correlacionada en el tiempo puede provocar interrupciones en el servicio. Para voz, como un \u00fanico paquete contiene t\u00edpicamente varias -LRB- tramas de voz -RRB-, este efecto es m\u00e1s significativo que, por ejemplo, para v\u00eddeo. B\u00e1sicamente se traduce en p\u00e9rdidas de paquetes aisladas versus p\u00e9rdidas que ocurren en r\u00e1fagas. Figura 1 :Funciones de utilidad esquem\u00e1ticas dependientes de la p\u00e9rdida de m\u00e1s y menos -LRB- -1 -RRB- paquetes importantes m\u00e1s importantes con respecto a la percepci\u00f3n del usuario que otros del mismo flujo. Consideremos un flujo con dos tipos de fotogramas de importancia perceptual muy diferente -LRB- con el mismo tama\u00f1o, frecuencia y sin interdependencia entre los fotogramas -RRB-. Bajo la p\u00e9rdida del 50% de los paquetes, la calidad de percepci\u00f3n var\u00eda enormemente entre el lugar donde se recibe el 50% de las tramas con alta importancia perceptiva y el lugar donde se recibe el 50% de las tramas menos importantes. El soporte de red para flujos multimedia en tiempo real puede tener como objetivo, por un lado, ofrecer un servicio que, sin embargo, al implementarse dentro de una red conmutada PA&ET, resultar\u00e1 costoso para el proveedor de la red y, por tanto, para el usuario. Por otro lado, dentro de un servicio con p\u00e9rdidas, se deben tener en cuenta las restricciones de sensibilidad anteriores. Consideremos ahora el caso de que el 50 % de los paquetes de flujo identificados sean m\u00e1s importantes -LRB- designados por o menos importantes debido a cualquiera de las restricciones de sensibilidad anteriores. La Figura 1 a -RRB- muestra una funci\u00f3n de utilidad gen\u00e9rica que describe el nivel de Calidad de Servicio en funci\u00f3n del porcentaje de paquetes perdidos. Para el tr\u00e1fico multimedia en tiempo real, dicha utilidad debe corresponder a la calidad percibida de v\u00eddeo/voz. Si el sistema de transmisi\u00f3n no conoce la importancia relativa de los paquetes, las tasas de p\u00e9rdida para los paquetes y -1 son iguales. Debido a la sensibilidad sobreproporcional de los paquetes a la p\u00e9rdida, as\u00ed como a la dependencia del rendimiento de recuperaci\u00f3n de p\u00e9rdida final de los paquetes, la funci\u00f3n de utilidad est\u00e1 disminuyendo significativamente de una manera no lineal -LRB- aproximada en la figura por partes funciones lineales -RRB- con una tasa de p\u00e9rdida creciente. La Figura 1 b -RRB- presenta donde todos los paquetes est\u00e1n protegidos a expensas de -1. La ca\u00edda de la funci\u00f3n de utilidad -LRB- para tasas de p\u00e9rdida < 50 % -RRB- se reduce, porque los paquetes est\u00e1n protegidos y la conexi\u00f3n de extremo a extremo De este modo, la recuperaci\u00f3n de p\u00e9rdidas puede funcionar correctamente en una gama m\u00e1s amplia de tasas de p\u00e9rdidas indicadas por el \u00e1rea sombreada. Esto da como resultado una degradaci\u00f3n elegante de la utilidad de la aplicaci\u00f3n. Tenga en cuenta que cuanto mayor sea la no linealidad de la contribuci\u00f3n de utilidad de los paquetes -LRB-, desviaci\u00f3n de la curva de puntos en la Fig. 1 a -RRB-, mayor ser\u00e1 la ganancia potencial en utilidad cuando la protecci\u00f3n est\u00e1 habilitada. Los resultados de la utilidad de calidad percibida real para aplicaciones multimedia muestran un comportamiento no lineal *. Como los mecanismos tienen que implementarse dentro de la red -LRB- hopby-hop -RRB- y/o en los sistemas finales -LRB- end-to-end -RRB-, tenemos otro eje de clasificaci\u00f3n. La adaptaci\u00f3n del remitente al estado actual de congesti\u00f3n de la red mediante un esquema -LRB- para evitar p\u00e9rdidas, es dif\u00edcil de aplicar a la voz. Teniendo en cuenta que los flujos de voz son muy bajos, el coste relativo de transmitir la informaci\u00f3n de retroalimentaci\u00f3n es -LRB- en comparaci\u00f3n, por ejemplo, con un flujo de v\u00eddeo -RRB-. El mayor sin embargo,la falta de un c\u00f3dec es verdaderamente escalable en t\u00e9rminos de su salida y la correspondiente calidad de percepci\u00f3n. cuando se supone la disponibilidad de potencia inform\u00e1tica, se puede elegir permanentemente el c\u00f3dec m\u00e1s bajo sin disminuir realmente la calidad de percepci\u00f3n. Para las p\u00e9rdidas de extremo a extremo, debido a las limitaciones de retardo en tiempo real, se han propuesto esquemas de bucle abierto como la correcci\u00f3n de errores directa -LRB-FEC-RRB-. Si bien son atractivos porque se pueden utilizar hoy en d\u00eda en Internet, tambi\u00e9n tienen varios inconvenientes. La cantidad de informaci\u00f3n redundante debe ser adaptable para evitar quitar ancho de banda a otros flujos. El uso de redundancia tambi\u00e9n tiene implicaciones para la adaptaci\u00f3n del retardo -LRB- -LSB- lo -RSB- -RRB- empleada para eliminar la fluctuaci\u00f3n de los paquetes en el receptor. Tenga en cuenta que los tipos de sensibilidad a las p\u00e9rdidas presentados tambi\u00e9n se aplican a los resultados que hemos obtenido que confirman la forma de la curva de \"utilidad general\" que se muestra en la Fig. 1, claramente las funciones de utilidad de la \"sub\". Los flujos y sus relaciones son m\u00e1s complejos y s\u00f3lo aproximadamente aditivos. Tabla 1: Probabilidades de estado y transici\u00f3n calculadas para un rastreo de Internet de extremo a extremo utilizando un modelo general de Markov -LRB- de tercer orden -RRB- por Yajnik et. al.. que se ven reforzados por mecanismos de recuperaci\u00f3n de p\u00e9rdidas de extremo a extremo. Los mecanismos de extremo a extremo pueden reducir y cambiar esas sensibilidades, pero no pueden acercarse a eliminarlas. Por lo tanto en este trabajo asumimos que se elige la tarifa m\u00e1s baja posible que proporcione la calidad deseada. No se utiliza retroalimentaci\u00f3n/adaptaci\u00f3n ni redundancia, sin embargo, a nivel de extremo a extremo, se lleva a cabo la identificaci\u00f3n/marcado de paquetes sensibles a p\u00e9rdida -LRB- remitente -RRB- as\u00ed como ocultaci\u00f3n de p\u00e9rdida -LRB- receptor -RRB-. Los esquemas de soporte salto a salto permiten entonces intercambiar la p\u00e9rdida de un paquete, que se considera m\u00e1s importante, contra otro del mismo flujo que es de menor importancia. Empleamos datos reales y medimos su utilidad en presencia de p\u00e9rdida de paquetes mediante mediciones objetivas de la calidad del habla. El documento est\u00e1 estructurado de la siguiente manera: La Secci\u00f3n 2 presenta m\u00e9tricas a nivel de paquete y de usuario. Empleamos estas m\u00e9tricas para describir la sensibilidad del tr\u00e1fico a la p\u00e9rdida de paquetes en la secci\u00f3n 3. La secci\u00f3n 4 presenta brevemente un algoritmo de gesti\u00f3n de colas que se puede utilizar para el control de p\u00e9rdidas dentro del flujo. En la secci\u00f3n 5, presentamos resultados que documentan el desempe\u00f1o de los mecanismos propuestos tanto a nivel de extremo a extremo como por salto. La secci\u00f3n 6 concluye el art\u00edculo.El uso de redundancia tambi\u00e9n tiene implicaciones para la adaptaci\u00f3n del retardo -LRB- -LSB- lo -RSB- -RRB- empleada para eliminar la fluctuaci\u00f3n de los paquetes en el receptor. Tenga en cuenta que los tipos de sensibilidad a las p\u00e9rdidas presentados tambi\u00e9n se aplican a los resultados que hemos obtenido que confirman la forma de la curva de \"utilidad general\" que se muestra en la Fig. 1, claramente las funciones de utilidad de la \"sub\". Los flujos y sus relaciones son m\u00e1s complejos y s\u00f3lo aproximadamente aditivos. Tabla 1: Probabilidades de estado y transici\u00f3n calculadas para un rastreo de Internet de extremo a extremo utilizando un modelo general de Markov -LRB- de tercer orden -RRB- por Yajnik et. al.. que se ven reforzados por mecanismos de recuperaci\u00f3n de p\u00e9rdidas de extremo a extremo. Los mecanismos de extremo a extremo pueden reducir y cambiar esas sensibilidades, pero no pueden acercarse a eliminarlas. Por lo tanto en este trabajo asumimos que se elige la tarifa m\u00e1s baja posible que proporcione la calidad deseada. No se utiliza retroalimentaci\u00f3n/adaptaci\u00f3n ni redundancia, sin embargo, a nivel de extremo a extremo, se lleva a cabo la identificaci\u00f3n/marcado de paquetes sensibles a p\u00e9rdida -LRB- remitente -RRB- as\u00ed como ocultaci\u00f3n de p\u00e9rdida -LRB- receptor -RRB-. Los esquemas de soporte salto a salto permiten entonces intercambiar la p\u00e9rdida de un paquete, que se considera m\u00e1s importante, contra otro del mismo flujo que es de menor importancia. Empleamos datos reales y medimos su utilidad en presencia de p\u00e9rdida de paquetes mediante mediciones objetivas de la calidad del habla. El documento est\u00e1 estructurado de la siguiente manera: La Secci\u00f3n 2 presenta m\u00e9tricas a nivel de paquete y de usuario. Empleamos estas m\u00e9tricas para describir la sensibilidad del tr\u00e1fico a la p\u00e9rdida de paquetes en la secci\u00f3n 3. La secci\u00f3n 4 presenta brevemente un algoritmo de gesti\u00f3n de colas que se puede utilizar para el control de p\u00e9rdidas dentro del flujo. En la secci\u00f3n 5, presentamos resultados que documentan el desempe\u00f1o de los mecanismos propuestos tanto a nivel de extremo a extremo como por salto. La secci\u00f3n 6 concluye el art\u00edculo.El uso de redundancia tambi\u00e9n tiene implicaciones para la adaptaci\u00f3n del retardo -LRB- -LSB- lo -RSB- -RRB- empleada para eliminar la fluctuaci\u00f3n de los paquetes en el receptor. Tenga en cuenta que los tipos de sensibilidad a las p\u00e9rdidas presentados tambi\u00e9n se aplican a los resultados que hemos obtenido que confirman la forma de la curva de \"utilidad general\" que se muestra en la Fig. 1, claramente las funciones de utilidad de la \"sub\". Los flujos y sus relaciones son m\u00e1s complejos y s\u00f3lo aproximadamente aditivos. Tabla 1: Probabilidades de estado y transici\u00f3n calculadas para un rastreo de Internet de extremo a extremo utilizando un modelo general de Markov -LRB- de tercer orden -RRB- por Yajnik et. al.. que se ven reforzados por mecanismos de recuperaci\u00f3n de p\u00e9rdidas de extremo a extremo. Los mecanismos de extremo a extremo pueden reducir y cambiar esas sensibilidades, pero no pueden acercarse a eliminarlas. Por lo tanto en este trabajo asumimos que se elige la tarifa m\u00e1s baja posible que proporcione la calidad deseada. No se utiliza retroalimentaci\u00f3n/adaptaci\u00f3n ni redundancia, sin embargo, a nivel de extremo a extremo, se lleva a cabo la identificaci\u00f3n/marcado de paquetes sensibles a p\u00e9rdida -LRB- remitente -RRB- as\u00ed como ocultaci\u00f3n de p\u00e9rdida -LRB- receptor -RRB-. Los esquemas de soporte salto a salto permiten entonces intercambiar la p\u00e9rdida de un paquete, que se considera m\u00e1s importante, contra otro del mismo flujo que es de menor importancia. Empleamos datos reales y medimos su utilidad en presencia de p\u00e9rdida de paquetes mediante mediciones objetivas de la calidad del habla. El documento est\u00e1 estructurado de la siguiente manera: La Secci\u00f3n 2 presenta m\u00e9tricas a nivel de paquete y de usuario. Empleamos estas m\u00e9tricas para describir la sensibilidad del tr\u00e1fico a la p\u00e9rdida de paquetes en la secci\u00f3n 3. La secci\u00f3n 4 presenta brevemente un algoritmo de gesti\u00f3n de colas que se puede utilizar para el control de p\u00e9rdidas dentro del flujo. En la secci\u00f3n 5, presentamos resultados que documentan el desempe\u00f1o de los mecanismos propuestos tanto a nivel de extremo a extremo como por salto. La secci\u00f3n 6 concluye el art\u00edculo.que se considera m\u00e1s importante, frente a otro del mismo flujo que es de menor importancia. Empleamos datos reales y medimos su utilidad en presencia de p\u00e9rdida de paquetes mediante mediciones objetivas de la calidad del habla. El documento est\u00e1 estructurado de la siguiente manera: La Secci\u00f3n 2 presenta m\u00e9tricas a nivel de paquete y de usuario. Empleamos estas m\u00e9tricas para describir la sensibilidad del tr\u00e1fico a la p\u00e9rdida de paquetes en la secci\u00f3n 3. La secci\u00f3n 4 presenta brevemente un algoritmo de gesti\u00f3n de colas que se puede utilizar para el control de p\u00e9rdidas dentro del flujo. En la secci\u00f3n 5, presentamos resultados que documentan el desempe\u00f1o de los mecanismos propuestos tanto a nivel de extremo a extremo como por salto. La secci\u00f3n 6 concluye el art\u00edculo.que se considera m\u00e1s importante, frente a otro del mismo flujo que es de menor importancia. Empleamos datos reales y medimos su utilidad en presencia de p\u00e9rdida de paquetes mediante mediciones objetivas de la calidad del habla. El documento est\u00e1 estructurado de la siguiente manera: La Secci\u00f3n 2 presenta m\u00e9tricas a nivel de paquete y de usuario. Empleamos estas m\u00e9tricas para describir la sensibilidad del tr\u00e1fico a la p\u00e9rdida de paquetes en la secci\u00f3n 3. La secci\u00f3n 4 presenta brevemente un algoritmo de gesti\u00f3n de colas que se puede utilizar para el control de p\u00e9rdidas dentro del flujo. En la secci\u00f3n 5, presentamos resultados que documentan el desempe\u00f1o de los mecanismos propuestos tanto a nivel de extremo a extremo como por salto. La secci\u00f3n 6 concluye el art\u00edculo.", "keyphrases": ["modelo de extremo a extremo", "c\u00f3dec basado en muestras", "recuperaci\u00f3n y control de p\u00e9rdidas", "sensibilidad a la p\u00e9rdida", "soporte de red para multimedia en tiempo real", "calidad de servicio", "recuperaci\u00f3n de p\u00e9rdidas de extremo a extremo", "tr\u00e1fico voip", "control de p\u00e9rdida intraflujo", "m\u00e9trica a nivel de paquete", "modelo de gen markov", "sensaci\u00f3n de tr\u00e1fico voip", "algoritmo de gesti\u00f3n de colas", "c\u00f3dec basado en fotogramas"]}
{"file_name": "C-22", "text": "Recopilaci\u00f3n de m\u00e9tricas de tiempo de ejecuci\u00f3n para la adaptaci\u00f3n compatible con middleware de aplicaciones m\u00f3viles RESUMEN Este art\u00edculo propone, implementa y eval\u00faa, en t\u00e9rminos del peor de los casos, una estrategia de recopilaci\u00f3n de m\u00e9tricas en l\u00ednea para facilitar la adaptaci\u00f3n de aplicaciones a trav\u00e9s de la movilidad de objetos utilizando un marco de objetos m\u00f3viles y middleware de soporte. La soluci\u00f3n se basa en una representaci\u00f3n abstracta del sistema de objetos m\u00f3viles, que contiene contenedores que agregan m\u00e9tricas para cada componente espec\u00edfico, incluidos administradores de host, tiempos de ejecuci\u00f3n y objetos m\u00f3viles. Una caracter\u00edstica clave de la soluci\u00f3n es la especificaci\u00f3n de m\u00faltiples criterios configurables para controlar la medici\u00f3n y propagaci\u00f3n de m\u00e9tricas a trav\u00e9s del sistema. La plataforma MobJeX se utiliz\u00f3 como base para la implementaci\u00f3n y las pruebas con una serie de pruebas de laboratorio realizadas para medir la escalabilidad, la eficiencia y la aplicaci\u00f3n de criterios simples de medici\u00f3n y propagaci\u00f3n para reducir los gastos generales de recolecci\u00f3n. 1. INTRODUCCI\u00d3N Una adaptaci\u00f3n eficaz requiere informaci\u00f3n detallada y actualizada tanto del sistema como del propio software. Las m\u00e9tricas relacionadas con la informaci\u00f3n de todo el sistema -LRB-, por ejemplo, procesador, memoria y carga de red -RRB-, se denominan m\u00e9tricas ambientales -LSB- 5 -RSB-, mientras que las m\u00e9tricas que representan el comportamiento de la aplicaci\u00f3n se denominan m\u00e9tricas de software -LSB- 8 -RSB- . Adem\u00e1s, el tipo de m\u00e9tricas necesarias para realizar la adaptaci\u00f3n depende del tipo de adaptaci\u00f3n requerida. Por ejemplo, la adaptaci\u00f3n basada en servicios, en la que la calidad del servicio o el comportamiento del servicio se modifica en respuesta a cambios en el entorno de ejecuci\u00f3n, generalmente requiere m\u00e9tricas ambientales detalladas, pero s\u00f3lo m\u00e9tricas de software simples -LSB- 4 -RSB-. Por otro lado, la adaptaci\u00f3n a trav\u00e9s de la movilidad de objetos -LSB- 6 -RSB-, tambi\u00e9n requiere m\u00e9tricas de software detalladas -LSB- 9 -RSB- ya que la ubicaci\u00f3n de los objetos depende de las caracter\u00edsticas de ejecuci\u00f3n de los propios objetos m\u00f3viles. Con la excepci\u00f3n de MobJeX -LSB- 6 -RSB-, los sistemas de objetos m\u00f3viles existentes como Voyager -LSB- 10 -RSB-, FarGo -LSB- 11, 12 -RSB- y JavaParty -LSB- 13 -RSB- no proporcionan una adaptaci\u00f3n automatizada y, por lo tanto, carecen del proceso de recopilaci\u00f3n de m\u00e9tricas necesario para respaldar este proceso. En el caso de MobJeX, aunque se ha implementado un motor de adaptaci\u00f3n -LSB- 5 -RSB-, las pruebas preliminares se realizaron utilizando m\u00e9tricas sint\u00e9ticas predefinidas ya que hay poco trabajo previo sobre la recopilaci\u00f3n din\u00e1mica de m\u00e9tricas de software en marcos de objetos m\u00f3viles, y no existen medios para recopilarlos autom\u00e1ticamente. En consecuencia, la principal contribuci\u00f3n de este art\u00edculo es una soluci\u00f3n para la recopilaci\u00f3n de m\u00e9tricas din\u00e1micas para respaldar la adaptaci\u00f3n a trav\u00e9s de la movilidad de objetos para aplicaciones m\u00f3viles. Este problema no es trivial ya que los marcos t\u00edpicos de objetos m\u00f3viles constan de m\u00faltiples aplicaciones y componentes de middleware y, por lo tanto, la recopilaci\u00f3n de m\u00e9tricas debe realizarse en diferentes ubicaciones y los resultados se propagan de manera eficiente al motor de adaptaci\u00f3n. El resto del trabajo se organiza como sigue :La secci\u00f3n 2 describe la estructura general y la implementaci\u00f3n de marcos de objetos m\u00f3viles para comprender los desaf\u00edos relacionados con la recopilaci\u00f3n, propagaci\u00f3n y entrega de m\u00e9tricas como se describe en la secci\u00f3n 3. La secci\u00f3n 4 describe algunas pruebas y resultados iniciales y la secci\u00f3n 5 cierra con un resumen. conclusiones y discusi\u00f3n de trabajos futuros. 2. ANTECEDENTES En general, una aplicaci\u00f3n orientada a objetos consta de objetos que colaboran para proporcionar la funcionalidad requerida por un dominio de problema determinado. Los marcos de objetos m\u00f3viles permiten que algunos de estos objetos se etiqueten como objetos m\u00f3viles, proporcionando soporte de middleware para que dichos objetos se muevan en tiempo de ejecuci\u00f3n a otros hosts. Como m\u00ednimo, un marco de objetos m\u00f3viles con al menos una aplicaci\u00f3n m\u00f3vil en ejecuci\u00f3n consta de los siguientes componentes: tiempos de ejecuci\u00f3n, objetos m\u00f3viles y proxies -LSB- 14 -RSB-, aunque la terminolog\u00eda utilizada por los marcos individuales puede diferir -LSB- 6, 10-13 -RSB-. Un tiempo de ejecuci\u00f3n es un proceso contenedor para la gesti\u00f3n de objetos m\u00f3viles. Por ejemplo, en FarGo -LSB- 15 -RSB- este componente se conoce como n\u00facleo y en la mayor\u00eda de sistemas se requieren tiempos de ejecuci\u00f3n separados para permitir que diferentes aplicaciones se ejecuten de forma independiente, aunque este no es el caso de MobJeX, que puede ejecutar m\u00faltiples aplicaciones en un \u00fanico tiempo de ejecuci\u00f3n utilizando subprocesos. Las propias aplicaciones comprenden objetos m\u00f3viles, que interact\u00faan entre s\u00ed a trav\u00e9s de proxies -LSB- 14 -RSB-. Tras la migraci\u00f3n, los objetos proxy se mueven con el objeto de origen. El sistema basado en Java MobJeX, que se utiliza como plataforma de implementaci\u00f3n para la soluci\u00f3n de recopilaci\u00f3n de m\u00e9tricas descrita en este documento, agrega una serie de componentes de middleware adicionales. En primer lugar, un administrador de host -LRB- conocido como servicio en MobJeX -RRB- proporciona un punto central de comunicaci\u00f3n al ejecutarse en un puerto conocido por host, facilitando as\u00ed la enumeraci\u00f3n o b\u00fasqueda de componentes como tiempos de ejecuci\u00f3n u objetos m\u00f3viles. En segundo lugar, MobJeX tiene un contenedor de objetos m\u00f3viles por aplicaci\u00f3n llamado administrador de transporte -LRB-TM-RRB-. Como tales, los administradores de host y transporte se consideran en la soluci\u00f3n proporcionada en la siguiente secci\u00f3n, pero podr\u00edan omitirse en el caso general. Finalmente, dependiendo del modo de adaptaci\u00f3n, MobJeX puede tener un controlador de sistema centralizado que incorpora un motor de adaptaci\u00f3n global para realizar una optimizaci\u00f3n de todo el sistema. 5. RESUMEN Y CONCLUSIONES Dados los desaf\u00edos de desarrollar aplicaciones m\u00f3viles que se ejecutan en entornos din\u00e1micos/heterog\u00e9neos, y el inter\u00e9s posterior en la adaptaci\u00f3n de aplicaciones, este documento ha propuesto e implementado una estrategia de recopilaci\u00f3n de m\u00e9tricas en l\u00ednea para ayudar a dicha adaptaci\u00f3n utilizando un marco de objetos m\u00f3viles y soporte. software intermedio. Se realizaron estudios de laboratorio controlados para determinar el peor desempe\u00f1o en los casos, as\u00ed como para mostrar la reducci\u00f3n en los gastos generales de recolecci\u00f3n al aplicar criterios de recolecci\u00f3n simples. Adem\u00e1s,pruebas adicionales proporcionaron una indicaci\u00f3n inicial de las caracter\u00edsticas de los objetos de aplicaci\u00f3n -LRB- basados \u200b\u200ben el tiempo de ejecuci\u00f3n del m\u00e9todo -RRB- que ser\u00edan buenos candidatos para la adaptaci\u00f3n utilizando la implementaci\u00f3n en el peor de los casos de la estrategia de recopilaci\u00f3n de m\u00e9tricas propuesta. Una caracter\u00edstica clave de la soluci\u00f3n fue la especificaci\u00f3n de m\u00faltiples criterios configurables para controlar la propagaci\u00f3n de m\u00e9tricas a trav\u00e9s del sistema, reduciendo as\u00ed los gastos generales de recopilaci\u00f3n. Adem\u00e1s, dicha historia temporal tambi\u00e9n podr\u00eda facilitar decisiones inteligentes con respecto a la recopilaci\u00f3n de m\u00e9tricas ya que, por ejemplo, una m\u00e9trica que se sabe que es en gran medida constante no necesita medirse con frecuencia. El trabajo futuro tambi\u00e9n implicar\u00e1 la evaluaci\u00f3n de una amplia gama de escenarios de adaptaci\u00f3n en el marco MobJeX para cuantificar los beneficios que se pueden obtener mediante la adaptaci\u00f3n a trav\u00e9s de la movilidad de objetos y as\u00ed demostrar en la pr\u00e1ctica la eficacia de la soluci\u00f3n descrita en este documento. Finalmente, los autores desean explorar la aplicaci\u00f3n de los conceptos de recopilaci\u00f3n de m\u00e9tricas descritos en este art\u00edculo a un sistema de gesti\u00f3n de context m\u00e1s general y reutilizable -LSB- 20 -RSB-.", "keyphrases": ["datos", "aplicaci\u00f3n orientada a objetos", "marco de objetos m\u00f3viles", "mobjex", "Java", "las m\u00e9tricas contienen", "recopilaci\u00f3n m\u00e9trica", "proximo", "realizar y escalable", "medir", "propagaci\u00f3n y entrega", "estructura"]}
{"file_name": "H-26", "text": "Un m\u00e9todo de vector de soporte para optimizar la precisi\u00f3n promedio RESUMEN El aprendizaje autom\u00e1tico se usa com\u00fanmente para mejorar los sistemas de recuperaci\u00f3n clasificados. Debido a dificultades computacionales, se han desarrollado pocas t\u00e9cnicas de aprendizaje para optimizar directamente la precisi\u00f3n promedio promedio -LRB-MAP-RRB-, a pesar de su uso generalizado en la evaluaci\u00f3n de dichos sistemas. Los enfoques existentes que optimizan MAP no encuentran una soluci\u00f3n global \u00f3ptima o son computacionalmente costosos. Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra eficientemente una soluci\u00f3n global \u00f3ptima para una relajaci\u00f3n directa de MAP. Evaluamos nuestro enfoque utilizando los corpus Web Track TREC 9 y TREC 10 -LRB- WT10g -RRB-, compar\u00e1ndolos con SVM optimizados para precisi\u00f3n y ROCArea. En la mayor\u00eda de los casos, mostramos nuestro m\u00e9todo para producir mejoras estad\u00edsticamente significativas en las puntuaciones MAP. 1. INTRODUCCI\u00d3N Los sistemas de recuperaci\u00f3n de informaci\u00f3n de \u00faltima generaci\u00f3n suelen utilizar t\u00e9cnicas de aprendizaje autom\u00e1tico para aprender funciones de clasificaci\u00f3n. Sin embargo, la mayor\u00eda de los enfoques actuales no optimizan la medida de evaluaci\u00f3n m\u00e1s utilizada, a saber, la precisi\u00f3n promedio media -LRB-MAP-RRB-. En cambio, los algoritmos actuales tienden a adoptar uno de dos enfoques generales. El primer enfoque es aprender un modelo que estime la probabilidad de que un documento sea relevante, dado que si se resuelve de manera efectiva, la clasificaci\u00f3n con mejor desempe\u00f1o de MAP se puede derivar f\u00e1cilmente de las probabilidades de relevancia. Sin embargo, lograr un MAP alto s\u00f3lo requiere encontrar un buen ordenamiento de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema m\u00e1s dif\u00edcil de lo necesario, lo que probablemente requiera m\u00e1s datos de entrenamiento para lograr el mismo rendimiento MAP. El segundo enfoque com\u00fan es aprender una funci\u00f3n que maximice una medida sustituta. Las medidas de rendimiento optimizadas incluyen precisi\u00f3n -LSB- 17, 15 -RSB-, ROCArea -LSB- 1, 5, 10, 11, 13, 21 -RSB- o modificaciones de ROCArea -LSB- 4 -RSB- y NDCG -LSB- 2, 3 -RSB-. Aprender un modelo para optimizar tales medidas podr\u00eda dar como resultado un rendimiento MAP sub\u00f3ptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento MAP, se sabe que ni lograr una precisi\u00f3n \u00f3ptima ni ROCArea pueden garantizar un rendimiento MAP \u00f3ptimo -LSB- 7 -RSB-. En este art\u00edculo, presentamos un enfoque general para aprender funciones de clasificaci\u00f3n que maximizan el rendimiento de MAP. Espec\u00edficamente, presentamos un algoritmo SVM que optimiza globalmente una relajaci\u00f3n de p\u00e9rdida de bisagra de MAP. Este enfoque simplifica el proceso de obtenci\u00f3n de funciones de clasificaci\u00f3n con alto rendimiento MAP al evitar pasos intermedios y heur\u00edsticas adicionales. El nuevo algoritmo tambi\u00e9n hace que conceptualmente sea tan f\u00e1cil optimizar las SVM para MAP como antes solo era posible en t\u00e9rminos de precisi\u00f3n y ROCArea. A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft -LSB-16-RSB- y Caruana et al. -LSB- 6 -RSB-, nuestra t\u00e9cnica es computacionalmente eficiente y al mismo tiempo encuentra una soluci\u00f3n global \u00f3ptima.Ahora describimos el algoritmo en detalle y proporcionamos pruebas de su correcci\u00f3n. A continuaci\u00f3n, proporcionamos un an\u00e1lisis del tiempo de ejecuci\u00f3n. Tambi\u00e9n hemos desarrollado un paquete de software que implementa nuestro algoritmo y que est\u00e1 disponible para el usuario p\u00fablico. 6. CONCLUSIONES Y TRABAJO FUTURO Hemos presentado un m\u00e9todo SVM que optimiza directamente MAP. Proporciona un enfoque basado en principios y evita heur\u00edsticas dif\u00edciles de controlar. Formulamos el problema de optimizaci\u00f3n y presentamos un algoritmo que probablemente encuentra la soluci\u00f3n en tiempo polinomial. Hemos demostrado emp\u00edricamente que nuestro m\u00e9todo es generalmente superior o competitivo con los m\u00e9todos SVM convencionales. Nuestro nuevo m\u00e9todo hace que conceptualmente sea tan f\u00e1cil optimizar SVM para MAP como antes solo era posible para Accuracy y ROCArea. Dado que otros m\u00e9todos normalmente requieren ajustar m\u00faltiples heur\u00edsticas, tambi\u00e9n esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento. El marco de aprendizaje utilizado por nuestro m\u00e9todo es bastante general.", "keyphrases": ["aprendizaje autom\u00e1tico", "sistema de recuperaci\u00f3n de rangos", "aprender tecnica", "media exacta media", "soluci\u00f3n \u00f3ptima", "relajarse del mapa", "informar al sistema de recuperaci\u00f3n", "probable", "medida sustituta", "funci\u00f3n de p\u00e9rdida", "supervisar aprender"]}
{"file_name": "H-25", "text": "Retroalimentaci\u00f3n de t\u00e9rminos para la recuperaci\u00f3n de informaci\u00f3n con modelos de lenguaje RESUMEN En este art\u00edculo, retroalimentaci\u00f3n basada en t\u00e9rminos de West Udy para la recuperaci\u00f3n de informaci\u00f3n en el enfoque de modelado de lenguaje. Con la retroalimentaci\u00f3n de t\u00e9rminos, un usuario juzga directamente la relevancia de t\u00e9rminos individuales sin interactuar con los documentos de retroalimentaci\u00f3n, tomando control total del proceso de expansi\u00f3n de la consulta. Proponemos un m\u00e9todo basado en cl\u00fasteres para seleccionar t\u00e9rminos para presentar al usuario para su juicio, as\u00ed como algoritmos efectivos para construir modelos de lenguaje de consulta refinados a partir de comentarios de t\u00e9rminos del usuario. Se ha demostrado que nuestros algoritmos aportan una mejora significativa en la precisi\u00f3n de la recuperaci\u00f3n con respecto a una base sin comentarios y logran un rendimiento comparable al de los comentarios relevantes. Son \u00fatiles incluso cuando no hay documentos relevantes en la parte superior. 1. INTRODUCCI\u00d3N En el enfoque de modelado del lenguaje para la recuperaci\u00f3n de informaci\u00f3n, la retroalimentaci\u00f3n a menudo se modela como una estimaci\u00f3n de un modelo de consulta mejorado o un modelo de relevancia basado en un conjunto de documentos de retroalimentaci\u00f3n -LSB- 25, 13 -RSB-. Esto est\u00e1 en l\u00ednea con la forma tradicional de realizar comentarios sobre relevancia: presentar al usuario documentos o pasajes para que juzgue su relevancia y luego extraer t\u00e9rminos de los documentos o pasajes evaluados para ampliar la consulta inicial. Es una forma indirecta de buscar la ayuda del usuario para la construcci\u00f3n del modelo de consulta, en el sentido de que el modelo de consulta refinado -LRB- basado en t\u00e9rminos -RRB- se aprende a trav\u00e9s de documentos/pasajes de retroalimentaci\u00f3n, que son estructuras de t\u00e9rminos de alto nivel. Tiene la desventaja de que los t\u00e9rminos irrelevantes, que aparecen junto con otros relevantes en el contenido juzgado, pueden usarse err\u00f3neamente para ampliar la consulta, provocando efectos no deseados. Por ejemplo, para la consulta TREC ``logros del telescopio Hubble'', cuando un documento relevante habla m\u00e1s sobre la reparaci\u00f3n del telescopio que sobre sus descubrimientos, se pueden agregar t\u00e9rminos irrelevantes como ``paseo espacial'' a la consulta modificada. Podemos considerar una forma m\u00e1s directa de involucrar a un usuario en la mejora del modelo de consulta, sin un paso intermedio de retroalimentaci\u00f3n del documento que pueda introducir ruido. La idea es presentar un n\u00famero -LRB- razonable -RRB- de t\u00e9rminos individuales al usuario y pedirle que juzgue la relevancia de cada t\u00e9rmino o especifique directamente sus probabilidades en el modelo de consulta. En comparaci\u00f3n con la retroalimentaci\u00f3n de relevancia tradicional, este enfoque basado en t\u00e9rminos para el refinamiento del modelo de consulta interactiva tiene varias ventajas. En primer lugar, el usuario tiene un mejor control del modelo de consulta final mediante la manipulaci\u00f3n directa de los t\u00e9rminos: puede dictar qu\u00e9 t\u00e9rminos son relevantes, irrelevantes y, posiblemente, en qu\u00e9 grado. Esto evita el riesgo de incorporar t\u00e9rminos no deseados al modelo de consulta, aunque a veces el usuario introduce t\u00e9rminos de baja calidad. Esto es especialmente \u00fatil para la b\u00fasqueda ad hoc interactiva. En este caso, la retroalimentaci\u00f3n sobre la relevancia es in\u00fatil, ya que no se puede aprovechar ning\u00fan documento relevante, pero la retroalimentaci\u00f3n sobre los t\u00e9rminos sigue siendo a menudo \u00fatil, ya que permite seleccionar t\u00e9rminos relevantes de documentos irrelevantes.Durante nuestra participaci\u00f3n en TREC 2005 HARD Track y el estudio continuado posterior, exploramos c\u00f3mo explotar la retroalimentaci\u00f3n de t\u00e9rminos del usuario para construir modelos de consulta mejorados para la recuperaci\u00f3n de informaci\u00f3n en el enfoque de modelado de lenguaje. Identificamos dos subtareas clave de la retroalimentaci\u00f3n basada en t\u00e9rminos, es decir, la selecci\u00f3n de t\u00e9rminos de presentaci\u00f3n previa a la retroalimentaci\u00f3n y la construcci\u00f3n del modelo de consulta posterior a la retroalimentaci\u00f3n, con algoritmos efectivos desarrollados para ambas. Impusimos una estructura de grupo secundaria a los t\u00e9rminos y descubrimos que una vista de grupo arroja informaci\u00f3n adicional sobre las necesidades de informaci\u00f3n del usuario y proporciona una buena forma de utilizar la retroalimentaci\u00f3n de los t\u00e9rminos. A trav\u00e9s de experimentos encontramos que la retroalimentaci\u00f3n de t\u00e9rminos mejora significativamente con respecto a la l\u00ednea de base sin retroalimentaci\u00f3n, aunque el usuario a menudo comete errores en el juicio de relevancia. Entre nuestros algoritmos, el que tiene mejor rendimiento de recuperaci\u00f3n es TCFB, la combinaci\u00f3n de TFB, el algoritmo de retroalimentaci\u00f3n de t\u00e9rminos directos, y CFB, el algoritmo de retroalimentaci\u00f3n basado en cl\u00fasteres. Tambi\u00e9n variamos la cantidad de t\u00e9rminos de retroalimentaci\u00f3n y observamos una mejora razonable incluso con n\u00fameros bajos. Finalmente, al comparar la retroalimentaci\u00f3n de t\u00e9rminos con la retroalimentaci\u00f3n a nivel de documento, descubrimos que es una alternativa viable a esta \u00faltima con un rendimiento de recuperaci\u00f3n competitivo. El resto del documento est\u00e1 organizado de la siguiente manera. La secci\u00f3n 2 analiza algunos trabajos relacionados. La Secci\u00f3n 4 describe nuestro enfoque general para la retroalimentaci\u00f3n de t\u00e9rminos. Presentamos nuestro m\u00e9todo para la selecci\u00f3n de t\u00e9rminos de presentaci\u00f3n en la Secci\u00f3n 3 y los algoritmos para la construcci\u00f3n del modelo de consulta en la Secci\u00f3n 5. Los resultados del experimento se dan en la Secci\u00f3n 6. La Secci\u00f3n 7 concluye este art\u00edculo. 2. TRABAJO RELACIONADO La retroalimentaci\u00f3n de relevancia -LSB- 17, 19 -RSB- ha sido reconocida durante mucho tiempo como un m\u00e9todo eficaz para mejorar el rendimiento de la recuperaci\u00f3n. Normalmente, los N documentos principales recuperados mediante la consulta original se presentan al usuario para que los juzgue, despu\u00e9s de lo cual se extraen los t\u00e9rminos de los documentos relevantes evaluados, se ponderan seg\u00fan su potencial de atraer documentos m\u00e1s relevantes y se agregan al modelo de consulta. La consulta expandida generalmente representa la informaci\u00f3n que el usuario necesita mejor que la original, que a menudo es solo una consulta breve de palabras clave. Una segunda iteraci\u00f3n de recuperaci\u00f3n utilizando esta consulta modificada normalmente produce un aumento significativo en la precisi\u00f3n de la recuperaci\u00f3n. En los casos en los que no se dispone de un verdadero juicio de relevancia y se supone que todos los N documentos principales son relevantes, se denomina retroalimentaci\u00f3n ciega o pseudo -LSB- 5, 16 -RSB- y generalmente a\u00fan trae mejoras en el rendimiento. Debido a que el documento es una unidad de text grande, cuando se utiliza para comentarios sobre relevancia, se pueden introducir muchos t\u00e9rminos irrelevantes en el proceso de comentarios. Para superar esto, se propone y se ha demostrado que la retroalimentaci\u00f3n de pasaje mejora el rendimiento de la retroalimentaci\u00f3n -LSB- 1, 23 -RSB-. Una soluci\u00f3n m\u00e1s directa es pedirle al usuario su opini\u00f3n sobre la relevancia de los t\u00e9rminos de retroalimentaci\u00f3n. Por ejemplo, en algunos sistemas de retroalimentaci\u00f3n de relevancia como -LSB- 12 -RSB-,hay un paso de interacci\u00f3n que permite al usuario agregar o eliminar t\u00e9rminos de expansi\u00f3n despu\u00e9s de que se extraigan autom\u00e1ticamente de los documentos relevantes. En muchos casos, se ha descubierto que la retroalimentaci\u00f3n de relevancia de t\u00e9rminos mejora efectivamente el rendimiento de recuperaci\u00f3n -LSB- 6, 22, 12, 4, 10 -RSB-. Por ejemplo, el estudio en -LSB- 12 -RSB- muestra que el usuario prefiere tener conocimiento expl\u00edcito y control directo de qu\u00e9 t\u00e9rminos se utilizan para la expansi\u00f3n de consultas, y se demuestra que la interfaz penetrable que proporciona esta libertad funciona mejor que otras interfaces. . Sin embargo, en algunos otros casos no hay ning\u00fan beneficio significativo -LSB- 3, 14 -RSB-, incluso si al usuario le gusta interactuar con los t\u00e9rminos de expansi\u00f3n. Se descubre que el usuario no es bueno para identificar t\u00e9rminos \u00fatiles para la expansi\u00f3n de consultas, cuando una interfaz de presentaci\u00f3n de t\u00e9rminos simple no puede proporcionar suficiente context sem\u00e1ntico de los t\u00e9rminos de retroalimentaci\u00f3n. Nuestro trabajo se diferencia de los anteriores en dos aspectos importantes. La forma habitual de presentar los t\u00e9rminos de retroalimentaci\u00f3n es simplemente mostrar los t\u00e9rminos en una lista. Se han realizado algunos trabajos sobre interfaces de usuario alternativas. Sin embargo, en ambos estudios no hay diferencias significativas en el rendimiento. En nuestro trabajo adoptamos el enfoque m\u00e1s simple de t\u00e9rminos + casillas de verificaci\u00f3n. Nos centramos en la presentaci\u00f3n de t\u00e9rminos y la construcci\u00f3n de modelos de consulta a partir de t\u00e9rminos de retroalimentaci\u00f3n, y creemos que el uso de contexts para mejorar la calidad de los t\u00e9rminos de retroalimentaci\u00f3n deber\u00eda ser ortogonal a nuestro m\u00e9todo. 7. CONCLUSIONES En este art\u00edculo estudiamos el uso de t\u00e9rminos de retroalimentaci\u00f3n para la recuperaci\u00f3n de informaci\u00f3n interactiva en el enfoque de modelado del lenguaje. Propusimos un m\u00e9todo basado en cl\u00fasteres para seleccionar t\u00e9rminos de presentaci\u00f3n, as\u00ed como algoritmos para estimar modelos de consulta refinados a partir de los comentarios de los t\u00e9rminos de los usuarios. Vimos una mejora significativa en la precisi\u00f3n de la recuperaci\u00f3n gracias a la retroalimentaci\u00f3n de t\u00e9rminos, a pesar de que un usuario a menudo comete errores en el juicio de relevancia que perjudican su rendimiento. Descubrimos que el algoritmo de mejor rendimiento es TCFB, que se beneficia de la combinaci\u00f3n de evidencia de t\u00e9rminos observados directamente con TFB y relevancia de grupo aprendida indirectamente con CFB. Cuando reducimos la cantidad de t\u00e9rminos de presentaci\u00f3n, la retroalimentaci\u00f3n de t\u00e9rminos a\u00fan puede mantener gran parte de su aumento de rendimiento por encima de la l\u00ednea de base. Finalmente, comparamos la retroalimentaci\u00f3n de t\u00e9rminos con la retroalimentaci\u00f3n de relevancia a nivel de documento y descubrimos que el rendimiento de TCFB3C est\u00e1 a la par con este \u00faltimo con 5 documentos de retroalimentaci\u00f3n. Consideramos la retroalimentaci\u00f3n de t\u00e9rminos como una alternativa viable a la retroalimentaci\u00f3n de relevancia tradicional, especialmente cuando no hay documentos relevantes en la parte superior. Proponemos ampliar nuestro trabajo de varias maneras. Primero, queremos estudiar si el uso de varios contexts puede ayudar al usuario a identificar mejor la relevancia de los t\u00e9rminos, sin sacrificar la simplicidad y compacidad de la retroalimentaci\u00f3n de los t\u00e9rminos. En segundo lugar, actualmente todos los t\u00e9rminos se presentan al usuario en un solo lote. En su lugar, podr\u00edamos considerar la retroalimentaci\u00f3n iterativa de t\u00e9rminos, presentando primero una peque\u00f1a cantidad de t\u00e9rminos y mostrar m\u00e1s t\u00e9rminos despu\u00e9s de recibir comentarios de los usuarios o detenernos cuando la consulta refinada sea lo suficientemente buena.Los t\u00e9rminos presentados deben seleccionarse din\u00e1micamente para maximizar los beneficios del aprendizaje en cualquier momento. En tercer lugar, tenemos planes de incorporar comentarios sobre t\u00e9rminos en nuestra barra de herramientas UCAIR -LSB-20-RSB-, un complemento de Internet Explorer, para que funcione en la b\u00fasqueda web. Tambi\u00e9n estamos interesados \u200b\u200ben estudiar c\u00f3mo combinar la retroalimentaci\u00f3n de t\u00e9rminos con la retroalimentaci\u00f3n de relevancia o la retroalimentaci\u00f3n impl\u00edcita. Podr\u00edamos, por ejemplo, permitir que el usuario modifique din\u00e1micamente t\u00e9rminos en un modelo de lenguaje aprendido de documentos de comentarios.", "keyphrases": ["retroalimentaci\u00f3n de la base terminol\u00f3gica", "informar recuperar", "modelo de lenguaje", "consulta ampl\u00eda el proceso", "modelo de consulta", "interactuar b\u00fasqueda ad hoc", "recuperar realizar", "probable", "kl-diverg", "t\u00e9rmino actual"]}
{"file_name": "H-9", "text": "Aprenda de los registros de b\u00fasqueda web para organizar los resultados de la b\u00fasqueda RESUMEN La organizaci\u00f3n eficaz de los resultados de la b\u00fasqueda es fundamental para mejorar la utilidad de cualquier motor de b\u00fasqueda. La agrupaci\u00f3n de resultados de b\u00fasqueda es una forma eficaz de organizar los resultados de b\u00fasqueda, lo que permite al usuario navegar r\u00e1pidamente hacia documentos relevantes. Sin embargo, dos deficiencias de este enfoque hacen que no siempre funcione bien: -LRB- 1 -RRB- los clusters descubiertos no necesariamente corresponden a los aspectos interesantes de un tema desde la perspectiva del usuario; y -LRB- 2 -RRB- las etiquetas de cl\u00faster generadas no son lo suficientemente informativas como para permitir que un usuario identifique el cl\u00faster correcto. En este art\u00edculo, proponemos abordar estas dos deficiencias aprendiendo -LRB- 1 -RRB \"aspectos interesantes\" de un tema a partir de registros de b\u00fasqueda web y organizando los resultados de b\u00fasqueda en consecuencia; y -LRB- 2 -RRB- genera etiquetas de cl\u00faster m\u00e1s significativas utilizando palabras de consulta anteriores ingresadas por los usuarios. Evaluamos nuestro m\u00e9todo propuesto en los datos de registro de un motor de b\u00fasqueda comercial. En comparaci\u00f3n con los m\u00e9todos tradicionales de agrupaci\u00f3n de resultados de b\u00fasqueda, nuestro m\u00e9todo puede ofrecer una mejor organizaci\u00f3n de los resultados y etiquetas m\u00e1s significativas. 1. INTRODUCCI\u00d3N La utilidad de un motor de b\u00fasqueda se ve afectada por m\u00faltiples factores. Si bien el factor principal es la solidez del modelo de recuperaci\u00f3n subyacente y la funci\u00f3n de clasificaci\u00f3n, c\u00f3mo organizar y presentar los resultados de la b\u00fasqueda tambi\u00e9n es un factor muy importante que puede afectar significativamente la utilidad de un motor de b\u00fasqueda. Sin embargo, en comparaci\u00f3n con la gran cantidad de literatura sobre modelos de recuperaci\u00f3n, hay relativamente poca investigaci\u00f3n sobre c\u00f3mo mejorar la eficacia de la organizaci\u00f3n de los resultados de b\u00fasqueda. La estrategia m\u00e1s com\u00fan para presentar los resultados de la b\u00fasqueda es una lista clasificada simple. Intuitivamente, esta estrategia de presentaci\u00f3n es razonable para resultados de b\u00fasqueda homog\u00e9neos y no ambiguos; En general, funcionar\u00eda bien cuando los resultados de la b\u00fasqueda sean buenos y un usuario pueda encontrar f\u00e1cilmente muchos documentos relevantes en los resultados mejor clasificados. En estos ejemplos, una vista agrupada de los resultados de la b\u00fasqueda ser\u00eda mucho m\u00e1s \u00fatil para un usuario que una simple lista clasificada. La agrupaci\u00f3n tambi\u00e9n es \u00fatil cuando los resultados de la b\u00fasqueda son deficientes, en cuyo caso, de lo contrario, un usuario tendr\u00eda que recorrer una larga lista secuencialmente para llegar al primer documento relevante. Como estrategia alternativa principal para presentar los resultados de b\u00fasqueda, se ha estudiado relativamente extensamente la agrupaci\u00f3n de resultados de b\u00fasqueda -LSB- 9, 15, 26, 27, 28 -RSB-. La idea general en pr\u00e1cticamente todo el trabajo existente es realizar agrupaciones en un conjunto de resultados de b\u00fasqueda mejor clasificados para dividir los resultados en agrupaciones naturales, que a menudo corresponden a diferentes subtemas del tema de consulta general. Se generar\u00e1 una etiqueta para indicar de qu\u00e9 se trata cada grupo. Luego, un usuario puede ver las etiquetas para decidir qu\u00e9 grupo buscar. Sin embargo, esta estrategia de agrupaci\u00f3n tiene dos deficiencias que hacen que no siempre funcione bien: primero,Los grupos descubiertos de esta manera no corresponden necesariamente a los aspectos interesantes de un tema desde la perspectiva del usuario. Pero los grupos descubiertos por los m\u00e9todos actuales pueden dividir los resultados en \"c\u00f3digos locales\" y \"c\u00f3digos internacionales\". ''Estos grupos no ser\u00edan muy \u00fatiles para los usuarios; Incluso el mejor grupo tendr\u00eda todav\u00eda una precisi\u00f3n baja. En segundo lugar, las etiquetas de cl\u00faster generadas no son lo suficientemente informativas como para permitir al usuario identificar el cl\u00faster correcto. Hay dos razones para este problema: -LRB- 1 -RRB- Los clusters no corresponden a los intereses de un usuario, por lo que sus etiquetas no ser\u00edan muy significativas o \u00fatiles. Por ejemplo, la consulta ambigua `` jaguar '' puede significar un animal o un autom\u00f3vil. Un grupo puede etiquetarse como `` panthera onca. '' En este art\u00edculo, proponemos una estrategia diferente para dividir los resultados de b\u00fasqueda, que aborda estas dos deficiencias imponiendo una partici\u00f3n de los resultados de b\u00fasqueda orientada al usuario. Es decir, intentamos descubrir qu\u00e9 aspectos de un tema de b\u00fasqueda probablemente sean interesantes para un usuario y organizar los resultados en consecuencia. Espec\u00edficamente, proponemos hacer lo siguiente: Primero, aprenderemos \"aspectos interesantes\" de temas similares a partir de registros de b\u00fasqueda y organizaremos los resultados de la b\u00fasqueda en funci\u00f3n de estos \"aspectos interesantes\". Por ejemplo, si la consulta actual se ha producido muchas veces en los registros de b\u00fasqueda, podemos ver qu\u00e9 tipos de p\u00e1ginas vieron los usuarios en los resultados y qu\u00e9 tipo de palabras se utilizan junto con dicha consulta. En caso de que la consulta sea ambigua, como `` jaguar '', podemos esperar ver algunos grupos claros correspondientes a diferentes sentidos de `` jaguar ''. Estos aspectos pueden resultar muy \u00fatiles para organizar futuros resultados de b\u00fasqueda sobre \"coche\". En segundo lugar, generaremos etiquetas de grupo m\u00e1s significativas utilizando palabras de consulta anteriores ingresadas por los usuarios. Por tanto, pueden ser mejores etiquetas que las extra\u00eddas del contenido normal de los resultados de b\u00fasqueda. Para implementar las ideas presentadas anteriormente, nos basamos en los registros de los motores de b\u00fasqueda y creamos una colecci\u00f3n de historial que contiene las consultas anteriores y los clics asociados. Dada una nueva consulta, encontramos sus consultas pasadas relacionadas de la colecci\u00f3n de historial y aprendemos aspectos mediante la aplicaci\u00f3n del algoritmo de agrupaci\u00f3n de estrellas -LSB- 2 -RSB- a estas consultas pasadas y clics. Luego podemos organizar los resultados de la b\u00fasqueda en estos aspectos utilizando t\u00e9cnicas de categorizaci\u00f3n y etiquetar cada aspecto seg\u00fan la consulta anterior m\u00e1s representativa en el grupo de consultas. Evaluamos nuestro m\u00e9todo para la organizaci\u00f3n de resultados utilizando registros de un motor de b\u00fasqueda comercial. Comparamos nuestro m\u00e9todo con la clasificaci\u00f3n predeterminada del motor de b\u00fasqueda y la agrupaci\u00f3n tradicional de resultados de b\u00fasqueda. Los resultados muestran que nuestro m\u00e9todo es eficaz para mejorar la utilidad de b\u00fasqueda y las etiquetas generadas utilizando palabras de consulta anteriores son m\u00e1s legibles que las generadas utilizando enfoques de agrupaci\u00f3n tradicionales. El resto del documento est\u00e1 organizado de la siguiente manera.Primero revisamos el trabajo relacionado en la Secci\u00f3n 2. En la Secci\u00f3n 3, describimos los datos de registro del motor de b\u00fasqueda y nuestro procedimiento para crear una colecci\u00f3n de historial. En la Secci\u00f3n 4 presentamos nuestro enfoque en detalle. Describimos el conjunto de datos en la Secci\u00f3n 5 y los resultados experimentales se discuten en la Secci\u00f3n 6. Finalmente, concluimos nuestro art\u00edculo y discutimos el trabajo futuro en la Secci\u00f3n 7. 2. TRABAJO RELACIONADO Nuestro trabajo est\u00e1 estrechamente relacionado con el estudio de la agrupaci\u00f3n de resultados de b\u00fasqueda. En -LSB- 9, 15 -RSB-, los autores utilizaron el algoritmo Scatter/Gather para agrupar los principales documentos devueltos por un sistema de recuperaci\u00f3n de informaci\u00f3n tradicional. Sus resultados validan la hip\u00f3tesis de clusters -LSB-20-RSB- de que los documentos relevantes tienden a formar clusters. En estos art\u00edculos, los autores propusieron agrupar los resultados de un motor de b\u00fasqueda real en funci\u00f3n de los fragmentos o el contenido de los documentos devueltos. Se comparan varios algoritmos de agrupamiento y se demostr\u00f3 que el algoritmo de agrupamiento de \u00e1rboles de sufijos -LRB-STC-RRB- es el m\u00e1s eficaz. Tambi\u00e9n demostraron que utilizar fragmentos es tan eficaz como utilizar documentos completos. Sin embargo, un desaf\u00edo importante de la agrupaci\u00f3n de documentos es generar etiquetas significativas para las agrupaciones. Para superar esta dificultad, en -LSB- 28 -RSB-, se estudiaron algoritmos de aprendizaje supervisado para extraer frases significativas de los fragmentos de resultados de b\u00fasqueda y luego estas frases se utilizaron para agrupar los resultados de b\u00fasqueda. En -LSB-13-RSB-, los autores propusieron utilizar un algoritmo de agrupamiento monot\u00e9tico, en el que un documento se asigna a un grupo en funci\u00f3n de una \u00fanica caracter\u00edstica, para organizar los resultados de la b\u00fasqueda, y la caracter\u00edstica \u00fanica se utiliza para etiquetar el grupo correspondiente. . La agrupaci\u00f3n de resultados de b\u00fasqueda tambi\u00e9n ha atra\u00eddo mucha atenci\u00f3n en servicios web industriales y comerciales como Vivisimo -LSB- 22 -RSB-. Sin embargo, en todos estos trabajos, los clusters se generan \u00fanicamente en funci\u00f3n de los resultados de la b\u00fasqueda. Por lo tanto, los grupos obtenidos no reflejan necesariamente las preferencias de los usuarios y las etiquetas generadas pueden no ser informativas desde el punto de vista del usuario. Los m\u00e9todos de organizaci\u00f3n de los resultados de b\u00fasqueda basados \u200b\u200ben la categorizaci\u00f3n de text se estudian en -LSB- 6, 8 -RSB-. En este trabajo, se entrena un clasificador de text utilizando un directorio web y luego los resultados de la b\u00fasqueda se clasifican en categor\u00edas predefinidas. Los autores dise\u00f1aron y estudiaron diferentes interfaces de categor\u00edas y descubrieron que las interfaces de categor\u00edas son m\u00e1s efectivas que las interfaces de listas. Sin embargo, las categor\u00edas predefinidas suelen ser demasiado generales para reflejar los aspectos m\u00e1s detallados de una consulta. Los registros de b\u00fasqueda han sido explotados para varios prop\u00f3sitos diferentes en el pasado. Por ejemplo, agrupar consultas de b\u00fasqueda para encontrar aquellas Preguntas Frecuentes -LRB- FAQ -RRB- se estudia en -LSB- 24, 4 -RSB-. En nuestro trabajo, exploramos el historial de consultas pasadas para organizar mejor los resultados de b\u00fasqueda para consultas futuras. Utilizamos el algoritmo de agrupamiento de estrellas -LSB- 2 -RSB-, que es un enfoque basado en partici\u00f3n de gr\u00e1ficos, para aprender aspectos interesantes de los registros de b\u00fasqueda dada una nueva consulta. 7.CONCLUSIONES Y TRABAJO FUTURO En este art\u00edculo, estudiamos el problema de organizar los resultados de b\u00fasqueda de una manera orientada al usuario. Para lograr este objetivo, nos basamos en los registros de los motores de b\u00fasqueda para conocer aspectos interesantes desde la perspectiva de los usuarios. Dada una consulta, recuperamos sus consultas relacionadas del historial de consultas anteriores, aprendemos los aspectos agrupando las consultas pasadas y la informaci\u00f3n de clics asociada, y categorizamos los resultados de la b\u00fasqueda en los aspectos aprendidos. Comparamos nuestro m\u00e9todo basado en registros con el m\u00e9todo tradicional basado en cl\u00fasteres y la l\u00ednea base de clasificaci\u00f3n en los motores de b\u00fasqueda. Los experimentos muestran que nuestro m\u00e9todo basado en registros puede superar consistentemente al m\u00e9todo basado en cl\u00fasteres y mejorar con respecto a la l\u00ednea base de clasificaci\u00f3n, especialmente cuando las consultas son dif\u00edciles o los resultados de la b\u00fasqueda son diversos. Adem\u00e1s, nuestro m\u00e9todo basado en registros puede generar etiquetas de aspectos m\u00e1s significativas que las etiquetas de grupo generadas en funci\u00f3n de los resultados de b\u00fasqueda cuando agrupamos los resultados de b\u00fasqueda. Hay varias direcciones interesantes para ampliar a\u00fan m\u00e1s nuestro trabajo: Primero, aunque los resultados de nuestro experimento han mostrado claramente que la idea de aprender de los registros de b\u00fasqueda para organizar los resultados de la b\u00fasqueda es prometedora, los m\u00e9todos con los que hemos experimentado son relativamente simples. Ser\u00eda interesante explorar otros m\u00e9todos potencialmente m\u00e1s eficaces. En particular, esperamos desarrollar modelos probabil\u00edsticos para aprender aspectos y organizar resultados simult\u00e1neamente. En segundo lugar, con la forma propuesta de organizar los resultados de b\u00fasqueda, podemos esperar obtener informaci\u00f3n de retroalimentaci\u00f3n informativa de un usuario -LRB-, por ejemplo, el aspecto elegido por un usuario para ver -RRB-. Por tanto, ser\u00eda interesante estudiar c\u00f3mo mejorar a\u00fan m\u00e1s la organizaci\u00f3n de los resultados bas\u00e1ndose en dicha informaci\u00f3n de retroalimentaci\u00f3n. Finalmente, podemos combinar un registro de b\u00fasqueda general con cualquier registro de b\u00fasqueda personal para personalizar y optimizar la organizaci\u00f3n de los resultados de b\u00fasqueda para cada usuario individual.Aunque los resultados de nuestro experimento han mostrado claramente que la idea de aprender de los registros de b\u00fasqueda para organizar los resultados de la b\u00fasqueda es prometedora, los m\u00e9todos con los que hemos experimentado son relativamente simples. Ser\u00eda interesante explorar otros m\u00e9todos potencialmente m\u00e1s eficaces. En particular, esperamos desarrollar modelos probabil\u00edsticos para aprender aspectos y organizar resultados simult\u00e1neamente. En segundo lugar, con la forma propuesta de organizar los resultados de b\u00fasqueda, podemos esperar obtener informaci\u00f3n de retroalimentaci\u00f3n informativa de un usuario -LRB-, por ejemplo, el aspecto elegido por un usuario para ver -RRB-. Por tanto, ser\u00eda interesante estudiar c\u00f3mo mejorar a\u00fan m\u00e1s la organizaci\u00f3n de los resultados bas\u00e1ndose en dicha informaci\u00f3n de retroalimentaci\u00f3n. Finalmente, podemos combinar un registro de b\u00fasqueda general con cualquier registro de b\u00fasqueda personal para personalizar y optimizar la organizaci\u00f3n de los resultados de b\u00fasqueda para cada usuario individual.Aunque los resultados de nuestro experimento han mostrado claramente que la idea de aprender de los registros de b\u00fasqueda para organizar los resultados de la b\u00fasqueda es prometedora, los m\u00e9todos con los que hemos experimentado son relativamente simples. Ser\u00eda interesante explorar otros m\u00e9todos potencialmente m\u00e1s eficaces. En particular, esperamos desarrollar modelos probabil\u00edsticos para aprender aspectos y organizar resultados simult\u00e1neamente. En segundo lugar, con la forma propuesta de organizar los resultados de b\u00fasqueda, podemos esperar obtener informaci\u00f3n de retroalimentaci\u00f3n informativa de un usuario -LRB-, por ejemplo, el aspecto elegido por un usuario para ver -RRB-. Por tanto, ser\u00eda interesante estudiar c\u00f3mo mejorar a\u00fan m\u00e1s la organizaci\u00f3n de los resultados bas\u00e1ndose en dicha informaci\u00f3n de retroalimentaci\u00f3n. Finalmente, podemos combinar un registro de b\u00fasqueda general con cualquier registro de b\u00fasqueda personal para personalizar y optimizar la organizaci\u00f3n de los resultados de b\u00fasqueda para cada usuario individual.", "keyphrases": ["recuperar modelo", "funci\u00f3n de rango", "ambiguo", "vista de cl\u00faster", "significado de etiqueta de grupo", "recoger historia", "consulta pasada", "hacer clic a trav\u00e9s", "algoritmo de c\u00famulo de estrellas", "algoritmo de agrupaci\u00f3n de \u00e1rboles de sufijos", "fragmento de resultado de b\u00fasqueda", "algoritmo de grupo monothet", "pseudodocumento", "gr\u00e1fico similar de pares", "par\u00e1metro de umbral similar", "m\u00e9todo de base centroide", "coseno similar", "prototipo de centroide", "rango rec\u00edproco", "m\u00e9todo de base logar\u00edtmica", "media exacta media"]}
{"file_name": "H-5", "text": "Destilaci\u00f3n de informaci\u00f3n basada en utilidades sobre documentos secuenciados temporalmente RESUMEN Este art\u00edculo examina un nuevo enfoque para la destilaci\u00f3n de informaci\u00f3n sobre documentos ordenados temporalmente y propone un esquema de evaluaci\u00f3n novedoso para dicho marco. Combina las fortalezas y se extiende m\u00e1s all\u00e1 del filtrado adaptativo convencional, la detecci\u00f3n de novedades y la clasificaci\u00f3n de pasajes no redundantes con respecto a las necesidades de informaci\u00f3n duraderas -LRB- `tareas' con m\u00faltiples consultas -RRB-. Nuestro enfoque admite comentarios detallados de los usuarios mediante el resaltado de tramos arbitrarios de text y aprovecha dicha informaci\u00f3n para la optimizaci\u00f3n de la utilidad en entornos adaptativos. Para nuestros experimentos, definimos tareas hipot\u00e9ticas basadas en eventos noticiosos en el corpus TDT4, con m\u00faltiples consultas por tarea. Se generaron claves de respuesta -LRB- nuggets -RRB- para cada consulta y se utiliz\u00f3 un procedimiento semiautom\u00e1tico para adquirir reglas que permitan comparar autom\u00e1ticamente los nuggets con las respuestas del sistema. Tambi\u00e9n proponemos una extensi\u00f3n de la m\u00e9trica NDCG para evaluar la utilidad de pasajes clasificados como una combinaci\u00f3n de relevancia y novedad. Nuestros resultados muestran mejoras alentadoras en la utilidad utilizando el nuevo enfoque, en comparaci\u00f3n con los sistemas b\u00e1sicos sin aprendizaje incremental o componentes de detecci\u00f3n de novedades. 1. INTRODUCCI\u00d3N El seguimiento de informaci\u00f3n nueva y relevante a partir de flujos de datos temporales para usuarios con necesidades duraderas ha sido un tema de investigaci\u00f3n desafiante en la recuperaci\u00f3n de informaci\u00f3n. El filtrado adaptativo -LRB- AF -RRB- es una de esas tareas de predicci\u00f3n en l\u00ednea de la relevancia de cada nuevo documento con respecto a temas predefinidos. Basado en la consulta inicial y algunos ejemplos positivos -LRB- si est\u00e1n disponibles -RRB-, un sistema AF mantiene un perfil para cada tema de inter\u00e9s y lo actualiza constantemente en funci\u00f3n de los comentarios del usuario. A pesar de los logros sustanciales en las recientes investigaciones sobre filtrado adaptativo, siguen sin resolverse problemas importantes con respecto a c\u00f3mo aprovechar los comentarios de los usuarios de manera efectiva y eficiente. Espec\u00edficamente, los siguientes problemas pueden limitar seriamente la verdadera utilidad de los sistemas AF en aplicaciones del mundo real: configuraci\u00f3n de filtrado adaptativo: \u00e9l o ella reacciona al sistema s\u00f3lo cuando el sistema toma una decisi\u00f3n \"s\u00ed\" en un documento, confirmando o rechazando esa decisi\u00f3n. Una alternativa m\u00e1s \"activa\" ser\u00eda permitir al usuario realizar m\u00faltiples consultas sobre un tema, revisar una lista clasificada de documentos candidatos -LRB- o pasajes -RRB- por consulta, y proporcionar comentarios sobre la lista clasificada, refinando as\u00ed su informaci\u00f3n. necesidad y solicitar listas clasificadas actualizadas. Esta \u00faltima forma de interacci\u00f3n del usuario ha sido muy eficaz en la recuperaci\u00f3n est\u00e1ndar para consultas ad hoc. C\u00f3mo implementar una estrategia de este tipo para las necesidades de informaci\u00f3n duraderas en entornos de FA es una cuesti\u00f3n abierta a la investigaci\u00f3n. 2. Sin embargo, un usuario real puede estar dispuesto a proporcionar comentarios m\u00e1s informativos y detallados resaltando algunos fragmentos de text en un documento recuperado como relevantes, en lugar de etiquetar todo el documento como relevante.Aprovechar de manera efectiva esta retroalimentaci\u00f3n tan detallada podr\u00eda mejorar sustancialmente la calidad de un sistema AF. Para ello, debemos permitir el aprendizaje supervisado a partir de fragmentos de text etiquetados de duraci\u00f3n arbitraria en lugar de permitir simplemente documentos etiquetados. 3. Los documentos seleccionados por el sistema suelen ser muy redundantes. Un sistema AF convencional seleccionar\u00eda todas estas noticias redundantes para recibir comentarios de los usuarios, lo que har\u00eda perder el tiempo al usuario y ofrecer\u00eda poca ganancia. Claramente, las t\u00e9cnicas para la detecci\u00f3n de novedades pueden ayudar en principio -LSB- 25, 2, 22 -RSB- a mejorar la utilidad de los sistemas AF. Sin embargo, la efectividad de tales t\u00e9cnicas a nivel de pasaje para detectar novedades con respecto a la retroalimentaci\u00f3n -LRB- fina -RRB- del usuario y para detectar redundancia en listas clasificadas a\u00fan debe evaluarse utilizando una medida de utilidad que imite las necesidades de un usuario real. Al nuevo proceso lo llamamos destilaci\u00f3n de informaci\u00f3n basada en utilidades. Tenga en cuenta que los corpus de referencia convencionales para las evaluaciones de FA, que tienen juicios de relevancia a nivel de documento y no definen tareas con m\u00faltiples consultas, son insuficientes para evaluar el nuevo enfoque. Por lo tanto, ampliamos un corpus de referencia (la colecci\u00f3n TDT4 de noticias y transmisiones de televisi\u00f3n) con definiciones de tareas, m\u00faltiples consultas por tarea y claves de respuestas por consulta. Hemos llevado a cabo nuestros experimentos en este corpus TDT4 extendido y hemos puesto a disposici\u00f3n p\u00fablica los datos generados adicionalmente para futuras evaluaciones comparativas 1. Para evaluar autom\u00e1ticamente los tramos de text arbitrarios devueltos por el sistema utilizando nuestras claves de respuestas, desarrollamos a\u00fan m\u00e1s un esquema de evaluaci\u00f3n con semi- Procedimiento autom\u00e1tico para adquirir reglas que puedan hacer coincidir las pepitas con las respuestas del sistema. Adem\u00e1s, proponemos una extensi\u00f3n de NDCG -LRB- Ganancia acumulada descontada normalizada -RRB- -LSB- 9 -RSB- para evaluar la utilidad de pasajes clasificados en funci\u00f3n tanto de la relevancia como de la novedad. La secci\u00f3n 2 describe el proceso de destilaci\u00f3n de informaci\u00f3n con un ejemplo concreto. La Secci\u00f3n 3 describe los n\u00facleos t\u00e9cnicos de nuestro sistema llamado CAF \u00b4 E - CMU Adaptive Filtering Engine. La secci\u00f3n 4 analiza cuestiones relacionadas con la metodolog\u00eda de evaluaci\u00f3n y propone un nuevo esquema. La secci\u00f3n 5 describe el corpus TDT4 ampliado. La secci\u00f3n 6 presenta nuestros experimentos y resultados. La secci\u00f3n 7 concluye el estudio y ofrece perspectivas futuras. 7. COMENTARIOS FINALES Este art\u00edculo presenta la primera investigaci\u00f3n sobre la destilaci\u00f3n de informaci\u00f3n basada en utilidades con un sistema que aprende las necesidades de informaci\u00f3n duraderas a partir de comentarios detallados de los usuarios a lo largo de una secuencia de pasajes clasificados. Nuestro sistema, llamado CAF \u00b4 E, combina filtrado adaptativo, detecci\u00f3n de novedades y clasificaci\u00f3n de pasajes antiredundante en un marco unificado para la optimizaci\u00f3n de servicios p\u00fablicos. Desarrollamos un nuevo esquema para evaluaci\u00f3n y retroalimentaci\u00f3n automatizadas basado en un procedimiento semiautom\u00e1tico para adquirir reglas que permiten comparar autom\u00e1ticamente pepitas con las respuestas del sistema.Tambi\u00e9n propusimos una extensi\u00f3n de la m\u00e9trica NDCG para evaluar la utilidad de pasajes clasificados como una combinaci\u00f3n ponderada de relevancia y novedad. Nuestros experimentos en el corpus de referencia TDT4 recientemente anotado muestran una mejora alentadora de la utilidad sobre Indri, y tambi\u00e9n sobre nuestro propio sistema con el aprendizaje incremental y la detecci\u00f3n de novedades desactivados.", "keyphrases": ["base de utilidad informar destilar", "documento de orden temporal", "rango de paso", "adaptar filtro", "recuperaci\u00f3n ad hoc", "detectar novedades", "nueva metodolog\u00eda de evaluaci\u00f3n", "respuesta kei", "regla de coincidencia de pepitas", "marco unifi", "m\u00e9trica ndcg"]}
{"file_name": "C-8", "text": "Context de operaci\u00f3n y transformaci\u00f3n operativa basada en context RESUMEN La transformaci\u00f3n operativa -LRB- OT -RRB- es una t\u00e9cnica para mantener la coherencia y deshacer grupos, y se est\u00e1 aplicando a un n\u00famero cada vez mayor de aplicaciones colaborativas. La base te\u00f3rica de la TO es crucial para determinar su capacidad para resolver problemas nuevos y existentes, as\u00ed como la calidad de esas soluciones. La teor\u00eda de la causalidad ha sido la base de todos los sistemas de TO anteriores, pero es inadecuada para captar los requisitos esenciales de correcci\u00f3n. Investigaciones anteriores hab\u00edan inventado varios parches para solucionar este problema, lo que dio como resultado algoritmos OT cada vez m\u00e1s intrincados y complicados. Despu\u00e9s de haber dise\u00f1ado, implementado y experimentado con una serie de algoritmos de OT, reflexionamos sobre lo aprendido y nos propusimos desarrollar un nuevo marco te\u00f3rico para comprender y resolver mejor los problemas de OT, reducir su complejidad y respaldar su evoluci\u00f3n continua. En este art\u00edculo, informamos los principales resultados de este esfuerzo: la teor\u00eda del context de operaci\u00f3n y el algoritmo COT -LRB- OT basado en context -RRB-. El algoritmo COT es capaz de soportar tanto hacer como deshacer cualquier operaci\u00f3n en cualquier momento, sin requerir funciones de transformaci\u00f3n para preservar la propiedad de reversibilidad, la propiedad de convergencia 2 y las propiedades inversas 2 y 3. El algoritmo COT no solo es m\u00e1s simple y m\u00e1s eficiente que el control OT anterior. algoritmos, pero tambi\u00e9n simplifica el dise\u00f1o de funciones de transformaci\u00f3n. Implementamos el algoritmo COT en un motor de colaboraci\u00f3n gen\u00e9rico y lo utilizamos para admitir una variedad de aplicaciones colaborativas novedosas. 1. INTRODUCCI\u00d3N La transformaci\u00f3n operativa -LRB- OT -RRB- se invent\u00f3 originalmente para mantener la coherencia en los editores de grupos de text plano -LSB- 4 -RSB-. Para respaldar de manera efectiva y eficiente las aplicaciones nuevas y existentes, debemos continuar mejorando la capacidad y la calidad de la OT para resolver problemas nuevos y antiguos. La solidez de la base te\u00f3rica de la TO es crucial en este proceso. Sin embargo, la teor\u00eda de la causalidad es inadecuada para captar las condiciones esenciales del TO para una transformaci\u00f3n correcta. La limitaci\u00f3n de la teor\u00eda de la causalidad hab\u00eda causado problemas de correcci\u00f3n desde el comienzo mismo de la AT. El algoritmo dOPT fue el primer algoritmo OT y se bas\u00f3 \u00fanicamente en las relaciones de concurrencia entre operaciones -LSB- 4 -RSB-: un par de operaciones son transformables siempre que sean concurrentes. Sin embargo, investigaciones posteriores descubrieron que la condici\u00f3n de concurrencia por s\u00ed sola no es suficiente para garantizar la correcci\u00f3n de la transformaci\u00f3n. Otra condici\u00f3n es que las dos operaciones simult\u00e1neas deben definirse en el mismo estado del documento. Este enigma se resolvi\u00f3 de varias maneras, pero la teor\u00eda de la causalidad, as\u00ed como sus limitaciones, fueron heredadas por todos los algoritmos OT de seguimiento. La limitaci\u00f3n de la teor\u00eda de la causalidad se volvi\u00f3 a\u00fan m\u00e1s prominente cuando se aplic\u00f3 la TO para resolver el problema de deshacer en los editores de grupo.El concepto de causalidad no es adecuado para captar las relaciones entre una operaci\u00f3n inversa -LRB- como interpretaci\u00f3n de un comando de deshacer de nivel meta -RRB- y otras operaciones de edici\u00f3n normales. De hecho, la relaci\u00f3n de causalidad no est\u00e1 definida para operaciones inversas -LRB- ver Secci\u00f3n 2 -RRB-. Se inventaron varios parches para solucionar este problema, lo que dio como resultado algoritmos OT m\u00e1s complejos y complejos -LSB- 18, 21 -RSB-. apoyando su continua evoluci\u00f3n. En este art\u00edculo, informamos los principales resultados de este esfuerzo: la teor\u00eda del context de operaci\u00f3n y el algoritmo COT -LRB- OT basado en context -RRB-. Primero, definimos dependencia causal/independencia y describimos brevemente sus limitaciones en la Secci\u00f3n 2. Luego, presentamos los elementos clave de la teor\u00eda del context de operaci\u00f3n, incluida la definici\u00f3n de context de operaci\u00f3n, relaciones de dependencia/independencia del context, basadas en el context. condiciones y vectores de context en la Secci\u00f3n 3. En la Secci\u00f3n 4, presentamos el algoritmo COT b\u00e1sico para respaldar el mantenimiento de la coherencia -LRB- do -RRB- y deshacer grupo bajo el supuesto de que las funciones de transformaci\u00f3n subyacentes pueden preservar algunas propiedades de transformaci\u00f3n importantes. Luego, estas propiedades de transformaci\u00f3n y sus condiciones previas se analizan en la Secci\u00f3n 5. Las soluciones COT a estas propiedades de transformaci\u00f3n se presentan en la Secci\u00f3n 6. La comparaci\u00f3n del trabajo COT con el trabajo OT anterior, las cuestiones de correcci\u00f3n de OT y el trabajo futuro se analizan en la Secci\u00f3n 7. Finalmente, las principales contribuciones de este trabajo se resumen en la Secci\u00f3n 8. 8. CONCLUSIONES Hemos aportado la teor\u00eda del context de operaci\u00f3n y el algoritmo COT -LRB- OT basado en context -RRB-. La teor\u00eda del context de operaci\u00f3n es capaz de capturar relaciones y condiciones esenciales para todo tipo de operaci\u00f3n en un sistema OT; Proporciona una nueva base para comprender y resolver mejor los problemas de OT. El algoritmo COT proporciona soluciones uniformes tanto para el mantenimiento de la coherencia como para los problemas de deshacer; es m\u00e1s simple y eficiente que los algoritmos de control OT anteriores con capacidades similares; y simplifica significativamente el dise\u00f1o de funciones de transformaci\u00f3n. El algoritmo COT se ha implementado en un motor de colaboraci\u00f3n gen\u00e9rico y se utiliza para admitir una variedad de aplicaciones colaborativas novedosas -LSB- 24 -RSB-. Las aplicaciones del mundo real brindan oportunidades y desaf\u00edos interesantes para la futura investigaci\u00f3n de OT. La teor\u00eda del context de operaci\u00f3n y el algoritmo COT servir\u00e1n como nuevas bases para abordar los desaf\u00edos t\u00e9cnicos en las aplicaciones OT existentes y emergentes.Presentamos los principales resultados de este esfuerzo: la teor\u00eda del context de operaci\u00f3n y el algoritmo COT -LRB- OT basado en context -RRB-. Primero, definimos dependencia causal/independencia y describimos brevemente sus limitaciones en la Secci\u00f3n 2. Luego, presentamos los elementos clave de la teor\u00eda del context de operaci\u00f3n, incluida la definici\u00f3n de context de operaci\u00f3n, relaciones de dependencia/independencia del context, basadas en el context. condiciones y vectores de context en la Secci\u00f3n 3. En la Secci\u00f3n 4, presentamos el algoritmo COT b\u00e1sico para respaldar el mantenimiento de la coherencia -LRB- do -RRB- y deshacer grupo bajo el supuesto de que las funciones de transformaci\u00f3n subyacentes pueden preservar algunas propiedades de transformaci\u00f3n importantes. Luego, estas propiedades de transformaci\u00f3n y sus condiciones previas se analizan en la Secci\u00f3n 5. Las soluciones COT a estas propiedades de transformaci\u00f3n se presentan en la Secci\u00f3n 6. La comparaci\u00f3n del trabajo COT con el trabajo OT anterior, las cuestiones de correcci\u00f3n de OT y el trabajo futuro se analizan en la Secci\u00f3n 7. Finalmente, las principales contribuciones de este trabajo se resumen en la Secci\u00f3n 8. 8. CONCLUSIONES Hemos aportado la teor\u00eda del context de operaci\u00f3n y el algoritmo COT -LRB- OT basado en context -RRB-. La teor\u00eda del context de operaci\u00f3n es capaz de capturar relaciones y condiciones esenciales para todo tipo de operaci\u00f3n en un sistema OT; Proporciona una nueva base para comprender y resolver mejor los problemas de OT. El algoritmo COT proporciona soluciones uniformes tanto para el mantenimiento de la coherencia como para los problemas de deshacer; es m\u00e1s simple y eficiente que los algoritmos de control OT anteriores con capacidades similares; y simplifica significativamente el dise\u00f1o de funciones de transformaci\u00f3n. El algoritmo COT se ha implementado en un motor de colaboraci\u00f3n gen\u00e9rico y se utiliza para admitir una variedad de aplicaciones colaborativas novedosas -LSB- 24 -RSB-. Las aplicaciones del mundo real brindan oportunidades y desaf\u00edos interesantes para la futura investigaci\u00f3n de OT. La teor\u00eda del context de operaci\u00f3n y el algoritmo COT servir\u00e1n como nuevas bases para abordar los desaf\u00edos t\u00e9cnicos en las aplicaciones OT existentes y emergentes.Presentamos los principales resultados de este esfuerzo: la teor\u00eda del context de operaci\u00f3n y el algoritmo COT -LRB- OT basado en context -RRB-. Primero, definimos dependencia causal/independencia y describimos brevemente sus limitaciones en la Secci\u00f3n 2. Luego, presentamos los elementos clave de la teor\u00eda del context de operaci\u00f3n, incluida la definici\u00f3n de context de operaci\u00f3n, relaciones de dependencia/independencia del context, basadas en el context. condiciones y vectores de context en la Secci\u00f3n 3. En la Secci\u00f3n 4, presentamos el algoritmo COT b\u00e1sico para respaldar el mantenimiento de la coherencia -LRB- do -RRB- y deshacer grupo bajo el supuesto de que las funciones de transformaci\u00f3n subyacentes pueden preservar algunas propiedades de transformaci\u00f3n importantes. Luego, estas propiedades de transformaci\u00f3n y sus condiciones previas se analizan en la Secci\u00f3n 5. Las soluciones COT a estas propiedades de transformaci\u00f3n se presentan en la Secci\u00f3n 6. La comparaci\u00f3n del trabajo COT con el trabajo OT anterior, las cuestiones de correcci\u00f3n de OT y el trabajo futuro se analizan en la Secci\u00f3n 7. Finalmente, las principales contribuciones de este trabajo se resumen en la Secci\u00f3n 8. 8. CONCLUSIONES Hemos aportado la teor\u00eda del context de operaci\u00f3n y el algoritmo COT -LRB- OT basado en context -RRB-. La teor\u00eda del context de operaci\u00f3n es capaz de capturar relaciones y condiciones esenciales para todo tipo de operaci\u00f3n en un sistema OT; Proporciona una nueva base para comprender y resolver mejor los problemas de OT. El algoritmo COT proporciona soluciones uniformes tanto para el mantenimiento de la coherencia como para los problemas de deshacer; es m\u00e1s simple y eficiente que los algoritmos de control OT anteriores con capacidades similares; y simplifica significativamente el dise\u00f1o de funciones de transformaci\u00f3n. El algoritmo COT se ha implementado en un motor de colaboraci\u00f3n gen\u00e9rico y se utiliza para admitir una variedad de aplicaciones colaborativas novedosas -LSB- 24 -RSB-. Las aplicaciones del mundo real brindan oportunidades y desaf\u00edos interesantes para la futura investigaci\u00f3n de OT. La teor\u00eda del context de operaci\u00f3n y el algoritmo COT servir\u00e1n como nuevas bases para abordar los desaf\u00edos t\u00e9cnicos en las aplicaciones OT existentes y emergentes.y el trabajo futuro se discute en la Secci\u00f3n 7. Finalmente, las principales contribuciones de este trabajo se resumen en la Secci\u00f3n 8. 8. CONCLUSIONES Hemos contribuido con la teor\u00eda del context de operaci\u00f3n y el algoritmo COT -LRB- OT basado en context -RRB-. La teor\u00eda del context de operaci\u00f3n es capaz de capturar relaciones y condiciones esenciales para todo tipo de operaci\u00f3n en un sistema OT; Proporciona una nueva base para comprender y resolver mejor los problemas de OT. El algoritmo COT proporciona soluciones uniformes tanto para el mantenimiento de la coherencia como para los problemas de deshacer; es m\u00e1s simple y eficiente que los algoritmos de control OT anteriores con capacidades similares; y simplifica significativamente el dise\u00f1o de funciones de transformaci\u00f3n. El algoritmo COT se ha implementado en un motor de colaboraci\u00f3n gen\u00e9rico y se utiliza para admitir una variedad de aplicaciones colaborativas novedosas -LSB- 24 -RSB-. Las aplicaciones del mundo real brindan oportunidades y desaf\u00edos interesantes para la futura investigaci\u00f3n de OT. La teor\u00eda del context de operaci\u00f3n y el algoritmo COT servir\u00e1n como nuevas bases para abordar los desaf\u00edos t\u00e9cnicos en las aplicaciones OT existentes y emergentes.y el trabajo futuro se discute en la Secci\u00f3n 7. Finalmente, las principales contribuciones de este trabajo se resumen en la Secci\u00f3n 8. 8. CONCLUSIONES Hemos contribuido con la teor\u00eda del context de operaci\u00f3n y el algoritmo COT -LRB- OT basado en context -RRB-. La teor\u00eda del context de operaci\u00f3n es capaz de capturar relaciones y condiciones esenciales para todo tipo de operaci\u00f3n en un sistema OT; Proporciona una nueva base para comprender y resolver mejor los problemas de OT. El algoritmo COT proporciona soluciones uniformes tanto para el mantenimiento de la coherencia como para los problemas de deshacer; es m\u00e1s simple y eficiente que los algoritmos de control OT anteriores con capacidades similares; y simplifica significativamente el dise\u00f1o de funciones de transformaci\u00f3n. El algoritmo COT se ha implementado en un motor de colaboraci\u00f3n gen\u00e9rico y se utiliza para admitir una variedad de aplicaciones colaborativas novedosas -LSB- 24 -RSB-. Las aplicaciones del mundo real brindan oportunidades y desaf\u00edos interesantes para la futura investigaci\u00f3n de OT. La teor\u00eda del context de operaci\u00f3n y el algoritmo COT servir\u00e1n como nuevas bases para abordar los desaf\u00edos t\u00e9cnicos en las aplicaciones OT existentes y emergentes.", "keyphrases": ["transformaci\u00f3n de \u00f3pera", "cuna", "base de context ot", "dependiente causal", "concurrir condici\u00f3n", "concurrir relacionar", "operaci\u00f3n inversa", "estado del documento", "\u00f3pera de origen", "transformar \u00f3pera", "grupo inverso", "vector representa del context de la \u00f3pera", "buffer hist\u00f3rico", "transformaci\u00f3n exclusiva"]}
{"file_name": "J-4", "text": "An\u00e1lisis de ingresos de una familia de reglas de clasificaci\u00f3n para subastas de palabras clave RESUMEN Las subastas de palabras clave se encuentran en el centro de los modelos de negocio de los principales motores de b\u00fasqueda actuales. Los anunciantes pujan por la ubicaci\u00f3n junto a los resultados de b\u00fasqueda y se les cobra por los clics en sus anuncios. Los anunciantes normalmente se clasifican seg\u00fan una puntuaci\u00f3n que tiene en cuenta sus ofertas y sus posibles tasas de clics. Consideramos una familia de reglas de clasificaci\u00f3n que contiene aquellas que normalmente se utilizan para modelar Yahoo! y los dise\u00f1os de subastas de Google como casos especiales. Encontramos que, en general, ninguno de estos es necesariamente \u00f3ptimo en t\u00e9rminos de ingresos en equilibrio, y que la elecci\u00f3n de la regla de clasificaci\u00f3n puede guiarse considerando la correlaci\u00f3n entre los valores de los postores y las tasas de clics. Proponemos un enfoque simple para determinar una regla de clasificaci\u00f3n \u00f3ptima para los ingresos dentro de nuestra familia, teniendo en cuenta los efectos sobre la satisfacci\u00f3n del anunciante y la experiencia del usuario. Ilustramos el enfoque utilizando simulaciones de Monte-Carlo basadas en distribuciones adaptadas a Yahoo! Datos de oferta y tasa de clics para una palabra clave de gran volumen. 1. INTRODUCCI\u00d3N Los principales motores de b\u00fasqueda como Google, Yahoo! y MSN venden anuncios subastando espacio en las p\u00e1ginas de resultados de b\u00fasqueda de palabras clave. Por ejemplo, cuando un usuario busca en la web * Este trabajo se realiz\u00f3 mientras el autor estaba en Yahoo! Investigaci\u00f3n. ``iPod'', los anunciantes que m\u00e1s pagan -LRB- por ejemplo, Apple o Best Buy -RRB- para esa palabra clave pueden aparecer en una secci\u00f3n separada ``patrocinada'' de la p\u00e1gina de arriba o a la derecha de los resultados algor\u00edtmicos. Generalmente, los anuncios que aparecen en una posici\u00f3n m\u00e1s alta de la p\u00e1gina atraen m\u00e1s atenci\u00f3n y m\u00e1s clics por parte de los usuarios. Por lo tanto, en igualdad de condiciones, los anunciantes prefieren posiciones m\u00e1s altas que posiciones m\u00e1s bajas. Los anunciantes pujan por la ubicaci\u00f3n en la p\u00e1gina en un formato de subasta en el que cuanto mayor sea su oferta, m\u00e1s probabilidades hay de que su anuncio aparezca encima de otros anuncios de la p\u00e1gina. Por convenci\u00f3n, los anunciantes de b\u00fasqueda patrocinados generalmente pujan y pagan por clic, lo que significa que pagan s\u00f3lo cuando un usuario hace clic en su anuncio y no pagan si su anuncio se muestra pero no se hace clic en \u00e9l. Overture Services, anteriormente GoTo.com y ahora propiedad de Yahoo! Inc., se le atribuye ser pionera en publicidad de b\u00fasqueda patrocinada. El \u00e9xito de Overture impuls\u00f3 a varias empresas a adoptar modelos de negocio similares, sobre todo Google, el motor de b\u00fasqueda web l\u00edder en la actualidad. MSN de Microsoft, anteriormente afiliado de Overture, ahora opera su propio mercado de subastas de palabras clave. El motor de b\u00fasqueda eval\u00faa las ofertas de los anunciantes y asigna las posiciones en la p\u00e1gina en consecuencia. Tenga en cuenta que, aunque las ofertas se expresan como pagos por clic, el motor de b\u00fasqueda no puede asignar clics directamente, sino que asigna impresiones o ubicaciones en la pantalla. Los clics se relacionan s\u00f3lo de manera estoc\u00e1stica con las impresiones. Hasta hace poco, Yahoo! clasific\u00f3 a los postores en orden decreciente de los valores por clic declarados por los anunciantes,mientras que Google clasifica en orden decreciente de valores por impresi\u00f3n declarados por los anunciantes. Nos referimos a estas reglas como \"clasificaci\u00f3n por oferta\" y \"clasificaci\u00f3n por ingresos\", respectivamente. ' Analizamos una familia de reglas de ranking que contiene Yahoo! y los modelos de Google como casos especiales. Consideramos rango ` Estos son t\u00e9rminos de la industria. Veremos, sin embargo, que la clasificaci\u00f3n por ingresos no es necesariamente \u00f3ptima en t\u00e9rminos de ingresos. reglas donde los postores se clasifican en orden decreciente de puntuaci\u00f3n eqb, donde e denota la tasa de clics de un anunciante -LRB- normalizada para la posici\u00f3n -RRB- yb su oferta. Observe que q = 0 corresponde a Yahoo! La regla de clasificaci\u00f3n por oferta y q = 1 corresponde a la regla de clasificaci\u00f3n por ingresos de Google. Nuestra premisa es que los postores est\u00e1n jugando un equilibrio sim\u00e9trico, tal como lo definen Edelman, Ostrovsky y Schwarz -LSB- 3 -RSB- y Varian -LSB- 11 -RSB-. Mostramos mediante simulaci\u00f3n que si bien q = 1 produce una asignaci\u00f3n eficiente, ajustes de q considerablemente menores que 1 pueden generar ingresos superiores en equilibrio bajo ciertas condiciones. El par\u00e1metro clave es la correlaci\u00f3n entre el valor del anunciante y la tasa de clics. Si esta correlaci\u00f3n es fuertemente positiva, entonces los q m\u00e1s peque\u00f1os son \u00f3ptimos en t\u00e9rminos de ingresos. Nuestras simulaciones se basan en distribuciones ajustadas a datos de Yahoo! subastas de palabras clave. Proponemos que los motores de b\u00fasqueda establezcan umbrales de p\u00e9rdida aceptable en la satisfacci\u00f3n del anunciante y la experiencia del usuario, y luego elijan el q \u00f3ptimo de ingresos consistente con estas restricciones. En la Secci\u00f3n 2 presentamos un modelo formal de subastas de palabras clave y establecemos sus propiedades de equilibrio en la Secci\u00f3n 3. En la Secci\u00f3n 4 observamos que otorgar cr\u00e9ditos a los agentes que ofertan puede tener el mismo efecto que ajustar expl\u00edcitamente la regla de clasificaci\u00f3n. En la Secci\u00f3n 5 damos una formulaci\u00f3n general del problema de dise\u00f1o de subasta de palabras clave \u00f3ptimas como un problema de optimizaci\u00f3n, de manera an\u00e1loga a la configuraci\u00f3n de subasta de un solo art\u00edculo. Luego, brindamos informaci\u00f3n te\u00f3rica sobre c\u00f3mo el ajuste q puede mejorar los ingresos y por qu\u00e9 la correlaci\u00f3n entre los valores de los postores y las tasas de clics es relevante. En la Secci\u00f3n 6 consideramos el efecto de q sobre la satisfacci\u00f3n del anunciante y la experiencia del usuario. En la Secci\u00f3n 7 describimos nuestras simulaciones e interpretamos sus resultados. Trabajo relacionado. Ambos art\u00edculos definen de forma independiente un refinamiento atractivo del equilibrio de Nash para subastas de palabras clave y analizan sus propiedades de equilibrio. Llamaron a este refinamiento \"equilibrio local libre de envidia\" y \"equilibrio sim\u00e9trico\", respectivamente. Varian tambi\u00e9n proporciona alg\u00fan an\u00e1lisis emp\u00edrico. El modelo general de subastas de palabras clave utilizado aqu\u00ed, donde los postores se clasifican seg\u00fan un peso multiplicado por su oferta, fue introducido por Aggarwal, Goel y Motwani -LSB- 1 -RSB-. Ese art\u00edculo tambi\u00e9n establece una conexi\u00f3n entre los ingresos de las subastas de palabras clave en entornos de informaci\u00f3n incompleta con los ingresos en equilibrio sim\u00e9trico.Iyengar y Kumar -LSB- 5 -RSB- estudian el problema de dise\u00f1o de subasta de palabras clave \u00f3ptimas en un entorno de informaci\u00f3n incompleta y tambi\u00e9n establecen la conexi\u00f3n con el equilibrio sim\u00e9trico. Hacemos uso de esta conexi\u00f3n al formular el problema de dise\u00f1o de subasta \u00f3ptimo en nuestro entorno. Fueron los primeros en darse cuenta de que la correlaci\u00f3n entre los valores de los postores y las tasas de clics deber\u00eda ser un par\u00e1metro clave que afecte el rendimiento de los ingresos de varios mecanismos de clasificaci\u00f3n. Para simplificar, suponen que los postores ofertan sus valores reales, por lo que su modelo es muy diferente del nuestro y, en consecuencia, tambi\u00e9n lo son sus hallazgos. Seg\u00fan sus simulaciones, la clasificaci\u00f3n por ingresos siempre -LRB- domina d\u00e9bilmente la clasificaci\u00f3n por oferta en t\u00e9rminos de ingresos, mientras que nuestros resultados sugieren que la clasificaci\u00f3n por oferta puede funcionar mucho mejor para las correlaciones negativas. Lahaie -LSB- 8 -RSB- ofrece un ejemplo que sugiere que la clasificaci\u00f3n por oferta deber\u00eda generar m\u00e1s ingresos cuando los valores y las tasas de clics est\u00e1n correlacionados positivamente, mientras que la clasificaci\u00f3n por ingresos deber\u00eda funcionar mejor cuando la correlaci\u00f3n es negativa. En este trabajo hacemos un estudio m\u00e1s profundo de esta conjetura. 8. CONCLUSIONES En este trabajo analizamos las propiedades de ingresos de una familia de reglas de clasificaci\u00f3n que contiene Yahoo! y los modelos de Google como casos especiales. En la pr\u00e1ctica, deber\u00eda ser muy sencillo moverse entre reglas dentro de la familia: esto implica simplemente cambiar el exponente q aplicado a los efectos del anunciante. Tambi\u00e9n demostramos que, en principio, se podr\u00eda obtener el mismo efecto utilizando cr\u00e9ditos de licitaci\u00f3n. A pesar de la simplicidad del cambio de reglas, las simulaciones revelaron que ajustar q adecuadamente puede mejorar significativamente los ingresos. En las simulaciones, las mejoras en los ingresos fueron mayores que las que se podr\u00edan obtener utilizando precios de reserva. Por otro lado, demostramos que la satisfacci\u00f3n del anunciante y la experiencia del usuario podr\u00edan verse afectadas si q se hace demasiado peque\u00f1o. Ser\u00eda interesante realizar este an\u00e1lisis para una variedad de palabras clave, para ver si la configuraci\u00f3n \u00f3ptima de q es siempre tan sensible al nivel de correlaci\u00f3n. Si es as\u00ed, entonces simplemente usar clasificaci\u00f3n por oferta cuando hay una correlaci\u00f3n positiva y clasificaci\u00f3n por ingresos cuando hay una correlaci\u00f3n negativa podr\u00eda ser bueno para una primera aproximaci\u00f3n y ya mejorar los ingresos. Tambi\u00e9n ser\u00eda interesante comparar los efectos del ajuste de q frente al precio de reserva para palabras clave que tienen pocos postores. En principio, el ingreso m\u00ednimo en el equilibrio de Nash se puede encontrar mediante programaci\u00f3n lineal. Sin embargo, pueden surgir muchas asignaciones en el equilibrio de Nash y es necesario resolver un programa lineal para cada una de ellas. Todav\u00eda no existe una forma eficiente de enumerar todas las posibles asignaciones de Nash, por lo que actualmente no es factible encontrar el ingreso m\u00ednimo. Si este problema pudiera resolverse, podr\u00edamos ejecutar simulaciones para el equilibrio de Nash en lugar del equilibrio sim\u00e9trico, para ver si nuestros conocimientos son s\u00f3lidos ante la elecci\u00f3n del concepto de soluci\u00f3n. Podr\u00edan resultar pertinentes clases m\u00e1s amplias de reglas de clasificaci\u00f3n. Por ejemplo,es posible introducir descuentos ds y clasificar seg\u00fan wsbs \u2212 ds ; el an\u00e1lisis de equilibrio tambi\u00e9n se generaliza a este caso. Con esta clase m\u00e1s grande, la puntuaci\u00f3n virtual puede ser igual a la puntuaci\u00f3n, por ejemplo, en el caso de una distribuci\u00f3n marginal uniforme entre valores. Figura 4: Ingresos, eficiencia y relevancia para diferentes puntajes de reserva r, con correlaci\u00f3n de Spearman de 0,4 y q = 1.", "keyphrases": ["ingresos", "subasta de palabras clave", "rango de ingresos \u00f3ptimos", "regla de rango", "motor de b\u00fasqueda", "publicidad", "b\u00fasqueda de patrocinadores", "clasificaci\u00f3n por oferta", "rango por ingresos", "ganancia", "ingresos publicitarios", "palabra clave de b\u00fasqueda de precios", "problema de dise\u00f1o de subasta \u00f3ptimo"]}
{"file_name": "C-31", "text": "Apocrita: un sistema distribuido de intercambio de archivos entre pares para intranets RESUMEN Muchas organizaciones deben crear documentos para diversos fines, y es posible que todos los miembros de la organizaci\u00f3n deban poder acceder a dichos documentos. Este acceso puede ser necesario para editar o simplemente ver un documento. En algunos casos estos documentos se comparten entre autores, v\u00eda correo electr\u00f3nico, para ser editados. Esto puede provocar f\u00e1cilmente que se env\u00ede una versi\u00f3n incorrecta o que se creen conflictos entre varios usuarios que intentan realizar modificaciones en un documento. Incluso puede haber varios documentos diferentes en proceso de edici\u00f3n. Es posible que se le solicite al usuario que busque un documento en particular; algunas herramientas de b\u00fasqueda, como Google Desktop, pueden ser una soluci\u00f3n para documentos locales, pero no encontrar\u00e1n un documento en la m\u00e1quina de otro usuario. Otro problema surge cuando un documento est\u00e1 disponible en la m\u00e1quina de un usuario y ese usuario est\u00e1 desconectado, en cuyo caso ya no se puede acceder al documento. En este art\u00edculo presentamos Apocrita, un revolucionario sistema distribuido de intercambio de archivos P2P para Intranets. 1. INTRODUCCI\u00d3N El paradigma inform\u00e1tico Peer-to-Peer -LRB-P2P-RRB- se est\u00e1 convirtiendo en una forma completamente nueva de intercambio mutuo de recursos a trav\u00e9s de Internet. Con el acceso cada vez m\u00e1s com\u00fan a Internet de banda ancha, la tecnolog\u00eda P2P finalmente se ha convertido en una forma viable de compartir documentos y archivos multimedia. Ya existen programas en el mercado que permiten compartir archivos P2P. Estos programas permiten a millones de usuarios compartir archivos entre ellos. Los archivos descargados a\u00fan requieren mucha gesti\u00f3n manual por parte del usuario. El usuario a\u00fan necesita colocar los archivos en el directorio adecuado, administrar archivos con m\u00faltiples versiones y eliminar los archivos cuando ya no los necesite. Nos esforzamos por facilitar el proceso de compartir documentos dentro de una Intranet. Muchas organizaciones deben crear documentos para diversos fines y es posible que todos los miembros de la organizaci\u00f3n tengan acceso a dichos documentos. Este acceso puede ser necesario para editar o simplemente ver un documento. En algunos casos estos documentos se env\u00edan entre autores, v\u00eda correo electr\u00f3nico, para ser editados. Esto puede provocar f\u00e1cilmente que se env\u00ede una versi\u00f3n incorrecta o que se creen conflictos entre varios usuarios que intentan realizar modificaciones en un documento. Incluso puede haber varios documentos diferentes en proceso de edici\u00f3n. Es posible que se le solicite al usuario que busque un documento en particular; algunas herramientas de b\u00fasqueda, como Google Desktop, pueden ser una soluci\u00f3n para documentos locales, pero no encontrar\u00e1n un documento en la m\u00e1quina de otro usuario. Adem\u00e1s, algunas organizaciones no cuentan con un servidor para compartir archivos ni con la infraestructura de red necesaria para habilitarlo. En este art\u00edculo presentamos Apocrita, que es un sistema de intercambio de archivos P2P distribuido y rentable para este tipo de organizaciones. En la secci\u00f3n 2 presentamos Apocrita. El mecanismo y el protocolo de indexaci\u00f3n distribuida se presentan en la Secci\u00f3n 3. La Secci\u00f3n 4 presenta el modelo de distribuci\u00f3n entre pares. Un prototipo de prueba de concepto se presenta en la Secci\u00f3n 5,y las evaluaciones de desempe\u00f1o se analizan en la Secci\u00f3n 6. El trabajo relacionado se presenta en la Secci\u00f3n 7, y finalmente las conclusiones y el trabajo futuro se analizan en la Secci\u00f3n 8. 7. TRABAJO RELACIONADO Actualmente existen varios sistemas P2P descentralizados -LSB- 1, 2, 3 -RSB-. que Apocrita presenta algunas de sus funcionalidades. Sin embargo, Apocrita tambi\u00e9n tiene caracter\u00edsticas novedosas de b\u00fasqueda e indexaci\u00f3n que hacen que este sistema sea \u00fanico. Por ejemplo, Majestic-12 -LSB- 4 -RSB- es un proyecto de indexaci\u00f3n y b\u00fasqueda distribuida dise\u00f1ado para realizar b\u00fasquedas en Internet. Cada usuario instalar\u00eda un cliente, que se encarga de indexar una parte de la web. Un \u00e1rea central para consultar el \u00edndice est\u00e1 disponible en la p\u00e1gina web de Majestic-12. El \u00edndice en s\u00ed no se distribuye, s\u00f3lo se distribuye el acto de indexaci\u00f3n. El aspecto de indexaci\u00f3n distribuida de este proyecto se relaciona m\u00e1s estrechamente con los objetivos de Apocrita. YaCy -LSB- 6 -RSB- es una aplicaci\u00f3n de b\u00fasqueda web peer-to-peer. YaCy est\u00e1 dise\u00f1ado para mantener un \u00edndice distribuido de Internet. Utiliz\u00f3 una tabla hash distribuida -LRB-DHT-RRB- para mantener el \u00edndice. El nodo local se utiliza para realizar consultas, pero todos los resultados que se devuelven son accesibles en Internet. YaCy utiliz\u00f3 muchos pares y DHT para mantener un \u00edndice distribuido. Apocrita tambi\u00e9n utilizar\u00e1 un \u00edndice distribuido en implementaciones futuras y puede beneficiarse del uso de una implementaci\u00f3n de DHT. Sin embargo, YaCy est\u00e1 dise\u00f1ado como un motor de b\u00fasqueda web y, como tal, resuelve un problema muy diferente al de Apocrita. 8. CONCLUSIONES Y TRABAJO FUTURO Presentamos Apocrita, un sistema distribuido de b\u00fasqueda e indexaci\u00f3n P2P destinado a usuarios de la red en una Intranet. Puede ayudar a las organizaciones sin un servidor de archivos de red o la infraestructura de red necesaria para compartir documentos. Elimina la necesidad de compartir documentos manualmente entre los usuarios mientras se editan y reduce la posibilidad de que se distribuyan versiones conflictivas. A pesar de estas deficiencias, la experiencia adquirida con el dise\u00f1o y la implementaci\u00f3n de Apocrita nos ha brindado m\u00e1s informaci\u00f3n sobre c\u00f3mo construir sistemas distribuidos desafiantes.YaCy est\u00e1 dise\u00f1ado para mantener un \u00edndice distribuido de Internet. Utiliz\u00f3 una tabla hash distribuida -LRB-DHT-RRB- para mantener el \u00edndice. El nodo local se utiliza para realizar consultas, pero todos los resultados que se devuelven son accesibles en Internet. YaCy utiliz\u00f3 muchos pares y DHT para mantener un \u00edndice distribuido. Apocrita tambi\u00e9n utilizar\u00e1 un \u00edndice distribuido en implementaciones futuras y puede beneficiarse del uso de una implementaci\u00f3n de DHT. Sin embargo, YaCy est\u00e1 dise\u00f1ado como un motor de b\u00fasqueda web y, como tal, resuelve un problema muy diferente al de Apocrita. 8. CONCLUSIONES Y TRABAJO FUTURO Presentamos Apocrita, un sistema distribuido de b\u00fasqueda e indexaci\u00f3n P2P destinado a usuarios de la red en una Intranet. Puede ayudar a las organizaciones sin un servidor de archivos de red o la infraestructura de red necesaria para compartir documentos. Elimina la necesidad de compartir documentos manualmente entre los usuarios mientras se editan y reduce la posibilidad de que se distribuyan versiones conflictivas. A pesar de estas deficiencias, la experiencia adquirida con el dise\u00f1o y la implementaci\u00f3n de Apocrita nos ha brindado m\u00e1s informaci\u00f3n sobre c\u00f3mo construir sistemas distribuidos desafiantes.YaCy est\u00e1 dise\u00f1ado para mantener un \u00edndice distribuido de Internet. Utiliz\u00f3 una tabla hash distribuida -LRB-DHT-RRB- para mantener el \u00edndice. El nodo local se utiliza para realizar consultas, pero todos los resultados que se devuelven son accesibles en Internet. YaCy utiliz\u00f3 muchos pares y DHT para mantener un \u00edndice distribuido. Apocrita tambi\u00e9n utilizar\u00e1 un \u00edndice distribuido en implementaciones futuras y puede beneficiarse del uso de una implementaci\u00f3n de DHT. Sin embargo, YaCy est\u00e1 dise\u00f1ado como un motor de b\u00fasqueda web y, como tal, resuelve un problema muy diferente al de Apocrita. 8. CONCLUSIONES Y TRABAJO FUTURO Presentamos Apocrita, un sistema distribuido de b\u00fasqueda e indexaci\u00f3n P2P destinado a usuarios de la red en una Intranet. Puede ayudar a las organizaciones sin un servidor de archivos de red o la infraestructura de red necesaria para compartir documentos. Elimina la necesidad de compartir documentos manualmente entre los usuarios mientras se editan y reduce la posibilidad de que se distribuyan versiones conflictivas. A pesar de estas deficiencias, la experiencia adquirida con el dise\u00f1o y la implementaci\u00f3n de Apocrita nos ha brindado m\u00e1s informaci\u00f3n sobre c\u00f3mo construir sistemas distribuidos desafiantes.", "keyphrases": ["de igual a igual", "sistema para compartir archivos", "intranet", "autor", "documento", "ap\u00f3crita", "jxta", "\u00edndice de distribuci\u00f3n", "modelo de distribuci\u00f3n peer-to-peer", "consulta idl", "archivo de \u00edndice", "archivo entrante", "b\u00fasqueda p2p"]}
{"file_name": "C-20", "text": "Migraci\u00f3n de centros de datos en vivo a trav\u00e9s de WAN: un enfoque cooperativo s\u00f3lido y consciente del context RESUMEN Una preocupaci\u00f3n importante para los proveedores de servicios basados \u200b\u200ben Internet es la operaci\u00f3n continua y la disponibilidad de los servicios ante interrupciones, ya sean planificadas o no. En este documento abogamos por un enfoque cooperativo y consciente del context para la migraci\u00f3n de centros de datos a trav\u00e9s de WAN para abordar las interrupciones de manera no disruptiva. Buscamos espec\u00edficamente lograr una alta disponibilidad de los servicios del centro de datos frente a interrupciones planificadas e imprevistas de las instalaciones del centro de datos. Hacemos uso de tecnolog\u00edas de virtualizaci\u00f3n de servidores para permitir la replicaci\u00f3n y migraci\u00f3n de las funciones del servidor. Proponemos nuevas funciones de red para permitir la migraci\u00f3n y replicaci\u00f3n de servidores a trav\u00e9s de redes de \u00e1rea amplia -LRB-, por ejemplo, Internet -RRB-, y finalmente mostramos la utilidad de la tecnolog\u00eda de replicaci\u00f3n de almacenamiento inteligente y din\u00e1mica para garantizar que las aplicaciones tengan acceso a los datos ante interrupciones. con objetivos de punto de recuperaci\u00f3n muy ajustados. 1. INTRODUCCI\u00d3N Una preocupaci\u00f3n importante para los proveedores de servicios basados \u200b\u200ben Internet es la operaci\u00f3n continua y la disponibilidad de los servicios ante interrupciones, ya sean planificadas o no. Una interrupci\u00f3n relativamente menor puede perturbar e incomodar a una gran cantidad de usuarios. Hoy en d\u00eda, estos servicios est\u00e1n alojados casi exclusivamente en centros de datos. Los avances recientes en tecnolog\u00edas de virtualizaci\u00f3n de servidores -LSB- 8, 14, 22 -RSB- permiten la migraci\u00f3n en vivo de servicios dentro de un entorno de red de \u00e1rea local -LRB- LAN -RRB-. En el entorno LAN, estas tecnolog\u00edas han demostrado ser una herramienta muy eficaz para permitir la gesti\u00f3n del centro de datos de forma no disruptiva. No solo puede soportar eventos de mantenimiento planificados -LSB- 8 -RSB-, sino que tambi\u00e9n se puede utilizar de una manera m\u00e1s din\u00e1mica para equilibrar autom\u00e1ticamente la carga entre los servidores f\u00edsicos en un centro de datos -LSB- 22 -RSB-. Cuando se utilizan estas tecnolog\u00edas en un entorno LAN, los servicios se ejecutan en un servidor virtual y los servicios de migraci\u00f3n proporcionados por el marco de virtualizaci\u00f3n subyacente permiten que un servidor virtual se migre de un servidor f\u00edsico a otro, sin ning\u00fan tiempo de inactividad significativo para el servicio o la aplicaci\u00f3n. . En particular, dado que el servidor virtual conserva la misma direcci\u00f3n de red que antes, las interacciones en curso a nivel de red no se ven interrumpidas. De manera similar, en un entorno LAN, los requisitos de almacenamiento normalmente se satisfacen mediante almacenamiento conectado a la red -LRB- NAS -RRB- o mediante una red de \u00e1rea de almacenamiento -LRB- SAN -RRB- a la que a\u00fan se puede acceder desde la nueva ubicaci\u00f3n del servidor f\u00edsico para permitir acceso continuo al almacenamiento. Desafortunadamente, en un entorno de \u00e1rea amplia -LRB- WAN -RRB-, la migraci\u00f3n del servidor en vivo no es tan f\u00e1cil de lograr por dos razones: Primero, la migraci\u00f3n en vivo requiere que el servidor virtual mantenga la misma direcci\u00f3n de red para que, desde el punto de vista de la conectividad de la red, el servidor migrado es indistinguible del original. Segundo,Si bien se han desarrollado mecanismos de replicaci\u00f3n remota bastante sofisticados en el context de la recuperaci\u00f3n ante desastres -LSB- 20, 7, 11 -RSB-, estos mecanismos no son adecuados para la migraci\u00f3n de centros de datos en vivo, porque en general las tecnolog\u00edas disponibles desconocen la aplicaci\u00f3n/servicio. sem\u00e1ntica de nivel. En este art\u00edculo describimos un dise\u00f1o para la migraci\u00f3n de servicios en vivo a trav\u00e9s de WAN. Nuestro dise\u00f1o hace uso de tecnolog\u00edas de virtualizaci\u00f3n de servidores existentes y propone mecanismos de red y almacenamiento para facilitar la migraci\u00f3n a trav\u00e9s de una WAN. La esencia de nuestro enfoque es la migraci\u00f3n cooperativa y consciente del context, donde un sistema de gesti\u00f3n de migraci\u00f3n organiza la migraci\u00f3n del centro de datos en los tres subsistemas involucrados, es decir, las plataformas de servidores, la red de \u00e1rea amplia y el sistema de almacenamiento en disco. Si bien conceptualmente es similar en naturaleza al trabajo basado en LAN descrito anteriormente, el uso de tecnolog\u00edas de migraci\u00f3n a trav\u00e9s de una red de \u00e1rea amplia presenta desaf\u00edos \u00fanicos y, hasta donde sabemos, no se ha logrado. Nuestra principal contribuci\u00f3n es el dise\u00f1o de un marco que permitir\u00e1 la migraci\u00f3n a trav\u00e9s de una WAN de todos los subsistemas involucrados en la habilitaci\u00f3n de servicios del centro de datos. Describimos nuevos mecanismos, as\u00ed como extensiones de tecnolog\u00edas existentes para permitir esto y describimos la funcionalidad cooperativa y consciente del context necesaria en los diferentes subsistemas para permitir esto. 4. TRABAJO RELACIONADO El trabajo previo sobre este tema se divide en varias categor\u00edas: migraci\u00f3n de m\u00e1quinas virtuales, replicaci\u00f3n de almacenamiento y soporte de red. El n\u00facleo de nuestra t\u00e9cnica es la capacidad de encapsular aplicaciones dentro de m\u00e1quinas virtuales que se pueden migrar sin tiempos de inactividad de las aplicaciones -LSB- 15 -RSB-. Como se indic\u00f3 anteriormente, estas t\u00e9cnicas suponen que la migraci\u00f3n se realiza en una LAN. Tambi\u00e9n se ha estudiado la migraci\u00f3n de VM en el sistema Shirako -LSB- 10 -RSB- y para entornos grid -LSB- 17, 19 -RSB-. El software de m\u00e1quina virtual actual admite una funci\u00f3n de suspensi\u00f3n y reanudaci\u00f3n que se puede utilizar para admitir la migraci\u00f3n WAN, pero con tiempos de inactividad -LSB- 18, 12 -RSB-. Recientemente, se demostr\u00f3 la migraci\u00f3n WAN en vivo utilizando t\u00faneles IP en -LSB-21-RSB-, donde se configura un t\u00fanel IP desde el servidor de origen al de destino para reenviar paquetes de forma transparente hacia y desde la aplicaci\u00f3n; Recomendamos un enfoque alternativo que presuponga la compatibilidad con enrutadores de borde. En -LSB-11-RSB- se puede encontrar una excelente descripci\u00f3n de estos y otros, as\u00ed como una taxonom\u00eda detallada de los diferentes enfoques de replicaci\u00f3n. El sistema Ursa Minor sostiene que ning\u00fan modelo de falla es \u00f3ptimo para todas las aplicaciones y propuso respaldar selecciones espec\u00edficas de tipos de datos de modelos de falla y esquemas de codificaci\u00f3n para la replicaci\u00f3n -LSB- 1 -RSB-. En el context del soporte de red, nuestro trabajo est\u00e1 relacionado con el enfoque RouterFarm -LSB- 2 -RSB-, que utiliza cambios de red orquestados para realizar un mantenimiento casi sin interrupciones en los enrutadores de borde del proveedor. Adem\u00e1s de estar en un \u00e1rea de aplicaci\u00f3n diferente, nuestro enfoque difiere del trabajo de RouterFarm en dos aspectos. Segundo,Debido a los estrictos requisitos de tiempo de la migraci\u00f3n en vivo, esperamos que nuestro enfoque requiera una nueva funcionalidad de enrutador -LRB- en lugar de ser realizable a trav\u00e9s de las interfaces de configuraci\u00f3n existentes -RRB-. En un esp\u00edritu similar al de ROC, abogamos por el uso de mecanismos desde la migraci\u00f3n de VM en vivo hasta la replicaci\u00f3n de almacenamiento para soportar interrupciones planificadas y no planificadas en los centros de datos -LRB- en lugar de una replicaci\u00f3n completa para enmascarar tales fallas -RRB-. 5. CONCLUSI\u00d3N Una preocupaci\u00f3n importante para los proveedores de servicios basados \u200b\u200ben Internet es la operaci\u00f3n continua y la disponibilidad de los servicios ante interrupciones, ya sean planificadas o no. En este documento, defendemos un enfoque cooperativo y consciente del context para la migraci\u00f3n de centros de datos a trav\u00e9s de WAN para abordar las interrupciones de manera no disruptiva. Buscamos lograr una alta disponibilidad de los servicios del centro de datos frente a interrupciones planificadas e incidentales de las instalaciones del centro de datos. Abogamos por el uso de tecnolog\u00edas de virtualizaci\u00f3n de servidores para permitir la replicaci\u00f3n y migraci\u00f3n de las funciones del servidor. Propusimos nuevas funciones de red para permitir la migraci\u00f3n y replicaci\u00f3n de servidores a trav\u00e9s de redes de \u00e1rea amplia -LRB- como Internet o una red privada virtual distribuida geogr\u00e1ficamente -RRB-, y finalmente mostramos la utilidad de la tecnolog\u00eda de replicaci\u00f3n de almacenamiento inteligente y din\u00e1mico para garantizar que las aplicaciones tengan acceso. a los datos ante interrupciones con objetivos de punto de recuperaci\u00f3n muy estrictos.", "keyphrases": ["servicio basado en internet", "migraci\u00f3n del centro de datos", "p\u00e1lido", "LAN", "servidor virtual", "r\u00e9plica de almacenamiento", "r\u00e9plica sincr\u00f3nica", "r\u00e9plica as\u00edncrona", "soporte de red", "almacenamiento", "voz sobre ip", "voip", "bases de datos"]}
{"file_name": "J-20", "text": "Algoritmos de compensaci\u00f3n para los mercados de intercambio de trueque: habilitaci\u00f3n de intercambios de ri\u00f1ones a nivel nacional RESUMEN En los mercados de intercambio de trueque, los agentes buscan intercambiar sus art\u00edculos entre s\u00ed para mejorar sus propias utilidades. Estos intercambios constan de ciclos de agentes, en los que cada agente recibe el art\u00edculo del siguiente agente del ciclo. Nos centramos principalmente en el pr\u00f3ximo mercado nacional de intercambio de ri\u00f1ones, donde los pacientes con enfermedad renal pueden obtener donantes compatibles intercambiando sus propios donantes dispuestos pero incompatibles. Con m\u00e1s de 70.000 pacientes esperando ya un ri\u00f1\u00f3n de cad\u00e1ver en Estados Unidos, este mercado se considera la \u00fanica manera \u00e9tica de reducir significativamente las 4.000 muertes por a\u00f1o atribuidas a la enfermedad renal. El problema de compensaci\u00f3n implica encontrar un intercambio que maximice el bienestar social cuando la duraci\u00f3n m\u00e1xima de un ciclo es fija. Los ciclos largos est\u00e1n prohibidos ya que, por motivos de incentivo, todos los trasplantes de un ciclo deben realizarse simult\u00e1neamente. Adem\u00e1s, en los intercambios de trueque generalmente, m\u00e1s agentes se ven afectados si uno sale de un ciclo m\u00e1s largo. Demostramos que el problema de resoluci\u00f3n con esta restricci\u00f3n de duraci\u00f3n del ciclo es NP-dif\u00edcil. Resolverlo exactamente es uno de los principales desaf\u00edos para establecer un intercambio nacional de ri\u00f1ones. Presentamos el primer algoritmo capaz de limpiar estos mercados a escala nacional. La clave es la formulaci\u00f3n incremental de problemas. Adaptamos dos paradigmas para la tarea: generaci\u00f3n de restricciones y generaci\u00f3n de columnas. Para cada uno, desarrollamos t\u00e9cnicas que mejoran dr\u00e1sticamente tanto el tiempo de ejecuci\u00f3n como el uso de la memoria. Concluimos que la generaci\u00f3n de columnas escala dr\u00e1sticamente mejor que la generaci\u00f3n de restricciones. Nuestro algoritmo tambi\u00e9n admite varias generalizaciones, tal como lo exigen los intercambios de ri\u00f1ones en el mundo real. Nuestro algoritmo reemplaz\u00f3 a CPLEX como el algoritmo de compensaci\u00f3n de Alliance for Paired Donation, uno de los principales intercambios de ri\u00f1ones. Los partidos se realizan cada dos semanas y ya se han realizado trasplantes basados \u200b\u200ben nuestras optimizaciones. 1. INTRODUCCI\u00d3N La funci\u00f3n de los ri\u00f1ones es filtrar los desechos de la sangre. La insuficiencia renal provoca la acumulaci\u00f3n de estos desechos, lo que provoca la muerte en meses. Una opci\u00f3n de tratamiento es la di\u00e1lisis, en la que el paciente va a un hospital para que una m\u00e1quina externa filtre su sangre. Se requieren varias visitas por semana y cada una dura varias horas. La calidad de vida en di\u00e1lisis puede ser extremadamente baja y, de hecho, muchos pacientes optan por abandonar la di\u00e1lisis, lo que lleva a una muerte natural. S\u00f3lo el 12 % de los pacientes en di\u00e1lisis sobrevive 10 a\u00f1os -LSB- 23 -RSB-. En cambio, el tratamiento preferido es un trasplante de ri\u00f1\u00f3n. Los trasplantes de ri\u00f1\u00f3n son, con diferencia, el trasplante m\u00e1s com\u00fan. Lamentablemente, la demanda de ri\u00f1ones supera con creces la oferta. En Estados Unidos, en 2005, 4.052 personas murieron esperando un trasplante de ri\u00f1\u00f3n que les salvar\u00eda la vida. Durante este tiempo, casi 30.000 personas se agregaron a la lista de espera nacional, mientras que solo 9.913 personas abandonaron la lista luego de recibir un ri\u00f1\u00f3n de un donante fallecido. Para muchos pacientes con enfermedad renal,la mejor opci\u00f3n es encontrar un donante vivo, es decir, una persona sana dispuesta a donar uno de sus dos ri\u00f1ones. En 2005, hubo 6.563 donaciones de seres vivos en Estados Unidos. y su destinatario son incompatibles en cuanto a tipo de sangre o de tejido. En el pasado, el donante incompatible era enviado a casa, dejando al paciente a la espera de un ri\u00f1\u00f3n de un donante fallecido. Sin embargo, ahora existen algunos intercambios regionales de ri\u00f1ones en los Estados Unidos, en los que los pacientes pueden intercambiar sus donantes incompatibles entre s\u00ed para obtener cada uno un donante compatible. Estos mercados son ejemplos de intercambios de trueque. En un mercado de trueque, los agentes -LRB- pacientes -RRB- buscan intercambiar sus art\u00edculos -LRB- donantes incompatibles -RRB- entre s\u00ed. Estos intercambios constan de ciclos de agentes, en los que cada agente recibe el art\u00edculo del siguiente agente del ciclo. Los intercambios de trueque son omnipresentes: los ejemplos incluyen Peerflix -LRB- DVDs -RRB- -LSB- 11 -RSB-, Read It Swap It -LRB- libros -RRB- -LSB- 12 -RSB- e Intervac -LRB- casas de vacaciones. RRB- -LSB- 9 -RSB-. Desde hace muchos a\u00f1os existe incluso una gran bolsa de zapatos en Estados Unidos -LSB- 10 -RSB-. Las personas con pies de diferentes tama\u00f1os lo utilizan para evitar tener que comprar dos pares de zapatos. Los amputados de piernas tienen un intercambio separado para compartir el costo de comprar un solo par de zapatos. Podemos codificar un mercado de intercambio de trueque como un gr\u00e1fico dirigido G = -LRB- V, E -RRB- de la siguiente manera. Construya un v\u00e9rtice para cada agente. Agregue un borde ponderado e de un agente vi a otro vj, si vi quiere el elemento de vj. El peso we de e representa la utilidad para vi de obtener el elemento de vj. Un ciclo c en este gr\u00e1fico representa un posible intercambio, en el que cada agente del ciclo obtiene el art\u00edculo del siguiente agente. El peso wc de un ciclo c es la suma de los pesos de sus aristas. Un intercambio es una colecci\u00f3n de ciclos inconexos. El peso de un intercambio es la suma de sus pesos de ciclo. Un intercambio que maximiza el bienestar social es aquel que tiene un peso m\u00e1ximo. La Figura 1 ilustra un mercado de ejemplo con 5 agentes, -LCB- v1, v2,..., v5 -RCB-, en el que todas las aristas tienen peso 1. El mercado tiene 4 ciclos, c1 = -LRB- v1, v2 -RRB -, c2 = -LRB- v2, v3 -RRB-, c3 = -LRB- v3, v4 -RRB- y c4 = -LRB- v1, v2, v3, v4, v5 -RRB-, y dos -LRB- inclusi\u00f3n -RRB- intercambios m\u00e1ximos, es decir, M1 = -LCB- c4 -RCB- y M2 = -LCB- c1, c3 -RCB-. El intercambio M1 tiene tanto peso m\u00e1ximo como cardinalidad m\u00e1xima -LRB-, es decir, incluye la mayor cantidad de aristas/v\u00e9rtices -RRB-. Figura 1: Ejemplo de mercado de intercambio de trueque. El problema de soluci\u00f3n es encontrar un intercambio de peso m\u00e1ximo que consista en ciclos con una longitud como m\u00e1ximo de una peque\u00f1a constante L. Esta restricci\u00f3n de longitud del ciclo surge naturalmente por varias razones. Por ejemplo, en un intercambio de ri\u00f1\u00f3n, todas las operaciones de un ciclo deben realizarse simult\u00e1neamente; de lo contrario, un donante podr\u00eda retirarse despu\u00e9s de que su pareja incompatible haya recibido un ri\u00f1\u00f3n. Debido a tales limitaciones de recursos, el pr\u00f3ximo mercado nacional de intercambio de ri\u00f1ones probablemente solo permitir\u00e1 ciclos de duraci\u00f3n 2 y 3.Otra motivaci\u00f3n para los ciclos cortos es que si el ciclo no logra intercambiarse, menos agentes se ven afectados. Por ejemplo, las pruebas de \u00faltima hora en un intercambio renal revelan a menudo nuevas incompatibilidades que no se detectaron en las pruebas iniciales -LRB- a partir de las cuales se construy\u00f3 el gr\u00e1fico de compatibilidad -RRB-. En la Secci\u00f3n 3, mostramos que -LRB- la versi\u00f3n de decisi\u00f3n de -RRB- el problema de compensaci\u00f3n es NP-completo para L > 3. Un enfoque entonces podr\u00eda ser buscar un buen algoritmo heur\u00edstico o de aproximaci\u00f3n. Sin embargo, por dos razones, buscamos un algoritmo exacto basado en una formulaci\u00f3n de programa lineal entero -LRB-ILP-RRB-, que resolvemos mediante una b\u00fasqueda de \u00e1rbol especializada. 9 En primer lugar, cualquier p\u00e9rdida de optimizaci\u00f3n podr\u00eda provocar muertes innecesarias de pacientes. 9 En segundo lugar, una caracter\u00edstica atractiva de utilizar una formulaci\u00f3n ILP es que permite modelar f\u00e1cilmente una serie de variaciones del objetivo y agregar restricciones adicionales al problema. O, si por varias razones -LRB- por ejemplo, \u00e9ticas -RRB- se requiere un intercambio de cardinalidad m\u00e1xima, se puede al menos en una segunda pasada encontrar la soluci\u00f3n -LRB- de todas las soluciones de cardinalidad m\u00e1xima -RRB- que tenga la menor cantidad de 3 -ciclos. Otras variaciones que se pueden resolver incluyen encontrar varias formas de colecciones de ciclos `` tolerantes a fallas '' -LRB- no disjuntas -RRB- en el caso de que ciertos pares que se pensaban compatibles resultaran ser incompatibles despu\u00e9s de todo. En este art\u00edculo presentamos el primer algoritmo capaz de limpiar estos mercados a escala nacional. Las codificaciones ILP simples son demasiado grandes para siquiera construirlas en el hardware actual, por no hablar de resolverlas. La clave entonces es la formulaci\u00f3n incremental de problemas. Adaptamos dos paradigmas para la tarea: generaci\u00f3n de restricciones y generaci\u00f3n de columnas. Para cada uno, desarrollamos una serie de t\u00e9cnicas -LRB- principalmente espec\u00edficas de problemas -RRB- que mejoran dr\u00e1sticamente tanto el tiempo de ejecuci\u00f3n como el uso de la memoria. 1.1 Trabajo previo Varios art\u00edculos recientes han utilizado simulaciones y algoritmos de compensaci\u00f3n de mercado para explorar el impacto de un intercambio nacional de ri\u00f1ones -LSB- 13, 20, 6, 14, 15, 17 -RSB-. Por ejemplo, al utilizar el algoritmo de coincidencia m\u00e1xima de Edmond -LSB- 4 -RSB-, -LSB- 20 -RSB- se muestra que un mercado nacional de intercambio por pares -LRB- que utilice ciclos de longitud 2 \u00fanicamente -RRB- dar\u00eda como resultado m\u00e1s trasplantes, reducci\u00f3n del tiempo de espera y ahorros de 750 millones de d\u00f3lares en costos de atenci\u00f3n m\u00e9dica en 5 a\u00f1os. Esos resultados son conservadores en dos sentidos. En primer lugar, el mercado simulado conten\u00eda s\u00f3lo 4.000 pacientes iniciales, y se a\u00f1ad\u00edan 250 pacientes cada 3 meses. Se nos ha informado que el mercado podr\u00eda casi duplicar este tama\u00f1o. En segundo lugar, los intercambios se restringieron a ciclos de longitud 2 -LRB- porque eso es todo lo que se puede modelar como coincidencia m\u00e1xima y se resolvieron utilizando el algoritmo de Edmonds -RRB-. Permitir ciclos de longitud 3 conduce a ganancias significativas adicionales.Esto se ha demostrado en los mercados de intercambio de ri\u00f1\u00f3n con 100 pacientes utilizando CPLEX para resolver una codificaci\u00f3n de programa entero del problema de compensaci\u00f3n -LSB- 15 -RSB-. En este art\u00edculo, presentamos un algoritmo alternativo para este programa de n\u00fameros enteros que puede limpiar mercados con m\u00e1s de 10.000 pacientes -LRB- y el mismo n\u00famero de donantes dispuestos -RRB-. Permitir ciclos de longitud superior a 3 a menudo no conduce a ninguna mejora en el tama\u00f1o del intercambio -LSB- 15 -RSB-. -LRB- Adem\u00e1s, en un modelo te\u00f3rico simplificado, cualquier intercambio renal se puede convertir en uno con ciclos de longitud como m\u00e1ximo 4 -LSB- 15 -RSB-. -RRB- Si bien esto no es v\u00e1lido para los intercambios de trueque generales, ni siquiera para todos los mercados de intercambio de ri\u00f1ones, en la Secci\u00f3n 5.2.3 hacemos uso de la observaci\u00f3n de que los ciclos cortos son suficientes para aumentar dr\u00e1sticamente la velocidad de nuestro algoritmo. En un nivel alto, el problema de compensaci\u00f3n para los intercambios de trueque es similar al problema de compensaci\u00f3n -LRB- tambi\u00e9n conocido como problema de determinaci\u00f3n del ganador -RRB- en subastas combinatorias. En ambos entornos, la idea es reunir toda la informaci\u00f3n pertinente sobre los agentes en un punto de compensaci\u00f3n central y ejecutar un algoritmo de compensaci\u00f3n centralizado para determinar la asignaci\u00f3n. Ambos problemas son NP-dif\u00edciles. Ambos se resuelven mejor utilizando t\u00e9cnicas de b\u00fasqueda de \u00e1rboles. Desde 1999, se ha realizado un trabajo importante en ciencias de la computaci\u00f3n y en investigaci\u00f3n de operaciones sobre algoritmos de b\u00fasqueda de \u00e1rboles \u00f3ptimos m\u00e1s r\u00e1pidos para compensar subastas combinatorias. Sin embargo, el problema de compensaci\u00f3n del intercambio renal -LRB- con un l\u00edmite de 3 o m\u00e1s en el tama\u00f1o del ciclo -RRB- es diferente del problema de compensaci\u00f3n de subasta combinatoria en aspectos significativos. La diferencia m\u00e1s importante es que las formulaciones naturales del problema de la subasta combinatoria tienden a caber f\u00e1cilmente en la memoria, por lo que el tiempo es el cuello de botella en la pr\u00e1ctica. Por el contrario, las formulaciones naturales del problema de intercambio renal -LRB- con L = 3 -RRB- ocupan al menos espacio c\u00fabico en el n\u00famero de pacientes para igualar el modelo y, por lo tanto, la memoria se convierte en un cuello de botella mucho antes que el tiempo cuando se utiliza la b\u00fasqueda de \u00e1rbol est\u00e1ndar. , como ramificar y cortar en CPLEX, para abordar el problema. Por lo tanto, los enfoques que se han desarrollado para las subastas combinatorias no pueden solucionar el problema del intercambio renal. 1.2 Esquema del art\u00edculo El resto del art\u00edculo est\u00e1 organizado de la siguiente manera. La secci\u00f3n 2 analiza el proceso mediante el cual generamos datos realistas del mercado de intercambio de ri\u00f1ones, con el fin de comparar los algoritmos de compensaci\u00f3n. La secci\u00f3n 3 contiene una prueba de que el problema de decisi\u00f3n de compensaci\u00f3n del mercado es NP-completo. Las secciones 4 y 5 contienen cada una una formulaci\u00f3n ILP del problema de compensaci\u00f3n. Tambi\u00e9n detallamos en esas secciones nuestras t\u00e9cnicas utilizadas para resolver esos programas en instancias grandes. La secci\u00f3n 6 presenta experimentos sobre las diversas t\u00e9cnicas. La secci\u00f3n 7 analiza la implementaci\u00f3n reciente de nuestro algoritmo. Finalmente, presentamos nuestras conclusiones en la Secci\u00f3n 8 y sugerimos direcciones de investigaci\u00f3n futuras. 7.APLICANDO LA TECNOLOG\u00cdA Nuestro algoritmo e implementaci\u00f3n reemplazaron a CPLEX como el algoritmo de compensaci\u00f3n de la Alianza para la Donaci\u00f3n Pareada, uno de los principales intercambios de ri\u00f1\u00f3n, en diciembre de 2006. Realizamos una prueba de compatibilidad cada dos semanas y los primeros trasplantes basados \u200b\u200ben nuestras soluciones ya han realizado. Si bien actualmente hay -LRB- por razones pol\u00edticas/interpersonales -RRB- al menos cuatro intercambios de ri\u00f1ones en los EE. UU., todos entienden que un intercambio nacional unificado y no fragmentado salvar\u00eda m\u00e1s vidas. Estamos en conversaciones con intercambios de ri\u00f1ones adicionales que est\u00e1n interesados \u200b\u200ben adoptar nuestra tecnolog\u00eda. De esta manera, se espera que nuestra tecnolog\u00eda -LRB- y los procesos que la rodean -RRB- sirvan como sustrato que eventualmente ayude a unificar los intercambios. Al menos la escalabilidad computacional ya no es un obst\u00e1culo. 8. CONCLUSI\u00d3N E INVESTIGACI\u00d3N FUTURA En este trabajo hemos desarrollado los algoritmos exactos para intercambios de trueque m\u00e1s escalables hasta la fecha, con especial atenci\u00f3n al pr\u00f3ximo mercado nacional de intercambio de ri\u00f1ones en el que pacientes con enfermedad renal ser\u00e1n emparejados con donantes compatibles mediante el intercambio de sus propios donantes dispuestos pero incompatibles. Con m\u00e1s de 70.000 pacientes esperando ya un ri\u00f1\u00f3n de cad\u00e1ver en Estados Unidos, este mercado se considera la \u00fanica manera \u00e9tica de reducir significativamente las 4.000 muertes por a\u00f1o atribuidas a la enfermedad renal. Nuestro trabajo presenta el primer algoritmo capaz de limpiar estos mercados a escala nacional. Resuelve de forma \u00f3ptima el problema de eliminaci\u00f3n del intercambio renal con 10.000 parejas de donadores. La mejor tecnolog\u00eda anterior -LRB- vanilla CPLEX -RRB- no puede manejar instancias m\u00e1s all\u00e1 de aproximadamente 900 pares donante-destinatario porque se queda sin memoria. La clave de nuestra mejora es la formulaci\u00f3n incremental de problemas. Adaptamos dos paradigmas para la tarea: generaci\u00f3n de restricciones y generaci\u00f3n de columnas. Para cada uno, desarrollamos una serie de t\u00e9cnicas que mejoran sustancialmente tanto el tiempo de ejecuci\u00f3n como el uso de la memoria. Algunas de las t\u00e9cnicas utilizan observaciones de dominio espec\u00edfico, mientras que otras son independientes del dominio. Concluimos que la generaci\u00f3n de columnas escala dram\u00e1ticamente mejor que la generaci\u00f3n de restricciones. Sin duda, se podr\u00edan utilizar m\u00e1s ajustes de par\u00e1metros y quiz\u00e1s t\u00e9cnicas adicionales de mejora de la velocidad para hacer que el algoritmo sea a\u00fan m\u00e1s r\u00e1pido. Nuestro algoritmo tambi\u00e9n admite varias generalizaciones, seg\u00fan lo deseado por los intercambios de ri\u00f1ones en el mundo real. Debido a que utilizamos una metodolog\u00eda ILP, tambi\u00e9n podemos soportar una variedad de restricciones laterales, que a menudo juegan un papel importante en los mercados en la pr\u00e1ctica -LSB- 19 -RSB-. Tambi\u00e9n podemos apoyar la imposici\u00f3n de una parte de la asignaci\u00f3n, por ejemplo: \"Este adolescente gravemente enfermo tiene que recibir un ri\u00f1\u00f3n si es posible\". ''Nuestro trabajo ha tratado el intercambio de ri\u00f1\u00f3n como un problema por lotes con informaci\u00f3n completa -LRB- al menos en el corto plazo, lo m\u00e1s probable es que los intercambios de ri\u00f1\u00f3n contin\u00faen ejecut\u00e1ndose en modo por lotes de vez en cuando -RRB-. Dos direcciones importantes para el trabajo futuro son abordar expl\u00edcitamente los aspectos del problema tanto en l\u00ednea como de informaci\u00f3n limitada.El aspecto en l\u00ednea es que los donatarios y los donantes llegar\u00e1n al sistema con el tiempo, y puede ser mejor no ejecutar el intercambio miopemente \u00f3ptimo ahora, sino guardar parte del mercado actual para coincidencias posteriores.", "keyphrases": ["mercado de intercambio de trueque", "f\u00f3sforo", "g\u00e9nero de columna", "ri\u00f1\u00f3n", "trasplante", "caracter\u00edstica del mercado", "genero instant\u00e1neo", "enfoque de soluci\u00f3n", "f\u00f3rmula de borde", "f\u00f3rmula c\u00edclica"]}
{"file_name": "H-2", "text": "Expansi\u00f3n de consultas personalizadas para la Web RESUMEN La ambig\u00fcedad inherente de las consultas cortas de palabras clave exige m\u00e9todos mejorados para la recuperaci\u00f3n en la Web. En este documento proponemos mejorar dichas consultas web ampli\u00e1ndolas con t\u00e9rminos recopilados del Repositorio de informaci\u00f3n personal de cada usuario, personalizando as\u00ed impl\u00edcitamente el resultado de la b\u00fasqueda. Introducimos cinco t\u00e9cnicas amplias para generar palabras clave de consulta adicionales mediante el an\u00e1lisis de datos de usuario en niveles de granularidad crecientes, que van desde an\u00e1lisis de t\u00e9rminos y niveles compuestos hasta estad\u00edsticas globales de coocurrencia, as\u00ed como el uso de tesauros externos. Nuestro extenso an\u00e1lisis emp\u00edrico bajo cuatro escenarios diferentes muestra que algunos de estos enfoques funcionan muy bien, especialmente en consultas ambiguas, lo que produce un aumento muy fuerte en la calidad de las clasificaciones de resultados. Posteriormente, llevamos este marco de b\u00fasqueda personalizado un paso m\u00e1s all\u00e1 y proponemos que el proceso de expansi\u00f3n se adapte a las diversas caracter\u00edsticas de cada consulta. Un conjunto separado de experimentos indica que los algoritmos adaptativos aportan una mejora adicional estad\u00edsticamente significativa con respecto al mejor enfoque de expansi\u00f3n est\u00e1tica. 1. INTRODUCCI\u00d3N La creciente popularidad de los motores de b\u00fasqueda ha determinado que la b\u00fasqueda de palabras clave simples se convierta en la \u00fanica interfaz de usuario ampliamente aceptada para buscar informaci\u00f3n en la Web. Sin embargo, las consultas de palabras clave * Parte de este trabajo se realiz\u00f3 mientras el autor visitaba Yahoo! Investigaci\u00f3n, Barcelona, \u200b\u200bEspa\u00f1a. inherentemente ambiguo. La consulta \"libro can\u00f3nico\", por ejemplo, cubre varias \u00e1reas de inter\u00e9s diferentes: religi\u00f3n, fotograf\u00eda, literatura y m\u00fasica. Claramente, uno preferir\u00eda que los resultados de la b\u00fasqueda estuvieran alineados con el tema de inter\u00e9s del usuario -LRB- s -RRB-, en lugar de mostrar una selecci\u00f3n de URL populares de cada categor\u00eda. Los estudios han demostrado que m\u00e1s del 80 % de los usuarios preferir\u00edan recibir resultados de b\u00fasqueda personalizados -LSB- 33 -RSB- en lugar de los gen\u00e9ricos actuales. La expansi\u00f3n de consultas ayuda al usuario a formular una mejor consulta, agregando palabras clave adicionales a la solicitud de b\u00fasqueda inicial para encapsular sus intereses en ella, as\u00ed como para enfocar el resultado de la b\u00fasqueda web en consecuencia. Se ha demostrado que funciona muy bien en conjuntos de datos grandes, especialmente con consultas de entrada cortas -LRB-; consulte, por ejemplo, -LSB- 19, 3 -RSB- -RRB-. \u00a1Este es exactamente el escenario de b\u00fasqueda web! En este trabajo nos proponemos mejorar la reformulaci\u00f3n de consultas Web explotando el Repositorio de Informaci\u00f3n Personal del usuario -LRB- PIR -RRB-, es decir, la colecci\u00f3n personal de documentos de text, correos electr\u00f3nicos, p\u00e1ginas Web almacenadas en cach\u00e9, etc. Surgen varias ventajas al desplazarse Personalizaci\u00f3n de b\u00fasqueda web hasta el nivel de Escritorio -LRB- tenga en cuenta que por ``Escritorio'' nos referimos a PIR, y utilizamos los dos t\u00e9rminos indistintamente -RRB-. En primer lugar est\u00e1, por supuesto, la calidad de la personalizaci\u00f3n: el escritorio local es un rico dep\u00f3sito de informaci\u00f3n que describe con precisi\u00f3n la mayor\u00eda, si no todos, los intereses del usuario.Nuestros algoritmos ampl\u00edan las consultas web con palabras clave extra\u00eddas del PIR del usuario, personalizando as\u00ed impl\u00edcitamente el resultado de la b\u00fasqueda. Despu\u00e9s de una discusi\u00f3n de trabajos previos en la Secci\u00f3n 2, primero investigamos el an\u00e1lisis del context de consulta del Escritorio local en la Secci\u00f3n 3.1.1. Proponemos varias t\u00e9cnicas basadas en palabras clave, expresiones y res\u00famenes para determinar los t\u00e9rminos de expansi\u00f3n de aquellos documentos personales que mejor coincidan con la consulta web. En la Secci\u00f3n 3.1.2 trasladamos nuestro an\u00e1lisis a la colecci\u00f3n global de Escritorio e investigamos expansiones basadas en m\u00e9tricas de coocurrencia y tesauros externos. Los experimentos presentados en la Secci\u00f3n 3.2 muestran que muchos de estos enfoques funcionan muy bien, especialmente en consultas ambiguas, produciendo mejoras en NDCG -LSB- 15 -RSB- de hasta un 51,28 %. En la Secci\u00f3n 4 avanzamos m\u00e1s este marco algor\u00edtmico y proponemos hacer que el proceso de expansi\u00f3n se adapte al nivel de claridad de la consulta. Esto produce una mejora adicional del 8,47 % con respecto al mejor algoritmo identificado anteriormente. Concluimos y discutimos el trabajo adicional en la Secci\u00f3n 5. 2. TRABAJO ANTERIOR Este documento re\u00fane dos \u00e1reas de IR: personalizaci\u00f3n de b\u00fasqueda y expansi\u00f3n autom\u00e1tica de consultas. Existe una gran cantidad de algoritmos para ambos dominios. Por lo tanto, en esta secci\u00f3n presentamos un an\u00e1lisis separado, introduciendo primero algunos enfoques para personalizar la b\u00fasqueda, ya que esto representa el objetivo principal de nuestra investigaci\u00f3n, y luego analizando varias t\u00e9cnicas de expansi\u00f3n de consultas y su relaci\u00f3n con nuestros algoritmos. 2.1 B\u00fasqueda personalizada La b\u00fasqueda personalizada consta de dos componentes principales: -LRB- 1 -RRB- Perfiles de usuario y -LRB- 2 -RRB- El algoritmo de b\u00fasqueda real. Esta secci\u00f3n divide los antecedentes relevantes seg\u00fan el enfoque de cada art\u00edculo en cualquiera de estos elementos. Enfoques centrados en el Perfil del Usuario. Sugiyama et al. -LSB- 32 -RSB- analiz\u00f3 el comportamiento de navegaci\u00f3n y gener\u00f3 perfiles de usuario como caracter\u00edsticas -LRB- t\u00e9rminos -RRB- de las p\u00e1ginas visitadas. Al realizar una nueva consulta, los resultados de la b\u00fasqueda se clasificaron seg\u00fan la similitud entre cada URL y el perfil del usuario. Qiu y Cho -LSB- 26 -RSB- utilizaron el aprendizaje autom\u00e1tico en el historial de clics anteriores del usuario para determinar los vectores de preferencia de temas y luego aplicar el PageRank sensible al tema -LSB- 13 -RSB-. La creaci\u00f3n de perfiles de usuario basada en el historial de navegaci\u00f3n tiene la ventaja de ser bastante f\u00e1cil de obtener y procesar. Probablemente esta sea la raz\u00f3n por la que tambi\u00e9n lo emplean varios motores de b\u00fasqueda industriales -LRB-, por ejemplo, Yahoo! MiWeb2 -RRB-. Sin embargo, esto definitivamente no es suficiente para conocer en profundidad los intereses de los usuarios. Adem\u00e1s, ninguno de ellos investig\u00f3 la aplicaci\u00f3n adaptativa de la personalizaci\u00f3n. Enfoques centrados en el Algoritmo de Personalizaci\u00f3n. Haveliwala -LSB- 13 -RSB- calcul\u00f3 un PageRank orientado a temas, en el que 16 vectores de PageRank sesgados en cada uno de los temas principales de Open Directory se calcularon inicialmente fuera de l\u00ednea y luego se combinaron en tiempo de ejecuci\u00f3n en funci\u00f3n de la similitud entre los usuarios. consulta y cada uno de los 16 temas. 2.2 Expansi\u00f3n autom\u00e1tica de consultas La expansi\u00f3n autom\u00e1tica de consultas tiene como objetivo derivar una mejor formulaci\u00f3n de la consulta del usuario para mejorar la recuperaci\u00f3n. Se basa en explotar varias caracter\u00edsticas sociales o espec\u00edficas de la colecci\u00f3n para generar t\u00e9rminos adicionales, que se agregan a las palabras clave de entrada originales antes de identificar los documentos coincidentes devueltos como salida. En esta secci\u00f3n examinamos algunos de los trabajos representativos de expansi\u00f3n de consultas agrupados seg\u00fan la fuente empleada para generar t\u00e9rminos adicionales: -LRB- 1 -RRB- Comentarios de relevancia, -LRB- 2 -RRB- Estad\u00edsticas de coocurrencia basadas en colecciones y -LRB - 3 -RRB- Informaci\u00f3n del tesauro. Algunos otros enfoques tambi\u00e9n se abordan al final de la secci\u00f3n. T\u00e9cnicas de retroalimentaci\u00f3n de relevancia. La idea principal de Relevance Feedback -LRB- RF -RRB- es que se puede extraer informaci\u00f3n \u00fatil de los documentos relevantes devueltos para la consulta inicial. Los primeros enfoques fueron manuales -LSB- 28 -RSB- en el sentido de que era el usuario quien eleg\u00eda los resultados relevantes, y luego se aplicaron diversos m\u00e9todos para extraer nuevos t\u00e9rminos, relacionados con la consulta y los documentos seleccionados. Efthimiadis -LSB- 11 -RSB- present\u00f3 una revisi\u00f3n exhaustiva de la literatura y propuso varios m\u00e9todos simples para extraer nuevas palabras clave basadas en la frecuencia de los t\u00e9rminos, la frecuencia de los documentos, etc. Usamos algunos de estos como inspiraci\u00f3n para nuestras t\u00e9cnicas espec\u00edficas de escritorio. Chang y Hsu -LSB- 5 -RSB- pidieron a los usuarios que eligieran grupos relevantes, en lugar de documentos, reduciendo as\u00ed la cantidad de interacci\u00f3n necesaria. Tambi\u00e9n se ha demostrado que RF se automatiza eficazmente al considerar los documentos mejor clasificados como relevantes -LSB- 37 -RSB- -LRB- esto se conoce como Pseudo RF -RRB-. Lam y Jones -LSB- 21 -RSB- utilizaron el resumen para extraer oraciones informativas de los documentos mejor clasificados y las agregaron a la consulta del usuario. Finalmente, Yu et al. -LSB- 38 -RSB- seleccion\u00f3 los t\u00e9rminos de expansi\u00f3n de segmentos de p\u00e1ginas web basados \u200b\u200ben la visi\u00f3n para hacer frente a los m\u00faltiples temas que residen en ellos. T\u00e9cnicas basadas en la coocurrencia. Se ha demostrado que los t\u00e9rminos que coexisten con las palabras clave emitidas aumentan la precisi\u00f3n cuando se a\u00f1aden a la consulta -LSB- 17 -RSB-. Tambi\u00e9n hemos investigado tres de estos enfoques para identificar palabras clave relevantes para la consulta del rico, aunque bastante complejo, repositorio de informaci\u00f3n personal. T\u00e9cnicas basadas en tesauros. Un m\u00e9todo ampliamente explorado es ampliar la consulta del usuario con nuevos t\u00e9rminos, cuyo significado est\u00e9 estrechamente relacionado con las palabras clave ingresadas. Al igual que con los m\u00e9todos de coocurrencia, los experimentos iniciales con este enfoque fueron controvertidos, ya sea reportando mejoras o incluso reducciones en la calidad de la producci\u00f3n -LSB- 36 -RSB-. Tambi\u00e9n utilizamos t\u00e9rminos de expansi\u00f3n basados \u200b\u200ben WordNet. Sin embargo, basamos este proceso en el an\u00e1lisis de la relaci\u00f3n a nivel de escritorio entre la consulta original y las nuevas palabras clave propuestas. Otras t\u00e9cnicas. Hay muchos otros intentos de extraer t\u00e9rminos de expansi\u00f3n. Aunque ortogonal a nuestro enfoque,Dos trabajos son muy relevantes para el entorno Web: Cui et al. -LSB- 8 -RSB- gener\u00f3 correlaciones de palabras utilizando la probabilidad de que aparezcan t\u00e9rminos de consulta en cada documento, seg\u00fan se calcula en los registros del motor de b\u00fasqueda. Kraft y Zien -LSB- 19 -RSB- demostraron que el text ancla es muy similar a las consultas de los usuarios y, por lo tanto, lo explotaron para adquirir palabras clave adicionales. 5. CONCLUSIONES Y TRABAJO FUTURO En este art\u00edculo propusimos expandir las consultas de b\u00fasqueda web explotando el Repositorio de informaci\u00f3n personal del usuario para extraer autom\u00e1ticamente palabras clave adicionales relacionadas tanto con la consulta misma como con los intereses del usuario, personalizando el resultado de la b\u00fasqueda. En este context, el art\u00edculo incluye las siguientes contribuciones: \u2022 Propusimos cinco t\u00e9cnicas para determinar t\u00e9rminos de expansi\u00f3n a partir de documentos personales. Cada uno de ellos produce palabras clave de consulta adicionales mediante el an\u00e1lisis del escritorio del usuario en niveles de granularidad crecientes, que van desde an\u00e1lisis de t\u00e9rminos y niveles de expresi\u00f3n hasta estad\u00edsticas globales de coocurrencia y tesauros externos. Figura 1: Ganancia relativa de NDCG -LRB- en % -RRB- para cada algoritmo en general, as\u00ed como separado por categor\u00eda de consulta. \u2022 Proporcionamos un an\u00e1lisis emp\u00edrico exhaustivo de varias variantes de nuestros enfoques, bajo cuatro escenarios diferentes. Mostramos que algunos de estos enfoques funcionan muy bien, produciendo mejoras en NDCG de hasta un 51,28 %. \u2022 Avanzamos m\u00e1s all\u00e1 en este marco de b\u00fasqueda personalizada y propusimos que el proceso de expansi\u00f3n se adaptara a las caracter\u00edsticas de cada consulta, poniendo especial \u00e9nfasis en su nivel de claridad. \u2022 En un conjunto separado de experimentos, demostramos que nuestros algoritmos adaptativos proporcionaban una mejora adicional del 8,47 % con respecto al mejor enfoque previamente identificado. Actualmente estamos realizando investigaciones sobre la dependencia entre varias funciones de consulta y el n\u00famero \u00f3ptimo de t\u00e9rminos de expansi\u00f3n. Tambi\u00e9n estamos analizando otros tipos de enfoques para identificar sugerencias de expansi\u00f3n de consultas, como aplicar el An\u00e1lisis Sem\u00e1ntico Latente en los datos del Escritorio. Finalmente, estamos dise\u00f1ando un conjunto de combinaciones m\u00e1s complejas de estas m\u00e9tricas para proporcionar una mayor adaptabilidad a nuestros algoritmos.Cada uno de ellos produce palabras clave de consulta adicionales mediante el an\u00e1lisis del escritorio del usuario en niveles de granularidad crecientes, que van desde an\u00e1lisis de t\u00e9rminos y niveles de expresi\u00f3n hasta estad\u00edsticas globales de coocurrencia y tesauros externos. Figura 1: Ganancia relativa de NDCG -LRB- en % -RRB- para cada algoritmo en general, as\u00ed como separado por categor\u00eda de consulta. \u2022 Proporcionamos un an\u00e1lisis emp\u00edrico exhaustivo de varias variantes de nuestros enfoques, bajo cuatro escenarios diferentes. Mostramos que algunos de estos enfoques funcionan muy bien, produciendo mejoras en NDCG de hasta un 51,28 %. \u2022 Avanzamos m\u00e1s all\u00e1 en este marco de b\u00fasqueda personalizada y propusimos que el proceso de expansi\u00f3n se adaptara a las caracter\u00edsticas de cada consulta, poniendo especial \u00e9nfasis en su nivel de claridad. \u2022 En un conjunto separado de experimentos, demostramos que nuestros algoritmos adaptativos proporcionaban una mejora adicional del 8,47 % con respecto al mejor enfoque previamente identificado. Actualmente estamos realizando investigaciones sobre la dependencia entre varias funciones de consulta y el n\u00famero \u00f3ptimo de t\u00e9rminos de expansi\u00f3n. Tambi\u00e9n estamos analizando otros tipos de enfoques para identificar sugerencias de expansi\u00f3n de consultas, como aplicar el An\u00e1lisis Sem\u00e1ntico Latente en los datos del Escritorio. Finalmente, estamos dise\u00f1ando un conjunto de combinaciones m\u00e1s complejas de estas m\u00e9tricas para proporcionar una mayor adaptabilidad a nuestros algoritmos.Cada uno de ellos produce palabras clave de consulta adicionales mediante el an\u00e1lisis del escritorio del usuario en niveles de granularidad crecientes, que van desde an\u00e1lisis de t\u00e9rminos y niveles de expresi\u00f3n hasta estad\u00edsticas globales de coocurrencia y tesauros externos. Figura 1: Ganancia relativa de NDCG -LRB- en % -RRB- para cada algoritmo en general, as\u00ed como separado por categor\u00eda de consulta. \u2022 Proporcionamos un an\u00e1lisis emp\u00edrico exhaustivo de varias variantes de nuestros enfoques, bajo cuatro escenarios diferentes. Mostramos que algunos de estos enfoques funcionan muy bien, produciendo mejoras en NDCG de hasta un 51,28 %. \u2022 Avanzamos m\u00e1s all\u00e1 en este marco de b\u00fasqueda personalizada y propusimos que el proceso de expansi\u00f3n se adaptara a las caracter\u00edsticas de cada consulta, poniendo especial \u00e9nfasis en su nivel de claridad. \u2022 En un conjunto separado de experimentos, demostramos que nuestros algoritmos adaptativos proporcionaban una mejora adicional del 8,47 % con respecto al mejor enfoque previamente identificado. Actualmente estamos realizando investigaciones sobre la dependencia entre varias funciones de consulta y el n\u00famero \u00f3ptimo de t\u00e9rminos de expansi\u00f3n. Tambi\u00e9n estamos analizando otros tipos de enfoques para identificar sugerencias de expansi\u00f3n de consultas, como aplicar el An\u00e1lisis Sem\u00e1ntico Latente en los datos del Escritorio. Finalmente, estamos dise\u00f1ando un conjunto de combinaciones m\u00e1s complejas de estas m\u00e9tricas para proporcionar una mayor adaptabilidad a nuestros algoritmos.", "keyphrases": ["consulta corta de palabras clave", "recuperaci\u00f3n web", "consulta web", "persona informar repositorio", "salida de b\u00fasqueda", "agregar palabra clave de consulta", "nivel granular", "an\u00e1lisis de t\u00e9rminos y niveles compuestos", "estatista global co-ocurrente", "tesauro externo", "an\u00e1lisis empir extensivo", "pregunta ambigua", "calidad", "rango de salida", "marco de b\u00fasqueda de personas", "expande el proceso", "Varias caracter\u00edsticas de cada consulta.", "adaptar el algoritmo", "improvisaci\u00f3n significativa", "enfoque de expansi\u00f3n est\u00e1tica"]}
{"file_name": "J-30", "text": "Implementaci\u00f3n con un espacio de acci\u00f3n acotado RESUMEN Si bien el dise\u00f1o de mecanismos tradicionales generalmente asume isomorfismo entre el tipo de agentes y los espacios de acci\u00f3n, en muchas situaciones los agentes enfrentan restricciones estrictas en su espacio de acci\u00f3n debido, por ejemplo, a razones t\u00e9cnicas, de comportamiento o regulatorias. Ideamos un marco general para el estudio del dise\u00f1o de mecanismos en entornos de un solo par\u00e1metro con espacios de acci\u00f3n restringidos. Nuestra contribuci\u00f3n es triple. En primer lugar, caracterizamos condiciones suficientes bajo las cuales la regla de elecci\u00f3n social te\u00f3ricamente \u00f3ptima en materia de informaci\u00f3n puede implementarse en estrategias dominantes, y demostramos que cualquier regla de elecci\u00f3n social multilineal es implementable en una estrategia dominante sin costo adicional. En segundo lugar, identificamos las condiciones necesarias para la optimizaci\u00f3n de los mecanismos de acci\u00f3n limitada y caracterizamos completamente los mecanismos y estrategias \u00f3ptimos en juegos con dos jugadores y dos alternativas. Finalmente, demostramos que para cualquier regla de elecci\u00f3n social multilineal, el mecanismo \u00f3ptimo con k acciones incurre en una p\u00e9rdida esperada de O -LRB- k21 -RRB- en comparaci\u00f3n con los mecanismos \u00f3ptimos con espacios de acci\u00f3n ilimitados. Nuestros resultados se aplican a diversos entornos econ\u00f3micos y computacionales, y demostramos su aplicabilidad a juegos de se\u00f1alizaci\u00f3n, modelos de bien p\u00fablico y enrutamiento en redes. 1. INTRODUCCI\u00d3N El dise\u00f1o de mecanismos es un subcampo de la teor\u00eda de juegos que estudia c\u00f3mo dise\u00f1ar reglas de juegos que den resultados deseables, cuando los jugadores son racionales. En una configuraci\u00f3n est\u00e1ndar, los jugadores mantienen cierta informaci\u00f3n privada (sus \"tipos\") y eligen \"acciones\" de sus espacios de acci\u00f3n para maximizar sus utilidades. El planificador social desea implementar una funci\u00f3n de elecci\u00f3n social, que mapee cada estado posible del mundo -LRB- es decir, un perfil de los tipos de jugadores -RRB- a una \u00fanica alternativa. Por ejemplo, un gobierno que desea emprender un proyecto de bien p\u00fablico -LRB-, por ejemplo, construir un puente -RRB- s\u00f3lo si el beneficio total para los actores excede su costo. Gran parte de la literatura sobre dise\u00f1o de mecanismos restringe la atenci\u00f3n a los mecanismos de revelaci\u00f3n directa, en los que el espacio de acci\u00f3n de un jugador es id\u00e9ntico a su espacio de tipo. Este enfoque se debe al principio de revelaci\u00f3n que afirma que si alg\u00fan mecanismo logra un determinado resultado en un equilibrio, el mismo resultado se puede lograr en uno veraz: un equilibrio en el que cada agente simplemente informa su tipo privado -LSB- 15 -RSB -. Sin embargo, en muchos entornos los mecanismos de revelaci\u00f3n directa no son viables ya que las acciones disponibles para los jugadores tienen un poder expresivo limitado. Consideremos, por ejemplo, el bien estudiado modelo de \"detecci\u00f3n\", en el que una empresa de seguros desea vender diferentes tipos de p\u00f3lizas a diferentes conductores en funci\u00f3n de sus niveles de precauci\u00f3n, que es su informaci\u00f3n privada. Hay varias razones para restricciones tan estrictas en los espacios de acci\u00f3n.Los compradores en tales entornos se enfrentan s\u00f3lo a dos acciones: comprar o no comprar, aunque pueden tener un n\u00famero infinito de valores posibles para el art\u00edculo. En muchos entornos similares, los jugadores tambi\u00e9n pueden mostrarse reacios a revelar sus tipos exactos, pero dispuestos a revelar informaci\u00f3n parcial sobre ellos. Por ejemplo, los agentes normalmente no estar\u00e1n dispuestos a revelar sus tipos, incluso si es beneficioso para ellos en el corto plazo, ya que podr\u00eda perjudicarlos en transacciones futuras. Los agentes tambi\u00e9n pueden no confiar en el mecanismo para mantener sus valoraciones privadas -LSB- 16 -RSB-, o ni siquiera conocer su tipo exacto mientras que calcularlo puede resultar caro -LSB- 12 -RSB-. Consideremos, por ejemplo, un modelo de bien p\u00fablico: un planificador social debe decidir si construye un puente. Los dos jugadores en el juego tienen algunos beneficios conocidos de forma privada \u03b81, \u03b82 \u2208 -LSB- 0, 1 -RSB- al usar este puente. El planificador social pretende construir el puente s\u00f3lo si la suma de estos beneficios excede el costo de construcci\u00f3n del puente. El planificador social no puede acceder a los datos privados de los jugadores y s\u00f3lo puede conocerlos a partir de las acciones de los jugadores. Cuando se permite la revelaci\u00f3n directa, el planificador social puede ejecutar el conocido mecanismo VCG, donde los jugadores tienen incentivos para informar sus datos verdaderos; por lo tanto, el planificador puede obtener la informaci\u00f3n privada exacta de los jugadores y construir el puente s\u00f3lo cuando deber\u00eda construirse. Supongamos ahora que los jugadores no pueden enviar todos sus datos secretos, sino que s\u00f3lo pueden elegir una acci\u00f3n entre dos posibles -LRB-, por ejemplo, ``0'' o ``1'' -RRB-. Ahora bien, es evidente que el planificador social ya no podr\u00e1 construir siempre el puente seg\u00fan su funci\u00f3n objetivo, debido a la limitada expresividad de los mensajes de los jugadores. En este trabajo intentamos analizar qu\u00e9 se puede lograr en presencia de tales restricciones. En varios art\u00edculos anteriores se estudiaron las restricciones al espacio de acci\u00f3n, para modelos espec\u00edficos. Estudiaron subastas de un solo art\u00edculo en las que a los postores se les permite enviar mensajes con un tama\u00f1o muy limitado. Caracterizaron los mecanismos \u00f3ptimos bajo esta restricci\u00f3n y demostraron que se pueden lograr resultados casi \u00f3ptimos incluso con limitaciones muy estrictas en el espacio de acci\u00f3n. Nuestro trabajo generaliza los principales resultados de Blumrosen et al. a un marco general de dise\u00f1o de mecanismos que se puede aplicar a una multitud de modelos. Un entorno de dise\u00f1o de mecanismo est\u00e1ndar est\u00e1 compuesto por agentes con informaci\u00f3n privada -LRB-, sus ``tipos'' -RRB-, y un planificador social, que desea implementar una funci\u00f3n de elecci\u00f3n social, c -- una funci\u00f3n que mapea cualquier perfil del tipos de agentes en una alternativa elegida. Un resultado cl\u00e1sico en este escenario dice que bajo alg\u00fan supuesto de monotonicidad sobre las preferencias de los agentes -el supuesto de \"cruce \u00fanico\" -LRB- ver definici\u00f3n a continuaci\u00f3n -RRB-- una funci\u00f3n de elecci\u00f3n social es implementable en estrategias dominantes si y s\u00f3lo si es mon\u00f3tono en los tipos de jugadores. Sin embargo,En entornos con espacios de acci\u00f3n restringidos, el planificador social normalmente no puede implementar todas las funciones de elecci\u00f3n social debido a limitaciones de informaci\u00f3n inherentes. Es decir, para algunas realizaciones de los tipos de jugadores, la decisi\u00f3n del planificador social ser\u00e1 incompatible con la funci\u00f3n de elecci\u00f3n social c. Para medir cuantitativamente qu\u00e9 tan bien los mecanismos de acci\u00f3n limitada pueden aproximarse a las funciones de elecci\u00f3n social originales, seguimos el supuesto est\u00e1ndar de que la funci\u00f3n de elecci\u00f3n social se deriva de una funci\u00f3n de valor social, g, que asigna un valor real a cada alternativa A. y realizaci\u00f3n de los tipos de jugadores. Por lo tanto, la funci\u00f3n de elecci\u00f3n social c elegir\u00e1 una alternativa que maximice la funci\u00f3n de valor social, dado el tipo \u2192 \u2212 \u03b8 = -LRB- \u03b81,. . Obs\u00e9rvese que la funci\u00f3n de valor social no es necesariamente la funci\u00f3n de bienestar social: la funci\u00f3n de bienestar social es un caso especial de g en el que g se define como la suma de las valoraciones de los jugadores para la alternativa elegida. A continuaci\u00f3n se presentan varios ejemplos simples de funciones de valor social: \u2022 Bienes p\u00fablicos. Un gobierno desea construir un puente s\u00f3lo si la suma de los beneficios que los agentes obtienen de \u00e9l excede su costo de construcci\u00f3n C. Las funciones de valor social en un juego de 2 jugadores ser\u00e1n, por lo tanto: g -LRB- \u03b81, \u03b82, `` construir '' -RRB- = \u03b81 + \u03b82-C y g -LRB- \u03b81, \u03b82, ``no construir '' -RRB- = 0. \u2022 Enrutamiento en redes. Considere una red que se compone de dos enlaces en paralelo. Cada enlace tiene una probabilidad secreta pi de transferir un mensaje con \u00e9xito. Un remitente desea enviar su mensaje a trav\u00e9s de la red s\u00f3lo si la probabilidad de \u00e9xito es mayor que, digamos, el 90 por ciento (la probabilidad conocida en una red alternativa). \u2022 Subastas de un solo art\u00edculo. Considere una subasta de 2 jugadores, donde el subastador desea asignar el art\u00edculo al jugador que lo valora m\u00e1s. La funci\u00f3n de elecci\u00f3n social est\u00e1 dada por: g -LRB- \u03b81, \u03b82, `` el jugador 1 gana '' -RRB- = \u03b81 y para la segunda alternativa es g -LRB- \u03b81, \u03b82, `` el jugador 2 gana '' - RRB- = \u03b82. 1.1 Nuestra contribuci\u00f3n En este art\u00edculo, presentamos un marco general para el estudio del dise\u00f1o de mecanismos en entornos con un n\u00famero limitado de acciones. Asumimos un modelo bayesiano donde los jugadores tienen tipos privados unidimensionales, distribuidos independientemente en alg\u00fan intervalo real. La pregunta principal que nos hacemos es: cuando a los agentes s\u00f3lo se les permite utilizar k acciones diferentes, \u00bfqu\u00e9 mecanismos logran el valor social esperado \u00f3ptimo? Tenga en cuenta que esta pregunta en realidad se compone de dos preguntas separadas. La primera pregunta es una pregunta te\u00f3rica de la informaci\u00f3n: \u00bfcu\u00e1l es el resultado \u00f3ptimo que se puede lograr cuando los jugadores s\u00f3lo pueden revelar informaci\u00f3n usando estas k acciones -LRB-? Recuerde que su espacio de tipos puede ser continuo -RRB-. La otra pregunta involucra consideraciones de teor\u00eda de juegos: cu\u00e1l es el mejor resultado que se puede lograr con k acciones, d\u00f3nde este resultado deber\u00eda lograrse en un equilibrio de estrategia dominante.Estas cuestiones plantean la cuesti\u00f3n del \"precio de la implementaci\u00f3n\": \u00bfpuede siempre implementarse el resultado \u00f3ptimo de la teor\u00eda de la informaci\u00f3n en un equilibrio de estrategia dominante? Y si no, \u00bfen qu\u00e9 medida el requisito de la estrategia dominante degrada el resultado \u00f3ptimo? Nuestra primera contribuci\u00f3n es la caracterizaci\u00f3n de condiciones suficientes para implementar la regla \u00f3ptima de elecci\u00f3n social de la teor\u00eda de la informaci\u00f3n en estrategias dominantes. Mostramos que para la familia de funciones multilineales de valor social -LRB- ese Teorema: Dada cualquier funci\u00f3n multilineal de valor social de cruce simple, y para cualquier n\u00famero de alternativas y jugadores, la regla de elecci\u00f3n social que es \u00f3ptima en teor\u00eda de la informaci\u00f3n es implementable en condiciones dominantes. estrategias. Las funciones multilineales de valor social capturan muchos modelos importantes y bien estudiados e incluyen, por ejemplo, el ejemplo de ruta dado anteriormente y cualquier funci\u00f3n de bienestar social en la que las valoraciones de los jugadores sean lineales en sus tipos -LRB-, como los bienes p\u00fablicos. y subastas -RRB-. La implementabilidad de los mecanismos de informaci\u00f3n te\u00f3ricamente \u00f3ptimos nos permite utilizar una rutina est\u00e1ndar en el dise\u00f1o de mecanismos y primero determinar la regla de elecci\u00f3n social \u00f3ptima y luego calcular los pagos apropiados que aseguren la compatibilidad de incentivos. Para mostrar este resultado, demostramos un lema \u00fatil que ofrece otra caracterizaci\u00f3n de funciones de elecci\u00f3n social cuyo \"precio de implementaci\u00f3n\" es cero. Mostramos que para cualquier funci\u00f3n de elecci\u00f3n social, la compatibilidad de incentivos en mecanismos limitados por acci\u00f3n es equivalente a la propiedad de que el valor social esperado \u00f3ptimo se logra con estrategias no decrecientes -LRB- o estrategias de umbral -RRB-.1 En otras palabras, Este lema implica que siempre se puede implementar, con estrategias dominantes, la mejor regla de elecci\u00f3n social que se pueda lograr con estrategias no decrecientes. Nuestra segunda contribuci\u00f3n es la caracterizaci\u00f3n de los mecanismos \u00f3ptimos de acci\u00f3n limitada. Identificamos algunas condiciones necesarias para la optimizaci\u00f3n de los mecanismos en general y, utilizando estas condiciones, caracterizamos completamente los mecanismos \u00f3ptimos en entornos con dos jugadores y dos alternativas. Completamos la caracterizaci\u00f3n de los mecanismos \u00f3ptimos con la descripci\u00f3n de las estrategias \u00f3ptimas, estrategias que son \"mutuamente maximizadoras\". Dado que los pagos en la implementaci\u00f3n de una estrategia dominante est\u00e1n definidos \u00fanicamente por una asignaci\u00f3n mon\u00f3tona y un perfil de estrategias, esto tambi\u00e9n define los pagos en el mecanismo. Damos una prueba intuitiva de la optimizaci\u00f3n de tales estrategias, generalizando el concepto de estrategias \u00f3ptimas `` mutuamente centradas '' de -LSB- 4 -RSB-. Sorprendentemente, a diferencia de las subastas \u00f3ptimas en -LSB- 4 -RSB-, para algunas funciones de valor social no triviales, el mecanismo \"diagonal\" \u00f3ptimo puede no utilizar todas las k acciones disponibles. Teorema: Para cualquier funci\u00f3n de valor social multilineal de cruce \u00fanico sobre dos alternativas,el mecanismo de acci\u00f3n k de 2 jugadores \u00f3ptima desde el punto de vista informativo es diagonal, y las estrategias dominantes \u00f3ptimas son mutuamente maximizadoras. Lograr una caracterizaci\u00f3n completa del mecanismo \u00f3ptimo limitado a la acci\u00f3n para entornos multijugador o multialternativos parece ser m\u00e1s dif\u00edcil. Para respaldar esta afirmaci\u00f3n, observamos que el n\u00famero de mecanismos que satisfacen las condiciones necesarias mencionadas anteriormente est\u00e1 creciendo exponencialmente en el n\u00famero de jugadores. 1La restricci\u00f3n a estrategias no decrecientes es muy com\u00fan en la literatura. Un resultado notable de Athey -LSB- 1 -RSB- muestra que cuando una estrategia no decreciente es la mejor respuesta para cualquier otro perfil de estrategias no decrecientes, debe existir un equilibrio bayesiano-Nash puro. Nuestro siguiente resultado compara el valor social esperado en los mecanismos de acci\u00f3n k con el valor social esperado \u00f3ptimo cuando el espacio de acci\u00f3n no est\u00e1 restringido. Para cualquier n\u00famero de jugadores o alternativas, y para cualquier perfil de funciones de distribuci\u00f3n independientes, construimos mecanismos que son casi \u00f3ptimos, hasta una diferencia aditiva de O -LRB- k21 -RRB-. Este resultado se logra en las estrategias dominantes. Teorema: Para cualquier funci\u00f3n multilineal de valor social, el mecanismo de acci\u00f3n k \u00f3ptimo incurre en una p\u00e9rdida social esperada de O -LRB- k21 -RRB-. Tenga en cuenta que existen funciones de elecci\u00f3n social que se pueden implementar con k acciones sin p\u00e9rdida alguna -LRB-, por ejemplo, la regla `` elegir siempre la alternativa A '' -RRB-. Sin embargo, sabemos que en algunos entornos -LRB-, por ejemplo, subastas -LSB- 5 -RSB- -RRB- la p\u00e9rdida \u00f3ptima puede ser proporcional a 1k2, por lo que es imposible un mejor l\u00edmite superior general. Finalmente, presentamos nuestros resultados en el context de varias aplicaciones naturales. Primero, damos una soluci\u00f3n expl\u00edcita para un juego de bien p\u00fablico con k-acciones. Esta es una aplicaci\u00f3n natural en nuestro context ya que los niveles educativos suelen ser discretos -LRB-, por ejemplo, BA, MA y PhD -RRB-. El \u00faltimo ejemplo ilustra c\u00f3mo nuestros resultados se aplican a entornos donde el objetivo del planificador social no es la maximizaci\u00f3n del bienestar -LRB- ni variantes del mismo como los ``maximizadores afines'' -RRB-. El resto del art\u00edculo est\u00e1 organizado de la siguiente manera: nuestro modelo y notaciones se describen en la Secci\u00f3n 2. Luego describimos nuestros resultados generales con respecto a la implementaci\u00f3n en entornos multijugador y multialternativos en la Secci\u00f3n 3, incluido el an\u00e1lisis asint\u00f3tico del valor social. p\u00e9rdida. En la Secci\u00f3n 4, caracterizamos completamente los mecanismos \u00f3ptimos para entornos de 2 jugadores con dos alternativas. En la Secci\u00f3n 5, concluimos aplicando nuestros resultados generales a varios modelos bien estudiados. 5. EJEMPLOS Nuestros resultados se aplican a una variedad de entornos econ\u00f3micos, computacionales y en red. En esta secci\u00f3n, demostramos la aplicabilidad de nuestros resultados a modelos de bien p\u00fablico, juegos de se\u00f1alizaci\u00f3n y aplicaciones de enrutamiento. 5.1 Aplicaci\u00f3n 1: Bienes p\u00fablicos El modelo de bien p\u00fablico trata con un planificador social -LRB-, por ejemplo, el gobierno -RRB- que necesita decidir si suministra un bien p\u00fablico, como la construcci\u00f3n de un puente.Sea S\u00ed y No las respectivas alternativas de construir y no construir el puente. v = v1,..., vn es el vector de los tipos de jugadores: los valores que obtienen al usar el puente. La decisi\u00f3n que maximiza el bienestar social es construir el puente si y s\u00f3lo si se construye P, el bienestar social es P i vi es mayor que su costo, denotado por C. La utilidad del jugador i bajo el pago pi es ui = vi - - pi si el puente est\u00e1 construido y 0 en caso contrario. Es bien sabido que sin restricciones en el espacio de acci\u00f3n, es posible inducir una revelaci\u00f3n veraz mediante mecanismos VCG, por lo que se puede lograr una eficiencia total. Obviamente, cuando el conjunto de acciones se limita a k acciones, no podemos lograr la eficiencia total debido a las limitaciones de informaci\u00f3n. Por lo tanto, el mecanismo de acci\u00f3n te\u00f3ricamente \u00f3ptimo para la informaci\u00f3n es implementable en estrategias dominantes. Adem\u00e1s, como sugiere el Teorema 3, en el juego de bien p\u00fablico de dos jugadores de k-acci\u00f3n, podemos caracterizar completamente los mecanismos \u00f3ptimos. En la demostraci\u00f3n del Teorema 3, vimos que cuando para ambos jugadores g -LRB- \u03b8i, \u03b8i, A -RRB- = g -LRB- \u03b8i, \u03b8i, B -RRB-, el mecanismo no es degenerado con respecto a ambos jugadores.6 Esta condici\u00f3n claramente se cumple aqu\u00ed -LRB- 1 + 0 -- C = 0 + 1 -- C -RRB-, por lo tanto, los mecanismos \u00f3ptimos utilizar\u00e1n todas las k acciones. 1. Asignaci\u00f3n: Construya el puente si j '' b1 + b2 > k. Estrategias: Estrategias de umbral basadas en los vectores \u2192 -- x, -- \u2192 y donde para cada 1 < i < k-1, 2. Asignaci\u00f3n : Construya el puente si j '' b1 + b2 > k -- 1. Estrategias: Estrategias de umbral basadas en los vectores \u2192 -- x, -- \u2192 y donde para cada 1 < i < k-1: Recuerde que definimos los mecanismos \u00f3ptimos por su esquema de asignaci\u00f3n y por las estrategias \u00f3ptimas para los jugadores. Es bien sabido que el esquema de asignaci\u00f3n en los mecanismos mon\u00f3tonos define de manera \u00fanica los pagos que aseguran la compatibilidad de los incentivos. En los juegos de bienes p\u00fablicos, estos pagos satisfacen la regla de que un jugador paga el valor m\u00e1s bajo por el cual se construye el puente, cuando la acci\u00f3n del otro jugador es fija. Por lo tanto, los pagos para los jugadores 1 y 2 que informan las acciones b1 y b2 son los siguientes: en el mecanismo 1 de la Proposici\u00f3n 3, p1 = xb2 y p2 = yb1; en el mecanismo 2 de la Proposici\u00f3n 3, p1 = xb2 - 1 y p2 = yb1 - 1. Ahora mostramos un ejemplo m\u00e1s espec\u00edfico que supone distribuciones uniformes. El ejemplo muestra c\u00f3mo el mecanismo \u00f3ptimo est\u00e1 determinado por el costo C: para costos bajos, el mecanismo de tipo 1 es \u00f3ptimo y para costos altos el mecanismo \u00f3ptimo es de tipo 2. Una caracter\u00edstica interesante adicional de los mecanismos \u00f3ptimos en el ejemplo es que son sim\u00e9tricos con respecto a los jugadores. Esto se contrapone a los mecanismos \u00f3ptimos del modelo de subasta -LSB- 5 -RSB- que son asim\u00e9tricos -LRB- incluso cuando los valores de los jugadores se extraen de distribuciones id\u00e9nticas -RRB-. Figura 2: Mecanismos \u00f3ptimos en un juego de bienes p\u00fablicos de 2 jugadores, 2 alternativas y 2 acciones, cuando los tipos est\u00e1n distribuidos uniformemente en -LSB- 0,1 -RSB-. El mecanismo de la izquierda es \u00f3ptimo cuando C < 1 y el otro es \u00f3ptimo cuando C > 1. EJEMPLO 1. Supongamos que los tipos de ambos jugadores est\u00e1n distribuidos uniformemente en -LSB- 0, 1 -RSB-. La Figura 2 ilustra los mecanismos \u00f3ptimos para k = 2 y muestra c\u00f3mo tanto el esquema de asignaci\u00f3n como los pagos dependen del costo de construcci\u00f3n C. Entonces, los mecanismos que maximizan el bienestar son: 5.2 Aplicaci\u00f3n 2: Se\u00f1alizaci\u00f3n Ahora estudiamos un modelo de se\u00f1alizaci\u00f3n en el trabajo. mercados. En este modelo, el tipo de cada trabajador, \u03b8i \u2208 -LSB- \u03b8, \u03b8 -RSB-, describe el nivel de productividad del trabajador. La empresa quiere tomar sus decisiones de contrataci\u00f3n de acuerdo con una funci\u00f3n de decisi\u00f3n f -LRB- \u2212 \u2192 \u03b8 -RRB-. Por ejemplo, la empresa puede querer contratar al trabajador m\u00e1s productivo -LRB- como en el modelo de subasta -RRB-, o contratar a un grupo de trabajadores s\u00f3lo si su suma de productividades es mayor que alg\u00fan umbral -LRB- similar al del bien p\u00fablico. modelo -RRB-. Sin embargo, la productividad del trabajador es invisible para la empresa; la empresa s\u00f3lo observa el nivel educativo del trabajador e, lo que deber\u00eda transmitir se\u00f1ales sobre su nivel de productividad. Tenga en cuenta que el supuesto aqu\u00ed es que adquirir educaci\u00f3n, en cualquier nivel, no afecta la productividad del trabajador, sino que s\u00f3lo indica sus habilidades. Un componente principal de este modelo es el hecho de que a medida que el trabajador es m\u00e1s productivo, le resulta m\u00e1s f\u00e1cil adquirir una educaci\u00f3n de alto nivel. Adem\u00e1s, el costo de adquirir educaci\u00f3n aumenta con el nivel educativo. M\u00e1s formalmente, una funci\u00f3n continua C -LRB- e, \u03b8 -RRB- describe el costo que supone para un trabajador adquirir cada nivel educativo en funci\u00f3n de su productividad. Una acci\u00f3n para un trabajador en este juego es el nivel educativo que elige adquirir. En los modelos est\u00e1ndar, este espacio de acci\u00f3n es continuo, y entonces existe un \"equilibrio de separaci\u00f3n total\" -LRB- bajo las condiciones de cruce simple en la funci\u00f3n de costos -RRB-. Es decir, existe un equilibrio en el que cada tipo se asigna a un nivel educativo diferente; por tanto, la empresa puede inducir los niveles exactos de productividad de los trabajadores mediante este mecanismo de se\u00f1alizaci\u00f3n. Sin embargo, es dif\u00edcil imaginar un mundo con una continuidad de niveles educativos. Generalmente ocurre que s\u00f3lo hay varios niveles educativos discretos -LRB-, por ejemplo, BSc, MSc, PhD -RRB-. Con k niveles de educaci\u00f3n, es posible que la empresa no pueda seguir exactamente la funci\u00f3n de decisi\u00f3n f. Para lograr el mejor resultado en k acciones, la empresa puede querer que los trabajadores jueguen de acuerdo con estrategias de umbral espec\u00edficas. Resulta que la condici\u00f3n est\u00e1ndar, la condici\u00f3n de cruce \u00fanico en la funci\u00f3n de costos, es suficiente para garantizar que estas estrategias de umbral sean dominantes para los jugadores. COROLARIO 4. Considere una funci\u00f3n de decisi\u00f3n multilineal f y una funci\u00f3n de costo de cruce \u00fanico para los jugadores. Con k niveles de educaci\u00f3n, la empresa puede implementar en estrategias dominantes una funci\u00f3n de decisi\u00f3n que incurre en una p\u00e9rdida de O -LRB- k21 -RRB- en comparaci\u00f3n con la funci\u00f3n de decisi\u00f3n f. 5.3 Aplicaci\u00f3n 3: Enrutamiento En nuestro \u00faltimo ejemplo, mostramos la aplicabilidad de nuestros resultados al enrutamiento en redes con p\u00e9rdidas. En tales sistemas, el remitente debe decidir a trav\u00e9s de qu\u00e9 red transmitir su mensaje. En este ejemplo, nos centramos en redes de caminos paralelos. Los bordes de estas redes est\u00e1n controlados por diferentes agentes ego\u00edstas, y cada borde aparece s\u00f3lo en una de las redes. Supongamos que el remitente, que desea enviar un mensaje desde el origen al receptor, conoce la topolog\u00eda de cada red, pero la probabilidad de \u00e9xito en cada enlace, pi, es la informaci\u00f3n privada del enlace. El problema del remitente es decidir si env\u00eda un mensaje a trav\u00e9s de la red N1 o a trav\u00e9s de una red alternativa N2. Obviamente, el remitente desea enviar el mensaje a trav\u00e9s de N1 s\u00f3lo si la probabilidad total de \u00e9xito en N1 es mayor que la probabilidad de \u00e9xito en N2. Sea f N -LRB- \u2212 \u2192 p -RRB- la probabilidad de \u00e9xito en la red N con un vector de probabilidad de \u00e9xito \u2192 \u2212 p. La funci\u00f3n de elecci\u00f3n social en este ejemplo es as\u00ed: c -LRB- \u2212 \u2192 p -RRB- \u2208 argmax -LCB- N1, N2 -RCB- -LCB- fN1 -LRB- \u2212 \u2192 p -RRB-, f N2 -LRB- \u2212 \u2192 p -RRB- -RCB-. Figura 3: Un ejemplo de una red de ruta paralela, donde cada enlace tiene una probabilidad pi de \u00e9xito en la transmisi\u00f3n. Mostramos que la probabilidad general de \u00e9xito en tales redes es multilineal en pi y, por lo tanto, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k \u00f3ptima es implementable mediante estrategia dominante. En este ejemplo, asumimos que cada agente tiene una funci\u00f3n de valoraci\u00f3n de cruce simple sobre las alternativas. Es decir, cada jugador desea que el mensaje se env\u00ede a trav\u00e9s de su red, y su beneficio est\u00e1 correlacionado positivamente con sus datos secretos -LRB-, por ejemplo, la valoraci\u00f3n del jugador i puede ser exactamente pi -RRB-. Nos gustar\u00eda enfatizar que el planificador social en este ejemplo -LRB- y el remitente -RRB- no pretende maximizar el bienestar social. Es decir, el valor social no es la suma de los tipos de jugadores ni ninguna suma ponderada de los tipos -LRB- ``maximizador af\u00edn'' -RRB-. La probabilidad de \u00e9xito de enviar un mensaje a trav\u00e9s de una red de rutas paralelas es multilineal, ya que se puede expresar mediante la siguiente f\u00f3rmula multilineal -LRB- donde P denota el conjunto de todas las rutas entre la fuente y el sumidero -RRB-: Tenga en cuenta que para En cada enlace i, la derivada parcial en pi de la probabilidad de \u00e9xito escrita en la Ecuaci\u00f3n 3 es positiva. En todas las dem\u00e1s redes que no contienen el enlace i, la derivada parcial es claramente cero. Por lo tanto, la funci\u00f3n de valor social es de cruce simple y nuestros resultados generales pueden aplicarse. COROLARIO 5. Para cualquier funci\u00f3n de elecci\u00f3n social que maximice la probabilidad de \u00e9xito en redes de caminos paralelos, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k informativamente \u00f3ptima es implementable -LRB- para cualquier k -RRB-. Reconocimiento. El trabajo del segundo autor tambi\u00e9n cuenta con el apoyo de Lady Davis Trust Fellowship.En tales sistemas, el remitente debe decidir a trav\u00e9s de qu\u00e9 red transmitir su mensaje. En este ejemplo, nos centramos en redes de caminos paralelos. Los bordes de estas redes est\u00e1n controlados por diferentes agentes ego\u00edstas, y cada borde aparece s\u00f3lo en una de las redes. Supongamos que el remitente, que desea enviar un mensaje desde el origen al receptor, conoce la topolog\u00eda de cada red, pero la probabilidad de \u00e9xito en cada enlace, pi, es la informaci\u00f3n privada del enlace. El problema del remitente es decidir si env\u00eda un mensaje a trav\u00e9s de la red N1 o a trav\u00e9s de una red alternativa N2. Obviamente, el remitente desea enviar el mensaje a trav\u00e9s de N1 s\u00f3lo si la probabilidad total de \u00e9xito en N1 es mayor que la probabilidad de \u00e9xito en N2. Sea f N -LRB- \u2212 \u2192 p -RRB- la probabilidad de \u00e9xito en la red N con un vector de probabilidad de \u00e9xito \u2192 \u2212 p. La funci\u00f3n de elecci\u00f3n social en este ejemplo es as\u00ed: c -LRB- \u2212 \u2192 p -RRB- \u2208 argmax -LCB- N1, N2 -RCB- -LCB- fN1 -LRB- \u2212 \u2192 p -RRB-, f N2 -LRB- \u2212 \u2192 p -RRB- -RCB-. Figura 3: Un ejemplo de una red de ruta paralela, donde cada enlace tiene una probabilidad pi de \u00e9xito en la transmisi\u00f3n. Mostramos que la probabilidad general de \u00e9xito en tales redes es multilineal en pi y, por lo tanto, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k \u00f3ptima es implementable mediante estrategia dominante. En este ejemplo, asumimos que cada agente tiene una funci\u00f3n de valoraci\u00f3n de cruce simple sobre las alternativas. Es decir, cada jugador desea que el mensaje se env\u00ede a trav\u00e9s de su red, y su beneficio est\u00e1 correlacionado positivamente con sus datos secretos -LRB-, por ejemplo, la valoraci\u00f3n del jugador i puede ser exactamente pi -RRB-. Nos gustar\u00eda enfatizar que el planificador social en este ejemplo -LRB- y el remitente -RRB- no pretende maximizar el bienestar social. Es decir, el valor social no es la suma de los tipos de jugadores ni ninguna suma ponderada de los tipos -LRB- ``maximizador af\u00edn'' -RRB-. La probabilidad de \u00e9xito de enviar un mensaje a trav\u00e9s de una red de rutas paralelas es multilineal, ya que se puede expresar mediante la siguiente f\u00f3rmula multilineal -LRB- donde P denota el conjunto de todas las rutas entre la fuente y el sumidero -RRB-: Tenga en cuenta que para En cada enlace i, la derivada parcial en pi de la probabilidad de \u00e9xito escrita en la Ecuaci\u00f3n 3 es positiva. En todas las dem\u00e1s redes que no contienen el enlace i, la derivada parcial es claramente cero. Por lo tanto, la funci\u00f3n de valor social es de cruce simple y nuestros resultados generales pueden aplicarse. COROLARIO 5. Para cualquier funci\u00f3n de elecci\u00f3n social que maximice la probabilidad de \u00e9xito en redes de caminos paralelos, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k informativamente \u00f3ptima es implementable -LRB- para cualquier k -RRB-. Reconocimiento. El trabajo del segundo autor tambi\u00e9n cuenta con el apoyo de Lady Davis Trust Fellowship.En tales sistemas, el remitente debe decidir a trav\u00e9s de qu\u00e9 red transmitir su mensaje. En este ejemplo, nos centramos en redes de caminos paralelos. Los bordes de estas redes est\u00e1n controlados por diferentes agentes ego\u00edstas, y cada borde aparece s\u00f3lo en una de las redes. Supongamos que el remitente, que desea enviar un mensaje desde el origen al receptor, conoce la topolog\u00eda de cada red, pero la probabilidad de \u00e9xito en cada enlace, pi, es la informaci\u00f3n privada del enlace. El problema del remitente es decidir si env\u00eda un mensaje a trav\u00e9s de la red N1 o a trav\u00e9s de una red alternativa N2. Obviamente, el remitente desea enviar el mensaje a trav\u00e9s de N1 s\u00f3lo si la probabilidad total de \u00e9xito en N1 es mayor que la probabilidad de \u00e9xito en N2. Sea f N -LRB- \u2212 \u2192 p -RRB- la probabilidad de \u00e9xito en la red N con un vector de probabilidad de \u00e9xito \u2192 \u2212 p. La funci\u00f3n de elecci\u00f3n social en este ejemplo es as\u00ed: c -LRB- \u2212 \u2192 p -RRB- \u2208 argmax -LCB- N1, N2 -RCB- -LCB- fN1 -LRB- \u2212 \u2192 p -RRB-, f N2 -LRB- \u2212 \u2192 p -RRB- -RCB-. Figura 3: Un ejemplo de una red de ruta paralela, donde cada enlace tiene una probabilidad pi de \u00e9xito en la transmisi\u00f3n. Mostramos que la probabilidad general de \u00e9xito en tales redes es multilineal en pi y, por lo tanto, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k \u00f3ptima es implementable mediante estrategia dominante. En este ejemplo, asumimos que cada agente tiene una funci\u00f3n de valoraci\u00f3n de cruce simple sobre las alternativas. Es decir, cada jugador desea que el mensaje se env\u00ede a trav\u00e9s de su red, y su beneficio est\u00e1 correlacionado positivamente con sus datos secretos -LRB-, por ejemplo, la valoraci\u00f3n del jugador i puede ser exactamente pi -RRB-. Nos gustar\u00eda enfatizar que el planificador social en este ejemplo -LRB- y el remitente -RRB- no pretende maximizar el bienestar social. Es decir, el valor social no es la suma de los tipos de jugadores ni ninguna suma ponderada de los tipos -LRB- ``maximizador af\u00edn'' -RRB-. La probabilidad de \u00e9xito de enviar un mensaje a trav\u00e9s de una red de rutas paralelas es multilineal, ya que se puede expresar mediante la siguiente f\u00f3rmula multilineal -LRB- donde P denota el conjunto de todas las rutas entre la fuente y el sumidero -RRB-: Tenga en cuenta que para En cada enlace i, la derivada parcial en pi de la probabilidad de \u00e9xito escrita en la Ecuaci\u00f3n 3 es positiva. En todas las dem\u00e1s redes que no contienen el enlace i, la derivada parcial es claramente cero. Por lo tanto, la funci\u00f3n de valor social es de cruce simple y nuestros resultados generales pueden aplicarse. COROLARIO 5. Para cualquier funci\u00f3n de elecci\u00f3n social que maximice la probabilidad de \u00e9xito en redes de caminos paralelos, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k informativamente \u00f3ptima es implementable -LRB- para cualquier k -RRB-. Reconocimiento. El trabajo del segundo autor tambi\u00e9n cuenta con el apoyo de Lady Davis Trust Fellowship.y cada borde aparece solo en una de las redes. Supongamos que el remitente, que desea enviar un mensaje desde el origen al receptor, conoce la topolog\u00eda de cada red, pero la probabilidad de \u00e9xito en cada enlace, pi, es la informaci\u00f3n privada del enlace. El problema del remitente es decidir si env\u00eda un mensaje a trav\u00e9s de la red N1 o a trav\u00e9s de una red alternativa N2. Obviamente, el remitente desea enviar el mensaje a trav\u00e9s de N1 s\u00f3lo si la probabilidad total de \u00e9xito en N1 es mayor que la probabilidad de \u00e9xito en N2. Sea f N -LRB- \u2212 \u2192 p -RRB- la probabilidad de \u00e9xito en la red N con un vector de probabilidad de \u00e9xito \u2192 \u2212 p. La funci\u00f3n de elecci\u00f3n social en este ejemplo es as\u00ed: c -LRB- \u2212 \u2192 p -RRB- \u2208 argmax -LCB- N1, N2 -RCB- -LCB- fN1 -LRB- \u2212 \u2192 p -RRB-, f N2 -LRB- \u2212 \u2192 p -RRB- -RCB-. Figura 3: Un ejemplo de una red de ruta paralela, donde cada enlace tiene una probabilidad pi de \u00e9xito en la transmisi\u00f3n. Mostramos que la probabilidad general de \u00e9xito en tales redes es multilineal en pi y, por lo tanto, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k \u00f3ptima es implementable mediante estrategia dominante. En este ejemplo, asumimos que cada agente tiene una funci\u00f3n de valoraci\u00f3n de cruce simple sobre las alternativas. Es decir, cada jugador desea que el mensaje se env\u00ede a trav\u00e9s de su red, y su beneficio est\u00e1 correlacionado positivamente con sus datos secretos -LRB-, por ejemplo, la valoraci\u00f3n del jugador i puede ser exactamente pi -RRB-. Nos gustar\u00eda enfatizar que el planificador social en este ejemplo -LRB- y el remitente -RRB- no pretende maximizar el bienestar social. Es decir, el valor social no es la suma de los tipos de jugadores ni ninguna suma ponderada de los tipos -LRB- ``maximizador af\u00edn'' -RRB-. La probabilidad de \u00e9xito de enviar un mensaje a trav\u00e9s de una red de rutas paralelas es multilineal, ya que se puede expresar mediante la siguiente f\u00f3rmula multilineal -LRB- donde P denota el conjunto de todas las rutas entre la fuente y el sumidero -RRB-: Tenga en cuenta que para En cada enlace i, la derivada parcial en pi de la probabilidad de \u00e9xito escrita en la Ecuaci\u00f3n 3 es positiva. En todas las dem\u00e1s redes que no contienen el enlace i, la derivada parcial es claramente cero. Por lo tanto, la funci\u00f3n de valor social es de cruce simple y nuestros resultados generales pueden aplicarse. COROLARIO 5. Para cualquier funci\u00f3n de elecci\u00f3n social que maximice la probabilidad de \u00e9xito en redes de caminos paralelos, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k informativamente \u00f3ptima es implementable -LRB- para cualquier k -RRB-. Reconocimiento. El trabajo del segundo autor tambi\u00e9n cuenta con el apoyo de Lady Davis Trust Fellowship.y cada borde aparece solo en una de las redes. Supongamos que el remitente, que desea enviar un mensaje desde el origen al receptor, conoce la topolog\u00eda de cada red, pero la probabilidad de \u00e9xito en cada enlace, pi, es la informaci\u00f3n privada del enlace. El problema del remitente es decidir si env\u00eda un mensaje a trav\u00e9s de la red N1 o a trav\u00e9s de una red alternativa N2. Obviamente, el remitente desea enviar el mensaje a trav\u00e9s de N1 s\u00f3lo si la probabilidad total de \u00e9xito en N1 es mayor que la probabilidad de \u00e9xito en N2. Sea f N -LRB- \u2212 \u2192 p -RRB- la probabilidad de \u00e9xito en la red N con un vector de probabilidad de \u00e9xito \u2192 \u2212 p. La funci\u00f3n de elecci\u00f3n social en este ejemplo es as\u00ed: c -LRB- \u2212 \u2192 p -RRB- \u2208 argmax -LCB- N1, N2 -RCB- -LCB- fN1 -LRB- \u2212 \u2192 p -RRB-, f N2 -LRB- \u2212 \u2192 p -RRB- -RCB-. Figura 3: Un ejemplo de una red de ruta paralela, donde cada enlace tiene una probabilidad pi de \u00e9xito en la transmisi\u00f3n. Mostramos que la probabilidad general de \u00e9xito en tales redes es multilineal en pi y, por lo tanto, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k \u00f3ptima es implementable mediante estrategia dominante. En este ejemplo, asumimos que cada agente tiene una funci\u00f3n de valoraci\u00f3n de cruce simple sobre las alternativas. Es decir, cada jugador desea que el mensaje se env\u00ede a trav\u00e9s de su red, y su beneficio est\u00e1 correlacionado positivamente con sus datos secretos -LRB-, por ejemplo, la valoraci\u00f3n del jugador i puede ser exactamente pi -RRB-. Nos gustar\u00eda enfatizar que el planificador social en este ejemplo -LRB- y el remitente -RRB- no pretende maximizar el bienestar social. Es decir, el valor social no es la suma de los tipos de jugadores ni ninguna suma ponderada de los tipos -LRB- ``maximizador af\u00edn'' -RRB-. La probabilidad de \u00e9xito de enviar un mensaje a trav\u00e9s de una red de rutas paralelas es multilineal, ya que se puede expresar mediante la siguiente f\u00f3rmula multilineal -LRB- donde P denota el conjunto de todas las rutas entre la fuente y el sumidero -RRB-: Tenga en cuenta que para En cada enlace i, la derivada parcial en pi de la probabilidad de \u00e9xito escrita en la Ecuaci\u00f3n 3 es positiva. En todas las dem\u00e1s redes que no contienen el enlace i, la derivada parcial es claramente cero. Por lo tanto, la funci\u00f3n de valor social es de cruce simple y nuestros resultados generales pueden aplicarse. COROLARIO 5. Para cualquier funci\u00f3n de elecci\u00f3n social que maximice la probabilidad de \u00e9xito en redes de caminos paralelos, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k informativamente \u00f3ptima es implementable -LRB- para cualquier k -RRB-. Reconocimiento. El trabajo del segundo autor tambi\u00e9n cuenta con el apoyo de Lady Davis Trust Fellowship.el remitente desea enviar el mensaje a trav\u00e9s de N1 s\u00f3lo si la probabilidad total de \u00e9xito en N1 es mayor que la probabilidad de \u00e9xito en N2. Sea f N -LRB- \u2212 \u2192 p -RRB- la probabilidad de \u00e9xito en la red N con un vector de probabilidad de \u00e9xito \u2192 \u2212 p. La funci\u00f3n de elecci\u00f3n social en este ejemplo es as\u00ed: c -LRB- \u2212 \u2192 p -RRB- \u2208 argmax -LCB- N1, N2 -RCB- -LCB- fN1 -LRB- \u2212 \u2192 p -RRB-, f N2 -LRB- \u2212 \u2192 p -RRB- -RCB-. Figura 3: Un ejemplo de una red de ruta paralela, donde cada enlace tiene una probabilidad pi de \u00e9xito en la transmisi\u00f3n. Mostramos que la probabilidad general de \u00e9xito en tales redes es multilineal en pi y, por lo tanto, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k \u00f3ptima es implementable mediante estrategia dominante. En este ejemplo, asumimos que cada agente tiene una funci\u00f3n de valoraci\u00f3n de cruce simple sobre las alternativas. Es decir, cada jugador desea que el mensaje se env\u00ede a trav\u00e9s de su red, y su beneficio est\u00e1 correlacionado positivamente con sus datos secretos -LRB-, por ejemplo, la valoraci\u00f3n del jugador i puede ser exactamente pi -RRB-. Nos gustar\u00eda enfatizar que el planificador social en este ejemplo -LRB- y el remitente -RRB- no pretende maximizar el bienestar social. Es decir, el valor social no es la suma de los tipos de jugadores ni ninguna suma ponderada de los tipos -LRB- ``maximizador af\u00edn'' -RRB-. La probabilidad de \u00e9xito de enviar un mensaje a trav\u00e9s de una red de rutas paralelas es multilineal, ya que se puede expresar mediante la siguiente f\u00f3rmula multilineal -LRB- donde P denota el conjunto de todas las rutas entre la fuente y el sumidero -RRB-: Tenga en cuenta que para En cada enlace i, la derivada parcial en pi de la probabilidad de \u00e9xito escrita en la Ecuaci\u00f3n 3 es positiva. En todas las dem\u00e1s redes que no contienen el enlace i, la derivada parcial es claramente cero. Por lo tanto, la funci\u00f3n de valor social es de cruce simple y nuestros resultados generales pueden aplicarse. COROLARIO 5. Para cualquier funci\u00f3n de elecci\u00f3n social que maximice la probabilidad de \u00e9xito en redes de caminos paralelos, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k informativamente \u00f3ptima es implementable -LRB- para cualquier k -RRB-. Reconocimiento. El trabajo del segundo autor tambi\u00e9n cuenta con el apoyo de Lady Davis Trust Fellowship.el remitente desea enviar el mensaje a trav\u00e9s de N1 s\u00f3lo si la probabilidad total de \u00e9xito en N1 es mayor que la probabilidad de \u00e9xito en N2. Sea f N -LRB- \u2212 \u2192 p -RRB- la probabilidad de \u00e9xito en la red N con un vector de probabilidad de \u00e9xito \u2192 \u2212 p. La funci\u00f3n de elecci\u00f3n social en este ejemplo es as\u00ed: c -LRB- \u2212 \u2192 p -RRB- \u2208 argmax -LCB- N1, N2 -RCB- -LCB- fN1 -LRB- \u2212 \u2192 p -RRB-, f N2 -LRB- \u2212 \u2192 p -RRB- -RCB-. Figura 3: Un ejemplo de una red de ruta paralela, donde cada enlace tiene una probabilidad pi de \u00e9xito en la transmisi\u00f3n. Mostramos que la probabilidad general de \u00e9xito en tales redes es multilineal en pi y, por lo tanto, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k \u00f3ptima es implementable mediante estrategia dominante. En este ejemplo, asumimos que cada agente tiene una funci\u00f3n de valoraci\u00f3n de cruce simple sobre las alternativas. Es decir, cada jugador desea que el mensaje se env\u00ede a trav\u00e9s de su red, y su beneficio est\u00e1 correlacionado positivamente con sus datos secretos -LRB-, por ejemplo, la valoraci\u00f3n del jugador i puede ser exactamente pi -RRB-. Nos gustar\u00eda enfatizar que el planificador social en este ejemplo -LRB- y el remitente -RRB- no pretende maximizar el bienestar social. Es decir, el valor social no es la suma de los tipos de jugadores ni ninguna suma ponderada de los tipos -LRB- ``maximizador af\u00edn'' -RRB-. La probabilidad de \u00e9xito de enviar un mensaje a trav\u00e9s de una red de rutas paralelas es multilineal, ya que se puede expresar mediante la siguiente f\u00f3rmula multilineal -LRB- donde P denota el conjunto de todas las rutas entre la fuente y el sumidero -RRB-: Tenga en cuenta que para En cada enlace i, la derivada parcial en pi de la probabilidad de \u00e9xito escrita en la Ecuaci\u00f3n 3 es positiva. En todas las dem\u00e1s redes que no contienen el enlace i, la derivada parcial es claramente cero. Por lo tanto, la funci\u00f3n de valor social es de cruce simple y nuestros resultados generales pueden aplicarse. COROLARIO 5. Para cualquier funci\u00f3n de elecci\u00f3n social que maximice la probabilidad de \u00e9xito en redes de caminos paralelos, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k informativamente \u00f3ptima es implementable -LRB- para cualquier k -RRB-. Reconocimiento. El trabajo del segundo autor tambi\u00e9n cuenta con el apoyo de Lady Davis Trust Fellowship.y su beneficio est\u00e1 correlacionado positivamente con sus datos secretos -LRB-, por ejemplo, la valoraci\u00f3n del jugador i puede ser exactamente pi -RRB-. Nos gustar\u00eda enfatizar que el planificador social en este ejemplo -LRB- y el remitente -RRB- no pretende maximizar el bienestar social. Es decir, el valor social no es la suma de los tipos de jugadores ni ninguna suma ponderada de los tipos -LRB- ``maximizador af\u00edn'' -RRB-. La probabilidad de \u00e9xito de enviar un mensaje a trav\u00e9s de una red de rutas paralelas es multilineal, ya que se puede expresar mediante la siguiente f\u00f3rmula multilineal -LRB- donde P denota el conjunto de todas las rutas entre la fuente y el sumidero -RRB-: Tenga en cuenta que para En cada enlace i, la derivada parcial en pi de la probabilidad de \u00e9xito escrita en la Ecuaci\u00f3n 3 es positiva. En todas las dem\u00e1s redes que no contienen el enlace i, la derivada parcial es claramente cero. Por lo tanto, la funci\u00f3n de valor social es de cruce simple y nuestros resultados generales pueden aplicarse. COROLARIO 5. Para cualquier funci\u00f3n de elecci\u00f3n social que maximice la probabilidad de \u00e9xito en redes de caminos paralelos, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k informativamente \u00f3ptima es implementable -LRB- para cualquier k -RRB-. Reconocimiento. El trabajo del segundo autor tambi\u00e9n cuenta con el apoyo de Lady Davis Trust Fellowship.y su beneficio est\u00e1 correlacionado positivamente con sus datos secretos -LRB-, por ejemplo, la valoraci\u00f3n del jugador i puede ser exactamente pi -RRB-. Nos gustar\u00eda enfatizar que el planificador social en este ejemplo -LRB- y el remitente -RRB- no pretende maximizar el bienestar social. Es decir, el valor social no es la suma de los tipos de jugadores ni ninguna suma ponderada de los tipos -LRB- ``maximizador af\u00edn'' -RRB-. La probabilidad de \u00e9xito de enviar un mensaje a trav\u00e9s de una red de rutas paralelas es multilineal, ya que se puede expresar mediante la siguiente f\u00f3rmula multilineal -LRB- donde P denota el conjunto de todas las rutas entre la fuente y el sumidero -RRB-: Tenga en cuenta que para En cada enlace i, la derivada parcial en pi de la probabilidad de \u00e9xito escrita en la Ecuaci\u00f3n 3 es positiva. En todas las dem\u00e1s redes que no contienen el enlace i, la derivada parcial es claramente cero. Por lo tanto, la funci\u00f3n de valor social es de cruce simple y nuestros resultados generales pueden aplicarse. COROLARIO 5. Para cualquier funci\u00f3n de elecci\u00f3n social que maximice la probabilidad de \u00e9xito en redes de caminos paralelos, la funci\u00f3n de elecci\u00f3n social de acci\u00f3n k informativamente \u00f3ptima es implementable -LRB- para cualquier k -RRB-. Reconocimiento. El trabajo del segundo autor tambi\u00e9n cuenta con el apoyo de Lady Davis Trust Fellowship.", "keyphrases": ["espacio de acci\u00f3n limitado", "implementar", "estrategia de dominio", "funci\u00f3n de elecci\u00f3n social", "funci\u00f3n decisiva", "condici\u00f3n de cruz simple", "funci\u00f3n multilineal", "mecanico optimo", "mecanismo ligado a la acci\u00f3n", "probabilidad de \u00e9xito"]}
{"file_name": "C-19", "text": "Interfaz de servicio: una nueva abstracci\u00f3n para implementar y componer protocolos * RESUMEN En este art\u00edculo comparamos dos enfoques para el dise\u00f1o de marcos de protocolos: herramientas para implementar protocolos de red modulares. El enfoque m\u00e1s com\u00fan utiliza eventos como abstracci\u00f3n principal para una interacci\u00f3n local entre m\u00f3dulos de protocolo. Sostenemos que un enfoque alternativo, basado en la abstracci\u00f3n de servicios, es m\u00e1s adecuado para expresar protocolos modulares. Tambi\u00e9n facilita funciones avanzadas en el dise\u00f1o de protocolos, como la actualizaci\u00f3n din\u00e1mica de protocolos distribuidos. Luego describimos una implementaci\u00f3n experimental de un marco de protocolo basado en servicios en Java. 1. INTRODUCCI\u00d3N Permiten implementar protocolos complejos descomponi\u00e9ndolos en varios m\u00f3dulos cooperando entre s\u00ed. Este enfoque facilita la reutilizaci\u00f3n de c\u00f3digo y la personalizaci\u00f3n de protocolos distribuidos para satisfacer las necesidades de diferentes aplicaciones. Adem\u00e1s, los m\u00f3dulos de protocolo se pueden conectar al sistema de forma din\u00e1mica. Todas estas caracter\u00edsticas de los marcos de protocolo los convierten en una tecnolog\u00eda habilitadora interesante para implementar sistemas adaptables -LSB- 14 -RSB-, una clase importante de aplicaciones. La mayor\u00eda de los marcos de protocolos se basan en eventos -LRB-. Todos los marcos citados anteriormente se basan en esta abstracci\u00f3n -RRB-. Los eventos se utilizan para la comunicaci\u00f3n asincr\u00f3nica entre diferentes m\u00f3dulos en la misma m\u00e1quina. Por ejemplo, la composici\u00f3n de m\u00f3dulos puede requerir conectores para enrutar eventos, lo que introduce una carga para un compositor de protocolo -LSB- 4 -RSB-. Los marcos de protocolo como Appia y Eva ampl\u00edan el enfoque basado en eventos con canales. Sin embargo, en nuestra opini\u00f3n, esta soluci\u00f3n no es satisfactoria ya que la composici\u00f3n de pilas de protocolos complejas se vuelve m\u00e1s dif\u00edcil. En este art\u00edculo, proponemos un nuevo enfoque para construir protocolos modulares, que se basa en una abstracci\u00f3n de servicios. Comparamos este nuevo enfoque con el enfoque com\u00fan basado en eventos. Mostramos que los marcos de protocolos basados \u200b\u200ben servicios tienen varias ventajas, por ejemplo, permiten una composici\u00f3n de protocolos bastante sencilla, una implementaci\u00f3n clara y un mejor soporte para el reemplazo din\u00e1mico de protocolos distribuidos. Para validar nuestras afirmaciones, hemos implementado SAMOA, un marco de protocolo experimental que se basa exclusivamente en el enfoque basado en servicios para la composici\u00f3n e implementaci\u00f3n de m\u00f3dulos. El marco nos permiti\u00f3 comparar las implementaciones basadas en servicios y eventos de un middleware de comunicaci\u00f3n grupal adaptable. La secci\u00f3n 2 define nociones generales. La Secci\u00f3n 3 presenta las principales caracter\u00edsticas de los marcos basados \u200b\u200ben eventos y las caracter\u00edsticas que son distintas para cada marco. La secci\u00f3n 4 describe nuestro nuevo enfoque, que se basa en la abstracci\u00f3n de servicios. La secci\u00f3n 5 analiza las ventajas de un marco de protocolo basado en servicios en comparaci\u00f3n con un marco de protocolo basado en eventos. La descripci\u00f3n de nuestra implementaci\u00f3n experimental se presenta en la Secci\u00f3n 6. Finalmente, concluimos en la Secci\u00f3n 7. 7. CONCLUSI\u00d3N En el art\u00edculo,Propusimos un nuevo enfoque para la composici\u00f3n del protocolo que se basa en la noci\u00f3n de interfaz de servicio, en lugar de eventos. Creemos que el marco basado en servicios tiene varias ventajas sobre los marcos basados \u200b\u200ben eventos. Una implementaci\u00f3n de prototipo nos permiti\u00f3 validar nuestras ideas.", "keyphrases": ["marco de protocolo", "algoritmo de distribuci\u00f3n", "sistema de distribuci\u00f3n", "interfaz de servicio", "red", "comun", "marco basado en eventos", "pila", "m\u00f3dulo", "pedido", "responder"]}
{"file_name": "I-21", "text": "Interacciones entre barreras de mercado y redes de comunicaci\u00f3n en sistemas de marketing RESUMEN Investigamos un marco en el que los agentes buscan productos satisfactorios utilizando referencias de otros agentes. Nuestro modelo de un mecanismo para transmitir el boca a boca y los efectos conductuales resultantes se basa en la integraci\u00f3n de un m\u00f3dulo que gobierna el comportamiento local de los agentes con un m\u00f3dulo que gobierna la estructura y funci\u00f3n de la red subyacente de agentes. El comportamiento local incorpora un modelo de elecci\u00f3n satisfactorio, un conjunto de reglas que rigen las interacciones entre agentes, incluido el aprendizaje sobre la confiabilidad de otros agentes a lo largo del tiempo, y restricciones externas al comportamiento que pueden ser impuestas por barreras de mercado o costos de cambio. El comportamiento local tiene lugar en un sustrato de red a trav\u00e9s del cual los agentes intercambian informaci\u00f3n positiva y negativa sobre los productos. Utilizamos varias distribuciones de grados que dictan el grado de conectividad e incorporamos tanto efectos de mundo peque\u00f1o como la noci\u00f3n de v\u00ednculo preferencial en nuestros modelos de red. Comparamos la efectividad de los sistemas de referencia en varias estructuras de red para tareas de elecci\u00f3n f\u00e1cil y dif\u00edcil, y evaluamos c\u00f3mo esta efectividad cambia con la imposici\u00f3n de barreras de mercado. 1. INTRODUCCI\u00d3N El comportamiento de deserci\u00f3n, es decir, el motivo por el que las personas podr\u00edan dejar de utilizar un determinado producto o servicio, depende en gran medida de la afinidad psicol\u00f3gica o satisfacci\u00f3n que sienten hacia el producto que utilizan actualmente -LSB- 14 -RSB- y de la disponibilidad de otros m\u00e1s atractivos. alternativas -LSB- 17 -RSB-. Sin embargo, en muchos casos la decisi\u00f3n de desertar o no tambi\u00e9n depende de diversas limitaciones externas que se imponen al comportamiento de cambio, ya sea por la estructura del mercado, o por los propios proveedores -LRB- en forma de contratos formales o informales. -RRB-, u otros denominados \"costes de cambio\" o barreras de mercado -LSB- 12, 5 -RSB-. La caracter\u00edstica clave de todos estos casos es que el grado en que la afinidad psicol\u00f3gica juega un papel en la toma de decisiones real est\u00e1 limitado por barreras del mercado, de modo que los agentes no pueden seguir aquellos cursos de acci\u00f3n que ser\u00edan m\u00e1s satisfactorios en un mercado sin restricciones. Si bien el nivel de satisfacci\u00f3n con un producto actualmente utilizado depender\u00e1 en gran medida de las propias experiencias del producto durante el per\u00edodo de uso, es probable que se obtenga conocimiento de alternativas potencialmente m\u00e1s satisfactorias aumentando la informaci\u00f3n obtenida de las experiencias personales. experiencias con informaci\u00f3n sobre las experiencias de otros recopiladas a trav\u00e9s de la comunicaci\u00f3n informal de boca en boca. Adem\u00e1s, existe una relaci\u00f3n importante entre las barreras del mercado y la comunicaci\u00f3n boca a boca. En presencia de barreras de mercado, los agentes econ\u00f3micos restringidos atrapados en relaciones de productos insatisfactorias tender\u00e1n a difundir esta informaci\u00f3n a otros agentes. En ausencia de tales barreras,los agentes son libres de desertar de productos insatisfactorios y, por lo tanto, la comunicaci\u00f3n boca a boca tender\u00eda a ser positiva. Dado que la imposici\u00f3n de al menos algunas formas de barreras al mercado es a menudo una decisi\u00f3n estrat\u00e9gica tomada por los proveedores de productos, estas relaciones pueden ser clave para el \u00e9xito de un proveedor en particular. Adem\u00e1s, la relaci\u00f3n entre las barreras del mercado y la comunicaci\u00f3n boca a boca puede ser rec\u00edproca. La estructura y funci\u00f3n de la red a trav\u00e9s de la cual se lleva a cabo la comunicaci\u00f3n boca a boca, y en particular la forma en que la red cambia en respuesta a la imposici\u00f3n de barreras de mercado, tambi\u00e9n influyen en la determinaci\u00f3n de qu\u00e9 barreras de mercado son m\u00e1s efectivas. Un marco de modelo basado en agentes permite una investigaci\u00f3n al nivel del tomador de decisiones individual, en el 2. ANTECEDENTES 2.1 Comunicaci\u00f3n de boca en boca El papel de la comunicaci\u00f3n de boca en boca en el comportamiento de sistemas complejos se ha estudiado en modelos tanto anal\u00edticos como de simulaci\u00f3n. Las investigaciones del boca a boca basadas en simulaci\u00f3n -LSB- 6, 13 -RSB- se han centrado en desarrollar estrategias para garantizar que un sistema alcance un nivel de equilibrio en el que todos los agentes est\u00e9n satisfechos, en gran medida aprendiendo sobre la eficacia de las referencias de otros o variando el grado de inercia en el comportamiento individual. El marco de simulaci\u00f3n permite un modelado del entorno m\u00e1s complejo que los modelos anal\u00edticos, en los que las referencias son aleatorias y s\u00f3lo hay dos opciones disponibles, y el trabajo en -LSB- 6 -RSB- en particular es un antecedente cercano del trabajo. presentado en este art\u00edculo, siendo nuestra principal contribuci\u00f3n incluir la estructura de la red y las restricciones impuestas por las barreras del mercado como efectos adicionales. 2.2 Barreras de mercado La medida en que las barreras de mercado influyen en el comportamiento de los sistemas atrae la atenci\u00f3n principalmente de los economistas interesados \u200b\u200ben c\u00f3mo las barreras distorsionan la competencia y de los especialistas en marketing interesados \u200b\u200ben c\u00f3mo las barreras distorsionan las elecciones de los consumidores. Una tipolog\u00eda \u00fatil de barreras de mercado distingue barreras \"transaccionales\" asociadas con el costo monetario de cambiar -LRB-, por ejemplo en servicios financieros -RRB-, barreras de \"aprendizaje\" asociadas con la decisi\u00f3n de reemplazar productos existentes bien conocidos, y barreras \"contractuales\" que imponen restricciones legales para la duraci\u00f3n del contrato -LSB- 12 -RSB-. Una tipolog\u00eda diferente -LSB- 5 -RSB- introduce el aspecto adicional de barreras \"relacionales\" que surgen de las relaciones personales que pueden estar entrelazadas con el uso de un producto en particular. En general, hay poca evidencia emp\u00edrica sobre la relaci\u00f3n entre la creaci\u00f3n de barreras para el cambio y la retenci\u00f3n de una base de clientes, y hasta donde sabemos, no hay trabajos previos que utilicen modelos basados \u200b\u200ben agentes para generar hallazgos emp\u00edricos. Burnham et al.-LSB- 5 -RSB- encuentran que las barreras de mercado percibidas representan casi el doble de la variaci\u00f3n en la intenci\u00f3n de permanecer con un producto que la explicada por la satisfacci\u00f3n con el producto -LRB- 30 % y 16 % respectivamente -RRB-, y que as\u00ed- Las llamadas barreras relacionales son considerablemente m\u00e1s influyentes que las barreras transaccionales o de aprendizaje. Adem\u00e1s, encuentran que los consumidores perciben que los costos de cambio existen incluso en mercados que son fluidos y donde las barreras parecen ser d\u00e9biles. En pocas palabras, las barreras del mercado parecen desempe\u00f1ar un papel m\u00e1s importante en lo que hace la gente que la satisfacci\u00f3n; y su presencia puede ser m\u00e1s generalizada de lo que generalmente se piensa. 5. CONCLUSIONES Y TRABAJOS RELACIONADOS El comportamiento de compra en muchos mercados tiene lugar sobre un sustrato de redes de comunicaci\u00f3n boca a boca a trav\u00e9s de las cuales los agentes intercambian informaci\u00f3n sobre productos y sus gustos y disgustos. Comprender las formas en que los flujos de comunicaci\u00f3n de boca en boca influyen en el comportamiento del mercado agregado requiere estudiar tanto las propiedades estructurales subyacentes de la red como las reglas locales que gobiernan el comportamiento de los agentes en la red cuando toman decisiones de compra y cuando interact\u00faan con otros. agentes. Estas reglas locales a menudo est\u00e1n limitadas por la naturaleza de un mercado particular o impuestas por proveedores estrat\u00e9gicos o costumbres sociales. La modelizaci\u00f3n adecuada de un mecanismo de transmisi\u00f3n de boca en boca y los efectos conductuales resultantes requiere, por tanto, la consideraci\u00f3n de una serie de componentes complejos que interact\u00faan: redes de comunicaci\u00f3n, credibilidad de la fuente, procesos de aprendizaje, habituaci\u00f3n y memoria, restricciones externas al comportamiento, teor\u00edas. de transferencia de informaci\u00f3n y comportamiento adaptativo. En este art\u00edculo hemos intentado abordar algunas de estas cuestiones de una manera que refleje c\u00f3mo podr\u00edan actuar los agentes en el mundo real. Es el hallazgo final el que probablemente sea m\u00e1s sorprendente y m\u00e1s relevante en la pr\u00e1ctica para el campo de la investigaci\u00f3n de mercados, y sugiere que no siempre ser\u00e1 lo mejor para un l\u00edder del mercado imponer barreras que impidan que los clientes se vayan. En las redes mal conectadas, el efecto de las barreras sobre las cuotas de mercado es leve. Por el contrario, en redes bien conectadas, el boca a boca negativo puede impedir que los agentes prueben un producto que de otro modo les habr\u00eda parecido satisfactorio, y esto puede infligir un da\u00f1o significativo a la participaci\u00f3n de mercado. Los productos con una peque\u00f1a cuota de mercado -LRB- que, en el context de nuestras simulaciones, generalmente se debe al producto que ofrece un rendimiento deficiente -RRB-, no se ven relativamente afectados por el boca a boca negativo, ya que la mayor\u00eda de las pruebas de productos probablemente no sean satisfactorias en cualquier caso. El modelado basado en agentes proporciona una forma natural de comenzar a investigar los tipos de din\u00e1micas que ocurren en los sistemas de marketing. Naturalmente, la utilidad de los resultados depende en gran medida de la calidad del modelado de los dos \"m\u00f3dulos\" que comprenden la estructura de la red y el comportamiento local. Del lado de la red,El trabajo futuro podr\u00eda investigar la relaci\u00f3n entre las distribuciones de grados, la forma en que se crean y destruyen las conexiones a lo largo del tiempo, si el apego preferencial es influyente y en qu\u00e9 medida la identidad social informa la estructura de la red, todo en redes m\u00e1s grandes de agentes m\u00e1s heterog\u00e9neos. Desde el punto de vista del comportamiento, se podr\u00eda observar la adaptaci\u00f3n de los umbrales de satisfacci\u00f3n durante el curso de la comunicaci\u00f3n, las respuestas a cambios sistem\u00e1ticos en el desempe\u00f1o de los productos a lo largo del tiempo, la integraci\u00f3n de varias fuentes de informaci\u00f3n y diferentes estructuras de barreras del mercado. Todas estas \u00e1reas brindan oportunidades fascinantes para introducir realidades psicol\u00f3gicas en modelos de sistemas de marketing y observar el comportamiento resultante del sistema bajo descripciones de escenarios cada vez m\u00e1s realistas.", "keyphrases": ["sistema de referencia", "comportamiento de compra", "comunicaci\u00f3n de boca en boca", "sistema de mercado", "comportamiento defectuoso", "psic\u00f3logo af\u00edn", "cambiar de comportamiento", "modelo de base de agentes", "psic\u00f3logo social", "barrera del mercado", "elecci\u00f3n de consumo", "costo del cambio"]}
{"file_name": "C-34", "text": "Investigaciones sobre el esquema de establecimiento de claves por pares para redes de sensores distribuidas RESUMEN Los esquemas de seguridad de establecimiento de claves por pares, que permiten a los sensores comunicarse entre s\u00ed de forma segura, desempe\u00f1an un papel fundamental en la investigaci\u00f3n sobre problemas de seguridad en redes de sensores inal\u00e1mbricas. Se presenta un nuevo tipo de modelo de distribuci\u00f3n de redes de sensores desplegados en cl\u00faster, y en base al cual, un innovador modelo de Hipercubo Jer\u00e1rquico - H -LRB- k, u, m, v, n -RRB- y la relaci\u00f3n de mapeo entre las redes de sensores desplegados en cl\u00faster y Se proponen los H -LRB- k, u, m, v, n -RRB-. Utilizando buenas propiedades del modelo H -LRB- k, u, m, v, n -RRB-, se dise\u00f1a un nuevo marco general para la predistribuci\u00f3n de claves por pares y un nuevo algoritmo de establecimiento de claves por pares, que combina la idea de KDC -LRB- Centro de Distribuci\u00f3n de Claves -RRB- y esquemas de pool polin\u00f3mico. Adem\u00e1s, se inspecciona seriamente el rendimiento del algoritmo de establecimiento de claves por pares recientemente propuesto. El an\u00e1lisis te\u00f3rico y las cifras experimentales muestran que el nuevo algoritmo tiene un mejor rendimiento y proporciona mayores posibilidades para que el sensor establezca claves por pares, en comparaci\u00f3n con trabajos relacionados anteriores. 1. INTRODUCCI\u00d3N La comunicaci\u00f3n de seguridad es un requisito importante en muchas aplicaciones de redes de sensores, por lo que se utilizan claves secretas compartidas entre nodos en comunicaci\u00f3n para cifrar datos. Como uno de los servicios de seguridad m\u00e1s fundamentales, el establecimiento de claves por pares permite que los nodos sensores se comuniquen de forma segura entre s\u00ed mediante t\u00e9cnicas criptogr\u00e1ficas. Sin embargo, debido a las capacidades computacionales limitadas de los nodos sensores, la energ\u00eda de la bater\u00eda y la memoria disponible, no les es factible utilizar t\u00e9cnicas tradicionales de establecimiento de claves por pares, como la criptograf\u00eda de clave p\u00fablica y el centro de distribuci\u00f3n de claves -LRB-KDC-RRB-. Recientemente se han desarrollado varios enfoques alternativos para realizar el establecimiento de claves por pares en redes de sensores con recursos limitados sin implicar el uso de criptograf\u00eda tradicional -LSB-14-RSB-. Eschenauer y Gligor propusieron un esquema b\u00e1sico de predistribuci\u00f3n de claves probabil\u00edsticas para el establecimiento de claves por pares -LSB- 1 -RSB-. En el esquema, cada nodo sensor elige aleatoriamente un conjunto de claves de un conjunto de claves antes de la implementaci\u00f3n, de modo que dos nodos sensores tengan una cierta probabilidad de compartir al menos una clave com\u00fan. Chan et al. ampli\u00f3 a\u00fan m\u00e1s esta idea y present\u00f3 dos esquemas de predistribuci\u00f3n de claves: un esquema de predistribuci\u00f3n de claves compuestas q y un esquema de claves aleatorias por pares. El esquema q-compuesto requiere que dos sensores cualesquiera compartan al menos q claves predistribuidas. El esquema aleatorio selecciona aleatoriamente un par de sensores y asigna a cada par una clave aleatoria \u00fanica -LSB- 2 -RSB-. Bas\u00e1ndose en dicho marco, presentaron dos esquemas de predistribuci\u00f3n de claves por pares: un esquema de asignaci\u00f3n de subconjuntos aleatorios y un esquema basado en cuadr\u00edculas. En esos esquemas se utiliza un grupo polin\u00f3mico, en lugar de utilizar un grupo de claves en las t\u00e9cnicas anteriores.El esquema de asignaci\u00f3n de subconjuntos aleatorios asigna a cada nodo sensor los secretos generados a partir de un subconjunto aleatorio de polinomios en el grupo de polinomios. El esquema basado en cuadr\u00edcula asocia polinomios con las filas y columnas de una cuadr\u00edcula artificial, asigna a cada nodo sensor una coordenada \u00fanica en la cuadr\u00edcula y le da al nodo los secretos generados a partir de los polinomios de filas y columnas correspondientes. Con base en esta cuadr\u00edcula, cada nodo sensor puede identificar si puede establecer directamente una clave por pares con otro nodo y, en caso contrario, con qu\u00e9 nodos intermedios puede contactar para establecer indirectamente la clave por pares. Du et al desarrollaron de forma independiente un enfoque similar a los esquemas descritos por Liu et al. -LSB- 5 -RSB-. En lugar de basarse en el esquema de Blundo, su enfoque se basa en el esquema de Blom -LSB- 6 -RSB-. Todos los esquemas anteriores mejoran la seguridad con respecto al esquema b\u00e1sico de predistribuci\u00f3n de claves probabil\u00edsticas. Sin embargo, el problema del establecimiento de claves por pares en las redes de sensores a\u00fan no est\u00e1 bien resuelto. Para los esquemas de predistribuci\u00f3n de claves probabil\u00edsticos b\u00e1sicos y q-compuestos, a medida que aumenta el n\u00famero de nodos comprometidos, la fracci\u00f3n de claves por pares afectadas aumenta r\u00e1pidamente. Como resultado, una peque\u00f1a cantidad de nodos comprometidos puede afectar una gran fracci\u00f3n de claves por pares -LSB- 3 -RSB-. Aunque el esquema de claves aleatorias por pares no sufre el problema de seguridad anterior, genera una gran sobrecarga de memoria, que aumenta linealmente con el n\u00famero de nodos en la red si el nivel de seguridad se mantiene constante -LSB- 2 -RSB- -LSB - 4 -RSB-. Para el esquema de asignaci\u00f3n aleatoria de subconjuntos, sufre mayores gastos generales de comunicaci\u00f3n y c\u00e1lculo. En 2004, Liu propuso un nuevo esquema de predistribuci\u00f3n de claves por pares basado en hipercubos -LSB-7-RSB-, que extiende el esquema basado en cuadr\u00edculas desde una cuadr\u00edcula bidimensional a un hipercubo multidimensional. El an\u00e1lisis muestra que el esquema basado en hipercubo mantiene algunas propiedades atractivas del esquema basado en cuadr\u00edcula, incluida la garant\u00eda de establecer claves por pares y la resistencia a los compromisos de los nodos. Adem\u00e1s, cuando se requiere una seguridad perfecta contra el compromiso de los nodos, el esquema basado en hipercubo puede admitir una red m\u00e1s grande agregando m\u00e1s dimensiones en lugar de aumentar la sobrecarga de almacenamiento en los nodos sensores. Aunque el esquema basado en hipercubo -LRB- consideramos que el esquema basado en cuadr\u00edcula es un caso especial del esquema basado en hipercubo -RRB- que tiene muchas propiedades atractivas, requiere que dos nodos cualesquiera en las redes de sensores puedan comunicarse directamente entre s\u00ed. Esta fuerte suposici\u00f3n no es pr\u00e1ctica en la mayor\u00eda de las aplicaciones reales de las redes de sensores. En este art\u00edculo, presentamos una especie de nuevo modelo de distribuci\u00f3n de redes de sensores basado en clusters, y para el cual proponemos un nuevo esquema de predistribuci\u00f3n de claves por pares. Con base en la topolog\u00eda, proponemos un novedoso modelo de hipercubo jer\u00e1rquico basado en la distribuci\u00f3n de conglomerados para establecer la clave por pares. Desarrollamos una especie de nuevo algoritmo de establecimiento de claves por pares con nuestro modelo de hipercubo jer\u00e1rquico.La estructura de este art\u00edculo se organiza de la siguiente manera: en la secci\u00f3n 3, se presenta un nuevo modelo de distribuci\u00f3n de redes de sensores implementadas en cl\u00faster. En la secci\u00f3n 4, se propone un nuevo modelo de Hipercubo Jer\u00e1rquico. En la secci\u00f3n 5, se analiza la relaci\u00f3n de mapeo entre la red de sensores implementada por los cl\u00fasteres y el modelo de hipercubo jer\u00e1rquico. En las secciones 6 y 7, se dise\u00f1an nuevos algoritmos de establecimiento de claves por pares basados \u200b\u200ben el modelo de hipercubo jer\u00e1rquico y se describen an\u00e1lisis detallados. Finalmente, la secci\u00f3n 8 presenta una conclusi\u00f3n. 2. Definici\u00f3n PRELIMINAR 1 -LRB- Predistribuci\u00f3n de claves -RRB-: El procedimiento, que se utiliza para codificar los correspondientes algoritmos de cifrado y descifrado en los nodos sensores antes de la distribuci\u00f3n, se denomina Predistribuci\u00f3n de claves. Definici\u00f3n 2 -LRB- Clave por pares -RRB-: Para dos nodos A y B cualesquiera, si tienen una clave com\u00fan E, entonces la clave E se denomina clave por pares entre ellos. 8. CONCLUSI\u00d3N Se propone un nuevo modelo de hipercubo jer\u00e1rquico denominado H -LRB- k, u, m, v, n -RRB-, que puede usarse para la predistribuci\u00f3n de claves por pares para redes de sensores implementadas en cl\u00fasteres. Y bas\u00e1ndose en el modelo H -LRB- k, u, m, v, n -RRB-, se dise\u00f1a respectivamente un innovador esquema y algoritmo de predistribuci\u00f3n de claves por pares, combinando las buenas propiedades de los esquemas de cifrado de clave polin\u00f3mica y conjunto de claves. Por lo tanto, el algoritmo tradicional de predistribuci\u00f3n de claves por pares basado en el modelo de hipercubo -LSB-7-RSB- es s\u00f3lo un caso especial del nuevo algoritmo propuesto en este art\u00edculo. Los an\u00e1lisis te\u00f3ricos y experimentales muestran que el algoritmo recientemente propuesto es un algoritmo eficiente de establecimiento de claves por pares que es adecuado para las redes de sensores implementadas en cl\u00faster.combinando las buenas propiedades de los esquemas de cifrado de clave polin\u00f3mica y conjunto de claves. Por lo tanto, el algoritmo tradicional de predistribuci\u00f3n de claves por pares basado en el modelo de hipercubo -LSB-7-RSB- es s\u00f3lo un caso especial del nuevo algoritmo propuesto en este art\u00edculo. Los an\u00e1lisis te\u00f3ricos y experimentales muestran que el algoritmo recientemente propuesto es un algoritmo eficiente de establecimiento de claves por pares que es adecuado para las redes de sensores implementadas en cl\u00faster.combinando las buenas propiedades de los esquemas de cifrado de clave polin\u00f3mica y conjunto de claves. Por lo tanto, el algoritmo tradicional de predistribuci\u00f3n de claves por pares basado en el modelo de hipercubo -LSB-7-RSB- es s\u00f3lo un caso especial del nuevo algoritmo propuesto en este art\u00edculo. Los an\u00e1lisis te\u00f3ricos y experimentales muestran que el algoritmo recientemente propuesto es un algoritmo eficiente de establecimiento de claves por pares que es adecuado para las redes de sensores implementadas en cl\u00faster.", "keyphrases": ["red de sensores", "piscina kei", "kei predistribuir", "modelo de hipercubo jerarca", "asegurar", "algoritmo de establecimiento de pairwis kei", "modelo de distribuci\u00f3n basado en clusters", "polinomi kei", "cifrar", "c\u00f3digo de nodo", "alta tolerancia a fallas"]}
{"file_name": "H-32", "text": "Pepitas interesantes y su impacto en la respuesta a preguntas definitorias RESUMEN Los enfoques actuales para identificar oraciones definitorias en el context de la respuesta a preguntas implican principalmente el uso de patrones ling\u00fc\u00edsticos o sint\u00e1cticos para identificar pepitas informativas. Esto es insuficiente ya que no abordan el factor de novedad que tambi\u00e9n debe poseer una pepita de definici\u00f3n. Este art\u00edculo propone abordar la deficiencia mediante la construcci\u00f3n de un ``Modelo de Inter\u00e9s Humano'' a partir del conocimiento externo. Se espera que dicho modelo permita calcular el inter\u00e9s humano en la oraci\u00f3n con respecto al tema. Comparamos y contrastamos nuestro modelo con los modelos actuales de respuesta a preguntas de definici\u00f3n para mostrar que el inter\u00e9s juega un factor importante en la respuesta a preguntas de definici\u00f3n. 1. RESPUESTA A PREGUNTAS DEFINICIONALES La respuesta a preguntas de definici\u00f3n se introdujo por primera vez en la tarea principal de la pista de respuesta a preguntas de la Conferencia de recuperaci\u00f3n de texts en 2003. Las preguntas de definici\u00f3n, tambi\u00e9n denominadas Otras preguntas en los \u00faltimos a\u00f1os, se definen de la siguiente manera. Dado un tema de pregunta X, la tarea de un sistema de definici\u00f3n de control de calidad es similar a responder la pregunta \"\u00bfQu\u00e9 es X?\". ''. El sistema de control de calidad por definici\u00f3n consiste en buscar en un corpus de noticias y devolver un conjunto de respuestas que describan mejor el tema de la pregunta. Cada respuesta debe ser una pepita \u00fanica y espec\u00edfica de un tema que constituya una faceta en la definici\u00f3n del tema de la pregunta. 1.1 Los dos aspectos de los bloques de temas Oficialmente, los bloques de respuestas espec\u00edficos de un tema o simplemente los bloques de temas se describen como `` bloques informativos ''. Cada pepita informativa es un fragmento de oraci\u00f3n que describe informaci\u00f3n objetiva sobre el tema. A partir de la observaci\u00f3n del conjunto de respuestas a las preguntas de definici\u00f3n de TREC 2003 a 2005, parece que un n\u00famero significativo de elementos tem\u00e1ticos no pueden describirse simplemente como elementos informativos. M\u00e1s bien, estos temas tienen una cualidad similar a una trivia asociada. Por lo general, se trata de informaci\u00f3n fuera de lo com\u00fan sobre un tema que puede despertar el inter\u00e9s de un lector humano. Por esta raz\u00f3n, decidimos definir las pepitas de respuesta que pueden evocar el inter\u00e9s humano como \"pepitas interesantes\". En esencia, hay pepitas interesantes que responden a las preguntas \"\u00bfPor qu\u00e9 es famoso X?\" '' , `` \u00bfQu\u00e9 define a X? ''. Ahora tenemos dos perspectivas muy diferentes sobre lo que constituye una respuesta a las preguntas de Definici\u00f3n. Una respuesta puede ser alguna informaci\u00f3n f\u00e1ctica importante sobre el tema o alg\u00fan aspecto novedoso e interesante sobre el tema. Esta dualidad de informaci\u00f3n e inter\u00e9s se puede observar claramente en las cinco respuestas vitales para un tema del TREC 2005 de \"George Foreman\". Ciertas pepitas de respuesta son m\u00e1s informativas, mientras que otras son de naturaleza m\u00e1s interesante. Nuggets informativos: se convirti\u00f3 en el campe\u00f3n mundial m\u00e1s antiguo en la historia del boxeo. Nuggets interesantes: regresaron al boxeo despu\u00e9s de una pausa de 10 a\u00f1os. Como se ve aqu\u00ed,Las pepitas interesantes tienen alg\u00fan factor sorpresa o cualidad \u00fanica que las hace interesantes para los lectores humanos. 1.2 Identificaci\u00f3n de pepitas interesantes Dado que la descripci\u00f3n oficial original de las definiciones incluye la identificaci\u00f3n de pepitas informativas, la mayor\u00eda de las investigaciones se han centrado por completo en identificar pepitas informativas. En este art\u00edculo, nos centramos en explorar las propiedades de pepitas interesantes y desarrollar formas de identificarlas. Se desarrolla un sistema de respuesta a preguntas definitorias del ''Modelo de Inter\u00e9s Humano'' con \u00e9nfasis en identificar pepitas interesantes para evaluar el impacto de las pepitas interesantes en el desempe\u00f1o de un sistema de respuesta a preguntas definitorias. Adem\u00e1s, experimentamos combinando el modelo de inter\u00e9s humano con un sistema de respuesta a preguntas definitorias basado en patrones l\u00e9xicos para capturar pepitas tanto informativas como interesantes. 2. TRABAJO RELACIONADO Actualmente existen dos m\u00e9todos generales para responder preguntas definitorias. El m\u00e9todo m\u00e1s com\u00fan que utiliza un enfoque basado en patrones l\u00e9xicos fue propuesto por primera vez por Blair-Goldensohn et al. -LSB- 1 -RSB- y Xu et al. -LSB- 14 -RSB-. Ambos grupos utilizaron predominantemente patrones como c\u00f3pulas y apositivos, as\u00ed como patrones lexicosint\u00e1cticos elaborados manualmente para identificar oraciones que contienen pepitas informativas. Por ejemplo, Xu et al. utiliz\u00f3 40 `` patrones estructurados '' definidos manualmente en su sistema de respuesta a preguntas de definici\u00f3n de 2003. Desde entonces, en un intento por capturar una clase m\u00e1s amplia de pepitas de informaci\u00f3n, se han creado muchos sistemas de este tipo de complejidad creciente. Un sistema reciente de Harabagiu et al. -LSB- 6 -RSB- cre\u00f3 un sistema de respuesta a preguntas definitorias que combina el uso de 150 patrones positivos y negativos definidos manualmente, relaciones de entidades nombradas y plantillas de extracci\u00f3n de informaci\u00f3n especialmente dise\u00f1adas para 33 dominios de destino. Como se puede imaginar, este es un enfoque intensivo en conocimiento que requiere que un ling\u00fcista experto defina manualmente todos los patrones l\u00e9xicos o sint\u00e1cticos posibles necesarios para identificar tipos espec\u00edficos de informaci\u00f3n. En lugar de codificar patrones manualmente, las respuestas a evaluaciones de preguntas de definici\u00f3n anteriores se convirtieron en patrones gen\u00e9ricos y se entrena un modelo probabil\u00edstico para identificar dichos patrones en oraciones. Se ha demostrado que este enfoque de patrones l\u00e9xicosint\u00e1cticos es adecuado para identificar datos informativos como la fecha de nacimiento de una persona o el nombre del director ejecutivo de una empresa. Sin embargo, estos patrones son aplicables globalmente a todos los temas o a un conjunto espec\u00edfico de entidades como m\u00fasicos u organizaciones. Esto contrasta directamente con las interesantes pepitas que son muy espec\u00edficas de temas individuales y no de un conjunto de entidades. Por ejemplo, las pepitas interesantes para George Foreman son espec\u00edficas s\u00f3lo de George Foreman y de ning\u00fan otro boxeador o ser humano. Por lo tanto, la especificidad o relevancia del tema es un criterio importante que ayuda a identificar pepitas interesantes.Esto lleva a la exploraci\u00f3n del segundo enfoque basado en la relevancia que se ha utilizado en la respuesta a preguntas de definici\u00f3n. Predominantemente, este enfoque se ha utilizado como m\u00e9todo de respaldo para identificar oraciones definitorias cuando el m\u00e9todo primario de patrones l\u00e9xicosint\u00e1cticos no logr\u00f3 encontrar un n\u00famero suficiente de pepitas informativas -LSB- 1 -RSB-. Tambi\u00e9n se ha utilizado un enfoque similar como sistema de referencia para TREC 2003 -LSB-14-RSB-. M\u00e1s recientemente, Chen et al. -LSB- 3 -RSB- adapt\u00f3 un modelo de lenguaje bigrama o bit\u00e9rmino para la respuesta a preguntas definitorias. Generalmente, el enfoque basado en la relevancia requiere un ``corpus de definici\u00f3n'' que contenga documentos muy relevantes para el tema. El sistema de referencia de TREC 2003 simplemente utiliza las palabras tem\u00e1ticas como corpus de definici\u00f3n. Blair-Goldensohn et al. -LSB- 1 -RSB- utiliza un aprendizaje autom\u00e1tico para incluir en el corpus definitorio oraciones que probablemente sean definitorias. Chen et al. -LSB- 3 -RSB- recopila fragmentos de Google para crear su corpus definitorio. A partir del corpus de definici\u00f3n, se construye un vector centroide de definici\u00f3n o se selecciona un conjunto de palabras centroides. Este vector centroide o conjunto de palabras centroides se considera altamente indicativo del tema. Luego, los sistemas pueden usar este centroide para identificar respuestas definitorias mediante el uso de una variedad de m\u00e9tricas de distancia para compararlas con oraciones encontradas en el conjunto de documentos recuperados para el tema. BlairGoldensohn et al. -LSB- 1 -RSB- utiliza la similitud del coseno para clasificar oraciones por \"centralidad\". Como se describe aqu\u00ed, el enfoque basado en la relevancia es muy espec\u00edfico de temas individuales debido a su dependencia de un corpus de definici\u00f3n espec\u00edfico del tema. Sin embargo, si las oraciones individuales se ven como un documento, entonces los enfoques basados \u200b\u200ben la relevancia utilizan esencialmente las palabras centroides espec\u00edficas del tema recopiladas como una forma de recuperaci\u00f3n de documentos con expansi\u00f3n de consultas automatizada para identificar oraciones muy relevantes. Por lo tanto, tales m\u00e9todos identifican oraciones relevantes y no oraciones que contienen pepitas de definici\u00f3n. Sin embargo, el sistema de referencia TREC 2003 -LSB-14-RSB- super\u00f3 a todos los dem\u00e1s sistemas excepto a uno. El modelo de lenguaje bi-t\u00e9rmino -LSB- 3 -RSB- es capaz de informar resultados que son altamente competitivos con los resultados del estado del arte utilizando este enfoque basado en la recuperaci\u00f3n. En TREC 2006, un modelo de suma ponderada simple de todos los t\u00e9rminos con t\u00e9rminos ponderados utilizando \u00fanicamente fragmentos de Google super\u00f3 a todos los dem\u00e1s sistemas por un margen significativo -LSB- 7 -RSB-. Creemos que los detalles interesantes a menudo vienen en forma de trivia, hechos novedosos o raros sobre el tema que tienden a coexistir fuertemente con la menci\u00f3n directa de las palabras clave del tema. Esto puede explicar por qu\u00e9 el m\u00e9todo basado en la relevancia puede funcionar de manera competitiva en la respuesta a preguntas de definici\u00f3n. Sin embargo, la simple comparaci\u00f3n con un \u00fanico vector centroide o un conjunto de palabras centroides puede haber enfatizado demasiado la relevancia del tema y solo ha identificado pepitas de definici\u00f3n interesantes de manera indirecta. A\u00fan,Los m\u00e9todos de recuperaci\u00f3n basados \u200b\u200ben la relevancia se pueden utilizar como punto de partida para identificar pepitas interesantes. Describiremos c\u00f3mo ampliamos dichos m\u00e9todos para identificar pepitas interesantes en la siguiente secci\u00f3n. 7. CONCLUSI\u00d3N Este art\u00edculo ha presentado una perspectiva novedosa para responder preguntas de definici\u00f3n a trav\u00e9s de la identificaci\u00f3n de pepitas interesantes. Las pepitas interesantes son piezas de informaci\u00f3n poco comunes sobre el tema que pueden evocar la curiosidad del lector humano. La noci\u00f3n de un \"lector humano promedio\" es una consideraci\u00f3n importante en nuestro enfoque. Esto es muy diferente del enfoque de patrones l\u00e9xico-sint\u00e1cticos donde el context de un lector humano ni siquiera se considera al encontrar respuestas a preguntas de definici\u00f3n. Utilizando esta perspectiva, hemos demostrado que utilizando una combinaci\u00f3n de un corpus externo cuidadosamente seleccionado, compar\u00e1ndolo con m\u00faltiples centroides y teniendo en cuenta t\u00e9rminos raros pero muy espec\u00edficos de un tema, podemos construir un m\u00f3dulo de respuesta a preguntas definitorias que se centre m\u00e1s en identificar pepitas que son de inter\u00e9s para los seres humanos. Los resultados experimentales han demostrado que este enfoque puede superar significativamente a los sistemas de respuesta a preguntas definitorios de \u00faltima generaci\u00f3n. Adem\u00e1s, demostramos que se requieren al menos dos tipos diferentes de fragmentos de respuestas para formar un conjunto m\u00e1s completo de respuestas definitorias. Lo que parece ser un buen conjunto de respuestas de definici\u00f3n es informaci\u00f3n general que proporciona una descripci\u00f3n general informativa r\u00e1pida combinada con algunos aspectos novedosos o interesantes sobre el tema. Por lo tanto, creemos que un buen sistema de respuesta a preguntas sobre definiciones necesitar\u00eda recoger tipos de pepitas tanto informativas como interesantes para proporcionar una cobertura definitoria completa de todos los aspectos importantes del tema. De hecho, esto es natural ya que los dos modelos han sido dise\u00f1ados para identificar dos tipos muy diferentes de respuestas de definici\u00f3n utilizando tipos de caracter\u00edsticas muy diferentes. Como resultado, actualmente solo podemos lograr un sistema h\u00edbrido que tenga el mismo nivel de desempe\u00f1o que nuestro Modelo de Inter\u00e9s Humano propuesto. Abordamos el problema de la respuesta a preguntas de definici\u00f3n desde una perspectiva novedosa, con la noci\u00f3n de que el factor de inter\u00e9s juega un papel en la identificaci\u00f3n de respuestas de definici\u00f3n. Aunque los m\u00e9todos que utilizamos son simples, se ha demostrado experimentalmente que son efectivos. Nuestro enfoque tambi\u00e9n puede proporcionar una idea de algunas anomal\u00edas en ensayos anteriores de respuesta a preguntas sobre definiciones. Por ejemplo, el sistema de definici\u00f3n m\u00e1s alto en la reciente evaluaci\u00f3n TREC 2006 fue capaz de superar significativamente a todos los dem\u00e1s sistemas utilizando probabilidades de unigramas relativamente simples extra\u00eddas de fragmentos de Google. Sospechamos que el principal contribuyente al desempe\u00f1o del sistema Tabla 3: TREC 2005 Temas agrupados por tipo de entidad En nuestro trabajo futuro, buscamos mejorar a\u00fan m\u00e1s el sistema combinado incorporando m\u00e1s evidencia que respalde las respuestas de definici\u00f3n correctas o filtrando las respuestas obvias. respuestas incorrectas.", "keyphrases": ["nosotros de ling\u00fcista", "conocimiento externo", "c\u00e1lculo de inter\u00e9s humano", "nueva corporacion", "tema de la pregunta", "informar pepita", "fragmento de oraci\u00f3n", "lector humano", "inter\u00e9s", "pepita de inter\u00e9s", "calidad unica", "factor sorpresa", "patr\u00f3n l\u00e9xico", "labor manual", "sistema de base"]}
{"file_name": "I-4", "text": "Coordinaci\u00f3n de metanivel para resolver cadenas de negociaci\u00f3n en sistemas semicooperativos de m\u00faltiples agentes RESUMEN Una cadena de negociaci\u00f3n se forma cuando m\u00faltiples negociaciones relacionadas se distribuyen entre m\u00faltiples agentes. Para ordenar y estructurar adecuadamente las negociaciones que ocurren en la cadena para optimizar la utilidad esperada, presentamos una extensi\u00f3n a un marco de negociaci\u00f3n concurrente de un solo agente. Este trabajo est\u00e1 dirigido a sistemas multiagente semi-cooperativos, donde cada agente tiene sus propios objetivos y trabaja para maximizar su utilidad local; sin embargo, el desempe\u00f1o de cada agente individual est\u00e1 estrechamente relacionado con la cooperaci\u00f3n de otros agentes y el desempe\u00f1o general del sistema. Introducimos una fase previa a la negociaci\u00f3n que permite a los agentes transferir informaci\u00f3n de metanivel. Utilizando esta informaci\u00f3n, el agente puede construir un modelo m\u00e1s preciso de la negociaci\u00f3n en t\u00e9rminos de modelar la relaci\u00f3n de flexibilidad y probabilidad de \u00e9xito. Este modelo m\u00e1s preciso ayuda al agente a elegir una mejor soluci\u00f3n de negociaci\u00f3n en el context de la cadena de negociaci\u00f3n global. El agente tambi\u00e9n puede utilizar esta informaci\u00f3n para asignar el tiempo adecuado para cada negociaci\u00f3n y as\u00ed encontrar un buen orden de todas las negociaciones relacionadas. Los datos experimentales muestran que estos mecanismos mejoran significativamente el rendimiento general de los agentes y del sistema. 1. INTRODUCCI\u00d3N La negociaci\u00f3n sofisticada para la asignaci\u00f3n de tareas y recursos es crucial para la pr\u00f3xima generaci\u00f3n de aplicaciones de sistemas multiagente -LRB- MAS -RRB-. Los grupos de agentes necesitan negociar eficientemente sobre m\u00faltiples temas relacionados al mismo tiempo en un entorno complejo y distribuido donde existen fechas l\u00edmite para completar las negociaciones. Esta es un \u00e1rea de investigaci\u00f3n importante en la que se ha trabajado muy poco. Este trabajo est\u00e1 dirigido a sistemas multiagente semi-cooperativos, donde cada agente tiene sus propios objetivos y trabaja para maximizar su utilidad local; sin embargo, el desempe\u00f1o de cada agente individual est\u00e1 estrechamente relacionado con la cooperaci\u00f3n de otros agentes y el desempe\u00f1o general del sistema. No existe un \u00fanico objetivo global en tales sistemas, ya sea porque cada agente representa una organizaci\u00f3n/usuario diferente, o porque es dif\u00edcil/imposible dise\u00f1ar un \u00fanico objetivo global. Este problema surge debido a m\u00faltiples tareas concurrentes, limitaciones de recursos e incertidumbres y, por lo tanto, ning\u00fan agente tiene suficiente conocimiento o recursos computacionales para determinar qu\u00e9 es lo mejor para todo el sistema -LSB- 11 -RSB-. Para realizar tareas que llegan continuamente a la organizaci\u00f3n virtual, se necesita y se prefiere la cooperaci\u00f3n y la reubicaci\u00f3n de subtareas. No existe un objetivo global \u00fanico ya que cada agente puede estar involucrado en m\u00faltiples organizaciones virtuales. Mientras tanto, el desempe\u00f1o de cada agente individual est\u00e1 estrechamente relacionado con la cooperaci\u00f3n de otros agentes y el desempe\u00f1o general de la organizaci\u00f3n virtual. La negociaci\u00f3n en tales sistemas no es un juego de suma cero,Se puede llegar a un acuerdo que aumente las utilidades de ambos agentes mediante una negociaci\u00f3n eficiente. Adem\u00e1s, hay m\u00faltiples encuentros entre agentes ya que todo el tiempo llegan nuevas tareas. En tales negociaciones, el precio puede ser importante o no, ya que puede fijarse como resultado de un contrato a largo plazo. Otros factores como la calidad y el tiempo de entrega tambi\u00e9n son importantes. Los mecanismos de reputaci\u00f3n en el sistema hacen que hacer trampa no sea atractivo desde un punto de vista a largo plazo debido a los m\u00faltiples encuentros entre agentes. Otra diferencia importante entre este trabajo y otros trabajos sobre negociaci\u00f3n es que aqu\u00ed la negociaci\u00f3n no se considera un proceso independiente. M\u00e1s bien es una parte de la actividad del agente que est\u00e1 estrechamente entrelazada con la planificaci\u00f3n, programaci\u00f3n y ejecuci\u00f3n de las actividades del agente, que tambi\u00e9n pueden estar relacionadas con otras negociaciones. Con base en este reconocimiento, este trabajo sobre negociaci\u00f3n se preocupa m\u00e1s por el proceso de toma de decisiones a nivel meta en la negociaci\u00f3n que por los protocolos o lenguajes b\u00e1sicos. se lleven a cabo las negociaciones. Estas macroestrategias son diferentes de aquellas microestrategias que dirigen el hilo de la negociaci\u00f3n individual, como por ejemplo si el agente debe ceder y cu\u00e1nto debe ceder, etc. -LSB- 3 -RSB-. En este art\u00edculo ampliamos un modelo de negociaci\u00f3n multivinculado -LSB- 10 -RSB- desde una perspectiva de un solo agente a una perspectiva de m\u00faltiples agentes, de modo que un grupo de agentes involucrados en cadenas de negociaciones interrelacionadas puedan encontrar una negociaci\u00f3n macro casi \u00f3ptima. estrategias para proseguir sus negociaciones. La Secci\u00f3n 2 describe el proceso de negociaci\u00f3n b\u00e1sico y revisa brevemente el modelo de negociaci\u00f3n multivinculada de un solo agente. La secci\u00f3n 3 presenta un escenario complejo de cadena de suministro. La secci\u00f3n 4 detalla c\u00f3mo resolver los problemas que surgen en la cadena de negociaci\u00f3n. La secci\u00f3n 5 informa sobre el trabajo experimental. La Secci\u00f3n 6 analiza el trabajo relacionado y la Secci\u00f3n 7 presenta conclusiones y \u00e1reas de trabajo futuro. 2. ANTECEDENTES DE LA NEGOCIACI\u00d3N MULTIV\u00cdNCULA Este proceso puede ir y venir hasta que se llegue a un acuerdo o los agentes decidan detenerse. Si se llega a un acuerdo y un agente no puede cumplir el compromiso, debe pagar a la otra parte una multa de liberaci\u00f3n como se especifica en el compromiso. Una negociaci\u00f3n comienza con una propuesta, que anuncia que se debe realizar una tarea -LRB- t -RRB- incluye los siguientes atributos: 1. fecha l\u00edmite -LRB- dl -RRB-: la \u00faltima hora de finalizaci\u00f3n de la tarea; la tarea debe estar terminada antes de la fecha l\u00edmite dl. 3. requisito m\u00ednimo de calidad -LRB- minq -RRB-: la tarea debe finalizar con un logro de calidad no menor que minq. 4. recompensa regular -LRB- r -RRB-: si la tarea se completa seg\u00fan lo solicitado en el contrato, el agente contratista obtendr\u00e1 la recompensa r. 5. Tasa de recompensa por finalizaci\u00f3n anticipada -LRB- e -RRB-: si el agente contratista puede terminar la tarea antes de dl, obtendr\u00e1 la recompensa adicional por finalizaci\u00f3n anticipada proporcional a esta tasa. 6.El problema de la negociaci\u00f3n multivinculada tiene dos dimensiones: las negociaciones y los temas de las negociaciones. Las negociaciones est\u00e1n interrelacionadas y los temas est\u00e1n interrelacionados; los atributos de las negociaciones y los atributos de los sujetos tambi\u00e9n est\u00e1n interrelacionados. Esta complejidad bidimensional de las interrelaciones lo distingue del cl\u00e1sico problema de gesti\u00f3n de proyectos o problema de programaci\u00f3n, donde todas las tareas a programar son tareas locales y no se necesita negociaci\u00f3n. 1. duraci\u00f3n de la negociaci\u00f3n -LRB- \u03b4 -LRB- v -RRB- -RRB-: el tiempo m\u00e1ximo permitido para que se complete la negociaci\u00f3n v, ya sea alcanzando una propuesta acordada -LRB- exitosa -RRB- o sin acuerdo -LRB- fracaso - RRB-. 2. hora de inicio de la negociaci\u00f3n -LRB- \u03b1 -LRB- v -RRB- -RRB-: la hora de inicio de la negociaci\u00f3n v. \u03b1 -LRB- v -RRB- es un atributo que debe ser decidido por el agente. 3. fecha l\u00edmite de negociaci\u00f3n -LRB- e -LRB- v -RRB- -RRB-: la negociaci\u00f3n v debe finalizar antes de esta fecha l\u00edmite e -LRB- v -RRB-. La negociaci\u00f3n ya no es v\u00e1lida despu\u00e9s del tiempo e -LRB- v -RRB-, que es lo mismo que un resultado fallido de esta negociaci\u00f3n. 4. Depende de un conjunto de atributos, que incluyen tanto los atributos en negociaci\u00f3n -LRB- es decir, recompensa, flexibilidad, etc. -RRB- como los atributos-de-negociaci\u00f3n -LRB- es decir, hora de inicio de la negociaci\u00f3n, fecha l\u00edmite de negociaci\u00f3n, etc. RRB-. Un agente involucrado en m\u00faltiples procesos de negociaci\u00f3n relacionados necesita razonar sobre c\u00f3mo gestionar estas negociaciones en t\u00e9rminos de ordenarlas y elegir los valores apropiados para las caracter\u00edsticas. Este es el problema de negociaci\u00f3n multienlace -LSB- 10 -RSB- : \u03c1 -LRB- v -RRB- -RRB-, que describe la relaci\u00f3n entre la negociaci\u00f3n v y sus hijos. La relaci\u00f3n AND asociada con una negociaci\u00f3n v significa que el cumplimiento exitoso del compromiso en v requiere que todos sus nodos secundarios tengan logros exitosos. La relaci\u00f3n OR asociada con una negociaci\u00f3n v significa que el cumplimiento exitoso del compromiso en v requiere que al menos un nodo secundario lo haya logrado con \u00e9xito, donde los m\u00faltiples nodos secundarios representan alternativas para lograr el mismo objetivo. El problema de negociaci\u00f3n multivinculado es un problema de optimizaci\u00f3n local. Resolver un problema de negociaci\u00f3n multienlazado es encontrar una soluci\u00f3n de negociaci\u00f3n -LRB- 0, \u03d5 -RRB- con utilidad esperada optimizada Elf -LRB- 0, \u03d5 -RRB-, que se define como: Un orden de negociaci\u00f3n 0 define una soluci\u00f3n parcial orden de todos los temas de negociaci\u00f3n. Una asignaci\u00f3n de caracter\u00edsticas \u03d5 es una funci\u00f3n de mapeo que asigna un valor a cada atributo que debe decidirse en la negociaci\u00f3n. Un resultado de negociaci\u00f3n \u03c7 para un conjunto de negociaciones -LCB- vj 1, -LRB- j = 1,..., n -RRB- especifica el resultado de cada negociaci\u00f3n, ya sea exitosa o fallida. Hay un total de 2n resultados diferentes para n negociaciones: -LCB- chii1, -LRB- i = 1,..., 2n -RRB-. P -LRB- \u03c7i, \u03d5 -RRB- denota la probabilidad del resultado \u03c7i dada la asignaci\u00f3n de caracter\u00edsticas \u03d5, que se calcula en funci\u00f3n de la probabilidad de \u00e9xito de cada negociaci\u00f3n. La Sexta Internacional..Conferencia conjunta. Figura 1: Un escenario de cadena de negociaci\u00f3n compleja Se ha desarrollado un algoritmo de b\u00fasqueda heur\u00edstica -LSB- 10 -RSB- para resolver el problema de negociaci\u00f3n multienlace del agente \u00fanico que produce soluciones casi \u00f3ptimas. Este algoritmo se utiliza como n\u00facleo de la toma de decisiones de cada agente individual en el escenario de la cadena de negociaci\u00f3n. En el resto del art\u00edculo, presentamos nuestro trabajo sobre c\u00f3mo mejorar la soluci\u00f3n local de un solo agente en el context de la cadena de negociaci\u00f3n global. 6. TRABAJO RELACIONADO Fatima, Wooldridge y Jennings -LSB- 1 -RSB- estudiaron los m\u00faltiples temas en negociaci\u00f3n en t\u00e9rminos de la agenda y el procedimiento de negociaci\u00f3n. Sin embargo, este trabajo es limitado ya que s\u00f3lo involucra la perspectiva de un \u00fanico agente sin entender que el agente puede ser parte de una cadena de negociaci\u00f3n. Mailler y Lesser -LSB- 4 -RSB- han presentado un enfoque para un problema de asignaci\u00f3n de recursos distribuidos donde ocurre el escenario de la cadena de negociaci\u00f3n. Modela el problema de negociaci\u00f3n como un problema de optimizaci\u00f3n de restricciones distribuidas -LRB-DCOP-RRB- y se utiliza un mecanismo de mediaci\u00f3n cooperativa para centralizar partes relevantes del DCOP. En nuestro trabajo, la negociaci\u00f3n involucra temas m\u00e1s complicados como recompensa, penalizaci\u00f3n y utilidad; Adem\u00e1s, adoptamos un enfoque de distribuci\u00f3n donde no se necesita control centralizado. Se ha aplicado un enfoque centralizado parcial basado en mediadores a la coordinaci\u00f3n y programaci\u00f3n de la red de tareas complejas -LSB- 8 -RSB-, que es diferente de nuestro trabajo ya que el sistema es un sistema cooperativo completo y la utilidad individual de un solo agente no est\u00e1 preocupada. en absoluto. Una subasta combinatoria -LSB- 2, 9 -RSB- podr\u00eda ser otro enfoque para resolver el problema de la cadena de negociaci\u00f3n. Sin embargo, en una subasta combinatoria, el agente no razona sobre el orden de las negociaciones. Esto conducir\u00eda a un problema similar a los que analizamos cuando se utiliza la pol\u00edtica del mismo plazo. 7. CONCLUSI\u00d3N Y TRABAJO FUTURO En este art\u00edculo, hemos resuelto los problemas de la cadena de negociaci\u00f3n extendiendo nuestro modelo de negociaci\u00f3n multivinculado desde la perspectiva de un \u00fanico agente a m\u00faltiples agentes. En lugar de resolver el problema de la cadena de negociaci\u00f3n con un enfoque centralizado, adoptamos un enfoque distribuido donde cada agente tiene un modelo local extendido y un proceso de toma de decisiones. Hemos introducido una fase previa a la negociaci\u00f3n que permite a los agentes transferir informaci\u00f3n de metanivel sobre cuestiones de negociaci\u00f3n relacionadas. Utilizando esta informaci\u00f3n, el agente puede construir un modelo m\u00e1s preciso de la negociaci\u00f3n en t\u00e9rminos de modelar la relaci\u00f3n de flexibilidad y probabilidad de \u00e9xito. Este modelo m\u00e1s preciso ayuda al agente a elegir la soluci\u00f3n de negociaci\u00f3n adecuada. Los datos experimentales muestran que estos mecanismos mejoran significativamente el rendimiento general del agente y del sistema. En una futura ampliaci\u00f3n de este trabajo, nos gustar\u00eda desarrollar mecanismos para verificar qu\u00e9 tan confiables son los agentes.Un escenario de cadena de negociaci\u00f3n compleja Se ha desarrollado un algoritmo de b\u00fasqueda heur\u00edstica -LSB-10-RSB- para resolver el problema de negociaci\u00f3n multiv\u00ednculo del agente \u00fanico que produce soluciones casi \u00f3ptimas. Este algoritmo se utiliza como n\u00facleo de la toma de decisiones de cada agente individual en el escenario de la cadena de negociaci\u00f3n. En el resto del art\u00edculo, presentamos nuestro trabajo sobre c\u00f3mo mejorar la soluci\u00f3n local de un solo agente en el context de la cadena de negociaci\u00f3n global. 6. TRABAJO RELACIONADO Fatima, Wooldridge y Jennings -LSB- 1 -RSB- estudiaron los m\u00faltiples temas en negociaci\u00f3n en t\u00e9rminos de la agenda y el procedimiento de negociaci\u00f3n. Sin embargo, este trabajo es limitado ya que s\u00f3lo involucra la perspectiva de un \u00fanico agente sin entender que el agente puede ser parte de una cadena de negociaci\u00f3n. Mailler y Lesser -LSB- 4 -RSB- han presentado un enfoque para un problema de asignaci\u00f3n de recursos distribuidos donde ocurre el escenario de la cadena de negociaci\u00f3n. Modela el problema de negociaci\u00f3n como un problema de optimizaci\u00f3n de restricciones distribuidas -LRB-DCOP-RRB- y se utiliza un mecanismo de mediaci\u00f3n cooperativa para centralizar partes relevantes del DCOP. En nuestro trabajo, la negociaci\u00f3n involucra temas m\u00e1s complicados como recompensa, penalizaci\u00f3n y utilidad; Adem\u00e1s, adoptamos un enfoque de distribuci\u00f3n donde no se necesita control centralizado. Se ha aplicado un enfoque centralizado parcial basado en mediadores a la coordinaci\u00f3n y programaci\u00f3n de la red de tareas complejas -LSB- 8 -RSB-, que es diferente de nuestro trabajo ya que el sistema es un sistema cooperativo completo y la utilidad individual de un solo agente no est\u00e1 preocupada. en absoluto. Una subasta combinatoria -LSB- 2, 9 -RSB- podr\u00eda ser otro enfoque para resolver el problema de la cadena de negociaci\u00f3n. Sin embargo, en una subasta combinatoria, el agente no razona sobre el orden de las negociaciones. Esto conducir\u00eda a un problema similar a los que analizamos cuando se utiliza la pol\u00edtica del mismo plazo. 7. CONCLUSI\u00d3N Y TRABAJO FUTURO En este art\u00edculo, hemos resuelto los problemas de la cadena de negociaci\u00f3n extendiendo nuestro modelo de negociaci\u00f3n multivinculado desde la perspectiva de un \u00fanico agente a m\u00faltiples agentes. En lugar de resolver el problema de la cadena de negociaci\u00f3n con un enfoque centralizado, adoptamos un enfoque distribuido donde cada agente tiene un modelo local extendido y un proceso de toma de decisiones. Hemos introducido una fase previa a la negociaci\u00f3n que permite a los agentes transferir informaci\u00f3n de metanivel sobre cuestiones de negociaci\u00f3n relacionadas. Utilizando esta informaci\u00f3n, el agente puede construir un modelo m\u00e1s preciso de la negociaci\u00f3n en t\u00e9rminos de modelar la relaci\u00f3n de flexibilidad y probabilidad de \u00e9xito. Este modelo m\u00e1s preciso ayuda al agente a elegir la soluci\u00f3n de negociaci\u00f3n adecuada. Los datos experimentales muestran que estos mecanismos mejoran significativamente el rendimiento general del agente y del sistema. En una futura ampliaci\u00f3n de este trabajo, nos gustar\u00eda desarrollar mecanismos para verificar qu\u00e9 tan confiables son los agentes.Un escenario de cadena de negociaci\u00f3n compleja Se ha desarrollado un algoritmo de b\u00fasqueda heur\u00edstica -LSB-10-RSB- para resolver el problema de negociaci\u00f3n multiv\u00ednculo del agente \u00fanico que produce soluciones casi \u00f3ptimas. Este algoritmo se utiliza como n\u00facleo de la toma de decisiones de cada agente individual en el escenario de la cadena de negociaci\u00f3n. En el resto del art\u00edculo, presentamos nuestro trabajo sobre c\u00f3mo mejorar la soluci\u00f3n local de un solo agente en el context de la cadena de negociaci\u00f3n global. 6. TRABAJO RELACIONADO Fatima, Wooldridge y Jennings -LSB- 1 -RSB- estudiaron los m\u00faltiples temas en negociaci\u00f3n en t\u00e9rminos de la agenda y el procedimiento de negociaci\u00f3n. Sin embargo, este trabajo es limitado ya que s\u00f3lo involucra la perspectiva de un \u00fanico agente sin entender que el agente puede ser parte de una cadena de negociaci\u00f3n. Mailler y Lesser -LSB- 4 -RSB- han presentado un enfoque para un problema de asignaci\u00f3n de recursos distribuidos donde ocurre el escenario de la cadena de negociaci\u00f3n. Modela el problema de negociaci\u00f3n como un problema de optimizaci\u00f3n de restricciones distribuidas -LRB-DCOP-RRB- y se utiliza un mecanismo de mediaci\u00f3n cooperativa para centralizar partes relevantes del DCOP. En nuestro trabajo, la negociaci\u00f3n involucra temas m\u00e1s complicados como recompensa, penalizaci\u00f3n y utilidad; Adem\u00e1s, adoptamos un enfoque de distribuci\u00f3n donde no se necesita control centralizado. Se ha aplicado un enfoque centralizado parcial basado en mediadores a la coordinaci\u00f3n y programaci\u00f3n de la red de tareas complejas -LSB- 8 -RSB-, que es diferente de nuestro trabajo ya que el sistema es un sistema cooperativo completo y la utilidad individual de un solo agente no est\u00e1 preocupada. en absoluto. Una subasta combinatoria -LSB- 2, 9 -RSB- podr\u00eda ser otro enfoque para resolver el problema de la cadena de negociaci\u00f3n. Sin embargo, en una subasta combinatoria, el agente no razona sobre el orden de las negociaciones. Esto conducir\u00eda a un problema similar a los que analizamos cuando se utiliza la pol\u00edtica del mismo plazo. 7. CONCLUSI\u00d3N Y TRABAJO FUTURO En este art\u00edculo, hemos resuelto los problemas de la cadena de negociaci\u00f3n extendiendo nuestro modelo de negociaci\u00f3n multivinculado desde la perspectiva de un \u00fanico agente a m\u00faltiples agentes. En lugar de resolver el problema de la cadena de negociaci\u00f3n con un enfoque centralizado, adoptamos un enfoque distribuido donde cada agente tiene un modelo local extendido y un proceso de toma de decisiones. Hemos introducido una fase previa a la negociaci\u00f3n que permite a los agentes transferir informaci\u00f3n de metanivel sobre cuestiones de negociaci\u00f3n relacionadas. Utilizando esta informaci\u00f3n, el agente puede construir un modelo m\u00e1s preciso de la negociaci\u00f3n en t\u00e9rminos de modelar la relaci\u00f3n de flexibilidad y probabilidad de \u00e9xito. Este modelo m\u00e1s preciso ayuda al agente a elegir la soluci\u00f3n de negociaci\u00f3n adecuada. Los datos experimentales muestran que estos mecanismos mejoran significativamente el rendimiento general del agente y del sistema. En una futura ampliaci\u00f3n de este trabajo, nos gustar\u00eda desarrollar mecanismos para verificar qu\u00e9 tan confiables son los agentes.", "keyphrases": ["agente m\u00faltiple", "marco de negociaci\u00f3n", "cadena de negociaci\u00f3n", "sistema multiagente semi-cooper", "prenegociaci\u00f3n", "negociaciones multienlace", "agente", "conjunto de distribuci\u00f3n", "tarea concurrente m\u00faltiple", "\u00f3rgano virtual", "reubicaci\u00f3n de subtarea", "mec\u00e1nico de reputaci\u00f3n", "escenario complejo de cadena de suministro"]}
{"file_name": "I-14", "text": "Un algoritmo de b\u00fasqueda distribuida basado en el aprendizaje por refuerzo para sistemas jer\u00e1rquicos de recuperaci\u00f3n de informaci\u00f3n de igual a igual RESUMEN Las estrategias de enrutamiento existentes dominantes empleadas en los sistemas de recuperaci\u00f3n de informaci\u00f3n basados \u200b\u200ben pares -LRB- P2P -RRB- -LRB- IR -RRB- se basan en similitudes enfoques. En estos enfoques, los agentes dependen de la similitud de contenido entre las consultas entrantes y sus agentes vecinos directos para dirigir las sesiones de b\u00fasqueda distribuida. Sin embargo, dicha heur\u00edstica es miope en el sentido de que los agentes vecinos pueden no estar conectados con agentes m\u00e1s relevantes. En este art\u00edculo, se desarrolla un enfoque basado en el aprendizaje por refuerzo en l\u00ednea para aprovechar las caracter\u00edsticas din\u00e1micas de tiempo de ejecuci\u00f3n de los sistemas IR P2P representadas por informaci\u00f3n sobre sesiones de b\u00fasqueda pasadas. Espec\u00edficamente, los agentes mantienen estimaciones sobre la capacidad de los agentes intermedios para proporcionar documentos relevantes para las consultas entrantes. Estas estimaciones se actualizan gradualmente a partir de la informaci\u00f3n de retroalimentaci\u00f3n obtenida en sesiones de b\u00fasqueda anteriores. Con base en esta informaci\u00f3n, los agentes derivan las pol\u00edticas de enrutamiento correspondientes. A partir de entonces, estos agentes enrutan las consultas seg\u00fan las pol\u00edticas aprendidas y actualizan las estimaciones seg\u00fan las nuevas pol\u00edticas de enrutamiento. Los resultados experimentales demuestran que el algoritmo de aprendizaje mejora considerablemente el rendimiento del enrutamiento en dos conjuntos de recopilaci\u00f3n de pruebas que se han utilizado en una variedad de estudios de IR distribuidos. 1. INTRODUCCI\u00d3N En los \u00faltimos a\u00f1os ha habido un creciente inter\u00e9s en estudiar c\u00f3mo controlar los procesos de b\u00fasqueda en sistemas peer-to-peer -LRB- P2P -RRB- de recuperaci\u00f3n de informaci\u00f3n -LRB- IR -RRB- -LSB- 6, 13, 14, 15 -RSB-. En esta l\u00ednea de investigaci\u00f3n, uno de los problemas centrales que preocupa a los investigadores es encaminar eficientemente las consultas de los usuarios en la red a agentes que est\u00e9n en posesi\u00f3n de los documentos adecuados. En ausencia de informaci\u00f3n global, las estrategias dominantes para abordar este problema son los enfoques basados \u200b\u200ben la similitud de contenido -LSB- 6, 13, 14, 15 -RSB-. Si bien la similitud de contenido entre las consultas y los nodos locales parece ser un indicador acreditable de la cantidad de documentos relevantes que residen en cada nodo, estos enfoques est\u00e1n limitados por una serie de factores. En segundo lugar, los enfoques basados \u200b\u200ben similitudes no tienen en cuenta las caracter\u00edsticas de tiempo de ejecuci\u00f3n de los sistemas IR P2P, incluidos los par\u00e1metros ambientales, el uso del ancho de banda y la informaci\u00f3n hist\u00f3rica de las sesiones de b\u00fasqueda pasadas, que proporcionan informaci\u00f3n valiosa para los algoritmos de enrutamiento de consultas. En este art\u00edculo, desarrollamos un enfoque de IR basado en el aprendizaje por refuerzo para mejorar el rendimiento de los algoritmos de b\u00fasqueda de IR distribuidos. Los agentes pueden adquirir mejores estrategias de b\u00fasqueda recopilando y analizando informaci\u00f3n de comentarios de sesiones de b\u00fasqueda anteriores. En particular, los agentes mantienen estimaciones, es decir, la utilidad esperada, sobre la capacidad de los agentes intermedios de proporcionar documentos relevantes para tipos espec\u00edficos de consultas entrantes.Estas estimaciones se actualizan gradualmente a partir de la informaci\u00f3n de retroalimentaci\u00f3n obtenida en sesiones de b\u00fasqueda anteriores. En funci\u00f3n de la informaci\u00f3n de utilidad esperada actualizada, los agentes derivan las pol\u00edticas de enrutamiento correspondientes. A partir de entonces, estos agentes enrutan las consultas seg\u00fan las pol\u00edticas aprendidas y actualizan las estimaciones de la utilidad esperada seg\u00fan las nuevas pol\u00edticas de enrutamiento. Este proceso se lleva a cabo de manera iterativa. El objetivo del algoritmo de aprendizaje, aunque consume algo de ancho de banda de la red, es acortar el tiempo de enrutamiento para que se procesen m\u00e1s consultas por unidad de tiempo y al mismo tiempo se encuentren documentos m\u00e1s relevantes. Esto contrasta con los enfoques basados \u200b\u200ben similitud de contenido, donde se repiten operaciones similares para cada consulta entrante y el tiempo de procesamiento se mantiene pr\u00e1cticamente constante a lo largo del tiempo. Otra forma de ver este art\u00edculo es que nuestro enfoque b\u00e1sico para la b\u00fasqueda IR distribuida es construir una red superpuesta jer\u00e1rquica -LRB- organizaci\u00f3n de agentes -RRB- basada en la medida de similitud de contenido entre las colecciones de documentos de los agentes de manera ascendente. En trabajos anteriores, hemos demostrado que esta organizaci\u00f3n mejora significativamente el rendimiento de la b\u00fasqueda. La intenci\u00f3n del aprendizaje por refuerzo es adaptar las decisiones de enrutamiento de los agentes a las situaciones din\u00e1micas de la red y aprender de sesiones de b\u00fasqueda pasadas. Espec\u00edficamente, las contribuciones de este documento incluyen: -LRB- 1 -RRB- un enfoque basado en aprendizaje por refuerzo para que los agentes adquieran pol\u00edticas de enrutamiento satisfactorias basadas en estimaciones de la contribuci\u00f3n potencial de sus agentes vecinos; -LRB- 2 -RRB- dos estrategias para acelerar el proceso de aprendizaje. El resto de este art\u00edculo est\u00e1 organizado de la siguiente manera: la Secci\u00f3n 2 revisa los sistemas jer\u00e1rquicos de intercambio de contenido y el algoritmo de b\u00fasqueda de dos fases basado en dicha topolog\u00eda. La secci\u00f3n 3 describe un enfoque basado en el aprendizaje por refuerzo para dirigir el proceso de enrutamiento; La secci\u00f3n 4 detalla los entornos experimentales y analiza los resultados. La Secci\u00f3n 5 analiza los estudios relacionados y la Secci\u00f3n 6 concluye el art\u00edculo. 5. TRABAJO RELACIONADO El problema del enrutamiento de contenido difiere del enrutamiento a nivel de red en redes de comunicaciones de conmutaci\u00f3n de paquetes en que el enrutamiento basado en contenido ocurre en redes a nivel de aplicaci\u00f3n. Adem\u00e1s, los agentes de destino en nuestros algoritmos de enrutamiento de contenido son m\u00faltiples y las direcciones no se conocen en el proceso de enrutamiento. Los problemas de enrutamiento a nivel IP han sido atacados desde la perspectiva del aprendizaje por refuerzo -LSB- 2, 5, 11, 12 -RSB-. Hay dos clases principales de algoritmos de enrutamiento de paquetes distribuidos y adaptativos en la literatura: algoritmos de vector distancia y algoritmos de estado de enlace. Si bien esta l\u00ednea de estudios tiene cierta similitud con nuestro trabajo, se ha centrado principalmente en redes de comunicaci\u00f3n con conmutaci\u00f3n de paquetes. Cada agente mantiene estimaciones, probabil\u00edstica o determin\u00edsticamente, de la distancia hasta un determinado destino a trav\u00e9s de sus vecinos. Se despliega una variante de las t\u00e9cnicas Q-Learning The Sixth Intl..Conferencia conjunta. actualizar las estimaciones para converger a las distancias reales. Se ha descubierto que la propiedad de localidad es una caracter\u00edstica importante de los sistemas de recuperaci\u00f3n de informaci\u00f3n en estudios de modelado de usuarios -LSB- 3 -RSB-. El enfoque basado en el aprendizaje se percibe como m\u00e1s beneficioso para sistemas reales de recuperaci\u00f3n de informaci\u00f3n distribuida que exhiben propiedad de localidad. Esto se debe a que el tr\u00e1fico de los usuarios y los patrones de consulta pueden reducir el espacio de estado y acelerar el proceso de aprendizaje. Los trabajos relacionados para aprovechar esta propiedad incluyen -LSB- 7 -RSB-, donde los autores intentaron abordar este problema mediante t\u00e9cnicas de modelado de usuario. 6. CONCLUSIONES En este art\u00edculo, se desarrolla un enfoque basado en el aprendizaje por refuerzo para mejorar el rendimiento de los algoritmos de b\u00fasqueda IR distribuidos. En particular, los agentes mantienen estimaciones, es decir, la utilidad esperada, sobre la capacidad de los agentes intermedios para proporcionar documentos relevantes para las consultas entrantes. Estas estimaciones se actualizan gradualmente a partir de la informaci\u00f3n de retroalimentaci\u00f3n obtenida en sesiones de b\u00fasqueda anteriores. Con base en la informaci\u00f3n de servicios p\u00fablicos esperada actualizada, los agentes modifican sus pol\u00edticas de enrutamiento. A partir de entonces, estos agentes enrutan las consultas seg\u00fan las pol\u00edticas aprendidas y actualizan las estimaciones de la utilidad esperada seg\u00fan las nuevas pol\u00edticas de enrutamiento. Los experimentos en dos conjuntos de datos de IR distribuidos diferentes ilustran que el enfoque de aprendizaje por refuerzo mejora considerablemente la utilidad acumulativa con el tiempo.", "keyphrases": ["sistema de recuperaci\u00f3n de informaci\u00f3n peer-to-peer", "reforzar aprender", "algoritmo de b\u00fasqueda de distribuci\u00f3n", "derrotar a las decisiones", "\u00fatil", "red", "aprender algoritmo", "pol\u00edtica de derrota", "pregunta"]}
{"file_name": "C-23", "text": "Implementaci\u00f3n de un mecanismo de ajuste din\u00e1mico con selecci\u00f3n eficiente de r\u00e9plicas en entornos de cuadr\u00edcula de datos RESUMEN La arquitectura de asignaci\u00f3n conjunta se desarroll\u00f3 para permitir la descarga paralela de conjuntos de datos desde m\u00faltiples servidores. Se han acoplado y utilizado varias estrategias de coasignaci\u00f3n para explotar las diferencias de tasas entre varios enlaces cliente-servidor y para abordar las fluctuaciones din\u00e1micas de las tasas dividiendo archivos en m\u00faltiples bloques de iguales tama\u00f1os. Sin embargo, un obst\u00e1culo importante, el tiempo de inactividad de los servidores m\u00e1s r\u00e1pidos que tienen que esperar a que el servidor m\u00e1s lento entregue el bloque final, hace que sea importante reducir las diferencias en el tiempo de finalizaci\u00f3n entre los servidores r\u00e9plica. En este art\u00edculo, proponemos un esquema de asignaci\u00f3n din\u00e1mica, a saber, un esquema de asignaci\u00f3n conjunta de ajuste recursivo, para mejorar el rendimiento de la transferencia de datos en Data Grids. Nuestro enfoque reduce el tiempo de inactividad dedicado a esperar al servidor m\u00e1s lento y disminuye el tiempo de finalizaci\u00f3n de la transferencia de datos. Tambi\u00e9n proporcionamos un esquema eficaz para reducir el costo de volver a ensamblar bloques de datos. 1. INTRODUCCI\u00d3N Los Data Grids agregan recursos distribuidos para resolver problemas de gesti\u00f3n de conjuntos de datos de gran tama\u00f1o. La mayor\u00eda de las aplicaciones Data Grid se ejecutan simult\u00e1neamente y acceden a una gran cantidad de archivos de datos en el entorno Grid. Ciertas aplicaciones cient\u00edficas que requieren un uso intensivo de datos, como la f\u00edsica de alta energ\u00eda, las aplicaciones bioinform\u00e1ticas y los observatorios astrof\u00edsicos virtuales, implican enormes cantidades de datos que requieren sistemas de gesti\u00f3n de archivos de datos para replicar archivos y gestionar las transferencias de datos y el acceso distribuido a los datos. La descarga de grandes conjuntos de datos desde varias ubicaciones de r\u00e9plica puede generar diferentes tasas de rendimiento, porque los sitios de r\u00e9plica pueden tener diferentes arquitecturas, cargas de sistema y conectividad de red. Una forma de mejorar las velocidades de descarga es determinar las mejores ubicaciones de r\u00e9plicas utilizando t\u00e9cnicas de selecci\u00f3n de r\u00e9plicas -LSB- 19 -RSB-. Este m\u00e9todo selecciona los mejores servidores para proporcionar velocidades de transferencia \u00f3ptimas porque la calidad del ancho de banda puede variar de manera impredecible debido a la naturaleza compartida de Internet. Otra forma es utilizar la tecnolog\u00eda de coasignaci\u00f3n -LSB- 17 -RSB- para descargar datos. La coasignaci\u00f3n de transferencias de datos permite a los clientes descargar datos desde m\u00faltiples ubicaciones estableciendo m\u00faltiples conexiones en paralelo. En el trabajo anterior -LSB- 17 -RSB- se proporcionaron varias estrategias de coasignaci\u00f3n. Sigue existiendo un inconveniente del tiempo de inactividad, ya que los servidores m\u00e1s r\u00e1pidos deben esperar a que el servidor m\u00e1s lento entregue su bloque final. Por lo tanto, es importante reducir las diferencias en el tiempo de finalizaci\u00f3n entre los servidores de r\u00e9plica. En este art\u00edculo, proponemos un esquema de asignaci\u00f3n conjunta din\u00e1mico basado en la arquitectura de transferencia de datos Grid de asignaci\u00f3n conjunta llamado esquema de asignaci\u00f3n conjunta de ajuste recursivo que reduce el tiempo de inactividad dedicado a esperar al servidor m\u00e1s lento y mejora el rendimiento de la transferencia de datos -LSB- 24 -RSB- . Los resultados experimentales muestran que nuestro enfoque es superior a los m\u00e9todos anteriores y logr\u00f3 el mejor rendimiento general.Tambi\u00e9n analizamos el costo de combinaci\u00f3n y proporcionamos un esquema eficaz para reducirlo. La revisi\u00f3n de antecedentes y los estudios relacionados se presentan en la Secci\u00f3n 2 y la arquitectura de asignaci\u00f3n conjunta y el trabajo relacionado se presentan en la Secci\u00f3n 3. En la Secci\u00f3n 4, proponemos un servicio eficiente de selecci\u00f3n de r\u00e9plicas. Nuestros enfoques de investigaci\u00f3n se describen en la Secci\u00f3n 5, y los resultados experimentales y una evaluaci\u00f3n del desempe\u00f1o de nuestro esquema se presentan en la Secci\u00f3n 6. La Secci\u00f3n 7 concluye este trabajo de investigaci\u00f3n. 2. ANTECEDENTES 2.1 Cuadr\u00edcula de datos Las cuadr\u00edculas de datos -LSB- 1, 2, 16 -RSB- federan una gran cantidad de recursos de almacenamiento. Grandes colecciones de datos medidos o computados est\u00e1n surgiendo como recursos importantes en muchas aplicaciones intensivas en datos. 2.1.1 Gesti\u00f3n de r\u00e9plicas La gesti\u00f3n de r\u00e9plicas implica la creaci\u00f3n o eliminaci\u00f3n de r\u00e9plicas en un sitio de cuadr\u00edcula de datos -LSB- 19 -RSB-. En otras palabras, la funci\u00f3n de un administrador de r\u00e9plicas es crear o eliminar r\u00e9plicas dentro de sistemas de almacenamiento espec\u00edficos. En la mayor\u00eda de los casos, estas r\u00e9plicas son copias exactas de los archivos originales, creadas \u00fanicamente para aprovechar ciertos beneficios de rendimiento. Un administrador de r\u00e9plicas normalmente mantiene un cat\u00e1logo de r\u00e9plicas que contiene direcciones de sitios de r\u00e9plica y las instancias de archivos. El servicio de gesti\u00f3n de r\u00e9plicas es responsable de gestionar la replicaci\u00f3n de copias completas y parciales de conjuntos de datos, definidos como colecciones de archivos. El servicio de administraci\u00f3n de r\u00e9plicas es solo un componente en un entorno Data Grid que brinda soporte para aplicaciones de alto rendimiento y uso intensivo de datos. Una r\u00e9plica o ubicaci\u00f3n es un subconjunto de una colecci\u00f3n que se almacena en un sistema de almacenamiento f\u00edsico particular. Puede haber varios subconjuntos posiblemente superpuestos de una colecci\u00f3n almacenados en m\u00faltiples sistemas de almacenamiento en una cuadr\u00edcula de datos. Estos sistemas de almacenamiento Grid pueden utilizar una variedad de tecnolog\u00edas de almacenamiento subyacentes y protocolos de movimiento de datos, que son independientes de la gesti\u00f3n de r\u00e9plicas. 2.1.2 Cat\u00e1logo de r\u00e9plicas Como se mencion\u00f3 anteriormente, el prop\u00f3sito del cat\u00e1logo de r\u00e9plicas es proporcionar asignaciones entre nombres l\u00f3gicos para archivos o colecciones y una o m\u00e1s copias de los objetos en sistemas de almacenamiento f\u00edsico. El cat\u00e1logo de r\u00e9plicas incluye entradas opcionales que describen archivos l\u00f3gicos individuales. Los archivos l\u00f3gicos son entidades con nombres globalmente \u00fanicos que pueden tener una o m\u00e1s instancias f\u00edsicas. Opcionalmente, el cat\u00e1logo puede contener una entrada de archivo l\u00f3gico en el cat\u00e1logo de r\u00e9plica para cada archivo l\u00f3gico de una colecci\u00f3n. Una cuadr\u00edcula de datos puede contener varios cat\u00e1logos de r\u00e9plicas. Por ejemplo, una comunidad de investigadores interesados \u200b\u200ben un tema de investigaci\u00f3n particular podr\u00eda mantener un cat\u00e1logo r\u00e9plica de una colecci\u00f3n de conjuntos de datos de inter\u00e9s mutuo. Es posible crear jerarqu\u00edas de cat\u00e1logos de r\u00e9plicas para imponer una estructura similar a un directorio en colecciones l\u00f3gicas relacionadas. Adem\u00e1s, el administrador de r\u00e9plicas puede realizar control de acceso a cat\u00e1logos completos, as\u00ed como a archivos l\u00f3gicos individuales. 2.1.3 Selecci\u00f3n de R\u00e9plicas El prop\u00f3sito de la selecci\u00f3n de r\u00e9plicas -LSB- 16 -RSB- es seleccionar una r\u00e9plica de entre los sitios que constituyen un Data Grid -LSB- 19 -RSB-.Los criterios de selecci\u00f3n dependen de las caracter\u00edsticas de la aplicaci\u00f3n. Al utilizar este mecanismo, los usuarios de Data Grid pueden administrar f\u00e1cilmente r\u00e9plicas de conjuntos de datos en sus sitios, con un mejor rendimiento. Se han dedicado muchos esfuerzos previos al problema de la selecci\u00f3n de r\u00e9plicas. El proceso com\u00fan de selecci\u00f3n de r\u00e9plicas consta de tres pasos: preparaci\u00f3n de datos, preprocesamiento y predicci\u00f3n. Luego, las aplicaciones pueden seleccionar una r\u00e9plica seg\u00fan sus atributos espec\u00edficos. La selecci\u00f3n de r\u00e9plicas es importante para las aplicaciones con uso intensivo de datos y puede proporcionar transparencia de ubicaci\u00f3n. Cuando un usuario solicita acceder a un conjunto de datos, el sistema determina una forma adecuada de entregar la r\u00e9plica al usuario. 2.2 Globus Toolkit y GridFTP El Proyecto Globus -LSB- 9, 11, 16 -RSB- proporciona herramientas de software denominadas colectivamente The Globus Toolkit que facilitan la creaci\u00f3n de Grids computacionales y aplicaciones basadas en Grids. Muchas organizaciones utilizan Globus Toolkit para crear Grids computacionales para respaldar sus aplicaciones. La composici\u00f3n del Globus Toolkit puede representarse en tres pilares: gesti\u00f3n de recursos, servicios de informaci\u00f3n y gesti\u00f3n de datos. GRAM implementa un protocolo de gesti\u00f3n de recursos, MDS implementa un protocolo de servicios de informaci\u00f3n y GridFTP implementa un protocolo de transferencia de datos. La alianza Globus propuso un protocolo com\u00fan de transferencia y acceso a datos denominado GridFTP que proporciona un movimiento de datos seguro y eficiente en entornos Grid -LSB- 3 -RSB-. Este protocolo, que ampl\u00eda el protocolo FTP est\u00e1ndar, proporciona un superconjunto de funciones que ofrecen los distintos sistemas de almacenamiento Grid actualmente en uso. Para resolver los problemas que aparecen, la comunidad Data Grid intenta desarrollar un mecanismo de transporte de datos seguro y eficiente y servicios de gesti\u00f3n de r\u00e9plicas. GridFTP es un protocolo de transporte de datos confiable, seguro y eficiente desarrollado como parte del proyecto Globus. Existe otra tecnolog\u00eda clave del proyecto Globus, llamada cat\u00e1logo de r\u00e9plicas -LSB- 16 -RSB- que se utiliza para registrar y gestionar copias completas y parciales de conjuntos de datos. El cat\u00e1logo de r\u00e9plicas contiene la informaci\u00f3n de asignaci\u00f3n de un archivo o colecci\u00f3n l\u00f3gico a uno o m\u00e1s archivos f\u00edsicos. 2.3 Servicio Meteorol\u00f3gico de Red El Servicio Meteorol\u00f3gico de Red -LRB- NWS -RRB- -LSB- 22 -RSB- es un sistema de monitoreo generalizado y distribuido para producir pron\u00f3sticos de desempe\u00f1o a corto plazo basados \u200b\u200ben mediciones hist\u00f3ricas de desempe\u00f1o. El objetivo del sistema es caracterizar y pronosticar din\u00e1micamente el rendimiento entregable a nivel de aplicaci\u00f3n a partir de un conjunto de recursos computacionales y de red. 2.4 Utilidades Sysstat Las utilidades Sysstat -LSB- 15 -RSB- son una colecci\u00f3n de herramientas de monitoreo del rendimiento para el sistema operativo Linux. El paquete Sysstat incorpora los comandos sar, mpstat e iostat. El comando sar recopila e informa informaci\u00f3n sobre la actividad del sistema, que tambi\u00e9n se puede guardar en un archivo de actividad del sistema para una inspecci\u00f3n futura.El comando iostat informa estad\u00edsticas de CPU y estad\u00edsticas de E/S para dispositivos y discos tty. 7. CONCLUSIONES La arquitectura de coasignaci\u00f3n proporciona un agente coordinado para asignar bloques de datos. Un trabajo anterior demostr\u00f3 que el esquema din\u00e1mico de coasignaci\u00f3n conduce a mejoras en el desempe\u00f1o. Sin embargo, no puede soportar el tiempo de inactividad de los servidores m\u00e1s r\u00e1pidos, que deben esperar a que el servidor m\u00e1s lento entregue su bloque final. Propusimos el esquema de coasignaci\u00f3n de ajuste recursivo para mejorar el rendimiento de la transferencia de datos utilizando la arquitectura de coasignaci\u00f3n en -LSB- 17 -RSB-. En este enfoque, las cargas de trabajo de los servidores de r\u00e9plica seleccionados se ajustan continuamente durante las transferencias de datos y proporcionamos una funci\u00f3n que permite a los usuarios definir un umbral de bloque final, de acuerdo con su entorno de cuadr\u00edcula de datos. Los resultados experimentales muestran la efectividad de nuestra t\u00e9cnica propuesta para mejorar el tiempo de transferencia y reducir el tiempo inactivo general dedicado a esperar al servidor m\u00e1s lento. Tambi\u00e9n discutimos el costo de recombinaci\u00f3n y proporcionamos un esquema efectivo para reducirlo.", "keyphrases": ["distribuir recursos", "aplicaci\u00f3n de cuadr\u00edcula de datos", "r\u00e9plica", "co-asignar", "gran conjunto de datos", "protocolo de gesti\u00f3n de recursos", "r\u00e9plica", "estrategias de coasignaci\u00f3n", "servidor", "llevar a cabo"]}
{"file_name": "J-28", "text": "Subastas de unidades m\u00faltiples aproximadamente a prueba de estrategias y manejables RESUMEN Presentamos un mecanismo de subasta aproximadamente eficiente y aproximadamente a prueba de estrategias para un problema de asignaci\u00f3n de m\u00faltiples unidades de un solo bien. El lenguaje de oferta en nuestras subastas permite curvas constantes por partes marginalmente decrecientes. Primero, desarrollamos un esquema de aproximaci\u00f3n en tiempo totalmente polinomial para el problema de asignaci\u00f3n de unidades m\u00faltiples, que calcula una aproximaci\u00f3n -LRB- 1 + e -RRB- en el peor de los casos T = O -LRB- n3/e -RRB-, dadas n ofertas cada una con un n\u00famero constante de piezas. En segundo lugar, incorporamos este esquema de aproximaci\u00f3n dentro de un mecanismo de Vickrey-Clarke-Groves -LRB-VCG-RRB- y calculamos los pagos a n agentes para un costo asint\u00f3tico de O -LRB- T log n -RRB-. La ganancia m\u00e1xima posible por manipulaci\u00f3n para un postor en el esquema combinado est\u00e1 limitada por e / -LRB- 1 + e -RRB- V, donde V es el excedente total en el resultado eficiente. 1. INTRODUCCI\u00d3N En este art\u00edculo presentamos un esquema de aproximaci\u00f3n en tiempo totalmente polinomial para el problema de subasta de unidades m\u00faltiples de un solo bien. Nuestro esquema es aproximadamente eficiente y aproximadamente a prueba de estrategias. Los escenarios de subasta considerados en nuestro art\u00edculo est\u00e1n motivados por las tendencias recientes en el comercio electr\u00f3nico; por ejemplo, las empresas utilizan cada vez m\u00e1s las subastas para su abastecimiento estrat\u00e9gico. Consideramos tanto una variaci\u00f3n de subasta inversa como una variaci\u00f3n de subasta directa, y proponemos un lenguaje de oferta compacto y expresivo que permite curvas constantes marginales decrecientes por partes. En la subasta inversa, consideramos un \u00fanico comprador con una demanda de M unidades de un bien y n proveedores, cada uno con una funci\u00f3n de costo marginal decreciente por partes constante. Adem\u00e1s, cada proveedor tambi\u00e9n puede expresar un l\u00edmite superior o restricci\u00f3n de capacidad sobre la cantidad de unidades que puede suministrar. Los modelos de variaci\u00f3n inversa, por ejemplo, una subasta de adquisiciones para obtener materias primas u otros servicios -LRB-, por ejemplo, placas de circuitos, proveedores de energ\u00eda, cartuchos de t\u00f3ner -RRB-, con lotes de tama\u00f1o flexible. En la subasta a plazo, consideramos un \u00fanico vendedor con M unidades de un bien y n compradores, cada uno con una funci\u00f3n de valoraci\u00f3n marginalmente decreciente por partes constante. Un comprador tambi\u00e9n puede expresar un l\u00edmite inferior, o tama\u00f1o m\u00ednimo de lote, para la cantidad de unidades que demanda. La variaci\u00f3n a plazo modela, por ejemplo, una subasta para vender el exceso de inventario en lotes de tama\u00f1o flexible. Consideramos la complejidad computacional de implementar el mecanismo Vickrey-Clarke-Groves -LSB- 22, 5, 11 -RSB- para el problema de subasta multiunitaria. El mecanismo Vickrey-Clarke-Groves -LRB-VCG-RRB- tiene una serie de propiedades econ\u00f3micas interesantes en este context, incluida la solidez de la estrategia, de modo que la oferta veraz es una estrategia dominante para los compradores en la subasta a plazo y para los vendedores en la subasta inversa, y eficiencia asignativa, de modo que el resultado maximice el excedente total del sistema. Sin embargo, como analizamos en la Secci\u00f3n 2,la aplicaci\u00f3n del enfoque basado en VCG se limita en sentido inverso a los casos en los que los pagos totales a los vendedores son menores que el valor del resultado para el comprador. De lo contrario, en estos casos la subasta debe realizarse con p\u00e9rdidas o no se puede esperar que el comprador elija participar voluntariamente. Este es un ejemplo del problema del d\u00e9ficit presupuestario que a menudo ocurre en el dise\u00f1o de mecanismos eficientes -LSB- 17 -RSB-. El problema computacional es interesante, porque incluso con curvas de oferta marginalmente decrecientes, el problema de asignaci\u00f3n subyacente resulta -LRB- d\u00e9bilmente -RRB- intratable. Por ejemplo, la cl\u00e1sica mochila 0/1 es un caso especial de este problema.1 Modelamos el 1. Sin embargo, el problema puede resolverse f\u00e1cilmente mediante un esquema codicioso si eliminamos todas las restricciones de capacidad del vendedor y todo el problema de asignaci\u00f3n como un problema novedoso y interesante generalizaci\u00f3n del problema cl\u00e1sico de la mochila y desarrollar un esquema de aproximaci\u00f3n de tiempo totalmente polinomial, calculando una aproximaci\u00f3n -LRB- 1 + ~ -RRB- - en el peor de los casos T = O -LRB- n3 / \u03b5 -RRB-, donde cada oferta tiene un n\u00famero fijo de piezas constantes por partes. Dado este esquema, un c\u00e1lculo sencillo de los pagos de VCG a todos los n agentes requiere un tiempo O -LRB- nT -RRB-. Este l\u00edmite superior tiende a 1 a medida que aumenta el n\u00famero de vendedores. El mecanismo VCG aproximado es -LRB- \u03b5 1 + \u03b5 -RRB- - a prueba de estrategias para una aproximaci\u00f3n dentro de -LRB- 1 + ~ -RRB- de la asignaci\u00f3n \u00f3ptima. Esto significa que un postor puede ganar como m\u00e1ximo -LRB- \u03b5 1 + \u03b5 -RRB- V de una oferta no veraz, donde V es el excedente total de la asignaci\u00f3n eficiente. La secci\u00f3n 2 define formalmente las subastas a plazo e inversa, y define los mecanismos de VCG. Tambi\u00e9n demostramos nuestras afirmaciones sobre la resistencia a la estrategia \u03b5. La Secci\u00f3n 3 proporciona la formulaci\u00f3n de mochila generalizada para los problemas de asignaci\u00f3n de unidades m\u00faltiples e introduce el esquema de aproximaci\u00f3n temporal totalmente polinomial. La secci\u00f3n 4 define el esquema de aproximaci\u00f3n para los pagos en el mecanismo VCG. La secci\u00f3n 5 concluye. 1.1 Trabajo relacionado En los \u00faltimos a\u00f1os ha habido un inter\u00e9s considerable en caracterizar el tiempo polinomial o casos especiales aproximables del problema de asignaci\u00f3n combinatoria general, en los que hay m\u00faltiples elementos diferentes. El problema de asignaci\u00f3n combinatoria -LRB- CAP -RRB- es NP-completo e inaproximable -LRB-, por ejemplo, -LSB- 6 -RSB- -RRB-. Identificamos un problema de asignaci\u00f3n no trivial pero aproximado con un lenguaje de oferta excluyente y expresivo: en nuestro entorno, al postor se le permite aceptar como m\u00e1ximo un punto en la curva de oferta. La idea de utilizar aproximaciones dentro de los mecanismos, manteniendo al mismo tiempo la total resistencia a la estrategia o la dominancia \u03b5, ha recibido cierta atenci\u00f3n anteriormente. Por ejemplo, Lehmann et al. -LSB- 15 -RSB- proponen una aproximaci\u00f3n codiciosa y a prueba de estrategias a un problema de subasta combinatoria unidireccional. Restricciones de tama\u00f1o m\u00ednimo de lote de Feigen por parte de los compradores.baum & Shenker -LSB- 8 -RSB- han definido el concepto de aproximaciones estrat\u00e9gicamente fieles y han propuesto el estudio de las aproximaciones como una direcci\u00f3n importante para el dise\u00f1o de mecanismos algor\u00edtmicos. Eso et al. -LSB- 7 -RSB- han estudiado un problema de adquisiciones similar, pero para un modelo de descuento por volumen diferente. Este trabajo anterior formula el problema como un programa lineal entero mixto general y proporciona algunos resultados emp\u00edricos sobre datos simulados. Kalagnanam et al. -LSB- 12 -RSB- abordan subastas dobles, donde m\u00faltiples compradores y vendedores intercambian un bien divisible. El enfoque de este art\u00edculo tambi\u00e9n es diferente: investiga los precios de equilibrio utilizando las curvas de oferta y demanda, mientras que nuestro enfoque se centra en el dise\u00f1o de mecanismos eficientes. Ausubel -LSB- 1 -RSB- ha propuesto una subasta multiunidad de precio ascendente para compradores con valores marginales decrecientes -LSB- 1 -RSB-, interpretada como un algoritmo primal-dual -LSB- 2 -RSB-. 5. CONCLUSIONES Presentamos un esquema de aproximaci\u00f3n en tiempo totalmente polinomial para el problema de subasta de m\u00faltiples unidades de un solo bien, utilizando un lenguaje de oferta marginal decreciente por partes constantes. Nuestro esquema es aproximadamente eficiente y aproximadamente a prueba de estrategias dentro de cualquier factor especificado \u03b5 > 0. Como tal, es un ejemplo de resultado de dominancia \u03b5 computacionalmente manejable, as\u00ed como un ejemplo de un problema de asignaci\u00f3n no trivial pero aproximado. Es particularmente interesante que podamos calcular los pagos a n agentes en un mecanismo basado en VCG en el peor de los casos O -LRB- T log n -RRB-, donde T es la complejidad temporal para calcular la soluci\u00f3n a un \u00fanico problema de asignaci\u00f3n.Es particularmente interesante que podamos calcular los pagos a n agentes en un mecanismo basado en VCG en el peor de los casos O -LRB- T log n -RRB-, donde T es la complejidad temporal para calcular la soluci\u00f3n a un \u00fanico problema de asignaci\u00f3n.Es particularmente interesante que podamos calcular los pagos a n agentes en un mecanismo basado en VCG en el peor de los casos O -LRB- T log n -RRB-, donde T es la complejidad temporal para calcular la soluci\u00f3n a un \u00fanico problema de asignaci\u00f3n.", "keyphrases": ["Mecanismo de subasta aproximadamente eficiente y a prueba de estrategias.", "problema de asignaci\u00f3n de unidades m\u00faltiples de un solo bien", "esquema completo de aproximaci\u00f3n polinomi-tiempo", "vickrei-clark-grove", "subasta a plazo", "subasta inversa", "equilibrio", "margen-disminuci\u00f3n piezawis curva constante", "idioma de oferta", "programa din\u00e1mico"]}
{"file_name": "C-40", "text": "Indexaci\u00f3n de bordes en una cuadr\u00edcula para entornos virtuales altamente din\u00e1micos \u2217 RESUMEN Los sistemas de aplicaciones basados \u200b\u200ben juegos recientemente emergentes, como Second Life1, proporcionan entornos virtuales 3D donde m\u00faltiples usuarios interact\u00faan entre s\u00ed en tiempo real. Est\u00e1n llenos de contenido virtual aut\u00f3nomo y mutable que los usuarios aumentan continuamente. Para que los sistemas sean altamente escalables y din\u00e1micamente extensibles, generalmente se construyen sobre una divisi\u00f3n de subespacio de red basada en cliente-servidor, donde los mundos virtuales se dividen en submundos manejables. En cada submundo, el usuario recibe continuamente actualizaciones relevantes de la geometr\u00eda de los objetos en movimiento desde servidores conectados remotamente y los representa seg\u00fan su punto de vista, en lugar de recuperarlos de un medio de almacenamiento local. En tales sistemas, la determinaci\u00f3n del conjunto de objetos que son visibles desde el punto de vista del usuario es uno de los principales factores que afectan el rendimiento y la escalabilidad del servidor. Espec\u00edficamente, realizar pruebas de visibilidad en tiempo real en entornos virtuales extremadamente din\u00e1micos es una tarea muy desafiante ya que millones de objetos y submillones de usuarios activos se mueven e interact\u00faan. Reconocemos que los desaf\u00edos descritos est\u00e1n estrechamente relacionados con un problema de base de datos espacial y, por lo tanto, asignamos los objetos geom\u00e9tricos en movimiento en el espacio virtual a un conjunto de objetos multidimensionales en una base de datos espacial mientras modelamos cada avatar como un objeto espacial y un consulta en movimiento. Desafortunadamente, los m\u00e9todos de indexaci\u00f3n espacial existentes no son adecuados para este tipo de entornos nuevos. El objetivo principal de este art\u00edculo es presentar una estructura de \u00edndice espacial eficiente que minimice la aparici\u00f3n inesperada de objetos y admita una determinaci\u00f3n de visibilidad en tiempo real altamente escalable. Luego descubrimos muchas propiedades \u00fatiles de esta estructura y comparamos la estructura del \u00edndice con varios m\u00e9todos de indexaci\u00f3n espacial en t\u00e9rminos de calidad de la consulta, rendimiento del sistema y utilizaci\u00f3n de recursos. Esperamos que nuestro enfoque siente las bases para los marcos virtuales de pr\u00f3xima generaci\u00f3n que pueden fusionarse con los servicios basados \u200b\u200ben web existentes en un futuro pr\u00f3ximo. \u2217 Esta investigaci\u00f3n ha sido financiada en parte por subvenciones NSF EEC9529152 -LRB- IMSC ERC -RRB- e IIS-0534761, y donaciones de equipos de Intel Corporation, Hewlett-Packard, Sun Microsystems y Raptor Networks Technology. Categor\u00edas y descriptores de temas: C. 2.4 -LSB- Computadora - Com 1. INTRODUCCI\u00d3N Recientemente, los juegos en l\u00ednea multijugador masivo -LRB- MMOGs -RRB- se han estudiado como un marco para entornos virtuales de pr\u00f3xima generaci\u00f3n. En este art\u00edculo, nos centraremos principalmente en los dos primeros requisitos. La extensibilidad din\u00e1mica permite que los usuarios de juegos normales implementen su propio contenido creado. Este es un concepto poderoso, pero desafortunadamente, el contenido creado por el usuario tiende a crear desequilibrios entre la complejidad de la escena existente, causando problemas de rendimiento en todo el sistema. Otro requisito importante es la escalabilidad.Al dividir cuidadosamente el mundo en m\u00faltiples submundos o replicar mundos en ubicaciones geogr\u00e1ficamente dispersas, se puede admitir un gran n\u00famero de usuarios simult\u00e1neos. Second Life -LSB- 4 -RSB- es el primer sistema MMOG implementado con \u00e9xito que cumple ambos requisitos. Pero reconocemos que estos requisitos tambi\u00e9n son v\u00e1lidos para los nuevos entornos virtuales. Figura 1: Se produjo un estallido de objetos cuando un usuario avanza -LRB- capturas de pantalla de Second Life -RRB- donde \u0394 = 2 segundos. emplea un modelo de transmisi\u00f3n de objetos 3D basado en cliente/servidor -LSB- 5 -RSB-. En este modelo, un servidor transmite continuamente eventos de actualizaci\u00f3n y datos de geometr\u00eda a cada usuario conectado. Como resultado, este entorno de juego extensible ha acelerado la implementaci\u00f3n de contenido creado por el usuario y les brinda libertad ilimitada para buscar una experiencia de navegaci\u00f3n en su espacio. Una de las operaciones principales en las aplicaciones MMOG que transmiten objetos 3D es calcular con precisi\u00f3n todos los objetos que son visibles para un usuario. Sin embargo, el enfoque tradicional de determinaci\u00f3n de la visibilidad tiene un problema de aparici\u00f3n de objetos. Por ejemplo, una casa fuera del rango visible de un usuario no se dibuja en el momento t, como se ilustra en la Figura 1 -LRB- a -RRB-. A medida que el usuario avanza, la casa aparecer\u00e1 repentinamente en el momento -LRB- t + \u0394 -RRB- como se muestra en la Figura 1 -LRB- b -RRB-. El c\u00e1lculo de visibilidad para cada usuario no s\u00f3lo debe ser preciso, sino tambi\u00e9n r\u00e1pido. Este desaf\u00edo se ilustra por el hecho de que el n\u00famero m\u00e1ximo de usuarios simult\u00e1neos por servidor de Second Life sigue siendo un orden de magnitud menor que el de los mundos estacionarios. Para abordar estos desaf\u00edos, proponemos un m\u00e9todo que identifica los objetos visibles m\u00e1s relevantes de una base de datos de geometr\u00eda determinada -LRB- modelo de vista -RRB- y luego presentamos un m\u00e9todo de indexaci\u00f3n r\u00e1pida que calcula los objetos visibles para cada usuario -LRB- indexaci\u00f3n espacial. -RRB-. Nuestros dos m\u00e9todos novedosos representan las principales contribuciones de este trabajo. La secci\u00f3n 2 presenta trabajos relacionados. La secci\u00f3n 3 describe nuestro nuevo m\u00e9todo de visualizaci\u00f3n. En la Secci\u00f3n 4, presentamos suposiciones sobre nuestra aplicaci\u00f3n objetivo e introducimos un nuevo m\u00e9todo de indexaci\u00f3n espacial dise\u00f1ado para soportar c\u00e1lculos de visibilidad en tiempo real. Tambi\u00e9n discutimos sus problemas de optimizaci\u00f3n. La Secci\u00f3n 5 informa sobre el an\u00e1lisis cuantitativo y la Secci\u00f3n 6 presenta los resultados preliminares de nuestros experimentos basados \u200b\u200ben simulaci\u00f3n. Finalmente, concluimos y abordamos direcciones de investigaci\u00f3n futuras en la Secci\u00f3n 7. 2. TRABAJO RELACIONADO La determinaci\u00f3n de la visibilidad ha sido ampliamente explorada en el campo de los gr\u00e1ficos 3D. Se han propuesto varios algoritmos de renderizado local para eliminar objetos innecesarios antes del renderizado o en cualquier etapa del proceso de renderizado. Sin embargo, estos algoritmos suponen que todos los objetos visibles candidatos se han almacenado localmente. Si los objetos de destino se almacenan en servidores remotos, los clientes reciben los elementos geom\u00e9tricos necesarios para la representaci\u00f3n desde las bases de datos del servidor. Sin embargo,Estos algoritmos de optimizaci\u00f3n en l\u00ednea no resuelven los problemas de rendimiento en el servidor en entornos muy concurridos. Por otro lado, nuestro modelo de c\u00e1lculo de visibilidad, representativo de esta categor\u00eda, se basa en diferentes supuestos sobre la representaci\u00f3n de datos de entidades virtuales. En el \u00e1rea de gr\u00e1ficos, se ha trabajado poco para soportar c\u00e1lculos de visibilidad en tiempo real para una gran cantidad de objetos y usuarios en movimiento. Aqu\u00ed reconocemos que estos problemas relacionados con los gr\u00e1ficos tienen una similitud muy estrecha con los problemas de las bases de datos espaciales. Recientemente, varias publicaciones han abordado la cuesti\u00f3n de la escalabilidad sobre c\u00f3mo admitir cantidades masivas de objetos y consultas en entornos altamente din\u00e1micos. Para admitir actualizaciones frecuentes, se han estudiado en profundidad dos pol\u00edticas de partici\u00f3n: -LRB- 1 -RRB- indexaci\u00f3n espacial basada en \u00e1rbol R e -LRB- 2 -RRB- indexaci\u00f3n espacial basada en cuadr\u00edcula. El modelo de partici\u00f3n basado en cuadr\u00edcula es un caso especial de partici\u00f3n fija. Recientemente, se ha redescubierto porque puede ser eficiente en entornos altamente din\u00e1micos. Q-Index -LSB- 13, 11 -RSB- es uno de los trabajos anteriores que redescubre la utilidad de la partici\u00f3n del espacio basada en cuadr\u00edculas para entornos de objetos en movimiento emergentes. A diferencia de los m\u00e9todos tradicionales de indexaci\u00f3n espacial que construyen un \u00edndice sobre los objetos en movimiento, crea un \u00edndice sobre las consultas de rango continuo, suponiendo que las consultas se mueven con poca frecuencia mientras que los objetos se mueven libremente. La idea b\u00e1sica del \u00e1rbol Q+R -LSB- 14 -RSB- es separar estructuras de indexaci\u00f3n para objetos cuasi estacionarios y objetos en movimiento: los objetos en movimiento r\u00e1pido se indexan en un Quadtree y los objetos cuasi estacionarios se almacenan en un R \u2217 - \u00e1rbol. Se propuso SINA -LSB- 10 -RSB- para proporcionar evaluaciones de consultas eficientes para cualquier combinaci\u00f3n de objetos estacionarios/en movimiento y consultas estacionarias/en movimiento. Espec\u00edficamente, este enfoque solo detecta eficientemente actualizaciones de objetos -LRB- positivos -RRB- reci\u00e9n descubiertos o que ya no son relevantes -LRB- negativos -RRB-. A diferencia de otros m\u00e9todos de indexaci\u00f3n espacial que se centran en reducir el costo de evaluaci\u00f3n de consultas, Hu et al. -LSB- 12 -RSB- propuso un marco general que minimiza el costo de comunicaci\u00f3n para las actualizaciones de ubicaci\u00f3n manteniendo un \u00e1rea rectangular llamada regi\u00f3n segura alrededor de objetos en movimiento. Siempre que cualquier objeto resida en esta regi\u00f3n, se garantiza que todos los resultados de la consulta ser\u00e1n v\u00e1lidos en el sistema. Si los objetos se mueven fuera de su regi\u00f3n, las solicitudes de actualizaci\u00f3n de ubicaci\u00f3n deben enviarse al servidor de la base de datos y las consultas afectadas se reeval\u00faan sobre la marcha. Nuestro m\u00e9todo de indexaci\u00f3n es muy similar a los enfoques anteriores. La principal diferencia es que nosotros nos concentramos m\u00e1s en la determinaci\u00f3n de la visibilidad en tiempo real, mientras que otros asumen restricciones de tiempo flexibles. 6. EVALUACI\u00d3N Esta secci\u00f3n presenta dos configuraciones de simulaci\u00f3n y sus resultados de desempe\u00f1o. La secci\u00f3n 6.1 examina si nuestro nuevo enfoque de vista es superior a los modelos de vista existentes, a pesar de su mayor complejidad de indexaci\u00f3n. Secci\u00f3n 6.2 analiza el grado de practicidad y escalabilidad de nuestro m\u00e9todo de indexaci\u00f3n dise\u00f1ado para nuestro nuevo modelo de vista. 6.1 Justificaci\u00f3n del modelo de vista iniciado por objeto 6.1.1 M\u00e9tricas de evaluaci\u00f3n P es la proporci\u00f3n de elementos relevantes recuperados con respecto a todos los elementos recuperados. Un valor m\u00e1s bajo de P implica que el conjunto de resultados de la consulta contiene una gran cantidad de objetos innecesarios que no es necesario entregar a un cliente. Un valor P m\u00e1s alto significa una carga de tr\u00e1fico de red mayor que la requerida. R es la relaci\u00f3n entre elementos relevantes recuperados y todos los elementos relevantes. Un valor R m\u00e1s bajo significa que se ignoran m\u00e1s objetos que deber\u00edan reconocerse. A partir de la medida R, podemos estimar cuantitativamente la aparici\u00f3n de objetos que explotan. Adem\u00e1s de las m\u00e9tricas P y R, utilizamos una m\u00e9trica de evaluaci\u00f3n de consultas de valor \u00fanico estandarizada que combina P y R, llamada medida E -LSB- 15 -RSB-. La medida E se define como: Si \u03b2 es menor que 1, P se vuelve m\u00e1s importante. De lo contrario, R afectar\u00e1 significativamente la medida E. Un valor de medida E m\u00e1s bajo implica que el modelo de vista probado tiene una calidad m\u00e1s alta. El mejor valor de medida E es cero, donde los mejores valores para P y R son ambos. 6.1.2 Configuraci\u00f3n de la simulaci\u00f3n Probamos cuatro esquemas de procesamiento de consultas, que utilizan un modelo de vista iniciado por el usuario o iniciado por un objeto: \u2022 C\u00e1lculo de visibilidad iniciado por el usuario \u2013 RQ \u2013 OP: Consulta de regi\u00f3n \u2013 Punto de objeto \u2022 Objeto c\u00e1lculo de visibilidad orientado - PQ-OR: Consulta de punto - Regi\u00f3n de objeto - RQ-OR: Consulta de regi\u00f3n - Regi\u00f3n de objeto - ACQ-OR: Consulta de celda aproximada - Regi\u00f3n de objeto RQ - OP es el esquema de c\u00e1lculo t\u00edpico que recopila todos los objetos cuya ubicaci\u00f3n est\u00e1 dentro de un AOI definido por el usuario. PQ -- OR recopila un conjunto de objetos cuyo AOI se cruza con un punto de usuario determinado, formalmente -LCB- o | qP \u2208 oR -RCB-. RQ -- OR, un esquema de c\u00e1lculo imaginario, es la combinaci\u00f3n de RQ -- OP y PQ -- OR donde el AOI de un objeto se cruza con el de un usuario, -LCB- o | oR \u2229 qR = ~ \u2205 -RCB-. Por \u00faltimo, ACQ-OR, un modelo de c\u00e1lculo de visibilidad aproximada, es un esquema especial dise\u00f1ado para la partici\u00f3n del espacio basada en cuadr\u00edculas, que es nuestra metodolog\u00eda de evaluaci\u00f3n de celdas elegida para la indexaci\u00f3n de bordes. Si un espacio virtual se divide en celdas en mosaico y un punto de usuario pertenece a una de las celdas, el ACQ-OR busca los objetos cuyos AOI Tabla 5: C\u00e1lculos de P y R de diferentes esquemas de determinaci\u00f3n de visibilidad. Tabla 6: El tiempo transcurrido medido -LRB- segundos -RRB- de 100.000 objetos en movimiento y 10.000 usuarios en movimiento en un entorno que se mueve lentamente se cruzar\u00eda con la regi\u00f3n de la celda de la cuadr\u00edcula correspondiente. Identifica cualquier objeto o que satisfaga la condici\u00f3n cR n oR _ ~ 0 donde la celda c tambi\u00e9n satisface qP E cR. Nuestro programa de simulaci\u00f3n pobl\u00f3 100.000 entidades de objetos y 10.000 entidades de usuarios en un espacio unitario 2D, -LSB- 0, 1 -RRB- x -LSB- 0, 1 -RRB-. Las entidades pobladas est\u00e1n ubicadas uniformemente en el espacio unitario.El programa realiza pruebas de intersecci\u00f3n entre todos los usuarios y todas las entidades de objetos de manera exhaustiva y calcula los valores de medida P, R y E -LRB- que se muestran en la Tabla 5 -RRB-. 6.1.3 Resultados experimentales Distribuci\u00f3n de la medida P y R: La Figura 7 muestra la distribuci\u00f3n de P y R para RQ - OP. Podemos observar que P y R son aproximadamente inversamente proporcionales entre s\u00ed cuando se var\u00eda el rango de AOI de un usuario. Una longitud lateral m\u00e1s peque\u00f1a conduce a una mayor precisi\u00f3n pero a una menor amplitud. Por ejemplo, el 5 % de la longitud lateral de un AOI de usuario detecta todos los objetos cuya longitud lateral del AOI es al menos el 5 %. Por lo tanto, se garantiza que cada objeto recuperado por RQ - OP se representar\u00e1 en el cliente. Pero RQ-OP no puede detectar los objetos fuera del AOI del usuario, por lo que faltan demasiados objetos que deber\u00edan renderizarse. De manera similar, el usuario cuyo AOI es m\u00e1s ancho que cualquier otro AOI no puede pasar por alto ning\u00fan objeto que deba renderizarse, pero detecta demasiados objetos innecesarios. Para eliminar cualquier problema de explosi\u00f3n de objetos, la longitud lateral de cualquier AOI debe ser mayor o igual a la distancia m\u00e1xima visible de cualquier objeto en el sistema, lo que puede provocar una degradaci\u00f3n significativa del sistema. Distribuci\u00f3n de medidas electr\u00f3nicas: la Figura 8 revela dos tendencias. En primer lugar, los valores de precisi\u00f3n de RQ - OP se encuentran entre los de ACQ - OR -LRB- cuadr\u00edcula de 100 x 100 -RRB- y RQ - OR. En segundo lugar, la curva de tendencia del gr\u00e1fico de medida Precisi\u00f3n - a - E de RQ - OR muestra semejanza con la de ACQ - OR. Efecto de diferentes tama\u00f1os de cuadr\u00edcula: la Figura 9 muestra la diferencia estad\u00edstica de E - valores de medida de siete esquemas de partici\u00f3n de cuadr\u00edcula diferentes -LRB- usando ACQ - OR -RRB- y un modelo RQ - OP. Usamos un diagrama de caja y bigotes para mostrar tanto los valores medianos como las varianzas de las distribuciones de medidas E y los valores at\u00edpicos de cada esquema. Tambi\u00e9n extraemos el valor mediano de las medidas RQ - OP E -LRB- l\u00ednea verde -RRB- para fines de comparaci\u00f3n. Si bien los esquemas ACQ - OR tienen algunos valores at\u00edpicos, sus valores de medida E est\u00e1n muy concentrados alrededor de los valores medianos, por lo que son menos sensibles al AOI del objeto. Como se esperaba, la partici\u00f3n de cuadr\u00edcula de grano fino mostr\u00f3 un valor de medida E m\u00e1s peque\u00f1o. El esquema RQ-OP mostr\u00f3 una variaci\u00f3n m\u00e1s amplia en su calidad que otros esquemas, lo que se puede atribuir en gran medida a las diferentes longitudes del lado del usuario. A medida que la medida R se vuelve m\u00e1s importante, la calidad de la consulta de ACQ - OR mejora de manera m\u00e1s evidente que la de RQ - OP. De la Figura 9, el esquema de cuadr\u00edcula de 20x20 tuvo una mejor medida E. Tabla 7: Tiempo transcurrido medido -LRB- segundos -RRB- de 100.000 objetos en movimiento y 10.000 usuarios en movimiento en un entorno altamente din\u00e1mico -LRB- valor en un entorno priorizado que en un entorno con la misma prioridad. Como resultado, podemos anticipar aproximadamente que al menos la partici\u00f3n de celdas de cuadr\u00edcula de 20x20 recupera una mayor calidad de conjuntos visibles que RQ - OP. 6.2 Evaluaci\u00f3n de la indexaci\u00f3n de bordes En esta secci\u00f3n,Presentamos los resultados preliminares de las simulaciones que examinan la aplicabilidad de nuestra implementaci\u00f3n de indexaci\u00f3n de bordes. Para estimar el grado de soporte en tiempo real de nuestro m\u00e9todo de indexaci\u00f3n, utilizamos el tiempo total transcurrido para actualizar todas las entidades en movimiento y calcular los conjuntos visibles para cada celda. Tambi\u00e9n experimentamos con diferentes pol\u00edticas de partici\u00f3n de red y las comparamos con soluciones de b\u00fasqueda exhaustivas. 6.2.1 Configuraci\u00f3n de la simulaci\u00f3n Implementamos algoritmos de indexaci\u00f3n de bordes en C y ejecutamos los experimentos en un procesador Itanium de 64 bits a 900 MHz con 8 GB de memoria. Implementamos un mecanismo de tabla hash generalizado para almacenar estructuras de nodos y bordes. 6.2.2 Resultados experimentales Costo de monitoreo peri\u00f3dico: Las tablas 6 y 7 muestran los n\u00fameros de rendimiento de diferentes m\u00e9todos de indexaci\u00f3n de bordes al variar v. La velocidad de movimiento de las entidades tambi\u00e9n se asign\u00f3 uniformemente entre 0 y v. Sin embargo, el m\u00e9todo de dos tablas mostr\u00f3 un Tiempo de evaluaci\u00f3n ligeramente mayor que los dos m\u00e9todos de tabla \u00fanica debido a su eliminaci\u00f3n secuencial de tokens. La Tabla 7 ejemplific\u00f3 el tiempo transcurrido de actualizaciones de \u00edndices y evaluaciones de celdas en un entorno altamente din\u00e1mico donde coexisten objetos que se mueven lentamente y din\u00e1micamente. En comparaci\u00f3n con los resultados mostrados en la Tabla 6, el enfoque de dos tablas produjo cifras de rendimiento similares independientemente de los entornos m\u00f3viles subyacentes. Sin embargo, la ganancia de rendimiento obtenida mediante la pol\u00edtica incremental de la tabla \u00fanica disminuye en comparaci\u00f3n con la del entorno de movimiento lento. Efecto de diferentes tama\u00f1os de cuadr\u00edcula: la cantidad de actualizaciones de objetos y evaluaciones de celdas que se pueden admitir en un per\u00edodo de tiempo determinado es una m\u00e9trica de rendimiento importante para cuantificar el rendimiento del sistema. En esta secci\u00f3n, evaluamos los resultados de rendimiento de tres modelos de c\u00e1lculo de visibilidad diferentes: dos m\u00e9todos de b\u00fasqueda exhaustiva impulsados \u200b\u200bpor c\u00e1lculo; y uno dos: m\u00e9todo de indexaci\u00f3n del borde de la tabla con diferentes tama\u00f1os de cuadr\u00edcula. Figura 7: Distribuci\u00f3n de P y R medida por RQ - OP. Figura 8: E: mide el valor en funci\u00f3n de Figura 9: E: mide el valor en funci\u00f3n de ACQ: esquema de partici\u00f3n de cuadr\u00edcula QR cuando Figura 10: Tiempo total transcurrido de diferentes esquemas de indexaci\u00f3n. Los m\u00e9todos de b\u00fasqueda exhaustivos no mantienen resultados intermedios. Simplemente calculan si un punto de usuario determinado est\u00e1 dentro de un AOI de objeto determinado. Pueden tolerar comportamientos impredecibles de movimiento de objetos. La Figura 10 revela la diferencia de rendimiento entre las soluciones exhaustivas y los m\u00e9todos de dos tablas, una diferencia de hasta dos \u00f3rdenes de magnitud. Como se muestra en la Secci\u00f3n 5, el tiempo total transcurrido de actualizaciones de objetos y evaluaciones de celdas es lineal con respecto a la longitud lateral promedio del AOI del objeto. Debido a que la longitud de los lados est\u00e1 representada por unidades de celda, un aumento en el n\u00famero de celdas aumenta las longitudes de los lados proporcionalmente. La Figura 10 ilustra que los resultados de la simulaci\u00f3n medidos coinciden aproximadamente con la ganancia de rendimiento esperada calculada a partir del an\u00e1lisis. 7.CONCLUSI\u00d3N Y TRABAJO FUTURO Para respaldar la extensibilidad y escalabilidad din\u00e1micas en entornos altamente din\u00e1micos, propusimos un nuevo paradigma de vista, el modelo de vista iniciado por objetos, y su m\u00e9todo de indexaci\u00f3n eficiente, la indexaci\u00f3n de bordes. En comparaci\u00f3n con el modelo de vista tradicional, nuestro nuevo modelo de vista promete eliminar cualquier problema de aparici\u00f3n de objetos que pueda observarse f\u00e1cilmente en entornos virtuales existentes a expensas de una mayor complejidad de indexaci\u00f3n. Nuestro modelo de indexaci\u00f3n de bordes, sin embargo, puede superar una complejidad de indexaci\u00f3n tan alta al indexar extensiones espaciales en el nivel de borde, no en el nivel de nodo, en un submundo dividido en cuadr\u00edcula y fue validado a trav\u00e9s de an\u00e1lisis cuantitativos y simulaciones. Sin embargo, por ahora nuestra indexaci\u00f3n de bordes a\u00fan conserva una mayor complejidad, incluso en un dominio bidimensional. Actualmente, estamos desarrollando otro m\u00e9todo de indexaci\u00f3n de bordes para que la complejidad de la indexaci\u00f3n sea constante. Una vez que la complejidad de la indexaci\u00f3n se vuelva constante, planeamos indexar extensiones espaciales 3D y datos de geometr\u00eda multiresolucional. Esperamos que nuestra indexaci\u00f3n perimetral pueda contribuir a la implementaci\u00f3n exitosa de entornos de juego de pr\u00f3xima generaci\u00f3n.", "keyphrases": ["\u00edndice de borde", "entorno virtual din\u00e1mico", "aplicaci\u00f3n de juego base", "contenido virtual mutable", "bases de datos espaciales", "m\u00e9todo de \u00edndice espacial", "prueba visible en tiempo real", "modelo de vista inicial de objeto", "objeto pop", "extensiones espaciales 3d"]}
{"file_name": "C-86", "text": "Abordar el comportamiento estrat\u00e9gico en un asignador de recursos microecon\u00f3micos implementado RESUMEN Si bien durante mucho tiempo se han propuesto sistemas basados \u200b\u200ben el mercado como soluciones para la asignaci\u00f3n distribuida de recursos, pocos se han implementado para uso productivo en sistemas inform\u00e1ticos reales. Con este fin, presentamos nuestra experiencia inicial utilizando Mirage, un sistema de asignaci\u00f3n de recursos microecon\u00f3micos basado en una subasta combinatoria repetida. Mirage asigna tiempo en un banco de pruebas de red de sensores inal\u00e1mbricos de 148 nodos muy utilizado. En particular, nos centramos en el comportamiento estrat\u00e9gico de los usuarios observado durante un per\u00edodo de cuatro meses en el que se asignaron 312.148 horas de nodo en 11 proyectos de investigaci\u00f3n. Con base en estos resultados, presentamos un conjunto de desaf\u00edos clave para los sistemas de asignaci\u00f3n de recursos basados \u200b\u200ben el mercado basados \u200b\u200ben subastas combinatorias repetidas. Finalmente, proponemos mejoras al esquema de subasta actual del sistema para mitigar las estrategias observadas hasta la fecha y tambi\u00e9n comentamos algunos pasos iniciales hacia la construcci\u00f3n de una subasta combinatoria repetida aproximadamente a prueba de estrategias. 1. INTRODUCCI\u00d3N Los sistemas basados \u200b\u200ben el mercado se han propuesto desde hace mucho tiempo como soluciones para la asignaci\u00f3n de recursos en sistemas distribuidos, incluidas Grids computacionales -LSB- 2, 20 -RSB-, bancos de pruebas de redes de \u00e1rea amplia -LSB- 9 -RSB- y peer-to-. sistemas pares -LSB- 17 -RSB-. Sin embargo, si bien los fundamentos te\u00f3ricos de los esquemas basados \u200b\u200ben el mercado han logrado avances significativos en los \u00faltimos a\u00f1os, la integraci\u00f3n pr\u00e1ctica de los mecanismos basados \u200b\u200ben el mercado en sistemas inform\u00e1ticos reales y las observaciones emp\u00edricas de dichos sistemas bajo cargas de trabajo reales siguen siendo un objetivo dif\u00edcil de alcanzar. Con este fin, hemos dise\u00f1ado, implementado y desplegado un sistema de asignaci\u00f3n de recursos microecon\u00f3micos llamado Mirage -LSB- 3 -RSB- para programar el tiempo del banco de pruebas en una red de sensores inal\u00e1mbricos de 148 nodos -LRB- SensorNet -RRB- banco de pruebas en Intel Research. El sistema, que emplea una subasta combinatoria repetida -LSB- 5, 14 -RSB- para programar asignaciones, ha estado en producci\u00f3n durante m\u00e1s de cuatro meses y ha programado m\u00e1s de 312.148 horas de nodo en 11 proyectos de investigaci\u00f3n hasta la fecha. Al dise\u00f1ar e implementar Mirage, ten\u00edamos tres objetivos principales. Primero, quer\u00edamos validar si era necesario un esquema de asignaci\u00f3n de recursos basado en el mercado. Un problema econ\u00f3mico s\u00f3lo existe cuando los recursos son escasos. Por lo tanto, un objetivo clave fue medir primero tanto la contenci\u00f3n de recursos como el rango de valoraciones subyacentes que los usuarios otorgan a los recursos durante per\u00edodos de escasez de recursos. En segundo lugar, quer\u00edamos observar c\u00f3mo se comportar\u00edan realmente los usuarios en un entorno basado en el mercado. Con Mirage, quer\u00edamos observar hasta qu\u00e9 punto se manten\u00eda la racionalidad y de qu\u00e9 manera los usuarios intentar\u00edan crear estrategias y jugar con el sistema. Finalmente, quer\u00edamos identificar qu\u00e9 otros problemas pr\u00e1cticos surgir\u00edan en el despliegue de un sistema basado en el mercado. En este art\u00edculo, informamos brevemente sobre nuestro primer objetivo, centr\u00e1ndonos principalmente en el segundo. Al implementar Mirage,Tomamos la decisi\u00f3n temprana de basar el sistema en una subasta combinatoria repetida que se sabe que no es a prueba de estrategias. Es decir, los usuarios interesados \u200b\u200bpodr\u00edan intentar aumentar su beneficio personal, a expensas de los dem\u00e1s, al no revelar su verdadero valor para el sistema. Tomamos esta decisi\u00f3n principalmente porque el dise\u00f1o de un mecanismo a prueba de estrategias sigue siendo un problema abierto y desafiante y quer\u00edamos implementar un sistema que funcione y adquirir experiencia con usuarios reales para abordar nuestros tres objetivos de manera oportuna. La implementaci\u00f3n de un mecanismo no estrat\u00e9gico tambi\u00e9n tuvo el beneficio de probar la racionalidad y ver c\u00f3mo y en qu\u00e9 medida los usuarios intentar\u00edan jugar con el sistema. La contribuci\u00f3n clave de este art\u00edculo es un an\u00e1lisis de dicho comportamiento estrat\u00e9gico observado durante un per\u00edodo de cuatro meses y propuestas de refinamiento para mitigar dicho comportamiento en el camino hacia la construcci\u00f3n de una subasta combinatoria repetida aproximadamente a prueba de estrategias. El resto de este documento est\u00e1 organizado de la siguiente manera. En la Secci\u00f3n 2, presentamos una descripci\u00f3n general de Mirage que incluye observaciones de alto nivel sobre el uso durante un per\u00edodo de cuatro meses. En la Secci\u00f3n 3, examinamos el comportamiento estrat\u00e9gico del usuario, centr\u00e1ndonos en los cuatro tipos principales de estrategias empleadas por los usuarios en el sistema. Con base en estos resultados, la Secci\u00f3n 4 presenta un conjunto de desaf\u00edos clave para los sistemas de asignaci\u00f3n de recursos basados \u200b\u200ben el mercado basados \u200b\u200ben subastas combinatorias repetidas. Como primer paso para abordar algunos de estos desaf\u00edos, describimos mejoras al esquema de subasta actual de Mirage que mitigan las estrategias observadas hasta la fecha y tambi\u00e9n comentamos algunos pasos iniciales hacia la construcci\u00f3n de una subasta combinatoria repetida aproximadamente a prueba de estrategias para Mirage. Finalmente, en la Secci\u00f3n 5, concluimos el art\u00edculo. 5. CONCLUSI\u00d3N A pesar de utilizar inicialmente una subasta combinatoria repetida que se sabe que no es a prueba de estrategias, Mirage se ha mostrado muy prometedor como veh\u00edculo para la asignaci\u00f3n del banco de pruebas de SensorNet. Sin embargo, para lograr plenamente estos beneficios es necesario abordar problemas clave en el dise\u00f1o de mecanismos a prueba de estrategias y la optimizaci\u00f3n combinatoria. La naturaleza temporal de los recursos computacionales y las demandas combinatorias de recursos de las aplicaciones distribuidas a\u00f1aden una capa adicional de complejidad.El resto de este documento est\u00e1 organizado de la siguiente manera. En la Secci\u00f3n 2, presentamos una descripci\u00f3n general de Mirage que incluye observaciones de alto nivel sobre el uso durante un per\u00edodo de cuatro meses. En la Secci\u00f3n 3, examinamos el comportamiento estrat\u00e9gico del usuario, enfoc\u00e1ndonos en los cuatro tipos principales de estrategias empleadas por los usuarios en el sistema. Con base en estos resultados, la Secci\u00f3n 4 presenta un conjunto de desaf\u00edos clave para los sistemas de asignaci\u00f3n de recursos basados \u200b\u200ben el mercado basados \u200b\u200ben subastas combinatorias repetidas. Como primer paso para abordar algunos de estos desaf\u00edos, describimos mejoras al esquema de subasta actual de Mirage que mitigan las estrategias observadas hasta la fecha y tambi\u00e9n comentamos algunos pasos iniciales hacia la construcci\u00f3n de una subasta combinatoria repetida aproximadamente a prueba de estrategias para Mirage. Finalmente, en la Secci\u00f3n 5, concluimos el art\u00edculo. 5. CONCLUSI\u00d3N A pesar de utilizar inicialmente una subasta combinatoria repetida que se sabe que no es a prueba de estrategias, Mirage se ha mostrado muy prometedor como veh\u00edculo para la asignaci\u00f3n del banco de pruebas de SensorNet. Sin embargo, para lograr plenamente estos beneficios es necesario abordar problemas clave en el dise\u00f1o de mecanismos a prueba de estrategias y la optimizaci\u00f3n combinatoria. La naturaleza temporal de los recursos computacionales y las demandas combinatorias de recursos de las aplicaciones distribuidas a\u00f1aden una capa adicional de complejidad.El resto de este documento est\u00e1 organizado de la siguiente manera. En la Secci\u00f3n 2, presentamos una descripci\u00f3n general de Mirage que incluye observaciones de alto nivel sobre el uso durante un per\u00edodo de cuatro meses. En la Secci\u00f3n 3, examinamos el comportamiento estrat\u00e9gico del usuario, centr\u00e1ndonos en los cuatro tipos principales de estrategias empleadas por los usuarios en el sistema. Con base en estos resultados, la Secci\u00f3n 4 presenta un conjunto de desaf\u00edos clave para los sistemas de asignaci\u00f3n de recursos basados \u200b\u200ben el mercado basados \u200b\u200ben subastas combinatorias repetidas. Como primer paso para abordar algunos de estos desaf\u00edos, describimos mejoras al esquema de subasta actual de Mirage que mitigan las estrategias observadas hasta la fecha y tambi\u00e9n comentamos algunos pasos iniciales hacia la construcci\u00f3n de una subasta combinatoria repetida aproximadamente a prueba de estrategias para Mirage. Finalmente, en la Secci\u00f3n 5, concluimos el art\u00edculo. 5. CONCLUSI\u00d3N A pesar de utilizar inicialmente una subasta combinatoria repetida que se sabe que no es a prueba de estrategias, Mirage se ha mostrado muy prometedor como veh\u00edculo para la asignaci\u00f3n del banco de pruebas de SensorNet. Sin embargo, para lograr plenamente estos beneficios es necesario abordar problemas clave en el dise\u00f1o de mecanismos a prueba de estrategias y la optimizaci\u00f3n combinatoria. La naturaleza temporal de los recursos computacionales y las demandas combinatorias de recursos de las aplicaciones distribuidas a\u00f1aden una capa adicional de complejidad.", "keyphrases": ["sistema de asignaci\u00f3n de recursos", "subasta combinatoria", "sistema de base de mercado", "sistema de distribuci\u00f3n", "comportamiento estrat\u00e9gico", "racionar", "esquema basado en subasta", "sistema mirag", "prueba de sensornetb", "precio hora-nodo", "gastos generales utilizables", "programaci\u00f3n por lotes", "distribuir aplicaci\u00f3n"]}