{"file_name": "2186.abstr", "text": "Strategies for high throughput, templated zeolite synthesis. The design and redesign of high throughput experiments for zeolite synthesis are addressed. A model that relates materials function to the chemical composition of the zeolite and the structure directing agent is introduced. Using this model, several Monte Carlo-like design protocols are evaluated. Multi-round protocols are bound to be effective, and strategies that use a priori information about the structure-directing libraries are found to be the best", "keyphrases": ["templat zeolit synthesi", "high throughput strategi", "materi function", "chemic composit", "structur direct agent", "mont carlo-lik design protocol", "multi-round protocol", "a priori inform", "catalyt activ", "catalyt select", "organo-c templat molecul", "combinatori method", "random energi model", "figur of merit", "materi discoveri", "small molecul design", "voronoi diagram", "phase-depend random gaussian variabl", "metropolis-typ method", "ligand librari", "reflect boundari condit"]}
{"file_name": "255.abstr", "text": "The culture of usability. Now that most of us agree that usability testing is an integral investment in site development, it's time to recognize that the standard approach falls short. It is possible to do less work and get better results while spending less money. By bringing usability testing in-house and breaking tests into more manageable sessions, you can vastly improve your online offering without affecting your profit margin", "keyphrases": ["usabl test program", "web site"]}
{"file_name": "379.abstr", "text": "Feedforward maximum power point tracking of PV systems using fuzzy controller. A feedforward maximum power (MP) point tracking scheme is developed for the interleaved dual boost (IDB) converter fed photovoltaic (PV) system using fuzzy controller. The tracking algorithm changes the duty ratio of the converter such that the solar cell array (SCA) voltage equals the voltage corresponding to the MP point at that solar insolation. This is done by the feedforward loop, which generates an error signal by comparing the instantaneous array voltage and reference voltage. The reference voltage for the feedforward loop, corresponding to the MP point, is obtained by an off-line trained neural network. Experimental data is used for off-line training of the neural network, which employs back-propagation algorithm. The proposed fuzzy feedforward peak power tracking effectiveness is demonstrated through the simulation and experimental results, and compared with the conventional proportional plus integral (PI) controller based system. Finally, a comparative study of interleaved boost and conventional boost converter for the PV applications is given and their suitability is discussed", "keyphrases": ["feedforward maximum power point track", "pv system", "fuzzi control", "interleav dual boost convert feed", "photovolta system", "track algorithm", "duti ratio", "solar cell array voltag", "solar insol", "feedforward loop", "error signal", "instantan array voltag", "refer voltag", "off-lin train neural network", "back-propag algorithm", "fuzzi feedforward peak power track effect"]}
{"file_name": "2024.abstr", "text": "Binocular model for figure-ground segmentation in translucent and occluding images. A Fourier-based solution to the problem of figure-ground segmentation in short baseline binocular image pairs is presented. Each image is modeled as an additive composite of two component images that exhibit a spatial shift due to the binocular parallax. The segmentation is accomplished by decoupling each Fourier component in one of the resultant additive images into its two constituent phasors, allocating each to its appropriate object-specific spectrum, and then reconstructing the foreground and background using the inverse Fourier transform. It is shown that the foreground and background shifts can be computed from the differences of the magnitudes and phases of the Fourier transform of the binocular image pair. While the model is based on translucent objects, it also works with occluding objects", "keyphrases": ["binocular model", "figure-ground segment", "transluc imag", "occlud imag", "imag", "imag segment", "fourier-bas solut", "short baselin binocular imag pair", "compon imag", "spatial shift", "binocular parallax", "fourier compon decoupl", "phasor", "object-specif spectrum", "foreground", "background", "invers fourier transform", "binocular imag pair", "transluc object", "occlud object"]}
{"file_name": "1969.abstr", "text": "Modeling self-consistent multi-class dynamic traffic flow. In this study, we present a systematic self-consistent multiclass multilane traffic model derived from the vehicular Boltzmann equation and the traffic dispersion model. The multilane domain is considered as a two-dimensional space and the interaction among vehicles in the domain is described by a dispersion model. The reason we consider a multilane domain as a two-dimensional space is that the driving behavior of road users may not be restricted by lanes, especially motorcyclists. The dispersion model, which is a nonlinear Poisson equation, is derived from the car-following theory and the equilibrium assumption. Under the concept that all kinds of users share the finite section, the density is distributed on a road by the dispersion model. In addition, the dynamic evolution of the traffic flow is determined by the systematic gas-kinetic model derived from the Boltzmann equation. Multiplying Boltzmann equation by the zeroth, first- and second-order moment functions, integrating both side of the equation and using chain rules, we can derive continuity, motion and variance equation, respectively. However, the second-order moment function, which is the square of the individual velocity, is employed by previous researches does not have physical meaning in traffic flow", "keyphrases": ["self-consist multiclass dynam traffic flow model", "multilan traffic model", "vehicular boltzmann equat", "traffic dispers model", "road user", "nonlinear poisson equat", "car-follow theori", "dynam evolut", "varianc equat", "motion equat", "poisson equat"]}
{"file_name": "381.abstr", "text": "Robust fuzzy controlled photovoltaic power inverter with Taguchi method. This paper presents design and implementation of a robust fuzzy controlled photovoltaic (PV) power inverter with Taguchi tuned scaling factors. To achieve fast transient response, small steady-state error and system robustness, a robust fuzzy controller is adopted, in which its input and output scaling factors are determined efficiently by using the Taguchi-tuning algorithm. The proposed system can operate in different modes, grid-connection mode and stand-alone mode, and can accommodate wide load variations. Simulation results and hardware measurements obtained from a prototype with a microcontroller (Intel 80196KC) are presented to verify the theoretical discussions, and its adaptivity, robustness and feasibility", "keyphrases": ["robust fuzzi control photovolta power invert", "taguchi method", "tune scale factor", "transient respons", "steady-st error", "system robust", "output scale factor", "grid-connect mode", "stand-alon mode", "load variat", "microcontrol", "adapt", "feasibl"]}
{"file_name": "2017.abstr", "text": "Autofocus system for microscope. A technique is developed for microscope autofocusing, which is called the eccentric light beam approach with high resolution, wide focusing range, and compact construction. The principle is described. The theoretical formula of the eccentric light beam approach deduced can be applied not only to an object lens whose objective plane is just at the focal plane, but also to an object lens whose objective plane is not at the focal plane. The experimental setup uses a semiconductor laser device as the light source. The laser beam that enters into the microscope is eccentric with the main light axis. A defocused signal is acquired by a symmetrical silicon photocell for the change of the reflected light position caused by differential amplification and processed by a microprocessor. Then the electric signal is power-amplified and drives a dc motor, which moves a fine working platform to an automatic focus of the microscope. The result of the experiments shows a +or-0.1- mu m precision of autofocusing for a range of +or-500- mu m defocusing. The system has high reliability and can meet the requirements of various accurate micro measurement systems", "keyphrases": ["autofocu system", "microscop autofocus", "eccentr light beam approach", "object len", "object plane", "semiconductor laser", "main light axi", "defocus signal", "symmetr silicon photocel", "reflect light posit", "differenti amplif", "microprocessor", "power-amplifi electr signal", "dc motor", "fine work platform", "high reliabl", "micro measur system"]}
{"file_name": "248.abstr", "text": "Universal dynamic synchronous self-stabilization. We prove the existence of a \"universal\" synchronous self-stabilizing protocol, that is, a protocol that allows a distributed system to stabilize to a desired nonreactive behaviour (as long as a protocol stabilizing to that behaviour exists). Previous proposals required drastic increases in asymmetry and knowledge to work, whereas our protocol does not use any additional knowledge, and does not require more symmetry-breaking conditions than available; thus, it is also stabilizing with respect to dynamic changes in the topology. We prove an optimal quiescence time n + D for a synchronous network of n processors and diameter D; the protocol can be made finite state with a negligible loss in quiescence time. Moreover, an optimal D + 1 protocol is given for the case of unique identifiers. As a consequence, we provide an effective proof technique that allows one to show whether self-stabilization to a certain behaviour is possible under a wide range of models", "keyphrases": ["univers dynam synchron self-stabil", "synchron self-stabil protocol", "distribut system", "nonreact behaviour", "topolog", "dynam chang", "optim quiescenc time", "synchron network", "finit state", "quiescenc time", "optim protocol", "uniqu identifi", "proof techniqu", "self-stabil", "anonym network", "graph fibrat"]}
{"file_name": "350.abstr", "text": "There is no optimal routing policy for the torus. A routing policy is the method used to select a specific output channel for a message from among a number of acceptable output channels. An optimal routing policy is a policy that maximizes the probability of a message reaching its destination without delays. Optimal routing policies have been proposed for several regular networks, including the mesh and the hypercube. An open problem in interconnection network research has been the identification of an optimal routing policy for the torus. In this paper, we show that there is no optimal routing policy for the torus. Our result is demonstrated by presenting a detailed example in which the best choice of output channel is dependent on the probability of each channel being available. This result settles, in the negative, a conjecture by J. Wu (1996) concerning an optimal routing policy for the torus", "keyphrases": ["optim rout polici", "toru", "hypercub"]}
{"file_name": "2129.abstr", "text": "A universal decomposition of the integration range for exponential functions. The problem of determining the independent constants for decomposition of the integration range of exponential functions was solved on the basis of a similar approach to polynomials. The constants obtained enable one to decompose the integration range in two so that the integrals over them are equal independently of the function parameters. For the nontrigonometrical polynomials of even functions, an alternative approach was presented", "keyphrases": ["integr rang univers decomposit", "exponenti function", "polynomi", "integr rang decomposit", "nontrigonometr polynomi", "even function"]}
{"file_name": "348.abstr", "text": "Lower bounds on the information rate of secret sharing schemes with homogeneous access structure. We present some new lower bounds on the optimal information rate and on the optimal average information rate of secret sharing schemes with homogeneous access structure. These bounds are found by using some covering constructions and a new parameter, the k-degree of a participant, that is introduced in this paper. Our bounds improve the previous ones in almost all cases", "keyphrases": ["lower bound", "optim inform rate", "optim averag inform rate", "k-degre", "cryptographi", "inform rate", "secret share scheme", "homogen access structur"]}
{"file_name": "368.abstr", "text": "From a biological to a computational model for the autonomous behavior of an animat. Endowing an autonomous system like a robot with intelligent behavior is difficult for several reasons. First, behavior is such a wide topic that a general framework paradigm of inspiration must be chosen in order to obtain a consistent model. Such a framework can be, for example, biological modeling or an artificial intelligence approach. Second, a general framework is not sufficient to determine a fully specified program to be implemented in a robot. Many choices, tuning and tests must be carried out before obtaining a robust system. A biological model is presented, based on the definition of cortex-like automata, representing elementary functions in the perceptive, motor or associative domain. These automata are connected in a network whose architecture, functioning and learning rules are described in a cortical framework. Second, the computational model derived from that biological model is specified. The way units exchange and compute variables through links is explained, with reference to corresponding biological elements. It is then easier to report experiments allowing an autonomous system to learn regularities of a simple environment and to exploit them to satisfy some internal drives. Even if additional biological hints can be added, this model allow us to better understand how a biological model can be implemented and how biological properties can emerge from a distributed set of units", "keyphrases": ["autonom system", "robot", "autonom behavior", "intellig behavior", "animat", "tune", "test", "robust system", "biolog model", "cortex-lik automata", "elementari function", "percept domain", "associ domain", "motor domain", "learn rule", "architectur", "comput model", "variabl comput", "variabl exchang", "link", "regular learn", "simpl environ", "intern drive"]}
{"file_name": "2039.abstr", "text": "An inverse problem for a model of a hierarchical structure. We consider the inverse problem for the identification of the coefficient in a parabolic equation. The model is applied to describe the functioning of a hierarchical structure; it is also relevant for heat-conduction theory. Unique solvability of the inverse problem is proved", "keyphrases": ["invers problem", "hierarch structur", "parabol equat", "heat-conduct theori", "uniqu solvabl"]}
{"file_name": "2060.abstr", "text": "Decisions, decisions, decisions: a tale of special collections in the small academic library. A case study of a special collections department in a small academic library and how its collections have been acquired and developed over the years is described. It looks at the changes that have occurred in the academic environment and what effect, if any, these changes may have had on the department and how it has adapted to them. It raises questions about development and acquisitions policies and procedures", "keyphrases": ["special collect", "small academ librari", "case studi", "acquisit polici", "out-of-print book", "univers librari"]}
{"file_name": "295.abstr", "text": "Hours of operation and service in academic libraries: toward a national standard. In an effort toward establishing a standard for academic library hours, the article surveys and compares hours of operation and service for ARL libraries and IPEDS survey respondents. The article ranks the ARL (Association for Research Libraries) libraries according to hours of operation and reference hours and then briefly discusses such issues as libraries offering twenty-four access and factors affecting service hour decisions", "keyphrases": ["academ librari hour", "operation/servic hour", "arl librari", "ipe survey respond", "integr post secondari educ data system", "associ for research librari"]}
{"file_name": "233.abstr", "text": "The Canadian National Site Licensing Project. In January 2000, a consortium of 64 universities in Canada signed a historic inter-institutional agreement that launched the Canadian National Site Licensing Project (CNSLP), a three-year pilot project aimed at bolstering the research and innovation capacity of the country's universities. CNSLP tests the feasibility of licensing, on a national scale, electronic versions of scholarly publications; in its initial phases the project is focused on full-text electronic journals and research databases in science, engineering, health and environmental disciplines. This article provides an overview of the CNSLP initiative, summarizes organizational and licensing accomplishments to date, and offers preliminary observations on challenges and opportunities for subsequent phases of the project", "keyphrases": ["canadian nation site licens project", "inter-institut agreement", "research and innov", "cnslp", "academ librari", "inform resourc", "electron scholarli public", "full-text electron journal", "research databas"]}
{"file_name": "414.abstr", "text": "The efficacy of electronic telecommunications in fostering interpersonal relationships. The effectiveness of electronic telecommunications as a supplementary aid to instruction and as a communication link between students, and between students and instructors in fostering interpersonal relationships was explored in this study. More specifically, the impacts of e-mail, one of the most accessible, convenient, and easy to use computer-mediated communications, on student attitudes toward the instructor, group-mates, and other classmates were investigated. A posttest-only experimental design was adopted. In total, 68 prospective teachers enrolling in a \"Computers in Education\" course participated in the study for a whole semester. Results from the study provided substantial evidence supporting e-mail's beneficial effects on student attitudes toward the instructor and other classmates", "keyphrases": ["interperson relationship", "telecommun", "student commun link", "e-mail", "computer-medi commun", "student attitud", "comput in educ cours", "educ technolog"]}
{"file_name": "271.abstr", "text": "On the use of neural network ensembles in QSAR and QSPR. Despite their growing popularity among neural network practitioners, ensemble methods have not been widely adopted in structure-activity and structure-property correlation. Neural networks are inherently unstable, in that small changes in the training set and/or training parameters can lead to large changes in their generalization performance. Recent research has shown that by capitalizing on the diversity of the individual models, ensemble techniques can minimize uncertainty and produce more stable and accurate predictors. In this work, we present a critical assessment of the most common ensemble technique known as bootstrap aggregation, or bagging, as applied to QSAR and QSPR. Although aggregation does offer definitive advantages, we demonstrate that bagging may not be the best possible choice and that simpler techniques such as retraining with the full sample can often produce superior results. These findings are rationalized using Krogh and Vedelsby's (1995) decomposition of the generalization error into a term that measures the average generalization performance of the individual networks and a term that measures the diversity among them. For networks that are designed to resist over-fitting, the benefits of aggregation are clear but not overwhelming", "keyphrases": ["neural network ensembl", "qsar", "qspr", "train set", "train paramet", "gener perform", "uncertainti", "bootstrap aggreg", "bag", "retrain", "gener error decomposit", "structure-act correl", "structure-properti correl"]}
{"file_name": "1931.abstr", "text": "Mathematical fundamentals of constructing fuzzy Bayesian inference techniques. Problems and an associated technique for developing a Bayesian approach to decision-making in the case of fuzzy data are presented. The concept of fuzzy and pseudofuzzy quantities is introduced and main operations with pseudofuzzy quantities are considered. The basic relationships and the principal concepts of the Bayesian decision procedure based on the modus-ponens rule are proposed. Some problems concerned with the practical realization of the fuzzy Bayesian method are considered", "keyphrases": ["mathemat fundament", "fuzzi bayesian infer techniqu", "decis make", "pseudofuzzi quantiti", "modus-ponen rule"]}
{"file_name": "2111.abstr", "text": "Extended depth-of-focus imaging of chlorophyll fluorescence from intact leaves. Imaging dynamic changes in chlorophyll a fluorescence provides a valuable means with which to examine localised changes in photosynthetic function. Microscope-based systems provide excellent spatial resolution which allows the response of individual cells to be measured. However, such systems have a restricted depth of focus and, as leaves are inherently uneven, only a small proportion of each image at any given focal plane is in focus. In this report we describe the development of algorithms, specifically adapted for imaging chlorophyll fluorescence and photosynthetic function in living plant cells, which allow extended-focus images to be reconstructed from images taken in different focal planes. We describe how these procedures can be used to reconstruct images of chlorophyll fluorescence and calculated photosynthetic parameters, as well as producing a map of leaf topology. The robustness of this procedure is demonstrated using leaves from a number of different plant species", "keyphrases": ["chlorophyl fluoresc", "intact leav", "extend depth-of-focu imag", "leaf topolog map", "plant speci", "calcul photosynthet paramet", "individu cell respons", "microscope-bas system", "charge-coupl devic", "maximum fluoresc yield", "minimum fluoresc yield", "variabl fluoresc", "numer apertur", "primari quinon acceptor", "spatial resolut", "algorithm develop", "extended-focu imag reconstruct", "biophys research techniqu"]}
{"file_name": "2123.abstr", "text": "\"Hidden convexity\" of finite-dimensional stationary linear discrete-time systems under conical constraints. New properties of finite-dimensional linear discrete-time systems under conical control constraints that are similar to the \"hidden convexity\" of continuous-time systems are studied", "keyphrases": ["hidden convex", "finite-dimension stationari linear discrete-tim system", "conic constraint", "control constraint"]}
{"file_name": "1989.abstr", "text": "Managing system risk. Companies are increasingly required to provide assurance that their systems are secure and conform to commercial security standards. Senior business managers are ultimately responsible for the security of their corporate systems and for the implications in the event of a failure. Businesses will be exposed to unquantified security risks unless they have a formal risk management framework in place to enable risks to be identified, evaluated and managed. Failure to assess and manage risks can lead to a business suffering serious financial impacts, commercial embarrassment and fines or sanctions from regulators. This is both a key responsibility and opportunity for Management Services Practitioners", "keyphrases": ["risk manag framework", "commerci secur standard", "it project"]}
{"file_name": "276.abstr", "text": "Assessment of the macrocyclic effect for the complexation of crown-ethers with alkali cations using the substructural molecular fragments method. The Substructural Molecular Fragments method (Solov'ev, V. P.; Varnek, A. A.; Wipff, G. J. Chem. Inf. Comput. Sci. 2000, 40, 847-858) was applied to assess stability constants (logK) of the complexes of crown-ethers, polyethers, and glymes with Na/sup +/, K/sup +/, and Cs/sup +/ in methanol. One hundred forty-seven computational models including different fragment sets coupled with linear or nonlinear fitting equations were applied for the data sets containing 69 (Na/sup +/), 123 (K/sup +/), and 31 (Cs/sup +/) compounds. To account for the \"macrocyclic effect\" for crown-ethers, an additional \"cyclicity\" descriptor was used. \"Predicted\" stability constants both for macrocyclic compounds and for their open-chain analogues are in good agreement with the experimental data reported earlier and with those studied experimentally in this work. The macrocyclic effect as a function of cation and ligand is quantitatively estimated for all studied crown-ethers", "keyphrases": ["substructur molecular fragment method", "stabil constant", "complex", "crown-eth", "alkali cation", "macrocycl effect", "comput model", "differ fragment set", "nonlinear fit equat", "linear fit equat", "cyclic descriptor", "open-chain analogu", "data mine", "structure-properti tool", "molecular graph decomposit", "quantit structure-properti relationship", "augment atom", "trail program", "statist paramet", "thermodynam paramet"]}
{"file_name": "1954.abstr", "text": "Estimating long-range dependence: finite sample properties and confidence intervals. A major issue in financial economics is the behavior of asset returns over long horizons. Various estimators of long-range dependence have been proposed. Even though some have known asymptotic properties, it is important to test their accuracy by using simulated series of different lengths. We test R/S analysis, detrended fluctuation analysis and periodogram regression methods on samples drawn from Gaussian white noise. The DFA statistics turns out to be the unanimous winner. Unfortunately, no asymptotic distribution theory has been derived for this statistics so far. We were able, however, to construct empirical (i.e approximate) confidence intervals for all three methods. The obtained values differ largely from heuristic values proposed by some authors for the R/S statistics and are very close to asymptotic values for the periodogram regression method", "keyphrases": ["long-rang depend", "finit sampl properti", "confid interv", "financi econom", "asset return", "long horizon", "asymptot properti", "detrend fluctuat analysi", "periodogram regress method", "gaussian white nois", "heurist valu"]}
{"file_name": "2027.abstr", "text": "Motion estimation using modified dynamic programming. A new method for computing precise estimates of the motion vector field of moving objects in a sequence of images is proposed. Correspondence vector-field computation is formulated as a matching optimization problem for multiple dynamic images. The proposed method is a heuristic modification of dynamic programming applied to the 2-D optimization problem. Motion-vector-field estimates using real movie images demonstrate good performance of the algorithm in terms of dynamic motion analysis", "keyphrases": ["modifi dynam program", "motion estim", "precis estim", "motion vector field", "move object", "imag sequenc", "vector-field comput", "match optim problem", "multipl dynam imag", "heurist modif", "dynam program", "2-d optim problem", "motion vector field estim", "real movi imag", "algorithm", "dynam motion analysi"]}
{"file_name": "333.abstr", "text": "Teaching psychology as a laboratory science in the age of the Internet. For over 30 years, psychologists have relied on computers to teach experimental psychology. With the advent of experiment generators, students can create well-designed experiments and can test sophisticated hypotheses from the start of their undergraduate training. Characteristics of new Net-based experiment generators are discussed and compared with traditional stand-alone generators. A call is made to formally evaluate the instructional effectiveness of the wide range of experiment generators now available. Specifically, software should be evaluated in terms of known learning outcomes, using appropriate control groups. The many inherent differences between any two software programs should be made clear. The teacher's instructional method should be fully described and held constant between comparisons. Finally, the often complex interaction between the teacher's instructional method and the pedagogical details of the software must be considered", "keyphrases": ["experiment psycholog teach", "laboratori scienc", "internet", "comput", "well-design experi", "hypothesi test", "undergradu train", "net-bas experi gener", "stand-alon gener", "instruct effect", "softwar", "known learn outcom", "control group", "teacher instruct method", "pedagog detail"]}
{"file_name": "1979.abstr", "text": "Combining spatial and scale-space techniques for edge detection to provide a spatially adaptive wavelet-based noise filtering algorithm. New methods for detecting edges in an image using spatial and scale-space domains are proposed. A priori knowledge about geometrical characteristics of edges is used to assign a probability factor to the chance of any pixel being on an edge. An improved double thresholding technique is introduced for spatial domain filtering. Probabilities that pixels belong to a given edge are assigned based on pixel similarity across gradient amplitudes, gradient phases and edge connectivity. The scale-space approach uses dynamic range compression to allow wavelet correlation over a wider range of scales. A probabilistic formulation is used to combine the results obtained from filtering in each domain to provide a final edge probability image which has the advantages of both spatial and scale-space domain methods. Decomposing this edge probability image with the same wavelet as the original image permits the generation of adaptive filters that can recognize the characteristics of the edges in all wavelet detail and approximation images regardless of scale. These matched filters permit significant reduction in image noise without contributing to edge distortion. The spatially adaptive wavelet noise-filtering algorithm is qualitatively and quantitatively compared to a frequency domain and two wavelet based noise suppression algorithms using both natural and computer generated noisy images", "keyphrases": ["spatial techniqu", "scale-spac techniqu", "edg detect", "spatial adapt wavelet-bas nois filter algorithm", "a priori knowledg", "geometr characterist", "probabl factor", "doubl threshold techniqu", "spatial domain filter", "pixel similar", "gradient amplitud", "gradient phase", "edg connect", "dynam rang compress", "wavelet correl", "probabilist formul", "final edg probabl imag", "adapt filter", "approxim imag", "match filter", "imag nois", "spatial adapt wavelet noise-filt algorithm", "nois suppress"]}
{"file_name": "2091.abstr", "text": "Prospects for quantitative computed tomography imaging in the presence of foreign metal bodies using statistical image reconstruction. X-ray computed tomography (CT) images of patients bearing metal intracavitary applicators or other metal foreign objects exhibit severe artifacts including streaks and aliasing. We have systematically evaluated via computer simulations the impact of scattered radiation, the polyenergetic spectrum, and measurement noise on the performance of three reconstruction algorithms: conventional filtered backprojection (FBP), deterministic iterative deblurring, and a new iterative algorithm, alternating minimization (AM), based on a CT detector model that includes noise, scatter, and polyenergetic spectra. Contrary to the dominant view of the literature, FBP streaking artifacts are due mostly to mismatches between FBP's simplified model of CT detector response and the physical process of signal acquisition. Artifacts on AM images are significantly mitigated as this algorithm substantially reduces detector-model mismatches. However, metal artifacts are reduced to acceptable levels only when prior knowledge of the metal object in the patient, including its pose, shape, and attenuation map, are used to constrain AM's iterations. AM image reconstruction, in combination with object-constrained CT to estimate the pose of metal objects in the patient, is a promising approach for effectively mitigating metal artifacts and making quantitative estimation of tissue attenuation coefficients a clinical possibility", "keyphrases": ["quantit comput tomographi imag", "foreign metal bodi", "statist imag reconstruct", "metal artifact reduct", "brachytherapi", "medic diagnost imag", "signal acquisit physic process", "object-constrain ct", "iter algorithm", "altern minim", "ct detector model", "nois", "scatter", "polyenerget spectra", "clinic possibl", "determinist iter deblur", "filter backproject"]}
{"file_name": "256.abstr", "text": "Debugging Web applications. The author considers how one can save time tracking down bugs in Web-based applications by arming yourself with the right tools and programming practices. A wide variety of debugging tools have been written with Web developers in mind", "keyphrases": ["web applic debug tool", "program"]}
{"file_name": "402.abstr", "text": "Fast frequency acquisition phase-frequency detectors for Gsamples/s phase-locked loops. This paper describes two techniques for designing phase-frequency detectors (PFDs) with higher operating frequencies [periods of less than 8* the delay of a fan-out-4 inverter (FO-4)] and faster frequency acquisition. Prototypes designed in 0.25- mu m CMOS process exhibit operating frequencies of 1.25 GHz [=1/(8.FO-4)] and 1.5 GHz [=1/(6.7.FO-4)] for two techniques, respectively, whereas a conventional PFD operates at <1 GHz [=1/(10.FO-4)]. The two proposed PFDs achieve a capture range of 1.7* and 1.4* the conventional design, respectively", "keyphrases": ["phase-frequ detector", "fast frequenc acquisit", "cmo process", "clock gener", "latch-bas pfd architectur", "phase-lock loop", "gsamples/ pll", "pass-transistor dff pfd architectur", "1.25 ghz", "1.5 ghz", "0.25 micron"]}
{"file_name": "1932.abstr", "text": "Solution of the safe problem on (0,1)-matrices. A safe problem with mn locks is studied. It is reduced to a system of linear equations in the modulo 2 residue class. There are three possible variants defined by the numbers m and n evenness, with only one of them having a solution. In two other cases, correction of the initial state of the safe insuring a solution is proposed", "keyphrases": ["safe problem", "mn lock", "linear equat", "modulo 2 residu class", "(0", "1)-matric", "comput game", "linear diophantin equat"]}
{"file_name": "1974.abstr", "text": "Real-time implementation of a new low-memory SPIHT image coding algorithm using DSP chip. Among all algorithms based on wavelet transform and zerotree quantization, Said and Pearlman's (1996) set partitioning in hierarchical trees (SPIHT) algorithm is well-known for its simplicity and efficiency. This paper deals with the real-time implementation of SPIHT algorithm using DSP chip. In order to facilitate the implementation and improve the codec's performance, some relative issues are thoroughly discussed, such as the optimization of program structure to speed up the wavelet decomposition. SPIHT's high memory requirement is a major drawback for hardware implementation. In this paper, we modify the original SPIHT algorithm by presenting two new concepts-number of error bits and absolute zerotree. Consequently, the memory cost is significantly reduced. We also introduce a new method to control the coding process by number of error bits. Our experimental results show that the implementation meets common requirement of real-time video coding and is proven to be a practical and efficient DSP solution", "keyphrases": ["spiht algorithm", "real-tim implement", "wavelet transform", "zerotre quantiz", "codec", "wavelet decomposit", "number of error bit", "absolut zerotre", "dsp chip", "set partit in hierarch tree", "memori cost reduct", "video code"]}
{"file_name": "2022.abstr", "text": "Two-step integral imaging for orthoscopic three-dimensional imaging with improved viewing resolution. We present a two-step integral imaging system to obtain 3-D orthoscopic real images. By adopting a nonstationary micro-optics technique, we demonstrate experimentally the potential usefulness of two-step integral imaging", "keyphrases": ["two-step integr imag", "resolut improv view", "two-step integr imag system", "3-d orthoscop real imag", "nonstationari micro-opt techniqu", "3-d imag reconstruct", "liquid crystal light valv", "display devic", "lclv", "pickup lenslet array"]}
{"file_name": "330.abstr", "text": "Improving computer security for authentication of users: influence of proactive password restrictions. Entering a user name-password combination is a widely used procedure for identification and authentication in computer systems. However, it is a notoriously weak method, in that the passwords adopted by many users are easy to crack. In an attempt to, improve security, proactive password checking may be used, in which passwords must meet several criteria to be more resistant to cracking. In two experiments, we examined the influence of proactive password restrictions on the time that it took to generate an acceptable password and to use it subsequently to log in. The required length was a minimum of five characters in experiment I and eight characters in experiment 2. In both experiments, one condition had only the length restriction, and the other had additional restrictions. The additional restrictions greatly increased the time it took to generate the password but had only a small effect on the time it took to use it subsequently to log in. For the five-character passwords, 75% were cracked when no other restrictions were imposed, and this was reduced to 33% with the additional restrictions. For the eight-character passwords, 17% were cracked with no other restrictions, and 12.5% with restrictions. The results indicate that increasing the minimum character length reduces crackability and increases security, regardless of whether additional restrictions are imposed", "keyphrases": ["comput secur", "user authent", "proactiv password check", "proactiv password restrict", "length restrict", "five-charact password", "eight-charact password"]}
{"file_name": "1955.abstr", "text": "Simulation of evacuation processes using a bionics-inspired cellular automaton model for pedestrian dynamics. We present simulations of evacuation processes using a recently introduced cellular automaton model for pedestrian dynamics. This model applies a bionics approach to describe the interaction between the pedestrians using ideas from chemotaxis. Here we study a rather simple situation, namely the evacuation from a large room with one or two doors. It is shown that the variation of the model parameters allows to describe different types of behaviour, from regular to panic. We find a non-monotonic dependence of the evacuation times on the coupling constants. These times depend on the strength of the herding behaviour, with minimal evacuation times for some intermediate values of the couplings, i.e., a proper combination of herding and use of knowledge about the shortest way to the exit", "keyphrases": ["evacu process simul", "chemotaxi", "nonmonoton depend", "coupl constant", "herd behaviour", "bionics-inspir cellular automaton model", "pedestrian dynam"]}
{"file_name": "325.abstr", "text": "Open courseware and shared knowledge in higher education. Most college and university campuses in the United States and much of the developed world today maintain one, two, or several learning management systems (LMSs), which are courseware products that provide students and faculty with Web-based tools to manage course-related applications. Since the mid-1990s, two predominant models of Web courseware management systems have emerged: commercial and noncommercial. Some of the commercial products available today were created in academia as noncommercial but have since become commercially encumbered. Other products remain noncommercial but are struggling to survive in a world of fierce commercial competition. This article argues for an ethics of pedagogy in higher education that would be based on the guiding assumptions of the non-proprietary, peer-to-peer, open-source software movement", "keyphrases": ["open coursewar", "share knowledg", "higher educ", "learn manag system", "colleg", "univers", "web coursewar manag system", "commerci product", "ethic", "internet", "open-sourc softwar"]}
{"file_name": "1982.abstr", "text": "Verifying resonant grounding in distribution systems. The authors describe RESFAL, a software tool that can check on the behavior of distribution network resonant grounding systems with regard to compensation coil tuning and to fault detection", "keyphrases": ["resfal softwar tool", "reson ground system", "compens coil tune", "fault detect", "comput simul", "power distribut system"]}
{"file_name": "2056.abstr", "text": "Gifts to a science academic librarian. Gifts, by their altruistic nature, perfectly fit into the environment of universities and academic libraries. As a university's community and general public continue to donate materials, libraries accept donations willingly, both in-kind and monetary. Eight steps of gift processing are listed in the paper. Positive and negative aspects of gift acceptance are discussed. Gifts bring value for academic libraries. Gifts can be considered additional routes to contribute to library collections without direct purchases, options to add money to the library budget, and the cement of social relationships. But, unfortunately, large donations are time-consuming, labor-intensive and costly to process. Great amounts of staff time and processing space are two main negative aspects that cause concern and put the value of gift acceptance under consideration by librarians. Some strategies in handling gifts are recommended. To be effective, academic science librarians need to approach gifts as an investment. Librarians are not to be forced by moral and public notions and should be able to make professional decisions in evaluating proposed collections", "keyphrases": ["scienc academ librarian", "academ librari", "donat", "gift process", "librari collect", "budget", "staff time", "profession decis", "research librari", "acquisit", "gift book"]}
{"file_name": "338.abstr", "text": "Down up [IT projects]. Despite the second quarter's gloomy GDP report, savvy CIOs are forging ahead with big IT projects that will position their companies to succeed when the economy soars again", "keyphrases": ["strateg technolog project", "walgreen", "ford", "caterpillar", "victoria' secret", "morgan stanley", "stapl"]}
{"file_name": "2014.abstr", "text": "Adaptive filtering for noise reduction in hue saturation intensity color space. Even though the hue saturation intensity (HSI) color model has been widely used in color image processing and analysis, the conversion formulas from the RGB color model to HSI are nonlinear and complicated in comparison with the conversion formulas of other color models. When an RGB image is degraded by random Gaussian noise, this nonlinearity leads to a nonuniform noise distribution in HSI, making accurate image analysis more difficult. We have analyzed the noise characteristics of the HSI color model and developed an adaptive spatial filtering method to reduce the magnitude of noise and the nonuniformity of noise variance in the HSI color space. With this adaptive filtering method, the filter kernel for each pixel is dynamically adjusted, depending on the values of intensity and saturation. In our experiments we have filtered the saturation and hue components and generated edge maps from color gradients. We have found that by using the adaptive filtering method, the minimum error rate in edge detection improves by approximately 15%", "keyphrases": ["adapt filter", "nois reduct", "hue satur intens color space", "color imag process", "color imag analysi", "rgb color model", "random gaussian nois", "nonuniform nois distribut", "accur imag analysi", "adapt spatial filter method", "nonuniform", "nois varianc", "hsi color space", "filter kernel", "pixel", "satur", "intens", "gener edg map", "color gradient", "edg detect", "minimum error rate"]}
{"file_name": "2190.abstr", "text": "Standards for service discovery and delivery. For the past five years, competing industries and standards developers have been hotly pursuing automatic configuration, now coined the broader term service discovery. Jini, Universal Plug and Play (UPnP), Salutation, and Service Location Protocol are among the front-runners in this new race. However, choosing service discovery as the topic of the hour goes beyond the need for plug-and-play solutions or support for the SOHO (small office/home office) user. Service discovery's potential in mobile and pervasive computing environments motivated my choice", "keyphrases": ["servic discoveri", "jini", "univers plug and play", "salut", "servic locat protocol", "mobil comput", "pervas comput"]}
{"file_name": "1936.abstr", "text": "A new approach to the decomposition of Boolean functions by the method of q-partitions.II. Repeated decomposition. For pt.I see Upr. Sist. Mash., no. 6, p. 29-42 (1999). A new approach to the decomposition of Boolean,functions that depend on n variables and are represented in various forms is considered. The approach is based on the method of q-partitioning of minterms and on the introduced concept of a decomposition clone. The theorem on simple disjunctive decomposition of full and partial functions is formulated. The approach proposed is illustrated by examples", "keyphrases": ["boolean function decomposit", "minterm", "decomposit clone", "disjunct decomposit", "partial function", "logic synthesi", "q-partit"]}
{"file_name": "2089.abstr", "text": "World's biggest battery helps to stabilise Alaska. In this paper, the author describes a battery energy storage system which is under construction to provide voltage compensation in support of Alaska's 138 kV Northern Intertie", "keyphrases": ["power system stabilis", "batteri energi storag system", "voltag compens", "usa", "interconnect power system", "138 kv", "77 mw"]}
{"file_name": "269.abstr", "text": "Genetic algorithm guided selection: variable selection and subset selection. A novel genetic algorithm guided selection method, GAS, has been described. The method utilizes a simple encoding scheme which can represent both compounds and variables used to construct a QSAR/QSPR model. A genetic algorithm is then utilized to simultaneously optimize the encoded variables that include both descriptors and compound subsets. The GAS method generates multiple models each applying to a subset of the compounds. Typically the subsets represent clusters with different chemotypes. Also a procedure based on molecular similarity is presented to determine which model should be applied to a given test set compound. The variable selection method implemented in GAS has been tested and compared using the Selwood data set (n = 31 compounds; nu = 53 descriptors). The results showed that the method is comparable to other published methods. The subset selection method implemented in GAS has been first tested using an artificial data set (n = 100 points; nu = 1 descriptor) to examine its ability to subset data points and second applied to analyze the XLOGP data set (n = 1831 compounds; nu = 126 descriptors). The method is able to correctly identify artificial data points belonging to various subsets. The analysis of the XLOGP data set shows that the subset selection method can be useful in improving a QSAR/QSPR model when the variable selection method fails", "keyphrases": ["genet algorithm guid select method", "encod scheme", "compound", "variabl", "variabl select", "subset select", "qsar/qspr model", "optim", "descriptor", "compound subset", "multipl model", "cluster", "chemotyp", "molecular similar", "selwood data set", "xlogp data set", "artifici data point"]}
{"file_name": "406.abstr", "text": "Windows XP fast user switching. The Windows NT family of operating systems has always supported the concept of multiple user accounts, but they've taken the concept a step further with Windows XP's Fast User Switching feature. Fast User Switching is a new feature of Windows XP that allows multiple users to log on to the same machine and quickly switch between the logged on accounts. Fast User Switching is implemented using some of the built-in capabilities of Terminal Services. Terminal Server has been around for a while but is much more feature rich and integrated in Windows XP. A machine with the terminal services (Remote Desktop) client can log on to and run applications on a remote machine running the terminal server", "keyphrases": ["window xp fast user switch", "multipl user logon access", "oper system", "multipl user account", "termin servic", "termin server", "remot desktop"]}
{"file_name": "227.abstr", "text": "Relativistic constraints on the distinguishability of orthogonal quantum states. The constraints imposed by special relativity on the distinguishability of quantum states are discussed. An explicit expression relating the probability of an error in distinguishing two orthogonal single-photon states to their structure, the time t at which a measurement starts, and the interval of time T elapsed from the start of the measurement until the time at which the outcome is obtained by an observer is given as an example", "keyphrases": ["relativist constraint", "orthogon quantum state", "special rel", "orthogon single-photon state", "time interv", "observ", "nonrelativist quantum inform theori", "quantum commun channel", "quantum-st distinguish"]}
{"file_name": "263.abstr", "text": "K-12 instruction and digital access to archival materials. Providing K-12 schools with digital access to archival materials can strengthen both student learning and archival practice, although it cannot replace direct physical access to records. The article compares a variety of electronic and nonelectronic projects to promote teaching with primary source materials. The article also examines some of the different historiographical and pedagogical approaches used in archival Web sites geared for K-12 instruction, focusing on differences between the educational sites sponsored by the Library of Congress and the National Archives and Records Administration", "keyphrases": ["k-12 instruct", "digit access", "archiv materi", "student learn", "archiv practic", "electron project", "nonelectron project", "primari sourc materi", "direct physic access", "historiograph approach", "pedagog approach", "archiv web", "educ site", "librari of congress", "nation archiv and record administr"]}
{"file_name": "31.abstr", "text": "Adaptive neural/fuzzy control for interpolated nonlinear systems. Adaptive control for nonlinear time-varying systems is of both theoretical and practical importance. We propose an adaptive control methodology for a class of nonlinear systems with a time-varying structure. This class of systems is composed of interpolations of nonlinear subsystems which are input-output feedback linearizable. Both indirect and direct adaptive control methods are developed, where the spatially localized models (in the form of Takagi-Sugeno fuzzy systems or radial basis function neural networks) are used as online approximators to learn the unknown dynamics of the system. Without assumptions on rate of change of system dynamics, the proposed adaptive control methods guarantee that all internal signals of the system are bounded and the tracking error is asymptotically stable. The performance of the adaptive controller is demonstrated using a jet engine control problem", "keyphrases": ["adapt neural/fuzzi control", "interpol nonlinear system", "time-vari system", "input-output feedback lineariz system", "indirect control", "direct control", "spatial local model", "takagi-sugeno fuzzi system", "radial basi function neural network", "onlin approxim", "unknown dynam", "track error", "jet engin control", "stabil analysi"]}
{"file_name": "364.abstr", "text": "MACLP: multi agent constraint logic programming. Multi agent systems (MAS) have become the key technology for decomposing complex problems in order to solve them more efficiently, or for problems distributed in nature. However, many industrial applications, besides their distributed nature, also involve a large number of parameters and constraints, i.e they are combinatorial. Solving such particularly hard problems efficiently requires programming tools that combine MAS technology with a programming schema that facilitates the modeling and solution of constraints. This paper presents MACLP (multi agent constraint logic programming), a logic programming platform for building, in a declarative way, multi agent systems with constraint-solving capabilities. MACLP extends CSPCONS, a logic programming system that permits distributed program execution through communicating sequential Prolog processes with constraints, by providing all the necessary facilities for communication between agents. These facilities abstract from the programmer all the low-level details of the communication and allow him to focus on the development of the agent itself", "keyphrases": ["multi agent constraint logic program", "multi agent system", "paramet", "combinatori problem", "hard problem", "constraint solv", "distribut program execut", "commun sequenti prolog process"]}
{"file_name": "1995.abstr", "text": "A comparison of computational color constancy algorithms. I: Methodology and experiments with synthesized data. We introduce a context for testing computational color constancy, specify our approach to the implementation of a number of the leading algorithms, and report the results of three experiments using synthesized data. Experiments using synthesized data are important because the ground truth is known, possible confounds due to camera characterization and pre-processing are absent, and various factors affecting color constancy can be efficiently investigated because they can be manipulated individually and precisely. The algorithms chosen for close study include two gray world methods, a limiting case of a version of the Retinex method, a number of variants of Forsyth's (1990) gamut-mapping method, Cardei  's (2000) neural net method, and Finlayson  's color by correlation method (Finlayson  1997, 2001; Hubel and Finlayson 2000) . We investigate the ability of these algorithms to make estimates of three different color constancy quantities: the chromaticity of the scene illuminant, the overall magnitude of that illuminant, and a corrected, illumination invariant, image. We consider algorithm performance as a function of the number of surfaces in scenes generated from reflectance spectra, the relative effect on the algorithms of added specularities, and the effect of subsequent clipping of the data. All data is available on-line at http://www.cs.sfu.ca/~color/data, and implementations for most of the algorithms are also available (http://www.cs.sfu.ca/~color/code)", "keyphrases": ["comput color constanc algorithm", "synthes data", "gray world method", "retinex method", "gamut-map method", "neural net method", "color by correl method", "chromat", "scene illumin", "illumin invari imag", "algorithm perform", "reflect spectra", "specular", "clip"]}
{"file_name": "1952.abstr", "text": "Comprehensive encoding and decoupling solution to problems of decoherence and design in solid-state quantum computing. Proposals for scalable quantum computing devices suffer not only from decoherence due to the interaction with their environment, but also from severe engineering constraints. Here we introduce a practical solution to these major concerns, addressing solid-state proposals in particular. Decoherence is first reduced by encoding a logical qubit into two qubits, then completely eliminated by an efficient set of decoupling pulse sequences. The same encoding removes the need for single-qubit operations, which pose a difficult design constraint. We further show how the dominant decoherence processes can be identified empirically, in order to optimize the decoupling pulses", "keyphrases": ["solid-st quantum comput", "decoher", "logic qubit encod", "puls sequenc decoupl", "engin constraint", "decoupl puls optim", "scalabl quantum comput devic", "exchang hamiltonian"]}
{"file_name": "2134.abstr", "text": "Linear models of circuits based on the multivalued components. Linearization and planarization of the circuit models is pivotal to the submicron technologies. On the other hand, the characteristics of the VLSI circuits can be sometimes improved by using the multivalued components. It was shown that any l-level circuit based on the multivalued components is representable as an algebraic model based on l linear arithmetic polynomials mapped correspondingly into l decision diagrams that are linear and planar by nature. Complexity of representing a circuit as the linear decision diagram was estimated as O(G) with G for the number of multivalued components in the circuit. The results of testing the LinearDesignMV algorithm on circuits of more than 8000 LGSynth 93 multivalued components were presented", "keyphrases": ["linear circuit model", "linear", "planar", "submicron technolog", "vlsi circuit", "linear arithmet polynomi", "linear planar decis diagram", "circuit represent complex", "lineardesignmv algorithm", "lgsynth 93 multivalu compon"]}
{"file_name": "266.abstr", "text": "Pattern recognition strategies for molecular surfaces. I. Pattern generation using fuzzy set theory. A new method for the characterization of molecules based on the model approach of molecular surfaces is presented. We use the topographical properties of the surface as well as the electrostatic potential, the local lipophilicity/hydrophilicity, and the hydrogen bond density on the surface for characterization. The definition and the calculation method for these properties are reviewed. The surface is segmented into overlapping patches with similar molecular properties. These patches can be used to represent the characteristic local features of the molecule in a way that is beyond the atomistic resolution but can nevertheless be applied for the analysis of partial similarities of different molecules as well as for the identification of molecular complementarity in a very general sense. The patch representation can be used for different applications, which will be demonstrated in subsequent articles", "keyphrases": ["pattern recognit strategi", "molecular surfac", "pattern gener", "fuzzi set theori", "model approach", "topograph properti", "electrostat potenti", "local lipophilicity/hydrophil", "hydrogen bond densiti", "segment surfac", "overlap patch", "molecular properti", "local featur", "atomist resolut", "partial similar", "molecular complementar", "patch represent", "lipophil", "hydrophil"]}
{"file_name": "270.abstr", "text": "Using molecular equivalence numbers to visually explore structural features that distinguish chemical libraries. A molecular equivalence number (meqnum) classifies a molecule with respect to a class of structural features or topological shapes such as its cyclic system or its set of functional groups. Meqnums can be used to organize molecular structures into nonoverlapping, yet highly relatable classes. We illustrate the construction of some different types of meqnums and present via examples some methods of comparing diverse chemical libraries based on meqnums. In the examples we compare a library which is a random sample from the MDL Drug Data Report (MDDR) with a library which is a random sample from the Available Chemical Directory (ACD). In our analyses, we discover some interesting features of the topological shape of a molecule and its set of functional groups that are strongly linked with compounds occurring in the MDDR but not in the ACD. We also illustrate the utility of molecular equivalence indices in delineating the structural domain over which an SAR conclusion is valid", "keyphrases": ["molecular equival number", "molecul classif", "structur featur", "topolog shape", "cyclic system", "function group", "nonoverlap relat class", "chemic librari", "mdl drug data report", "avail chemic directori", "molecular equival indic"]}
{"file_name": "2004.abstr", "text": "New paradigms for interactive 3D volume segmentation. We present a new virtual reality-based interaction metaphor for semi-automatic segmentation of medical 3D volume data. The mouse-based, manual initialization of deformable surfaces in 3D represents a major bottleneck in interactive segmentation. In our multi-modal system we enhance this process with additional sensory feedback. A 3D haptic device is used to extract the centreline of a tubular structure. Based on the obtained path a cylinder with varying diameter is generated, which in turn is used as the initial guess for a deformable surface", "keyphrases": ["interact 3d volum segment", "virtual realiti", "interact metaphor", "medic imag segment", "mous", "deform surfac", "interact segment", "multi-mod system", "sensori feedback", "3d haptic devic", "tubular structur", "vari diamet cylind", "deform surfac", "haptic interact"]}
{"file_name": "218.abstr", "text": "ISCSI poised to lower SAN costs. IT managers building storage area networks or expanding their capacity may be able to save money by using iSCSI and IP systems rather than Fibre Channel technologies", "keyphrases": ["san cost", "storag area network", "iscsi", "ip system"]}
{"file_name": "243.abstr", "text": "BioOne: a new model for scholarly publishing. This article describes a unique electronic journal publishing project involving the University of Kansas, the Big 12 Plus Libraries Consortium, the American Institute of Biological Sciences, Allen Press, and SPARC, the Scholarly Publishing and Academic Resources Coalition. This partnership has created BioOne, a database of 40 full-text society journals in the biological and environmental sciences, which was launched in April, 2001. The genesis and development of the project is described and financial, technical, and intellectual property models for the project are discussed. Collaborative strategies for the project are described", "keyphrases": ["bioon full-text societi journal databas", "electron journal publish project", "scholarli publish model", "univers of kansa", "big 12 plu librari consortium", "american institut of biolog scienc", "allen press", "sparc", "scholarli publish and academ resourc coalit", "biolog scienc", "environment scienc", "intellectu properti model", "technic model", "financi model", "collabor strategi"]}
{"file_name": "212.abstr", "text": "Knowledge management-capturing the skills of key performers in the power industry. The growing pressure to reduce the cost of electrical power in recent years has resulted in an enormous \"brain-drain\" within the power industry. A novel approach has been developed by Eskom to capture these skills before they are lost and to incorporate these into a computer-based programme called \"knowledge management\"", "keyphrases": ["power industri", "key perform", "knowledg manag", "skill captur", "brain-drain", "eskom", "computer-bas programm", "south africa", "personnel manag"]}
{"file_name": "206.abstr", "text": "Information architecture: looking ahead. It may be a bit strange to consider where the field of information architecture (IA) is headed. After all, many would argue that it's too new to be considered as a field at all, or that it is mislabeled, and by no means is there a widely accepted definition of what information architecture actually is. Practicing information architects probably number in the thousands, and this vibrant group is already building various forms of communal infrastructure, ranging from an IA journal and a self-organizing \"library\" of resources to a passel of local professional groups and degree-granting academic programs. So the profession has achieved a beachhead that will enable it to stabilize and perhaps even grow during these difficult times", "keyphrases": ["inform architectur", "inform architect", "commun infrastructur", "local profession group", "degree-gr academ program"]}
{"file_name": "2084.abstr", "text": "Evaluation of combined dispatching and routeing strategies for a flexible manufacturing system. This paper deals with the evaluation of combined dispatching and routeing strategies on the performance of a flexible manufacturing system. Three routeing policies - no alternative routings, alternative routeing dynamics and alternative routeing plans - are considered with four dispatching rules with finite buffer capacity. In addition, the effect of changing part mix ratios is also discussed. The performance measures considered are makespan, average machine utilization, average flow time and average delay at local input buffers. Simulation results indicate that the alternative routings dynamic policy gives the best results in three performance measures except for average delay at local input buffers. Further, the effect of changing part mix ratios is not significant", "keyphrases": ["altern rout", "flexibl manufactur system", "fm", "dispatch rule", "finit buffer capac", "part mix ratio", "averag flow time"]}
{"file_name": "41.abstr", "text": "Controller performance analysis with LQG benchmark obtained under closed loop conditions. This paper proposes a new method for obtaining a linear quadratic Gaussian (LQG) benchmark in terms of the variances of process input and output from closed-loop data, for assessing the controller performance. LQG benchmark has been proposed in the literature to assess controller performance since the LQG tradeoff curve represents the limit of performance in terms of input and output variances. However, an explicit parametric model is required to calculate the LQG benchmark. In this work, we propose a data driven subspace approach to calculate the LQG benchmark under closed-loop conditions with certain external excitations. The optimal LQG-benchmark variances are obtained directly from the subspace matrices corresponding to the deterministic inputs and the stochastic inputs, which are identified using closed-loop data with setpoint excitation. These variances are used for assessing the controller performance. The method proposed in this paper is applicable to both univariate and multivariate systems. Profit analysis for the implementation of feedforward control to the existing feedback-only control system is also analyzed under the optimal LQG performance framework", "keyphrases": ["control perform analysi", "lqg benchmark", "linear quadrat gaussian benchmark", "closed-loop data", "subspac matric", "determinist input", "stochast input", "univari system", "multivari system", "profit analysi", "feedforward control", "state space model"]}
{"file_name": "40.abstr", "text": "New tuning method for PID controller. In this paper, a tuning method for proportional-integral-derivative (PID) controller and the performance assessment formulas for this method are proposed. This tuning method is based on a genetic algorithm based PID controller design method. For deriving the tuning formula, the genetic algorithm based design method is applied to design PID controllers for a variety of processes. The relationship between the controller parameters and the parameters that characterize the process dynamics are determined and the tuning formula is then derived. Using simulation studies, the rules for assessing the performance of a PID controller tuned by the proposed method are also given. This makes it possible to incorporate the capability to determine if the PID controller is well tuned or not into an autotuner. An autotuner based on this new tuning method and the corresponding performance assessment rules is also established. Simulations and real-time experimental results are given to demonstrate the effectiveness and usefulness of these formulas", "keyphrases": ["tune method", "pid control", "proportional-integral-deriv control", "genet algorithm", "control design method", "process dynam", "autotun"]}
{"file_name": "2154.abstr", "text": "Optimize/sup IT/ robot condition monitoring tool. As robots have gained more and more 'humanlike' capability, users have looked increasingly to their builders for ways to measure the critical variables-the robotic equivalent of a physical check-up-in order to monitor their condition and schedule maintenance more effectively. This is all the more essential considering the tremendous pressure there is to improve productivity in today's global markets. Developed for ABB robots with an S4-family controller and based on the company's broad process know-how, Optimize/sup IT/ robot condition monitoring offers maintenance routines with embedded checklists that give a clear indication of a robot's operating condition. It performs semi-automatic measurements that support engineers during trouble-shooting and enable action to be taken to prevent unplanned stops. By comparing these measurements with reference data, negative trends can be detected early and potential breakdowns predicted. Armed with all these features, Optimize/sup IT/ robot condition monitoring provides the ideal basis for reliability-centered maintenance (RCM) for robots", "keyphrases": ["optimize/sup it/ robot condit monitor tool", "mainten schedul", "condit monitor", "abb robot", "s4-famili control", "semi-automat measur", "reliability-cent mainten"]}
{"file_name": "311.abstr", "text": "Information architecture without internal theory: an inductive design process. This article suggests that Information Architecture (IA) design is primarily an inductive process. Although top-level goals, user attributes and available content are periodically considered, the process involves bottom-up design activities. IA is inductive partly because it lacks internal theory, and partly because it is an activity that supports emergent phenomena (user experiences) from basic design components. The nature of IA design is well described by Constructive Induction (CI), a design process that involves locating the best representational framework for the design problem, identifying a solution within that framework and translating it back to the design problem at hand. The future of IA, if it remains inductive or develops a body of theory (or both), is considered", "keyphrases": ["inform architectur design", "induct design process", "bottom-up design activ", "intern theori", "emerg phenomena", "user experi", "construct induct"]}
{"file_name": "202.abstr", "text": "Estimation of error in curvature computation on multi-scale free-form surfaces. A novel technique for multi-scale curvature computation on a free-form 3-D surface is presented. This is achieved by convolving local parametrisations of the surface with 2-D Gaussian filters iteratively. In our technique, semigeodesic coordinates are constructed at each vertex of the mesh. Smoothing results are shown for 3-D surfaces with different shapes indicating that surface noise is eliminated and surface details are removed gradually. A number of evolution properties of 3-D surfaces are described. Next, the surface Gaussian and mean curvature values are estimated accurately at multiple scales which are then mapped to colours and displayed directly on the surface. The performance of the technique when selecting different directions as an arbitrary direction for the geodesic at each vertex are also presented. The results indicate that the error observed for the estimation of Gaussian and mean curvatures is quite low after only one iteration. Furthermore, as the surface is smoothed iteratively, the error is further reduced. The results also show that the estimation error of Gaussian curvature is less than that of mean curvature. Our experiments demonstrate that estimation of smoothed surface curvatures are very accurate and not affected by the arbitrary direction of the first geodesic line when constructing semigeodesic coordinates. Our technique is independent of the underlying triangulation and is also more efficient than volumetric diffusion techniques since 2-D rather than 3-D convolutions are employed. Finally, the method presented here is a generalisation of the Curvature Scale Space method for 2-D contours. The CSS method has outperformed comparable techniques within the MPEG-7 evaluation framework. As a result, it has been selected for inclusion in the MPEG-7 package of standards", "keyphrases": ["multi-scal curvatur comput", "free-form 3d surfac", "local parametris", "2d gaussian filter", "surfac nois", "evolut properti", "surfac gaussian valu", "mean curvatur valu", "semigeodes coordin", "underli triangul", "volumetr diffus techniqu", "convolut", "curvatur scale space method", "mpeg-7 evalu framework"]}
{"file_name": "2036.abstr", "text": "Computer processing of data on mental impairments during the acute period of concussion. The article presents results of computer processing of experimental information obtained from patients during the acute period of concussion. A number of computational procedures are described", "keyphrases": ["comput process", "mental impair", "acut period of concuss", "comput procedur"]}
{"file_name": "2115.abstr", "text": "Control of combustion processes in an internal combustion engine by low-temperature plasma. A new method of operation of internal combustion engines enhances power and reduces fuel consumption and exhaust toxicity. Low-temperature plasma control combines working processes of thermal engines and steam machines into a single process", "keyphrases": ["combust process", "intern combust engin", "low-temperatur plasma", "fuel consumpt", "exhaust toxic", "work process", "thermal engin", "steam machin"]}
{"file_name": "2035.abstr", "text": "Search for efficient solutions of multi-criterion problems by target-level method. The target-level method is considered for solving continuous multi-criterion maximization problems. In the first step, the decision-maker specifies a target-level point (the desired criterion values); then in the set of vector evaluations we seek points that are closest to the target point in the Chebyshev metric. The vector evaluations obtained in this way are in general weakly efficient. To identify the efficient evaluations, the second step maximizes the sum of the criteria on the set generated in step 1. We prove the relationship between the evaluations and decisions obtained by the proposed procedure, on the one hand, and the efficient (weakly efficient) evaluations and decisions, on the other hand. If the Edgeworth-Pareto hull of the set of vector evaluations is convex, the set of efficient vector evaluations can be approximated by the proposed method", "keyphrases": ["multi-criterion problem", "target-level method", "continu multi-criterion maxim problem", "target-level point", "chebyshev metric", "edgeworth-pareto hull"]}
{"file_name": "2033.abstr", "text": "Optical encoding of color three-dimensional correlation. Three-dimensional (3D) correlation of color images, considering the color distribution as the third dimension, has been shown to be useful for color pattern recognition tasks. Nevertheless, 3D correlation cannot be directly performed on an optical correlator, that can only process two-dimensional (2D) signals. We propose a method to encode 3D functions onto 2D ones in such a way that the Fourier transform and correlation of these signals, that can be optically performed, encode the 3D Fourier transform and correlation of the 3D signals. The theory for the encoding is given and experimental results obtained in an optical correlator are shown", "keyphrases": ["optic encod", "color three-dimension correl", "3d correl", "color imag", "color distribut", "color pattern recognit task", "optic correl", "3d function encod", "fourier transform", "3d fourier transform"]}
{"file_name": "20.abstr", "text": "Adaptive state feedback control for a class of linear systems with unknown bounds of uncertainties. The problem of adaptive robust stabilization for a class of linear time-varying systems with disturbance and nonlinear uncertainties is considered. The bounds of the disturbance and uncertainties are assumed to be unknown, being even arbitrary. For such uncertain dynamical systems, the adaptive robust state feedback controller is obtained. And the resulting closed-loop systems are asymptotically stable in theory. Moreover, an adaptive robust state feedback control scheme is given. The scheme ensures the closed-loop systems exponentially practically stable and can be used in practical engineering. Finally, simulations show that the control scheme is effective", "keyphrases": ["robust stabil", "adapt stabil", "linear time-vari system", "nonlinear uncertainti", "closed-loop system", "uncertain dynam system", "state feedback", "adapt control", "robust control", "uncertain system"]}
{"file_name": "252.abstr", "text": "Reaching for five nines: ActiveWatch and SiteSeer. Every Web admin's dream is achieving the fabled five nines-99.999 percent uptime. To attain such availability, your Web site must be down no more than about five minutes per year. Technologies like RAID, clustering, and load balancing make this easier, but to actually track uptime, maintain auditable records, and discover patterns in failures to prevent downtime in the future, you'll need to set up external monitoring. Because your Internet connection is a key factor in measuring uptime, you must monitor your site from the Internet itself, beyond your firewall. You could monitor with custom software on remote hosts, or you could use one of the two reasonably priced services available: Mercury Interactive's ActiveWatch and Freshwater Software's SiteSeer (Freshwater Software has been a subsidiary of Mercury Interactive for about a year now.) The two services offer a slightly different mix of features and target different markets. Both services offer availability and performance monitoring from several remote locations, alerts to email or pager, and periodic reports. They differ in what's most easily monitored, and in the way you interact with the services", "keyphrases": ["web site", "uptim track", "audit record", "failur pattern discoveri", "downtim", "extern monitor", "internet connect", "mercuri interact activewatch", "freshwat softwar sites", "perform monitor", "avail monitor", "remot locat", "email alert", "pager alert", "period report"]}
{"file_name": "287.abstr", "text": "Loudspeaker voice-coil inductance losses: circuit models, parameter estimation, and effect on frequency response. When the series resistance is separated and treated as a separate element, it is shown that losses in an inductor require the ratio of the flux to MMF in the core to be frequency dependent. For small-signal operation, this dependence leads to a circuit model composed of a lossless inductor and a resistor in parallel, both of which are frequency dependent. Mathematical expressions for these elements are derived under the assumption that the ratio of core flux to MMF varies as omega /sup n-1/, where n is a constant. A linear regression technique is described for extracting the model parameters from measured data. Experimental data are presented to justify the model for the lossy inductance of a loudspeaker voice-coil. A SPICE example is presented to illustrate the effects of voice-coil inductor losses on the frequency response of a typical driver", "keyphrases": ["loudspeak voice-coil induct loss", "circuit model", "paramet estim", "frequenc respons", "seri resist", "small-sign oper", "linear regress", "lossi induct", "spice", "loudspeak driver", "lossless inductor", "core flux to mmf ratio"]}
{"file_name": "2107.abstr", "text": "The effects of asynchronous computer-mediated group interaction on group processes. This article reports a study undertaken to investigate some of the social psychological processes underlying computer-supported group discussion in natural computer-mediated contexts. Based on the concept of deindividuation, it was hypothesized that personal identifiability and group identity would be important factors that affect the perceptions and behavior of members of computer-mediated groups. The degree of personal identifiability and the strength of group identity were manipulated across groups of geographically dispersed computer users who took part in e-mail discussions during a 2-week period. The results do not support the association between deindividuation and uninhibited behavior cited in much previous research. Instead, the data provide some support for a social identity perspective of computer-mediated communication, which explains the higher levels uninhibited in identifiable computer-mediated groups. However, predictions based on social identity theory regarding group polarization and group cohesion were not supported. Possible explanations for this are discussed and further research is suggested to resolve these discrepancies", "keyphrases": ["asynchron computer-medi group interact", "group process", "social issu", "psycholog", "deindividu", "internet", "person identifi", "group ident", "geograph dispers comput user", "e-mail discuss", "social ident theori", "group polar", "group cohes"]}
{"file_name": "1972.abstr", "text": "Online auctions: dynamic pricing and the lodging industry. The traditional channels of distribution for overnight accommodation are rapidly being displaced by Web site scripting, online intermediaries, and specialty brokers. Businesses that pioneered Internet usage relied on it as a sales and marketing alternative to predecessor product distribution channels. As such, Web sites replace the traditional trading model to the Internet. Web-enabled companies are popular because the medium renders the process faster, less costly, highly reliable, and secure. Auction-based models impact business models by converting the price setting mechanism from supplier-centric to market-centric and transforming the trading model from \"one to many\" to \"many to many.\" Historically, pricing was based on the cost of production plus a margin of profit. Traditionally, as products and services move through the supply chain, from the producer to the consumer, various intermediaries added their share of profit to the price. As Internet based mediums of distribution become more prevalent, traditional pricing models are being supplanted with dynamic pricing. A dynamic pricing model represents a flexible system that changes prices not only from product to product, but also from customer to customer and transaction to transaction. Many industry leaders are skeptical of the long run impact of online auctions on lodging industry profit margins, despite the fact pricing theory suggests that an increase in the flow of information results in efficient market pricing. The future of such endeavors remains promising, but controversial", "keyphrases": ["onlin auction", "dynam price", "lodg industri", "overnight accommod", "web site script", "onlin intermediari", "specialti broker", "internet usag", "sale", "market", "trade model", "busi model", "price set mechan", "suppli chain"]}
{"file_name": "21.abstr", "text": "Discrete output feedback sliding mode control of second order systems - a moving switching line approach. The sliding mode control systems (SMCS) for which the switching variable is designed independent of the initial conditions are known to be sensitive to parameter variations and extraneous disturbances during the reaching phase. For second order systems this drawback is eliminated by using the moving switching line technique where the switching line is initially designed to pass the initial conditions and is subsequently moved towards a predetermined switching line. In this paper, we make use of the above idea of moving switching line together with the reaching law approach to design a discrete output feedback sliding mode control. The main contributions of this work are such that we do not require to use system states as it makes use of only the output samples for designing the controller and by using the moving switching line a low sensitivity system is obtained through shortening the reaching phase. Simulation results show that the fast output sampling feedback guarantees sliding motion similar to that obtained using state feedback", "keyphrases": ["slide mode control", "switch variabl", "paramet variat", "move switch line", "discret output feedback", "fast output sampl feedback", "state feedback"]}
{"file_name": "345.abstr", "text": "In search of strategic operations research/management science. We define strategic OR/MS as \"OR/MS work that leads to a sustainable competitive advantage.\" We found evidence of strategic OR/MS in the literature of strategic information systems (SIS) and OR/MS. We examined 30 early examples of SIS, many of which contained OR/MS work. Many of the most successful had high OR/MS content, while the least successful contained none. The inclusion of OR/MS work may be a key to sustaining an advantage from information technology. We also examined the Edelman Prize finalist articles published between 1990 and 1999. We found that 13 of the 42 private sector applications meet our definition of strategic OR/MS", "keyphrases": ["oper research", "manag scienc", "strateg or/m", "strateg inform system", "si"]}
{"file_name": "1960.abstr", "text": "Streaming, disruptive interference and power-law behavior in the exit dynamics of confined pedestrians. We analyze the exit dynamics of pedestrians who are initially confined in a room. Pedestrians are modeled as cellular automata and compete to escape via a known exit at the soonest possible time. A pedestrian could move forward, backward, left or right within each iteration time depending on adjacent cell vacancy and in accordance with simple rules that determine the compulsion to move and physical capability relative to his neighbors. The arching signatures of jamming were observed and the pedestrians exited in bursts of various sizes. Power-law behavior is found in the burst-size frequency distribution for exit widths w greater than one cell dimension (w > 1). The slope of the power-law curve varies with w from -1.3092 (w = 2) to -1.0720 (w = 20). Streaming which is a diffusive behavior, arises in large burst sizes and is more likely in a single-exit room with w = 1 and leads to a counterintuitive result wherein an average exit throughput Q is obtained that is higher than with w = 2, 3, or 4. For a two-exit room (w = 1), Q is not greater than twice the yield of a single-exit room. If the doors are not separated far enough (< 4w), Q becomes even significantly less due to a collective slow-down that emerges among pedestrians crossing in each other's path (disruptive interference effect). For the same w and door number, Q is also higher with relaxed pedestrians than with anxious ones", "keyphrases": ["stream", "cellular automata", "iter time", "adjac cell vacanc", "arch signatur", "jam", "burst-siz frequenc distribut", "collect slow-down", "self-organis critic", "disrupt interfer", "power-law behavior", "exit dynam", "confin pedestrian"]}
{"file_name": "2117.abstr", "text": "The p-p rearrangement and failure-tolerance of double p-ary multirings and generalized hypercubes. It is shown that an arbitrary grouped p-element permutation can be implemented in a conflict-free way through the commutation of channels on the double p-ary multiring or the double p-ary hypercube. It is revealed that in arbitrary single-element permutations, these commutators display the property of the (p-1)-nodal failure-tolerance and the generalized hypercube displays in addition the property of the (p-1)-channel failure-tolerance", "keyphrases": ["p-p rearrang", "failure-toler", "doubl p-ari multir", "gener hypercub", "p-element permut", "conflict-fre implement", "single-el permut", "commut"]}
{"file_name": "229.abstr", "text": "Simple minds [health care IT]. A few things done properly, and soon, is the short-term strategy for the UK NHS IT programme. Can it deliver this time?", "keyphrases": ["uk nh it programm", "health care", "strategi"]}
{"file_name": "26.abstr", "text": "Learning weights for the quasi-weighted means. We study the determination of weights for quasi-weighted means (also called quasi-linear means) when a set of examples is given. We consider first a simple case, the learning of weights for weighted means, and then we extend the approach to the more general case of a quasi-weighted mean. We consider the case of a known arbitrary generator f. The paper finishes considering the use of parametric functions that are suitable when the values to aggregate are measure values or ratio", "keyphrases": ["quasi-weight mean", "quasi-linear mean", "learn", "parametr function", "measur valu", "ratio valu"]}
{"file_name": "1953.abstr", "text": "Social percolation and the influence of mass media. In the marketing model of Solomon and Weisbuch, people buy a product only if their neighbours tell them of its quality, and if this quality is higher than their own quality expectations. Now we introduce additional information from the mass media, which is analogous to the ghost field in percolation theory. The mass media shift the percolative phase transition observed in the model, and decrease the time after which the stationary state is reached", "keyphrases": ["social percol", "mass media influenc", "solomon-weisbuch market model", "qualiti expect", "ghost field", "percol phase transit", "stationari state", "custom", "cinema", "extern field"]}
{"file_name": "2133.abstr", "text": "Nonlockability in multirings and hypercubes at serial transmission of data blocks. For the multiring and hypercube, a method of conflictless realization of an arbitrary permutation of \"large\" data items that can be divided into many \"smaller\" data blocks was considered, and its high efficiency was demonstrated", "keyphrases": ["nonlock", "multir", "hypercub", "data block serial transmiss", "multiprocessor comput system"]}
{"file_name": "331.abstr", "text": "Multidimensional data visualization. Historically, data visualization has been limited primarily to two dimensions (, histograms or scatter plots). Available software packages (, Data Desk 6.1, MatLab 6.1, SAS-JMP 4.04, SPSS 10.0) are capable of producing three-dimensional scatter plots with (varying degrees of) user interactivity. We constructed our own data visualization application with the Visualization Toolkit (Schroeder , 1998) and Tcl/Tk to display multivariate data through the application of glyphs (Ware, 2000). A glyph is a visual object onto which many data parameters may be mapped, each with a different visual attribute (, size or color). We used our multi-dimensional data viewer to explore data from several psycholinguistic experiments. The graphical interface provides flexibility when users dynamically explore the multidimensional image rendered from raw experimental data. We highlight advantages of multidimensional data visualization and consider some potential limitations", "keyphrases": ["multidimension data visual", "3d scatter plot", "user interact", "visual toolkit", "tcl/tk", "multivari data display", "glyph", "visual object", "data paramet", "visual attribut", "multi-dimension data viewer", "psycholinguist experi", "graphic interfac", "multidimension imag render"]}
{"file_name": "412.abstr", "text": "Using virtual reality to teach disability awareness. A desktop virtual reality (VR) program was designed and evaluated to teach children about the accessibility and attitudinal barriers encountered by their peers with mobility impairments. Within this software, children sitting in a virtual wheelchair experience obstacles such as stairs, narrow doors, objects too high to reach, and attitudinal barriers such as inappropriate comments. Using a collaborative research methodology, 15 youth with mobility impairments assisted in developing and beta-testing the software. The effectiveness of the program was then evaluated with 60 children in Grades 4-6 using a controlled pretest/posttest design. The results indicated that the program was effective for increasing children's knowledge of accessibility barriers. Attitudes, grade level, familiarity with individuals with a disability, and gender were also investigated", "keyphrases": ["virtual realiti", "disabl awar teach", "children", "access", "virtual wheelchair", "collabor research methodolog", "mobil impair", "softwar beta-test", "collabor softwar develop", "comput aid instruct", "softwar effect", "gender"]}
{"file_name": "2151.abstr", "text": "Industrial/sup IT/ for performance buildings. ABB has taken a close look at how buildings are used and has come up with a radical solution for the technical infrastructure that places the end-user's processes at the center and integrates all the building's systems around their needs. The new solution is based on the realization that tasks like setting up an office meeting, registering a hotel guest or moving a patient in a hospital, can all benefit from the same Industrial IT concepts employed by ABB to optimize manufacturing, for example in the automotive industry", "keyphrases": ["industrial/sup it/", "abb", "build manag system", "technic infrastructur", "build system integr", "industri it concept"]}
{"file_name": "387.abstr", "text": "Design and implementation of a brain-computer interface with high transfer rates. This paper presents a brain-computer interface (BCI) that can help users to input phone numbers. The system is based on the steady-state visual evoked potential (SSVEP). Twelve buttons illuminated at different rates were displayed on a computer monitor. The buttons constituted a virtual telephone keypad, representing the ten digits 0-9, BACKSPACE, and ENTER. Users could input phone number by gazing at these buttons. The frequency-coded SSVEP was used to judge which button the user desired. Eight of the thirteen subjects succeeded in ringing the mobile phone using the system. The average transfer rate over all subjects was 27.15 bits/min. The attractive features of the system are noninvasive signal recording, little training required for use, and high information transfer rate. Approaches to improve the performance of the system are discussed", "keyphrases": ["brain-comput interfac with high transfer rate", "phone number input", "steady-st visual evok potenti", "illumin button", "system perform improv", "virtual telephon keypad", "frequency-cod ssvep", "mobil phone ring", "comput monitor"]}
{"file_name": "2116.abstr", "text": "Optimization of the characteristics of computational processes in scalable resources. The scalableness of resources is taken to mean the possibility of the prior change in the obtained dynamic characteristics of computational processes for a certain basic set of processors and the communication medium in an effort to optimize the dynamics of software applications. A method is put forward for the generation of optimal strategies-a set of the versions of the fulfillment of programs on the basis of a vector criterion. The method is urgent for the effective use of resources of computational clusters and metacomputational media and also for dynamic control of processes in real time on the basis of the static scaling", "keyphrases": ["comput process", "scalabl resourc", "dynam characterist", "commun medium", "softwar applic", "optim strategi", "vector criterion", "comput cluster", "metacomput media", "dynam control", "static scale"]}
{"file_name": "2095.abstr", "text": "Global stability of the attracting set of an enzyme-catalysed reaction system. The essential feature of enzymatic reactions is a nonlinear dependency of reaction rate on metabolite concentration taking the form of saturation kinetics. Recently, it has been shown that this feature is associated with the phenomenon of \"loss of system coordination\" (Liu, 1999). In this paper, we study a system of ordinary differential equations representing a branched biochemical system of enzyme-mediated reactions. We show that this system can become very sensitive to changes in certain maximum enzyme activities. In particular, we show that the system exhibits three distinct responses: a unique, globally-stable steady-state, large amplitude oscillations, and asymptotically unbounded solutions, with the transition between these states being almost instantaneous. It is shown that the appearance of large amplitude, stable limit cycles occurs due to a \"false\" bifurcation or canard explosion. The subsequent disappearance of limit cycles corresponds to the collapse of the domain of attraction of the attracting set for the system and occurs due to a global bifurcation in the flow, namely, a saddle connection. Subsequently, almost all nonnegative data become unbounded under the action of the dynamical system and correspond exactly to loss of system coordination. We discuss the relevance of these results to the possible consequences of modulating such systems", "keyphrases": ["enzymat reaction", "nonlinear depend", "metabolit concentr", "satur kinet", "biochem system", "ordinari differenti equat", "enzyme-medi reaction", "saddl connect", "stabl limit cycl", "bifurc"]}
{"file_name": "2088.abstr", "text": "Layer-based machining: recent development and support structure design. There is growing interest in additive and subtractive shaping theories that are synthesized to integrate the layered manufacturing process and material removal process. Layer-based machining has emerged as a promising method for integrated additive and subtractive shaping theory. In the paper, major layer-based machining systems are reviewed and compared according to characteristics of stock layers, numerical control machining configurations, stacking operations, input format and raw materials. Support structure, a major issue in machining-based systems which has seldom been addressed in previous research, is investigated in the paper with considerations of four situations: floating overhang, cantilever, vaulted overhang and ceiling. Except for the floating overhang where a support structure should not be overlooked, the necessity for support structures for the other three situations is determined by stress and deflection analysis. This is demonstrated by the machining of a large castle model", "keyphrases": ["layer-bas machin", "support structur design", "addit shape theori", "subtract shape theori", "layer manufactur process", "materi remov process", "stock layer", "numer control machin configur", "stack oper", "input format", "raw materi", "float overhang", "cantilev", "vault overhang", "ceil", "stress", "deflect analysi"]}
{"file_name": "290.abstr", "text": "MEMS applications in computer disk drive dual-stage servo systems. We present a decoupled discrete time pole placement design method, which can be combined with a self-tuning scheme to compensate variations in the microactuator's (MA's) resonance mode. Section I of the paper describes the design and fabrication of a prototype microactuator with an integrated gimbal structure. Section II presents a decoupled track-following controller design and a self-tuning control scheme to compensate for the MA's resonance mode variations", "keyphrases": ["comput disk drive dual-stag servo system", "mem", "microactu", "servo control", "hard disk drive", "decoupl discret time pole placement design method", "self-tun scheme", "electrostat design", "fabric process", "track-follow control design"]}
{"file_name": "2081.abstr", "text": "Three-dimensional optimum design of the cooling lines of injection moulds based on boundary element design sensitivity analysis. A three-dimensional numerical simulation using the boundary element method is proposed, which can predict the cavity temperature distributions in the cooling stage of injection moulding. Then, choosing the radii and positions of cooling lines as design variables, the boundary integral sensitivity formulations are deduced. For the optimum design of cooling lines, the squared difference between the objective temperature and temperature of the cavity is taken as the objective function. Based on the optimization techniques with design sensitivity analysis, an iterative algorithm to reach the minimum value of the objective function is introduced, which leads to the optimum design of cooling lines at the same time", "keyphrases": ["inject mould", "3d numer simul", "boundari element method", "caviti temperatur distribut", "cool stage", "boundari integr sensit analysi", "iter algorithm", "heat conduct", "object function", "optim"]}
{"file_name": "362.abstr", "text": "On batch-constructing B/sup +/-trees: algorithm and its performance evaluation. Efficient construction of indexes is very important in bulk-loading a database or adding a new index to an existing database since both of them should handle an enormous volume of data. In this paper, we propose an algorithm for batch-constructing the B/sup +/-tree, the most widely used index structure in database systems. The main characteristic of our algorithm is to simultaneously process all the key values to be placed on each B+-tree page when accessing the page. This avoids the overhead due to accessing the same page multiple times, which results from applying the B+-tree insertion algorithm repeatedly. For performance evaluation, we have analyzed our algorithm in terms of the number of disk accesses. The results show that the number of disk accesses excluding those in the relocation process is identical to the number of pages belonging to the B/sup +/-tree. Considering that the relocation process is an unavoidable preprocessing step for batch-constructing of B/sup +/-trees, our algorithm requires just one disk access per B+-tree page, and therefore turns out to be optimal. We also present the performance tendency in relation with different parameter values via simulation. Finally, we show the performance enhancement effect of our algorithm, compared with the one using repeated insertions through experiments", "keyphrases": ["b+-tree batch construct", "algorithm perform evalu", "databas bulk load", "index structur", "b+-tree page", "page access", "b+-tree insert algorithm", "disk access", "reloc process", "simul"]}
{"file_name": "253.abstr", "text": "Accessible streaming content. Make sure your Web site is offering quality service to all your users. The article provides some tips and tactics for making your streaming media accessible. Accessibility of streaming content for people with disabilities is often not part of the spec for multimedia projects, but it certainly affects your quality of service. Most of the resources available on Web accessibility deal with HTML. Fortunately, rich media and streaming content developers have a growing number of experts to turn to for information and assistance. The essentials of providing accessible streaming content are simple: blind and visually impaired people need audio to discern important visual detail and interface elements, while deaf and hard-of-hearing people need text to access sound effects and dialog. Actually implementing these principles is quite a challenge, though. Now due to a relatively new law in the US, known as Section 508, dealing with accessibility issues is becoming an essential part of publishing on the Web", "keyphrases": ["web site", "qualiti servic", "stream media", "content provid", "unit state", "access stream content", "disabl user", "multimedia project", "web access", "html", "stream content develop", "visual impair peopl", "blind peopl", "visual detail", "interfac element", "deaf peopl", "hard-of-hear peopl", "sound effect", "section 508", "access issu", "web publish"]}
{"file_name": "288.abstr", "text": "Complexity transitions in global algorithms for sparse linear systems over finite fields. We study the computational complexity of a very basic problem, namely that of finding solutions to a very large set of random linear equations in a finite Galois field modulo q. Using tools from statistical mechanics we are able to identify phase transitions in the structure of the solution space and to connect them to the changes in the performance of a global algorithm, namely Gaussian elimination. Crossing phase boundaries produces a dramatic increase in memory and CPU requirements necessary for the algorithms. In turn, this causes the saturation of the upper bounds for the running time. We illustrate the results on the specific problem of integer factorization, which is of central interest for deciphering messages encrypted with the RSA cryptosystem", "keyphrases": ["complex transit", "global algorithm", "spars linear system", "finit field", "random linear equat", "finit galoi field", "statist mechan", "gaussian elimin", "phase boundari", "integ factor", "messag deciph", "encrypt", "rsa cryptosystem", "disord system"]}
{"file_name": "4.abstr", "text": "Industry insiders loading up on cheap company stock. A surge of telecom executives and directors purchasing their own companies, stock in the last two months points toward a renewed optimism in the beleaguered sector, say some observers, who view the rash of insider buying as a vote of confidence from management. Airgate PCS, Charter Communications, Cox Communications, Crown Castle International, Nextel Communications and Nortel Networks all have seen infusions of insider investment this summer, echoing trends in both the telecom industry and the national economy", "keyphrases": ["telecom industri", "insid invest"]}
{"file_name": "2082.abstr", "text": "Managing safety and strategic stocks to improve materials requirements planning performance. This paper provides a methodology for managing safety and strategic stocks in materials requirements planning (MRP) environments to face uncertainty in market demand. A set of recommended guidelines suggest where to position, how to dimension and when to replenish both safety and strategic stocks. Trade-offs between stock positioning and dimensioning and between stock positioning and replenishment order triggering are outlined. The study reveals also that most of the decisions are system specific, so that they should be evaluated in a quantitative manner through simulation. A case study is reported, where the benefits from adopting the new proposed methodology lie in achieving the target service level even under peak demand conditions, with the value of safety stocks as a whole growing only by about 20 per cent", "keyphrases": ["mrp", "materi requir plan", "market demand", "strateg stock", "safeti stock", "inventori manag", "varianc control", "stock replenish", "servic level", "peak demand"]}
{"file_name": "203.abstr", "text": "Plenoptic image editing. This paper presents a new class of interactive image editing operations designed to maintain consistency between multiple images of a physical 3D scene. The distinguishing feature of these operations is that edits to any one image propagate automatically to all other images as if the (unknown) 3D scene had itself been modified. The modified scene can then be viewed interactively from any other camera viewpoint and under different scene illuminations. The approach is useful first as a power-assist that enables a user to quickly modify many images by editing just a few, and second as a means for constructing and editing image-based scene representations by manipulating a set of photographs. The approach works by extending operations like image painting, scissoring, and morphing so that they alter a scene's plenoptic function in a physically-consistent way, thereby affecting scene appearance from all viewpoints simultaneously. A key element in realizing these operations is a new volumetric decomposition technique for reconstructing an scene's plenoptic function from an incomplete set of camera viewpoints", "keyphrases": ["interact imag edit oper", "multipl imag", "physic 3d scene", "modifi scene", "camera viewpoint", "image-bas scene represent", "imag paint", "scissor", "morph", "plenopt function", "volumetr decomposit techniqu", "plenopt imag edit"]}
{"file_name": "1967.abstr", "text": "Modeling daily realized futures volatility with singular spectrum analysis. Using singular spectrum analysis (SSA), we model the realized volatility and logarithmic standard deviations of two important futures return series. The realized volatility and logarithmic standard deviations are constructed following the methodology of Andersen  [J. Am. Stat. Ass. 96 (2001) 42-55] using intra-day transaction data. We find that SSA decomposes the volatility series quite well and effectively captures both the market trend (accounting for about 34-38% of the total variance in the series) and, more importantly, a number of underlying market periodicities. Reliable identification of any periodicities is extremely important for options pricing and risk management and we believe that SSA can be a useful addition to the financial practitioners' toolbox", "keyphrases": ["daili realiz futur volatil", "singular spectrum analysi", "ssa", "logarithm standard deviat", "return seri", "intraday transact data", "market trend", "market period", "risk manag", "option price", "financi practition", "econophys", "asset return"]}
{"file_name": "383.abstr", "text": "Outlier resistant adaptive matched filtering. Robust adaptive matched filtering (AMF) whereby outlier data vectors are censored from the covariance matrix estimate is considered in a maximum likelihood estimation (MLE) setting. It is known that outlier data vectors whose steering vector is highly correlated with the desired steering vector, can significantly degrade the performance of AMF algorithms such as sample matrix inversion (SMI) or fast maximum likelihood (FML). Four new algorithms that censor outliers are presented which are derived via approximation to the MLE solution. Two algorithms each are related to using the SMI or the FML to estimate the unknown underlying covariance matrix. Results are presented using computer simulations which demonstrate the relative effectiveness of the four algorithms versus each other and also versus the SMI and FML algorithms in the presence of outliers and no outliers. It is shown that one of the censoring algorithms, called the reiterative censored fast maximum likelihood (CFML) technique is significantly superior to the other three censoring methods in stressful outlier scenarios", "keyphrases": ["outlier resist adapt match filter", "covari matrix estim", "maximum likelihood estim set", "steer vector", "sampl matrix invers", "fast maximum likelihood", "censor algorithm", "reiter censor fast maximum likelihood"]}
{"file_name": "2167.abstr", "text": "Finally! some sensible European legislation on software. The European Commission has formally tabled a draft Directive on the Protection by Patents of Computer-Implemented Inventions. The aim of this very important Directive is to harmonise national patent laws relating to inventions using software. It follows an extensive consultation launched by the Commission in October 2000. The impetus behind the Directive was the recognition at EU level of a total lack of unity between the European Patent Office and European national courts in deciding what was or was not deemed patentable when it came to the subject of computer programs", "keyphrases": ["european commiss", "direct on the protect by patent of computer-impl invent", "nation patent law", "law harmonis", "eu", "european patent offic", "nation court", "comput program"]}