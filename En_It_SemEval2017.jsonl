{"file_name": "S221267161200220X", "text": "Per fornire al governo un monitoraggio efficace delle tendenze future delle variabili economiche e un buon riferimento per lo sviluppo di una politica ragionevole, in questo documento stabiliamo un modello di serie temporali sugli investimenti diretti esteri (IDE) della Cina utilizzando l'analisi e l'intervento wavelet analisi e analisi di serie temporali e prevedere l\u2019andamento degli investimenti diretti esteri nei prossimi anni. Questo modello elimina l'interferenza del rumore per la previsione utilizzando l'analisi wavelet e descrive l'autocorrelazione e la volatilit\u00e0 variabile nel tempo delle serie temporali finanziarie utilizzando il modello ARIMA-GARCH-M. I risultati della simulazione mostrano che questo modello spiega bene la struttura dinamica delle tendenze degli IDE in Cina.", "keyphrases": ["investimenti diretti esteri", "modello arima-garch-m", "finanza temporale seri", "andamento della variabile economica", "sviluppare una ragione politica", "autocorrelazione", "analisi dell'intervento", "prevedere l\u2019andamento degli IDE", "analisi wavelet", "IDE", "analisi della serie temporale", "interferenza del rumore", "tempo-variabile volatile", "stabilire un modello temporale", "modello di serie temporale", "monitor degli effetti"]}
{"file_name": "S0370269304007129", "text": "Analizziamo i momenti di dipolo magnetico ed elettrico diagonali e di transizione dei leptoni carichi in modelli technicolor estesi (ETC), tenendo conto della natura multiscala della rottura della simmetria di Gauge ETC, del comportamento conforme (camminata) della teoria del technicolor e del mescolamento dei corpi carichi -matrice di massa leptonica. Mostriamo che gli effetti di miscelazione dominano i contributi dell'ETC ai momenti di dipolo elettrico dei leptoni carichi e che questi possono produrre un valore di |de| paragonabile al limite attuale. Il tasso per \u03bc\u2192e\u03b3 pu\u00f2 anche essere vicino al suo limite. Da questi e altri processi derivano i vincoli sugli angoli di mescolamento dei leptoni carichi. I vincoli sono tali che il contributo dell'ETC al momento magnetico anomalo del muone, che include un termine significativo di miscelazione leptonica, pu\u00f2 avvicinarsi, ma non superare, l'attuale livello di sensibilit\u00e0.", "keyphrases": ["magnete diagonale e di transito e momento dipolo elettrificato del leptone di carica", "effetto misto", "caricare la miscela leptonica angl", "mescolarsi nella matrice di massa dei leptoni carichi", "termine di mix leptonico", "estendere il technicolor", "eccetera", "tasso per \u03bc\u2192e\u03b3", "carica leptone elettr momento dipolo", "Momento magnetico anomalo del muone", "rottura dei simmetri gaug", "conformarsi (camminare) al comportamento del technicolor theori", "valore di |de|", "matrice di massa dei leptoni carichi"]}
{"file_name": "S0167931712002699", "text": "Poich\u00e9 continua la progressione verso nodi litografici pi\u00f9 piccoli, \u00e8 diventato necessario adottare pellicole di resist pi\u00f9 sottili per mitigare problemi come il collasso del modello. Per affrontare il problema della ridotta resistenza all'attacco dei film sottili di fotoresist, l'industria dei semiconduttori ha iniziato a sviluppare processi multistrato in cui il modello viene prima trasferito in una maschera dura organica intermedia con una maggiore selettivit\u00e0 all'attacco prima del trasferimento finale del modello di silicio [25\u201327]. In questo articolo dimostriamo come l'introduzione di un tale processo multistrato possa anche avvantaggiare la litografia della nanosfera aumentando le proporzioni ottenibili dei nanopilastri di silicio senza la necessit\u00e0 di processi di incisione complessi che richiedono apparecchiature specializzate e costose, ma necessitando invece solo di un SF6/C4F8 standard accoppiato induttivamente processo di attacco in modalit\u00e0 mista al plasma (ICP) a temperatura ambiente [28]. Come materiale dello strato intermedio abbiamo utilizzato la poliimmide, che trova ampio utilizzo come materiale di incapsulamento per la produzione di circuiti integrati. Si modella facilmente nel plasma di ossigeno e ha una velocit\u00e0 di attacco inferiore rispetto al silicio nel gas SF6. La sua flessibilit\u00e0 pu\u00f2 essere utilizzata anche per la fabbricazione di pilastri in polimero morbido mediante lo stesso processo che mostreremo. Il processo multistrato aumenta leggermente la complessit\u00e0 della preparazione del campione, ma consente all'attacco ICP di base di ottenere strutture con proporzioni elevate con dimensioni pi\u00f9 piccole rispetto a quelle precedentemente riportate senza la necessit\u00e0 di complesse apparecchiature di incisione.", "keyphrases": ["ridurre la resistenza all'attacco della pellicola sottile di fotoresist", "processo multistrato", "il modello crolla", "icp", "incidere equipaggiare", "capsula materia", "trasferimento del modello in silicio", "materiale dello strato intermedio", "maschera dura dell'organo intermedio", "accoppiare il plasma", "processo di incisione complesso", "litografia nanosferica", "attacco icp", "poliimmide", "sf6 ga", "pellicola resistente pi\u00f9 sottile", "plasma di ossigeno", "nodo litografico pi\u00f9 piccolo", "nanopilastro di silicio", "sottile pellicola fotoresist", "prodotto IC", "tessuto di morbido pilastro in polimero", "silicio", "preparazione del campione"]}
{"file_name": "S0301932214001931", "text": "Lo scopo di questo articolo \u00e8 quello di indagare l'influenza della forma delle particelle sulle particelle interagenti che fluiscono in un canale turbolento orizzontale, per particelle con un numero di Stokes significativo. Per raggiungere questo obiettivo, vengono eseguite simulazioni di grandi vortici (LES) di un flusso di canale turbolento orizzontale carico di cinque diverse forme di particelle, incorporando il modello di resistenza, portanza e coppia derivato da Zastawny (2012). Il caso ben documentato di flusso in un canale orizzontale descritto in Kussin e Sommerfeld (2002), che studiano le particelle sferiche, viene utilizzato come caso di riferimento. Le misurazioni nel loro lavoro sono state effettuate con l'anemometria Doppler di fase (PDA), per misurare simultaneamente la velocit\u00e0 del fluido e delle particelle. Il quadro numerico applicato in questo articolo \u00e8 stato precedentemente convalidato per le particelle sferiche in Mallouppas e van Wachem (2013). In quell\u2019articolo, viene dimostrato che il modello completo a elementi discreti (DEM) \u00e8 pi\u00f9 accurato nel determinare il comportamento delle particelle in questo flusso di canali orizzontali gas-solido rispetto al modello a sfera dura. Inoltre, questo articolo ha dimostrato che la meccanica dei fluidi \u00e8 modellata accuratamente utilizzando la struttura LES. Nel presente articolo, questo quadro \u00e8 esteso per tenere conto delle particelle non sferiche.", "keyphrases": ["modello a sfera dura", "quadro numerico", "le", "determinare il comportamento delle particelle nel flusso del canale gas-solido dell'orizzonte", "particella non sferica", "pda", "fluido", "dem", "anemometri con doppler di fase", "il quadro", "modello drag, lift e toqu", "particl", "flusso nel canale gas-solido", "grande eddi simul", "ga", "particella sferica", "flusso del canale turbol orizzontale", "studiare l'influenza della forma delle particelle sul flusso di particelle interagenti in un flusso di canali turbolenti orizzontali", "flusso del canale orizzontale", "comprende il modello a elementi discreti"]}
{"file_name": "S0963869514001066", "text": "Nel metodo Total Focusing (TFM) il raggio viene focalizzato sinteticamente in ogni punto della regione target [7] come segue. Dopo aver ottenuto i dati FMC, la regione target, che si trova nel piano x\u2013z in 2D (Figura 1), viene discretizzata in una griglia. I segnali provenienti da tutti gli elementi della matrice vengono quindi sommati per sintetizzare un focus in ogni punto di questa griglia. L'interpolazione lineare dei segnali nel dominio del tempo \u00e8 necessaria poich\u00e9 sono campionati in modo discreto. L'intensit\u00e0 dell'immagine TFM ITFM in qualsiasi punto (x,z) \u00e8 data da:(10)ITFM(x,z)=|\u2211HTR(1c((xT\u2212x)2+z2+(xR\u2212x)2+ z2))|forallT,Rdove HTR(t) \u00e8 la trasformata di Hilbert di un segnale uTR(t) nei dati FMC, xT \u00e8 la posizione x dell'elemento trasmittente (T) e xR \u00e8 la posizione x dell'elemento ricevente elemento (R). Si noti che la posizione z di tutti gli elementi \u00e8 zero (Figura 3a). La somma viene effettuata per tutte le possibili coppie trasmettitore-ricevitore e utilizza quindi tutte le informazioni catturate con FMC. In questo documento questo algoritmo viene denominato \"TFM convenzionale\".", "keyphrases": ["sintetizza un fuoco in ogni punto della griglia", "metodo della messa a fuoco totale", "fmc", "R", "elemento di trasmissione", "coppia trasmettitore-ricevitore", "campione discreto", "somma", "convento tfm", "piano x\u2013z", "discreto in una griglia", "tfm immagine itfm", "sommario", "griglia", "interpolazione lineare", "immagine tfm", "dati fmc", "T", "elemento di ricezione", "trasformata di Hilbert", "tfm"]}
{"file_name": "S0021999114007396", "text": "In questo lavoro, abbiamo sviluppato un semplice schema numerico basato sul metodo degli elementi finiti di Galerkin per un'equazione di diffusione frazionaria temporale multitermine che coinvolge pi\u00f9 derivate frazionarie di Caputo nel tempo. Viene fornita un'analisi completa degli errori dello schema di Galerkin spaziale semidiscreto. La teoria copre il caso praticamente molto importante di dati iniziali non uniformi e lato destro. L'analisi si basa essenzialmente su alcuni nuovi risultati di regolarit\u00e0 dell'equazione di diffusione frazionaria temporale multitermine. Inoltre, abbiamo sviluppato uno schema completamente discreto basato sulla discretizzazione alle differenze finite delle derivate frazionarie di Caputo. Sono state stabilite la stabilit\u00e0 e la stima dell'errore dello schema completamente discreto, a condizione che la soluzione sia uniforme. Gli estesi esperimenti numerici in una e due dimensioni hanno pienamente confermato la nostra analisi di convergenza: i tassi di convergenza empirica concordano bene con le previsioni teoriche sia per i dati lisci che per quelli non lisci.", "keyphrases": ["frazione temporale multitermine diffusa equat", "nuovo risultato regolare", "Metodo degli elementi finiti di Galerkin", "mono e bidimensionale", "finit differire discreti della frazione caputo deriv", "schema Galerkin", "schema numerico", "numero esper", "Tasso di convergenza dell'impero", "multipl caputo frazione derivata nel tempo", "schema completamente discreto"]}
{"file_name": "S2212671612001692", "text": "Il punto chiave della dinamica dei robot \u00e8 la progettazione e il controllo ottimali. L\u2019efficienza della dinamica dei robot \u00e8 stato l\u2019obiettivo dei ricercatori negli ultimi anni. In questo documento vengono utilizzate le viti per descrivere i problemi dinamici e in questo documento viene fornito un algoritmo dinamico in avanti ricorsivo O (N) del robot. Pu\u00f2 essere facilmente esteso alla topologia ad albero, al circuito chiuso e ai sistemi robotici spaziali. E tre metodi classici di dinamica dei robot vengono confrontati per facilit\u00e0 d'uso. I risultati mostrano che le dinamiche descritte con le viti sono utili nella modellazione dinamica ad alta efficienza. Le espressioni dinamiche basate sulle viti sono concise e chiare. La sua efficienza \u00e8 elevata rispetto a O(N) ed \u00e8 lineare rispetto al grado di libert\u00e0. Con il miglioramento dell'efficienza del calcolo, sar\u00e0 possibile il controllo della dinamica in tempo reale.", "keyphrases": ["efficienza del robot dinamico", "descrivere il problema dinamico", "miglioramento dell'efficienza del computer", "dynam descrivi con la vite", "o(n) ricorre robot", "vite", "topologia ad albero, anello chiuso e sistema robotico spaziale", "controllo dinamico in tempo reale", "lineare al grado di libert\u00e0", "modellazione dinamica ad alta efficienza.", "o(n) ricorre all'algoritmo di dinamica in avanti del robot", "dinam espresso", "dinamica del robot"]}
{"file_name": "S0021999113005652", "text": "Questo studio propone un nuovo quadro di modellazione numerica dello scambio di gas tra aria e acqua attraverso la loro interfaccia e la successiva reazione chimica in acqua basata su un modello esteso a due compartimenti. Lo scopo principale di questo studio \u00e8 fornire un concetto fondamentale per modellare i processi fisico-chimici dello scambio di gas, seguito dalla reazione chimica nell'acqua. Si \u00e8 anche tentato di dimostrare dati e conoscenze fondamentali sugli importanti fenomeni di trasporto ambientale, in particolare sugli effetti del numero di Schmidt e della velocit\u00e0 di reazione chimica sui meccanismi di scambio di gas attraverso l'interfaccia. I processi di scambio di gas sono separati in due sottofasi fisico-chimiche, la prima \u00e8 l'equilibrio gas-liquido tra le due fasi e la seconda \u00e8 la reazione chimica nella fase acquosa. Per semplificare le interazioni delle reazioni chimiche e dei fenomeni di trasporto turbolento nell'acqua, qui si presuppone una reazione chimica irreversibile del primo ordine del materiale gassoso dopo il suo assorbimento nella fase acquosa. Mentre un modello tradizionale a due compartimenti presuppone una concentrazione uniforme di un materiale in ciascun compartimento, il presente modello a due compartimenti utilizza una tecnica di fluidodinamica computazionale (CFD) nel compartimento dell'acqua per valutare lo sviluppo temporale dei profili tridimensionali della velocit\u00e0 e della concentrazione campi. Un approccio di simulazione numerica diretta (DNS) viene utilizzato per valutare i profili delle velocit\u00e0 dei fluidi e delle concentrazioni nell'acqua, e diverse importanti statistiche sulla turbolenza sono state valutate senza utilizzare chiusure turbolente e modelli su scala sub-griglia. Assumiamo che un flusso di fluido nella fase acquosa sia uno strato d'acqua turbolento ben sviluppato con un basso numero di Reynolds e il numero di Schmidt viene variato da 1 a 8 per osservare gli effetti della diffusione molecolare del gas nell'acqua sub-interfaccia sul tasso di cambio del gas all\u2019interfaccia. Sei gradi della velocit\u00e0 di reazione chimica adimensionale vengono utilizzati per trovare l'effetto della velocit\u00e0 di reazione chimica sui meccanismi di scambio di gas. Verranno inoltre esaminate estrapolazioni dei tassi di scambio di gas e dei relativi fenomeni di trasporto verso un numero di Schmidt pi\u00f9 grande e una velocit\u00e0 di reazione chimica pi\u00f9 rapida per prevedere i processi di scambio di gas dei gas reali di Sc\u223cO(102) sulla base dei risultati dei presenti esperimenti numerici .", "keyphrases": ["concentrazione in acqua", "reazione chimica in fase acquosa", "gasou materia", "ga scambio", "CFD", "ga tasso di cambio all'interfaccia", "prevedere il processo di scambio ga", "valutare il profilo della velocit\u00e0 del fluido e la concentrazione nell'acqua", "fase acquosa", "valutazione temporale dello sviluppo del profilo tridimensionale del campo di velocit\u00e0 e concentrazione", "processo di scambio ga", "ga meccanico di scambio", "ga meccanismo di scambio attraverso l'interfaccia", "reazione chimica in acqua", "fenomeni di trasporto turbolento in acqua", "concetto fondamentale", "reazione chimica", "fenomeni di trasporto", "calcolo fluidodinamico", "modello di processo fisico-chimico", "struttura", "numero esper", "sc\u223co(102)", "effetto della velocit\u00e0 della reazione chimica sul meccanismo di scambio del ga", "nuova struttura di un modello numerico", "osservare l'effetto del diffuso molecolare", "aria", "Reazione chimica irreversibile", "effetto del numero di Schmidt", "numero diretto simul", "equilibrio gas-liquido", "velocit\u00e0 fluida", "acqua", "modello a due comparti", "flusso del fluido nella fase acquosa", "ga", "velocit\u00e0 di reazione chimica adimensionale", "modello scala-sottogriglia", "molecolare diffuso", "velocit\u00e0 di reazione chimica", "tasso di cambio ga", "liquido", "gas", "d.n"]}
{"file_name": "S002199911500025X", "text": "In questo articolo \u00e8 stato introdotto un quadro numerico completamente accoppiato per flussi bifase con un'implementazione implicita della tensione superficiale. Questa struttura completamente accoppiata \u00e8 stata quindi utilizzata per confrontare l'influenza del trattamento di tensione superficiale sulle restrizioni del passo temporale risultanti dalle onde capillari. Lo studio condotto dimostra che le restrizioni sul passo temporale numerico risultante dalle onde capillari sono valide e invariate indipendentemente dal trattamento numerico della tensione superficiale. Poich\u00e9 la tensione superficiale non \u00e8 una funzione della pressione o della velocit\u00e0, il cambiamento nell'implementazione non influenza i coefficienti della matrice delle variabili primitive e, quindi, la stabilit\u00e0 numerica \u00e8 indipendente dal trattamento della tensione superficiale. Ulteriori analisi mostrano che il vincolo temporale capillare \u00e8 un requisito imposto dal campionamento spaziotemporale delle onde capillari, che \u00e8 indipendente dalla metodologia numerica applicata.", "keyphrases": ["tensione superficiale", "confrontare l'influenza", "quadro completamente accoppiato", "trattamento di tensione superficiale", "flusso bifase", "limitare il numero del passo temporale risultante dall'onda capillare", "campione spaziotempore dell'onda capillari", "Risultato della limitazione del passo temporale dall'onda capillare", "trattamento della tensione superficiale", "trattamento numerico della tensione superficiale", "Metodologia dei numeri applicativi", "onda capillare", "quadro numerico a coppia completa"]}
{"file_name": "S2212667812000810", "text": "Utilizzando l'indagine, le interviste agli esperti e il confronto, questo articolo indaga la costruzione dei curricula, la progettazione dei curricula e il contenuto dei curricula per gli studenti normali senza sport. Sulla base dell'indagine, questo articolo analizza il quadro teorico della costruzione curriculare e propone alcuni suggerimenti. Ci auguriamo che possa fornire alcune prove per la progettazione di curricula per studenti normali che non praticano sport.", "keyphrases": ["colloquio con esperti", "quadro teorico", "indagare la costruzione dei curricula, la progettazione dei curricula e il contenuto dei curricula", "progettazione dei programmi di studio", "invest"]}
{"file_name": "S0021999113005846", "text": "Sebbene il problema delle onde libere di Kelvin sia di notevole importanza teorica, i problemi con la forzatura e lo smorzamento hanno maggiore importanza pratica. In natura, la forzante potrebbe essere dovuta allo stress del vento sulla superficie libera o a un potenziale di marea astronomico, e lo smorzamento potrebbe essere dovuto allo stress turbolento di uno strato limite inferiore. Indipendentemente dai dettagli, la risposta forzata \u00e8 composta da onde di acque poco profonde, eventualmente comprese le onde Kelvin, con le ampiezze maggiori nelle onde con una frequenza naturale \u03c9f vicina a quella della frequenza forzante \u03c9; vari esempi di questo genere sono riportati nei capitoli 9 e 10 di Gill [16]. Quando \u03c9\u2248\u03c9f, c'\u00e8 una risposta quasi risonante di grande ampiezza, la cui dimensione \u00e8 sensibile al debole smorzamento e |\u03c9\u2212\u03c9f|. Pertanto, nelle soluzioni numeriche di onde forzate quasi risonanti, prevediamo che errori in \u03c9f (associati alla discretizzazione spaziale) potrebbero portare a errori non banali nella risposta forzata.", "keyphrases": ["onda Kelvin", "problema con forza e umidit\u00e0", "Problema delle onde Kelvin libere", "numero soluzione", "sforzo del vento sulla superficie libera", "vento", "potenziale mareale astronomico", "stress turbolento di uno strato limite inferiore", "onda poco profonda", "\u03c9", "umido", "forza", "debole umidit\u00e0", "onda di forza quasi risonante", "\u03c9f", "|\u03c9\u2212\u03c9f|", "frequenza naturale", "onda", "frequenza della forza", "forza respons", "discreti spaziali"]}
{"file_name": "S0370269304008731", "text": "Viene proposto uno scenario per la miscelazione di leptoni bi-grandi nel quadro di neutrini di Majorana quasi tre volte degenerati. Nella nostra proposta, imponiamo la simmetria Z3 nel settore dei neutrini ad una scala di alta energia per tenere conto dei tre neutrini degeneri e della massima miscelazione tra \u03bd\u03bc e \u03bd\u03c4. Per ottenere la scissione della massa del neutrino atmosferico mantenendo il massimo rimescolamento tra \u03bd\u03bc e \u03bd\u03c4, introduciamo una piccola perturbazione nella matrice della massa del neutrino senza rompere la simmetria Z3. D'altra parte, il rimescolamento dei neutrini solari avviene a causa della matrice di massa leptonica carica non diagonale, e il rimescolamento ampio e la suddivisione della massa desiderabili per l'oscillazione dei neutrini solari possono essere ottenuti mediante correzioni radiative.", "keyphrases": ["divisione della massa del neutrino nell'atmosfera mantenendo il mix massimo tra \u03bd\u03bc e \u03bd\u03c4", "matrice di massa dei neutrini", "miscela di neutrini solari", "matrice di massa leptonica con carica non diagonale", "settore dei neutrini", "neutrino degenere majorana", "neutrino", "neutrino solare", "radi corretto", "grande mix e suddivisione della massa per l'oscillazione del neutrino solare", "introdurre una piccola perturbazione nella matrice della massa dei neutrini senza rottura dei simmetri z3", "miscela leptonica bi-grande", "neutrino degenerante"]}
{"file_name": "S0301010409001219", "text": "\u00c8 noto [9,14,18,22] che i processi di frammentazione in molecole poliatomiche indotti da un intenso campo laser ultraveloce possono talvolta mostrare una sensibile dipendenza dalle caratteristiche di fase istantanea del campo laser. A seconda del cambiamento di segno degli impulsi laser emessi, la frammentazione potrebbe essere aumentata o soppressa [14,18,22]. Il controllo del risultato di tale frammentazione molecolare indotta dal laser con impulsi laser a femtosecondi ha prodotto una serie di effetti sperimentali e teorici negli ultimi anni. Tuttavia, continuano gli sforzi per un potenziamento specifico del canale del frammento, il che \u00e8 difficile poich\u00e9 \u00e8 anche una funzione del sistema molecolare in studio [20,22\u201324]. Qui riportiamo l'osservazione di un percorso di frammentazione coerentemente potenziato dell'n-propil benzene, che sembra avere a disposizione un canale di frammentazione cos\u00ec specifico. Abbiamo scoperto che per l'n-propil benzene, la resa relativa di C3H3+ \u00e8 estremamente sensibile alla fase dell'impulso laser rispetto a qualsiasi altro possibile canale. In effetti, si verifica un aumento di quasi un ordine di grandezza nella resa di C3H3+ quando vengono utilizzati impulsi con chirp negativo, mentre non vi \u00e8 alcun effetto con il chirp positivo. Inoltre, la resa relativa di tutti gli altri frammenti ionici pi\u00f9 pesanti risultanti dall'interazione del campo forte con la molecola non \u00e8 sensibile al segno del chirp, all'interno del livello di rumore.", "keyphrases": ["impulso laser cinguettio", "impulso laser a femtosecondi che cinguetta", "cinguettio", "canale", "intenso campo laser ultraveloce", "impulso laser", "processo di frammento", "molecola poliatomo", "ione frammento pi\u00f9 pesante", "sistema molecolare", "molecolar", "impulso cinguettio negativo", "canale del frammento", "c3h3+", "frammento molecolare indotto dal laser", "osservare un percorso di frammento di miglioramento della coerenza", "frammento", "potenziamento canale frammento", "n-propilbenzene", "campo laser", "postulare il cinguettio"]}
{"file_name": "S0010938X13002187", "text": "In questo studio vengono combinati i risultati di due tipi di test di ossidazione. La tabella 1 mostra la matrice del test con i due approcci inclusi. Tutti i test di 100 ore e il test condotto a 650\u00b0C sono stati eseguiti utilizzando una bilancia termogravimetrica (TGA). La variazione di peso durante questi test \u00e8 stata monitorata continuamente e adattata per adattarsi agli effetti di galleggiamento. Tutti gli altri test sono stati condotti in forni a tubi orizzontali. Per queste ultime prove, lotti di provini sono stati posti in vaschette di allumina e inseriti nei forni a temperatura. Per determinare la cinetica di ossidazione \u00e8 stata utilizzata la pesatura intermittente a temperatura ambiente. A intervalli di tempo selezionati, un campione veniva rimosso dal lotto per l'esame prima che l'esposizione alle alte temperature continuasse per il resto del lotto. La tabella 1 mostra gli intervalli di tempo scelti per l'esame. Finora \u00e8 stato eseguito un test isotermico a 600\u00b0C, con un tempo di esposizione di 1000 ore.", "keyphrases": ["il peso cambia durante questi test mentre il monitoraggio continua", "bilancia termogravimetrica", "barca di allumina", "fornace", "regolare per adattarsi all'effetto di galleggiamento", "matrice di prova", "determinare l'ossido cinetico", "forno tubolare Horizont", "prova dell'ossido", "tga", "la tabella 1 mostra l'intervallo di tempo scelto per l'esame"]}
{"file_name": "S0045782514000607", "text": "Come accennato in precedenza, il sistema debolmente penalizzato pu\u00f2 essere pensato come una formulazione generalizzata che pu\u00f2 dar luogo a formulazioni PL, penalizzate o PL condensate staticamente a seconda della scelta dell'operatore di proiezione. L'equivalenza di questi metodi nel regime debolmente penalizzato ci consente di combinare e sfruttare le buone caratteristiche di ciascun metodo. Ad esempio, la formulazione debolmente penalizzata combina la struttura semplificata del metodo della penalit\u00e0 con le caratteristiche di convergenza della formulazione PL. Tuttavia, a causa della rigidezza del sistema lineare ad alti valori del modulo di bulk, le formulazioni penalizzate (penalit\u00e0 classica/debolmente penalizzata) mostrano una convergenza non lineare deteriorata. Ci\u00f2 \u00e8 in netto contrasto con il metodo PL che (per schemi stabili inf-sup) mostra una rapida convergenza anche per moduli di massa elevati. Tuttavia, osserviamo che, quando la scelta di \u03c0h fornisce equivalenza con il metodo PL discreto, si osserva una scarsa convergenza non lineare sebbene, in linea di principio, la convergenza dovrebbe essere simile. Esaminando le formule di aggiornamento sia per gli approcci debolmente penalizzati che per quelli PL (vedi Appendice C), osserviamo che la convergenza deteriorata deriva da: (1) amplificazione residua iniziale e (2) amplificazione del residuo.", "keyphrases": ["pl, penali o static condens pl formul", "formula del gene", "initi residuo amplificatore", "peggioramento convergente", "approccio penale e pl debole", "convergente", "rigore classico/penale debole", "schema inf\u2013sup stabile", "pl formula", "amplificatore del residuo", "formula penale", "forma penale debole", "convergenza non lineare", "scarsa convergenza non lineare", "debole penale", "metodo penalistico", "per favore"]}
{"file_name": "S0032386110004039", "text": "Un'applicazione dei copolimeri casuali derivati \u200b\u200bda ROMP \u00e8 l'incorporazione covalente di porzioni di sensori ottici in una matrice polimerica. I polimeri ROM sono stati testati come materiali di matrice per il complesso fosforescente sensibile all'ossigeno, platino tetrakis (pentafluorofenil) porfirina. \u00c8 stata stabilita una correlazione tra la natura della catena laterale del polimero ROM e la risposta ottica delle molecole del sensore [34]. Numerosi lavori sono dedicati alla sintesi di molecole di sensori ottici compatibili con ROMP come i fenantroimidazoli [35,36], i complessi di europio [37] o i coloranti xantenici [38], la loro copolimerizzazione casuale e la valutazione dei loro profili di rilevamento nei copolimeri. Un'altra applicazione comprende copolimeri casuali con unit\u00e0 di eosina e/o etil dimetilammino benzoato legate covalentemente che sono stati testati come macroiniziatori per la fotopolimerizzazione degli acrilati mirando ad un sistema iniziatore/coinitiatore che combina una buona attivit\u00e0 di polimerizzazione con una migliore stabilit\u00e0 di migrazione [39].", "keyphrases": ["rom polim", "eosina legata alla covale", "sintesi della molecola del sensore ottico romp-abl", "complesso dell'europio", "complesso fosforescente platino tetrakis(pentafluorofenil)porfirina", "moieti del sensore ottico", "polimero", "macroiniti", "unit\u00e0 di etil dimetilammino benzoato", "matrice materia", "acrilico", "copolimero casuale derivato romp", "fenantroimidazolo", "sistema iniziatore/coiniti", "copolimero", "copolimero casuale con unit\u00e0 di eosina e/o etil dimetilammino benzoato legata alla covale", "colorante xantenico", "molecola del sensore ottico romp-abl", "valutazione del loro profilo sensoriale nel copolimero", "matrice polimera", "molecola del sensore", "copolimero", "catena laterale in polimero rom", "coval incorpora i moieti del sensore ottico in una matrice polimerica", "ossigeno"]}
{"file_name": "S1361841516300342", "text": "Gli approcci probabilistici e stocastici possono facilitare la ricerca di ottimi locali e globali. Gli algoritmi evolutivi, come la popolazione genetica (Jomier et al., 2006; Rivest-Henault et al., 2012; Ruijters et al., 2009), sono considerati una strategia che ha \u201cmeno probabilit\u00e0 di rimanere bloccata in un ottimo locale\u201d. (Ruijters et al., 2009). Una funzione di costo costituita dalla \u201csomma dei valori di intensit\u00e0 sfocata gaussiana nel [DSA] nei punti del modello proiettati\u201d (Jomier et al., 2006) \u00e8 ottimizzata utilizzando un ottimizzatore di algoritmo genetico. Altri autori \u201cusano la forma di condensazione del campionamento sequenziale Monte Carlo per stimare un gradiente della funzione di costo\u201d (Florin et al., 2005) per trovare il minimo globale. Inoltre, il filtro di Kalman \u00e8 adottato con successo (Curwen et al., 1994; Feldmar et al., 1997; Toledo et al., 1998).", "keyphrases": ["Approccio probabilistico e stocastico", "filtro Kalman", "popolo genet", "ricerca di ottimi locali e globali", "forma condensata del campione sequenziale di Mont Carlo", "stimare il gradiente della funzione di costo", "algoritmo genet ottimizzato", "Algoritmo evolutivo", "funzione di costo"]}
{"file_name": "S0370269304007567", "text": "Ciascuna posizione del colpo all'interno delle camere di deriva \u00e8 stata calcolata dal tempo di deriva digitalizzato da un convertitore analogico-digitale flash. Il calcolo \u00e8 stato effettuato sulla base di una relazione tra la posizione del colpo e il tempo di deriva (relazione x\u2013t). La relazione x\u2013t \u00e8 stata calcolata con precisione da un pacchetto di simulazione della camera di deriva, GARFIELD [20], e da un pacchetto di simulazione delle propriet\u00e0 dei gas, MAGBOLTZ [21]. Sebbene le camere siano state costruite con cura con una tolleranza di 100 \u03bcm, si \u00e8 verificata una piccola deviazione di posizione dei fili e dei modelli di modellazione del campo, che potrebbero modificare localmente il campo elettrico. Per tenere conto della limitata precisione nella costruzione della camera, durante gli esperimenti veniva comunemente applicata una correzione alla relazione x\u2013t calcolata. La correzione \u00e8 stata ottenuta per minimizzare il \u03c72 nell'adattamento di tracce diritte di eventi muonici puliti osservati sul terreno senza campo magnetico. La correzione \u00e8 stata minima quanto previsto dalla precisione nella produzione della camera. Durante le osservazioni, la relazione x\u2013t \u00e8 stata influenzata dalla variazione della pressione e della temperatura del gas della camera. Per tenere conto di queste variazioni dipendenti dal tempo, la relazione x\u2013t \u00e8 stata calibrata per ogni sessione di raccolta dati. Soprattutto nella calibrazione della relazione x \u2013 t degli ODC, SciFi ha fornito posizioni di riferimento assolute, che non sono influenzate dalla variazione della pressione o della temperatura.", "keyphrases": ["garfield", "magboltz", "ga propriet\u00e0 pacchetto simultaneo", "camera di deriva", "pacchetto simultaneo con camera di deriva", "produttore di camere", "campo magnetico", "occ", "Camera", "relazione tra la posizione dell'hit e il tempo di deriva", "x\u2013t relativo", "camera ga", "conversione flash da analogico a digitale"]}
{"file_name": "S0021999115008207", "text": "I flussi multifase sono comuni, anzi abbastanza generali, nei processi ambientali e industriali. In generale, questi possono essere modellati come problemi continui in cui le fasi sono miste (omogeneizzazione olio-acqua [36], trasporto di sedimenti [18]) o problemi di interfaccia in cui le fasi sono distinte e interagiscono all'interfaccia (stampaggio a iniezione assistito da gas [21], rottura del getto [40]). In alcuni casi i flussi iniziano come problemi di interfaccia ma quando avviene la miscelazione all'interfaccia diventano effettivamente continui, almeno a livello locale. L'intrappolamento d'aria, forse dovuto alla rottura delle onde, ne \u00e8 un ovvio esempio. Consideriamo qui problemi di interfaccia a due fasi in cui l'interfaccia rimane distinta e la differenza di densit\u00e0 \u00e8 elevata, aria e acqua, e dove una fase pu\u00f2 essere considerata incomprimibile. L'interfaccia \u00e8 transitoria e pu\u00f2 diventare altamente distorta e interconnessa. Tali problemi sono stati affrontati con metodi basati su mesh utilizzando re-meshing periodici (o adattativi) o funzioni aggiuntive di tracciamento di fase [40]. Tuttavia, questi approcci possono richiedere molto tempo per essere implementati e soggetti a errori nella rappresentazione della superficie [50] o nella conservazione della massa [34].", "keyphrases": ["aria", "olio-acqua homogenis", "metodo mesh-bas", "trasporto di sedimenti", "problema dell'interfaccia a due fasi", "flusso multifase", "acqua", "stampo ad iniezione assistita da gas", "rottura dell'onda", "ambiente e processo industriale", "mescolare", "fase sono mix", "problema di interfaccia", "rottura del getto liquido", "funzione traccia di fase", "ri-mesh", "ingresso d'aria", "distorcere e interconnettere"]}
{"file_name": "S0375960112002885", "text": "I calcoli dei principi primi hanno chiarito la struttura elettronica e la stabilit\u00e0 del cluster W@Si12 durante l'adsorbimento e la reazione delle molecole di O2. I nostri risultati mostrano che la gabbia prisma esagonale Si12 incapsulata a W \u00e8 molto inerte all'ossidazione. La molecola di O2 viene adsorbita solo debolmente nel cluster a temperature relativamente basse, nell'ordine di diverse decine di meV. Tuttavia, barriere di reazione significative (0,593\u20131,118 eV) per la molecola di O2 sul cluster sono identificate su diversi siti di adsorbimento, tuttavia, questi percorsi di reazione sono reazioni proibite dallo spin secondo la regola di selezione dello spin di Winger. Questi risultati implicano che l'O2 si desorbisce facilmente dalla superficie del cluster anzich\u00e9 dissociarsi e ossidare il cluster W@Si12 in seguito all'eccitazione. In condizioni di alta temperatura e alta pressione, le molecole di O2 possono dissociarsi sul sito marginale preferenziale superando una barriera energetica significativamente grande.", "keyphrases": ["condizioni di alta temperatura e alta pressione", "reazione", "assorbire", "calcolo del primo principio", "reazione proibita alla rotazione", "ossido", "w-encapsul si12 gabbia prisma esagonale", "bassa temperatura", "0,593\u20131,118 ev", "struttura elettronica e stabilit\u00e0", "grappolo", "o2", "regola di selezione rotazione dell'ala", "significativa barriera di reazione", "superare una barriera energetica significativa", "cluster w@si12", "Adsorbimento e reazione della molecola di o2"]}
{"file_name": "S0022311513011951", "text": "La cascata di spostamenti \u00e8 un processo rapido (dell'ordine dei picosecondi). Un'ulteriore migrazione di posti vacanti e SIA, principalmente per diffusione, avviene su una scala temporale dell'ordine dei nanosecondi [17]. Questo \u00e8 ancora breve rispetto ai tempi operativi, quindi \u00e8 importante considerare il risultato di equilibrio di tali processi: se i posti vacanti e i SIA trovassero probabilmente il loro partner Frenkel, si ricombinassero e si annichilassero, allora il metallo dovrebbe essenzialmente ritornare alla sua struttura originale; tuttavia, se i difetti formassero invece grandi cluster di un unico tipo, ci\u00f2 potrebbe comportare la formazione di vuoti, anse di dislocazione o rigonfiamento, con possibile indebolimento del materiale nel processo. I difetti possono essere intrappolati ai bordi o alla superficie dei grani, quindi affinch\u00e9 una particella di ODS possa effettuare la diffusione, la concentrazione deve essere tale che vi siano molte particelle di questo tipo in ciascun granello.", "keyphrases": ["migrazione di vacanc e sia", "rigonfiamento", "vuoto", "od particl", "ciclo di dislocazione", "cascata di spostamenti", "struttura", "difetto", "diffuso", "grano"]}
{"file_name": "S2212671612000637", "text": "L'approccio hamiltoniano e l'approccio variazionale vengono utilizzati per trattare l'oscillatore armonico relativistico per la relazione ampiezza-frequenza. La buona affidabilit\u00e0 \u00e8 dimostrata dal confronto dei risultati con quelli della letteratura aperta. La semplicit\u00e0 e l'efficienza dei metodi vengono descritte anche per diversi intervalli dell'ampiezza iniziale durante la ricerca della relazione ampiezza-frequenza per l'oscillatore armonico relativistico non lineare.", "keyphrases": ["armonia relativista oscil", "armonia relativista non lineare oscil", "approccio variato", "approccio hamiltoniano", "relazione ampiezza-frequenza", "confronto dei risultati", "letteratura aperta", "trattare l'armonia relativista oscil", "ampiezza iniziale"]}
{"file_name": "S1359028614000989", "text": "Le strategie di acquisizione dei dati devono bilanciare le scale e i volumi rilevanti dei set di dati da utilizzare nella modellazione fisica e statistica. Gli approcci per l'estrazione delle informazioni necessarie devono essere in grado di ignorare informazioni spurie, in modo da sviluppare una rete di modelli funzionanti per ciascun meccanismo attivo correlato a ciascun percorso di degrado a livello fisico mesoscopico e a livello di modello statistico basato sui dati. Per catturare l'evoluzione temporale della materia energetica su lunghi intervalli di tempo, sono necessari metodi informatici appropriati per bilanciare il volume dei dati (semplici flussi di dati di serie temporali univariate con set di dati di immagini volumetriche ad alta dimensione) considerando i rispettivi contenuti informativi [68,69 ]. I dati grezzi e le informazioni estratte devono essere accessibili per query e modellazione. Allo stesso modo, gli approcci di modellazione utilizzati per comprendere e parametrizzare i meccanismi e i fenomeni attivi nel corso della vita rientrano nelle ampie categorie di approcci micro, meso e macroscopici. La sperimentazione in laboratorio e nel mondo reale, l'informatica, l'analisi e lo sviluppo di modelli di rete per l'evoluzione mesoscopica dei materiali energetici nel corso della vita costituiscono insieme il campo della scienza del degrado.", "keyphrases": ["metodo informativo appropriato", "strategie di acquisizione dati", "laboratorio ed esperimento nel mondo reale", "approccio micro, meso e macroscopico", "flusso di dati time-seri univari", "informa", "modello", "approccio modello", "sviluppo del modello di rete", "modello fisico e statistico", "analit", "modello statalista", "energia materia", "set di dati di immagini volumetriche di grandi dimensioni", "rete del modello", "degradare la scienza", "estratto dei necessari informati", "catturare il tempo evolut", "queri"]}
{"file_name": "S2212667812000937", "text": "In questo articolo presentiamo algoritmi per la generazione automatica di domande di ragionamento logico. Gli algoritmi sono in grado di costruire domande risolvibili con soluzioni uniche. Gli algoritmi utilizzano tecniche di intelligenza artificiale come le reti semantiche per produrre domande verbali. Questi algoritmi sono di piccole dimensioni e sono in grado di sostituire i tradizionali database di domande. Sono particolarmente adatti per l'implementazione su piattaforme mobili con vincoli di memoria. Gli algoritmi possono essere applicati alla generazione di domande per colloqui di lavoro, esami di servizio civile, ecc.", "keyphrases": ["costruire domande risolvibili con una soluzione univoca", "ai tecnica", "rete semantica", "domanda verbale", "algoritmo per la generazione automatica di domande sulla ragione logica.", "genere della domanda sulla ragione logica", "generatore di domande per colloquio di lavoro", "Memori vincola la piattaforma mobile", "database di domande tradizionali"]}
{"file_name": "S0168583X14003929", "text": "La sorgente ionica pi\u00f9 utilizzata negli strumenti FIB \u00e8 una sorgente ionica di metallo liquido (LMIS) al gallio (Ga) [1]. Il gallio \u00e8 attraente come fonte di ioni a causa della sua bassa temperatura di fusione (29,8\u00b0C a pressione atmosferica standard [4]) e della sua bassa volatilit\u00e0 [1]. Tuttavia, alcuni materiali mostrano sensibilit\u00e0 al fascio di ioni Ga. Questa sensibilit\u00e0 si manifesta come cambiamenti nella struttura e nella composizione chimica del materiale di partenza dopo l'esposizione al fascio di ioni Ga [5]. I semiconduttori composti del gruppo III-V sono una classe di materiali che mostrano tale sensibilit\u00e0. \u00c8 stato recentemente riportato che la fresatura Cryo-FIB sopprime le reazioni tra il fascio di ioni Ga e i materiali III-V [6]. Il vantaggio suggerito della fresatura crio-FIB rispetto alla fresatura a temperatura ambiente dei materiali del gruppo III-V \u00e8 allettante, data la variet\u00e0 di applicazioni presenti e potenziali future per questi materiali (come dispositivi elettronici o fotonici, date le propriet\u00e0 favorevoli di trasporto degli elettroni e di interruzione diretta della banda). associato a diversi sistemi di semiconduttori III-V).", "keyphrases": ["ga", "strumento a fib", "gallio", "dispositivo elettrone o fotone", "materiali del gruppo iii-v", "mulino per criofibra", "iii-v materia", "fascio ionico ga", "semiconduttore"]}
{"file_name": "S0032386107010518", "text": "Le cicloaddizioni di Huisgen catalizzate da rame sono state recentemente ampiamente studiate dai chimici dei polimeri per la sintesi di polimeri funzionali (funzionali terminali o funzionali laterali). La post-funzionalizzazione dei polimeri sintetici \u00e8 una caratteristica importante dell'ingegneria macromolecolare poich\u00e9 molti meccanismi di polimerizzazione sono piuttosto sensibili alla presenza di gruppi voluminosi o funzionali. Ad esempio, un'ampia variet\u00e0 di polimeri telechelici (cio\u00e8 polimeri con estremit\u00e0 di catena definite) pu\u00f2 essere preparata in modo efficiente utilizzando una combinazione di polimerizzazione radicalica a trasferimento di atomi (ATRP) e CuAAC. Questa strategia \u00e8 stata segnalata in modo indipendente all'inizio del 2005 da van Hest e Opsteen [31], Lutz et al. [32] e Matyjaszewski et al. Tale passo \u00e8 stato importante poich\u00e9 l\u2019ATRP \u00e8 un metodo di polimerizzazione molto popolare nella moderna scienza dei materiali [34,35]. In effetti, l\u2019ATRP \u00e8 una tecnica semplice, che consente la preparazione di polimeri ben definiti con distribuzione ristretta del peso molecolare, lunghezza della catena prevedibile, microstruttura controllata, estremit\u00e0 della catena definite e architettura controllata [36\u201341]. Tuttavia, la gamma di possibilit\u00e0 dell\u2019ATRP pu\u00f2 essere ulteriormente ampliata dal CuAAC. Ad esempio, le estremit\u00e0 della catena \u03c9-bromo dei polimeri preparati mediante ATRP possono essere trasformate in azidi mediante sostituzione nucleofila e successivamente fatte reagire con alchini funzionali (Schema 3) [32]. A causa dell'elevata chemoselettivit\u00e0 del CuAAC, questo metodo \u00e8 altamente modulare e pu\u00f2 essere utilizzato per sintetizzare un'ampia gamma di polimeri \u03c9-funzionali. Inoltre, gli anelli triazolici formati non sono distanziatori \u201cpassivi\u201d ma funzioni interessanti che mostrano capacit\u00e0 di legami H, aromaticit\u00e0 e rigidit\u00e0.", "keyphrases": ["anello triazolico", "preparazione di polimeri ben definiti", "legame H", "sintetico polimero", "atrp", "telechel polim", "Estremit\u00e0 della catena \u03c9-bromo del polimero", "polimero", "azide", "polimero radicalico a trasferimento di atomi", "cicloadditivo huisgen catalizzatore di rame", "sintesi della funzione polim", "sostituto nucleofilo", "polym con estremit\u00e0 della catena definita", "motore macromolecolare", "polim", "Polimero con funzione \u03c9", "alchino", "funzione polim", "cuac"]}
{"file_name": "S0254058414000662", "text": "I gap di banda energetica HOMO-LUMO tra ilidi e i loro addotti pirenici suggeriscono che le 1,3-DC delle seconde ilidi di piridinio agli addotti ilidepirene siano controllati da HOMOilide-LUMOilide-pirene poich\u00e9 il gap di banda energetica \u00e8 pi\u00f9 piccolo di HOMOilide-pirene-LUMOilide. La regioselettivit\u00e0 della seconda cicloaddizione \u00e8 stata prevista utilizzando i coefficienti orbitali atomici corrispondenti a HOMOilide-LUMOilide-pirene. Secondo Fukui [33], le reazioni possono essere favorevoli nella direzione della massima sovrapposizione HOMO-LUMO di coefficienti pi\u00f9 grandi nei siti reattivi. Le interazioni pi\u00f9 favorevoli tra le corrispondenti ilidi e gli addotti dell'ilidepirene per formare la conformazione del regioisomero pi\u00f9 favorevole sono riportate nella Figura 3. Si prevede quindi che la seconda aggiunta di ilide alla struttura dell'ilidepirene proceda tramite le interazioni ilideC2/C6\u2013ilidepirene-C3 e ilideC7\u2013ilidepirene/C2 per producono le stesse conformazioni di regioisomeri. Considerando i calcoli teorici eseguiti per la struttura del pirene attaccata alla pirrolidina, si prevede anche che la formazione dello stesso tipo di regioisomeri sia favorevole per gli SWNT dopo l'1,3-DC delle ilidi di piridinio, Figura 3.", "keyphrases": ["formato dello stesso tipo di regione", "addotto ilidepirenico", "1,3-cc", "regione", "massima sovrapposizione omo-lumo", "la pirrolidina attacca il pirene", "addotto di ilide e ilidepirene", "seconda ilide di piridinio", "omoilide-lumoilide-pirene", "ilidec2/c6\u2013ilidepirene-c3", "coefficiente dell'orbita dell'atomo", "calcolo teorico", "la maggior parte preferisce conformarsi alla regione", "ilide", "regione conforme", "addotto del pirene", "swnt", "ilidepiren", "homo\u2013lumo", "regioselect del secondo cicloaddite", "ilidec7\u2013ilidepirene/c2", "1,3-dc di piridinio ilide", "omoilide-pirene-lumoilide"]}
{"file_name": "S1361841516300822", "text": "Per tutti i volontari la tecnica AAMM ha sovraperformato significativamente (p < 0,01) gli altri due metodi in tutti gli intervalli, come si pu\u00f2 vedere confrontando le curve di errore mostrate nella Figura 8 e le figure nella Tabella 1 nei materiali supplementari. La significativit\u00e0 \u00e8 stata valutata utilizzando un test dei ranghi con segno di Wilcoxon a 1 coda poich\u00e9 le distribuzioni degli errori generalmente non erano simmetriche. Gli errori di stima per AAMM e la sua controparte non adattiva, AAMM (no adatta. ), erano simili all'inizio della fase di applicazione, ma come anticipato, con il procedere della fase di applicazione, la tecnica AAMM ha continuamente migliorato la sua accuratezza incorporando pi\u00f9 e pi\u00f9 dati nel modello. In media la stima del movimento dell'AAMM \u00e8 migliorata del 22,94% in T5 rispetto alla sua controparte non adattiva. Tuttavia, il metodo si \u00e8 gi\u00e0 adattato in modo significativo al modello respiratorio in T2, cio\u00e8 dopo tra 3 e 7 minuti di imaging, dove le stime del movimento erano in media del 16,87% pi\u00f9 accurate rispetto all'inizio della fase di adattamento. Esaminando visivamente le curve per AAMM nella Figura 8 si pu\u00f2 vedere che per molti volontari (in particolare i volontari A, D, E e F) le curve di errore iniziano ad appiattirsi approssimativamente intorno al segno dei 7 minuti. Da ci\u00f2 si pu\u00f2 concludere che una scansione di calibrazione pi\u00f9 lunga di circa 12 minuti sarebbe ottimale, ovvero i 5 minuti utilizzati per la calibrazione in questo esperimento pi\u00f9 7 minuti di dati aggiunti durante la fase di applicazione. Si noti che questo tempo potrebbe essere significativamente ridotto se fosse utilizzata una sequenza senza gating cardiaco.", "keyphrases": ["stima del movimento", "Test del grado del segno di Wilcoxon a 1 coda", "aamm", "scansione del calibro", "immagine", "sequenza G non cardiaca", "aamm tecnica", "curva di errore", "calibro", "aamm (non adattare.)"]}
{"file_name": "S2212671612000704", "text": "Il carico dell'unit\u00e0 di pompaggio della trave \u00e8 variabile, che spesso si trova in uno stato di carico leggero. Riducendo una certa tensione \u00e8 possibile migliorare il fattore di potenza e l'efficienza dell'unit\u00e0 di pompaggio del fascio in condizioni di carico leggero. Possiamo modificare la tensione modificando l'angolo di innesco del tiristore. \u00c8 complesso e inaccettabile analizzare il cambiamento dei cicli del carico complessivo. Quindi possiamo dividere il carico dell'intero ciclo in pi\u00f9 parti uguali, ognuna delle quali pu\u00f2 essere pensata come un carico costante. La tensione ottimale per il carico corrente pu\u00f2 essere calcolata mediante un algoritmo genetico. Quando ciascun carico si trova nella tensione ottimale, possiamo ottenere l'intera regola di modifica della tensione ottimale. Quindi produce il risultato del risparmio energetico.", "keyphrases": ["cambiare l'angolo del trigger del tiristore", "ridurre una certa tensione", "cambiare la tensione", "gruppo pompa a trave", "calcolo mediante algoritmo genet", "algoritmo genet", "carico leggero", "carico corrente", "pompa a trave", "parte uguale", "risparmio energetico", "voltaggio ottimale", "carico costante", "angolo di innesco del tiristore", "migliorare il fattore di potenza e l'efficienza dell'unit\u00e0 pompa a trave", "intera regola modificabile della tensione ottimale.", "dividere il carico", "analizzare la variazione del ciclo del carico complessivo"]}
{"file_name": "S2212667814001476", "text": "I problemi di sicurezza dei dati ospitati in un provider di cloud computing rimangono nascosti a causa dell'eccessivo marketing che ha portato a una visione totalmente irrealistica della sicurezza del cloud computing. Sebbene il Cloud Computing non abbia ancora raggiunto il livello di maturit\u00e0 atteso dai suoi clienti, e che i problemi di riservatezza, integrit\u00e0, affidabilit\u00e0 e coerenza (CIRC) siano ancora aperti, i ricercatori in questo campo hanno gi\u00e0 considerato una futura strategia cloud che mira a: una migliore QoS, affidabilit\u00e0 e alta disponibilit\u00e0, \u00e8 il Multi-Clouds, Cloud of Clouds o Interclouds. Questo documento presenter\u00e0 i limiti di sicurezza nel singolo Cloud e l'utilit\u00e0 di adottare piuttosto la strategia Multi-Clouds per ridurre i rischi per la sicurezza, attraverso la utilizzo di DepSky che \u00e8 un sistema di storage virtuale che garantisce una migliore disponibilit\u00e0 e un'elevata riservatezza dei dati.", "keyphrases": ["dati", "mercato in eccesso", "riservatezza, integrit\u00e0, affidabilit\u00e0 e coerenza", "unica nuvola", "limite sicuro", "intercloud", "utilizzo di strategie piuttosto multi-cloud", "sistema di archiviazione virtuale", "multicloud", "calcolo della nuvola", "migliore utilizzo e alta fiducia", "future strategie cloud", "presentare il limite sicuro nel singolo cloud", "rischio sicuro", "nuvola di nuvole", "strategie multi-cloud", "fornitura di cloud computing", "depski", "sicurezza del cloud computing", "circ"]}
{"file_name": "S0167931714003347", "text": "Per studiare il comportamento meccanico delle pellicole metalliche su substrati polimerici conformi, vengono spesso utilizzati test di frammentazione [8\u201312]. Durante il test di frammentazione, la coppia film-substrato viene tesa sotto tensione uniassiale e osservata al microscopio ottico (LM) o al microscopio elettronico a scansione (SEM). I metalli fragili o i film ceramici si fratturano, formando crepe nello spessore (fessure del canale) a bassa deformazione perpendicolare alla direzione di deformazione. D'altra parte, i film metallici duttili si deformeranno inizialmente localmente sotto forma di colli a basse deformazioni (Figura 1a) e con una maggiore deformazione attraverso le crepe di spessore (TTC) possono svilupparsi (Figura 1b). Il test di frammentazione viene eseguito meglio in situ con LM o SEM in modo da poter osservare la deformazione quando si forma la prima fessura. La deformazione di frattura iniziale del film, nota anche come deformazione di inizio cricca, pu\u00f2 quindi essere utilizzata per determinare la sollecitazione di taglio della frattura interfacciale conoscendo la spaziatura delle fratture alla saturazione, \u03bb, lo spessore del film, h, e la sollecitazione di frattura, \u03c3f= Efilm\u03b5f, dove \u03b5f \u00e8 la deformazione di frattura, utilizzando il modello shear lag [8,13,14]. I test di frammentazione in situ con LM o SEM consentono di osservare l'evoluzione della spaziatura delle fessure in funzione della deformazione applicata (Figura 1c). In condizioni di deformazione a trazione, un film fragile si frattura inizialmente a deformazioni molto basse (<1%) e poi con ulteriore deformazione continua a formare fessure fino al raggiungimento della spaziatura delle fessure di saturazione. Una volta raggiunta la distanza di saturazione, tra i frammenti di fessura esistenti non possono pi\u00f9 formarsi crepe e la pellicola potrebbe delaminarsi per instabilit\u00e0.", "keyphrases": ["prova del frammento", "lm", "eseguire in situ con lm o sem", "crack space evoluto", "substrato polimerico", "studiare il comportamento del meccanico", "fibbia", "deformazione della frattura", "pellicola metallica", "funzione della tensione applicata", "metallo fragile", "frattura", "film fragile", "pellicola di ceramica", "delamina", "accoppiamento film-substr", "deformazione a trazione", "\u03c3f=efilm\u03b5f", "comportamento del meccanico", "sollecitazione di taglio", "microscopio elettronico a scansione", "film", "formare una crepa", "microscopi ottici", "sem", "modello di ritardo di taglio", "deformare locale", "deformazione sotto tensione uniassiale", "sottoporre a tensione"]}
{"file_name": "S0022311515002664", "text": "Il vantaggio principale dell'utilizzo di un modello 3D \u00e8 che consente l'applicazione di propriet\u00e0 del materiale anisotropo. Essendo una struttura reticolare esagonale compatta, un singolo grano di zirconio \u00e8 plasticamente anisotropo a causa della difficolt\u00e0 di attivare lo scorrimento con un componente \u3008c\u3009 [23\u201326]. Abaqus consente di rappresentare ci\u00f2 impostando rapporti potenziali di plasticit\u00e0. Le costanti elastiche e plastiche anisotrope sono mostrate nella Tabella 1. Le leghe di zirconio possono spesso avere una distribuzione bimodale dei poli basali, con un'inclinazione sulla direzione normale basale o c di \u00b1 30\u00b0 nella direzione normale indicata per Zircaloy-4 ricristallizzato [27 ,28]. Tuttavia, per semplicit\u00e0, la direzione normale basale o c \u00e8 stata considerata parallela alla direzione normale. Pertanto le direzioni 1, 2 e 3 nella Tabella 1 sono correlate al sistema di coordinate globali X, Y e Z per le simulazioni 3D, con la direzione 3 correlata alla direzione c di un reticolo di unit\u00e0 di zirconio. La tabella 1 mostra anche le propriet\u00e0 elastiche incorporate nelle simulazioni. Lo strato di ossido \u00e8 stato simulato come un materiale puramente elastico. Sebbene sia noto che l'ossido \u00e8 fortemente strutturato [29], viene comunque simulato come un solido omogeneo, pertanto in tutte le simulazioni sono state utilizzate le propriet\u00e0 isotrope del materiale per l'ossido.", "keyphrases": ["anisotropo materia propriet\u00e0", "elasto anisotropo e costante plastica", "ossido", "propriet\u00e0 isotrope della materia", "materiale di puro elast", "simul", "simulazione 3D", "strato di ossido", "zirconio", "modello 3D", "cristallo zircaloy-4", "reticolo in zirconio", "abaqu", "rapporto di potenziale plastico", "polo basale bimod distribuz", "grano di zirconio"]}
{"file_name": "S0377221716302259", "text": "Per quanto riguarda le implicazioni dei risultati di questo articolo, notiamo due punti. Da un punto di vista pratico, abbiamo dotato il modello additivo pesato di una struttura di funzione distanza, che assume valori negativi per i punti situati all'esterno della tecnologia e valori non negativi per i punti nell'insieme delle possibilit\u00e0 produttive. A questo proposito, la funzione di distanza additiva ponderata supporta metodologicamente il ramo della letteratura che ricorre al modello additivo ponderato o ad alcuni approcci correlati per misurare la produttivit\u00e0 nel tempo (vedi, ad esempio, Mahlberg & Sahoo, 2011 o Chang, 2012). Da un punto di vista teorico, abbiamo fornito una nuova funzione di distanza con alcune propriet\u00e0 interessanti in contrasto con quelle usuali, principalmente (1) quando si deve stimare l'inefficienza tecnica, la funzione di distanza additiva pesata coincide con il modello additivo pesato, che significa che l'inefficienza tecnica viene misurata seguendo la nozione di efficienza di Pareto-Koopmans; e (2) quando la produttivit\u00e0 deve essere determinata e scomposta nel tempo, la funzione di distanza additiva ponderata emerge come uno strumento interessante da utilizzare per la valutazione incrociata dei rendimenti dei cambiamenti di scala, poich\u00e9 questa funzione di distanza \u00e8 sempre fattibile, anche in caso di rendimenti variabili. scalare.", "keyphrases": ["implicito del risultato", "qualche approccio relativo", "modello di addizione di peso", "prendere un valore negativo per il punto individuato al di fuori della tecnologia e un valore non negativo per il punto nel prodotto possibile impostare", "significa che l'inefficacia tecnica \u00e8 una misura che segue la nozione pareto-koopman di efficienza", "una nuova funzione di distanza", "determinarsi e decomporre nel tempo", "misurare il prodotto nel tempo", "il modello di addizione del peso con una struttura di funzioni distanziatrici", "funzione di distanza", "funzione di distanza aggiuntiva peso", "la funzione di distanza aggiuntiva peso"]}
{"file_name": "S0010938X13005945", "text": "L'adesione/coesione del rivestimento \u00e8 stata valutata mediante il metodo del test di graffio, utilizzando un sistema Revetest (CSM Instruments SA, Svizzera) dotato di un penetratore di diamante H-270 (diametro 200\u03bcm). Sei rientranze di graffio sono state eseguite in condizioni precedentemente ottimizzate (modalit\u00e0 di carico progressivo lineare 1\u20134N, 4Nmin\u22121). Per facilitare la determinazione della posizione della spallazione/delaminazione, \u00e8 stata impiegata una lunghezza del graffio estesa di 6 mm. Le tracce dei graffi sono state successivamente osservate dal SEM per determinare le posizioni del primo cedimento del rivestimento e per comprendere la natura del cedimento del rivestimento. Durante i test di graffio, sono state registrate la forza di carico e la profondit\u00e0 di penetrazione e i rispettivi valori sono stati correlati con le posizioni di rottura osservate. La rugosit\u00e0 superficiale del rivestimento \u00e8 stata valutata utilizzando un tester di rugosit\u00e0 superficiale (TR200, Timegroup Inc.) secondo lo standard ISO [29]. A causa della presenza di porosit\u00e0 aperta nello strato esterno del rivestimento, \u00e8 stata utilizzata una lunghezza di misurazione per la determinazione della rugosit\u00e0 (Ra) di 0,8 mm. In totale sono state effettuate otto misurazioni in direzioni diverse.", "keyphrases": ["strato esterno", "sistema revetest (csm instrument sa, svizzera) dotato di un penetratore di diamante h-270 (diametro 200\u03bcm)", "metodo di prova del graffio", "adesione/coesione del rivestimento", "sono stati eseguiti i rientri di graffio", "determinazione della posizione della spallazione/delamina", "adesione/coesione", "ruvido", "la superficie ruvida del mantello \u00e8 stata valutata", "tester per superfici ruvide", "la forza di carico e la profondit\u00e0 di penetrazione sono state registrate e il loro valore di rispetto era correlato con l'osservazione della localizzazione del guasto", "RA", "otto misura", "cappotto", "la forza di carico e la profondit\u00e0 di penetrazione sono state record", "comprendere la natura del cedimento del rivestimento"]}
{"file_name": "S0045782515002686", "text": "Il metodo dei confini immersi (IBM), proposto da Peskin per studiare i modelli di flusso attorno alle valvole cardiache [3], \u00e8 stato applicato a un'ampia gamma di problemi tra cui il flusso sanguigno arterioso [4], la modellazione della coclea [5], la modellazione del rosso cellule del sangue nel flusso di Poiseuille [6] e flussi che coinvolgono particelle sospese [7]. Un elenco completo delle applicazioni pu\u00f2 essere trovato in [8]. L'IBM \u00e8 sia una formulazione matematica che uno schema numerico per problemi di interazione fluido-struttura. Come accennato in precedenza, in un classico problema di interazione fluido-struttura, il fluido e la struttura vengono considerati separatamente e quindi accoppiati insieme tramite alcune opportune condizioni di salto. Nell'IBM, tuttavia, la struttura, che di solito \u00e8 immersa in un fluido newtoniano, \u00e8 vista come parte del fluido circostante. Ci\u00f2 significa che \u00e8 necessario risolvere una sola equazione del moto (cio\u00e8 una formulazione ad una fase). Inoltre, l'IBM consente alla struttura immersa di muoversi liberamente sulla rete fluida sottostante, alleviando la necessit\u00e0 del remeshing richiesto in una formulazione classica.", "keyphrases": ["modello di flusso studiato attorno alla valvola cardiaca", "movimento", "fluido newtoniano", "maglia fluida sottostante", "fluido circostante", "Problema di interazione fluido-struttura", "ibm", "modello di globuli rossi nel flusso di Poiseuil", "struttura", "flusso sanguigno arterioso", "rimescolare", "accoppiarsi insieme", "flusso coinvolge sospende particl", "fluido", "modello della coclea", "Metodo dei limiti di Immers"]}
{"file_name": "S0167931714004456", "text": "Il PDMS (polidimetilsilossano) \u00e8 diventato di gran lunga il materiale pi\u00f9 popolare nella comunit\u00e0 accademica della microfluidica perch\u00e9 \u00e8 poco costoso, facile da fabbricare mediante replica di stampi realizzati utilizzando prototipazione rapida o altre tecniche, flessibile, otticamente trasparente, biocompatibile e la sua fabbricazione non richiede elevate investimenti di capitale e condizioni delle camere bianche. Varie tecniche sono state adattate per fabbricare strutture microfluidiche nel PDMS, tra cui l'attacco a umido e a secco [20\u201322], il patterning fotolitografico di un PDMS fotosensibile [23] e l'ablazione laser [24]. Ma sono state le tecniche di \u201clitografia morbida\u201d [25] introdotte da Whitesides a consentire l\u2019uso diffuso del PDMS e ad aprire l\u2019era della microfluidica basata su PDMS alla fine degli anni \u201990. Lo stampaggio di repliche, ovvero la fusione del prepolimero contro un master e la generazione di una replica del master in PDMS, \u00e8 diventata una tecnica di fabbricazione standard disponibile in quasi tutti i laboratori di ricerca. Panoramica dettagliate delle tecniche di litografia morbida e delle loro applicazioni possono essere trovate nelle revisioni di McDonald [26] e Sia [27]. Al giorno d'oggi sono disponibili molti strumenti dedicati a questo scopo e possono essere acquistati come set completo (SoftLithoBox\u00ae fornito da Elveflow (USA) [28]). Inoltre, aziende come FlowJEM (Canada) [29], Microfluidic Innovations (USA) [30] e Scientific Device Laboratory (USA) [31] forniscono un servizio di prototipazione rapida per dispositivi LOC basati su PDMS.", "keyphrases": ["cast di prepolym contro un master e genera una replica del master in pdm", "tecnica della \u201clitografia soft\u201d.", "pdm", "stampo replica", "tecnica del tessuto", "servizio di prototipazione rapida", "softlithobox\u00ae", "replica dello stampo", "polidimetilsilossano", "prototipo rapido", "prepolim", "tessuto", "modello di fotolitografia", "dispositivo di localizzazione pdms-base", "incidere a umido e a secco", "tecnica soft-litografia", "ablazione laser", "microfluido a base di pdms", "struttura microfluida del tessuto", "microfluido"]}
{"file_name": "S0165212511000874", "text": "La propagazione di disturbi instabili in condotti con geometria a variazione lenta, come quelli tipici di un motore aeronautico, pu\u00f2 essere modellata con successo utilizzando un approccio a scale multiple. Dalla prima applicazione [1] dell'analisi a scale multiple alla propagazione del suono in condotti di sezione rettangolare e circolare senza flusso medio, sviluppi pi\u00f9 recenti hanno esteso il metodo a casi con flusso medio uniforme [2], flusso medio vorticoso [3] , condotti di sezione trasversale arbitraria [4] (con flusso medio uniforme) e condotti fortemente curvi [5]. L'approccio a scale multiple presenta una serie di vantaggi distinti rispetto ai metodi numerici completi poich\u00e9 \u00e8 ideale per gestire frequenze pi\u00f9 elevate e la complessit\u00e0 computazionale \u00e8 solo marginalmente maggiore rispetto al calcolo dei modi propri all'interno di un condotto parallelo rettilineo. L'accuratezza e l'utilit\u00e0 dell'approccio su scale multiple \u00e8 stata convalidata rispetto a metodi agli elementi finiti [6] per configurazioni realistiche di motori aeronautici e frequenze acustiche [7,8].", "keyphrases": ["condotto curvo strongli", "approccio a scala multipla", "condotto", "configurazione aeroengine", "frequenza pi\u00f9 alta", "metodo degli el finiti", "significa flusso vorticoso", "metodo numerico", "analisi a pi\u00f9 scale", "calcolare il modo proprio", "approccio multiscal", "condotto rettilineo parallelo", "frequenza acustica", "flusso medio", "propagazione di disturbi instabili", "aeroengine", "propaganda sonora", "flusso medio uniforme"]}
{"file_name": "S0254058415300766", "text": "I ferromagneti semimetallici (HMF) hanno suscitato enorme interesse grazie alle loro applicazioni nei dispositivi spintronici [1]. I semiconduttori magnetici diluiti (DMS) sono considerati i migliori materiali per mostrare met\u00e0 metallicit\u00e0. Questi materiali hanno due componenti, uno \u00e8 un materiale semiconduttore con propriet\u00e0 diamagnetiche mentre l'altro \u00e8 un drogante magnetico come un metallo di transizione avente elettroni d non accoppiati [2]. Il vantaggio principale di questi materiali \u00e8 l'utilizzo dello spin dell'elettrone come vettore di informazioni poich\u00e9 funzionalit\u00e0 avanzate nei dispositivi spintronici possono essere praticabili utilizzando il grado di libert\u00e0 dello spin insieme alla carica degli elettroni [3]. Il problema principale relativo all'applicabilit\u00e0 di questi materiali \u00e8 aumentare la temperatura di Curie al di sopra della temperatura ambiente. Ecco perch\u00e9 l'interesse della ricerca si \u00e8 spostato verso i materiali con ampio gap di banda. \u00c8 stato riportato molto lavoro sui DMS con diversi semiconduttori II-VI e III-V come materiale ospite come ZnS, CdS, GaN, ZnO, ZnSe, ZnTe, TiO2, SnO2 [4\u201312].", "keyphrases": ["drogante magnetico", "materiale con ampio gap di banda", "elettrone", "dispositivo spintrone", "ferromagnete mezzo metallo", "migliorare la curi temperatur al di sopra della temperatura ambiente", "semiconduttore ii-vi e iii-v", "znse", "gan", "materiale ospite", "utilizzo dello spin dell'elettrone come portatore di informazioni", "zn", "zno", "materi per mostrare met\u00e0 metallo", "elettrone d non accoppiato", "semiconduttore magnetico diluito", "metallo in transito", "tio2", "CD", "dmss", "sno2", "materiale semiconduttore", "hmf", "znte"]}
{"file_name": "S0895611116300684", "text": "Nel caso del PSR applicato ai vasi, la conservazione di un'elevata curvatura e di rami (concavit\u00e0) richiede un valore elevato del parametro d, risultando in modelli con un numero elevato di poligoni. Per far fronte a questo problema, Wu (2013) valuta una variante del PSR (in quel lavoro denominata scale-adaptive [SA]), che include la poligonizzazione dipendente dalla curvatura (aumento/diminuzione della dimensione dei triangoli in base alla curvatura locale) (Wu, 2010). In Wu (2013), vengono valutati altri metodi tra cui MC (senza livellamento e decimazione) con applicazione alla modellazione dei vasi. Gli autori indicano la SA come un metodo adatto per la ricostruzione dei vasi con applicazioni nella pianificazione chirurgica. I metodi valutati da Wu (2013) potrebbero anche essere confrontati con un altro insieme di tecniche (noti come metodi basati su modelli) (Preim e Oeltze, 2008), ampiamente utilizzate nel context della modellazione dei vasi per la pianificazione chirurgica.", "keyphrases": ["adattamento in scala", "s\u00ec", "piano chirurgico", "aumentando/diminuendo la dimensione del triangolo in base alla curvatura locale", "mc", "modello di nave", "PSR", "poligono dipendente dalla curvatura", "metodo modello-bas", "ricostruzione della nave", "modello di vaso per il piano chirurgico", "PSR applicato alla nave"]}
{"file_name": "S0021999115004301", "text": "Una scelta popolare \u00e8 quella di accoppiare un insieme di punti di quadratura con un numero uguale di polinomi di Lagrange nodali definiti negli stessi punti, portando a un metodo di collocazione. Ci sono molti esempi di ci\u00f2 in tutta la letteratura, sia in termini di formulazioni Galerkin continuo (CG) e discontinuo (DG) pi\u00f9 tradizionalmente utilizzate, sia in termini di estensioni pi\u00f9 recenti come la tecnica di ricostruzione del flusso (FR) presentata da Huynh. 23]. Nei metodi di collocazione, mentre la maggior parte degli operatori lineari pu\u00f2 essere integrata esattamente in questa impostazione a seconda della scelta della quadratura, gli integrali dei termini non lineari tipicamente incorrono in errori numerici. Tuttavia, le efficienze computazionali che possono essere raggiunte attraverso l\u2019uso di una formulazione di collocazione, soprattutto data la presenza di una matrice di massa diagonale, spesso superano l\u2019errore numerico che si incorre.", "keyphrases": ["galerkin", "formulazione colloidale, soprattutto data la presenza di una matrice di massa diagonale", "metodo colloc", "opera lineare", "fr", "accoppiare un insieme di punti di quadratura con un numero uguale di polinomi lagrang nodali", "interrompere Galerkin", "c.g", "ricostruzione del flusso", "estensioni pi\u00f9 recenti", "dg"]}
{"file_name": "S0022311515300830", "text": "Pezzi solidi da 23-114 mg sono stati ulteriormente utilizzati per misurare gli incrementi di entalpia utilizzando un calorimetro ad alta temperatura multirilevatore Setaram (MDHTC-96) utilizzando un rilevatore di gocce. Per maggiori dettagli sulla tecnica rimandiamo ai nostri studi precedenti [9,10]. Le misurazioni sono state effettuate in atmosfera di argon (con un contenuto di ossigeno di 7 ppm), utilizzando lingotti di platino puro (64-144 mg) con purezza del 99,95% come materiale di riferimento. L'intervallo di temperatura dell'esperimento era compreso tra 430,3 K e 1088,8 K utilizzando incrementi di 50 K. Ogni corsa isotermica consisteva in 2-4 gocce di campioni Bi2UO6, ciascuno circondato da due gocce di platino da cui \u00e8 stata determinata la sensibilit\u00e0 del dispositivo. Le gocce sono state separate da intervalli di tempo di 20 minuti, abbastanza lunghi da ristabilire il segnale del flusso di calore monitorato. La sottrazione dello sfondo e l'integrazione dei picchi sono state eseguite utilizzando software disponibile in commercio per l'elaborazione dei dati. Le temperature riportate sono state corrette in conformit\u00e0 con la curva di calibrazione ottenuta prima della misurazione utilizzando diversi metalli standard di elevata purezza (Sn, Pb, Zn, Al, Ag, Ni) con varie temperature di fusione per coprire l'intero intervallo di temperature della misurazione. Dopo misurazioni calorimetriche alla temperatura massima considerata, il materiale \u00e8 stato sottoposto ad una nuova misurazione XRD, confermando la stabilit\u00e0 del composto nelle condizioni sperimentali.", "keyphrases": ["Argon", "sottrazione dello sfondo e integrazione del picco", "metallo standard di elevata purezza", "no", "lingotto di platino", "al", "composto", "mdhtc-96", "il commercio si avvale di software per l'elaborazione dei dati", "Ag", "pb", "flusso di calore", "zn", "riferire materia", "corsa isoterma", "misura del calorimetro", "xrd", "rilevatore di gocce", "incremento entalpico", "pezzo solido", "setaram multirivelatore calorimet ad alta temperatura", "processo dei dati", "2\u20134 gocce di campione bi2uo6", "misurare l'incremento entalpico", "corretto", "sn", "platino", "ossigeno"]}
{"file_name": "S2212667814000069", "text": "Nel presente articolo \u00e8 stato presentato un modello ipergrafico per la modellazione del sistema strutturale e l'analisi della riconfigurabilit\u00e0. Innanzitutto, rappresentiamo ciascuna equazione del sistema mediante un iperbordo, quindi estendiamo l'ipergrafo di modellazione con altri iperbordi colorati (rosso e blu) che ci consentono di eseguire il compito di analisi. Sulla base del modello ipergrafico dell'analisi bottom up, \u00e8 molto semplice verificare la riconfigurabilit\u00e0 del sistema in presenza di guasto verificando l'esistenza di percorsi dall'iperbordo interessato ai specifici iperbordi blu passando per i specifici iperbordi rossi. Il metodo \u00e8 illustrato attraverso un esempio pedagogico.", "keyphrases": ["ipergrafo del modello", "verificare l'esistenza del percorso dall'effetto hyperedg", "compito di analisi", "esempio pedagogico", "modello ipergrafico", "modello ipergrafico di analisi bottom up", "riconfigurare l'analisi", "riconfigurazione del sistema", "modello di sistema strutturale"]}
{"file_name": "S0167931712003905", "text": "In sintesi, abbiamo sviluppato una tecnica per la riduzione delle dimensioni dei nanofili sito-specifica mediante assottigliamento del FIB. Le immagini al microscopio elettronico a trasmissione di un nanofilo composito di tungsteno assottigliato con larghezza ridotta da 80 a 20 nm mostrano un restringimento uniforme lungo la lunghezza del filo e le immagini ad alta risoluzione non mostrano cambiamenti evidenti della morfologia dopo l'assottigliamento. La densit\u00e0 di corrente critica del filo depositato e di quello assottigliato fino a una larghezza di 50 nm \u00e8 rispettivamente 1,7\u00d7105 e 1,4\u00d7105 A/cm2 a 4,26 K, suggerendo una modulazione insignificante delle propriet\u00e0 elettriche durante l'assottigliamento. Questi risultati suggeriscono che la fresatura FIB \u00e8 un potenziale approccio per la riduzione dimensionale controllabile con alta risoluzione verso l'osservazione di effetti dimensionali e quantistici, nonch\u00e9 per la costruzione di nanodispositivi superconduttori 3D.", "keyphrases": ["fibmil", "nanowir composito sottile di tungsteno", "filo", "come filo di deposito", "Nanodispositivo superconduttore 3D", "modulo delle propriet\u00e0 elettr", "fib sottile", "restringimento uniforme", "immagine ad alta risoluzione", "riduzione delle dimensioni dei nanofili specifica per il sito", "trasmettere l'immagine al microscopio elettronico", "magro", "costrutto di nanodevic superconduttore 3d", "controllo della riduzione delle dimensioni con alta risoluzione verso l'osservazione delle dimensioni e dell'effetto quantistico"]}
{"file_name": "S0379711215000223", "text": "Le difficolt\u00e0 menzionate associate al processo di calibrazione hanno ispirato il concetto di modellazione inversa. In questo caso, i dati sperimentali vengono completamente integrati nel processo di calibrazione e viene utilizzata una routine di ottimizzazione per quantificare il miglior insieme di parametri che spiegano il comportamento osservato della pirolisi (cio\u00e8 adattamento della curva multivariabile). I dati sperimentali pi\u00f9 utilizzati per la calibrazione del modello sono stati il \u200b\u200btasso di perdita di massa e la temperatura superficiale [10\u201312]. La tecnica di ottimizzazione utilizzata \u00e8 funzione del numero di variabili e delle loro interazioni. In passato, solo i pochi parametri pi\u00f9 incerti (cio\u00e8 i parametri cinetici) venivano generalmente utilizzati come potenziometri [13]. Tuttavia, sono state sviluppate sofisticate procedure matematiche per aumentare il numero di parametri ottimizzati simultaneamente (Algoritmo Genetico (GA) [10,14] o Evoluzione Complessa Shuffled (SCE) [11]). Lautenberger e Fernandez-Pello [12] hanno recentemente studiato l'influenza che la scelta dell'algoritmo pu\u00f2 avere sui parametri ottimizzati. Utilizzando il loro codice GPYRO hanno generato una serie di dati sintetici (tasso di perdita di massa e temperatura delle superfici) e hanno provato con diversi algoritmi a ritrovare la serie di parametri di input. I quattro algoritmi di ottimizzazione hanno fornito risultati con un errore medio assoluto compreso tra l'1% e il 25%. SCE era l'algoritmo pi\u00f9 adatto. L'uso di dati sintetici evita convenientemente il problema della concordanza tra i fenomeni fisici reali e qualsiasi ipotesi di modellazione.", "keyphrases": ["tecnica ottimale", "paramet", "procedura matematica", "gpyro", "sce", "processo di calibrazione", "routine ottimale", "quantificare il miglior set di parametri", "dati del sintetizzatore", "algoritmo genet", "algoritmo", "parametro kinet", "temperatura superficiale [", "modello inverso", "calibro del modello", "scelta dell'algoritmo", "potenziometro", "tasso di perdita di massa", "evoluzione del complesso shuffle", "ga", "dati dell'esperimento", "comportamento di pirolisi", "vestibilit\u00e0 curva multivariata", "algoritmo ottimale"]}
{"file_name": "S0370157309002877", "text": "Iniziamo delineando la motivazione, la struttura e il contenuto della recensione. \u00c8 noto da tempo che i segnali cardiovascolari contengono un numero di componenti oscillatori che non sono esattamente periodici. In altre parole, i loro periodi (frequenze) fluttuano nel tempo. Ad esempio, la variabilit\u00e0 della frequenza cardiaca (HRV) ha fornito di per s\u00e9 un importante argomento di discussione. Introduciamo uno degli approcci statistici all'HRV nella Sezione 3. Tuttavia, per comprendere la variabilit\u00e0 del sistema cardiovascolare, la discussione di un'unica fonte non \u00e8 sufficiente perch\u00e9 il sistema cardiovascolare \u00e8 composto da molti componenti fisiologici diversi (sottosistemi) ed \u00e8 gli effetti della loro reciproca interazione che si combinano per produrre HRV. Ci\u00f2 \u00e8 dimostrato nella Sezione 4, rivelato dai risultati ottenuti utilizzando la trasformata wavelet. Nella Sezione 5 discutiamo l'interazione cardio-respiratoria in termini di sincronizzazione di fase. Per preparare il terreno a queste discussioni successive, riassumiamo i principi di base della dinamica di fase nella Sezione 2. Per i lettori che non hanno familiarit\u00e0 con gli aspetti fisiologici della ricerca, forniamo le Appendici A sul sistema cardiovascolare e B su come le misurazioni dei segnali cardiovascolari sono condotti. L'Appendice C fornisce dettagli sui metodi statistici utilizzati nelle analisi dei dati di gruppo.", "keyphrases": ["interagiscono cardio-respiratori", "metodo statalista", "dinamica di fase", "analisi dei dati di gruppo", "periodo", "componente fisiologico", "frequenza cardiaca variabile", "sottosistema", "trasformata wavelet", "introdurre uno degli approcci statali all'HRV", "segnale cardiovascolare", "sistema cardiovascolare", "approccio statalista", "frequenza", "componente oscillatori", "riassumere i principi base della dinamica di fase", "fase sincrona", "discutere l'interazione cardio-respiratoria", "hrv", "misura del segnale cardiovascolare", "comprendere la variabile del sistema cardiovascolare"]}
{"file_name": "S1877750313001269", "text": "Sebbene le tecnologie di virtualizzazione riducano certamente la complessit\u00e0 dell'utilizzo di un sistema, soprattutto quando si lavora su pi\u00f9 ambienti informatici eterogenei, non sono ampiamente utilizzate negli scenari di calcolo ad alte prestazioni. Come suggerisce il nome, HPC cerca di ottenere le massime prestazioni dalle piattaforme informatiche. I livelli software aggiuntivi hanno un impatto negativo sulle prestazioni, il che significa che negli scenari HPC gli utenti in genere eseguono le applicazioni il pi\u00f9 vicino possibile al \"bare metal\". Oltre al degrado delle prestazioni introdotto dalle tecnologie di virtualizzazione, la scelta di quali dettagli astrarre in un'interfaccia virtualizzata \u00e8 di per s\u00e9 molto importante. Il grid e il cloud computing supportano diversi modelli di interazione. Nel grid computing, l'utente interagisce con una risorsa individuale (o talvolta con un broker) per avviare lavori in un sistema di code. Nel cloud computing, gli utenti interagiscono con un server virtuale, acquisendo di fatto il controllo del proprio sistema operativo completo. Entrambi questi modelli di interazione pongono l'onere sull'utente di comprendere dettagli molto specifici del sistema con cui ha a che fare, rendendo la vita difficile all'utente finale, in genere uno scienziato che desidera far progredire le proprie indagini scientifiche senza specifici ostacoli all'usabilit\u00e0 ostruendo il percorso.", "keyphrases": ["broker", "scenario di calcolo ad alte prestazioni", "calcolo della griglia", "griglia e cloud computing", "sistema di code", "calcolo della nuvola", "interfaccia virtuale", "modello di interazione", "server virtuale", "applica", "calcolo ad alte prestazioni", "hpc", "tecnologia virtuale"]}
{"file_name": "S1746809416300933", "text": "ObiettivoLe risposte uditive allo stato stazionario (EASSR) evocate elettricamente sono potenziali neurali misurati nell'elettroencefalogramma (EEG) in risposta a treni di impulsi periodici presentati, ad esempio, attraverso un impianto cocleare (CI). Gli EASSR potrebbero essere potenzialmente utilizzati per l\u2019adattamento oggettivo dell\u2019IC. Tuttavia, i segnali EEG sono contaminati da artefatti elettrici CI. In questo articolo, abbiamo caratterizzato gli artefatti CI per la stimolazione in modalit\u00e0 monopolare e valutato a quale frequenza del polso, l'interpolazione lineare sulla parte del segnale contaminata con artefatti CI ha successo. Metodi Gli artefatti CI sono stati caratterizzati mediante le loro funzioni di crescita dell'ampiezza e la durata. Risultati Durate degli artefatti CI erano compresi tra 0,7 e 1,7 ms, agli elettrodi di registrazione controlaterali. Agli elettrodi di registrazione ipsilaterali, le durate degli artefatti CI variano da 0,7 a pi\u00f9 di 2 ms. Conclusione Con gli elettrodi di registrazione controlaterali, l'artefatto era pi\u00f9 breve dell'intervallo tra gli impulsi tra i soggetti per 500 pps, il che non era sempre il caso per 900 pps. Significato Gli EASSR privi di artefatti CI sono cruciale per un adattamento affidabile dell\u2019IC e la ricerca neuroscientifica. L'artefatto CI \u00e8 stato caratterizzato e l'interpolazione lineare consente di rimuoverlo dagli elettrodi di registrazione controlaterali per la stimolazione a 500 pps.", "keyphrases": ["artefatto ci", "segnale eeg", "ci si adatta", "eassr", "eg", "elettr evoca auditi stazionario respons", "elettrodo di registrazione controlaterale", "interpolazione lineare", "caratterizzare l'artefatto ci per lo stimolo in modalit\u00e0 monopolare", "potenziale neurale", "ricerca sulle neuroscienze", "ci", "elettroencefalogramma", "elettrodo di registrazione ipsilater", "impianto cocleare"]}
{"file_name": "S0377221716300984", "text": "In questo articolo proponiamo un quadro generale distribuito basato su agenti in cui ciascun agente implementa una diversa combinazione metaeuristica/ricerca locale. Inoltre, un agente si adatta continuamente durante il processo di ricerca utilizzando un protocollo di cooperazione diretta basato sull'apprendimento per rinforzo e sul pattern match. I buoni modelli che costituiscono soluzioni migliorative vengono identificati e condivisi dagli agenti. Questo sistema basato su agenti mira a fornire un quadro modulare flessibile per affrontare una variet\u00e0 di diversi ambiti problematici. Abbiamo valutato le prestazioni di questo approccio utilizzando il framework proposto che incorpora un insieme di metaeuristiche ben note con diverse configurazioni come agenti su due domini problematici, Permutation Flow-shop Scheduling e Capacited Vehicle Routing. I risultati mostrano il successo dell'approccio producendo tre nuovi risultati pi\u00f9 noti dei benchmark di Capacited Vehicle Routing testati, mentre i risultati per la pianificazione del flusso di permutazione sono commisurati ai valori pi\u00f9 noti per tutti i benchmark testati.", "keyphrases": ["buon modello", "agente", "corrispondenza del modello", "programma del flow-shop permutato", "fornire un quadro modulare flessibile", "programma del flow-shop permutato e percorso dei veicoli capacitivi", "dominio con due problemi", "affrontare una variet\u00e0 di ambiti problematici diversi", "sistema agente-bas", "incarna un insieme di metaeuristi ben noti con configurazioni diverse", "questo approccio", "un protocollo diretto di Cooper", "rafforzare l'apprendimento", "approccio", "adattare", "struttura", "ciascun agente implementa una diversa combinazione di ricerca metaeuristica/loc", "benchmark di rotta dei veicoli capacitivi"]}
{"file_name": "S0997754612001318", "text": "Molte applicazioni nella meccanica dei fluidi hanno dimostrato che l\u2019aspirazione superficiale pu\u00f2 essere utilizzata come efficace meccanismo di controllo del flusso. Ad esempio, Gregory e Walker [1] discutono di come l'introduzione dell'aspirazione estenda la regione del flusso laminare su un'ala spazzata riducendo lo spessore dello strato limite e l'entit\u00e0 della velocit\u00e0 del flusso trasversale. Le conclusioni per il flusso ad ala spazzata sono emerse da studi equivalenti del flusso di von K\u00e1rm\u00e1n (disco rotante) (vedi Gregory e Walker [2], Stuart [3]) e da allora il lavoro \u00e8 continuato su questo e sui flussi correlati utilizzando approcci numerici e asintotici ( vedere Ockendon [4], Dhanak [5], Bassom e Seddougui [6], Lingwood [7], Turkyilmazoglu [8], Lingwood e Garrett [9], per esempio). La letteratura dimostra che l\u2019aumento dell\u2019aspirazione ha un effetto stabilizzante sulla classe generale dei flussi \u201cB\u00f6dewadt, Ekman e von K\u00e1rm\u00e1n\u201d (BEK) che si traduce in un aumento dei numeri di Reynolds critici per l\u2019insorgenza di instabilit\u00e0 convettive e assolute, un restringimento del range di parametri instabili e una diminuzione dei tassi di amplificazione dei modi convettivi instabili. I risultati dell'instabilit\u00e0 convettiva sono interpretati in termini di un ritardo nell'inizio dei vortici a spirale, e i risultati dell'instabilit\u00e0 assoluta in termini dell'inizio della transizione laminare-turbolenta (Lingwood [7,10,11]).", "keyphrases": ["ruotare il disco", "ridurre lo spessore dello strato limite e l'entit\u00e0 della velocit\u00e0 del flusso incrociato", "diminuzione della frequenza di amplificazione", "approccio numerico e asintotico", "vortice a spirale", "assolutamente instabile", "meccanismo di controllo del flusso", "meccanica dei fluidi", "aumentare l'aspirazione", "\u201cb\u00f6dewadt, ekman e von k\u00e1rm\u00e1n\u201d (bek) flusso", "aumento del numero di Reynold critico", "ala spazzata", "ridurre lo spessore dello strato limite", "stretto nel campo dei parametri instabili", "transito laminare-turbule", "aspirazione superficiale", "spazzato-w", "convezione instabile", "grandezza della velocit\u00e0 del flusso incrociato", "flusso spazzato"]}
{"file_name": "S0022311515301069", "text": "La fluenza di ciascuna capsula \u00e8 stata determinata utilizzando set di monitoraggio dell'attivazione. Questi set di monitor sono costituiti da diversi pezzi di filo metallico che hanno una reazione di attivazione a uno specifico intervallo di energia. Le diverse energie di attivazione vengono scelte in modo tale da poter ricostruire lo spettro. In BODEX, ciascuna capsula conteneva un monitor di flusso posto sul \"lato posteriore\" (visto dal nucleo) e uno sul lato anteriore, posizionato all'altezza centrale delle capsule. Inoltre, \u00e8 stato posizionato un rilevatore in alto e uno in basso, per un totale di 6 set di monitor per gamba. La fluenza in ciascuna capsula \u00e8 stata determinata come la media tra i due monitor di flusso situati in ciascuna capsula. I set sono stati analizzati determinando l'attivazione di ciascun pezzo di filo, che indica la fluenza di uno specifico intervallo di energia. Nella tabella 3 sono riportati i valori delle fluenze per le due capsule contenenti molibdeno.", "keyphrases": ["set di monitor attivi.", "fluec di ogni capsula", "capsula", "tenere sotto controllo", "fluente", "set monitor di flusso", "rivelatore", "monitor di flusso", "pezzo di filo", "attivo", "molibdeno", "pezzo di filo metallico", "determinare l'attivazione di ciascun pezzo di filo", "set di monitor"]}
{"file_name": "S2212667814001397", "text": "In questo articolo viene proposto un metodo basato sull'analisi di regressione per calcolare il Journal Influence Score. Questo punteggio di influenza viene utilizzato per misurare l'influenza scientifica delle riviste accademiche. Il Journal Influence Score viene calcolato utilizzando vari fattori in modo ponderato. Il punteggio viene quindi confrontato con il punteggio SCImago Journal. I risultati mostrano che l\u2019errore \u00e8 piccolo tra i metodi esistenti e quelli proposti, dimostrando che il modello \u00e8 un modo fattibile ed efficace per calcolare l\u2019impatto scientifico delle riviste.", "keyphrases": ["analisi di regressione", "utilizzare vari fattori in modo ponderato", "punteggio di influenza del diario", "calcolare il punteggio di influenza della rivista", "Rivista Scholarli", "Punteggio del diario scimago", "confrontare con il punteggio del diario Scimago", "metodo base dell'analisi regressiva", "influenzare il punteggio", "influenza scientifica", "calcolo dell'impatto scientifico della rivista", "misurare l'influenza scientifica della rivista Scholarli"]}
{"file_name": "S0166218X1300348X", "text": "I programmi max-lineari sono stati utilizzati per descrivere problemi di ottimizzazione per sistemi interattivi multiprocessore. In alcuni casi le variabili utilizzate in questo modello devono essere intere; tuttavia, non sembra esistere alcun metodo per trovare soluzioni intere a programmi max-lineari. Per una classe generica di matrici, mostriamo che soluzioni intere a sistemi e programmi max-lineari a due lati possono essere trovate in tempo polinomiale. Per le matrici generali, adattiamo i metodi esistenti per trovare soluzioni reali per ottenere algoritmi per trovare soluzioni intere.", "keyphrases": ["variabile", "adattare il metodo esistente per trovare una soluzione reale", "soluzione integ", "algoritmo per trovare la soluzione intera", "sistema e programma max-lineare a due lati", "gene matricola", "problema di ottimizzazione", "sistema di interazione multiprocessore", "classe gener della matricola", "programma max-lineare"]}
{"file_name": "S0009261414000372", "text": "\u00c8 noto che le propriet\u00e0 ottiche degli atomi e delle molecole possono essere influenzate dal loro ambiente elettronico. Gli effetti del campo locale sui tassi di emissione spontanea all'interno di materiali fotonici nanostrutturati, ad esempio, sono familiari e sono stati ben riassunti [1]. I processi ottici, incluso il trasferimento di energia di risonanza, dipendono in modo simile dall'ambiente locale dei cromofori molecolari [2\u20134]. \u00c8 noto che molti sistemi biologici contengono organizzazioni complesse di molecole con bande di assorbimento spostate a causa dell'influenza elettronica di altri centri ottici vicini. Ad esempio, nei complessi di raccolta della luce ampiamente studiati, esistono due forme identificabili della batterioclorofilla, molecola antenna fotosintetica, con bande di assorbimento centrate su 800 e 850 nm; \u00e8 stato dimostrato che le forme pi\u00f9 efficienti di trasferimento di energia tra i due si verificano quando \u00e8 presente una specie di carotenoide vicina 5\u20137. Fino ad ora, la ricerca sull\u2019influenza pi\u00f9 ampia di una molecola vicina, fuori risonanza, sull\u2019assorbimento di fotoni si \u00e8 concentrata principalmente sul fenomeno del dicroismo circolare indotto, dove sia i calcoli elettrodinamici quantistici (QED) [8\u201310] che le procedure sperimentali [11\u2013 13] prevedere e verificare che un mediatore chirale conferisce la capacit\u00e0 ad un accettore achirale di mostrare un assorbimento differenziale circolare.", "keyphrases": ["fotone", "elettrodinamica quantistica", "inducono dicroismo circolare", "fascia assorbente", "molecola dell'antenna fotosintetica batterioclorofilla", "assorbimento differenziale circolare", "procedura dell'esperimento", "propriet\u00e0 ottiche", "trasferimento energetico della risonanza", "ambiente elettronico", "complesso di raccolta della luce", "qed", "effetto di campo locale", "materia fotonica della nanostruttura", "assorbimento di fotoni", "molecolar", "trasferimento energetico", "mediatore chirale", "ambiente locale del cromoforo molecolare", "influenza degli elettroni", "accettore achiro", "atomo", "speci di carotenoidi", "influenza di una molecola vicina, fuori risonanza, sull'assorbimento dei fotoni", "processo ottico"]}
{"file_name": "S0009261412012365", "text": "In queste condizioni sperimentali, la dinamica osservata deve verificarsi laddove il laser della sonda induce le reazioni che portano ad un'ulteriore ionizzazione [30]. Il modello di decadimento in due fasi [26] \u00e8 stato applicato per spiegare la suddetta frammentazione di DCPD in CPD, mostrata nella Figura 8a. L'adattamento delle componenti di aumento e decadimento dei transitori \u00e8 stato effettuato mediante programmazione Matlab\u00ae utilizzando l'algoritmo di adattamento della curva Levenberg-Marquardt. La costante di decadimento pi\u00f9 adatta per le componenti di decadimento biesponenziale del segnale ionico C10H12+ \u00e8 \u03c41=35fs e \u03c42=240fs, mentre quella per il segnale ionico C5H6+ \u00e8 \u03c41=36fs e \u03c42=280fs, rispettivamente. Queste costanti di decadimento sono conformi alle costanti di tempo precedentemente riportate del norbornene e del norbornadiene [22,23]. I transitori del frammento di reazione C5H6+ sono sufficientemente diversi da quelli dello ione genitore C10H12+, indicando che stiamo studiando la dinamica distinta dei neutri e non quella della frammentazione dello ione genitore [24]. L'applicazione dei principi di controllo laser in tali circostanze sperimentali conferma anche che stiamo controllando la resa del prodotto di C5H6+, risultante dalla reazione fotochimica del DCPD.", "keyphrases": ["reazione", "dcpd", "algoritmo di curvatura di Levenberg-Marquardt", "dinamica distinta del neutro", "\u03c41=35f", "c5h6+", "norbornadien", "programma matlab\u00ae", "Segnale ionico c10h12+", "c10h12+", "principio di controllo laser", "transitorio", "costante di decadimento pi\u00f9 adatta", "\u03c42=280f", "\u03c42=240f", "frammento di dcpd in cpd", "applicare il principio di controllo laser", "aumento e decadimento componente", "reazione fotochimica del dcpd", "norbornen", "costante di decadimento", "sonda laser", "decadimento biesponente compon", "cpd", "frammento ionico genitore", "osservare la dinamica", "\u03c41=36f", "Segnale ionico c5h6+", "controllare la resa del prodotto di c5h6+", "modello di decadimento a due stadi", "ulteriormente ionizzare", "ione genitore"]}
{"file_name": "S187775031300077X", "text": "Sebbene i modelli di campo medio siano stati utilizzati in tutti questi contesti, \u00e8 stata fatta poca analisi sul loro comportamento come sistemi dinamici spazialmente estesi. In parte, ci\u00f2 \u00e8 dovuto alla loro sconcertante complessit\u00e0. Il modello di Liley [15] qui considerato, ad esempio, consiste di quattordici equazioni differenziali parziali (PDE) accoppiate con forti non linearit\u00e0, imposte dall'accoppiamento tra i potenziali di membrana medi e gli input sinaptici medi. Il modello pu\u00f2 essere ridotto a un sistema di equazioni differenziali ordinarie (ODE) considerando solo soluzioni spazialmente omogenee, e il sistema risultante \u00e8 stato esaminato in dettaglio utilizzando l'analisi numerica delle biforcazioni (vedere [16] e i riferimenti ivi contenuti). Per calcolare equilibri, orbite periodiche e oggetti simili per il modello PDE, abbiamo bisogno di un codice di simulazione flessibile e stabile per il modello e la sua linearizzazione che possa essere eseguito in parallelo per scalare fino a una dimensione di dominio di circa 2500 cm2, la dimensione di un pianeta. corteccia umana adulta. Abbiamo anche bisogno di risolutori efficienti e iterativi per problemi lineari con matrici grandi e sparse. In questo articolo mostreremo che tutto ci\u00f2 pu\u00f2 essere realizzato nel pacchetto software open source PETSc [17]. La nostra implementazione consiste in una serie di funzioni in C disponibili pubblicamente [18].", "keyphrases": ["potente di membrana", "ode", "efficiente risolutore iter per problemi lineari con matrici di grandi dimensioni", "efficiente, risolutore di iter", "ordinari differenziali equat", "modello PDE", "Sistema dinamico di estensione spaziale", "differenziale parziale equat", "pde", "input sinaptico", "grandi, longheroni matriciali", "modello giglio", "analisi del numero biforco", "animali domestici", "modello del campo medio"]}
{"file_name": "S0021999113005718", "text": "La simulazione numerica del flusso di gas attraverso tali geometrie interne non banali \u00e8, tuttavia, estremamente impegnativa. Questo perch\u00e9 la fluidodinamica continua convenzionale, che presuppone che localmente un gas sia vicino a uno stato di equilibrio termodinamico, diventa non valida o imprecisa quando la scala caratteristica pi\u00f9 piccola della geometria (l'altezza del canale) si avvicina alla distanza media tra le collisioni molecolari, \u03bb [ 1]. Un'alternativa di modellazione accurata e flessibile per questi casi \u00e8 il metodo Monte Carlo di simulazione diretta (DSMC) [2]. Tuttavia, il DSMC pu\u00f2 essere proibitivo per le applicazioni a flusso interno, che tipicamente hanno una geometria con un rapporto d'aspetto elevato (cio\u00e8 sono estremamente lunghe, rispetto alla loro sezione trasversale). L\u2019elevato rapporto d\u2019aspetto crea un formidabile problema multiscala: i processi devono essere risolti che si verificano sulla scala caratteristica pi\u00f9 piccola della geometria (l\u2019altezza di un canale), cos\u00ec come sulla scala caratteristica pi\u00f9 grande della geometria (la lunghezza di una lunga rete di canali). ), contemporaneamente.", "keyphrases": ["applicazione a flusso interno", "modello accurato e flessibile si alterna", "dsmc", "rapporto d'aspetto elevato", "numero simul", "metodo diretto simul mont carlo", "convento fluidodinamico continuo", "problema multiscalare", "altezza del canale", "flusso ga", "equilibrio termodinamico", "rete di canali lunghi", "collisione molecolare"]}
{"file_name": "S0079642515000705", "text": "Quando dominata da meccanismi di ombreggiamento superficiale, l\u2019aggregazione delle particelle di vapore su una superficie \u00e8 un fenomeno complesso e non locale. In letteratura sono stati numerosi i tentativi di analizzare il meccanismo di crescita attraverso considerazioni puramente geometriche; cio\u00e8, assumendo che le particelle di vapore arrivino alla superficie del film lungo un'unica direzione angolare [38,41]. Sono stati esplorati anche approcci continui, basati sul fatto che le caratteristiche geometriche del film (cio\u00e8 le nanocolonne) sono molto pi\u00f9 grandi della dimensione tipica di un atomo [42,266,267]. Ad esempio, Poxson [228] ha sviluppato un modello analitico che tiene conto di fattori geometrici e di diffusione superficiale. Questo modello prevedeva con precisione la porosit\u00e0 e il tasso di deposizione dei film sottili utilizzando un singolo parametro di input relativo all'area della sezione trasversale delle nanocolonne, al volume del materiale e allo spessore del film. Inoltre, nel rif. [39], \u00e8 stato presentato un modello analitico semi-empirico per descrivere quantitativamente l'aggregazione delle strutture colonnari mediante un singolo parametro denominato angolo del ventaglio. Questa quantit\u00e0 dipendente dal materiale pu\u00f2 essere ottenuta sperimentalmente eseguendo la deposizione con incidenza normale su un substrato seminato con scanalatura impressa e quindi misurando l'aumento del diametro della colonna con lo spessore del film. Questo modello \u00e8 stato testato in varie condizioni [40], che ha restituito buoni risultati e una previsione accurata della relazione tra l'angolo incidente del flusso di deposizione e l'angolo di inclinazione delle colonne per diversi materiali.", "keyphrases": ["particelle di vapore", "approccio continuo", "pellicola sottile", "superficie diffusa", "aggregazione di particelle di vapore su una superficie", "modello semi-impero analitico", "superficie della pellicola", "substrato di semi groov", "considerare la geometria", "caratteristica geometrica", "analizzare il meccanismo di crescita", "fattore geometrico", "meccanismo dell'ombra superficiale", "prevedere la relazione tra l'angolo di incidenza del flusso di deposito e l'angolo di inclinazione della colonna", "singola diretta angolare", "film", "atomo", "la quantit\u00e0 descrive l'aggregato della struttura colonnare", "flusso di depositi", "nanocolonna", "modello analitico"]}
{"file_name": "S037877531001949X", "text": "Il processo di rivestimento della coagulazione indotta dal substrato (SIC) fornisce un rivestimento autoassemblato e quasi privo di leganti con piccole particelle. La maggior parte delle ricerche finora \u00e8 stata utilizzata per rivestire una variet\u00e0 di superfici con nerofumo altamente conduttivo [34,35,36]. Gli strati depositati con questa tecnica sono stati utilizzati nella schermatura delle onde elettromagnetiche, nel processo di metallizzazione dei fori passanti nei circuiti stampati e nella produzione di polimeri conduttori (come il Teflon) [37,38,39]. Un vantaggio di questo processo di dip-coating \u00e8 che pu\u00f2 essere utilizzato per qualsiasi tipo di superficie, a condizione che il substrato sia stabile in acqua e che le particelle utilizzate per il rivestimento formino una dispersione metastabile. Recentemente, \u00e8 stato sviluppato un processo di rivestimento SIC non acquoso del nero di carbonio studiando la stabilit\u00e0 delle dispersioni non acquose [36]. Queste dispersioni sono state utilizzate per preparare elettrodi compositi LiCoO2 per batterie agli ioni di litio con una conduttivit\u00e0 migliorata mantenendo elevato il contenuto di materiale attivo della batteria [35].", "keyphrases": ["scheda metallica di stampa", "schermo d'onda elettromagnetico", "teflon", "s\u00ec", "meta-st si disperde", "condurre polim", "carbone nero", "metallo", "cappotto sicuro", "rivestimento a immersione", "cappotto", "batteria agli ioni di litio", "il substrato induce il coagulo", "elettrodo composito licoo2"]}
{"file_name": "S0009261415000974", "text": "Nell'intervallo di temperature scelto, il dipeptide alanina mostra un comportamento molto semplice. Questo risultato \u00e8 dovuto al numero relativamente piccolo di minimi fisicamente rilevanti (sette sono stati caratterizzati utilizzando questo modello di campo di forza e solvente) e alla maggiore spaziatura di energia potenziale tra il minimo globale e i minimi di energia pi\u00f9 elevati. In effetti, gli incroci nel minimo globale approssimato dell\u2019energia libera per questo sistema (dove l\u2019energia libera del secondo minimo energetico potenziale pi\u00f9 basso diventa inferiore a quello del minimo energetico potenziale globale) nell\u2019approssimazione armonica si verificherebbero a 1170K. In generale, la previsione armonica per la temperatura di crossover tra due minimi \u00e8(4)kBTxo=V1\u2212V2ln((o2\u03bd\u00af2\u03ba)/(o1\u03bd\u00af1\u03ba)), dall'Eq. (3), che illustra chiaramente l'equilibrio tra energia potenziale ed entropia del pozzo.", "keyphrases": ["spazio potenzioenergetico pi\u00f9 ampio", "Campo di forze e modello del solvente", "intervallo di temperatura scelto", "equilibrio tra potenti energetici e ben entropi", "minimi di rilevanza fisica", "cross-ov nell'energia libera globale approssimativa", "dipeptide di alanina"]}
{"file_name": "S003238610801080X", "text": "Finora gli studi morfologici dei materiali polimerici multicomponente sono stati condotti mediante vari metodi microscopici e di diffusione. I microscopi ottici, i microscopi elettronici a trasmissione (TEM), i microscopi elettronici a scansione (SEM) e i microscopi a forza atomica (AFM) sono disponibili in commercio e ampiamente utilizzati. Il pi\u00f9 grande vantaggio della microscopia \u00e8 che forniscono rappresentazioni intuitive dello spazio reale delle varie morfologie. Tuttavia, quando si tratta di \u201cmisurazioni\u201d, soprattutto in termini quantitativi, la microscopia a volte manca di precisione statistica a causa del campo visivo ristretto. Al contrario, i metodi di diffusione forniscono una precisione statistica molto superiore a quella della microscopia semplicemente perch\u00e9 il volume di osservazione \u00e8 maggiore di quello dei microscopi. Bisogna ricordare, tuttavia, che i metodi di diffusione normalmente richiedono \u201cmodelli (ipotizzati)\u201d per l\u2019analisi dei dati in anticipo: essi non forniscono una visione intuitiva delle morfologie come fa la microscopia. Dopotutto, per la completa caratterizzazione di una specifica morfologia, potrebbe essere necessario conoscere prima le morfologie al microscopio e successivamente valutare i parametri strutturali mediante scattering sulla base della morfologia; i due metodi sono complementari.", "keyphrases": ["\u201cModelli (ipotizzati)\u201d", "microscopi", "sem", "microscopio", "tem", "studi morfologici", "materiale polimerico multicomponente", "afm", "microscopio elettronico a trasmissione", "microscopio a forza atomica", "microscopio elettronico a scansione", "metodo microscopico e di dispersione", "analisi dei dati", "microscopio ottico", "metodo di dispersione"]}
{"file_name": "S2212667814000331", "text": "Per risolvere il problema che il sistema di alimentazione PT del motore diesel non \u00e8 in grado di mantenere sul campo, abbiamo sviluppato un sistema portatile di acquisizione e analisi del segnale per il sistema di alimentazione PT del motore diesel. In primo luogo, \u00e8 stato analizzato il principio di funzionamento della pompa PT ed \u00e8 stata analizzata la relazione di mappatura dei guasti della pompa PT tra motivo e fenomeno di guasto; In secondo luogo, sono state analizzate le caratteristiche della pressione del carburante in caso di guasto della pompa PT del motore diesel; Infine, utilizzando il sistema portatile di acquisizione e analisi del segnale per diagnosticare il sistema di alimentazione PT del motore diesel, i risultati dell'esperimento mostrano che il sistema \u00e8 in grado di rilevare correttamente lo stato del sistema di alimentazione PT del motore diesel.", "keyphrases": ["pt principio di lavoro della pompa wa analyz", "rilevare lo stato del sistema di alimentazione del motore diesel", "sistema di analisi", "pompa motore diesel pt", "carburante per motore diesel", "pompa pt", "sono state analizzate le caratteristiche della pressione del carburante in caso di guasto", "diagnostica il sistema di alimentazione del motore diesel", "analisi", "problema che il sistema di alimentazione del motore diesel non \u00e8 in grado di mantenere sul campo", "acquisizione del segnale", "sistema di alimentazione del motore diesel pt", "sistema portatile di acquisizione e analisi del segnale"]}
{"file_name": "S0370269304006070", "text": "Lo scopo di questa Lettera \u00e8 rispondere alla domanda di cui sopra e confrontare quelle strutture a sei zeri delle matrici di massa leptonica con gli ultimi dati sperimentali. Innanzitutto, presenteremo un'analisi concisa delle matrici di massa leptoniche nella Tabella 1 e riveleremo le loro caratteristiche isomeriche, vale a dire che hanno le stesse conseguenze fenomenologiche, sebbene le loro strutture siano apparentemente diverse. In secondo luogo, esamineremo le previsioni di queste matrici di massa leptoniche confrontandole con gli intervalli 2\u03c3 e 3\u03c3 di due differenze al quadrato di massa dei neutrini e tre angoli di miscelazione del sapore leptonico,22 Per essere precisi, facciamo uso degli intervalli 2\u03c3 e 3\u03c3 di due differenze al quadrato di massa dei neutrini e tre angoli di miscelazione dei sapori leptonici forniti da M. Maltoni nel Rif. [5] che sono ottenuti da un'analisi globale dei pi\u00f9 recenti dati sui neutrini solari, atmosferici, del reattore (KamLAND e CHOOZ [10]) e dell'acceleratore (K2K). Non troviamo spazio parametrico consentito per sei matrici di massa leptonica isomerica al livello 2\u03c3. Al livello 3\u03c3, tuttavia, i loro risultati per le masse dei neutrini e gli angoli di miscelazione dei sapori dei leptoni possono essere compatibili con i dati attuali. In terzo luogo, incorporiamo il meccanismo dell\u2019altalena e l\u2019ipotesi Fukugita-Tanimoto-Yanagida [9] nelle matrici di massa dei leptoni carichi e dei neutrini di Dirac con sei zeri di trama. Risulta che le loro previsioni, incluso \u03b823\u224845\u00b0, sono in buon accordo con i dati sperimentali attuali anche al livello 2\u03c3.", "keyphrases": ["esaminare la previsione di questa matrice di massa leptonica", "dati dell'esperimento", "affrontare quelle texture a sei zeri della matrice di massa leptonica", "mix di sapori leptonici angl", "matrice della massa leptonica dell'isomero", "rivelare la loro caratteristica isomerica", "matrice di massa leptonica", "caricare il leptone", "neutrino", "dati attuali", "differenza tra massa e quadrato del neutrino", "ipotesi fukugita-tanimoto-yanagida", "Matrice di massa del neutrino dirac", "analisi globale", "meccanico dell'altalena", "dati sui neutrini solari, atmosferici, del reattore (kamland e chooz [10]) e dell'acceler (k2k)"]}
{"file_name": "S2212671612002181", "text": "Il numero di nodi nascosti \u00e8 un fattore critico per la generalizzazione dell'ELM. In generale, \u00e8 molto dispendioso in termini di tempo ottenere il numero ottimale di nodi nascosti con tentativi ed errori. Viene proposto un nuovo algoritmo per ottimizzare il numero di nodi nascosti per garantire una buona generalizzazione, che impiega il PSO nel processo di ottimizzazione con il principio di minimizzazione del rischio strutturale. I risultati della simulazione indicano che il nostro algoritmo per il numero ottimale di nodi nascosti \u00e8 ragionevole e fattibile con 6 set di dati su problemi di benchmark mediante confronti di accuratezza.", "keyphrases": ["olmo", "gener", "ottenere il numero ottimale di nodi nascosti", "ottimizzare il numero del nodo nascosto", "nodo nascosto", "pso", "nuovo algoritmo", "viene proposto un nuovo algoritmo", "algoritmo", "rischio strutturale principio minimo", "gener dell'olmo", "prova ed errore", "6 set di dati", "consumo di tempo", "processo ottimale", "confronto accurato"]}
{"file_name": "S0736585316300661", "text": "Per calcolare gli indici di prezzo edonistici nel modello lineare, \u00e8 necessario calcolare il prezzo iniziale o di riferimento (Triplett, 2006). Il presente studio adotta l\u2019approccio di de Haan e Diewert (2013): un indice dei prezzi \u00e8 costruito utilizzando il prezzo generato dai coefficienti stimati di un modello di regressione del periodo base ed \u00e8 calcolato sulla base dei valori medi del periodo base di una data cella caratteristiche del piano telefonico z\u00af per ciascun operatore (Tabella Supplementare S5). Per le caratteristiche continue si utilizzano le medie dirette; per le caratteristiche binarie vengono utilizzate le proporzioni dei piani telefonici contenenti la funzione. I prezzi risultanti per questo piano telefonico medio vengono convertiti in un indice applicando le variazioni di prezzo pure calcolate in precedenza (\u03b4s). Infine, l\u2019indice dei prezzi edonistici complessivo \u00e8 calcolato come media ponderata degli indici a livello di impresa. I pesi corrispondono alla proporzione relativa dei piani tariffari di telefonia mobile per operatore nel campione (0,3534 per HT, 0,3212 per Vip e 0,3254 per Tele2).", "keyphrases": ["modello di regressione del periodo base", "applica il calcolo precedente, pura variazione del prezzo", "modello lineare", "calcolo hedon prezzo indic"]}
{"file_name": "S221266781400080X", "text": "In questo articolo sono stati utilizzati diversi agenti flocculanti inorganici, tra cui FeSO4, Al2(SO4)3, FeCl3 e un coagulante organico PAM, per trattare le acque reflue provenienti dall'allevamento di animali domestici e pollame. Le condizioni operative ideali sono state raggiunte mediante l'esperimento a fattore singolo e l'esperimento di progettazione ortogonale. E le condizioni operative ideali sono le seguenti: la dose di FeSO4 e PAM \u00e8 rispettivamente 135,2 mg/L e 0,384 mg/L mantenendo il pH 10; e il tasso di rimozione corrispondente \u00e8 del 55% e del 60% per COD e torbidit\u00e0. Sulla base dei risultati sperimentali, questo articolo analizza i principali fattori che influenzano il trattamento di flocculazione delle acque reflue.", "keyphrases": ["aiuto alla coagulazione degli organi", "trattare le acque reflue", "al2(so4)3,", "feso4", "analizzare il fattore principale", "agente flocculante inorganico", "tasso di rimozione", "flocculo delle acque reflue", "fecl3", "merluzzo", "Esperimenti di progettazione ortogonali", "pam", "esperienza a fattore singolo", "trattamento del flocculo delle acque reflue"]}
{"file_name": "S1566253516300252", "text": "I metodi per il rilevamento delle anomalie in un context locale sono concettualmente opposti ai metodi centralizzati sopra descritti, che si basano su modelli condivisi a livello globale. Nel data mining, la nozione di localit\u00e0 viene spesso fornita come distanza tra i valori dei dati (data una metrica di distanza specifica come la distanza euclidea). Un punto dati viene confrontato con il valore dei suoi vicini pi\u00f9 vicini in termini di distanza dati [42]. Tuttavia, la nozione di localit\u00e0 pu\u00f2 essere data anche in base alla distanza geografica tra le fonti dei dati. Molti valori simili (cio\u00e8 dati con piccola distanza tra loro) danno luogo a una densit\u00e0 pi\u00f9 elevata, chiamata cluster, mentre valori meno simili danno luogo a una densit\u00e0 inferiore. Le anomalie possono non rientrare in alcun cluster ma, quando si verificano frequentemente, possono anche formare un cluster. Determinare se un dato \u00e8 normale o anomalo rispetto ai dati del quartiere locale \u00e8 una sfida.", "keyphrases": ["miniera di dati", "determinare se un dato \u00e8 normale o anomalo", "una metrica di distanza specifica come la distanza euclidea", "possono formare un cluster", "modello azionario globale", "la nozione di locale", "mani valore simile", "rilevamento anomalie", "distanza tra il valore dei dati", "valori meno simili determinano una densit\u00e0 inferiore", "una distanza geografica", "grappolo", "metodo centrale sopra descritto", "nozione di locale", "anomali", "rispetto al valore del vicino pi\u00f9 vicino"]}
{"file_name": "S0009261413011111", "text": "Le propriet\u00e0 ottiche delle eccitazioni cariche sono importanti per comprendere la fotofisica dei semiconduttori organici. L'iniezione di carica elettrica nei materiali organici polarizza l'ambiente circostante e modifica le lunghezze dei legami attorno ad esso, tale eccitazione \u00e8 definita polarone carico. L'assorbimento della luce e l'estinzione della fluorescenza da parte dei polaroni sono questioni importanti nel funzionamento dei dispositivi optoelettronici organici. \u00c8 particolarmente rilevante per lo sviluppo di laser pompati elettricamente. Con i recenti progressi nelle propriet\u00e0 dei materiali e nella progettazione ottica, la soglia laser delle strutture organiche sottoposte a pompaggio ottico \u00e8 ora sufficientemente bassa da consentire il pompaggio mediante diodi laser inorganici [1\u20133] e LED [4], il che \u00e8 promettente per la fabbricazione di materiali molto sensibili a basso costo dispositivi per biosensing e chemosensing [5,6]. Tuttavia, \u00e8 stato segnalato che l\u2019assorbimento della luce da parte delle cariche iniettate costituisce il principale ostacolo all\u2019uso del laser pompato elettricamente [7]. Le cariche iniettate possono anche estinguere la luminescenza poich\u00e9 accettano energia dagli eccitoni mediante interazioni dipolo-dipolo risonanti e questo \u00e8 un importante meccanismo di perdita nei LED organici cos\u00ec come nei laser. Le sezioni trasversali di assorbimento dei polaroni non sono note con la precisione desiderata a causa della difficolt\u00e0 di quantificare la densit\u00e0 di carica iniettata nella pellicola. Precedenti studi hanno utilizzato l\u2019iniezione elettrica controllata di cariche in dispositivi unipolari attraverso elettrodi di contatto e misurazioni della mobilit\u00e0 di carica dipendente dal campo per stimare le densit\u00e0 di carica che sono state confrontate con i valori ottenuti dall\u2019analisi capacit\u00e0-tensione e i due risultati differivano di un fattore tre [8 ,9].", "keyphrases": ["soglia laser della struttura dell'organo sotto pompa ottica", "assorbe la luce", "fotofisica dei semiconduttori d'organo", "sviluppo del laser a pompa elettrica", "materiale d'organo", "biosens", "analisi capacit\u00e0-tensione", "laser", "condotto dall'organo", "opera d'organo optoelettrone devic", "elettrodo di contatto", "pompa elettrica lase", "accettare energia dall'eccitone", "controllo elettr. iniezione di carica", "struttura dell'organo", "carica elettrica", "densit\u00e0 di carica", "chemosens", "pompa ottica", "laser a pompa elettrica", "caricare il polarone", "dispositivo veri sensit a basso costo", "diodo laser inorgano", "dispositivo unipolare", "la risonanza dipolo-dipolo interagisce", "misura mobile carica dipendente dal campo"]}
{"file_name": "S2212667812000032", "text": "La programmazione orientata agli aspetti (AOP) pu\u00f2 risolvere bene le preoccupazioni trasversali. A causa delle diverse caratteristiche dell'aspetto, l'AOP richiede nuove tecniche di test. Innanzitutto, questo articolo propone un modello per testare il software orientato agli aspetti. Per supportare il modello di test dei primi tre passaggi, proponiamo l'algoritmo di selezione dei casi di test rilevanti per gli aspetti. Quindi, sviluppiamo un nuovo strumento per implementare la teoria dell'automazione di casi di test selezionati. Infine, viene studiato un caso di sistema di conti bancari per illustrare il nostro approccio di testing.", "keyphrases": ["programma aspetto-ori", "sviluppare un nuovo strumento per implementare il teorema del caso di test con selezione automatica", "seleziona automaticamente il caso di test", "modello per testare il software aspetto-ori", "op", "modello di prova", "risolvere il problema trasversale", "algoritmo del caso di test relativo all'aspetto selezionato", "sistema di conti bancari"]}
{"file_name": "S0079642514000887", "text": "La manipolazione raffinata e la misurazione esatta delle propriet\u00e0 dei singoli nanomateriali, rispetto ai notevoli progressi nella loro preparazione, non sono state affrontate in modo approfondito, sebbene siano di primaria importanza per lo sviluppo sostenuto di nuovi dispositivi [58-61]. Ad oggi, diversi strumenti sono stati progettati per tali obiettivi, vale a dire microscopi elettronici a scansione (SEM), microscopi a forza atomica (AFM) e microscopi elettronici a trasmissione (TEM) [62,63]. Rispetto alle prime due configurazioni, che non hanno accesso diretto alla struttura interna del materiale e alle informazioni sul legame atomico [64-67], la tecnica TEM all'avanguardia in situ ad alta risoluzione consente non solo di manipolare con un singolo oggetto con precisione su scala nanometrica, ma anche per ottenere informazioni approfondite sui suoi stati fisici, chimici e microstrutturali [68-71]. La combinazione delle capacit\u00e0 di un TEM convenzionale ad alta risoluzione e di sonde AFM o STM produce supporti TEM avanzati e dedicati, che stanno diventando potenti strumenti nella manipolazione dei nanomateriali e nell'analisi delle propriet\u00e0. Tali supporti sono stati commercializzati, ad esempio, da \"Nanofactory Instruments AB\", Goteborg, Svezia [72]. La piena utilit\u00e0 di queste tecniche TEM avanzate in situ \u00e8 \u200b\u200bevidente per quanto riguarda l'analisi delle propriet\u00e0 meccaniche e termiche delle singole nanostrutture, i dati di elasticit\u00e0, plasticit\u00e0 e resistenza utilizzando prove dirette di piegatura o trazione [73-75], sondando le caratteristiche elettriche, emissione di campo [27,76,77], tracciamento del trasporto elettrico [78\u201380], saldatura [81,82] e drogaggio [83], ecc.", "keyphrases": ["tem", "microscopio elettronico a trasmissione", "nanostruttura", "microscopio elettronico a scansione", "misura esatta delle propriet\u00e0", "titolare", "microscopio a forza atomica", "prova diretta di piegatura o trazione", "manipolazione dei nanomateriali", "il legame atomico informa", "sostenere lo sviluppo di nuovi dispositivi", "titolare del tem", "analisi delle propriet\u00e0", "analisi delle propriet\u00e0 meccaniche e termiche", "saldare", "nanomateriali", "tecnica del tem", "manipolare con un oggetto individuale", "strumento", "caratteristiche elettriche della sonda", "sem", "traccia del trasporto elettrico", "afm", "struttura interna materi", "emissione di campo", "droga", "sonda stm"]}
{"file_name": "S0167931713004061", "text": "Abbiamo dimostrato un nuovo approccio alla produzione di impalcature di idrogel auto-pieghevoli mediante l'uso di metodi facilmente disponibili e veloci. Il processo mostra un efficace trasferimento del modello goffrando prima uno strato sacrificale e utilizzandolo come stampo solubile nel processo di fabbricazione. L'uso di uno strato sacrificale di PAA conferisce sensibilit\u00e0 ambientale alla pellicola di idrogel su una sola superficie. Il successivo rigonfiamento della rete interpenetrante PAA (IPN) a pH elevato provoca un differenziale di rigonfiamento attraverso la pellicola, facendola rotolare per adattarsi alla differenza di area superficiale tra le due superfici. Le fasi di funzionalizzazione e modellazione della superficie sono quindi combinate in un'unica operazione fotolitografica. Il risultato netto \u00e8 un metodo per produrre impalcature di idrogel auto-piegabili innescate dall'ambiente mediante un nuovo uso, a conoscenza degli autori, della goffratura dello strato sacrificale. I film di idrogel modellati possono essere innescati consecutivamente consentendo il successivo arrotolamento e srotolamento a seconda del pH dell'acqua. La scelta dell'idrogel PEGDMA fornisce una piattaforma versatile per la creazione di una variet\u00e0 di impalcature di idrogel e, pur essendo non incrostante e non tossico, \u00e8 permeabile alle proteine. Inoltre PEGDMA pu\u00f2 essere modificato per produrre idrogel adesivi biodegradabili e cellulari per una variet\u00e0 di applicazioni biomediche.", "keyphrases": ["trigger consecutivo", "impalcatura in idrogel ripiegabile", "Readili avvalersi e metodo di throughput veloce", "srotolare", "applicazione biomedica", "superficie", "produttore di impalcature in idrogel ripiegabili", "muffa solubile", "ip", "trasferimento del modello di effetto", "fotolitografia opera", "accogliere la differenza di superficie tra le due superfici", "rotolo", "pellicola di idrogel", "imprimere uno strato sacrificale", "pellicola di idrogel con motivo", "l'ambiente di produzione innesca l'auto-piegatura di tutta l'impalcatura di idrogel", "impalcatura di idrogel", "usarlo come stampo solubile nel processo del tessuto", "rigonfiamento della rete interpenetra paa", "idrogel", "pegdma idrogel", "gonfiarsi differente", "proteina", "piattaforma versatile per creare una variet\u00e0 di impalcature idrogel", "produrre idrogel biodegradabile e adesivo cellulare", "film", "nuovo uso del rilievo dello strato sacrificale", "paa rete interpenetra", "sacrificare lo strato di paa", "acquoso ph", "processo del tessuto", "pegdma", "ph"]}
{"file_name": "S0011227514002136", "text": "La misurazione e l'analisi del tempo di permanenza della pillola CPA consente di valutare la resistenza del limite termico all'interno della pillola; il confine termico determina la temperatura effettiva dei cristalli CPA rispetto alla temperatura del dito freddo, che viene mantenuta a temperatura costante da un programma di servocontrollo. La Figura 17 mostra il profilo della temperatura durante il riciclaggio della pillola CPA e il successivo funzionamento a 200 mK. Durante il tempo di attesa, il programma di servocontrollo ha mantenuto la temperatura della pillola CPA entro un millikelvin. Si prevede che la stabilit\u00e0 al microkelvin possa essere ottenuta con una termometria a lettura rapida (che non era disponibile al momento del test ma che sar\u00e0 utilizzata per mKCC), poich\u00e9 ci\u00f2 consentirebbe il controllo della temperatura su scale temporali molto pi\u00f9 rapide (millisecondi) rispetto a la lettura termometrica corrente (circa 1 s) utilizzata.", "keyphrases": ["cristallo cpa", "programma di servocontrollo", "misurare e analizzare il tempo di attesa della pillola cpa", "riciclare", "temperatura", "operativo a 200mk", "confini termici", "stabile al microkelvin", "mkcc", "dito freddo", "pillola", "resistenza ai confini termici", "termometri a lettura rapida", "pillola cpa"]}
{"file_name": "S000926141301539X", "text": "In questa Lettera rivisitiamo il modello Hamiltoniano di Chesnavich [37] alla luce dei recenti sviluppi in TST. Per i sistemi senza barriere come le reazioni ione-molecola, i concetti di OTS e TTS possono essere chiaramente formulati in termini di oggetti geometrici dello spazio delle fasi ben definiti. (Per il lavoro sulla descrizione dello spazio delle fasi di OTS, vedere Rif. Il primo obiettivo del presente articolo \u00e8 l'identificazione di queste nozioni con superfici di divisione dello spazio delle fasi ben definite collegate agli NHIM. Il secondo e principale obiettivo \u00e8 una delucidazione del fenomeno del roaming nel context del modello Hamiltoniano di Chesnavich. La funzione potenziale associata, che possiede molte caratteristiche associate a un PES molecolare realistico, porta a dinamiche che rivelano chiaramente le origini dell'effetto roaming. Sulla base delle nostre simulazioni di traiettoria, mostriamo come l'identificazione del I DS TTS e OTS con superfici periodiche di divisione dell'orbita (PODS) forniscono il quadro naturale per l'analisi del meccanismo di roaming.", "keyphrases": ["baccello", "periodo orbita dividere la superficie", "tst", "tt", "ben definito lo spazio delle fasi, la superficie divisa si attacca a nhim", "dynam che rivelano chiaramente l'origine dell'effetto roaming", "nhim", "traiettorie simul", "reazione ione-molecola", "funzione associati potenti", "chesnavich modello hamiltoniano", "identificativo", "ot", "oggetto di geometria spaziale"]}
{"file_name": "S0377221716301904", "text": "Proponiamo un modello di equilibrio che consente di analizzare l\u2019impatto di lungo periodo del disegno del mercato elettrico sull\u2019espansione delle linee di trasmissione da parte del regolatore e sugli investimenti nella capacit\u00e0 di generazione da parte delle imprese private nei mercati elettrici liberalizzati. Il modello incorpora le decisioni di investimento del gestore del sistema di trasmissione e delle imprese private in previsione di un mercato esclusivamente energetico e di un ridispacciamento basato sui costi. In diverse specifiche consideriamo i casi di una o pi\u00f9 zone di prezzo (suddivisione del mercato) e analizziamo diversi approcci per recuperare i costi di rete, in particolare tariffe forfettarie, basate sulla capacit\u00e0 di generazione e basate sull'energia. Per confrontare i risultati del nostro modello di mercato multilivello con un primo miglior benchmark, risolviamo anche il corrispondente problema del pianificatore integrato. Utilizzando due reti di prova mostriamo che i mercati esclusivamente energetici possono portare a decisioni di localizzazione non ottimali per la capacit\u00e0 di generazione e quindi implicare un\u2019eccessiva espansione della rete. La suddivisione del mercato risolve questi problemi solo parzialmente. Questi risultati sono validi per tutti i tipi di tariffe di rete considerati, sebbene gli investimenti differiscano leggermente tra questi regimi.", "keyphrases": ["problema del pianificatore integrale", "risolvere il problema del pianificatore intero corrispondente", "gene capac base", "espansione della rete in eccesso", "primo miglior punto di riferimento", "modello di equilibrio", "divisione del mercato", "modello di mercato multilivello", "analizzare l'impatto a lungo termine del disegno del mercato elettrico sull'espansione delle linee di trasmissione", "analizzare un approccio diverso per recuperare i costi di rete", "forfettario", "recupero costo di rete", "tariffa base energi"]}
{"file_name": "S0021999115000546", "text": "Il particolare modello di campo di fase che utilizziamo \u00e8 un'estensione di [6] e si basa sul modello di campo di fase termica tridimensionale di [7] e sul modello di campo di fase termica-solutale bidimensionale di [8]. Una caratteristica del problema fisico \u00e8 che \u00e8 puramente dissipativo, ovvero aumenta l\u2019entropia, come lo sono tutti i fenomeni naturali di rilassamento. Le PDE risultanti sono di tipo Allen-Cahn [9] e Carn-Hilliard [10]. Vale a dire, il modello coinvolge le derivate temporali dei tre campi accoppiate a forme che coinvolgono le derivate variazionali di alcuni funzionali \u2013 tipicamente il funzionale dell\u2019energia libera. Man mano che il dendrite cresce, l'energia libera si riduce monotonicamente nel tempo ma non raggiunge mai l'equilibrio se il confine del dominio \u00e8 lontano dal dendrite. Sebbene abbiamo elencato alcuni degli aspetti difficili di questo modello, l'aspetto rilassante \u00e8 tipicamente un vantaggio e si traduce in schemi numerici stabili: non c'\u00e8 convezione, ad esempio (almeno in assenza di flusso nella massa fusa).", "keyphrases": ["funzione energia libera", "funzione", "dendrite", "derivazione temporale della coppia di tre campi per formare la derivazione variabile coinvolv", "schema numerico", "pde", "modello di campo bidimensionale della fase di soluzione termica", "modello del campo di fase", "sciolto", "modello di campo della fase termica tridimensionale"]}
{"file_name": "S0377025714001682", "text": "Affinch\u00e9 la microreologia basata su DLS abbia successo, deve esserci un contrasto di dispersione sufficiente tra il campione e le particelle traccianti. Per raggiungere questo obiettivo, \u00e8 stata aggiunta la massima concentrazione possibile di particelle traccianti in modo tale che i singoli eventi di scattering continuassero a dominare (come determinato dalle misurazioni dei coefficienti di diffusione nell'acqua a diverse concentrazioni). Per determinare se la diffusione di fondo del campione fosse sufficientemente bassa rispetto a quella delle particelle traccianti, abbiamo anche confrontato le intensit\u00e0 di diffusione ottenute da campioni con e senza particelle traccianti in funzione del tempo. I risultati di questo esercizio sono mostrati nella Figura 6. Da questa figura si pu\u00f2 vedere che sebbene inizialmente la dispersione dal campione senza particelle traccianti sia bassa rispetto a quelli contenenti particelle traccianti, con il procedere della gelificazione ci\u00f2 alla fine cessa di essere il caso. Ci\u00f2 \u00e8 presumibilmente dovuto allo sviluppo di strutture supramolecolari, come quelle viste in precedenza (Figura 2B). Sulla base dei risultati nella Figura 6 si \u00e8 deciso di utilizzare solo i dati raccolti nei primi 240 minuti dell'esperimento, dopodich\u00e9 la dispersione dalla rete di gel \u00e8 diventata troppo grande per essere ignorata.", "keyphrases": ["dispersione dalla rete di gel", "particella tracciante", "dl base micro-reologo", "campione e la particella tracciante", "gelat", "spargere", "intensit\u00e0 di dispersione", "acqua", "struttura sopramolecolare"]}
{"file_name": "S2352179115300041", "text": "Lo svantaggio principale della termoossidazione nella maggior parte dei dispositivi attuali e in ITER \u00e8 la sua limitazione ai periodi di manutenzione, quando le pareti del recipiente possono essere riscaldate a circa 300\u2013400 \u00b0C mediante iniezione di elio caldo attraverso il sistema di raffreddamento [19,20], e anche a causa del necessario ricondizionamento delle pareti prima dell'operazione al plasma per rimuovere l'ossigeno assorbito [10]. Tuttavia la temperatura raggiunta non \u00e8 omogenea nel recipiente, poich\u00e9 \u00e8 limitata dalla distanza dai tubi di raffreddamento e quindi dalla struttura dell'apparecchio. L'analisi di questo studio \u00e8 una continuazione di lavori precedenti condotti per il trattamento dei codepositi di carbonio di ITER [1\u20133], quindi le temperature studiate sono comprese tra 350 \u00b0C per il divertore e 200\u2013275 \u00b0C per la parete principale e parti remote. Al momento, a causa delle restrizioni di bilancio e del trizio intrappolato negli strati di carbonio co-depositati, ITER non utilizzer\u00e0 materiali di carbonio nei punti di impatto del divertore nonostante la loro eccellente resilienza contro grandi carichi termici. Tuttavia, molti dei dispositivi sperimentali attuali per la fusione nucleare (DIII-D, TCV, ecc.) e quelli nuovi (JT-60SA, KSTAR, Wenderstein-7X) utilizzano elementi di carbonio, quindi la rimozione dei co-depositi di carbonio \u00e8 ancora necessaria per una migliore funzionamento del dispositivo: controllo della densit\u00e0 del plasma, eventi di polvere, ecc. Le temperature utilizzate in questo lavoro non sono molto diverse da quelle ottenibili nei dispositivi attuali, in modo tale che i risultati possano essere estrapolati ad esse. Inoltre, anche per ITER questo studio potrebbe essere utile nel caso in cui si debbano eventualmente installare materiali in carbonio nel caso in cui il funzionamento con piastrelle di tungsteno nei punti di impatto sia precluso da motivi imprevisti.", "keyphrases": ["tubo freddo", "controllo della densit\u00e0 plasmatica", "iter", "kstar", "jt-60sa", "sistema fantastico", "diii-d", "elemento di carbonio", "deviatore", "trizio", "nave", "elio", "materiale di carbonio", "wenderstein-7x", "carbonio", "polvere", "ricondire", "dispositivo per la fusione nucleare", "strato di carbonio", "rimozione del co-deposito di carbonio", "opera al plasma", "tcv", "piastrella in tungsteno", "termo-ossido", "parte remota", "iter di carbonio", "muro principale", "trattamento del co-deposito di carbonio iter", "ossigeno"]}
{"file_name": "S0301010413002139", "text": "Gli spettri vibrazionali della l-cisteina sono stati registrati e assegnati sia in soluzione [8,9] che allo stato solido [10\u201314]. Le assegnazioni spettrali sono state effettuate utilizzando campi di forza empirici [15], calcoli Hartree-Fock [10,16,17] basati sull'approssimazione della molecola isolata. Per i sistemi che presentano forti interazioni intermolecolari, questa approssimazione spesso porta a uno scarso accordo tra esperimento e teoria. Un esempio lampante \u00e8 quello delle purine [18], dove uno studio degli spettri vibrazionali allo stato solido mediante molecole isolate e calcoli periodici, ha dato un accordo quasi quantitativo tra teoria ed esperimento per quest'ultimo, mentre il primo ha dato solo un modesto accordo e non \u00e8 stato in grado di distinguere tra i tautomeri. Nel caso presente, dove la struttura \u00e8 costituita da ioni legati da legami idrogeno, sono essenziali calcoli periodici basati sulla cella primitiva completa [19]. L'unico lavoro [20] che include alcuni effetti allo stato solido utilizza la dinamica molecolare ma dal quale \u00e8 difficile estrarre assegnazioni. Lo scopo di questo articolo \u00e8 fornire un'assegnazione completa degli spettri vibrazionali della l-cisteina sia nella forma ortorombica che monoclina mediante l'uso di una combinazione di metodi computazionali e sperimentali.", "keyphrases": ["dinamica molecolare", "molecola di isolo ca", "cella primitiva completa", "ione", "calcolo di hartree-fock", "Metodo di calcolo e sperimentazione", "l-cisteina", "idrogeno", "tautom", "fornire un'assegnazione completa degli spettri vibrazionali della l-cisteina", "assegnazione spettrale", "purin", "Molecola di iso e calcolo del periodo", "studi degli spettri vibrazionali allo stato solido", "calcolo del periodo", "campo di forza imperiale"]}
{"file_name": "S0010938X13003818", "text": "In base all'analisi teorica, il valore del resistore di misura, Rm, non ha alcun effetto sul processo di corrosione e sul valore stimato della resistenza al rumore. Per convalidare questa conclusione, \u00e8 stato eseguito l'esperimento di Figura 9. Nello specifico, una coppia di campioni nominalmente identici \u00e8 stata inizialmente accoppiata da un resistore da 4,7 k\u03a9 e il loro potenziale rispetto a un elettrodo a calomelano saturo \u00e8 stato registrato utilizzando un convertitore analogico-digitale NI-USB 6009. Il segnale di rumore elettrochimico \u00e8 stato registrato utilizzando un software sviluppato internamente, acquisendo segmenti a 1023Hz di 1000 punti ad ogni iterazione. Tra le iterazioni, \u00e8 stata calcolata la media dei 1000 valori acquisiti per ottenere un unico valore di potenziale, successivamente salvato nel file utilizzato per le successive elaborazioni. Il set di dati finale comprendeva valori potenziali distanziati di 1\u00b10,05 s nel tempo. Partendo dal presupposto che il rumore presente sopra 1023Hz \u00e8 trascurabile rispetto al rumore presente sotto 0,5Hz, questa procedura consente una registrazione accurata del rumore potenziale nelle frequenze di interesse, evitando l'aliasing delle frequenze comprese tra 0,5 e 1023Hz e minimizzando l'interferenza a 50Hz da l'alimentazione di rete.", "keyphrases": ["accurare la registrazione dei potenti nois nella frequenza di interesse", "sviluppo interno del software", "set di dati", "segnale di rumore elettrochimico", "Resistenza da 4,7 k\u03c9", "processo di corrosione", "valore del resistore di misura", "valore della resistenza al rumore", "coppia di esemplari identificativi nominali", "analisi teorica", "conversione da analogico a digitale ni-usb 6009", "ottenere un unico valore di potenti", "valida questa conclusione", "rm", "elettrodo al calomelano saturo"]}
{"file_name": "S0370269304008305", "text": "Le correlazioni charm-quark-charm-antiquark nello scattering \u03b3p sono calcolate con l'approccio della fattorizzazione kt. Applichiamo diverse distribuzioni di gluoni non integrati (uGDF) utilizzate in letteratura. I risultati dei nostri calcoli vengono confrontati con risultati sperimentali molto recenti della Collaborazione FOCUS. Il CCFM uGDF sviluppato recentemente da Kwieci\u0144ski fornisce una buona descrizione dei dati. Nuovi osservabili sono suggeriti per studi futuri. Vengono presentate previsioni e prospettive per le energie HERA.", "keyphrases": ["lei \u00e8 energica", "antiquark", "quark", "distribuzione integra dei gluoni", "ccfm ugdf", "fascino", "dispersione \u03b3p", "approccio del fattore kt", "ugdf", "correlato di charm-quark-charm-antiquark nello scatter \u03b3p"]}
{"file_name": "S0963869514000954", "text": "Gli algoritmi di ottimizzazione globale vengono utilizzati in questo studio per risolvere il problema di ottimizzazione poich\u00e9 sono noti per essere efficienti nell'incorporare informazioni statistiche e nel gestire complicate funzioni obiettivo che hanno pi\u00f9 minimi/massimi locali. L'algoritmo genetico (GA) \u00e8 una tecnica di ottimizzazione globale che imita i processi di evoluzione biologica e viene utilizzata in questo particolare studio. L'algoritmo inizia con una selezione casuale di una popolazione dal dominio delle variabili decisionali (X). L'algoritmo genetico modifica ripetutamente questa popolazione. Ad ogni passaggio, l'algoritmo seleziona un gruppo di valori individuali dalla popolazione (genitore) che si evolvono attraverso crossover o mutazione per produrre membri della generazione successiva. Questo processo viene ripetuto per diverse generazioni finch\u00e9 non viene raggiunta una soluzione ottimale. Vedere [19] per una descrizione pi\u00f9 completa del GA.", "keyphrases": ["ga", "popul", "minimi/massimi locali", "crossov", "decis dominio variabile", "X", "genitore", "algoritmo genet", "tecnica di ottimizzazione globale", "imitare il processo di evoluzione biologica", "mutat", "selezione casuale di una popolazione", "risolvere il problema dell'ottimo", "algoritmo di ottimizzazione globale", "incorporare lo statista informare", "funzione dell'oggetto", "seleziona un gruppo di valori individuali"]}
{"file_name": "S0254058415304235", "text": "La conduttivit\u00e0 osservata di A2FeMoO6\u2013\u03b4 (A = Ca, Sr, Ba) [7] era collegata a un potenziale meccanismo di doppio scambio, con conduzione tra Fe3+-O-Mo-O-Fe2+. I meccanismi di doppio scambio, come proposto da Zener [23], presuppongono che il trasferimento di elettroni tra ioni in diversi stati di ossidazione possa essere facilitato se l'elettrone non deve alterare il suo stato di spin. Ci si aspetterebbe che la sostituzione di Mo con Fe in questo meccanismo si traduca in una riduzione della conduttivit\u00e0 attraverso la riduzione delle vie di percolazione disponibili, a meno che non possa verificarsi anche una delocalizzazione degli elettroni di Fe attraverso lo scambio Fe2+-O-Fe3+. Meccanismi di doppio scambio sono stati osservati in precedenza per il ferro valente misto negli ossidi di ferro [24] e, poich\u00e9 \u00e8 noto che il ferro esiste in uno stato valente misto per Ca2\u2013xSrxFeMoO6\u2013\u03b4 [25], ci\u00f2 fornisce una spiegazione plausibile per la struttura metallica osservata. conduttivit\u00e0. I calcoli della struttura delle bande e la spettroscopia Mossbauer potrebbero essere utilizzati per chiarire ulteriormente il meccanismo di conduzione di questi composti, tuttavia ci\u00f2 esula dallo scopo di questa indagine.", "keyphrases": ["fe2+-o-fe3+ scambio", "doppio cambio meccanico", "ossido", "ba", "elettrone", "sr", "composto", "riduzione del percorso dell'avail percol", "elettrone fe", "delocalis dell'elettrone fe", "ione", "Spettroscopi Mossbauer", "fe3+-o-mo-o-fe2+", "meccanismo a doppio cambio", "ferro nell'ossido di ferro", "osservare la condotta", "ferro", "mo", "calcolo struttura a bande", "condotta del metallo", "fe", "fe2+-o-fe3+", "condurre il meccanico", "circa", "riduzione della condotta", "trasferimento di elettroni", "a2femoo6\u2013\u03b4", "percorso del percol", "ca2\u2013xsrxfemoo6\u2013\u03b4", "sost"]}
{"file_name": "S074756321630348X", "text": "I giochi sui social network, che si riferiscono ai giochi collegati ai servizi di social network (SNS) direttamente o tramite applicazioni mobili (app), sono un'attivit\u00e0 online popolare. I giochi di social network (SNG) sono generalmente gratuiti e non assegnano premi in denaro, ma gli utenti possono effettuare acquisti in-game per avanzare all'interno del gioco, personalizzare il gioco, fare regali agli amici e accedere ad altri vantaggi e funzionalit\u00e0 esclusivi , portando questi giochi a essere definiti \"freemium\". Sebbene i SNG siano connessi a un SNS e incoraggino gli utenti a interagire con le loro connessioni, la maggior parte dei SNG pu\u00f2 essere riprodotta senza alcuna interazione sociale. La popolarit\u00e0 dei SNG \u00e8 cresciuta rapidamente e si prevede che il mercato globale dei SNG crescer\u00e0 ogni anno del 16% dal 2013 al 2019 per raggiungere un valore di mercato totale di 17,4 miliardi di dollari (Transparency Market Research, 2015). Un sondaggio condotto tra gli utenti di Facebook in Australia nel novembre 2012 ha riferito che ci sono oltre 3,5 milioni di giocatori social in tutta l'Australia e quasi il 70% gioca a SNG ogni giorno (Spiral Media, 2013), ed \u00e8 molto probabile che l'uso di SNG sia aumentato da allora .", "keyphrases": ["servizio di rete sociale", "app", "mercato sng", "sondaggio", "app mobile", "gioco di rete sociale", "sn", "canta"]}
{"file_name": "S0039602899010493", "text": "Sebbene i meccanismi di base del processo di AD siano ragionevolmente ben compresi, non \u00e8 risultato semplice applicare le teorie esistenti all\u2019interpretazione dei dati sperimentali. Ci\u00f2 che serve \u00e8 una combinazione della teoria dell'AD e della struttura elettronica di sistemi realistici, compresi i difetti superficiali e le specie adsorbite. Tali calcoli della struttura elettronica sono ancora complessi e richiedono molto tempo. In molti casi, soprattutto per le superfici isolanti, i tentativi di modellare gli spettri MIES utilizzano modelli semplici o intuitivi. Nei rif. [4,6,23] si assume che il principale meccanismo di transizione sia la diseccitazione Auger, e gli spettri MIES sono stati simulati dalla densit\u00e0 superficiale degli stati (DOS) proiettata sugli ioni di ossigeno superficiali dello strato superficiale pi\u00f9 alto utilizzando un Metodo Hartree-Fock (il codice cristallino [24,25]) e un metodo della teoria del funzionale della densit\u00e0 (DFT) (il codice cetep [26]). L'effetto della sovrapposizione tra le funzioni d'onda della superficie e dell'He(1s) \u00e8 stato preso in considerazione solo approssimativamente applicando un ulteriore fattore esponenziale z-dipendente al DOS della superficie. Altri ricercatori [5,6] hanno stimato la probabilit\u00e0 di transizione AD utilizzando un DOS proiettato sull'orbitale atomico 1 del proiettile. Tuttavia, non sono stati in grado di utilizzare metodi all'avanguardia per la struttura elettronica di superficie. Tuttavia il successo dei trattamenti semplificati [4\u20136], specialmente per le caratteristiche MIES come le energie relative dei diversi picchi, suggerisce che gli spettri reali sono effettivamente correlati alla proiezione del DOS superficiale sull'orbitale del proiettile.", "keyphrases": ["codice cetep", "Teoria della funzione densiti", "transito pubblicitario", "ione ossigeno superficiale", "i miei spettri", "diseccitazione della coclea", "anno Domini", "codice di cristallo", "metodo hartree-fock", "mio", "dft", "densit\u00e0 di stato", "adsorbire speci", "Fare", "difetto superficiale"]}
{"file_name": "S2212667814000045", "text": "L'opportunit\u00e0 offerta dalle tecnologie digitali di operare una profonda razionalizzazione negli acquisti delle forniture sta diventando indispensabile nella competizione tra imprese, ritenendo positivi gli effetti nella riduzione dei costi delle imprese che hanno adottato l'E-Procurement. Come confermato da numerosi casi di studio, l'automazione delle procedure di acquisto attraverso la tecnologia dell'e-procurement consente alle aziende di ottenere una riduzione dei costi (mediamente dell'8-12%) sul totale degli acquisti. Pertanto i modelli basati sul web stanno giocando un ruolo fondamentale all\u2019interno delle aziende, soprattutto nella generazione di valore della catena di fornitura. Questo articolo si concentra sul ruolo dell'e-procurement all'interno di una catena di fornitura mostrando, attraverso simulazioni, i vantaggi e le difficolt\u00e0 di implementare un uso sistematico di Internet e definendo la struttura di base di una catena di fornitura elettronica.", "keyphrases": ["casi di studio", "suppli", "ruolo dell'e-procur", "tecnologia e-procur", "ridurre il costo", "modello web-bas", "simul", "e-procur", "generatore di valore della filiera", "catena di fornitura elettronica", "procedura automatica", "razione", "catena di fornitura"]}
{"file_name": "S0257897213004131", "text": "La Figura 7 mostra la relazione tra il tempo di prova e i coefficienti di attrito di vari campioni in condizioni asciutte. Esiste un periodo di rodaggio e di usura costante nel processo di usura del rivestimento di AZ31 non rivestito e di anodizzazione senza nanoparticelle di Al2O3 mentre esiste un periodo di usura costante solo nel processo di usura del rivestimento di anodizzazione composito con nanoparticelle di Al2O3. Allo stesso tempo, l\u2019aggiunta di nanoparticelle all\u2019elettrolita ha portato ad una riduzione del coefficiente di attrito. Il coefficiente di attrito del rivestimento composito \u00e8 relativamente pi\u00f9 basso e pi\u00f9 stabile di quanto riportato in letteratura [24,25] per i rivestimenti anodizzati. Ci\u00f2 potrebbe essere causato dall\u2019\u201ceffetto rotolante\u201d prodotto dalle nanoparticelle di Al2O3 sulla superficie del rivestimento di ossido. Le nanoparticelle sferiche cambiano lo scorrimento in rotolamento, riducendo l'attrito, rendendo il coefficiente di attrito pi\u00f9 stabile. Il coefficiente di attrito del rivestimento anodizzato senza nanoparticelle Al2O3 presenta ampie fluttuazioni, forse a causa del danneggiamento del rivestimento. A differenza della lega di magnesio AZ31 non rivestita, i rivestimenti anodizzati presentano un coefficiente di attrito leggermente inferiore. Ci\u00f2 pu\u00f2 essere attribuito alla loro maggiore capacit\u00e0 di carico per l'elevata durezza.", "keyphrases": ["coefficiente di attrito", "rimuovere il rivestimento dalla lega di magnesio az31", "ridurre l'attrito", "riduzione dei coefficienti di attrito", "rivestimento anodico senza nanoparticelle al2o3", "elettrolita", "\u201ceffetto rullo\u201d", "tempo di prova", "rivestimento anodico", "nanoparticelle sferiche", "svestire az31", "cappotto", "rivestimento anodizzato composito", "nanoparticelle al2o3", "processo di usura", "nanoparticelle", "cappotto composito"]}
{"file_name": "S2212667812000536", "text": "In base alla situazione in cui gli studenti di informatica non riescono a soddisfare la domanda dell\u2019industria del software di personale qualificato, \u00e8 stato proposto un sistema di insegnamento pratico di sviluppo software tridimensionale \u201ctriplicemente guidato\u201d, con l\u2019obiettivo di migliorare le capacit\u00e0 di sviluppo software e il senso di innovazione degli studenti. Questo sistema pu\u00f2 effettivamente migliorare l'interesse degli studenti per lo sviluppo del software, le abilit\u00e0 pratiche e il senso di innovazione, gettando solide basi affinch\u00e9 gli studenti dopo la laurea possano integrarsi rapidamente nel processo di sviluppo del software, soddisfacendo le esigenze dell'industria del software.", "keyphrases": ["processo di sviluppo del software", "improvvisare il software sviluppare la capacit\u00e0 e il senso innovativo dello studente", "industrie del software", "Il software tridimensionale \u201ctriplice guida\u201d sviluppa un sistema di insegnamento pratico", "abilit\u00e0 pratica", "sviluppare software"]}
{"file_name": "S0032386108010392", "text": "La microdurezza pu\u00f2 essere correlata ad altre propriet\u00e0 meccaniche macroscopiche come il carico di snervamento, \u03c3, e il modulo elastico, E, entrambi derivati \u200b\u200bda prove di compressione. Per i metalli incruditi, Tabor ha derivato una proporzionalit\u00e0 diretta tra durezza e carico di snervamento a compressione: H\u22483\u03c3 [20]. Tuttavia, ci si rese presto conto che la relazione di Tabor si applica solo ai materiali che mostrano piena plasticit\u00e0 [9,10]. Sono state riportate deviazioni da questa relazione per un certo numero di metalli, vetri e polimeri in cui le deformazioni elastiche non sono trascurabili [9]. Pertanto, le diverse espressioni che descrivono la correlazione della durezza con le propriet\u00e0 meccaniche macroscopiche convenzionali si basano sulla validit\u00e0 dei modelli elasto-plastici sopra menzionati. In questo modo, la durezza e il carico di snervamento non sono pi\u00f9 direttamente proporzionali ma la loro relazione dipende dalle propriet\u00e0 specifiche del materiale, come il rapporto di Poisson e il modulo elastico [9,11\u201313]. \u00c8 stato dimostrato che questi modelli elasto-plastici non solo spiegano in modo soddisfacente un rapporto H/\u03c3 pari a \u22482 per un numero di materiali polietilenici di diversa natura, ma tengono anche conto teoricamente dell'intervallo di rapporti H/E determinati sperimentalmente [21].", "keyphrases": ["materiali che presentano una completa plasticit\u00e0", "bicchiere", "derivare una proporzione diretta", "materiale di polietilene", "prova di compressione", "propriet\u00e0 specifiche dei materiali,", "polym dove il ceppo elast", "la differenza espressa descrive la correlazione del duro con le propriet\u00e0 meccaniche del macroscop del convento", "metallo incrudito", "deviare da questa relazione", "microhard", "mantengono una proporzione diretta ma la loro relazione"]}
{"file_name": "S0167273814004408", "text": "Strati MIEC sottili di GDC e STFO su substrati YSZ monocristallini sono stati esposti all'atmosfera H2/H218O per esperimenti di scambio di traccianti guidati termicamente ed elettrochimicamente. I collettori di corrente rettangolari a film sottile di metallo nobile sono stati depositati sopra e sotto lo strato MIEC e utilizzati per la polarizzazione. La distribuzione laterale del tracciante ha rivelato diverse caratteristiche interessanti: (i) In caso di scambio termico del tracciante, una frazione tracciante potenziata si trova sopra il collettore di corrente metallico a causa della sua natura di blocco ionico. Ai bordi del collettore di corrente, la concentrazione di 18O diminuisce con un passo finito correlato alla diffusione nel piano degli ioni di ossigeno. (ii) A causa della bassa conduttivit\u00e0 elettronica di STFO e GDC, l'area MIEC influenzata da una polarizzazione applicata \u00e8 limitata a una regione vicina al collettore di corrente. La larghezza di questa regione attiva dipende dal bias. Ammonta a soli 10\u201315\u03bcm per STFO ma a pi\u00f9 di 100\u03bcm per GDC con una polarizzazione catodica di \u2212500 mV. (iii) Non solo l'incorporazione migliorata del tracciante dovuta alla polarizzazione catodica, ma anche la ridotta incorporazione dovuta alla polarizzazione anodica potrebbero essere risolte sperimentalmente nella regione attiva.", "keyphrases": ["applibia", "ridurre incorporare", "attuale collezionista", "gdc", "ione ossigeno", "scambiatore tracciante termico", "depositarsi sopra e sotto lo strato mielico", "Atmosfera h2/h218o", "strato mieloide", "larghezza di questa regione attiva", "polare", "successiva distribuzione del tracciante", "sottile strato mielico", "stfo", "esposizioni in atmosfera h2/h218o", "frazione tracciante", "bassa conduzione degli elettroni", "18o", "collettore di corrente rettangolare a film sottile in metallo nobile", "esperienza di scambio di traccianti", "substrato ysz monocristallino", "migliorare l'incorporazione del tracciante", "collettore di corrente in metallo", "diffusione nel piano dello ione ossigeno"]}
{"file_name": "S2212671612000613", "text": "La video-oculografia (VOG) \u00e8 uno dei metodi di misurazione del movimento oculare. Un problema chiave del VOG \u00e8 stimare con precisione il centro della pupilla. Quindi \u00e8 stato proposto un metodo di localizzazione degli alunni basato sulla morfologia e sull'algoritmo Canny per un sistema VOG basato su WIFI che \u00e8 stato sviluppato nel nostro ultimo lavoro. Inoltre, un volontario sano \u00e8 stato invitato a eseguire il test di tracciamento sinusoidale per valutare il metodo di localizzazione della pupilla. I risultati sperimentali hanno dimostrato che il metodo potrebbe tracciare i movimenti oculari e soddisfare i risultati attesi con la stimolazione.", "keyphrases": ["stimolo", "prova del binario sinusoidale", "video-oculografi", "misura del movimento oculare", "morfologo", "valutare il metodo di localizzazione degli alunni", "Accur stima il centro della pupilla", "metodo di misurazione del movimento oculare", "tracciare il movimento degli occhi", "volontario sano", "sistema vog wifi-bas", "Vog", "metodo di localizzazione dell'allievo", "algoritmo di Canni"]}
{"file_name": "S0011227515000648", "text": "Il cambio di prodotto tra i lotti #1/#2 e gli altri \u00e8 il pi\u00f9 influente sui risultati del test. La riprogettazione e l'aggiornamento alla tecnologia di processo a 110 nm riducono la velocit\u00e0 di passaggio presso LNT di circa la met\u00e0. Ci\u00f2 \u00e8 causato principalmente dalla maggiore incidenza di cancellazioni e timeout dei programmi con qualche contributo da tempi lunghi di cancellazione e programmazione ed errori di bit. La differenza nelle velocit\u00e0 di passaggio a 88K tra i lotti n. 3/n. 4 e n. 5/n. 6, che utilizzano la stessa tecnologia di processo con le stesse dimensioni, pu\u00f2 essere spiegata dalla fabbricazione in diverse linee di assemblaggio, dove altri processi o materiali di base possono \u00e8 stato cambiato. Ci\u00f2 significa tolleranze diverse nei materiali di base e nel processo di produzione, che sono tanto pi\u00f9 pronunciate quanto pi\u00f9 bassa \u00e8 la temperatura. Alcune delle differenze di scala tecnologica possono riflettere cambiamenti nei parametri dei transistor come transconduttanza/guadagno, tensione di soglia e pendenza di soglia [7].", "keyphrases": ["lotto n. 3/n. 4", "epoche e timeout del programma", "lnt", "transconduttanza/guadagno", "lotto n. 1/n. 2", "lunghe epoche", "tasso di passaggio", "Tecnologia di processo da 110 nm", "tensione di soglia", "linea di assemblaggio", "tempo del programma", "pendenza della soglia", "parametro del transistor", "tollerante", "tecnologia di processo", "errore di bit", "#5/#6", "cambio prodotto"]}
{"file_name": "S0304399111001811", "text": "Abbiamo sviluppato la teoria degli elettroni che trasportano momento angolare orbitale quantizzato. Per collegarci a situazioni realistiche, abbiamo considerato un'onda piana che si muove lungo l'asse ottico di un sistema di lenti, intercettata da un'apertura rotonda e centrata.88 Nell'esperimento, questa apertura porta la maschera olografica. Risulta che il movimento lungo l'asse ottico pu\u00f2 essere separato; l'equazione ridotta di Schr\u00f6dinger operante nel piano dell'apertura pu\u00f2 essere mappata sull'equazione differenziale di Bessel. Le autofunzioni risultanti rientrano in famiglie con momento angolare orbitale discreto \u210fm lungo l'asse ottico dove m \u00e8 un numero quantico magnetico. Questi vortici possono essere prodotti abbinando un'onda piana dopo il passaggio attraverso una maschera olografica con una dislocazione a forcella alle autofunzioni del problema cilindrico. I vortici possono essere focalizzati da lenti magnetiche in distribuzioni di carica simili a vulcani con divergenza angolare molto stretta, simili a correnti di circuito nel piano di diffrazione. L'inclusione dell'aberrazione sferica cambia la forma ad anello ma non distrugge l'intensit\u00e0 zero centrale dei vortici con m\u22600. La coerenza parziale dell'onda incidente porta ad un aumento del minimo di intensit\u00e0 centrale. \u00c8 dimostrato che \u00e8 necessario un angolo di sorgente molto piccolo (cio\u00e8 una coerenza molto elevata) per mantenere intatta la struttura del vulcano. La loro piccola ampiezza angolare nel campo lontano pu\u00f2 consentire la creazione di vortici elettronici di dimensioni nm o pi\u00f9 piccole, ma la richiesta di una coerenza estremamente elevata della sorgente pone una seria difficolt\u00e0.", "keyphrases": ["lente magnetica", "sistema di lenti", "coerenza parziale", "aereo", "creazione di vortici elettronici di dimensioni nm o pi\u00f9 piccole", "onda incidente", "incluso di aberr", "divergenza angolare", "Onda piana", "ridurre Schr\u00f6dinger equat", "vorticoso", "apertura", "rotondo, apertura centrale", "maschera olografica", "elettrone trasporta quantiz orbita momento angolare."]}
{"file_name": "S0021999114008523", "text": "Una descrizione multifisica di un sistema multiscala viene spesso definita modello \"ibrido\". In fluidodinamica, un tipico ibrido combina un trattamento molecolare (un modello 'micro') con uno fluido continuo (un modello 'macro'), con l'obiettivo di ottenere l'accuratezza del primo con l'efficienza del secondo [1 \u20134]. I modelli micro e macro hanno generalmente scale temporali caratteristiche che sono molto diverse, il che significa che le simulazioni accurate in termini temporali possono essere estremamente impegnative: la dimensione del passo temporale richiesto per rendere il micro modello stabile e accurato \u00e8 cos\u00ec piccola che le simulazioni su scala macro significativa i periodi di tempo sono intrattabili. Se il sistema \u00e8 \"a scala separata\", \u00e8 possibile effettuare un'approssimazione fisica (distinta da quella numerica) che consente ai modelli accoppiati di avanzare a velocit\u00e0 diverse (in modo asincrono) con penalit\u00e0 trascurabili sulla precisione su macroscala. E [5] sono stati i primi a introdurre e implementare questo concetto in un metodo time-stepping per sistemi accoppiati, indicato nella classificazione di Lockerby [6] come uno schema asincrono continuo (CA) (\"continuo\" poich\u00e9 i sistemi micro e macro i modelli avanzano senza interruzione [5]). In questo articolo estendiamo questa idea a sistemi multiscala comprendenti un numero arbitrario di modelli accoppiati.", "keyphrases": ["metodo a passi temporali per il sistema accoppiato", "fluido continuo", "modello \"micro\".", "modello \"ibrido\".", "ottenere l'accuratezza dei primi con l'efficacia dei secondi", "descrizione multifisica di un sistema multiscalare", "scala separata", "dinamica dei fluidi", "approssimazione fisica (distinta da quella numerica).", "il sistema multiscal comprende un numero arbitrario di modelli accoppiati", "continuo asincrono", "ibrido", "trattamento molecolare", "modello macro", "fluido", "modello micro e macro", "circa", "modello di coppia"]}
{"file_name": "S0167273811005091", "text": "Grazie alla sua ampia disponibilit\u00e0, la tecnica tomografica pi\u00f9 ampiamente adottata utilizza la potenza di fresatura di un fascio ionico focalizzato (FIB) insieme alle capacit\u00e0 di imaging del FE-SEM ad alta risoluzione, per fornire una sequenza di immagini 2D che possono essere efficacemente ricombinate nello spazio 3D. Tuttavia, poich\u00e9 questa tecnica \u00e8 distruttiva, gli studi sull\u2019evoluzione microstrutturale sono influenzati dalla variabilit\u00e0 intrinseca del campione. La tomografia nano-computerizzata (CT) a raggi X non distruttiva [9-11] fornisce una piattaforma per esplorare il cambiamento microstrutturale dinamico in assenza di queste possibili complicazioni ed \u00e8 compatibile sia con la radiazione di laboratorio che con quella di sincrotrone. Gli autori hanno precedentemente dimostrato una tecnica per la preparazione di geometrie ottimali del campione per nano-CT a raggi X [12], mentre questo percorso di preparazione del campione FIB comporter\u00e0 la rimozione selettiva di porzioni della microstruttura dell'elettrodo della cella a combustibile (e quindi potrebbe essere distruttivo per la cella a combustibile funzionante), la tecnica di caratterizzazione non distruttiva a raggi X consente una caratterizzazione ripetuta e non distruttiva del campione selezionato che facilita lo studio dei processi di evoluzione microstrutturale in risposta a vari cambiamenti ambientali.", "keyphrases": ["processo evolutivo della microstruttura", "esplorare i cambiamenti dinamici della microstruttura", "immagine 2D", "bugia", "tomografia nanocomputerizzata a raggi X non distruttiva", "preparazione di geometrie ottimali dei campioni per radiografie nano-ct", "cella a combustibile da lavoro", "fe-sem ad alta risoluzione", "tecnica dei caratteri a raggi X non distruttiva", "campione di fib", "tecnica tomografica", "radiografia nano-ct", "studi di microstruttura evoluta", "campione di fib preparare la rotta", "laboratori e radiazione di sincrotrone", "fascio ionico focalizzato", "ct", "seleziona campione", "microstruttura degli elettrodi delle celle a combustibile"]}
{"file_name": "S2212667814000264", "text": "In questo articolo presentiamo un progetto che mira a integrare le tecnologie di realt\u00e0 virtuale immersiva in un mondo virtuale tridimensionale. Utilizziamo una piattaforma educativa vAcademia come banco di prova per il progetto e ci concentriamo sul miglioramento del processo di apprendimento e, successivamente, dei risultati. Il nostro obiettivo \u00e8 aumentare l'immersivit\u00e0 dell'esperienza del mondo virtuale 3D applicando il tracciamento del movimento per il controllo dell'avatar e due tecnologie per la navigazione naturale: proiezione immersiva e display montato sulla testa. Inoltre, proponiamo le principali tipologie di scenari di apprendimento per l'utilizzo dei sistemi progettati.", "keyphrases": ["processo di apprendimento", "aumenta l'immersione nell'esperienza del mondo virtuale 3D", "principale tipo di scenario di apprendimento", "navigazione naturale", "controllare l'avatar", "traccia di movimento", "vacademia", "tecnologia della realt\u00e0 virtuale", "integr immerge la tecnologia della realt\u00e0 virtuale in un mondo virtuale tridimensionale", "piattaforma educativa", "progetto Immers", "display montato sulla testa"]}
{"file_name": "S1631070514000954", "text": "La superconduttivit\u00e0 negli attinidi fu osservata per la prima volta nel torio metallico nel 1929 [7], poi nell'uranio elementare nel 1942 [8] e nei composti dell'uranio nel 1958 [9]. Una nuova classe di superconduttori di uranio \u00e8 emersa negli anni '80 con la scoperta dei superconduttori di fermioni pesanti di uranio [10]. Ulteriori sorprese arrivarono all'inizio del secolo con la scoperta dei superconduttori ferromagnetici nei sistemi di uranio [11] e la prima osservazione della superconduttivit\u00e0 nei composti di plutonio [12] e nettunio [13]. Gli attinidi (o attinoidi) si trovano alla fine della tavola periodica (N=89 (Ac) o da 90 (Th) a 103 (Lr)). Gli elementi transuranici (o transuranici) sono gli elementi chimici con numero atomico (Z) maggiore di 92 (uranio) e, a causa della loro breve emivita su scala temporale geologica, sono essenzialmente elementi sintetici. Al di sopra di Z=103 (Lr), si parla di elementi transattinidi (o superattinidi). Questi ultimi elementi hanno emivite estremamente brevi e non \u00e8 disponibile alcuna quantit\u00e0 macroscopica per lo studio delle propriet\u00e0 della materia condensata.", "keyphrases": ["elemento transuranico", "superconduttore", "superattinide", "lr", "composto dell'uranio", "studi di propriet\u00e0 condensate-opache", "Superconduttore a fermioni pesanti di uranio", "transurano", "transattinide", "nettunio", "AC", "plutonio", "tabella del periodo", "uranio", "th", "elemento sintetico", "attinide", "superconduttore nell'attinide", "superconduttore dell'uranio", "superconduttore ferromagnete", "attinoide", "torio metallico"]}
{"file_name": "S0022311515002391", "text": "La sinterizzazione al plasma scintillante (SPS) \u00e8 una tecnica relativamente nuova basata sulla sinterizzazione [17] in cui la polvere da consolidare viene caricata in uno stampo di grafite elettricamente e termicamente conduttivo e una grande corrente continua pulsata (1000\u20135000 A) viene applicata sotto un pressione. Quando la corrente passa attraverso lo stampo di grafite (e la polvere se \u00e8 elettricamente conduttiva), la polvere viene riscaldata sia dall'esterno (lo stampo funge da elemento riscaldante) che dall'interno (per effetto Joule dovuto alla resistenza elettrica intrinseca della polvere Materiale). L'SPS \u00e8 caratterizzato da velocit\u00e0 di riscaldamento (fino a 2000\u00b0C/min) e raffreddamento molto rapide e tempi di mantenimento brevi (minuti) per raggiungere una densit\u00e0 vicina a quella teorica [17]. Pertanto, l\u2019SPS occupa uno spazio tempo-temperatura-densit\u00e0 molto diverso nelle mappe di consolidamento delle polveri rispetto ai metodi convenzionali, come la sinterizzazione con pressatura a caldo e l\u2019HIP con velocit\u00e0 di rampa di 50\u201380\u00b0C/min e tempo di mantenimento di poche ore. Sebbene l\u2019SPS sia stato studiato per un numero in rapida crescita di materiali [17], esiste solo un piccolo numero di studi sulla fabbricazione e sulla caratterizzazione microstrutturale degli acciai ODS lavorati mediante SPS, brevemente esaminati di seguito.", "keyphrases": ["sinterizzazione con pressa a caldo", "vecchio acciaio", "sp", "stampo in grafite", "sinterizzazione al plasma a scintilla", "Caratteristiche del tessuto e della microstruttura del processo di acciaio sp", "materiale in polvere", "mappa del solido in polvere", "metodo del convento", "polvere", "tecnica del bas-sinterizzazione", "elemento termico", "stampo in grafite a conduzione elettrica e termica e una grande corrente continua a impulsi (1000\u20135000 a) viene applicata sotto una pressione uniaxi", "muffa", "anca"]}
{"file_name": "S1687850714000405", "text": "Le xilanasi hanno potenziali applicazioni in vari campi. Alcune delle applicazioni importanti sono come maggesi. Le xilanasi sono utilizzate come agente sbiancante nell'industria della pasta di legno e della carta. Principalmente vengono utilizzati per idrolizzare la componente xilanica del legno che facilita la rimozione della lignina (Viikari, Kantelinen, Buchert e Puls, 1994). Aiuta anche a schiarire la pasta per evitare le operazioni di sbiancamento senza cloro (Paice, Jurasek, Ho, Bourbonnais e Archibald, 1989). Nei panifici le xilanasi agiscono sulla frazione glutine dell'impasto e aiutano nella ridistribuzione uniforme del contenuto di acqua del pane (Wong & Saddler, 1992). Le xilanasi hanno anche una potenziale applicazione nell'industria dei mangimi per animali. Sono utilizzati per l'idrolisi dei polisaccaridi non amidacei come l'arabinoxilano nelle diete monogastriche (Walsh, Power e Headon, 1993). Le xilanasi svolgono anche un ruolo chiave nella macerazione delle sostanze vegetali (Beck & Scoot, 1974), nella protoplastazione delle cellule vegetali, nella chiarificazione di succhi e vino (Biely, 1985), nella liquefazione della mucillagine del caff\u00e8 per la preparazione del caff\u00e8 liquido, nel recupero dell'olio dalle miniere sotterranee. , estrazione di aromi e pigmenti, oli vegetali e amido (McCleary, 1986) e per migliorare l'efficienza della produzione di insilati agricoli (Wong & Saddler, 1992).", "keyphrases": ["macerato di verdure opaco", "liquido della mucillagine del caff\u00e8", "estratto di aroma e pigmenti, olio vegetale e amido", "idrolizzare il componente xilano", "protoplasto della cellula vegetale", "rimozione della lignina", "legna", "schiarire la polpa", "chiarif di succo e vino", "agente candeggina", "lignina", "industria della pasta e della carta", "xylanas", "recupero di petrolio da miniera sotterranea", "componente xilano", "polisaccaride non amidaceo", "efficienza del prodotto insilato agricolo", "polpa", "industria dei mangimi animali", "preparare il caff\u00e8 liquido", "Candeggina senza cloro operaz", "arabinoxilano", "idrolisi di polisaccaridi non amidacei", "anche la ridistribuzione del contenuto di acqua del pane"]}
{"file_name": "S0021961415003821", "text": "Le serie omologhe di n-alcani sono qui rappresentate come catene omonucleari di segmenti CG sferici di Mie tangenti. Lo sviluppo di modelli CG per n-alcani lunghi come n-decano (n-C10H22) e n-eicosano (n-C20H42) \u00e8 gi\u00e0 stato dimostrato con successo utilizzando il formalismo SAFT-\u03b3 Mie [118]. La molecola di n-decano era rappresentata da catene di tre e catene di n-eicosano di sei segmenti Mie completamente flessibili legati tangenzialmente. \u00c8 previsto un certo grado di degenerazione dei parametri in termini di prestazioni complessive come conseguenza della natura conforme della descrizione dell'EOS [132]. Nel nostro lavoro attuale, utilizziamo una mappatura CG alternativa per gli n-alcani sviluppata in riferimento [122], in cui ciascun segmento \u00e8 stato considerato per rappresentare tre atomi di carbonio alchilico e i loro corrispondenti atomi di idrogeno. Applicando questa mappatura, le catene di n-alcani contenenti multipli di tre unit\u00e0 di carbonio possono essere rappresentate direttamente: n-C6H14, n-C9H20, n-C12H26, n-C15H32, n-C18H38, ecc. Una buona descrizione delle propriet\u00e0 termodinamiche di si \u00e8 scoperto che questi alcani sono provvisti di perline alchiliche CG caratterizzate dal potenziale Mie (15\u20136). Per comodit\u00e0, la coppia di esponenti (15\u20136) viene utilizzata anche per rappresentare le interazioni tra le sfere CG degli alcani interposti qui considerati; il numero di segmenti m \u00e8 considerato l'intero pi\u00f9 vicino della divisione del numero di carbonio C per tre. I parametri di dimensione \u03c3 ed energia \u220a vengono quindi stimati dalla densit\u00e0 sperimentale del liquido saturo e dalla pressione di vapore dei singoli alcani seguendo la consueta procedura SAFT-\u03b3 Mie. La mappatura scelta non \u00e8 affatto unica, poich\u00e9 si possono postulare insiemi di parametri che soddisfano altri requisiti, come essere \u201cuniversali\u201d su tutta la serie omologa [119] o correlati alle propriet\u00e0 critiche [125].", "keyphrases": ["n-c15h32", "saft-\u03b3 mie formale", "perlina CG", "pressione di vapore", "descrizione delle propriet\u00e0 termodinamiche", "mie (15\u20136) potenti", "n-c10h22", "serie omologa di n-alkan", "n-c6h14", "n-c20h42", "n-alkan", "catena omonucleare del segmento tangente mie sferico cg", "densit\u00e0 di liquidi saturi", "atomo di idrogeno", "n-c12h26", "atomo di dorsale di carbonio alchilico", "carbonio", "n-decano", "mio segmento", "sviluppo del modello cg per n-alkan lunghi", "catena n-alcanica", "n-c18h38", "Molecola n-decano", "n-c9h20", "n-eicosan", "mappa cg alternativa", "perla alchilica cg", "alcano", "unit\u00e0 di carbonio", "procedura saft-\u03b3 mie"]}
{"file_name": "S0888327016302333", "text": "I GFRF dei sistemi non lineari possono essere determinati mediante un metodo basato su modelli parametrici o un metodo basato su modelli non parametrici [8]. Nell'approccio parametrico, un modello parametrico non lineare viene prima identificato dai dati input-output. I GFRF vengono quindi ottenuti mappando il modello risultante nel dominio della frequenza utilizzando il metodo di sondaggio [9]. L'approccio non parametrico \u00e8 spesso definito identificazione del sistema di Volterra nel dominio della frequenza e si basa sull'osservazione che il modello di Volterra dei sistemi non lineari \u00e8 lineare in termini di nuclei di Volterra sconosciuti, che, nel dominio della frequenza, corrisponde a una relazione lineare tra la risposta in frequenza di uscita e GFRF lineari, quadratici e di ordine superiore. Questa relazione lineare consente l'uso dell'approccio dei minimi quadrati (LS) per risolvere i GFRF. Diversi ricercatori [10\u201312] hanno utilizzato questo metodo per stimare i GFRF. Ma di solito partivano dal presupposto che fosse noto a priori che il sistema in esame pu\u00f2 essere rappresentato solo da due o tre termini. Tuttavia, tali informazioni sono raramente disponibili a priori.", "keyphrases": ["un metodo parametrico-modello-bas", "relazione lineare", "un modello parametrico non lineare", "metodo della sonda", "il gfrf del sistema non lineare", "gfr", "sistema volterrano nel dominio della frequenza identificativo", "fatto il presupposto", "modello di volterra del sistema non lineare", "il sistema", "corrispondono ad una relazione lineare", "mappare il modello dei risultati nel dominio delle frequenze", "due o tre mandati", "un approccio minimo quadrato (ls).", "un metodo non parametrico del modello bas", "approccio non parametrico"]}
{"file_name": "S0010938X15002085", "text": "Lo spessore dell'ossido viene calcolato utilizzando l'aumento di peso e l'area superficiale. La modifica artificiale del profilo superficiale modificher\u00e0 l'area superficiale e lo spessore dell'ossido calcolato. Le immagini SEM dei campioni rimossi dopo 111 giorni di ossidazione sono state utilizzate per definire la variazione della lunghezza del profilo superficiale con la variazione della ruvidit\u00e0 applicata. Le lunghezze dei profili estratte dalle immagini sono state poi utilizzate per modificare la lunghezza del campione e quindi la superficie. La tabella 1 mostra gli spessori di ossido originali dopo 111 giorni di ossidazione, gli spessori di ossido modificati in base alla lunghezza del profilo superficiale e la differenza percentuale. I risultati mostrano una diminuzione massima dello spessore dell'ossido del 4% quando si utilizza una superficie che tiene conto della rugosit\u00e0. Il confronto della variazione dello spessore dell'ossido tra diverse finiture superficiali indica una variazione inferiore all'1%. Pertanto, l'impatto della variazione della lunghezza del profilo sullo spessore dell'ossido calcolato \u00e8 considerato insignificante. Inoltre, se le differenze nell\u2019aumento di peso fossero dovute solo a differenze nell\u2019area superficiale, ci si aspetterebbe che i campioni pi\u00f9 ruvidi mostrino ossidi pi\u00f9 spessi nelle prime fasi dell\u2019ossidazione.", "keyphrases": ["ossido", "immagine", "campione", "superficie", "profilo superficiale", "superficie", "profilo", "nessuna immagine"]}
{"file_name": "S2212667814000975", "text": "\u00c8 stato riconosciuto che le megalopoli stanno giocando un ruolo di primo piano nei processi sia di sviluppo economico che di cambiamento culturale. Pertanto, la nuova enfasi sulla sostenibilit\u00e0 del sistema di trasporto nelle megalopoli sta creando nuove richieste per un approccio adeguato per misurare le sue prestazioni e diagnosticare potenziali inconvenienti. Esaminando le descrizioni del sistema di trasporto sostenibile e il suo approccio di valutazione, viene sviluppato un quadro con applicabilit\u00e0 generale e risorsa di dati facilmente accessibile per valutare la sostenibilit\u00e0 del sistema di trasporto nelle megalopoli in base alla natura della struttura regionale e alle caratteristiche della domanda di trasporto nelle megalopoli. Il quadro proposto viene applicato nell'analisi e nel confronto del delta del fiume Jing-Jin-Ji e dello Yangtze.", "keyphrases": ["il quadro proposto \u00e8 applicabile", "sostegno del sistema dei trasporti", "sistema di trasporto", "approccio per misurarne le prestazioni e diagnosticare potenziali inconvenienti", "cambiamento culturale", "struttura", "sviluppo economico"]}
{"file_name": "S0098300414000259", "text": "Apache Pig \u00e8 una piattaforma per la creazione di flussi di lavoro MapReduce con Hadoop. Questi flussi di lavoro sono espressi come grafici aciclici diretti (DAG) di attivit\u00e0 che esistono a un livello concettualmente pi\u00f9 elevato rispetto alle loro implementazioni come serie di lavori MapReduce. Pig Latin \u00e8 il linguaggio procedurale utilizzato per costruire questi flussi di lavoro, fornendo una sintassi simile all'SQL dichiarativo comunemente utilizzato per i sistemi di database relazionali. Oltre alle operazioni SQL standard, Pig pu\u00f2 essere esteso con funzioni definite dall'utente (UDF) comunemente scritte in Java. Abbiamo adottato Pig per la nostra implementazione del correlatore per accelerare i tempi di sviluppo, consentire modifiche ad hoc del flusso di lavoro e abbracciare la migrazione della comunit\u00e0 Hadoop da MapReduce verso un'elaborazione DAG pi\u00f9 generalizzata (Mayer, 2013). Nello specifico, nel caso in cui le future versioni di Hadoop fossero ottimizzate per supportare paradigmi diversi da MapReduce, gli script Pig potrebbero trarre vantaggio da questi progressi senza ricodifica, mentre i lavori Java MapReduce espliciti dovrebbero essere riscritti.", "keyphrases": ["processo di giorno", "maiale apach", "uff", "maiale", "maiale latino", "sceneggiatura del maiale", "grafico aciclico diretto", "flusso di lavoro mapreduc", "sql operaz", "java mapreduc", "funzione definita dall'utente", "mq", "mapreduc", "giorno", "hadoop"]}
{"file_name": "S0022311514006941", "text": "La formulazione nella Tabella 1 \u00e8 stata derivata da un approccio empirico e ha portato a una matrice di vetro non classica. Carter [3] e Zhang [4] hanno adottato un approccio pi\u00f9 sistematico a tali rifiuti di vetroceramica. Queste forme di rifiuto erano mirate rispettivamente ai fanghi del bacino K di Hanford e all'immobilizzazione del flusso di rifiuti primari dalla produzione di molibdeno-99 presso il sito dell'Australian Nuclear Science and Technology Organization a Sydney. Nel lavoro di Carter e Zhang la fase cristallina prevista era il pirocloro titanato strettamente correlato, CaUTi2O7. La matrice di vetro \u00e8 stata formulata in modo tale che le specie trivalenti nella rete di vetro, boro e alluminio, fossero compensate su base molare dal sodio. La composizione stechiometrica del vetro in questa forma di rifiuto era Na2AlBSi6O16. Questo vetro fornisce un metodo mediante il quale la composizione del vetro pu\u00f2 essere variata sistematicamente. Dato che le osservazioni iniziali hanno dedotto un ruolo importante svolto dall\u2019allumina, si \u00e8 deciso di preparare una suite di vetroceramiche a base di zirconolite in cui la matrice vetrosa era definita da Na2Al1+xB1\u2013xSi6O16 per indagare il ruolo svolto dalla composizione del vetro nel controllo della fase cristallina stabilit\u00e0. L'elemento finale x=1 fornisce il minerale albite, NaAlSi3O8. Il punto di fusione dell'albite \u00e8 1120\u00b0C [5] e la composizione si raffredda fino a diventare vetro alle velocit\u00e0 di raffreddamento che si verificano durante un ciclo HIP. Dai diagrammi di fase disponibili, [6] non \u00e8 stato mostrato alcun analogo del boro per l'albite e il liquidus stimato dal diagramma di fase pertinente \u00e8 1100\u20131200\u00b0C. Non \u00e8 stato trovato alcun diagramma di fase per il sistema quaternario Na2O\u2013Al2O3\u2013B2O3\u2013SiO2.", "keyphrases": ["allumina", "na2o\u2013al2o3\u2013b2o3\u2013sio2", "pirocloruro di titanio", "na2albsi6o16", "sodio", "alluminio", "naalsi3o8", "molibdeno-99", "immobilis del flusso primario ottenuto dal prodotto del molibdeno-99", "bicchiere", "matrice vetrosa", "boro", "matrice vetrosa non di classe", "rete di vetro", "Fanghi Hanford K-Basin", "studiare il ruolo svolto dai compositi di vetro nel controllo della stabilit\u00e0 della fase cristallina", "albo dei minatori", "na2al1+xb1\u2013xsi6o16", "vetroceramica zirconolit", "cristallino", "forma di scarto di vetroceramica", "albit", "cauti2o7", "composto di vetro"]}
{"file_name": "S0022311514008691", "text": "La classe di acciai nota come leghe ferritiche rinforzate con dispersione di ossido (ODS) (note anche come leghe ferritiche nanostrutturate) \u00e8 costituita da una dispersione di particelle di ossido ultrafini in tutta la matrice. Queste particelle di ossido servono a migliorare le propriet\u00e0 meccaniche del sistema, in particolare alle alte temperature, inibendo il movimento di dislocazione e lo scorrimento dei bordi dei grani. Nelle applicazioni nucleari \u00e8 stato suggerito che le particelle di ossido agiscano come pozzi di difetti puntiformi [10,11] per migliorare la tolleranza alle radiazioni e come siti preferenziali per la formazione di bolle di He su scala nanometrica, riducendo quindi il rigonfiamento rispetto agli acciai non ODS [12\u2013 15]. La capacit\u00e0 delle particelle di ossido di migliorare queste propriet\u00e0 dipende dalla struttura e dalla composizione delle particelle [10,11,16,17] e dalla loro stabilit\u00e0 sotto irradiazione. Le composizioni tipiche degli acciai ODS includono tra il 9 e il 14% di Cr per la resistenza all'ossidazione (pi\u00f9 comunemente 14% in at.); W per indurimento in soluzione solida; Y2O3 che viene messo in soluzione solida durante il processo iniziale di alligazione meccanica ma poi durante il consolidamento ad alte temperature forma precipitati; e Ti per inibire una crescita significativa delle particelle di ossido; il resto \u00e8 costituito da Fe e impurit\u00e0 [18]. Per questo motivo questi acciai vengono spesso indicati come 14YWT, rispecchiando gli elementi costitutivi.", "keyphrases": ["y2o3", "vecchio acciaio", "elemento costitutivo", "soluzione solida", "rigonfiamento", "particelle di ossido", "ossido", "nanostruttura", "dispersioni di particelle di ossido ultrafini in tutta la matrice", "fe e impur", "classe di acciaio", "iradi", "struttura e composizione del particl", "lega di ferrite", "bolla su scala nanometrica", "ridurre il moto ondoso", "radi", "acciaio", "le dispersioni di ossido si rafforzano", "w", "acciaio non od", "precipizio", "tolleratore di radiazioni improvvisato", "9 e 14at.% cr", "migliorare le propriet\u00e0 meccaniche del sistema", "lega meccanica", "equilibrio", "ti", "14ywt", "consolidare", "od"]}
{"file_name": "S002231151500032X", "text": "Le leghe di zirconio vengono utilizzate come rivestimento per incapsulare i pellet di combustibile nei reattori nucleari ad acqua pressurizzata e bollente. La ricerca sull'ossidazione di queste leghe \u00e8 stata significativa sin dall'introduzione del materiale. Tuttavia, la microstruttura e i processi elettrochimici durante l\u2019ossidazione sono complessi e molte domande rimangono ancora senza risposta. Uno di questi problemi \u00e8 la formazione di crepe laterali vicino all'interfaccia metallo-ossido. \u00c8 stato osservato che piccole crepe si formano continuamente durante l'ossidazione, con reti su larga scala di crepe laterali che si formano ciclicamente ogni \u223c2\u03bcm di crescita dell'ossido. Queste reti di cricche possono essere correlate con l'accelerazione nella cinetica della corrosione [1\u20137]. Queste fessure laterali potrebbero consentire il collegamento di nanopori lungo i confini dei grani perpendicolari all'interfaccia metallo/ossido come riportato in [8,9]. Esperimenti utilizzando la diffrazione di raggi X al sincrotrone (S-XRD) condotti sia da Polatidis che da Petigny, hanno dimostrato separatamente che gli ossidi formati su Zircaloy-4 sono composti da fasi monocline e tetragonali stabilizzate, con una riduzione di circa il 7% nella frazione di fase tetragonale da 1 a una crescita di ossido di 3\u03bcm [4,10]. Una teoria \u00e8 che le crepe laterali possano destabilizzare la fase tetragonale vicino all'interfaccia metallo-ossido. Alla trasformazione di fase \u00e8 associata un'espansione di circa il 6%, che potrebbe portare alla frattura perpendicolare all'interfaccia metallo-ossido, generando cos\u00ec rapide vie di ingresso per le specie contenenti ossigeno [11,12].", "keyphrases": ["pellet di combustibile", "rivestito", "lega", "ossido", "trasformazione di fase", "interfaccia metallo/ossido", "grano", "Riduzione di circa il 7% nella fase tetragonale", "frattura", "ossido di queste leghe", "interfaccia metallo-ossido", "fase tetragonale", "ingresso", "s-xrd", "zircaloy-4", "collegamento dei nanopori", "corros kinet", "l'ossigeno contiene spec", "microstruttura e processo elettrochimico", "reattore nucleare ad acqua", "diffrazione dei raggi X di sincrotrone", "fase monoclina e stabilizzata del tetragono", "lega di zirconio"]}
{"file_name": "S0022311515303901", "text": "I reattori Magnox rappresentano la prima generazione di reattori raffreddati a gas nel Regno Unito che utilizzavano l\u2019anidride carbonica (CO2) come refrigerante primario e una rete a nido d\u2019ape di mattoni di grafite per fornire la moderazione dei neutroni. Durante il funzionamento del reattore furono prodotte quantit\u00e0 significative di monossido di carbonio (CO) dal refrigerante CO2. Questa CO a sua volta pu\u00f2 essere polimerizzata radioliticamente per formare un deposito carbonioso su superfici libere [12]. Questo deposito di carbonio non grafitico \u00e8 significativamente pi\u00f9 reattivo chimicamente con l'aria rispetto alla grafite sottostante [12,13]. Durante la vita di alcuni reattori Magnox, piccole quantit\u00e0 di gas metano venivano iniettate nel gas refrigerante per inibire la perdita di peso del nucleo di grafite dovuta all\u2019ossidazione radiolitica [14]. Il metano (CH4) \u00e8 un precursore di depositi carboniosi che formano uno strato sacrificale che protegge la grafite sottostante da un'eccessiva perdita di peso [15] e dalla riduzione della resistenza meccanica [16]. Si presume che l'incorporazione di azoto durante la formazione del deposito sia la successiva via di produzione degli elevati livelli di 14C osservati.", "keyphrases": ["ridurre la forza meccanica", "nucleo in grafite", "grafite", "refrigerante a CO2", "reattore", "deposito di carbonio", "neutrone", "cap4", "monossido di carbonio", "reattore Magnox", "metano", "formare un deposito di carbonio sulla superficie libera", "aria", "co", "azoto", "reattore raffreddato a gas", "polimero radiolitico", "metano ga", "refrigerante", "co2", "deposito di carbonio non grafitico", "l'azoto incorpora il formato di deposito", "inibiscono la perdita di peso del nucleo di grafite dovuta al radiolitico ossido", "neutrone moderato", "liquido refrigerante ga", "rete a nido d'ape di mattoni di grafite", "ossido radiolitico", "anidride carbonica", "perdita di peso in eccesso"]}
{"file_name": "S0021999113002945", "text": "La disuguaglianza (22) indica che la norma massima \u00e8 la pi\u00f9 libera tra tutte le norme p. Fortunatamente, questo vincolo pi\u00f9 flessibile non influenzerebbe seriamente l'accuratezza poich\u00e9 il valore di ||y||\u221e \u00e8 paragonabile a quello della 2-norma e della 1-norma. La norma massima ci fornisce il maggior numero di soluzioni possibili sotto una data limitazione di errore [24]. Ci\u00f2 aumenterebbe notevolmente la possibilit\u00e0 di trovare un gruppo di coefficienti ottimizzati durante la scansione di un vasto insieme di soluzioni. D\u2019altra parte, controllare la deviazione massima sembra pi\u00f9 ragionevole che controllare la \u201cdistanza\u201d tra i numeri d\u2019onda accurati e approssimati poich\u00e9 non funziona nel dominio spaziale. Pertanto, abbiamo scelto la norma massima come criterio per progettare le funzioni obiettivo per estendere il pi\u00f9 ampiamente possibile la copertura accurata del numero d'onda.", "keyphrases": ["2-norma", "norma-massima", "vasto set di soluzioni", "disuguale", "1-norma", "estendere la copertura del numero d'onda accu", "norma p", "deviazione massima", "funzione dell'oggetto", "coefficiente ottimale", "||y||\u221e"]}
{"file_name": "S0009261412006513", "text": "L\u2019acqua \u00e8 il liquido pi\u00f9 importante e la natura della sua struttura rimane un argomento di acceso dibattito e un\u2019attiva area di ricerca [1\u20139]. Gran parte di questo dibattito \u00e8 incentrato sul fatto se l\u2019acqua abbia una struttura prevalentemente tetraedrica con un continuum di legami idrogeno distorti, o se contenga una miscela di due componenti distinti. Uno sviluppo importante negli ultimi anni \u00e8 l\u2019applicazione di tecniche spettroscopiche del guscio interno, come la spettroscopia di assorbimento di raggi X (XAS) e la spettroscopia di emissione di raggi X (XES) al bordo K dell\u2019ossigeno per studiare la struttura dell\u2019acqua [2, 10\u201312]. Questi metodi possono fornire una sonda strutturale diretta dell\u2019acqua, fornendo informazioni sulla natura della sua rete di legami idrogeno. Gli studi teorici svolgono un ruolo fondamentale in questi studi, poich\u00e9 l'analisi dei dati sperimentali richiede calcoli per fornire un collegamento tra le caratteristiche spettrali osservate e la struttura sottostante. Tuttavia, la simulazione di XAS o XES per l'acqua liquida rappresenta una sfida difficile perch\u00e9 richiede simulazioni accurate di dinamica molecolare per fornire una descrizione corretta della struttura molecolare accoppiata con calcoli accurati delle propriet\u00e0 spettrali, cio\u00e8 energie di eccitazione e intensit\u00e0 di linea. Inoltre, \u00e8 necessario tenere conto anche del campionamento adeguato sulle configurazioni molecolari.", "keyphrases": ["calcolo", "xe", "intensit\u00e0 di linea", "struttura sottostante", "struttura molecolare", "rete di legami idrogeno", "sonda di struttura diretta dell'acqua", "ossigeno k-edg", "xa", "osservare le caratteristiche spettrali", "acqua", "Spettroscopi di assorbimento dei raggi X", "campione adeguato", "dati dell'esperimento", "Accur dinamica molecolare simul", "configurazione molecolare", "Spettroscopi di emissione di raggi X", "acqua liquida", "eccitare energia", "tecnica dello spettroscopio a guscio interno", "liquido", "distorcere il legame idrogeno", "propriet\u00e0 spettrali"]}
{"file_name": "S0370269304009347", "text": "La presenza di movimento caotico nei sistemi nucleari \u00e8 stata saldamente correlata alle statistiche dei livelli energetici elevati [8,9]. Le distribuzioni di Poisson di spaziature normalizzate di successivi livelli eccitati nucleari o atomici con lo stesso spin e parit\u00e0 corrispondono alla dinamica classica integrabile, mentre le statistiche di Wigner segnalano il movimento caotico nel corrispondente regime classico [10]. Le situazioni intermedie sono pi\u00f9 difficili da valutare. Molto recentemente \u00e8 stata avanzata la proposta di trattare le fluttuazioni spettrali \u03b4n come serie temporali discrete [11]. Definendo (1)\u03b4n=\u222b\u2212\u221eEn+1\u03c1\u02dc(E)dE\u2212n, con \u03c1\u02dc(E) la densit\u00e0 di livello medio che consente la mappatura a livelli adimensionali con densit\u00e0 di livello medio unitaria, e analizzando le fluttuazioni di energia come una serie temporali discrete, hanno scoperto che gli spettri dell\u2019energia nucleare si comportano come rumore 1f, postulando che questa potrebbe essere una firma caratteristica di generici sistemi caotici quantistici. Nel presente lavoro implementiamo questa idea, utilizzando il comportamento spettrale 1f come test per la presenza di caos negli errori di massa nucleare.", "keyphrases": ["livello di eccitazione", "statista di Wigner", "livello medio unitario densiti", "serie temporale discreta", "spettri dell\u2019energia nucleare", "1f comportamento spettrale", "distribuzione del veleno", "statista del livello energetico elevato", "sistema caotico quantistico", "mappa a livello adimensionale", "pariti", "analizzare la fluttuazione energetica", "\u03b4n", "caos nell'errore di massa nucleare", "integr classico dinam", "rotazione", "fluttuazione spettrale", "regime classico", "movimento caotico", "Movimento caotico nel sistema nucleare"]}
{"file_name": "S2212667813000762", "text": "Analizzando il significato del monitoraggio dinamico macroscopico di nuovi terreni edificabili, considerando l'influenza di vari fattori, questo articolo ha selezionato la pianura di Yinchuan per una tipica zona sperimentale, ha costruito una base di conoscenze sull'interpretazione delle immagini di telerilevamento, ha utilizzato immagini di telerilevamento multitemporali, effettuate attraverso interpretazione interattiva dei modelli di cambiamento di nuovi terreni edificabili e convalida sul campo. I risultati dell'interpretazione dell'immagine telerilevata su scala 20 m mostrano che l'area media minima del cambiamento di terreno di nuova costruzione monitorata dai dati telerilevati su scala 20 m \u00e8 di circa 6 acri. La capacit\u00e0 dei dati di telerilevamento su scala 20 m di identificare nuovi terreni edificabili, si rafforza ulteriormente, si riduce il riconoscimento dell'area pi\u00f9 piccola e la precisione del riconoscimento aumenta.", "keyphrases": ["interpretare", "Interpretazione dell'immagine del sensore remoto", "interagire interpreta il modello di cambiamento", "riconoscimento dell'area pi\u00f9 piccola dello spot", "pianura di Yinchuan", "identificare nuovi incrementi di terreno edificabile", "campo valido", "dati di rilevamento remoto", "costruire terreno", "base di conoscenza", "riconoscere", "immagine telesens", "imag.sens.remoto multitempo"]}
{"file_name": "S0098300413002185", "text": "Numerosi parametri del modello possono cambiare a livello regionale o stagionale, in particolare le propriet\u00e0 ottiche intrinseche dei costituenti dell'acqua [ai\u204e(\u03bb), aY\u204e(\u03bb), aD\u204e(\u03bb), bX(\u03bb), bb,X\u204e, bb ,Mie\u204e] e le propriet\u00e0 ottiche apparenti del fondale [Rib(\u03bb), Bi] e dell'atmosfera. Il database fornito con WASI \u00e8 stato derivato da misurazioni in situ dei laghi della Germania meridionale (Gege, 1998; Heege, 2000; Pinnel, 2007). Se non sono disponibili informazioni specifiche sul sito, possono essere utilizzate come prima approssimazione anche per altri ecosistemi. La variabilit\u00e0 all'interno di un ecosistema pu\u00f2 essere grande quanto quella tra ecosistemi diversi, ovvero non esistono insiemi di propriet\u00e0 ottiche specifici dell'ecosistema. Tuttavia, quando disponibili, \u00e8 necessario utilizzare informazioni specifiche sulla regione o sulla stagione. Idealmente, le propriet\u00e0 ottiche dovrebbero essere misurate nel sito di prova vicino al cavalcavia dell'aereo o del satellite. Ci\u00f2 tuttavia non \u00e8 sempre possibile. Una preziosa fonte di informazioni \u00e8 la pagina web dell\u2019IOCCG (IOCCG, 2013b). Mantiene un elenco di collegamenti a set di dati disponibili al pubblico, ad esempio la banca dati IOCCG (2006), il set di dati bio-ottici dell'algoritmo marino della NASA (NOMAD) e il sistema di archiviazione e archiviazione bio-ottico SeaWiFS (SeaBASS).", "keyphrases": ["sistema di archiviazione e archiviazione seawif bio-opt", "database", "ioccg", "banca dati ioccg (2006).", "propriet\u00e0 ottiche", "nomade", "misura in situ", "propriet\u00e0 ottiche del fondo [nervatura(\u03bb), bi] e dell'atmosfera", "spigola", "bb", "annuncio\u204e(\u03bb)", "informare sulla regione o sulla stagione specifica", "mie\u204e", "costitu. dell'acqua", "ero io", "ai\u204e(\u03bb", "ay\u204e(\u03bb)", "bx(\u03bb)", "Set di dati dell'algoritmo NASA Bio-Opt Marin", "bb,x\u204e"]}
{"file_name": "S0021999114008432", "text": "La validit\u00e0 delle condizioni al contorno semi-classiche per la WTE introdotte in [8] \u00e8 un argomento oggetto di un acceso dibattito, soprattutto dopo lavori recenti che affrontano la non unicit\u00e0 e le propriet\u00e0 di simmetria della funzione Wigner [27,28,46]. I casi di test numerici qui presentati riguardano potenziali simmetrici per i quali non possiamo fornire risultati affidabili, cio\u00e8 ben risolti, a causa della presenza di termini singolari nelle funzioni di Wigner allo stato stazionario, vedere la Sezione 4.3. Altri studi recenti dimostrano la convergenza dei calcoli WTE all'aumentare della dimensione del dominio di simulazione [44] cos\u00ec come i possibili miglioramenti adattando la distribuzione dei confini allo stato fisico della regione del dispositivo attivo [47]. Nonostante la loro natura approssimativa, anche qui utilizziamo condizioni al contorno di afflusso/deflusso e dimostriamo che risultati accurati e fisicamente validi possono essere ottenuti per valori di Lres sufficientemente grandi. A causa delle problematiche con i termini singolari presentiamo simulazioni solo per tensioni di polarizzazione diverse da zero VDS\u22600 V.", "keyphrases": ["non univoco e le propriet\u00e0 simmetriche della funzione Wigner", "altri studi recenti", "impiegare la condizione dei limiti di afflusso/deflusso", "presente simul solo per tensioni polari diverse da zero", "potenziale simmetrico", "risultato accurato e fisico valido", "adattare la distribuzione dei confini", "funzione Wigner allo stato stazionario", "valido di semi-classe boundari condit", "caso di test numerico", "aumenta la dimensione del dominio simul", "convergenza del calcolo del wte"]}
{"file_name": "S0010938X15301554", "text": "La lega di alluminio AA 2024-T3 \u00e8 ampiamente utilizzata per applicazioni aerospaziali grazie al suo elevato rapporto resistenza/peso e all'elevata tolleranza ai danni che derivano dal rame e dal magnesio come principali elementi di lega e dall'appropriata lavorazione termomeccanica. La microstruttura della lega \u00e8 relativamente complessa e sono state identificate numerose fasi composizionalmente distinte [1]. Pur possedendo propriet\u00e0 meccaniche favorevoli, la lega \u00e8 relativamente suscettibile alla corrosione e generalmente richiede un trattamento superficiale nelle applicazioni pratiche. Il comportamento alla corrosione della lega \u00e8 particolarmente influenzato dalla presenza delle particelle intermetalliche a causa dei loro diversi potenziali rispetto alla matrice della lega [2\u20139]. Le particelle della seconda fase contenenti rame sulla superficie della lega sono particolarmente dannose per la resistenza alla corrosione poich\u00e9 forniscono siti catodici preferenziali [2,10]. Uno dei principali tipi di particelle della seconda fase che \u00e8 importante per il comportamento alla corrosione della lega \u00e8 la particella della fase S (Al2CuMg) [1,11]. La deallegazione delle particelle della fase S, che pu\u00f2 rappresentare circa il 60% delle particelle costituenti nelle leghe AA2024 [11], \u00e8 comunemente osservata quando la lega \u00e8 esposta ad un ambiente aggressivo. Le particelle sono considerate importanti siti di inizio per una grave corrosione localizzata nella lega [11\u201322]. La deallegazione delle particelle della fase S e il conseguente arricchimento di rame determinano una diminuzione del potenziale Volta rispetto alla matrice e quindi le particelle deallate diventano siti catodici attivi [23\u201325].", "keyphrases": ["corrode", "lega", "diminuzione della tensione potenziale", "seconda fase particl", "s fase particl", "arricchire", "matrice di lega", "trattamento superficiale", "fase s", "comportamento corrosivo", "al2cumg", "lega aa2024", "processo termomeccanico", "particolato della seconda fase contenente rame", "aa Lega di alluminio 2024-t3", "applicazione aerospaziale", "fase composizionalmente distinta", "particl", "costituiscono particl", "elemento di lega", "rame", "magnesio", "sito del catodo", "deallo particl", "particella intermetallica", "resistere alla corrosione", "dealloy"]}
{"file_name": "S0022311513010313", "text": "I quattro rifiuti PCM delimitanti, riportati nella Tabella 1, sono stati simulati utilizzando i materiali e le geometrie pi\u00f9 appropriati. I fusti PCM \u201cmock up\u201d sono stati assemblati utilizzando i seguenti componenti: i fusti PCM sono stati simulati utilizzando barattoli e coperchi di vernice in acciaio dolce (Fenton Packaging Ltd.); Le borse in PVC sono state replicate utilizzando teli in PVC identici (Romar Workwear Ltd.); i rifiuti metallici sono stati simulati utilizzando acciaio inossidabile 18/8 di grado commerciale, alluminio e rame (Avus Metals & Plastics Ltd.) e pallini di piombo (Aldrich); i rifiuti inorganici sono stati simulati utilizzando rifiuti da laboratorio Pyrex, muratura frantumata, cemento e vetro di finestre; Come surrogato di PuO2 \u00e8 stato utilizzato CeO2 (da Acros Organics, >99,9%; essiccato per 15 ore a 600\u00b0C). Come additivo \u00e8 stata utilizzata la scoria d'altoforno granulata e macinata disponibile in commercio [27]. La composizione chimica analizzata \u00e8 riportata in Tabella 3. La calumite \u00e8 un materiale in polvere, con una tipica distribuzione granulometrica entro limiti di ca. 40 a ca. 400\u03bcm.", "keyphrases": ["acciaio inossidabile 18/8 di grado commerciale", "puo2 surrogato", "barattolo di vernice e coperchio in acciaio dolce", "amministratore delegato2", "pallini di piombo", "rilegato pcm era", "rifiuti inorganici", "materiale in polvere", "alluminio", "borsa in pvc", "muratori", "rifiuti metallici", "calumit", "tamburo PCM \u201cmock up\u201d.", "vetro della finestra", "particl", "rame", "tamburo pcm", "foglio in pvc identificativo", "concreto", "scoria d\u2019altoforno \u201ccalumite\u201d", "era Pyrex Labwar"]}
{"file_name": "S0301010413004096", "text": "\u00c8 fondamentale per il successo della tecnica NPD che il complesso MOF adsorba una quantit\u00e0 significativa di D2 per potenziare il segnale osservato. Questa tecnica presenta quindi degli svantaggi quando si studia l'interazione di legame all'interno dei MOF con bassi assorbimenti. Inoltre, gli studi cristallografici statici non possono fornire informazioni sulla dinamica delle molecole di gas adsorbite. Pertanto, \u00e8 molto impegnativo sondare sperimentalmente le interazioni di legame dell'H2 all'interno di un sistema ospite poroso che ha un assorbimento di gas molto basso a causa della mancanza di adeguate tecniche di caratterizzazione. Riportiamo qui l'applicazione della tecnica di scattering anelastico di neutroni (INS) in situ per consentire l'osservazione diretta della dinamica delle interazioni di legame tra le molecole di H2 adsorbite e un MOF poroso a base di alluminio, NOTT-300, che presenta una porosit\u00e0 moderata e una finestra a pori stretti e un assorbimento molto basso di H2. Questo studio di spettroscopia neutronica rivela che le molecole di H2 adsorbite non interagiscono con il ligando organico all'interno dei canali dei pori e formano interazioni molto deboli con le porzioni [Al(OH)2O4] attraverso un tipo di interazione attraverso la spaziatura (Al-O\u22efH2) . \u00c8 interessante notare che il bassissimo adsorbimento di H2 \u00e8 stato caratterizzato con successo come interazioni di legame deboli e, per la prima volta, abbiamo scoperto che l\u2019H2 adsorbito nel canale dei pori ha un movimento di rinculo di tipo liquido a 5K (sotto il suo punto di fusione) come un movimento diretto risultato di questa debole interazione con l'ospite MOF.", "keyphrases": ["adsorbire la molecola h2", "tecnica caratteristica", "permettono l'osservazione diretta del dinamismo del legame che interagisce", "al-o\u22efh2", "In", "mof", "adsorbimento h2", "interagiscono deboli", "assorbire h2", "legare interagire", "il legame debole interagisce", "Il legame h2 interagisce", "spettroscopi di neutroni", "adsorbire la molecola di ga", "porou a base di alluminio mof", "complesso mof", "tecnica npd", "interagire attraverso lo spazio", "d2", "h2", "ligando d'organo", "non-300", "ga", "studi di cristallografia statica", "in situ nell'ultima diffusione di neutroni", "[al(oh)2o4] moieti", "liquido"]}
{"file_name": "S092583881302834X", "text": "Le MG deformate plasticamente sviluppano disomogeneit\u00e0 e mostrano regioni pi\u00f9 dure e pi\u00f9 morbide [16]. Mentre in linea di principio questo potrebbe essere associato ad un BE secondo il modello composito, un MG non fornisce le basi per una teoria basata sulla dislocazione. La ricerca di un BE nel flusso plastico \u00e8 ostacolata dall'ammorbidimento dei MG associato allo shear-banding (in contrasto con l'incrudimento familiare nelle leghe convenzionali). La deformazione anelastica \u00e8, tuttavia, di interesse poich\u00e9 la sua dipendenza dal tempo deve essere correlata ai processi di rilassamento nella struttura MG che a loro volta dovrebbero essere collegati all'inizio della plasticit\u00e0. In particolare, l'anelasticit\u00e0 pu\u00f2 offrire un modo per studiare il funzionamento delle zone di trasformazione di taglio (STZ [17]) spesso utilizzate per interpretare la deformazione dei MG. Fujita ha utilizzato test di torsione per osservare l'anelasticit\u00e0 nei MG caricati (al massimo, sulla superficie cilindrica del campione) al 30%, 16% e solo il 4% dello sforzo di snervamento al taglio \u03c4y [18]. Nel presente lavoro applichiamo la torsione ai campioni MG per raggiungere sollecitazioni fino al 24% di \u03c4y e per la prima volta in regime elastico indaghiamo gli effetti dell'inversione della coppia.", "keyphrases": ["mg", "banda di taglio", "studiando l'effetto dell'inversione di coppia.", "un'ultima deformata", "cercare un essere nel flusso plastico", "osservare l'anelast in mg", "stz", "zona di trasformazione del taglio"]}
{"file_name": "S0167273815004130", "text": "La diffrazione di raggi X (XRD) su polvere a temperatura ambiente \u00e8 stata eseguita su un diffrattometro PANalytical Empireo. I modelli XRD ottenuti sono stati analizzati con il software STOE Win XPOW per determinare la purezza di fase, la struttura cristallina e i parametri cellulari dei campioni. L'analisi termogravimetrica (TGA) \u00e8 stata eseguita utilizzando uno strumento Netzsch STA 449C dotato del software di analisi termica Proteus. Gli studi TGA sono stati condotti in condizioni riducenti (5% H2/Ar) dalla temperatura ambiente a 900\u00b0C, al fine di determinare la variazione di peso della perovskite durante la riduzione. La microstruttura della superficie dei campioni \u00e8 stata analizzata utilizzando un microscopio elettronico a scansione a emissione di campo 74 JEOL JSM-6700 (FEG-SEM). La conduttivit\u00e0 totale dei campioni \u00e8 stata misurata utilizzando un metodo convenzionale a quattro terminali. I campioni di barre sono stati preparati mediante calcinazione a 1300\u00b0C per 1 ora. I contatti in filo d'oro sono stati attaccati alle barre, che poi sono state polimerizzate a 850\u00b0C per 1 ora. La conduttivit\u00e0 dei campioni \u00e8 stata misurata mediante ciclo redox a 900\u00b0C. Una bassa pressione parziale di ossigeno \u00e8 stata ottenuta utilizzando un flusso continuo del 5% H2/Ar.", "keyphrases": ["ciclo redox", "perovskit", "questo \u00e8 il software Win XPOW", "analisi termogravimetrica", "condotta totale", "modifica del peso", "ridurre condiz", "fluire", "struttura cristallina", "parametro cellulare", "contatto in filo d'oro", "5% h2/ar", "feg-sem", "tga", "software di analisi termica proteu", "microscopio elettronico a scansione a emissione di campo 74", "diffrazione dei raggi X in polvere", "fase puriti", "condotta", "h2/ar", "xrd", "calcina", "strumento netzsch sta 449c", "modello xrd", "diffrattometro empireo panalyt", "metodo a quattro termini", "bassa pressione parziale di ossigeno"]}
{"file_name": "S0010938X15003261", "text": "Il relativo potenziale di Volta (\u03a8) \u00e8 la differenza di potenziale tra una posizione infinitamente lontana dalla superficie e una posizione appena fuori dalla superficie, ed \u00e8 la quantit\u00e0 misurabile che caratterizza il comportamento elettrochimico di un metallo [12,17]. La tecnica della microscopia a forza con sonda Kelvin (SKPFM) consente il rilevamento dell'EWF locale (se l'EWF della punta \u00e8 noto) o delle differenze di potenziale di Volta (\u0394\u03a8) tra una punta per microscopia a forza atomica (solitamente rivestita in Pt) e la superficie metallica [14 ,15,19]. La risoluzione laterale di SKPFM pu\u00f2 raggiungere le decine di nm nell'aria ambiente, con una sensibilit\u00e0 fino a 10\u201320 meV [19]. Il potenziale volta \u00e8 una propriet\u00e0 caratteristica di una superficie metallica e pu\u00f2 essere utilizzato per comprendere i processi elettrochimici [16] . \u00c8 sensibile a qualsiasi tipo di difetto superficiale, variazioni chimiche e stress residuo [13,17]. Le differenze del potenziale volta nella microstruttura sono state utilizzate per prevedere il comportamento della corrosione [10,15,18,20\u201322]. Le regioni con maggiore (\u0394\u03a8) indicano una maggiore reattivit\u00e0 superficiale [11,15,18], ed \u00e8 stata segnalata anche una correlazione tra le differenze di potenziale Volta misurate in aria nominalmente secca e il loro potenziale di corrosione libera (Ecorr) predeterminato in condizioni di immersione [18 ].", "keyphrases": ["potenti differiscono", "volta potenti differiscono", "Comportamento elettrochimico di un metallo", "volta potenti differiscono nella microstruttura", "propriet\u00e0 di una superficie metallica", "\u03c8", "corros potente libero", "maggiore (\u03b4\u03c8) indice aumenta la superficie reattiva", "aria secca", "volta potenzio", "rilevamento dell'ewf locale", "cappotto", "superficie metallica", "Punta del microscopio a forza atomica", "aria ambiente", "ecorr", "prevedere il comportamento della corrosione", "scansione microscopi con sonda Kelvin", "\u03b4\u03c8", "skpfm", "metallo", "processo elettrochimico", "comprendere il processo elettrochimico", "misurare quantit\u00e0"]}
{"file_name": "S0009261415001517", "text": "Poich\u00e9 i recettori nella biologia umana sono costituiti principalmente da molecole chirali, l'azione dei farmaci coinvolge principalmente una forma enantiomerica specifica. Ci\u00f2 ha stimolato lo sviluppo, soprattutto nell\u2019industria farmaceutica, di una serie di tecniche per garantire prodotti enantiopuri. Tali metodi, per lo pi\u00f9 multi-step e dispendiosi in termini di tempo, possono tipicamente essere classificati in una delle due categorie distinte: meccanismi sintetici progettati per produrre un singolo stereoisomero o tecniche di separazione per isolare enantiomeri distinti da una miscela racemica. Uno svantaggio significativo, per entrambi gli approcci, \u00e8 la dipendenza dalla fornitura di reagenti o substrati enantiopuri: le vie di sintesi generalmente utilizzano blocchi costitutivi chirali o catalizzatori enantioselettivi [7,8], mentre le tecniche di separazione enantiomerica tipicamente incorporano molecole selettrici chirali per formare molecole chimicamente distinte e complessi diastereomerici distinguibili [8,9]. Un requisito fondamentale per mirare a ottenere prodotti enantiopuri, indipendentemente dal metodo sintetico, \u00e8 quindi un mezzo per misurare e quantificare debitamente l'eccesso enantiomerico, che indica il grado di chiralit\u00e0 all'interno dei prodotti molecolari. \u00c8 noto che la discriminazione chirale attraverso mezzi ottici offre metodi diretti e senza contatto per distinguere tra molecole di diversa manualit\u00e0, sulla base di osservazioni come le sottili differenze nell'assorbimento della luce polarizzata circolarmente sinistrorsa e destrorsa, o addirittura la torsione della polarizzazione nella rotazione ottica. Anche altri metodi ottici, in fase di sviluppo pi\u00f9 recente, mostrano qualche promessa di ottenere la separazione enantiomerica, come verr\u00e0 introdotto pi\u00f9 avanti.", "keyphrases": ["Molecola del selettore chirale", "complesso diastereoisomero", "eccesso di enantiomero", "catalizzatore enantioselettivo", "blocco di costruzione chirale", "ottenere prodotti enantiopur, indipendentemente dal metodo di sintesi", "molecola chirale", "grado di chirale", "metodi, per lo pi\u00f9 multi-step e time-consum", "significa misurare e duli quantificare l'eccesso di enantiomero", "prodotto molecolare", "reagente o substrato enantiopur", "meccanico di sintesi", "mezzo ottico", "assorbire", "torsione della polare nella rotazione ottica", "rotta di sintesi", "molecolar", "metodo di sintesi", "tecnica enantiom separ", "enantiom separ", "enantioma", "stereoisomia", "tecnica separata", "echniqu per garantire il prodotto enantiopur", "discriminazione chirale", "metodo ottico", "prodotto enantiopur"]}
{"file_name": "S0370269304009335", "text": "In questi contesti, tuttavia, la dimensione fisica dello spaziotempo \u00e8 un input piuttosto che una previsione della teoria. Infatti, nelle teorie standard il cui settore gravitazionale \u00e8 descritto dall'azione di Einstein-Hilbert, non vi \u00e8 alcun ostacolo ad effettuare riduzioni dimensionali a spaziotempi di dimensioni d\u22604. Allora sorge la domanda, dal momento che lo spazio di Minkowski a undici dimensioni \u00e8 uno stato massimamente (super)simmetrico, e la teoria si comporta bene attorno ad esso, perch\u00e9 la teoria non seleziona questa configurazione come vuoto, ma invece sceglie una particolare compattazione? spazio con minore simmetria. Una situazione ideale, invece, sarebbe che la teoria a undici dimensioni prevedesse dinamicamente un regime a bassa energia che potrebbe essere solo una teoria efficace a quattro dimensioni. In tale scenario, ci si dovrebbe aspettare che una soluzione di fondo con una dimensione spaziotemporale effettiva d>4 sia un falso vuoto in cui i propagatori per i campi dinamici sono mal definiti, per timore che una teoria efficace a bassa energia possa esistere in dimensioni superiori a quattro.", "keyphrases": ["falso vuoto", "dimensioni dello spaziotim fisico", "spazio di Minkowski", "Teoria dell'effetto quadridimensionale", "predire la teoria", "teoria standard", "regime di bassa energia", "Azione di Einstein-Hilbert", "Teoria delle undici dimensioni", "Teoria dell'effetto a bassa energia", "d>4", "propagazione per il campo dinamico", "soluzione di fondo", "spazio compattato", "effetto dimensioni spazio-temporali", "stato (super)simmetrico", "dimensione ridotta", "seleziona questa configurazione"]}
{"file_name": "S0021999114007876", "text": "In questo lavoro \u00e8 stata studiata la propagazione della luce in un mezzo di diffusione con indice di rifrazione costante a tratti utilizzando l'equazione del trasporto radiativo. La propagazione della luce in ciascun sottodominio con un indice di rifrazione costante \u00e8 stata modellata utilizzando l'RTE e le equazioni sono state accoppiate utilizzando condizioni al contorno che descrivono i fenomeni di riflessione e trasmissione di Fresnel sulle interfacce tra i sottodomini. Il sistema accoppiato risultante di RTE \u00e8 stato risolto numericamente utilizzando il FEM. Il modello proposto \u00e8 stato testato mediante simulazioni ed \u00e8 stato confrontato con la soluzione del metodo Monte Carlo. I risultati mostrano che il modello RTE accoppiato descrive accuratamente la propagazione della luce rispetto al metodo Monte Carlo. Inoltre, i risultati mostrano che trascurare i cambiamenti dell\u2019indice di rifrazione interno pu\u00f2 portare a misurazioni errate dei confini della luce diffusa. Ci\u00f2 indica che la qualit\u00e0 delle ricostruzioni DOT potrebbe essere aumentata incorporando un modello per i cambiamenti dell'indice di rifrazione interno nella procedura di ricostruzione dell'immagine.", "keyphrases": ["trasporto radi equat", "propagazione della luce in un mezzo di dispersione con indice di rifrazione costante pezzo-wis", "fem", "simul", "Fresnel riflette e trasmette i fenomeni", "punto ricostruire", "metodo Monte Carlo", "rte", "soluzione del metodo mont carlo", "modifica dell'indice di rifrazione", "sistema accoppiato di rte", "procedura di ricostruzione dell'immagine"]}
{"file_name": "S0167273813006735", "text": "Sebbene la spettroscopia di impedenza sia un metodo abbastanza comune per studiare elettrodi a film sottile a conduzione mista, [6,10\u201312] gli esperimenti con tracciante di ossigeno vengono spesso eseguiti su campioni sfusi [13\u201316]. Recentemente, sono state pubblicate diverse misurazioni IEDP di materiali catodici conduttori misti con film di ossido depositati su substrati isolanti [17\u201319]. Tuttavia, per quanto a conoscenza degli autori, nessuno studio finora ha riportato esperimenti con entrambe le tecniche applicate sulle stesse pellicole alla stessa temperatura. Questo contributo riporta i risultati di uno studio che applica EIS e IEDP a uno stesso film sottile di La0.6Sr0.4CoO3\u2212\u03b4 (LSC) al fine di ottenere risultati complementari sui contributi resistivi della cinetica di riduzione dell'ossigeno su tali film. Poich\u00e9 le misurazioni elettriche richiedono un conduttore di ioni di ossigeno, \u00e8 stata utilizzata la zirconia stabilizzata con ittrio (YSZ) come substrato per le pellicole LSC con due diverse dimensioni della grana. Da entrambi i tipi di esperimenti vengono dedotti parametri materiali quantitativi e il confronto dei dati ha consentito di verificare l'adeguatezza dei modelli di analisi.", "keyphrases": ["misura elettr", "pellicola dell'LSC", "la0.6sr0.4coo3\u2212\u03b4", "confronto dei dati", "Kinet di riduzione dell'ossigeno", "grano", "ossido di zirconio stabile con ittrio", "ei", "substrato isolano", "appropri del modello di analisi", "modello di analisi", "resistere al contributo del cineto riduttore di ossigeno", "pellicola sottile", "esperimento con tracciante di ossigeno", "parametro quantit\u00e0 materia", "campione collettivo", "applicare ei e iedp allo stesso film sottile la0.6sr0.4coo3\u2212\u03b4 (lsc)", "conduttore di ioni di ossigeno", "spettroscopi impediti", "lsc", "mescolare il materiale del catodo di conduzione", "mescolare l'elettrodo a film sottile condotto", "ysz", "iedp", "film", "pellicola di ossido", "misura iedp", "ossigeno"]}
{"file_name": "S2212667814000690", "text": "L'articolo presenta i risultati di studi sull'effetto dei nanotubi di carbonio a parete multipla da 18-20 nm in concentrazioni di 1 e 10 mg/ml per le diatomee Pseudo-nitzschia pungens (clone PP-07) e l'alga dorata Isochrysis galbana (clone TISO). Vengono rivelati gli effetti tossici dei nanotubi a parete multipla su entrambi i tipi di alghe, che si traducono in una diminuzione delle dimensioni lineari delle cellule, dei cloroplasti e in un numero ridotto di cellule quando incubate per 24 ore (Pseudo-nitzschia pungens) e 36 ore (Isochrysis galbana) .", "keyphrases": ["cellula", "cloroplasto", "alga", "nanotubo di carbonio", "incubo", "studi", "pseudo-nitzschia pungen", "presentare il risultato degli studi sull'effetto dei nanotubi di carbonio multiwal", "isochrysi galbana", "clone tiso", "effetto tossico", "alga dorata isochrysi galbana", "nanotubo", "clone pp-07"]}
{"file_name": "S0370157312000105", "text": "All'inizio degli anni '70, e in seguito all'\"et\u00e0 dell'oro\" della relativit\u00e0 generale avvenuta negli anni '60, esisteva un'ampia gamma di teorie candidate sulla gravit\u00e0 che potevano rivaleggiare con quella di Einstein. Era necessario un formalismo per affrontare questa grande abbondanza di possibilit\u00e0, e questo \u00e8 stato fornito sotto forma del formalismo parametrizzato post-newtoniano (PPN) di Kenneth Nordtvedt, Kip Thorne e Clifford Will. Il formalismo PPN fu costruito sul lavoro precedente di Eddington e Dicke e consent\u00ec di confrontare le numerose teorie disponibili all'epoca con osservazioni astrofisiche all'avanguardia come la misurazione del raggio laser lunare, l'eco radio e, nel 1974, l'Hulse-Taylor. pulsar binaria. Il formalismo PPN ha fornito una struttura chiara all'interno della quale \u00e8 possibile confrontare e valutare varie teorie, e da allora \u00e8 stato il punto di riferimento su come dovrebbero essere valutate le teorie della gravit\u00e0. Daremo uno schema del formalismo PPN e dei vincoli oggi disponibili al suo interno, nella Sezione 2.", "keyphrases": ["Pulsar binaria Hulse-Taylor", "il parametro \u00e8 post-newtoniano", "eco radiofonica", "teoria della gravitazione", "p.p.p", "il laser lunare squill\u00f2", "ppn formale", "osservazione dell'astrofisica del bordo tagliato", "genere rel", "punto di riferimento per come dovrebbe essere valutata la teoria della gravit\u00e0", "confrontare e valutare"]}
{"file_name": "S0022311514001640", "text": "La fase vapore \u00e8 costituita da un numero di gas diversi con il silicio che mostra una pressione parziale molto pi\u00f9 elevata rispetto a tutte le specie contenenti carbonio nell'intero intervallo di temperature. Come risultato immediato il vapore contiene una maggiore quantit\u00e0 di silicio lasciando la fase solida con un eccesso di carbonio. \u00c8 probabile che questo carbonio precipiti sulla superficie dei grani di SiC, un processo che diventa molto rapido quando la temperatura si avvicina a 2100K [24]. All'interno della particella TRISO lo strato SiC \u00e8 inserito tra due rivestimenti di carbonio denso. La pressione parziale in equilibrio termodinamico del carbonio gassoso che si forma sopra la grafite \u00e8 stata calcolata utilizzando i dati presi dalle tabelle JANAF e aggiunti alla Figura 1 [25], che ha mostrato che nell'intero intervallo di temperature rilevante per questo studio la pressione di vapore del carbonio \u00e8 di parecchie grandezze inferiore rispetto a quello delle fasi gassose dominanti al di sopra del SiC.", "keyphrases": ["ga", "vapore", "fase solida", "numero di gas diversi", "carbonio", "precipizio sulla superficie del grano sic", "s\u00ec", "pressione parziale", "sic grano", "grafite", "pressione di vapore del carbonio", "silicio", "triso particl", "fase vapore", "carbonio gassoso", "dati presi dalla tabella Janaf"]}
{"file_name": "S0021999112003579", "text": "Ordiniamo le incognite discrete in modo che il vettore delle incognite, xPS=[X,L], contenga le nx coordinate nodali sconosciute, seguite dai moltiplicatori di Lagrange discreti nb sconosciuti. I sistemi lineari da risolvere nel corso della soluzione basata su Newton dell'Eq. (10), soggetto al vincolo di spostamento (9), allora hanno struttura a punti di sella, (15) dove E \u00e8 la matrice di rigidezza tangente del problema pseudo-solido non vincolato, e i due blocchi fuori diagonale Cxl e Clx=CxlT derivano dall\u2019imposizione del vincolo di spostamento da parte dei moltiplicatori di Lagrange. Rimandiamo a [34] per la dimostrazione della stabilit\u00e0 LBB di questa discretizzazione; vedere anche [35,36] per una discussione sulla stabilit\u00e0 LBB dell'imposizione di condizioni al contorno di Dirichlet basata sul moltiplicatore di Lagrange in problemi correlati. Notiamo che durante il primo passo dell'iterazione di Newton, E \u00e8 definita positiva simmetrica poich\u00e9 rappresenta la matrice di rigidezza tangente relativa alla configurazione di equilibrio del sistema.", "keyphrases": ["coordinazione nodale", "matrice rigida tangente", "configurazione di equilibrio", "iter di Newton", "vettore di sconosciuto", "discreto", "xps=[x,l]", "clx=cxlt", "lagrange-moltiplicatore-bas imposit", "due blocchi fuori diagonale", "lbb", "dirichlet confini condit", "cxl", "soluzione newton-bas", "ordina il discreto sconosciuto", "problema pseudo-solido non vincolato", "lagrang multipli", "vincolo di spostamento", "struttura del punto di sella"]}
{"file_name": "S0957417416302561", "text": "\u2022 Maggiori sforzi dovrebbero essere diretti verso l'avanzamento dei metodi di estrazione delle caratteristiche per superare l'influenza dei fattori dinamici che limitano le prestazioni. L'uso di metodi avanzati di apprendimento automatico come le reti neurali profonde e l'estrazione di sinergie muscolari dovrebbe essere studiato anche su problemi sotto l'influenza di molteplici fattori dinamici poich\u00e9 tali metodi possono fornire miglioramenti sostanziali rispetto ai metodi di estrazione delle caratteristiche EMG tempo e frequenza utilizzati (Diener , Janke e Schultz, 2015 Ison, Vujaklija, Whitsell, Farina e Artemiadis, 2016; Nel frattempo, abbiamo dimostrato che le prestazioni degli algoritmi di apprendimento possono essere migliorate utilizzando metodi di estrazione delle caratteristiche che si basano sulle informazioni angolari dei modelli di attivazione muscolare. Funzionalit\u00e0 come TD-PSD e DFT si sono rivelate pi\u00f9 efficaci di altre nel ridurre l'impatto dei due fattori dinamici che abbiamo considerato in questo documento. Tali funzionalit\u00e0 possono essere facilmente implementate in un controller della protesi per il controllo in tempo reale, soprattutto perch\u00e9 oggigiorno i sistemi di riconoscimento dei pattern EMG stanno diventando disponibili per i test clinici, il sistema di controllo completo COAPT (Kuiken et al., 2014)11https://www. coaptengineering.com/.", "keyphrases": ["sistema di riconoscimento del pattern emg", "estratto delle caratteristiche", "controllo delle protesi", "caratteristica", "metodo di estrazione delle caratteristiche", "estratto sinergico muscolare", "controllo in tempo reale", "eseguire", "dft", "rete neurale profonda", "td-psd", "utilizzare il metodo di estrazione delle caratteristiche emg time-and-frequ", "sistema di controllo completo coapt", "metodo di apprendimento automatico avanzato", "prova clinica", "ridurre l'impatto dei due fattori dinamici"]}
{"file_name": "S0301679X14003272", "text": "La forza laterale, Q, viene misurata e registrata durante l'intero test da una cella di carico piezoelettrica collegata all'LSMB quasi stazionario. L'LSMB \u00e8 montato su supporti flessibili che forniscono flessibilit\u00e0 nella direzione orizzontale in modo che la maggior parte della forza laterale venga trasmessa attraverso il percorso di carico molto pi\u00f9 rigido che contiene la cella di carico, come mostrato nella Figura 2. Sia i sensori di spostamento che quelli di carico sono stati calibrati (entrambi esternamente e in situ) in condizioni statiche. I segnali di carico e spostamento vengono campionati a una velocit\u00e0 di duecento misurazioni per ciclo di fretting a tutte le frequenze di fretting, e questi dati vengono utilizzati per generare cicli di fretting. I circuiti sono stati utilizzati per ricavare l'ampiezza dello scorrimento di contatto e il coefficiente energetico di attrito in ciascun ciclo secondo il metodo suggerito da Fouvry [17]. I valori medi per questi sono stati calcolati per ciascun test (il coefficiente medio di attrito includeva valori associati ai transitori iniziali nei test come suggerito da Hirsch e Neu [18]).", "keyphrases": ["sensore di spostamento e carico", "la forza successiva, q, \u00e8 misura e registrazione", "lsmb", "flessione", "cella di carico", "cella di carico piezoelettrica", "anelli per tasti."]}
{"file_name": "S0022311513011422", "text": "\u00c8 ancora in corso un dibattito sulla struttura cristallina e sulla composizione degli ossidi fini presenti negli acciai ODS e sono state proposte e identificate numerose fasi diverse. \u00c8 necessaria una caratterizzazione completa delle particelle di ossido, compresa la struttura cristallina e la composizione, poich\u00e9 \u00e8 stato dimostrato che fasi diverse e varianti chimiche di una singola struttura rispondono in modo diverso alle alte temperature e all'irradiazione. Ribis e de Carlan [6] hanno studiato le caratteristiche di ingrossamento degli ossidi Y2O3 e Y2Ti2O7 ad alte temperature. Mostrano che l'aumento della dimensione delle particelle \u00e8 maggiore per la fase non contenente Ti. Allo stesso modo, Ratti [9], sebbene non alludano a specifiche fasi di ossido, hanno dimostrato che piccole aggiunte di Ti a una lega ODS al 18% di Cr riducono drasticamente i tassi di ingrossamento dei dispersidi rispetto a una lega equivalente senza titanio. Ad esempio, Ribis indica che le velocit\u00e0 di ingrossamento possono essere controllate dall'energia interfacciale tra le particelle della fase secondaria e la matrice; egli sottolinea che la resistenza all'ingrossamento osservata nel sistema Y, Ti, O \u00e8 probabilmente il risultato di un'energia di interfaccia molto bassa e questa sarebbe diversa da una fase all'altra. Whittle [10] hanno dimostrato che il pirocloro e le strutture strettamente correlate alla struttura del pirocloro rispondono in modi diversi all'irradiazione. Hanno rivelato che la struttura dell'ossido e le variazioni nella composizione possono influenzare la loro capacit\u00e0 di resistere e riprendersi dai danni indotti dalle radiazioni.", "keyphrases": ["o", "vecchio acciaio", "y2o3", "cristallo", "lega", "ossido", "particelle di ossido", "titanio", "iradi", "matrice", "s\u00ec", "tasso grossolano", "particl", "pirocloro", "y2ti2o7 ossido", "ossido fine", "disperso", "ti", "18% di lega", "caratteristica completa della particella di ossido"]}
{"file_name": "S0038092X14000942", "text": "Le prestazioni termiche della finestra intelligente sono state previste in base a diversi parametri simulati, ovvero intensit\u00e0 della radiazione solare diretta, temperatura ambiente, temperatura di ingresso dell'acqua e portata dell'acqua. La Figura 11 mostra un campione di distribuzione della temperatura di tutti i componenti della finestra su un piano che passa attraverso il segmento orizzontale della finestra in base alle condizioni fisiche di simulazione elencate nella Tabella 3. I dati di simulazione sono stati raccolti da tutte le simulazioni successive. L'effetto dell'aumento della radiazione solare diretta sia sulle celle solari che sulla temperatura dell'acqua \u00e8 mostrato nella Figura 12. Sono state eseguite tre diverse simulazioni assumendo intensit\u00e0 di radiazione solare diretta di 400, 600 e 800 W/m2 incidente sul vetro anteriore della finestra con temperatura ambiente impostata, temperatura di ingresso dell'acqua e portata dell'acqua rispettivamente di 273K, 283K e 0,01 kg/s. \u00c8 stato riscontrato che la temperatura dell'acqua aumenta di 5\u00b0C mentre passa attraverso il tubo, che trasporta le celle solari, da sinistra a destra per le unit\u00e0 pi\u00f9 in basso, con 800 W/m2 di radiazione solare incidente diretta.", "keyphrases": ["radiazione solare", "prestazione termica della finestra intelligente", "tubo", "aumenta la radiazione solare diretta sia sulla cella solare che sulla temperatura dell'acqua", "intensit\u00e0 della radiazione solare diretta", "parametro simultaneo", "dati simultanei", "portata dell'acqua", "simul", "temperatura ingresso acqua", "componente finestra", "pannello frontale della finestra", "condizioni fisiche simultanee", "temperatura ambiente", "celle a energia solare"]}
{"file_name": "S1364815216303541", "text": "Come caso particolare di dati del sondaggio, abbiamo utilizzato l\u2019iUTAH \u201cUtah Water Survey\u201d, che \u00e8 stato implementato da ricercatori partecipanti provenienti da diversi istituti di istruzione superiore dello Utah. Gli obiettivi dell'indagine erano documentare il modo in cui uno spaccato rappresentativo della popolazione adulta dello Utah pensa alle questioni idriche. L\u2019indagine comprendeva tre blocchi fondamentali di domande: percezione dell\u2019adeguatezza delle forniture idriche locali, percezione della qualit\u00e0 delle risorse idriche locali e preoccupazione su una serie di questioni idriche e non idriche. Una serie di domande aggiuntive hanno raccolto informazioni sulla familiarit\u00e0 degli intervistati con il costo dell'acqua, sui comportamenti di irrigazione del prato, sulla partecipazione ad attivit\u00e0 ricreative acquatiche e sugli attributi demografici. Il materiale supplementare a questo documento include un documento con una descrizione del set di dati nel suo complesso, un documento contenente lo strumento di indagine completo e due file di dati contenenti i risultati e un codice associato (vedere Sezione 4.3).", "keyphrases": ["descrizione del set di dati", "comportamento awn-wat", "La popolazione adulta dello Utah pensa al problema dell'acqua", "familiarit\u00e0 con il costo dell'acqua", "codebook associati", "iutah \u201cindagine sull\u2019acqua dello Utah\u201d,", "percezione della qualit\u00e0 della risorsa idrica locale", "sondaggio", "strumento di indagine completo", "partecipare alla ricreazione della base acquatica", "percezione dell'adeguatezza dell'approvvigionamento idrico locale", "materia supplementare", "attributo demografico", "preoccupazione per un raggio d'acqua e problemi non-wat"]}
{"file_name": "S0375960115004120", "text": "Un'altra caratteristica notevole del trattamento quantistico del campo pu\u00f2 essere rivelata dallo studio dello stato del vuoto. Per un campo classico, il vuoto si realizza semplicemente impostando il potenziale a zero, ottenendo un'evoluzione libera e inalterata dell'onda piana della particella (|\u03c8I\u3009=|\u03c8III\u3009=|k0\u3009). Nella trattazione quantizzata, il vuoto \u00e8 rappresentato da uno stato Fock iniziale |n0=0\u3009 che interagisce ancora con la particella e fornisce come stato finale |\u03a8III\u3009 dietro la regione di campo(19)|\u03a8I\u3009=|k0\u3009\u2297|0\u3009 \u21d2|\u03a8III\u3009=\u2211n=0\u221et0n|k\u2212n\u3009\u2297|n\u3009 con una probabilit\u00e0 di scambio di fotoni(20)P0,n=|t0n|2=1n!e\u2212\u039b2\u039b2n La particella trasferisce quindi energia al vuoto campo che porta a un numero di fotoni finali distribuito poissoniano. Consideriamo ad esempio un circuito risonante superconduttore come sorgente del campo. Il campo magnetico lungo l'asse di una bobina opportunamente sagomata \u00e8 ben approssimato dalla forma rettangolare. Una particella con un momento di dipolo magnetico che passa attraverso la bobina interagisce quindi con il circuito e lo eccita con una perdita misurabile di energia cinetica anche se il circuito \u00e8 inizialmente scarico e classicamente non esiste alcun campo a cui possa accoppiarsi. Il fenomeno per cui il vuoto nella teoria quantistica dei campi non significa \u201cnessuna influenza\u201d, come noto dalle forze di Casimir o dallo spostamento di Lamb, \u00e8 chiaramente visibile anche qui.", "keyphrases": ["Bobina dalla forma corretta", "Casimir forc o turno di agnello", "trattamento quantistico", "circuito risonante superconduttore", "particl", "campo magnetico", "trattamento del campo quantistico", "vuoto", "stato di vuoto", "onda piana della particella"]}
{"file_name": "S2212667814001440", "text": "In questo articolo presentiamo un sistema robotico mobile teleoperato per la sorveglianza degli anziani. Il robot funziona in modalit\u00e0 autonoma in cui naviga nell'ambiente e cerca situazioni insolite di persone anziane. Se un paziente \u00e8 sdraiato sul pavimento, il robot informa l'utente. L'utente cambia la modalit\u00e0 di controllo da controllo utente autonomo a controllo utente basato su aptica. Nella modalit\u00e0 autonoma, il robot utilizza il sensore visivo e i punti di riferimento per monitorare l'intero ambiente. Il robot \u00e8 dotato di microfono, altoparlante e monitor che consentono di comunicare con l'utente in luoghi remoti. Inoltre, il robot utilizza i sensori vitali per controllare le condizioni del paziente. Gli esperimenti preliminari di sorveglianza mostrano una buona prestazione.", "keyphrases": ["paziente", "luogo remoto", "tenere sotto controllo", "cambiare la modalit\u00e0 di controllo da autonoma a base tattile", "sensore vitale", "sorveglianza della vecchiaia", "Giacere sul pavimento", "gli anziani", "robot", "informare l'utente", "microfono", "sensore visivo e punto di riferimento da monitorare", "sistema robotico mobile teleoperativo", "altoparlante", "navigare nell'ambiente", "modalit\u00e0 autonoma", "comun", "condizione del paziente", "cerca una situazione insolita"]}
{"file_name": "S0370269304009530", "text": "Se all'LHC verranno scoperti segnali che suggeriscono la supersimmetria (SUSY), allora sar\u00e0 fondamentale misurare gli spin delle nuove particelle per dimostrare che sono effettivamente i super-partner previsti. Viene discusso un metodo mediante il quale \u00e8 possibile determinare gli spin di alcune particelle SUSY. Le distribuzioni angolari nei decadimenti delle sparticelle portano all'asimmetria di carica nelle distribuzioni di massa invarianti del getto leptonico. La dimensione dell'asimmetria \u00e8 proporzionale all'asimmetria della produzione primaria tra squark e anti-squark. Le simulazioni Monte Carlo vengono eseguite per un particolare punto del modello mSUGRA all'LHC. Le risultanti distribuzioni di asimmetria sono coerenti con uno sleepon con spin 0 e uno spin-12\u03c7\u02dc20, ma non sono coerenti con il fatto che entrambe le particelle siano scalari.", "keyphrases": ["spin-0 dormito", "Distribuzione di massa invariata del getto leptonico", "dimostrare che sono indipendenti dal super-partner previsto", "squark", "anti-squark", "asimmetrie di carica", "decadimento spartico", "particl", "supersimmetri", "susi", "super-partner", "distribuzione angolare", "susi particl", "punto del modello msugra", "misurare lo spin della nuova particella", "Monte Carlo simul", "prodotto primario asimmetrico", "distribuzione asimmetrica"]}
{"file_name": "S0370269304009049", "text": "Una delle sfide della cromodinamica quantistica (QCD) \u00e8 il problema relativistico dello stato legato. Nell'approccio hamiltoniano del cono di luce [1] le funzioni d'onda del cono di luce possono essere costruite in modo invariante al boost. \u00c8 necessario disporre di funzioni d'onda del cono di luce affidabili se si vuole calcolare lo scattering ad alta energia, in particolare le reazioni esclusive. Molte parametrizzazioni presuppongono la separabilit\u00e0 della dipendenza dalla frazione di momento longitudinale e dal momento trasversale, il che \u00e8 molto improbabile poich\u00e9 i due momenti sono accoppiati nell'operatore di energia cinetica. Sono stati tentati vari approcci per calcolare tali funzioni d'onda. Si pu\u00f2 usare la consueta Hamiltoniana di tempo uguale [2] e trasformare le funzioni d'onda risultanti in forma di cono di luce con l'aiuto di equazioni cinematiche su shell. L'Hamiltoniana del cono di luce in un'immagine di stringhe \u00e8 formulata nel Rif. [3]. Pi\u00f9 ambiziosa \u00e8 la costruzione di un'Hamiltoniana efficace che includa esplicitamente i gradi di libert\u00e0 di Gauge e quindi la risoluzione del problema dello stato legato. Per i mesoni questo approccio [4,5] necessita ancora di molti parametri da fissare. Sono stati fatti tentativi per risolvere la funzione d'onda dei quark di valenza per i mesoni in una semplice hamiltoniana con un potenziale a due corpi [6].", "keyphrases": ["reazione", "cinemat sullo scaffale equat", "qcd", "Il costrutto di un effetto hamiltoniano include esplicitamente il grado di libert\u00e0", "cromodinamica quantistica", "Funzione d'onda del quark di valenc", "approccio hamiltoniano light-con", "Problema dello stato legato relativista", "affidabile funzione d'onda luminosa", "hamiltoniano", "semplice hamiltoniano con un potente a due corpi", "risolvere la funzione d'onda del quark valenc per il mesone", "risolvere il problema dello stato legato", "mesone", "funzione d'onda luminosa", "hamiltoniano in tempo uguale", "calcolo della dispersione ad alta energia", "trasformare la funzione d'onda del risultato in una forma luminosa"]}
{"file_name": "S037026930400930X", "text": "Pubblicazioni recenti [31] impiegano una variet\u00e0 di metodi per calcolare i limiti massimi e non esiste una procedura universalmente accettata [27,32,33]. Scegliamo un approccio simile a quello inizialmente sostenuto da Feldman e Cousins \u200b\u200b[27]. Questo metodo \u00e8 stato poi esteso da Conrad et al. [34] per incorporare le incertezze nella sensibilit\u00e0 del rivelatore e la stima del fondo basata su un approccio descritto da Cousins \u200b\u200be Highland [35]. Un ulteriore affinamento del metodo di Conrad et al da parte di Hill [36] determina un comportamento pi\u00f9 appropriato del limite superiore quando il numero di eventi osservato \u00e8 inferiore al fondo stimato, come nel caso della presente misurazione. Abbiamo adottato questo metodo ma notiamo che la Tabella 2 contiene tutti i numeri necessari per calcolare un limite superiore utilizzando uno qualsiasi dei metodi descritti negli articoli sopra citati. Assumiamo che le funzioni di densit\u00e0 di probabilit\u00e0 di Fsens e le stime di fondo siano distribuite gaussiana.", "keyphrases": ["comportamento pi\u00f9 appropriato", "distribuzione gaussiana", "calcolare il limite superiore", "stima del fondo", "sensibilit\u00e0 del rilevatore", "ulteriore perfezionamento di Conrad et al. metodo", "probabile funzione densiti", "incorporare incertezze", "calcolare un limite superiore", "misura"]}
{"file_name": "S0021961414003255", "text": "Inoltre, si osservano effetti di segregazione mediante l'analisi XRD, che probabilmente \u00e8 avvenuta ad alta temperatura, e che \u00e8 stata parzialmente raffreddata a temperatura ambiente. L'analisi di fase ha mostrato fino a tre fasi distinte, che dovrebbero quindi avere una temperatura di transizione di fase misurabile distinta, se cristallizzano dal liquido sulla superficie. Nei termogrammi questi effetti non sono osservabili come diversi arresti di solidificazione o inflessioni chiare. La proporzione delle nuove fasi che compaiono \u00e8 piccola e quindi anche il calore latente rilasciato da questa nuova fase sar\u00e0 piccolo. La tecnica del segnale luminoso riflesso ha mostrato solo un cambiamento di fase durante il raffreddamento. Inoltre, la posizione di questa segregazione non pu\u00f2 essere determinata esattamente nella vasca fusa o successivamente nel materiale risolidificato. In superficie, dove viene misurata la temperatura, l'analisi del materiale mediante spettroscopia Raman non ha mostrato segni di segregazione, per cui anche le incertezze nella composizione per la transizione di fase sono prese dalle incertezze dell'analisi XRD per la fase pi\u00f9 abbondante ad ogni composizione in materiale risolidificato.", "keyphrases": ["solidificare nuovamente i materiali", "analisi della materia mediante spettroscopi raman", "analisi xrd", "cristallis", "spettroscopi Raman", "liquido", "effetto segregante", "flessione chiara", "pozza fusa", "transito di fase", "superficie", "segregare", "cambiamento di fase", "arresto solido", "Calore latente", "termogramma", "riflettere la tecnica del segnale luminoso", "dissetare"]}
{"file_name": "S0045782514001947", "text": "La nostra procedura non affronta il problema di come le parametrizzazioni possono variare per diversi tipi di flusso. Tuttavia, Edeling et al. [9] hanno effettuato calibrazioni separate per una serie di 13 flussi di strato limite. Hanno riassunto queste informazioni attraverso le calibrazioni calcolando gli intervalli di densit\u00e0 posteriore pi\u00f9 alta (HPD) e successivamente rappresentano l'incertezza totale della soluzione con una casella di probabilit\u00e0 (p-box). Questo p-box rappresenta sia la variabilit\u00e0 dei parametri tra i flussi, sia l'incertezza epistemica all'interno di ciascuna calibrazione. Viene effettuata una previsione di un nuovo flusso dello strato limite con le barre di incertezza generate da queste informazioni sull'incertezza e la stima dell'errore risultante si dimostra coerente con i dati di misurazione. Questo approccio \u00e8 utile, ma potrebbe essere ulteriormente esteso modellando la prossimit\u00e0 tra i flussi attraverso una distanza che sia correlata alle caratteristiche del flusso al fine di prendere in prestito la forza attraverso le calibrazioni invece di dividere le calibrazioni e quindi unire successivamente i risultati. Questo \u00e8 un luogo stimolante ma attraente per la ricerca futura.", "keyphrases": ["hpd", "tane posteriori pi\u00f9 alte", "dividere il calibro e quindi unire l'outcom", "flusso al confine", "fluire", "p-box", "modello prossimale attraverso il flusso", "scatola delle probabilit\u00e0", "parametro"]}
{"file_name": "S0038092X14004824", "text": "Storicamente, l\u2019interesse per una misurazione accurata del DNI \u00e8 iniziato decenni fa. I primi studi (Linke, 1931; Linke e Ulmitz, 1940) identificarono la difficolt\u00e0 di separare la misurazione del DNI da quella dell'irradianza diffusa nelle immediate vicinanze del sole, di seguito denominata irradianza circumsolare. Pastiels (1959) condusse uno studio dettagliato sulla geometria dei pireliometri e su come tale geometria interagisse con la radianza circumsolare, utilizzando rappresentazioni semplificate di quest'ultima. Varie comunicazioni furono poi presentate in una riunione del gruppo di lavoro dell'OMM tenutasi in Belgio nel 1966 (WMO, 1967) per migliorare l'accuratezza delle misurazioni pireliometriche, comprese le stime dell'aumento circumsolare. \u00c5ngstr\u00f6m (1961) e \u00c5ngstr\u00f6m e Rohde (1966) contribuirono successivamente allo stesso argomento, seguiti anni dopo da Major (1973, 1980). L\u2019intera questione della geometria dello strumento rispetto all\u2019irradiazione circumsolare era complessa e confusa all\u2019epoca perch\u00e9 diverse marche e modelli di strumenti avevano geometrie diverse. Ci\u00f2 \u00e8 stato notevolmente semplificato dopo che la WMO ha pubblicato delle linee guida sulla geometria raccomandata dei pireliometri, che hanno portato a una geometria relativamente \u201cstandard\u201d utilizzata in tutti gli strumenti recenti. Le questioni sperimentali relative alla misurazione del DNI sono discusse nella Sezione 3.2.", "keyphrases": ["pireliomet", "studi delle geometrie dei pireliometri, e di come tali geometri interagiscono con il radiante circumsolare", "separare la misura del dni da quella del diffuso irradi nelle immediate vicinanze del sole", "migliorare l'accuratezza delle misurazioni del pireliometro, inclusa la stima del miglioramento circumsolare"]}
{"file_name": "S0045782513001448", "text": "Tradizionalmente, la simulazione del flusso di fluido incomprimibile con il metodo SPH avviene attraverso una formulazione SPH debolmente comprimibile (WCSPH). In questo approccio, la pressione viene trattata come una variabile termodinamica e viene calcolata utilizzando un'equazione di stato artificiale. La velocit\u00e0 del suono \u00e8 impostata per essere sufficientemente elevata da limitare le variazioni di densit\u00e0 entro una piccola frazione della densit\u00e0 effettiva del fluido. In pratica, questa elevata velocit\u00e0 del suono pone una limitazione sulla dimensione massima consentita del passo temporale attraverso il vincolo di Courant-Friedrichs-Lewy (CFL). Una particolare debolezza riguarda il rumore nel campo di pressione poich\u00e9 una piccola perturbazione nella densit\u00e0 locale produrr\u00e0 una grande variazione nella pressione locale. Ci\u00f2 pu\u00f2 rendere le formulazioni WCSPH inefficaci per una previsione accurata di forza e pressione, sebbene i recenti sviluppi che creano distribuzioni di particelle pi\u00f9 uniformi abbiano migliorato questo aspetto [1,2]. Una revisione del metodo SPH pu\u00f2 essere trovata in [3] mentre una revisione della formulazione classica WCSPH applicata ai flussi a superficie libera pu\u00f2 essere trovata in [4].", "keyphrases": ["simultaneo del flusso del fluido incompresso", "particl", "artifici equat di stato", "metodo sph", "wcsph", "flusso a superficie libera", "crea una distribuzione delle particelle pi\u00f9 uniforme", "fluido", "flusso del fluido", "debolezza comprimere la formula sph"]}
{"file_name": "S0045782515002418", "text": "Gli schemi FR sono simili agli schemi DG nodali, che sono probabilmente il tipo pi\u00f9 popolare di metodo non strutturato di ordine elevato (almeno nel campo dell'aerodinamica computazionale). Come gli schemi DG nodali, gli schemi FR utilizzano una base polinomiale di ordine elevato (nodale) per approssimare la soluzione all'interno di ciascun elemento del dominio computazionale e, come gli schemi DG nodali, gli schemi FR non impongono esplicitamente la continuit\u00e0 della soluzione tra elementi. Tuttavia, a differenza degli schemi DG nodali, i metodi FR si basano esclusivamente sul sistema di governo in forma differenziale. Di seguito viene presentata una descrizione dell'approccio FR in 1D. Per ulteriori informazioni vedere l'articolo originale di Huynh [2].", "keyphrases": ["dominio informatico", "di alto livello", "schema fr", "metodo fr", "approssimare la soluzione", "calcolare l'aerodinamica", "approccio fr", "applicare inter-el solut continu", "nodale", "metodo di alto livello della struttura", "schema dg nodale"]}
{"file_name": "S0168365913009036", "text": "Sono stati valutati due metodi di formulazione di nanocomplessi anionici. In entrambi, i nanocomplessi sono stati preparati in acqua in un intervallo di rapporti di carica molare da L a D mentre il rapporto di carica molare del peptide P a D \u00e8 stato mantenuto costante a 3:1. Metodo 1 (L:D:P): il DNA \u00e8 stato prima aggiunto a un liposoma anionico (LA, LAP1 o LAP2) e incubato per 15 minuti a temperatura ambiente, quindi il peptide \u00e8 stato aggiunto con miscelazione rapida e incubato a temperatura ambiente per altri 20 minuti ; Metodo 2 (P:D:L): il peptide \u00e8 stato aggiunto al DNA e incubato per 15 minuti a temperatura ambiente, quindi \u00e8 stato aggiunto il liposoma con miscelazione rapida e incubato a temperatura ambiente per altri 20 minuti. Indipendentemente dal metodo di ordine di miscelazione, tutti i rapporti di carica molare in questo studio si riferiscono a L:P:D. Le formulazioni cationiche LPD e LCPRGPD sono state preparate nell'ordine L:P:D come descritto in precedenza; innanzitutto, il peptide \u00e8 stato aggiunto al liposoma DOTMA/DOPE o LCPRG, seguito dall'aggiunta del DNA con miscelazione rapida e incubato per 30 minuti a temperatura ambiente per consentire la formazione del complesso [30]. I nanocomplessi preparati sono stati denominati LPD (liposoma DOTMA/DOPE), LADP e PDLA (liposoma LA), PDLAP1 (liposoma LAP1), PDLAP2 (liposoma LAP2), PDLAPRG (liposoma LAPRG) e LCPRGPD (liposoma LCPRG).", "keyphrases": ["un liposoma anionico", "miscelazione rapida e incubazione", "pdlap1", "nanocomplesso", "pdla", "ladp", "incubo", "liposomi lcprg", "preparare", "giro liposomiale2", "lpd", "lcprgpd", "dna", "liposomiale laprg", "liposomiale la", "anno Domini", "pdlaprg", "la, giro1 o giro2", "liposomi dotma/dop", "nanocomplesso anionico della formula", "lcprg", "pdlap2", "liposomiale", "punto", "droga", "peptide", "giro liposomiale1"]}
{"file_name": "S0370269304007257", "text": "Alcuni accoppiamenti non standard, che dovrebbero essere determinati qui, potrebbero anche essere studiati nell'opzione standard e+e\u2212 di un collisore lineare. Vale quindi la pena di confrontare la potenza potenziale delle due opzioni. Per quanto riguarda il parametro \u03b1\u03b31, il collisore \u03b3\u03b3 non ne consente la determinazione, mentre potrebbe essere determinato in e+e\u2212. Il secondo accoppiamento tt\u0304\u03b3 \u03b1\u03b32, che \u00e8 proporzionale alla parte reale del momento di dipolo elettrico del quark top,44Vedi [23] tenendo conto del fatto che gli operatori OuB, OqB e OqW sono ridondanti, pu\u00f2 essere misurato qui. Va ricordato che le distribuzioni di energia e angolo polare dei leptoni e dei quark b nei collisori e+e\u2212 sono sensibili solo alla parte immaginaria del momento di dipolo elettrico,55 Tuttavia, va sottolineato che esistono osservabili sensibili anche al momento di dipolo elettrico. parte reale del momento di dipolo elettrico del quark top, si veda [24] mentre qui si potrebbe determinare la parte reale. Per la misura degli accoppiamenti \u03b3\u03b3H, i collisori e+e\u2212 sono, ovviamente, inutili, mentre in questo caso, per lo stato finale bX si potrebbero misurare sia \u03b1h1 che \u03b1h2. Nel caso della misurazione del fattore di forma del decadimento \u03b1d, l'opzione e+e\u2212 sembra essere un po' pi\u00f9 vantaggiosa, specialmente se la polarizzazione e+e\u2212 pu\u00f2 essere regolata in modo appropriato [25].", "keyphrases": ["collisione lineare", "e+e\u2212 collidono", "\u03b1h1 e \u03b1h2 potrebbero essere misurati", "Collisione \u03b3\u03b3", "immaginari parte del momento elettr dipol", "misura della coppia \u03b3\u03b3h", "opzione e+e\u2212", "Distribuzione dell'angolo polare del leptone e del quark b", "la vera parte del momento di dipolo elettr-quark top", "misura del fattore di forma del decadimento \u03b1d", "lo stato finale del bx", "e+e\u2212 polare", "accoppiamento non standard", "opzione e+e\u2212 standard", "potenza potente", "accoppiamento \u03b1\u03b32", "e+e\u2212", "parametro \u03b1\u03b31"]}
{"file_name": "S0888613X16300767", "text": "Tuttavia questa non \u00e8 solo una rappresentazione utile di un apposito modello statistico ben supportato. Se siamo disposti ad ammettere che il processo \u00e8 guidato da un CRG e che il modello MAP che abbiamo scoperto sta effettivamente generando il processo inattivo, allora identificare le componenti sconnesse del sistema ci consente di fare immediatamente asserzioni sull\u2019impatto dei vari controlli potremmo applicare a questo processo di regolamentazione \u2013 proprio come potremmo se credessimo che il modello fosse un\u2019estensione causale di una BN. Nel context dei microarray, l'obiettivo del clustering \u00e8 identificare modelli tra i dati e decidere su quali geni concentrarsi in ulteriori esperimenti pi\u00f9 gene-specifici. \u00c8 quindi necessario che lo scienziato faccia tali congetture causali sull'effetto dei controlli a sua disposizione sulle espressioni che riflettono il processo di regolamentazione sottostante che studia. Queste congetture possono essere universali o sfumate evocando idee di parsimonia.", "keyphrases": ["l'impatto dei vari controlli", "l'effetto del controllo", "congettura", "un modello statista ben supportato", "evoca l'idea di parsimoni", "miliardo", "processo inattivo", "modello di mappa", "grappolo", "modello identificativo tra i dati", "identificare il componente di disconnessione del sistema", "crg"]}
{"file_name": "S2212671612002120", "text": "In questo articolo viene discusso un metodo di progettazione per una piattaforma di simulazione di attacchi e difese di rete. Innanzitutto vengono analizzati i componenti e la funzione della piattaforma. Quindi viene utilizzato il secondo metodo di sviluppo di Visio per costruire la topologia della rete virtuale. Viene inoltre analizzata l'analisi della topologia della rete virtuale e descritto il relativo diagramma di flusso. Infine viene effettuato un esempio per testare le prestazioni della piattaforma. I risultati delle simulazioni mostrano l'efficacia del metodo proposto.", "keyphrases": ["rete virtuale", "eseguire la prova", "eseguire i test della piattaforma", "metodo di progettazione", "foglio di flusso relativo", "costruire la topologia della rete virtuale", "metodo di sviluppo di Visio Second", "attacco di rete", "difende la piattaforma simultanea", "parti della topologia della rete virtuale", "piattaforma"]}
{"file_name": "S221267161200217X", "text": "L'algoritmo della metodologia GO esistente \u00e8 teorico e difficile da risolvere con il computer. In questo articolo, ricerchiamo un nuovo metodo per ottenere l'affidabilit\u00e0 del sistema basato sulla metodologia GO. Secondo alcune propriet\u00e0 degli operatori nel grafico GO, il grafico GO pu\u00f2 essere trasformato in una struttura in serie, quindi gli insiemi di percorsi minimi vengono indotti in base al metodo di enumerazione dal primo all'ultimo operatore. \u00c8 molto conveniente per il computer calcolare l'affidabilit\u00e0 del sistema con il nuovo metodo basato su insiemi di percorsi minimi. Il caso di studio indica che il metodo \u00e8 adatto all'ingegneria pratica, che pu\u00f2 essere utilizzato per possedere l'analisi quantitativa di modelli metodologici GO complessi.", "keyphrases": ["analisi quantitativa", "struttura seriale", "vai al grafico", "motore pratico", "modello metodologico go complesso", "vai al metodo", "percorso minimo impostato", "nuovo metodo per ottenere l'affidabilit\u00e0 del sistema basato sul metodo go", "metodo enumerativo", "vai metodo algoritmo", "il percorso minimo impostato \u00e8 induc", "calcolare l'affidabilit\u00e0 del sistema"]}
{"file_name": "S0021999113002362", "text": "L'algoritmo consente la modellazione di plasmi di degenerazione arbitraria con l'approssimazione della collisione binaria. Utilizza un'interpolazione numerica della funzione di densit\u00e0 cumulativa inversa della distribuzione di Fermi-Dirac per inizializzare le particelle di simulazione e le collisioni sono soggette al blocco di Pauli. Non \u00e8 appropriato nel limite di un accoppiamento molto forte perch\u00e9 la teoria del plasma su cui si basa il codice Monte Carlo fallisce. Il limite di accoppiamento forte corrisponde a ln\u039b\u22723, dove ln\u039b \u00e8 il logaritmo di Coulomb [10]. Il codice \u00e8 progettato per ln\u039b>3 in plasmi collisionali con un livello di degenerazione non trascurabile. Si nota che tecniche Monte Carlo con capacit\u00e0 degenerate sono state sviluppate per studiare il trasporto nei semiconduttori [11] ma non esiste un metodo simile per i plasmi completamente ionizzati. Alcune delle tecniche descritte sono potenzialmente applicabili ad altri tipi di codici, ad esempio i codici Particle-In-Cell (PIC).", "keyphrases": ["distribuzione di fermi\u2013dirac", "codice Monte Carlo", "blocco Pauli", "limite di coppia forte", "logaritmo di Coulomb", "plasma", "numero interpol", "plasma di collisione", "coppia", "tecnica mont carlo", "collis binario approssimativo", "teoria del plasma", "simul particl", "plasma completamente ionico", "trasporto in semiconduttore", "collis", "modello di plasma di arbitrari degeneraci"]}
{"file_name": "S0885230816301759", "text": "Questo articolo propone un sistema di feedback sullo stress della frase in cui vengono combinati modelli di previsione, rilevamento e fornitura di feedback dello stress della frase. Questo sistema fornisce agli studenti non madrelingua un feedback sugli errori di stress delle frasi in modo che possano migliorare il ritmo e la fluidit\u00e0 dell'inglese in un context di studio autonomo. Il sistema di feedback sullo stress della frase \u00e8 stato ideato per prevedere e rilevare lo stress della frase di qualsiasi frase di pratica. L'accuratezza dei modelli di previsione e rilevamento \u00e8 stata rispettivamente del 96,6% e dell'84,1%. Il modello di fornitura del feedback sullo stress offre un feedback sullo stress positivo o negativo per ogni parola pronunciata confrontando la probabilit\u00e0 del modello di stress previsto con quella del modello di stress rilevato. In un esperimento che ha valutato l'effetto educativo del sistema proposto incorporato nel nostro sistema CALL, sono stati osservati miglioramenti significativi nell'accento e nel ritmo con gli studenti che si sono allenati con il nostro sistema ma non con quelli del gruppo di controllo.", "keyphrases": ["sistema di chiamata", "fornire agli studenti non-n feedback sull'errore di stress della frase", "sistema di feedback sullo stress delle frasi", "modello di feedback sullo stress fornito", "prevedere e rilevare l'accento della frase", "prevedere e rilevare il modello"]}
{"file_name": "S0010938X15300512", "text": "I processi di anodizzazione sono ampiamente utilizzati per proteggere le leghe di alluminio dalla corrosione [1]. I film risultanti sono composti da allumina amorfa e sono costituiti da una regione esterna relativamente spessa, porosa e da una regione interna pi\u00f9 sottile, non porosa [2,3]. La regione porosa contiene i pori principali della pellicola, che si estendono dalla superficie della pellicola allo strato barriera. In prossimit\u00e0 della superficie del film sono presenti anche pori incipienti pi\u00f9 corti, la cui crescita si \u00e8 arrestata nelle prime fasi dell'anodizzazione. Il diametro dei pori principali e lo spessore della regione interna della barriera dipendono dal potenziale applicato durante l'anodizzazione, con proporzionalit\u00e0 tipiche di ~1 nmV\u22121 [3,4]. Gli studi sulla migrazione ionica in film di allumina anodica porosi e di tipo barriera hanno solitamente rilevato un numero di trasporto di ioni O2\u2212 di circa 0,6 [5,6]. Durante la formazione di film porosi, gli ioni Al3+ che migrano verso l'esterno, che costituiscono il resto della corrente ionica, vengono espulsi nell'elettrolita alla base dei pori [7]. La corrente elettronica nella regione della barriera \u00e8 generalmente considerata trascurabile. Lo spessore della regione barriera, che \u00e8 relativamente costante durante la crescita di una pellicola a potenziale costante o a densit\u00e0 di corrente costante, \u00e8 mantenuto da un equilibrio tra la crescita dello strato barriera mediante la continua ossidazione del substrato di alluminio e l'assottigliamento della barriera strato mediante dissoluzione assistita sul campo dell'allumina alla base dei pori [8] o flusso assistito sul campo di allumina dallo strato barriera alle pareti dei pori [9\u201313]. I pori possono essere allargati verso la superficie della pellicola mediante dissoluzione chimica in una misura che dipende dalle condizioni di anodizzazione.", "keyphrases": ["pellicola di allumina anodica", "flusso di allumina assistito sul campo", "sottile dello strato barriera mediante la dissoluzione dell'assistenza sul campo", "allumina", "corrode", "ossido", "espellere", "base dei pori", "disciolto chimico", "poro maggiore", "poro incipit", "processo anodico", "parete dei pori", "film risultato", "arresto della crescita nella fase iniziale dell'anod", "allumina amorfa", "superficie della pellicola", "corrente ionica", "ione o2\u2212", "pellicola porou", "substrato di alluminio", "proteggere la lega di alluminio", "un cenno", "ione al3+ migratore verso l'esterno", "regione barriera", "estendersi dalla superficie della pellicola", "film", "migrazione ionica", "strato barriera", "poro", "elettrolita", "crescita dello strato barriera da parte dell'ossido continuo"]}
{"file_name": "S0167931714000203", "text": "Limitare la crescita del tubo pollinico a un singolo piano focale \u00e8 un argomento importante per consentire la loro accurata analisi della crescita sotto osservazione microscopica. Nel metodo convenzionale per analizzare la crescita dei tubi pollinici, i tubi pollinici crescono in modo disordinato su un mezzo solido, rendendo impossibile osservarne la crescita in dettaglio. Qui presentiamo un nuovo metodo per analizzare la crescita del tubo pollinico utilizzando un dispositivo a microcanali poli-dimetilsilossano per isolare i singoli tubi pollinici. La crescita del tubo pollinico \u00e8 confinata al microcanale e allo stesso piano focale, consentendo osservazioni microscopiche accurate. Questa metodologia ha il potenziale per analizzare la crescita dei tubi pollinici in ambienti microfluidici in risposta a prodotti chimici e molecole di segnalazione, aprendo la strada a vari esperimenti sulla riproduzione delle piante.", "keyphrases": ["accu osservazione al microscopio", "analisi della crescita del tubo pollinico,", "dispositivo microcanali poli-dimetilsilossano", "analisi del tubo pollinico", "molecola segnale", "nuovo metodo per analizzare la crescita del tubo pollinico", "tubo pollinico isol individu", "osservare la loro crescita in dettaglio.", "esperimento sulla riproduzione vegetale", "riproduzione vegetale", "crescere il tubo pollinico", "limitare la crescita del tubo pollinico su un unico piano focale", "crescita del tubo pollinico", "analisi della crescita del tubo pollinico", "tubo pollinico", "prodotto chimico", "analisi della crescita del tubo pollinico", "analisi della crescita al microscopio, osservazione"]}
{"file_name": "S2212671612000698", "text": "In Il rilevamento degli ostacoli si basa sulla mappatura prospettica inversa e sull'omografia. La classificazione degli ostacoli si basa sulla rete neurale fuzzy. La stima del punto di fuga si basa sulla strategia di estrazione delle caratteristiche. Il metodo sfrutta le relazioni geometriche tra gli elementi della scena in modo che l'ostacolo possa essere rilevato. L'omografia stimata del piano stradale tra immagini successive viene utilizzata per l'allineamento delle immagini. Viene descritto un nuovo metodo di fusione decisionale fuzzy con attribuzione fuzzy per il rilevamento degli ostacoli e l'applicazione di classificazione. La funzione di decisione fuzzy modifica i parametri con un algoritmo auto-adattato per ottenere una migliore probabilit\u00e0 di classificazione. \u00c8 dimostrato che il metodo pu\u00f2 ottenere risultati di classificazione migliori.", "keyphrases": ["metodo di fusione fuzzi decis", "rilevare", "algoritmo di autoadattamento", "immagine", "classif", "elemento", "allineamento immagine", "rilevamento degli ostacoli e classificazione dell'applicazione", "scena", "ostacolo", "aereo stradale", "Attributo fuzzi per il rilevamento degli ostacoli e l'applicazione classifica", "rete neurale fuzzi", "stima del punto di fuga", "strategia di estrazione delle caratteristiche", "relaz.geometria", "classe di ostacolo", "rilevamento degli ostacoli", "stima homographi", "mappa prospettica inversa e homographi", "la funzione fuzzi decis"]}
{"file_name": "S0032386109006612", "text": "A differenza dei polimeri, che vengono tipicamente sintetizzati in fase liquida, gli SWNT vengono prodotti attraverso una variet\u00e0 di tecniche di sintesi che tipicamente comportano la reazione di una materia prima gassosa di carbonio per formare i nanotubi sulle particelle catalitiche. I MWNT sono stati osservati per la prima volta nei reattori fullerene con scarica ad arco [1,26]; questa tecnica \u00e8 stata successivamente adattata per produrre SWNT [3]. Allo stesso modo, il metodo di produzione del fullerene mediante ablazione laser [27] \u00e8 stato adattato per produrre SWNT (\u223c1,4 nm di diametro) in quantit\u00e0 maggiori su particelle di catalizzatore metallico [28-30]. Sono stati sviluppati numerosi processi di deposizione chimica in fase vapore (CVD) per far crescere SWNT e MWNT, tutti coinvolgendo la reazione di un composto di carbonio gassoso come materia prima. Questi processi includono il letto fluidizzato [31], la crescita \u201ca tappeto\u201d di nanotubi di carbonio (CNT) da particelle catalitiche incorporate in un substrato [32\u201335] come mostrato nella Figura 3 e il \u201cflusso di gas catalitico CVD\u201d [36,37]. Una delle tecniche CVD pi\u00f9 efficaci, economiche e scalabili \u00e8 il processo HiPco (CO ad alta pressione), che non utilizza particelle catalitiche preformate a differenza della maggior parte delle altre tecniche CVD [38].", "keyphrases": ["questa tecnica", "processo hipco (co-alta pressione).", "particolato catalizzatore metallico", "la tecnica CVD pi\u00f9 efficace, economica e scalabile", "la reazione di un composto gassoso o di carbonio come materia prima", "nanotubo di carbonio", "tecnica cvd", "cvd", "\u201ccatalizzatore ga flusso cvd\u201d", "cnt", "prodotto attraverso una variet\u00e0 di tecniche di sintesi", "mwnt", "deposito di vapori chimici", "swnt", "sintetizza in fase liquida", "letto fluidizzato", "polim", "il metodo del prodotto fulleren dell'ablazione laser", "la reazione di una materia prima di carbonio gassoso per formare il nanotubo su particelle catalitiche", "Crescita \u201ca tappeto\u201d di nanotubi di carbonio (cnts) da particelle di catalizzatore incorporate in un substrato", "osservare nel reattore fulleren con scarica ad arco", "non utilizzare particelle catalitiche preformate"]}
{"file_name": "S2212671612000431", "text": "In questo articolo viene presentata un'implementazione di un sistema di riconoscimento facciale veloce basato su LBP (modello binario locale) su piattaforma Symbian. Innanzitutto, il volto nell'immagine scattata dalla fotocamera viene rilevato utilizzando l'algoritmo AdaBoost. In secondo luogo, viene eseguita la pre-elaborazione del viso, inclusa la posizione degli occhi, la normalizzazione geometrica e la normalizzazione dell'illuminazione. Durante la preelaborazione del volto, viene proposto e implementato un metodo rapido di localizzazione degli occhi denominato ER (Eyeball Search). Infine, per il riconoscimento viene adottato il LBP migliorato. Sebbene la capacit\u00e0 computazionale della piattaforma Symbian sia limitata, i risultati sperimentali mostrano buone prestazioni in termini di velocit\u00e0 di riconoscimento e tempo di stampa. In questo articolo viene presentata un'implementazione di un sistema di riconoscimento facciale veloce basato su LBP (modello binario locale) sulla piattaforma Symbian. Innanzitutto, il volto nell'immagine scattata dalla fotocamera viene rilevato utilizzando l'algoritmo AdaBoost. In secondo luogo, viene eseguita la pre-elaborazione del viso, inclusa la posizione degli occhi, la normalizzazione geometrica e la normalizzazione dell'illuminazione. Durante la preelaborazione del volto, viene proposto e implementato un metodo rapido di localizzazione degli occhi denominato ER (Eyeball Search). Infine, per il riconoscimento viene adottato il LBP migliorato. Sebbene la capacit\u00e0 computazionale della piattaforma Symbian sia limitata, i risultati sperimentali mostrano buone prestazioni per quanto riguarda il tasso di riconoscimento e il tempo di stampa", "keyphrases": ["modello binario locale", "geometria normale", "illumina normale", "preprocesso del volto", "ehm", "ricerca oculare", "lbp", "preprocesso", "riconoscere", "pre-processo del viso", "posizione dell'occhio, normalizzazione della geometria, illuminazione normale", "riconoscimento facciale", "algoritmo adaboost", "piattaforma Symbian", "localizzazione dell'occhio", "sistema di riconoscimento facciale", "metodo di localizzazione dell'occhio"]}
{"file_name": "S136481521630305X", "text": "Utilizzando i dati misurati da due siti arabili nel Regno Unito abbiamo dimostrato che i ritardi possono avere un impatto significativo sulla valutazione del modello e possono influenzare sia il livello di correlazione tra i dati misurati e simulati sia l'entit\u00e0 delle somme dei residui. Inoltre, abbiamo utilizzato la divisione del MSE in tre statistiche costituenti (SB, SDSD e LCS) per mostrare come il livello di correlazione pu\u00f2 influenzare la somma dei residui. Dividendo la serie di valori di ritardo previsti dall'algoritmo in serie mensili ed esaminando la distribuzione di frequenza dei ritardi, sono stati identificati alcuni modelli in queste serie temporalmente irregolari. Un compito impegnativo in relazione agli sfasamenti temporali tra i dati giornalieri osservati e quelli simulati \u00e8 determinarne la causa. Questo compito diventa pi\u00f9 difficile per i risultati del modello come le emissioni di N2O del suolo che sono guidate da varie variabili interagenti. Ancor di pi\u00f9, poich\u00e9 i set di dati misurati di N2O e i set di dati misurati dei loro fattori determinanti (umidit\u00e0 del suolo, contenuto di N del suolo) coprono periodi di tempo brevi, non sono continui e possono variare ampiamente in termini di dimensioni. In questo studio abbiamo implementato l'algoritmo utilizzando dati misurati e simulati per l'umidit\u00e0 del suolo (primo e secondo esempio) e N minerale del suolo (secondo esempio) e abbiamo confrontato i suoi risultati con i rispettivi risultati per N2O. Nel nostro primo esempio, abbiamo dimostrato che i ritardi stimati nella previsione di N2O sono correlati ai ritardi nella previsione dell\u2019umidit\u00e0 del suolo in un modo che cambia gradualmente nel tempo. Nel nostro secondo esempio, i ritardi nella previsione dell\u2019N2O sono stati spiegati dai ritardi nell\u2019umidit\u00e0 del suolo e nella previsione dell\u2019N minerale del suolo, con i quali avevano una relazione positiva.", "keyphrases": ["prevedere l'umidit\u00e0 del suolo", "dati di misurazione e simulazione dell'umidit\u00e0 del suolo", "set di dati n2o", "mse", "SDSD", "minatore del suolo n", "l.c", "costitu statista", "emissione di n2o", "valutazione del modello", "n2o prevedere", "sb", "minatore del suolo n prevedere", "umidit\u00e0 del suolo", "n2o"]}
{"file_name": "S0032386109001463", "text": "Quando catene polimeriche a tre componenti incompatibili sono legate in un punto di giunzione, le molecole stellari risultanti del tipo ABC si trovano in un campo molto frustrato. Cio\u00e8, i loro punti di giunzione non possono essere allineati su piani bidimensionali ma su linee unidimensionali, come mostrato schematicamente nella Figura 1. Inoltre, quando la differenza di lunghezza della catena non \u00e8 cos\u00ec grande, la schiera di punti di giunzione tende ad essere diritta e lungo. Di conseguenza ogni dominio con dimensioni mesoscopiche diventa cilindri e le loro sezioni trasversali potrebbero essere conformate da poligoni [28,29]. Questo perch\u00e9 \u00e8 probabile che tre interfacce, A/B, B/C e C/A siano piatte poich\u00e9 non esistono punti di giunzione sulle interfacce e quindi il contributo di entropia della catena all'energia libera della formazione della struttura \u00e8 considerevolmente piccolo rispetto ai blocchi regolari e sistemi di copolimeri ad innesto. \u00c8 un dato di fatto, Dotera ha previsto diversi modelli di piastrellatura con il metodo del legame diagonale, una nuova simulazione Monte Carlo [30], mentre Gemma e Dotera hanno sottolineato che solo tre piastrellature regolari, cio\u00e8 (6.6.6), (4.8.8 ) e (4.6.12) sono consentiti per molecole a tre ramificazioni proposte come \u201cteorema del poligono pari\u201d [31].", "keyphrases": ["molecola a tre rami", "tre interfacce, a/b, b/c e c/a", "molecola stellare", "catena polimerica", "cilindro", "poligono", "metodo del legame diagonale", "catena entropica", "Monte Carlo simul", "anche teorema del poligono"]}
{"file_name": "S1877750315300119", "text": "Espansioni del caos polinomiale generalizzato. Un approccio per modellare le densit\u00e0 con componenti numericamente dipendenti stocasticamente \u00e8 quello di riformulare il problema dell'incertezza come un insieme di componenti indipendenti attraverso l'espansione del caos polinomiale generalizzato [34]. Come descritto in dettaglio nella Sezione 3.1, una trasformazione di Rosenblatt consente la mappatura tra qualsiasi dominio e l'ipercubo unitario [0, 1]D. Con una doppia trasformazione possiamo riformulare la funzione di risposta f asf(x,t,Q)=f(x,t,TQ\u22121(TR(R)))\u2248f\u02c6(x,t,R)=\u2211n\u2208INcn (x,t)\u03a6n(R),dove R \u00e8 una qualsiasi variabile casuale estratta da pR, che per semplicit\u00e0 si sceglie sia costituita da componenti indipendenti. Inoltre, {\u03a6n}n\u2208IN \u00e8 costruito per essere ortogonale rispetto a LR, non a LQ. In ogni caso, R viene selezionato dallo schema Askey-Wilson o calcolato utilizzando la procedura discretizzata di Stieltjes. Notiamo che l'accuratezza dell'approssimazione peggiora se la composizione della trasformazione TQ\u22121\u2218TR non \u00e8 regolare [34]. Dakota, Turns e Chaospy supportano tutti le espansioni del caos polinomiale generalizzato per variabili stocastiche indipendenti e la copula Normale/Nataf elencata nella Tabella 2. Poich\u00e9 Chaospy ha la trasformazione di Rosenblatt alla base della struttura computazionale, le espansioni del caos polinomiale generalizzato sono infatti disponibili per tutte le densit\u00e0.", "keyphrases": ["schema askey-wilson", "procedura stieltj discreta", "densit\u00e0 del modello", "quadro informatico", "generalis polynomi chao si espande", "problema delle incertezze", "trasformata di rosenblatt", "gener polinomi chao si espande"]}
{"file_name": "S0045782514001492", "text": "La conservazione dell'energia \u00e8 fondamentale per garantire la stabilit\u00e0 di un metodo numerico, in particolare per problemi di contatto e collisione [28,43]. Sono stati sviluppati numerosi schemi di conservazione per garantire il risparmio energetico. Questi schemi fanno uso della penalizzazione del vincolo di contatto normale ed ereditano la propriet\u00e0 di conservazione dai problemi del continuo. Questi schemi di conservazione possono essere convenientemente combinati con il metodo degli elementi finiti per simulare il contatto e la collisione senza attrito [44] e con attrito [43]. Hesch e Betsch [45] hanno formulato il metodo di contatto nodo-segmento e hanno risolto problemi di contatto con grandi deformazioni con lo schema conservativo. Pi\u00f9 recentemente, \u00e8 stato sviluppato uno schema di discretizzazione temporale a conservazione di energia e momento [46] per problemi di contatto adesivo senza considerare l'attrito e la dissipazione. Anche se lo schema conservativo migliora la stabilit\u00e0 numerica, eredita dal metodo penalizzante anche la difficolt\u00e0 di dover determinare i parametri penalizzanti. Per eliminare la sensibilit\u00e0 alle penalit\u00e0, Chawla e Laursen [47] hanno proposto un algoritmo di conservazione dell\u2019energia e della quantit\u00e0 di moto, che fa uso di moltiplicatori di Lagrange invece di parametri di penalit\u00e0.", "keyphrases": ["penalit\u00e0 reg", "metodo di contatto da nodo a segmento", "schema di conservazione", "risparmio energetico", "dissipare", "Schema discreto dell'energia e della quantit\u00e0 di moto-conservazione del tempo", "attrito", "grosso problema di contatto deformato", "Algoritmo di conservazione dell'energia e della quantit\u00e0 di moto", "problema di contatto con l'adesivo", "simultaneo attrito [44] e attrito [43] contatto e collisione", "problema di contatto e collisione", "problema del continuo", "metodo degli elementi finiti"]}
{"file_name": "S2212671612002375", "text": "Il sistema esperto di ragionamento Power Grid \u00e8 un sistema complesso. Per risolvere la condivisione della conoscenza della base di conoscenza nel sistema esperto, astraiamo e analizziamo la procedura di indagine sulla sicurezza della rete elettrica utilizzando la tecnologia ontologica. Con la base di conoscenza Power Grid basata sull'ontologia, stabiliamo una relazione associata tra i vocabolari delle procedure. In questo articolo, introduciamo e analizziamo strumenti di ragionamento semantico come Jena. Il meccanismo del ragionatore e le regole di inferenza della grammatica sono stati inclusi e spiegati. Infine diamo un'applicazione specifica dell'ontologia e del ragionamento delle procedure investigative sulla sicurezza.", "keyphrases": ["strumento per la ragione semantica", "sistema esperto", "ragione meccanica", "Ontologo e motivazione della procedura di indagine sicura", "condivisione della conoscenza di base nel sistema esperto", "Procedura di indagine sicura sulla rete elettrica", "Applicazione specifica della procedura di investigazione sicura, ontologo e motivazione", "relazione associ dei vocabulari procedurali", "tecnologia ontologica", "introdurre e analizzare lo strumento della ragione semantica", "base di conoscenza", "astrarre e analizzare la procedura di indagine sicura della rete elettrica", "dedurre una regola grammaticale", "Jena", "sistema esperto del motivo della rete elettrica", "sistema", "base di conoscenza della rete elettrica ontology-bas"]}
{"file_name": "S0301010415002256", "text": "Per decenni, i modelli di accoppiamento vibronico [1\u20134] sono serviti da ponti che collegano gli studi di dinamica nucleare con gli studi statici di calcoli di strutture elettroniche [5]. Il modello di accoppiamento vibronico \u00e8 una semplice espansione polinomiale di superfici e accoppiamenti di energia potenziale diabatica. I coefficienti di espansione sono scelti in modo che gli autovalori dell'operatore potenziale si trasformino nelle superfici potenziali adiabatiche. Questa diabatizzazione da parte di ansatz aggira molti dei problemi legati alla descrizione dei sistemi non adiabatici. \u00c8 anche l'ispirazione per uno schema di diabatizzazione utilizzato nei moderni metodi dinamici diretti che includono effetti non adiabatici [6]. Affinch\u00e9 un modello hamiltoniano approssimi correttamente gli autovettori del vero hamiltoniano, deve coprire la rappresentazione irriducibile totalmente simmetrica (IrRep) dei gruppi puntuali a cui appartiene la molecola, nelle geometrie simmetriche appropriate [7]. In tempi recenti, molti articoli hanno dimostrato i vantaggi dell'utilizzo della simmetria nella costruzione dei potenziali del modello analitico [8\u201312], molto spesso nel context di gruppi di permutazione-inversione [13].", "keyphrases": ["calcolo della struttura elettronica", "rappresentare irriducibile", "sistema non adiabatico", "geometrie simmetriche", "modello con accoppiamento vibrante", "metodo dinamico diretto", "diabat potenti energi surfac e coupl", "modello di analita potente", "il polinomio si espande", "vero hamiltoniano", "diabatis", "schema diabatis", "espande i coefficienti", "modello hamiltoniano", "studi sulla dinamica nucleare", "gruppo permutazione-inverso", "irrep"]}
{"file_name": "S0022311514000919", "text": "La curva tratteggiata rappresenta la frazione molare di PuO2 sulla superficie del campione. Mostra che, seguendo i confini di fase UO2\u2013PuO2, piuttosto ben stabiliti in questo intervallo compositivo (vedere la Sezione 4.3 di seguito), la superficie liquida appena formata \u00e8 inizialmente arricchita in biossido di plutonio. Successivamente, a causa della rapida diffusione in fase liquida, la composizione iniziale del campione (x(PuO2)=0,25) tende a ripristinarsi rapidamente. \u00c8 comunque chiaro, dalla simulazione, che il rapido raffreddamento che avviene dopo la fine dell'impulso laser porta all'inizio della solidificazione prima che la composizione iniziale sia completamente recuperata nel liquido. Una crosta solida superficiale si forma quindi dopo il congelamento prima che la massa liquida totale si sia cristallizzata (vedere i riquadri nella Figura 4). La doppia inflessione durante il raffreddamento corrisponde in questo caso all'inizio della solidificazione sulla superficie del campione (prima inflessione) e alla scomparsa dell'ultimo liquido all'interno del materiale (seconda inflessione). La temperatura di ricalescenza pi\u00f9 alta rappresenta il punto di solidificazione di una composizione molto vicino a quella iniziale (circa \u00b10,01 su x(PuO2) nell'esempio corrente), ad eccezione di piccoli effetti di segregazione. Questi ultimi sono stati studiati anche sperimentalmente nella presente ricerca, mediante caratterizzazione dei materiali post-fusione.", "keyphrases": ["puo2", "solidif", "liquido", "superficie del campione", "Freddo", "Confini di fase uo2\u2013puo2", "simul", "congelare", "superficie liquida", "piccolo effetto segregante", "crosta solida superficiale", "impulso laser", "arricchire in biossido di plutonio", "caratteristiche del materiale post-fusione", "biossido di plutonio"]}
{"file_name": "S0370269304008974", "text": "Pertanto, l'estensione all'analogo incantato \u0398c(3099) fornisce un test interessante per la regola della somma SDO e per i calcoli del reticolo [17]. Qui, il quark charm \u00e8 piuttosto pesante, quindi l'immagine dei quark costituenti pu\u00f2 adattarsi bene e ci si aspetta che la previsione di JW per la parit\u00e0 venga riprodotta dalla QCD. Infatti, il calcolo del reticolo spento rileva che la parit\u00e0 di \u0398c(3099) \u00e8 positiva [28]. Nell'estensione alle regole di somma \u0398c(3099), ci sono due aspetti importanti che rendono questa regola di somma diversa dalla regola di somma SDO. Innanzitutto, poich\u00e9 il quark charm \u00e8 troppo pesante per formare condensato di quark, d\u00e0 effetti non perturbativi solo irradiando gluoni. Il condensato misto quark-gluoni \u3008s\u0304gs\u03c3\u00b7Gs\u3009, che era il contributo importante nella regola della somma \u0398+, \u00e8 sostituito da operatori gluonici nell'espansione dei quark pesanti che normalmente sono soppressi. In secondo luogo, la massa del quark charm deve essere mantenuta finita nell'OPE, cosa che pu\u00f2 essere fatta utilizzando l'espressione dello spazio del momento per il propagatore del quark charm. Questo \u00e8 diverso dalla regola della somma dei quark leggeri in cui il calcolo viene eseguito nello spazio delle coordinate e tutti i propagatori dei quark sono ottenuti in base all'espansione con la massa del quark piccolo. Tenendo presenti questi due aspetti, costruiamo le regole di somma QCD per \u0398c(3099) e vediamo come sono diverse dalla regola di somma \u0398+(1540).", "keyphrases": ["sostituzione con l'operazione gluonica nell'espansione dei quark pesanti", "s\u0304gs\u03c3\u00b7g", "immagine dei quark costituenti", "regola della somma", "jw prevedere", "temprare il calcolo lattico", "la regola della somma dei quark leggeri", "quark fascino", "gluone radiato", "Regola della somma \u03b8+", "spazio di slancio espresso", "regola della somma qcd", "propagazione dei quark", "opera gluonica", "La miscela quark-gluoni si condensa", "si estende al fascino analogu \u03b8c(3099)", "regola della somma sdo", "guarda come differiscono dalla regola di somma \u03b8+(1540).", "il quark si condensa", "regola della somma sdo e calcolo lattico", "piccolo quark", "qcd", "op", "La massa del quark charm deve essere mantenuta finita nell'opera", "quark pesante", "propagazione del quark charm"]}
{"file_name": "S0022311515002354", "text": "Gli idruri, una volta precipitati nello zirconio, degradano le propriet\u00e0 meccaniche di un componente, portando a riduzioni della resistenza alla trazione, della duttilit\u00e0 e della resistenza alla frattura [35\u201340]. Questi cambiamenti possono in definitiva compromettere l\u2019integrit\u00e0 del rivestimento durante la normale vita operativa, le condizioni di incidente e lo stoccaggio del carburante [13]. Oltre al degrado delle propriet\u00e0 meccaniche, la presenza di idruri pu\u00f2 influenzare anche fenomeni come l'interazione meccanica del rivestimento del pellet (PCMI); o introdurre meccanismi di guasto, come il cracking ritardato dell'idruro (DHC). Il primo meccanismo \u00e8 il prodotto dell\u2019espansione termica nei pellet di combustibile che introduce tensioni nel rivestimento, che possono quindi portare alla formazione di crepe in aree rese fragili da grandi concentrazioni di idruri [13]. Quest'ultimo meccanismo, DHC, \u00e8 un fenomeno di cracking subcritico, dipendente dal tempo, che richiede la diffusione dell'idrogeno a lungo raggio per la ripetuta crescita locale dell'idruro e la frattura in corrispondenza di un aumento dello stress di trazione idrostatica [5,41,42]. Il processo avviene per un lungo periodo di tempo sotto un carico applicato continuamente che \u00e8 inferiore al carico di snervamento del materiale [5,41,42].", "keyphrases": ["pcmi", "pellet di combustibile", "rivestito", "sollevatore di sforzo di trazione idrostatico", "dilatazioni termiche", "il meccanismo rivestito di pellet interagisce", "ritardare la cricca idrica", "idrogeno", "zirconio", "idrato", "crescita idrica locale", "fenomeno delle crepe", "carburante", "idrogeno diffuso", "dhc"]}
{"file_name": "S2212667814000380", "text": "Il comportamento della trave cellulare \u00e8 descritto utilizzando metodi di progettazione conformi alla norma BS: 5950, considerando in particolare la resistenza delle sezioni a T e dell'elemento del montante d'anima. Tale comportamento deriva dallo studio parametrico che coinvolge l'analisi degli elementi finiti utilizzando il software ANSYS. Il metodo di progettazione si basa sull'analisi plastica della sezione della trave ai carichi ultimi e sull'analisi elastica ai carichi di esercizio. Viene illustrata la procedura di progettazione della trave cellulare e viene elaborato un esempio basato sul metodo di progettazione e viene effettuata la sua verifica per verificarne l'idoneit\u00e0.", "keyphrases": ["la procedura di progettazione del fascio cellulare \u00e8 illustrata", "fascio cellulare", "ansi", "metodo di progettazione", "analisi elast", "analisi plastica della sezione della trave", "analisi degli elementi finiti"]}
{"file_name": "S0009261413006738", "text": "I PES qui utilizzati sono gi\u00e0 stati testati per verificarne la validit\u00e0 per scopi dinamici. Tali test includono studi della reazione di scambio dell'azoto [14] sia adiabatica eseguendo traiettorie sulle superfici pi\u00f9 basse, sia non adiabatica utilizzando il metodo TSH (Trajectory Surface Hoping) [22,23] per le transizioni allo stato eccitato della stessa simmetria. Si \u00e8 concluso che le transizioni non adiabatiche non potrebbero avere un impatto significativo sui coefficienti di velocit\u00e0, e quindi tutte le traiettorie qui riportate sono integrate in modo indipendente per ciascuna simmetria sul corrispondente PES adiabatico pi\u00f9 basso. Infatti, abbiamo testato l'impatto delle traiettorie che iniziano sui fogli superiori e non abbiamo riscontrato alcuna transizione vibrazionale, in questo caso vengono scambiate solo piccole quantit\u00e0 di energia rotazionale. Vengono trascurate anche le transizioni elettroniche allo stato di quartetto che si ritiene siano molto meno probabili del semplice trasferimento di energia vibrazionale qui studiato a causa del loro carattere proibito dallo spin. Va inoltre notato che l'uso di traiettorie quasiclassiche \u00e8 giustificato dalle grandi masse degli atomi coinvolti [24].", "keyphrases": ["intero indipendente per ogni simmetri", "traiettorie superficiali speranza", "verificarne la validit\u00e0 ai fini dinamici", "ruotare energia", "atomo", "tsh", "studi della reazione di scambio dell'azoto", "transito degli elettroni allo stato di quartetto", "transito vibrazionale", "metodo trajectori surfac Hope (tsh).", "uso di traiettorie quasiclassi", "coefficiente di tariffa"]}
{"file_name": "S0370269304012638", "text": "\u00c8 stato recentemente dimostrato [15] (vedi anche [13] e riferimenti ivi contenuti) che per uno sfondo auto-duale l'azione effettiva QED a due loop assume una forma notevolmente semplice che \u00e8 molto simile all'azione a un loop nello stesso sfondo. Ci si aspetta che questa somiglianza persista nei cicli pi\u00f9 alti, e quindi dovrebbe esserci qualche struttura notevole codificata nell'azione effettiva in tutti i cicli per le teorie di Gauge. Nel caso supersimmetrico, \u00e8 necessario sostituire il requisito dell'auto-dualit\u00e0 con quello della super-auto-dualit\u00e0 rilassata [16] per arrivare a conclusioni simili a quelle fornite in [15]. Ulteriori progressi in questa direzione possono essere ottenuti attraverso l'analisi di supergrafi covarianti N=2. Infine, riteniamo che i risultati di questa lettera possano essere utili nel context della corrispondenza ipotizzata [17\u201319] tra l'azione della brana D3 in AdS5\u00d7S5 e l'azione a bassa energia per N=4 SU(N) SYM sul suo ramo di Coulomb, con il gruppo di calibro SU(N) spezzato spontaneamente in SU(N\u22121)\u00d7U(1). Sono apparsi due test F6 indipendenti di questa congettura [19,20], con conclusioni contrastanti. L\u2019approccio qui sostenuto offre l\u2019opportunit\u00e0 per un ulteriore test.", "keyphrases": ["Azione della brana d3", "qed a due loop", "test f6 di questa congettura", "anello pi\u00f9 alto", "gruppo misuratore", "annunci5\u00d7s5", "su(n) sim", "supergrafo di Covari", "azione effetto qed a due loop", "ramo di Coulomb", "analisi del supergrafo di covari n=2", "azione con effetto a tutto loop", "su(n\u22121)\u00d7u(1)", "azione a ciclo unico", "sole)"]}
{"file_name": "S0370269304009657", "text": "In questa Lettera presentiamo i risultati di un calcolo relativistico delle costanti di decadimento nel quadro dell'equazione completa di Salpeter. L'equazione completa di Salpeter \u00e8 un'equazione relativistica che descrive uno stato legato. Poich\u00e9 questo metodo ha una base molto solida nella teoria quantistica dei campi, \u00e8 molto efficace nel descrivere uno stato legato che \u00e8 un sistema relativistico. In un articolo precedente [16], abbiamo risolto l'equazione istantanea di Bethe-Salpeter [17], chiamata anche equazione di Salpeter completa [18]. Dopo aver risolto l'intera equazione di Salpeter, abbiamo ottenuto la funzione d'onda relativistica dello stato legato. Abbiamo utilizzato questa funzione d'onda per calcolare l'energia cinetica media del quark pesante all'interno di un mesone pesante nello stato 0\u2212 e abbiamo ottenuto valori che concordano molto bene con recenti esperimenti. Abbiamo anche scoperto che le correzioni relativistiche sono piuttosto ampie e non possono essere ignorate [16]. In questa lettera utilizziamo questo metodo per prevedere i valori delle costanti di decadimento dei mesoni pesanti nello stato 0\u2212.", "keyphrases": ["risolvi l'istante bethe\u2013salpet equat", "ottenere val", "usa questo metodo", "quadro di salpet pieno equat", "sale pieno equat", "risolvi l'intero salpet equat", "descrivere uno stato legato", "mesone pesante", "il relativismo corretto \u00e8 piuttosto grande", "sistema relativista", "salpetto equat", "Funzione d'onda", "bethe-salpet equat", "calcolare la media del Kinet Energetico", "prevedere il valore della costante di decadimento", "quark pesante", "calcolo relativista della costante di decadimento", "Funzione d'onda relativista dello stato legato", "teoria quantistica dei campi", "equazione relativista"]}
{"file_name": "S0370269304006082", "text": "Lo scopo di questa nota non \u00e8 altro che quello di portare entrambi gli approcci su un piano di parit\u00e0 e di allentare le ipotesi in base alle quali i risultati di [11,13] sono stati derivati \u200b\u200butilizzando il primo approccio. Pi\u00f9 concretamente, generalizziamo le funzioni di partizione ad un ciclo, come derivate in [11,13] per livelli dispari, al caso di livelli pari. Inoltre, a livello delle funzioni di partizione implementiamo medicazioni aggiuntive della simmetria di parit\u00e0 del foglio mondiale e le identifichiamo con le medicazioni introdotte in [12] nell'approccio dello stato crosscap. Come previsto, tutte le informazioni fisiche possono essere lette interamente dalle varie ampiezze. Concluderemo con una raccolta di funzioni di partizione a un ciclo molto esplicite e generali e di condizioni di cancellazione del girino che coprono semplici estensioni attuali di tutti i 168 modelli Gepner con ulteriori medicazioni della simmetria di parit\u00e0. Infatti fornire una raccolta compatta delle principali formule rilevanti per la costruzione degli orientifold del modello Gepner supersimmetrico \u00e8 stata una delle motivazioni per scrivere questa Lettera. Ci auguriamo che queste espressioni risultino utili per una ricerca sistematica di modelli di tipo Standard e rispettivamente per fornire un insieme statistico nello spirito di [29].", "keyphrases": ["vestito", "estensione attuale di tutti i 168 modelli gepner", "addit vestito del mondo-foglio pariti simmetri", "portare entrambi gli approcci su un piede di parit\u00e0", "costruire il modello gepner supersimmetrico orientifold", "approccio dello stato crosscap", "fornire un insieme statalista nello spirito di [29]", "ricerca sistematica del modello standard-like", "rilassare l'ipotesi", "funzione di parte ad un ciclo", "pariti simmetri", "tadpol annulla condizione", "generare le funzioni partitiche a un ciclo,"]}
{"file_name": "S0038092X15000559", "text": "La mappatura progressiva dei fotoni \u00e8 stata proposta per la prima volta da Hachisuka (2008) come estensione iterativa dell'approccio standard di mappatura statica dei fotoni implementato nell'estensione Radiance. Combina pi\u00f9 mappe di fotoni pi\u00f9 piccole per approssimarne una molto pi\u00f9 grande che potrebbe non adattarsi alla memoria utilizzando l'approccio tradizionale. Attraverso l'iterazione, il processo mitiga il rumore inerente al raytracing Monte Carlo combinando risultati successivi e calcolandone la media. Allo stesso tempo, la stima della densit\u00e0 larghezza di banda1Larghezza di banda descrive il supporto, o area di influenza, di un filtro utilizzato per ponderare i fotoni recuperati dalla mappa fotonica durante una ricerca del vicino pi\u00f9 vicino su una superficie (Jensen, 2001). L'irradianza risultante \u00e8 proporzionale alla densit\u00e0 dei fotoni e la larghezza di banda \u00e8 definita dalla distanza (raggio) del fotone pi\u00f9 lontano trovato. In questo articolo generalizziamo il termine per descrivere il raggio o il numero di vicini pi\u00f9 vicini per una stima della densit\u00e0, a seconda dell'implementazione.1 (raggio o numero di fotoni pi\u00f9 vicini) viene gradualmente ridotto per mitigare la distorsione. Come sottolinea Hachisuka, le stime della densit\u00e0 accumulata convergono verso una soluzione imparziale nel limite.", "keyphrases": ["larghezza di banda stimata densiti1larghezza di banda", "iradi", "attenuando il rumore", "fotone", "appesantire il fotone", "ricerca del vicino pi\u00f9 vicino", "supporto, o area di influenza, di un filtro", "iter estende la mappa fotonica statica standard", "mappa fotonica", "mappa dei fotoni di progresso", "combinare il risultato del successo e la media", "superficie", "approccio tradizionale", "mont carlo raytrac", "il radianza si estende", "mitigare la bia", "descrivere il raggio o il numero del vicino pi\u00f9 vicino per una stima della densiti"]}
{"file_name": "S0370269304007701", "text": "I solitoni presentano la possibilit\u00e0 di oggetti estesi come stati stabili all'interno della teoria quantistica dei campi. Sebbene queste soluzioni siano ottenute da argomentazioni semi-classiche nel limite di accoppiamento debole, la loro validit\u00e0 come stati quantistici \u00e8 giustificata in base alle leggi di conservazione topologiche associate. Un evento pi\u00f9 curioso \u00e8 quello dei modi fermionici a energia zero intrappolati in tali soluzioni. La loro presenza richiede, secondo argomentazioni ben note [1,2], l'assegnazione di un numero di fermioni semiintero agli stati solitonici. Nella trattazione usuale, la reazione inversa dei fermioni modi zero sul solitone stesso viene ignorata. Tuttavia, i valori frazionari della carica fermionica hanno conseguenze interessanti sul destino del solitone se quest'ultimo non \u00e8 strettamente stabile. La ragione di ci\u00f2 \u00e8 che se la configurazione dovesse rilassarsi fino al banale vuoto in isolamento, non sarebbe disponibile uno stato simile a una particella per trasportare il valore frazionario della carica fermionica. La stabilit\u00e0 dinamica di tali oggetti \u00e8 stata sottolineata in [3], in context cosmologico in [4,5] e pi\u00f9 recentemente in [6\u20138]. Il fenomeno del numero frazionario di fermioni si verifica anche nei sistemi di materia condensata e le sue implicazioni ad ampio raggio richiedono una comprensione sistematica del fenomeno.", "keyphrases": ["solitone", "la reazione inversa del fermione mod zero sul solitone", "sistema di materia condensata", "assegnazione di un numero di fermioni semi-intero allo stato solitonico", "stato quantico", "trasporta il valore della frazione della carica del fermione", "il destino del solitone", "vuoto", "trappola modalit\u00e0 fermione a energia zero su tale soluzione", "sistematica per la comprensione del fenomeno", "argomento di semi-classe nel limite di coppia debole", "valore della frazione della carica del fermione", "stabilit\u00e0 dinamica di tale oggetto", "associati topologia conserva legge"]}
{"file_name": "S0749603615302184", "text": "Tuttavia, la riflettivit\u00e0 misurata \u00e8 inferiore al valore previsto (\u223c96%), che \u00e8 probabilmente correlato, tra gli altri fattori, alla ruvidit\u00e0 delle interfacce GaN/AlN, in particolare per il primo strato nello stack DBR, e alla non uniformit\u00e0 degli spessori dello strato DBR. Utilizzando le misurazioni STEM dello spessore di ciascuno strato (sul piano a) attraverso lo spessore della pila, calcoliamo un nuovo modello (curva verde) in cui la riflettivit\u00e0 complessiva \u00e8 ridotta all'85%. Ci\u00f2 implica che le variazioni nello spessore dello strato attraverso la pila sono la principale fonte della ridotta riflettivit\u00e0 rispetto al modello. Infatti, uno sguardo pi\u00f9 attento ai dati STEM della sezione trasversale e un'attenta estrazione dello spessore dello strato hanno rivelato che mentre gli spessori degli strati sono abbastanza coerenti attraverso lo stack DBR nelle regioni delle ali, c'\u00e8 una variazione monotona negli spessori degli strati misurati in le regioni della finestra. (La larghezza dello strato GaN aumenta gradualmente, mentre lo spessore dello strato AlN diminuisce attraverso lo stack DBR.). Questa osservazione potrebbe potenzialmente essere di importanza pratica, per campioni cresciuti su modelli con una densit\u00e0 di difetti uniforme, poich\u00e9 si potrebbero ottenere riflettivit\u00e0 molto migliori semplicemente alterando il tempo di crescita per contrastare il cambiamento nel tasso di crescita. Questa possibilit\u00e0 \u00e8 oggetto di indagini in corso. Inoltre, la presenza di crepe e solchi sulla superficie superiore pu\u00f2 ridurre ulteriormente la riflettivit\u00e0 misurata.", "keyphrases": ["pila dbr", "strato dbr", "dati staminali trasversali", "misura dello stelo", "alterare il tempo di crescita", "stack dbr nella regione dell'ala", "estratto di strato spesso", "strato di gan", "tutti gli strati", "calcolare un nuovo modello", "la regione della finestra", "interfaccia gan/aln"]}
{"file_name": "S0167931713004991", "text": "Il numero di esperimenti condotti \u00e8 stato ridotto selezionando i quattro parametri pi\u00f9 importanti per la variazione, Tabella 1, mentre i restanti parametri sono stati mantenuti costanti. La portata di O2 (QO2) \u00e8 stata mantenuta costante a 99 sccm, mentre la portata di SF6 (QSF6) \u00e8 stata variata tra 0 e 20 sccm. La pressione nella camera di attacco \u00e8 stata controllata per mantenere stabile la densit\u00e0 del gas. Poich\u00e9 la pressione ha un effetto pronunciato sulle caratteristiche di incisione, la pressione (p) \u00e8 stata variata tra 20 e 40 mTorr. Va notato che il sistema \u00e8 stato utilizzato in modalit\u00e0 di controllo automatico della pressione, che regola continuamente la valvola a farfalla per mantenere una pressione costante durante l'attacco. La potenza della bobina (PC) \u00e8 stata fissata a 1000 W, mentre la potenza del bias (PB) \u00e8 stata variata tra 0 e 30 W. Infine, la temperatura del mandrino del substrato (T) \u00e8 stata controllata tra 10 e 50\u00b0C. Questo progetto ha prodotto uno screening fattoriale completo in quattro parametri, in cui sono stati utilizzati tre punti centrali per verificare la curvatura quadratica, dove il termine quadratico di un parametro \u00e8 necessario per generare un modello valido. Il numero totale di esperimenti in questa configurazione \u00e8 19, elaborati per 20 minuti ciascuno. Gli esperimenti nel progetto sono stati condotti in ordine casuale.", "keyphrases": ["controllo automatico della pressione", "ga", "valvola a farfalla", "pressione nella camera di attacco", "camera di incisione", "mantenere stabile la densit\u00e0 ga", "controllare la curvatura del quadrato", "regolare la valvola a farfalla", "schermata fattoriale"]}
{"file_name": "S0370269304006756", "text": "Proponiamo un metodo per il calcolo della QCD reticolare delle interazioni nucleone-nucleone a bassa energia. Consiste nel simulare la QCD sullo sfondo di un campo \u201celettromagnetico\u201d il cui potenziale non \u00e8 nullo, ma la cui intensit\u00e0 di campo \u00e8 zero. Sintonizzando il campo di fondo, \u00e8 possibile determinare gli spostamenti di fase in qualsiasi momento (ma piccolo) misurando lo spostamento dell'energia dello stato fondamentale. Dimensioni del reticolo piccole, fino a 5 Fermi, possono essere sufficienti per il calcolo degli sfasamenti fino a momenti dell'ordine di m\u03c0/2.", "keyphrases": ["interagiscono nucleone-nucleone a bassa energia", "misurare lo spostamento dell'energia dello stato fondamentale", "l'intensit\u00e0 del campo \u00e8 zero", "calcolo dello sfasamento", "ottimizzare il campo dello sfondo", "calcolo qcd lattico dell'interazione nucleone-nucleone a bassa energia", "campo elettromagnetico", "simultaneo qcd", "dimensione del sottotetto", "sfasamento al momento ani (ma piccolo).", "calcolo qcd lattico"]}
{"file_name": "S0370269304008494", "text": "Uno degli obiettivi principali dell'attuale fisica nucleare \u00e8 l'osservazione di un ripristino almeno parziale della simmetria chirale. Poich\u00e9 si prevede che il parametro dell'ordine chirale \u3008q\u0304q\u3009 diminuisca di circa il 30% gi\u00e0 alla normale densit\u00e0 della materia nucleare [1\u20134], qualsiasi cambiamento nel medio dovuto alla caduta del condensato di quark dovrebbe in linea di principio essere osservabile nelle reazioni fotonucleari. La congettura che un ripristino cos\u00ec parziale della simmetria chirale provochi un ammorbidimento e un restringimento del mesone \u03c3 come partner chirale del pione nel mezzo nucleare [5,6] ha portato all\u2019idea di misurare la distribuzione di massa invariante \u03c00\u03c00 vicino al 2\u03c0 soglia nelle reazioni indotte dai fotoni sui nuclei [7]. In contrasto con la sua discutibile natura di vera e propria quasiparticella nel vuoto, il mesone \u03c3 potrebbe sviluppare un picco molto pi\u00f9 stretto a densit\u00e0 barionica finita a causa della soppressione dello spazio delle fasi per il decadimento \u03c3\u2192\u03c0\u03c0, rendendo quindi possibile esplorare le sue propriet\u00e0 quando incorporato in un sistema nucleare a molti corpi [8\u201311]. Misurare un miglioramento della soglia dello spettro di massa invariante \u03c00\u03c00 potrebbe servire come segnale per il ripristino parziale della simmetria chirale all\u2019interno dei nuclei e, quindi, fornire informazioni su una delle caratteristiche pi\u00f9 fondamentali della QCD.", "keyphrases": ["parametro dell'ordine chirale", "nuclei", "fotone", "pione", "mesone \u03c3", "ripristino parziale della simmetria chirale", "misurare la distribuzione di massa invariata \u03c00\u03c00", "fisica nucleare", "decadimento \u03c3\u2192\u03c0\u03c0", "reazione indotta da fotoni", "misurare una soglia di miglioramento dello spettro di massa invariabile \u03c00\u03c00", "reazione fotonucleare", "il quark si condensa", "osservare un ripristino almeno parziale dei simmetri chirali", "quasiparticl", "sistema nucleare a molti corpi", "qcd", "q\u0304q", "materia nucleare", "partner chirale", "mezzo nucleare"]}
{"file_name": "S0165168416300603", "text": "Nonostante il fatto che SRC-HE riduca il numero di FE, l\u2019estrazione di misurazioni audio basata su SRC non sarebbe comunque adatta per applicazioni in tempo reale [39]. Il precedente modulo SRC-HE viene quindi sostituito dalla trasformata di fase di correlazione incrociata generalizzata (GCC-PHAT) introdotta nella Sezione 2.1, poich\u00e9 ci\u00f2 non comporta complesse stime di funzioni puntuali. Lo svantaggio \u00e8 che l'algoritmo GCC di base pu\u00f2 rilevare solo una sorgente alla volta ed \u00e8 noto per essere sensibile ai riverberi della stanza [5], tuttavia \u00e8 comunque efficace in ambienti con riverbero moderato (T60\u22480,3s) [40]. Per questi motivi vengono inizialmente condotti esperimenti in cui \u00e8 attivo solo un interlocutore in un dato momento, come spesso accade in una conversazione educata tra due o pi\u00f9 persone. I segmenti vocali che utilizzano un rilevatore di attivit\u00e0 vocale (VAD) [41] vengono ulteriormente estratti ed elaborati utilizzando una fase GCC-PHAT, affinch\u00e9 il segnale sia pi\u00f9 robusto ai riverberi. Pertanto, il vettore di misura ottenuto za (vedi Sezione 2.1) pu\u00f2 ora essere riscritto come za={\u03c4m(t)}, dove ciascuna componente \u03c4m \u00e8 il TDOA raccolto sulla m-esima coppia di microfoni ad ogni passo temporale t. Poich\u00e9 i TDOA non sono lineari nella posizione dell'altoparlante, devono essere immessi in un filtro di Kalman esteso (EKF), come in [10] per ottenere una stima della posizione audio.", "keyphrases": ["segmento del discorso", "gcc-phat", "rilevatore di attivazione vocale", "filtro Kalman", "La m-esima coppia di microfoni", "stima positiva dell'audio", "src-lui", "Trasformata di fase del correlazione incrociata generalis", "ekf", "passo gcc-phat", "vad", "altoparlante", "algoritmo gcc"]}
{"file_name": "S1364815216303243", "text": "I tipici modelli di inondazioni 2D basati sulla fisica risolvono le equazioni delle acque poco profonde (SWE), che richiedono elevate risorse computazionali. Molti di questi modelli sono stati sviluppati per ottenere prestazioni migliori, pur mantenendo la precisione richiesta, riducendo la complessit\u00e0 degli SWE. Questa riduzione viene solitamente ottenuta approssimando o trascurando i termini meno significativi delle equazioni (Hunter et al., 2007; Yen e Tsai, 2001). Il modello JFLOW (Bradbrook et al., 2004), il modello Urban Inundation (UIM) (Chen et al., 2007) e la versione diffusiva di LISFLOOD-FP (Hunter et al., 2005) risolvono le equazioni delle onde di diffusione 2D che trascurare i termini inerziale (accelerazione locale) e avvezione (accelerazione convettiva) (Yen e Tsai, 2001). La versione inerziale di LISFLOOD-FP (Bates et al., 2010) risolve gli SWE senza il termine di avvezione. In entrambe le versioni di LISFLOOD-FP il flusso \u00e8 disaccoppiato nelle direzioni cartesiane. Altri modelli utilizzano SWE completi ma si concentrano sull'uso di griglie multi-risoluzione o mesh irregolari, come InfoWorks ICM (Innovyze, 2012) e MIKE FLOOD (DHI Software, 2014; H\u00e9nonin et al., 2013). Questi ultimi due modelli sono pacchetti commerciali e il codice applicato nelle tecniche di ottimizzazione non \u00e8 di pubblico dominio.", "keyphrases": ["acque poco profonde equat", "Infowork icm", "uim", "risolvere l'equat delle acque basse (swes)", "2d onda diffusa equat", "lisflood-fp", "Mike Flood", "griglia multi risoluzione o maglia irregolare", "cartesiano diretto", "modello di inondazione urbana", "ridurre il complesso dello swe", "modello di alluvione 2D fisicamente-bas", "swe", "jflusso"]}
{"file_name": "S0375960115005630", "text": "I sistemi in cui la forza Stern-Gerlach \u00e8 pi\u00f9 prominente sono quelli con un elevato gradiente di campo elettromagnetico. La sezione 2 considera le implicazioni dell'accoppiamento tra lo spin di un elettrone classico e il campo elettromagnetico in rapida variazione prodotto da un'onda di plasma guidata dal laser. Impulsi laser sufficientemente brevi e ad alta intensit\u00e0 possono formare onde longitudinali all'interno della densit\u00e0 elettronica di un plasma. Queste onde di densit\u00e0 si propagano con velocit\u00e0 paragonabile alla velocit\u00e0 di gruppo dell'impulso laser. Tuttavia, non tutti gli elettroni del plasma formano quest'onda; alcuni elettroni vengono catturati dall'onda e accelerati dai suoi campi elevati. L'onda alla fine collassa quando questi elettroni la smorzano (l'onda \"si rompe\"). Il gradiente di campo elettrico estremamente elevato di un'onda di plasma vicino alla rottura dell'onda fornisce un eccellente banco di prova teorico per gli effetti dei contributi di tipo Stern-Gerlach alla traiettoria di un elettrone di prova.", "keyphrases": ["gradiente di campo elettromagnetico", "poppa-gerlach forc", "onda di plasma guidata dal laser", "laser", "elettrone del plasma", "plasma", "l'onda 'si rompe'", "elettrone", "contributo di tipo stern-gerlach", "onda longitudinale", "l'elettrone smorza l'onda", "campo elettromagnetico", "elevato gradiente del campo elettrico di un'onda di plasma", "impulso laser ad alta intensit\u00e0", "impulso laser", "onda di densit\u00e0"]}
{"file_name": "S0010938X1530161X", "text": "Una parte fondamentale di questo problema \u00e8 che un ispettore ha accesso ai dati solo da una piccola area ispezionata. In quest'area esiste un solo spessore minimo, che non fornisce informazioni sufficienti per costruire un modello dagli spessori pi\u00f9 piccoli. Un ispettore pu\u00f2 generare un campione delle misurazioni di spessore pi\u00f9 piccole suddividendo i dati di ispezione in un numero di blocchi di uguali dimensioni. In ogni blocco viene registrato lo spessore minimo. Questo set costituisce un campione delle misurazioni di spessore pi\u00f9 piccole. Da questo campione \u00e8 possibile costruire un modello che tenga conto delle variazioni delle misure di spessore pi\u00f9 piccole. L'analisi dei valori estremi (EVA) fornisce una forma limitante per questo modello. Si afferma che, se le misurazioni dello spessore sottostante in ciascun blocco sono prese da distribuzioni indipendenti e identiche, allora il campione delle misurazioni dello spessore minimo seguir\u00e0 una distribuzione generalizzata dei valori estremi (GEVD).", "keyphrases": ["modello che tiene conto della variazione della misura di spessore pi\u00f9 piccola", "analisi dei valori estremi", "blocco di uguali dimensioni", "eva", "gevd", "campione", "bloccare", "modello del pi\u00f9 piccolo spessore", "costruire un modello del pi\u00f9 piccolo spessore", "dividere i dati di ispezione", "gener valore estremo distribut", "ispezionare i dati"]}
{"file_name": "S0021999112002847", "text": "In questo lavoro sviluppiamo un nuovo approccio alla DEA adatto alla modellazione di problemi tridimensionali. Gli attuali metodi DEA si basano sul fatto che \u00e8 possibile parametrizzare facilmente il confine della regione da modellare e quindi applicare un'approssimazione su base ortonormale sul sistema di coordinate dello spazio delle fasi del confine risultante. In due dimensioni questo \u00e8 semplice poich\u00e9 il confine pu\u00f2 essere parametrizzato lungo la sua lunghezza d'arco e la coordinata della quantit\u00e0 di moto associata (o direzione) pu\u00f2 essere presa tangente al confine. La base pu\u00f2 essere qualsiasi base univariata (in scala) adatta sia nella posizione che nella quantit\u00e0 di moto, come una base di Fourier [8] o polinomi di Chebyshev [9]. Diventa molto pi\u00f9 difficile definire una parametrizzazione adeguata della coordinata spaziale in tre dimensioni. Nello spazio della quantit\u00e0 di moto si possono impiegare coordinate polari sferiche e quindi questi problemi non sorgono.", "keyphrases": ["coordinazione della quantit\u00e0 di moto (o direzione).", "problema tridimensionale del modello", "sviluppare un nuovo approccio alla soluzione adatto al problema modello tridimensionale", "Sistema di coordinate dello spazio delle fasi borderari", "polinomi di Chebyshev", "coordinazione polare sferica", "base di Fourier", "parametris i confini della regione", "base univari", "base ortonorma approssimativa", "metodo dea", "lunghezza dell'arco", "dea"]}
{"file_name": "S2212667814001294", "text": "Il Knowledge Management (KM) \u00e8 uno dei punti caldi della ricerca negli ultimi dieci anni. Nella maggior parte dei casi, il numero di utenti in un sistema di gestione della conoscenza (KMS) \u00e8 molto ampio e provengono da diversi dipartimenti, anche da altre aziende. In questo documento, vengono analizzati alcuni difetti quando i metodi esistenti relativi al controllo degli accessi e alle raccomandazioni vengono implementati nel KMS per dimostrare che questi approcci ampiamente utilizzati devono essere estesi. Per superare le carenze del lavoro precedente, questo documento propone un metodo esteso di controllo degli accessi basato sui ruoli (RBAC) e un approccio ibrido di raccomandazione per il sistema di gestione della conoscenza. Inoltre, viene presentato un sistema reale per verificare la metodologia proposta.", "keyphrases": ["rbac", "km", "difetto quando esiste un metodo relativo al controllo degli accessi e si consiglia di distribuirlo in km vengono analizzati", "gestione della conoscenza", "approccio di raccomandazione ibrida", "sistema di gestione della conoscenza", "estendere", "verificare il metodo proposto", "controllo di accesso role-bas", "sistema della vita reale"]}
{"file_name": "S0045782515003680", "text": "Consideriamo l'ottimizzazione della forma di solidi bi e tridimensionali combinando superfici di suddivisione multirisoluzione con elementi finiti immersi. Come ampiamente discusso nella letteratura sull'analisi isogeometrica, le rappresentazioni geometriche utilizzate negli odierni software di progettazione assistita da computer (CAD) e di analisi degli elementi finiti (FEA) sono intrinsecamente incompatibili [1]. Ci\u00f2 \u00e8 particolarmente limitante nell'ottimizzazione della forma durante la quale un dato modello geometrico CAD deve essere aggiornato in modo iterativo in base ai risultati di un calcolo agli elementi finiti. Le carenze intrinseche della geometria attuale e delle rappresentazioni di analisi hanno motivato la proliferazione di varie tecniche di ottimizzazione della forma. Negli approcci pi\u00f9 diffusi viene ottimizzato un modello geometrico surrogato [2\u20138] o la mesh di analisi [9,10] invece del vero modello CAD, vedere anche [11] e i riferimenti ivi contenuti. In genere, \u00e8 noioso o impossibile mappare il modello geometrico surrogato ottimizzato o la mesh di analisi sul modello CAD originale, il che \u00e8 essenziale per continuare con il processo di progettazione e successivamente per scopi di produzione. Inoltre, le caratteristiche del progetto geometrico sono solitamente definite rispetto al modello CAD e non possono essere facilmente applicate al modello surrogato. Recentemente \u00e8 stata esplorata l'ottimizzazione della forma di gusci, solidi e altre applicazioni utilizzando l'analisi isogeometrica; cio\u00e8 attraverso l'ottimizzazione diretta del modello geometrico CAD [12\u201315].", "keyphrases": ["cadavere", "calcolo degli elementi finiti", "geometri e analisi rappresentano", "i geometri rappresentano", "progettazione assistita da computer", "modello surrogato", "Letteratura sull'analisi isogeometrica", "ottimizzazione della forma", "direttamente ottimizzato", "analisi isogeometrica", "analisi degli elementi finiti", "immerge l'elemento finito", "modello cad", "modello geometrico cad", "combin multiresolut subdivis surfac", "tecnica di forma ottimale", "conchiglia", "modello geometrico surrog ottimale", "solido a due e tre dimensioni", "maglia di analisi", "fe", "solido", "modello geometrico surrogato"]}
{"file_name": "S0957417416303773", "text": "Negli ultimi anni, principalmente motivati \u200b\u200bdall'impulso del data mining, sono sorti molti metodi per la riduzione della dimensionalit\u00e0. All'interno di questi \u00e8 opportuno evidenziare il metodo dell'Analisi delle Componenti Principali (PCA) (Jolliffe, 2002). In uno spazio vettoriale N-dimensionale, la versione pi\u00f9 semplice di PCA (PCA lineare) \u00e8 una tecnica che trova i vettori reciprocamente non correlati su cui la proiezione dei campioni genera le varianze pi\u00f9 elevate. Il risultato \u00e8 un insieme di vettori ortogonali ordinati in ordine decrescente in base alla varianza raggiunta. Il primo di questi vettori \u00e8 quello su cui \u00e8 massima la varianza della proiezione dei campioni. In questo senso, i KPI originali costituiscono la base dello spazio vettoriale N-dimensionale, mentre i KPI sintetici N^ rappresentano i vettori ortogonali con la varianza pi\u00f9 elevata. Per essere rigorosi, \u00e8 possibile calcolare fino a N KPI ortogonali sintetici. Tuttavia, solo un piccolo insieme di essi, il primo N^, \u00e8 sufficiente a spiegare la maggior parte della varianza dei dati.", "keyphrases": ["miniera di dati", "la versione pi\u00f9 semplice di PCA", "fino a n kpi ortogonali sintetici", "un insieme di vettori ortogonali", "trovare il vettore mutuamente incorretto", "PCA", "il primo n^", "Metodo di analisi princip compon", "pca lineare", "la varianza del progetto del campione \u00e8 massima", "il progetto del campione genera la varianza pi\u00f9 elevata", "Basi dello spazio vettoriale a n dimensioni", "dimensione ridotta", "n^ sintetizzato kpi"]}
{"file_name": "S1877750313000240", "text": "Alcuni studi nell\u2019ambito fisiologico sono di particolare rilevanza per questo lavoro. Questi includono un'analisi delle prestazioni di un solutore LB del flusso sanguigno utilizzando una gamma di geometrie sparse e non sparse [21] e un modello di previsione delle prestazioni per solutori reticolari-Boltzmann [22,23]. Questo modello di previsione delle prestazioni pu\u00f2 essere applicato in gran parte alla nostra applicazione HemeLB, sebbene HemeLB utilizzi una tecnica di scomposizione diversa ed esegua attivit\u00e0 di rendering e visualizzazione in tempo reale durante le simulazioni LB. Mazzeo e Coveney [1] hanno studiato la scalabilit\u00e0 di una versione precedente di HemeLB. Tuttavia, le attuali caratteristiche prestazionali di HemeLB sono sostanzialmente migliorate grazie a numerosi progressi successivi nel codice, tra gli altri: un formato di file compresso gerarchico migliorato; l'uso di ParMETIS per garantire un buon bilanciamento del carico; i modelli di comunicazione uniti per ridurre il sovraccarico del rendering; uso del polimorfismo in fase di compilazione per evitare chiamate di funzioni virtuali nei cicli interni.", "keyphrases": ["risolutore lb del flusso sanguigno", "rendere", "parmi", "eseguire il modello di previsione", "orlo", "applicazione dell'orlo", "polimorfo in fase di compilazione", "lb simul", "modello comune coalescente", "solutore reticolare-boltzmann"]}
{"file_name": "S0370269302013412", "text": "Consideriamo le conseguenze cosmologiche di una formulazione conforme-invariante della Relativit\u00e0 Generale di Einstein dove invece del fattore di scala della metrica spaziale nel funzionale dell'azione si verifica un campo scalare (dilatone) senza massa che scala tutte le masse inclusa la massa di Planck. Invece dell'espansione dell'universo otteniamo il tipo di evoluzione di massa di tipo Hoyle-Narlikar, dove la storia della temperatura dell'universo \u00e8 sostituita dalla storia della massa. Mostriamo che questo modello cosmologico invariante conforme fornisce una descrizione soddisfacente dei dati della nuova supernova Ia per la relazione effettiva magnitudine-spostamento verso il rosso senza una costante cosmologica e facciamo una previsione per il comportamento ad alto spostamento verso il rosso che devia da quello della cosmologia standard per z> 1.7. Consideriamo le conseguenze cosmologiche di una formulazione conforme-invariante della Relativit\u00e0 Generale di Einstein dove invece del fattore di scala della metrica spaziale nel funzionale dell'azione si verifica un campo scalare (dilatone) senza massa che scala tutte le masse inclusa la massa di Planck. Invece dell'espansione dell'universo otteniamo il tipo di evoluzione di massa di tipo Hoyle-Narlikar, dove la storia della temperatura dell'universo \u00e8 sostituita dalla storia della massa. Mostriamo che questo modello cosmologico invariante conforme fornisce una descrizione soddisfacente dei dati della nuova supernova Ia per la relazione effettiva magnitudine-spostamento verso il rosso senza una costante cosmologica e facciamo una previsione per il comportamento ad alto spostamento verso il rosso che devia da quello della cosmologia standard per z> 1.7.", "keyphrases": ["fattore di scala", "formula conforme-invariata del gene Einstein rel", "scalare senza massa", "comportamento ad alto redshift", "campo scalare (dilatone) senza massa", "costante cosmologica", "cosmologo standard", "Dati sulla supernova", "relazione magnitudo effetto-spostamento verso il rosso", "consid cosmolog consequ di una formula conforme-invariante del gener di Einstein rel", "massa", "temperatur histori dell'universo", "tipo di evoluzione di massa hoyle-narlikar", "dilatatore", "espansioni dell'universo", "Genere Einstein rel", "massa di planck", "modello cosmologico invariante conforme", "storia di massa"]}
{"file_name": "S0021999115007238", "text": "Un problema intrinseco della discretizzazione dello spazio delle fasi \u00e8 la separazione spuria dell'energia nei contenitori discretizzati. Questo \u00e8 chiamato \u201ceffetto sprinkler da giardino\u201d ed \u00e8 stato ampiamente studiato in [48,49,20]. (Nella comunit\u00e0 dei trasporti Boltzmann questo \u00e8 noto come effetto raggio.) Per mostrare questo effetto nella dimensione angolare, viene simulato un ampio dominio spaziale (4000 km\u00d74000 km), con un'onda monocromatica che si propaga su una lunga distanza in acque profonde (d =10000 m). Per la discretizzazione spaziale viene utilizzata una mesh triangolare strutturata, con una lunghezza del bordo dell'elemento di 67 km (Figura 11 (a)). Il campo d'onda iniziale, situato a 500 km dal lato inferiore e sinistro, ha una distribuzione gaussiana nello spazio, con un'altezza d'onda significativa di Hs = 2,5 me una deviazione standard di 150 km (Figura 11 (b)). La sua direzione media \u00e8 30\u00b0 con una distribuzione angolare di cos2\u2061(\u03b8) e una frequenza di 0,1Hz. La simulazione dipende dal tempo e viene eseguita per 5 giorni con un intervallo temporale di 600 s.", "keyphrases": ["acque profonde", "effetto raggio", "onda", "maglia triangolare della struttura", "simul", "onda monocromatica", "spuriou separa di energia nel contenitore discreto", "campo d'onda", "distribuzione gaussiana nello spazio", "discreto nello spazio di fase", "effetto irrigatore da giardino", "il dominio spaziale (4000km\u00d74000km) \u00e8 simul", "discreti spaziali"]}
{"file_name": "S2212667814001488", "text": "Questo articolo presenta risultati generali sul problema del rilevamento degli snippet di codice sorgente Java. Proponiamo lo strumento che utilizza il rilevamento dell'isomorfismo di grafici e sottografi. In letteratura sono state proposte numerose soluzioni per tutti questi compiti. Tuttavia, nonostante tutte queste soluzioni siano molto veloci, confrontano solo gli alberi statici costanti. La nostra soluzione offre l'inserimento dinamico di un campione di input con il linguaggio Scripthon preservando una velocit\u00e0 accettabile. Abbiamo utilizzato diverse ottimizzazioni per ottenere un numero molto basso di confronti durante l'algoritmo di corrispondenza.", "keyphrases": ["confronta solo l'albero statico costante", "lingua scripthon", "mantenere una velocit\u00e0 di accettazione", "immettere una dinamica di campionamento in input", "algoritmo di corrispondenza", "confronto", "rilevamento dello snippet di codice sorgente Java", "rilevamento di isomorfi di grafici e sottografi", "decisamente ottimale"]}
{"file_name": "S0370269304008792", "text": "Investighiamo il comportamento di densit\u00e0 dell'energia di simmetria rispetto all'equilibrio dell'isospin nei sistemi combinati Ru(Zr)+Zr(Ru) a energie relativistiche di 0,4 e 1,528 A GeV. Lo studio viene eseguito in un context relativistico e viene esplorato in particolare il contributo del campo isovettoriale e scalare \u03b4 all'energia di simmetria e alla dinamica dell'isospin. Troviamo che la miscelazione dell'isospin dipende dall'energia di simmetria e un comportamento pi\u00f9 rigido porta a una maggiore trasparenza. I risultati sono anche molto sensibili alla \u201cstruttura fine\u201d dell\u2019energia di simmetria, cio\u00e8 alle propriet\u00e0 covarianti dei campi mesonici isovettori. Il tracciato dell\u2019isospin appare molto meno dipendente dalle sezioni d\u2019urto neutrone-protone nel medio (\u03c3np) e questo rende tale osservabile molto peculiare per lo studio della parte isovettoriale dell'equazione di stato nucleare. In tale context, confronti con esperimenti supportano l'introduzione del mesone \u03b4 nella descrizione dell'equazione di stato isovettoriale.", "keyphrases": ["quadro relativista", "contributo dell'isovettore", "confronto con l'esperienza", "campo mesonico isovettore", "Il campo \u03b4 scalare ai simmetri energetici e all'isospin dinamico \u00e8 particolarmente esplorabile", "miscela di isospin", "introduzione del mesone \u03b4 nella descrizione dell'equazione di stato isovettore", "sistema combinato", "studi", "ru(zr)+zr(ru)", "energia relativista", "studi della parte isovettrice dell'equat di stato nucleare", "\u03c3np", "sezione d\u2019urto neutrone-protone media", "indagare il comportamento densificato dei simmetri energetici rispetto all'equilibrio dell'isospin", "mesone \u03b4"]}
{"file_name": "S2212671612001618", "text": "Questo articolo presenta un metodo di progettazione di controller non fragile basato sull'ottimizzazione quadratica delle prestazioni del sistema. Per le variazioni di guadagno del controllore additivo, le condizioni necessarie e sufficienti per l'esistenza di controllori con retroazione di stato non fragile vengono fornite e trasformate nei problemi LMI, che semplificano le soluzioni per ottenere controllori con retroazione di stato non fragile. I risultati della simulazione del controllo di volo dimostrano l'affidabilit\u00e0 e la validit\u00e0 del metodo.", "keyphrases": ["trasformare", "metodo di progettazione del controllo non fragile", "semplificare la soluzione", "problema lmi", "aggiungi la variazione del guadagno del controllo", "simulazione del controllo di volo", "controllo del feedback dello stato non fragile", "sistema quadrat eseguire ottim"]}
{"file_name": "S0370269304009803", "text": "Il nostro obiettivo \u00e8 quello di introdurre mesoni vettori in termini di una Lagrangiana che soddisfi l'algebra delle correnti a bassa energia. Un metodo coerente \u00e8 in termini di una Lagrangiana chirale non lineare con una simmetria locale nascosta [6]. In questa teoria i mesoni vettori emergono come mesoni vettori dinamici. L'interazione vettore-pseudoscalare a tre punti \u00e8 data da (11)ih4\u3008V\u03bc(P\u2202\u03bcP\u2212\u2202\u03bcPP)\u3009, dove h sta per l'accoppiamento vettore-pseudoscalare. Alcuni vertici tipici dei mesoni \u03c1 pseudoscalari sono (12)\u03c0+(p1)\u03c0\u2212(p2)\u03c10:h(p1\u2212p2)\u03bc\u03b5\u03bc,\u03c0+(p1)\u03c00(p2)\u03c1\u2212:h(p1\u2212p2) \u03bc\u03b5\u03bc,K+(p1)K\u00af0(p2)\u03c1\u2212:h2(p1\u2212p2)\u03bc\u03b5\u03bc,ecc., che \u00e8 direttamente correlato all'ampiezza del decadimento \u03c1: \u0393(\u03c1)=h2(|p\u03c0|)3/( 6\u03c0m\u03c12), dove p\u03c0 \u00e8 la quantit\u00e0 di moto dei pioni dello stato finale nel sistema di riferimento \u03c1 a riposo. Con \u0393(\u03c1)=149,2MeV troviamo h=5,95. Notiamo di sfuggita che la relazione Kawarabayashi\u2013Suzuki\u2013Riazuddin\u2013Fayyazuddin d\u00e0 il valore h=m\u03c1/(2f\u03c0)[12]. Quindi il valore di h nell'Eq. (4) e i due valori in questo paragrafo differiscono di poco (\u223c19%). I vertici forti a quattro punti che coinvolgono i pioni si ottengono dai primi due termini dell'Eq. (5). I vertici deboli si ottengono dalle definizioni di Q6 e Q8. Nel lavoro numerico useremo il valore di h dall'Eq. (4) e anche h=5.95 ottenuto dall'ampiezza del decadimento.", "keyphrases": ["verticale di \u03c1' al mesone pseudoscalare", "\u03c0+(p1)\u03c00(p2)\u03c1\u2212:h(p1\u2212p2)\u03bc\u03b5\u03bc", "si ottengono vertici deboli", "si ottengono forti vertici a quattro punti che coinvolgono il pione", "k+(p1)k\u00af0(p2)\u03c1\u2212:h2(p1\u2212p2)\u03bc\u03b5\u03bc", "\u03b3(\u03c1)=h2(|p\u03c0|)3/(6\u03c0m\u03c12)", "Algebra delle correnti a bassa energia", "mesone vettore dinamico", "differiscono per una piccola quantit\u00e0", "ih4\u3008v\u03bc(p\u2202\u03bcp\u2212\u2202\u03bcpp)\u3009", "interazione vettore-pseudo scalare", "kawarabayashi\u2013suzuki\u2013riazuddin\u2013fayyazuddin relat", "(12)\u03c0+(p1)\u03c0\u2212(p2)\u03c10:h(p1\u2212p2)\u03bc\u03b5\u03bc", "mesone vettore", "lagrangiana", "accoppiamento vettore-pseudoscalare", "simmetri locali nascosti", "p\u03c0", "quantit\u00e0 di moto del pione nello stato finale nel sistema di riferimento \u03c1 a riposo", "lagrangiana chirale non lineare", "\u03c1 larghezza di decadimento", "introdurre il mesone vettore", "H"]}
{"file_name": "S0010482516301810", "text": "Immagini angiografiche tridimensionali con sottrazione digitale (3D-DSA) dall'angiografia cerebrale diagnostica sono state ottenute almeno un giorno prima dell'embolizzazione in tutti i pazienti. I dati grezzi di 3D-DSA in un file DICOM sono stati utilizzati per creare un modello 3D del segmento del vaso target. Questi dati sono stati convertiti in dati di superficie del linguaggio di triangolazione standard (STL) come aggregazione di maglie triangolari fini utilizzando un software di visualizzazione e misurazione 3D (Amira versione X, FEI, Burlington, MA, USA). Una mesh volumetrica computazionale non strutturata \u00e8 stata costruita dalla superficie triangolata. Smoothing e remeshing sono seguiti come passaggi successivi. Il file STL \u00e8 stato quindi trasferito su una stampante 3D (OBJET30 Pro; Stratasys Ltd., Eden Prairie, MN, USA). La risoluzione dello strato di costruzione era di 0,028 mm e il modello del vaso stampato in 3D \u00e8 stato prodotto utilizzando resina acrilica (Vero). Dopo l\u2019immersione in acqua per alcune ore, la superficie del modello stampato in 3D \u00e8 stata levigata rimuovendo manualmente le spicole.", "keyphrases": ["amira versione x", "stl", "rimescolare", "modello 3D", "misura", "oggetto30pro", "stampante 3d", "si immerge nell'acqua", "embolia", "Software di visualizzazione e misurazione 3D", "lingua triangolare standard", "file stl", "mesh del volume di calcolo", "liscio", "angiografo tridimensionale con sottrazione di cifre", "visivo 3D", "vero", "maglia triangolare", "acqua", "file dicom", "3d-dsa", "superficie triangolare", "resina acrilica", "Modello di stampa 3D", "creare un modello 3D del segmento della nave target", "rimuovere la spicola.", "angiografi cerebrali"]}
{"file_name": "S0010938X15002954", "text": "Ci sono stati relativamente pochi tentativi di osservare e in alcuni casi di estrarre la densit\u00e0 di corrente media dalle immagini video scattate di pozzi 2D in crescita. Frankel ha presentato un metodo per misurare direttamente la densit\u00e0 di corrente anodica media dalla crescente velocit\u00e0 al confine dei pozzi in film sottili di Al [33], una lega di Al [34] e Ni-Fe [35]. Successivamente, Ryan [27,36] ha determinato la densit\u00e0 di corrente anodica nelle cavit\u00e0 che si propagano come dischi 2D in film sottili di acciaio inossidabile misurando la velocit\u00e0 di movimento del bordo della cavit\u00e0. Ernst e Newman [11,12,37] hanno studiato in dettaglio la stabilit\u00e0 della crescita delle cavit\u00e0 e hanno misurato la cinetica della propagazione delle cavit\u00e0 2D in profondit\u00e0 e larghezza e hanno confrontato i risultati con la cinetica degli elettrodi a matita 1D. Hanno sviluppato un modello semiquantitativo per la propagazione delle fosse che spiegava la formazione di una copertura di pizzo durante la crescita delle fosse, sebbene non avessero misurato la densit\u00e0 di corrente all'interno della fossa. Pi\u00f9 recentemente, Tang e Davenport [38] hanno tracciato il movimento dei confini dei pozzi e calcolato la densit\u00e0 di corrente istantanea ma media nei film sottili di Fe-Co. Tuttavia, non ci sono stati precedenti tentativi di quantificare la densit\u00e0 di corrente locale durante la crescita disomogenea delle cavit\u00e0, sebbene tale variazione locale nella densit\u00e0 di corrente sia stata riconosciuta da tempo [7].", "keyphrases": ["film sottile di fe-co", "disco 2d", "lega di al", "al", "corrente anodica", "crescita della fossa", "propagazione della fossa", "ni\u2013f [35] film sottile", "fossa", "Propagazione fossa 2D", "attuale", "2d fossa", "formato copertura fossa laci", "film sottile di acciaio inossidabile", "immagine video", "misurare il kinet della propagazione pit 2d", "bordo della fossa", "Elettrodo a matita 1d", "modello semiquantitativo", "copertura della fossa laci"]}
{"file_name": "S0021999113003422", "text": "Oscillazioni numeriche simili a quelle sopra descritte emergono anche nell'ISPM quando si utilizzano i kernel IBM classici a causa della loro mancanza di regolarit\u00e0 (con derivate seconde discontinue). Inoltre, \u00e8 importante notare che le tensioni della struttura immersa sono catturate nella descrizione lagrangiana e quindi, per calcolarle accuratamente, \u00e8 importante garantire che queste oscillazioni spurie non siano introdotte tramite le funzioni di interpolazione del kernel. In questo articolo, gli autori hanno specificatamente progettato una nuova famiglia di funzioni del kernel che non introducono queste oscillazioni spurie. Le funzioni del kernel sono ottenute tenendo conto delle condizioni di riproducibilit\u00e0 discreta originariamente introdotte da Peskin [14] (nel nostro caso, fatte su misura per griglie sfalsate cartesiane) e dei requisiti di regolarit\u00e0 per prevenire la comparsa di oscillazioni spurie durante il calcolo delle derivate. \u00c8 stato sviluppato un programma per computer Maple per ottenere espressioni esplicite per i nuovi kernel.", "keyphrases": ["derivazione computazionale", "funzione del kernel", "programma di calcolo mapl", "una nuova famiglia di funzioni del kernel che non introducono questi spuriou oscil", "kernel IBM", "numero oscil", "oscil", "nocciolo", "funzione di interpol del kernel", "ispm", "ottenere un express esplicito per il nuovo kernel", "descrizione lagrangiana", "griglia cartesiana sfalsata"]}
{"file_name": "S0254058415001212", "text": "Gli alluminuri di titanio gamma sono una famiglia di leghe a bassa densit\u00e0 e ad alte prestazioni con il potenziale di sostituire le attuali superleghe a base di Ni utilizzate nella produzione di componenti di motori aeronautici. La microfusione \u00e8 uno dei metodi pi\u00f9 economici per produrre prodotti in titanio e leghe di alluminuro di titanio, aumentando l'integrit\u00e0 e le propriet\u00e0 meccaniche dei componenti, riducendo allo stesso tempo gli sprechi di materiale e i costi di lavorazione [1]. Gli alluminuri di titanio sono difficili da lavorare principalmente a causa della bassa fluidit\u00e0 della lega TiAl attorno alla sua temperatura di fusione [2]. A causa dell'elevata affinit\u00e0 di elementi come ossigeno, azoto ecc., il titanio e le sue leghe possono facilmente interagire con i materiali dello stampo durante il processo di fusione a cera persa, generando uno strato indurito di interazione sulla superficie del metallo [3,4]. Questo strato indurito contiene una grande quantit\u00e0 di ossigeno disciolto ed \u00e8 molto fragile e suscettibile alla generazione e propagazione di cricche [5].", "keyphrases": ["lega", "superlega ni-bas", "processo di fusione", "titanio", "elemento", "materiale dello stampo", "il comp", "prodotto di componenti aeronautici", "investire cast", "superficie metallica", "alluminide gamma titanio", "sciogliere l'ossigeno", "azoto", "interagire con lo strato indurente", "alluminuro di titanio", "lega iniziale", "componente del motore aeronautico", "produrre prodotti in titanio e leghe di alluminidi di titanio", "generazione e propagazione del crack", "strato indurente", "lega di alluminuro di titanio", "ossigeno"]}
{"file_name": "S0045782512003428", "text": "La scelta delle funzioni di interpolazione e delle coordinate del punto di supporto per il campo del gradiente \u00e8 fondamentale per garantire stabilit\u00e0 e accuratezza della formulazione. Ad esempio, l'integrazione nodale e NS-FEM sono instabili e comportano la comparsa di modalit\u00e0 spurie a bassa energia. Hanno bisogno di funzioni energetiche di penalit\u00e0 non fisiche che li stabilizzino. Gli articoli [2,28] verificano numericamente la stabilit\u00e0, la convergenza e l'accuratezza di diverse varianti di W2 inclusi nuovi elementi che possono essere costruiti sulla base dell'idea di presunti gradienti di deformazione continua. Per gli elementi esaedrici del primo ordine, [2,28] ha trovato buoni risultati per i tipi di elementi C3D_8N_27C e C3D_8N_8I. Il primo \u00e8 definito da 27 punti di supporto e un'interpolazione del prodotto tensoriale di secondo ordine del gradiente di deformazione mediante polinomi di Lagrange. Quest'ultimo tipo di elemento \u00e8 definito da 16 punti di supporto di cui 8 punti coincidenti con i nodi e 8 punti aggiuntivi all'interno dell'elemento. Tra i tetraedri del primo ordine testati, il tetraedro integrato nodalmente con una modalit\u00e0 a bolle aggiuntiva nei gradienti \u00e8 risultato essere il pi\u00f9 accurato. Si \u00e8 rivelato anche il pi\u00f9 efficiente rispetto al tempo di calcolo nell'analisi esplicita [28] perch\u00e9 il passo temporale critico ampliato compensa il costo numerico leggermente aumentato per l'assemblaggio della forza di ripristino. La Figura 1 illustra le posizioni dei punti di supporto per varie formulazioni CAG e SFEM.", "keyphrases": ["coordinazione del punto di supporto per il campo del gradiente", "funzione di interpol", "stabil e accurati della formul", "c3d_8n_27c", "c3d_8n_8i", "tipo di elemento", "elemento esaedrico del primo ordine", "tetraedro intero nodale", "intero nodale e ns-fem", "stabilizzarli", "variante w2", "tetraedri del primo ordine", "Interpol prodotto tensoriale del secondo ordine", "gradiente di deformazione continua", "funzione energetica non fisica penalizzata", "numero di verifica della stabilit\u00e0, convergenza e accuratezza della variante sever w2", "formula cag e sfem", "tempo di calcolo nell'analisi esplicita"]}
{"file_name": "S0045782515001322", "text": "Uno dei risultati pi\u00f9 importanti dell'analisi comparativa \u00e8 il fatto che in tutti i casi testati l'uso di FM \u00e8 associato a una drastica riduzione del tempo di calcolo rispetto a FE, generalmente nell'ordine dei secondi per FM e nell'ordine di orari per FE. La tabella 1 riporta i tempi delle simulazioni per entrambi i metodi. L'espansione libera \u00e8 il caso pi\u00f9 veloce, dove FM raggiunge la configurazione senza carico in soli 2 s, mentre le simulazioni all'interno dei vasi con diametro di circa 30 mm richiedono circa 30 s. La maggior parte del tempo di esecuzione dell'algoritmo di distribuzione FM \u00e8 dedicato al controllo del contatto e ai calcoli delle implicazioni che la parete del vaso ha sulla struttura dello stent. \u00c8 interessante notare che in entrambi i metodi, il tempo di calcolo pi\u00f9 elevato (vale a dire, vasi curvi) non \u00e8 associato alla geometria pi\u00f9 complessa (vale a dire, caso paziente-specifico di dissezione aortica). Un altro fatto degno di nota \u00e8 la relazione tra il tempo di calcolo e il diametro del vaso in entrambi i metodi. Mentre il tempo di calcolo di FM sembrava essere direttamente correlato al diametro del vaso, non \u00e8 stata trovata alcuna relazione immediata per le simulazioni FE. Tale risultato \u00e8 probabilmente legato al modello di contatto semplificato utilizzato da FM, che fa s\u00ec che l'espansione dello stent-graft termini una volta che i nodi entrano in contatto con la parete del vaso. Al contrario, \u00e8 noto che l'algoritmo di contatto utilizzato nelle analisi FE aumenta il costo computazionale delle simulazioni.", "keyphrases": ["modello di contatto semplificato", "nodo", "simul", "fe", "l'innesto stent si espande", "analisi comparativa", "Algoritmo di distribuzione FM", "nave", "analisi fe", "vaso curvo", "algoritmo di contatto", "FM", "parete del vaso", "fe simul"]}
{"file_name": "S0168365912007560", "text": "Abbiamo affrontato la questione se l'accoppiamento dei carboidrati aumentasse l'assorbimento dell'antigene da parte delle DC tramite il targeting del recettore della lectina di tipo C. Pertanto, gli antigeni sono stati etichettati con il colorante pHrodo Red (Invitrogen), un colorante che emette fluorescenza specifica quando il pH diminuisce da neutro ad acido, come previsto negli endosomi/lisosomi delle cellule. La caratterizzazione in vitro dell'assorbimento cellulare dei neoglicocomplessi utilizzando cellule dendritiche derivate dal midollo osseo (BMDC) ha dimostrato un'ingestione superiore dei coniugati mannano MN-Ova e MN-Pap (Figura supplementare S4A-D, F). Ci\u00f2 \u00e8 stato confermato in vivo mediante iniezione intradermica con ago dell'antigene marcato nei padiglioni auricolari dei topi. L'assorbimento e il trasporto dell'antigene ai dLN dell'orecchio sono stati misurati dopo 24 ore mediante analisi FACS. Le DC nei LN cervicali sono state identificate in base alla loro elevata espressione di MHC di classe II (Figura 3A) e inoltre caratterizzate dall'espressione di CD8\u03b1, CD11b e CD11c e dall'assorbimento dell'antigene marcato con pHrodo (Figura 3B, D-F). I risultati hanno mostrato un numero significativamente elevato di DC pHrodo+MHCIIhigh per i coniugati di mannano MN-Ova e MN-Pap (e in misura minore per MD-Pap) rispetto agli antigeni non modificati (Figura 3C). Entrambi i carboidrati miravano all'antigene preferenzialmente alle DC CD8\u03b1\u2212, come indicato da un aumento delle DC CD8\u03b1\u2212/pHrodo+ rispetto agli antigeni non modificati (Figura 3E e F). Tuttavia, non \u00e8 stato completamente chiarito se gli antigeni siano stati assorbiti in situ dalle DC dermiche o dalle APC residenti nei LN attraverso i vasi linfatici afferenti. L'istologia ha rivelato che le cellule caricate con l'antigene nei dLN erano gi\u00e0 presenti 30 minuti dopo l'iniezione intradermica (Figura supplementare S4G), suggerendo entrambi i meccanismi.", "keyphrases": ["ingerire", "antigene phrodo-label", "cd8\u03b1\u2212/frodo+ dc", "phrodo+mhciihigh ma", "cd11b", "Bersaglio del recettore della lectina di tipo c", "mn\u2013ova", "cd8\u03b1", "mn-pap", "carboidrati", "cd8\u03b1\u2212cc", "cellule dendritiche derivate del midollo osseo", "fluorescente", "iniezione intradermica", "endosom", "iniezione intradermica con ago", "mannano-coniugante mn\u2013ova e mn\u2013pap", "lisosoma", "cella di carico dell'antigene", "analisi fac", "antigene", "colorante rosso phrodo", "se la coppia di carboidrati aumenta l'assorbimento dell'antigene", "md\u2013pap", "neoglicocomplesso", "invitrogeno", "cd11c", "bmdc"]}
{"file_name": "S2212667814001464", "text": "Recentemente, la tecnologia di virtualizzazione della rete ha attirato notevole attenzione come una delle tecnologie di rete di nuova generazione. In questo articolo, al fine di consentire il rapido cambiamento della topologia di una rete virtuale, proponiamo un nuovo metodo di costruzione della rete virtuale basato sul percorso pi\u00f9 breve. Nel metodo da noi proposto, inizialmente, un fornitore di servizi riceve la richiesta di un utente per la riconfigurazione della rete virtuale costruita. In questo caso, il fornitore di servizi riconfigura rapidamente la topologia della rete virtuale costruita in base al percorso pi\u00f9 breve. Valutiamo le prestazioni del nostro metodo proposto con la simulazione e mostriamo l'efficacia del nostro metodo proposto.", "keyphrases": ["tecnologia virtuale di rete", "percorso pi\u00f9 breve tra", "rete virtuale", "metodo di costruzione della rete virtuale", "simul", "tecnologia di rete di nuova generazione", "costruire una rete virtuale", "cambiamento rapido per la topologia di una rete virtuale", "riconfigurare la rete virtuale del costrutto", "metodo proposto", "riconfigurare la topologia della rete virtuale di costruzione", "servizio fornito"]}
{"file_name": "S0167844214000652", "text": "Un cedimento del legame \u00e8 pensato come una nucleazione di micro-fessure, in particolare come una separazione tra le cellule adiacenti nella struttura cellulare lungo la loro faccia comune. Inizialmente, le microfessure potrebbero essere disperse nel modello riflettendo la distribuzione casuale delle dimensioni dei pori e il basso livello di interazione dovuto alla ridistribuzione delle forze. L'interazione e la coalescenza possono verificarsi con l'aumento della popolazione di microfessure. Queste situazioni sono illustrate nella Figura 3. La struttura della superficie danneggiata pu\u00f2 essere rappresentata con un grafico matematico, dove i nodi del grafico rappresentano le facce danneggiate e i bordi del grafico esistono tra le facce danneggiate con tripla linea comune nella struttura cellulare, cio\u00e8 dove due micro-fessure formava una crepa continua pi\u00f9 grande. Con riferimento alla Figura 3, ciascuna faccia fallita \u00e8 un nodo del grafico e ogni coppia di facce fallite vicine \u00e8 un bordo del grafico.", "keyphrases": ["fallimento obbligazionario", "nucleato di micro-fessure", "poro", "grafico matematico", "separarsi tra le cellule adiacenti nella struttura cellulare lungo la loro faccia comune", "micro-fessurazione", "crepa", "struttura cellulare", "superficie fallita", "faccia da fallimento"]}
{"file_name": "S1386505616301769", "text": "I presunti vantaggi dell\u2019implementazione dell\u2019EMR nelle baraccopoli urbane sono ampiamente promossi. Sistemi informativi sanitari sempre pi\u00f9 efficienti potrebbero facilitare la comunicazione, aiutare a coordinare l\u2019assistenza e migliorare la continuit\u00e0 dell\u2019assistenza nelle comunit\u00e0 svantaggiate come Kibera. Tuttavia, i sistemi disponibili potrebbero non avere la capacit\u00e0 di semplificare l\u2019assistenza o migliorare l\u2019efficienza laddove i finanziamenti e le risorse umane sono scarsi, le infrastrutture sono inaffidabili e le richieste di dati sanitari sono opportunistiche, non strategiche. Questo studio ha descritto le percezioni delle parti interessate locali dell'EMR in due cliniche di baraccopoli urbane. Hanno condiviso molte osservazioni che potrebbero essere importanti per altre iniziative EMR da tenere in considerazione e si sono preoccupati maggiormente della sostenibilit\u00e0 delle iniziative EMR in comunit\u00e0 simili. Il futuro dell\u2019uso degli EMR nelle baraccopoli urbane \u00e8 promettente. Nuove tecnologie innovative, come le applicazioni mobili e i test di laboratorio nei punti di cura, potrebbero estendere la portata degli EMR laddove mancano le infrastrutture. I nuovi ecosistemi EMR basati su cloud, in cui i dati vengono raccolti e archiviati centralmente, potrebbero sfruttare le reti di telefoni cellulari per promuovere una maggiore condivisione delle informazioni sanitarie, il coordinamento delle cure e, in definitiva, risultati migliori per le popolazioni vulnerabili. Punti di sintesi Cosa era gi\u00e0 noto sull'argomento? associato alla crescita del numero e delle dimensioni delle baraccopoli urbane e al conseguente aumento del carico di malattie, peggiorando ulteriormente un sistema sanitario gi\u00e0 frammentato e inefficiente.", "keyphrases": ["em implementare", "app mobile", "sistema informativo sanitario", "emr", "Ecosistema emr basato sul cloud"]}
{"file_name": "S0370269304009074", "text": "In questa Lettera estendiamo la soluzione di McVittie ai buchi neri carichi. Per prima cosa deduciamo la metrica per un buco nero di Reissner-Nordstr\u00f6m nell'universo in espansione; diversi casi speciali della nostra soluzione sono esattamente gli stessi di alcune soluzioni scoperte in precedenza. Nel lavoro precedente [6] abbiamo applicato le condizioni asintotiche per ricavare la metrica di Schwarzschild nell'universo in espansione, che \u00e8 esattamente la stessa derivata da McVittie risolvendo le equazioni complete di Einstein. Ci\u00f2 dimostra la potenza di questo approccio semplice e diretto. In questa Lettera seguiamo la stessa procedura per ricavare la metrica per i buchi neri di Reissner\u2013Nordstr\u00f6m nell\u2019universo di Friedman\u2013Robertson\u2013Walker. Studiamo poi le influenze dell'evoluzione dell'universo sulla dimensione del buco nero. Infine, per studiare il movimento del pianeta, riscriviamo la metrica dal sistema di coordinate cosmiche al sistema di coordinate di Schwarzschild.", "keyphrases": ["dedurre la metrica per un buco nero di Reissner-Nordstr\u00f6m nell'universo in espansione", "seguire la stessa procedura per derivare la metrica", "estendi la soluzione Mcvittie nel buco nero carico", "caricare il buco nero", "Buco nero di Reissner-Nordstr\u00f6m", "buco nero", "Buco nero di Reissner\u2013Nordstr\u00f6m nell'universo di Friedman\u2013Robertson\u2013Walk", "condizione asintotica per derivare la metrica di Schwarzschild", "soluzione mcvittie", "studiare il moto del pianeta", "riscrivere la metrica dal sistema di coordinate cosmiche al sistema di coordinate di Schwarzschild", "studia l'influenza dell'evoluzione dell'universo sulla dimensione del buco nero", "applicare la condizione asintotica per derivare la metrica di Schwarzschild nell'universo espanso", "risolvere l'intero equat di Einstein"]}
{"file_name": "S2212667812000792", "text": "Viene presentato un modello guidato dai processi per costruire un sistema di gestione amministrativa dell'istruzione superiore istintivo ed efficiente per superare i problemi che la maggior parte delle universit\u00e0 si trova ad affrontare. Con questo modello, i processi vengono identificati esplicitamente e la routine dell\u2019amministrazione educativa viene suddivisa in piccoli compiti. Ogni attivit\u00e0 ha un ruolo designato di esecutori. Un processo descrive le attivit\u00e0 e le relazioni tra di loro. Un prototipo di sistema amministrativo per l'istruzione superiore \u00e8 costruito con la soluzione aperta Bonita. La demo mostra che il sistema amministrativo dell'istruzione superiore, basato sui processi, aiuta gli utenti finali a comprendere i processi in cui sono coinvolti e a concentrarsi su cosa fare.", "keyphrases": ["sistema amministrativo", "modello guidato dai processi", "processo sono identificati", "sistema di gestione amministrativa", "comprendere il processo in cui sono coinvolti", "bonita soluzione aperta", "educa amministraz", "problema superato"]}
{"file_name": "S0038092X15001024", "text": "Le catene di Markov della velocit\u00e0 del vento e dell'altezza delle nuvole vengono prodotte tenendo conto delle variazioni stagionali. Viene utilizzata una catena di Markov per ciascuna variabile che rappresenta ciascuna delle quattro stagioni, catturando la variabilit\u00e0 in diversi periodi dell'anno, per un totale di quattro catene ciascuna. Le catene di Markov del numero okta considerano anche l'effetto della stagione, con l'inclusione degli impatti della pressione e della variazione diurna. Vengono prodotte otto catene okta Markov divise per pressione superiore e inferiore alla media per ogni stagione, e vengono prodotte quattro catene okta Markov mattutine aggiuntive per catturare la variazione diurna per le transizioni okta tra le 00:00 e le 05:00 per ogni stagione. L'intento \u00e8 quello di catturare la variazione nella probabilit\u00e0 di transizione che si verifica a seguito dei cambiamenti meteorologici dovuti alla presenza di energia solare. Le 5 del mattino sono considerate il limite perch\u00e9 \u00e8 l'alba tipica dell'estate per i luoghi di studio applicato. 5h rappresenta 5 okta transizioni ed \u00e8 considerata una durata appropriata per rappresentare la leggera propensione allo spostamento verso un aumento okta, la Figura 8 mostra le differenze di transizione diurna. La Figura 2 mostra visivamente la catena media di Markov okta per l'intero anno, mentre l'effetto della stagione pu\u00f2 essere visto nella Figura 11.", "keyphrases": ["okta catena markoviana", "Catena di Markov velocit\u00e0 del vento e altezza delle nuvole", "catena di Markov", "catena di markov numero okta", "catturare la variazione probabile del transito"]}
{"file_name": "S0021999115007895", "text": "La dinamica di vari fenomeni fisici, come il movimento dei pendoli, dei pianeti o delle onde dell'acqua, pu\u00f2 essere descritta in un quadro variazionale. Lo sviluppo dei principi variazionali per la meccanica classica risale a Eulero, Lagrange e Hamilton; una panoramica di questa storia pu\u00f2 essere trovata in [1,19]. Questo approccio permette di esprimere tutta la dinamica di un sistema in un unico funzionale \u2013 la Lagrangiana \u2013 che \u00e8 un integrale di azione. La meccanica hamiltoniana \u00e8 una riformulazione della meccanica lagrangiana che fornisce un quadro utile per studiare le propriet\u00e0 di simmetria di un sistema. Ci\u00f2 \u00e8 espresso dal teorema di Noether che stabilisce la connessione diretta tra le propriet\u00e0 di simmetria dei sistemi hamiltoniani e le leggi di conservazione. Quando si approssima numericamente il sistema, \u00e8 vantaggioso preservare la struttura hamiltoniana anche a livello discreto. Dato che i sistemi hamiltoniani sono abbondanti in natura, la loro approssimazione numerica \u00e8 quindi un argomento di notevole rilevanza.", "keyphrases": ["approccio", "singola funzione", "numero approssimativo", "azione integrale", "pendolo", "esprimere tutta la dinamicit\u00e0 di un sistema", "struttura", "sistema hamiltoniano", "onda d'acqua", "la dinamica dei vari fenomeni fisici", "movimento di pendoli, pianeti o onde dell'acqua", "lagrangiana", "studiare le propriet\u00e0 dei simmetri di un sistema", "meccanico hamiltoniano", "sistema", "riformula della meccanica lagrangiana", "quadro di variazione", "pianeta", "principio variat", "dinamica di un sistema", "fenomeni fisici"]}
{"file_name": "S2212671612001163", "text": "L'articolo tratta il calcolo dei parametri di affidabilit\u00e0 dei componenti della rete di distribuzione. La conoscenza dei parametri di affidabilit\u00e0 dei componenti nelle reti elettriche \u00e8 necessaria per il calcolo dell'affidabilit\u00e0 e anche per il sistema di manutenzione incentrato sull'affidabilit\u00e0. I parametri di affidabilit\u00e0 dei componenti possono essere recuperati solo con database accurati delle societ\u00e0 di distribuzione. Tale database include registrazioni di interruzioni e interruzioni nelle reti elettriche. \u00c8 impossibile recuperare i parametri di affidabilit\u00e0 da questi dati in modo diretto a causa dell'eterogeneit\u00e0. In questo articolo presentiamo alcuni risultati dei calcoli sui database. Applichiamo questo framework per il recupero dei parametri dai dati di interruzione nelle repubbliche ceca e slovacca. Ci sono anche risultati concreti.", "keyphrases": ["dati", "Accur database di societ\u00e0 distributrici", "comp", "rete elettrica", "recuperare", "database", "eterogeneo", "calcolo affidabile", "recuperare il parametro affidabile", "calcolo dei parametri affidabili dei componenti della rete distribuita", "framework per il recupero di parametri da dati outag", "sistema di manutenzione affidabile", "introdurre alcuni risultati del calcolo del database", "parametro affidabile del componente", "registrazione delle interruzioni e delle interruzioni"]}
{"file_name": "S0038092X14004770", "text": "L\u2019ombreggiamento pu\u00f2 rappresentare il fattore pi\u00f9 dannoso sulle prestazioni di un impianto domestico. L'impatto dell'ombreggiamento sulle prestazioni varia a seconda della serie elettrica e della disposizione in parallelo delle celle all'interno di un modulo e dei moduli all'interno di un array installato. Sebbene siano stati proposti molti approcci all\u2019analisi dell\u2019ombreggiamento, l\u2019efficienza computazionale non viene riportata nonostante sia di grande importanza quando si incorporano algoritmi di ombreggiatura in un modello di rendimento energetico complessivo. La mancata considerazione degli impatti non lineari dell'ombreggiamento su sistemi pi\u00f9 piccoli, ad esempio, significa che la perdita di ombreggiamento \u00e8 notevolmente sottostimata, soprattutto da ostacoli apparentemente piccoli come antenne o camini. Ad esempio, il sistema mostrato nella Figura 1 illustra il caso in cui l'installatore potrebbe aver attestato un fattore di perdita d'ombra vicino all'unit\u00e0 secondo le linee guida sulla microgenerazione del Regno Unito (Micro generation Certification Scheme, 2013), cio\u00e8 trascurabile, ma le prestazioni del sistema sono gravemente compromesse a causa degli effetti di disadattamento delle celle non lineari. Un sottomodello di ombreggiatura efficace deve quindi fornire feedback per prendere decisioni informate sulla disposizione dell'array in prossimit\u00e0 di ostacoli, ma non deve fare affidamento su un calcolo ad alta potenza.", "keyphrases": ["effetto di disadattamento delle celle non lineare", "antenna", "camino", "modello di rendimento energetico", "sistema domestico", "cellula", "modulo", "perdita di ombra", "sottomodello dell'ombra dell'effetto", "sistema mostrato in fig. 1", "fornire feedback per informare le decisioni sul layout dell'array", "installare l'array", "analisi dell'ombra", "algoritmo dell'ombra", "sistema", "calcolo ad alta potenza", "ombra"]}
{"file_name": "S167420011300196X", "text": "Le celle fotovoltaiche rappresentano una delle tecnologie pi\u00f9 promettenti per la conversione della radiazione solare incidente in energia elettrica. Tuttavia, questa tecnologia \u00e8 ancora lontana dall\u2019essere in grado di competere con le tecnologie di conversione energetica basate sui combustibili fossili a causa della sua efficienza e densit\u00e0 energetica relativamente basse. Teoricamente, ci sono tre perdite inevitabili che limitano l'efficienza di conversione solare di un dispositivo con una singola soglia di assorbimento o band gap Eg: (1) assorbimento incompleto, dove i fotoni con energie inferiori a Eg non vengono assorbiti; (2) termalizzazione o raffreddamento del portatore, dove i fotoni solari con energia sufficiente generano coppie elettrone-lacuna e poi perdono immediatamente quasi tutta l'energia in eccesso di Eg sotto forma di calore; e (3) ricombinazione radiativa, dove una piccola frazione degli stati eccitati si ricombina radioattivamente con lo stato fondamentale alla massima potenza in uscita (Hanna & Nozik, 2006; Henry, 1980). Prendendo come esempio una massa d'aria di 1,5, per diversi band gap, ad esempio, \u00e8 possibile calcolare queste tre perdite e i risultati sono indicati dalle aree S1, S2 e S3 nella Figura 1. Si noti che l'area sotto la curva esterna \u00e8 l'energia solare per unit\u00e0 di superficie e che solo S4 pu\u00f2 essere consegnato al carico.", "keyphrases": ["cella fotovoltaica", "termico", "coppia elettrone-olo", "fotone", "conversione solare", "fotone solare", "assorbimento incompleto", "converte la radiazione solare incidente in energia elettrica", "energia solare", "radiazione solare incidente", "potenza elettrica", "assorbire", "portatore fresco", "conversione energetica a base di combustibili fossili", "radi ricombinazione"]}
{"file_name": "S0370269302014892", "text": "Brodsky e Lepage [8] hanno proposto una formula per la produzione di coppie di mesoni che assomiglia alla (25), ad eccezione di un diverso fattore di carica e della comparsa del fattore di forma del mesone elettromagnetico simile al tempo invece del fattore di forma di annichilazione R(s). Questa formula \u00e8 stata ottenuta dal risultato della torsione guida trascurando parte delle ampiezze con elicit\u00e0 fotoniche opposte. Come \u00e8 stato sottolineato in [9], questa parte non \u00e8 per\u00f2 approssimativamente indipendente dall'ampiezza della distribuzione dei pioni e non \u00e8 genericamente piccola. Notiamo anche che la comparsa di F\u03c0(s) nell'ampiezza \u03b3\u03b3\u2192\u03c0+\u03c0\u2212 non \u00e8 pi\u00f9 osservata se si prendono in considerazione le correzioni del momento trasverso partonico nel processo di hard scattering, e che queste correzioni non sono numericamente piccole per l'ampiezza valori di s con cui abbiamo a che fare [13]. Si noti inoltre che l'annichilazione di due fotoni produce due pioni in uno stato C-pari, mentre il fattore di forma elettromagnetico si proietta sullo stato C-dispari di una coppia di pioni. Al contrario, il nostro fattore di forma di annichilazione R2\u03c0(s) \u00e8 C-anche come discusso dopo (24). Infine, a causa di un particolare fattore di carica, la formula di Brodsky-Lepage porta ad una sezione d'urto nulla per l'annichilazione \u03b3\u03b3 in coppie di pseudoscalari neutri.", "keyphrases": ["r2\u03c0(s)", "fotone", "pione", "fattore di forma annientato", "processo di dispersione difficile", "coppia di mesoni", "annichilimento a due fotoni", "prodotto della coppia di mesoni", "mesone elettromagnete", "coppia di pioni", "trascurare parte dell'ampiezza con l'elica fotonica opposta", "formula di Brodskij-Lepag", "sezione d'urto nulla per \u03b3\u03b3 annihil", "fattore di forma dell'elettromagnete", "partone trasversale impulso", "formula per il prodotto della coppia di mesoni", "formula", "elica fotonica", "pseudoscalare neutro"]}
{"file_name": "S0098300413002720", "text": "Le reti neurali artificiali (ANN) sono state ampiamente utilizzate nei problemi scientifici e ingegneristici. Tentano di modellare la capacit\u00e0 dei sistemi nervosi biologici di riconoscere modelli e oggetti. L'architettura di base dell'ANN \u00e8 costituita da reti di funzioni primitive in grado di ricevere pi\u00f9 input ponderati che vengono valutati in termini di successo nel discriminare le classi in \u03a4a. Diversi tipi di funzioni primitive e configurazioni di rete danno luogo a modelli diversi (Hastie, 2009; Rojas, 1996). Durante l'addestramento i pesi delle connessioni di rete vengono adeguati se si verifica un errore nella separazione degli input e delle classi predefinite. La convergenza procede fino a quando la riduzione dell'errore tra le iterazioni raggiunge una soglia di decadimento (Kotsiantis, 2007; Rojas, 1996). Utilizziamo reti feed-forward con un singolo strato nascosto di nodi, un cosiddetto Multi-Layer Perceptron (MLP) (Venables e Ripley, 2002), e selezioniamo uno dei due possibili parametri: dimensione, numero di nodi nello strato nascosto.", "keyphrases": ["ann", "percettrone multistrato", "la riduzione dell'errore tra gli iter raggiunge una soglia di decadimento", "mlp", "modellare la capacit\u00e0 del sistema nervoso biologico di riconoscere modelli e oggetti", "ricevere input di peso multiplo", "ann architettura di base", "convergente", "selezionare uno dei due parametri possibili", "peso", "differiscono nel tipo di funzione primitiva e nella configurazione di rete", "rete feed-forward con un singolo strato nascosto di nodo", "connessione della rete ferroviaria", "rete di funzioni primitive", "rete neurale artificiale", "regolare se la separazione tra input e classe predefinita comporta un errore", "problema di scienza e ingegneria"]}
{"file_name": "S2212671612002338", "text": "La soglia robusta e automatica delle immagini a livello di grigio \u00e8 stata comunemente utilizzata nel campo del riconoscimento di modelli e della visione artificiale per il rilevamento, il tracciamento e il riconoscimento di oggetti. Lo schema Otsu, una tecnica di soglia dell'immagine ampiamente utilizzata, fornisce risultati di approvazione per la segmentazione di un'immagine a livello di grigio con una sola distribuzione modale nell'istogramma del livello di grigio. Tuttavia, fornisce scarsi risultati se l'istogramma di un livello di grigio non \u00e8 bimodale. Per migliorare ulteriormente le prestazioni dell'algoritmo Otsu, in questo lavoro viene presentato un algoritmo di soglia dell'immagine Otsu basato sulla mediana migliorato. Infine vengono eseguiti test approfonditi e gli esperimenti mostrano che il nostro metodo ottiene risultati pi\u00f9 soddisfacenti rispetto all'algoritmo di soglia originale di Otsu.", "keyphrases": ["rilevare", "migliorare la prestazione", "prova estesa", "schema otsu", "istogramma", "distribuzione modale", "Algoritmo di soglia otsu", "immagine del livello di grigio", "soglia robusta e automatizzata", "visione computerizzata", "istogramma del livello di grigio.", "segmento", "Algoritmo di soglia imag mediana-bas otsu", "riconoscimento del modello", "riconoscere", "tecnica della soglia dell'immagine", "traccia", "algoritmo otsu", "rilevamento, tracciamento e riconoscimento di oggetti", "soglia"]}
{"file_name": "S2212671612001291", "text": "Nel documento proponiamo una metodologia concettuale per controllare lo stato liquido delle leghe Al-Si nel sottoprocesso di fusione e mantenimento del processo di pressofusione. Detto questo, determiniamo le caratteristiche del forno di attesa in base alla percentuale in peso (% in peso) di determinate leghe e dei loro elementi. Successivamente il documento introduce un'applicazione della metodologia di ricerca per stabilire le caratteristiche del forno di mantenimento. L'applicazione \u00e8 stata realizzata in condizioni reali in una fonderia che utilizza una macchina a camera fredda orizzontale CLH 400.1. L'analisi chimica \u00e8 stata eseguita dallo spettrofotometro SPECTROLAB JR.CCD 2000. Infine l'ultima parte del documento elenca i risultati generali con possibili direzioni future per estendere questa metodologia nella pratica.", "keyphrases": ["lega", "spettrofotometro", "estendere questo metodo nella pratica", "macchina a camera fredda Horizont", "percentuale in peso", "% in peso", "spectrolab jr.ccd 2000", "processo di pressofusione", "clh 400,1", "analisi chimiche", "caratteristica del forno di attesa", "fonderi", "Metodologia concettuale per il controllo dello stato liquido", "sciogliere e trattenere il sottoprocesso", "applicazione della metodologia di ricerca", "vera condizione", "determinare le caratteristiche del forno di stiva", "tenere il forno", "lega al-si"]}
{"file_name": "S0166361516300926", "text": "Questa ricerca traccia l'implementazione di un sistema informativo sotto forma di moduli ERP che copre la gestione degli inquilini e dei contratti in una societ\u00e0 di servizi cinese. I disallineamenti tra le specifiche del sistema ERP e le esigenze degli utenti hanno portato all\u2019adozione di processi informali all\u2019interno dell\u2019organizzazione. Questi processi sono facilitati all\u2019interno di una struttura organizzativa informale e si basano su interazioni umane intraprese all\u2019interno dell\u2019organizzazione formale. Piuttosto che tentare di sopprimere l\u2019emergere dell\u2019organizzazione informale, l\u2019azienda ha deciso di incanalare le energie del personale coinvolto nei processi informali verso obiettivi organizzativi. L\u2019azienda ha raggiunto questo obiettivo sfruttando le capacit\u00e0 di quello che chiamiamo un sistema ERP ibrido, combinando le funzionalit\u00e0 di un\u2019installazione ERP tradizionale (formale) con le capacit\u00e0 dell\u2019Enterprise Social Software (ESS). Tuttavia, l'azienda ha riconosciuto che il funzionamento efficace del sistema ERP ibrido richiederebbe una serie di cambiamenti nella progettazione organizzativa in aree quali le strutture di reporting e i canali di comunicazione. Una narrazione fornita dalle interviste al personale aziendale \u00e8 tematizzata attorno alle caratteristiche formali e informali dell'organizzazione come definite in letteratura. Ci\u00f2 porta a una definizione delle caratteristiche dell\u2019organizzazione ibrida e delle strategie per abilitare un\u2019organizzazione ibrida, facilitata da un sistema ERP ibrido, che indirizza il comportamento formale e informale verso obiettivi organizzativi e fornisce un modello per future implementazioni ibride.", "keyphrases": ["es", "sistema erp", "modulo erp", "software sociale aziendale", "installazione dell'erp", "sistema erp ibrido"]}
{"file_name": "S0045782515001231", "text": "Analisi isogeometrica. L'idea centrale dell'analisi isogeometrica \u00e8 quella di utilizzare per la discretizzazione dell'equazione alle derivate parziali le stesse funzioni ansatz utilizzate per la rappresentazione della geometria del problema. Di solito, la geometria problematica \u03a9 \u00e8 rappresentata nella progettazione assistita da computer (CAD) mediante NURBS o T-spline. Questo concetto, originariamente inventato in [1] per i metodi agli elementi finiti (IGAFEM) si \u00e8 rivelato molto fruttuoso nelle applicazioni [1,2]; si veda anche la monografia [3]. Poich\u00e9 CAD fornisce direttamente una parametrizzazione del confine \u2202\u03a9, ci\u00f2 rende il metodo degli elementi al contorno (BEM) lo schema numerico pi\u00f9 attraente, se applicabile (ovvero, a condizione che la soluzione fondamentale dell'operatore differenziale sia esplicitamente nota). Il BEM isogeometrico (IGABEM) \u00e8 stato considerato per la prima volta per il BEM 2D in [4] e per il BEM 3D in [5]. A differenza del BEM standard con polinomi a tratti che \u00e8 ben studiato in letteratura, cfr le monografie [6,7] e i riferimenti in esse contenuti, l'analisi numerica di IGABEM \u00e8 essenzialmente aperta. Facciamo riferimento solo a [2,8\u201310] per esperimenti numerici e a [11] per alcune analisi di quadratura. In particolare, la stima dell'errore a posteriori \u00e8 stata ben studiata per il BEM standard, [12\u201318] cos\u00ec come nel recente articolo di panoramica [19], ma finora non \u00e8 stata trattata per l'IGABEM. Lo scopo del presente lavoro \u00e8 quello di far luce sull'analisi degli errori a posteriori per IGABEM che fornisce alcune basi matematiche di un corrispondente algoritmo adattivo.", "keyphrases": ["cadavere", "trave standard", "gettare una prima luce sull'analisi degli errori a posteriori per igabem", "progettazione assistita da computer", "igabem", "funzione ansatz", "analisi degli errori a posteriori", "stima dell'errore a posteriori", "analisi isogeometrica", "T-spline", "metodo degli elementi finiti", "Metodo degli elementi di contorno", "nurb", "analisi del quadrato", "2\u00b0 giorno", "adattare l'algoritmo", "3d bem", "isogeometro bem", "igafem", "problema geometrico", "schema numerico", "analisi numerica di igabem", "beh", "fondamento matematico di un algoritmo di adattamento corrispondente"]}
{"file_name": "S0370269304009232", "text": "Consideriamo singolarit\u00e0 a tempo finito, future (tipo improvviso o Big Rip) che possono verificarsi anche quando la condizione di energia forte non viene violata ma il parametro dell'equazione di stato dipende dal tempo. Recentemente, un esempio di tale singolarit\u00e0 \u00e8 stato presentato da Barrow, ne abbiamo trovato un altro esempio. Prendendo in considerazione la reazione di ritorno dei campi quantistici conformi vicino alla singolarit\u00e0, \u00e8 dimostrato esplicitamente che gli effetti quantistici possono ritardare (o attenuare) la singolarit\u00e0. Si sostiene che se l'evoluzione verso la singolarit\u00e0 \u00e8 realistica, a causa degli effetti quantistici l'universo potrebbe finire nella fase di De Sitter prima che il fattore di scala esploda. Questo quadro \u00e8 generalizzato per il mondo delle brane in cui possono verificarsi improvvise singolarit\u00e0 sulla brana con conclusioni qualitativamente simili.", "keyphrases": ["l\u2019universo potrebbe finire nella fase de sitter", "reazione posteriore del campo quantistico conforme quasi singolare", "braneworld", "qualit\u00e0 simile conclus", "ne abbiamo trovato un altro esempio", "evolve al singolare", "tempo finito, futur (tipo improvviso o grande strappo) singolare", "singolare", "esempio di tale singolare", "singolare improvviso", "brana", "il fattore di scala esplode", "effetto quantistico", "forte condizione energetica"]}
{"file_name": "S0003491615001955", "text": "Un vuoto fluttuante \u00e8 una caratteristica generale dei campi quantistici, di cui il campo libero di Maxwell considerato in [1\u201312] non \u00e8 che un esempio. Anche i campi fermionici, come quello che descrive l'elettrone, subiscono fluttuazioni del vuoto, di conseguenza ci si aspetta di trovare effetti Casimir associati a tali campi ogni volta che sono confinati in qualche modo. Tali effetti sono stati studiati per la prima volta nel context della fisica nucleare, all\u2019interno del cosiddetto \u201cmodello a borsa MIT\u201d del nucleone [13]. Nel modello a borsa si immagina il nucleone come un insieme di campi fermionici che descrivono quark confinati. Questi quark sono soggetti a una condizione al contorno sulla superficie del \"sacchetto\" che rappresenta la superficie del nucleone. Proprio come nel caso elettromagnetico, la condizione al contorno del sacco modifica le fluttuazioni del campo nel vuoto, che si traduce nella comparsa di una forza di Casimir [14\u201318]. Questa forza, sebbene molto debole su scala macroscopica, pu\u00f2 essere significativa sulle piccole scale incontrate nella fisica nucleare. Ha quindi importanti conseguenze per la fisica del nucleone modello a borsa [19].", "keyphrases": ["subire fluttuazioni di vuoto", "il bag boundari condit modifica la fluttuazione del vuoto del campo", "casimiro forc", "nucleone", "campo quantistico", "tale campo", "vuoto fluttuante", "campo di maxwel libero", "\u201cmodello mit bag\u201d del nucleone", "effetto casimiro", "fisica nucleare", "una raccolta di campi fermionici descrive il quark confin", "nucleone modello borsa", "campo fermionico"]}
{"file_name": "S0031920113000708", "text": "I jerk geomagnetici sono fenomeni evidenti ma poco compresi del campo magnetico terrestre, motivando le indagini sulla loro morfologia e sulla teoria dietro le loro origini. I jerk sono pi\u00f9 comunemente definiti dalla loro forma osservata in un singolo osservatorio come forme a \"V\" in un singolo componente della variazione secolare geomagnetica (SV), la prima derivata temporale del campo magnetico principale (MF). Ai tempi delle variazioni del gradiente, che separano andamenti lineari di diversi anni, sono associati cambiamenti a gradino nella derivata temporale seconda della MF (accelerazione secolare (SA)) e impulsi nella derivata temporale terza. La definizione SV di jerk a forma di \"V\" include un'aspettativa implicita di un cambiamento di \"grande\" grandezza nel gradiente senza la definizione di questa scala o del suo valore di soglia diversa dalla necessit\u00e0 di base che sia osservabile nei dati al di sopra dell'altamente variabile rumore di sottofondo. I jerk possono essere descritti dalla loro ampiezza, cio\u00e8 dalla differenza nei gradienti dei due segmenti lineari SV attorno a uno strappo, A=a2-a1, dove a2 \u00e8 il gradiente dopo lo strappo e a1 \u00e8 il gradiente prima dello strappo. Questa misura \u00e8 essenzialmente la modifica SA pi\u00f9 adatta durante uno scatto. L'ampiezza del jerk \u00e8 quindi positiva per un passo positivo in SA e negativa per un passo negativo. Qui non consideriamo l'estensione spaziale nella nostra definizione e ci riferiamo alle caratteristiche individuali in un componente del campo di una data serie temporale dell'osservatorio come un singolo jerk.", "keyphrases": ["acceleratore secolare", "s\u00ec", "segmento sv", "campo magnetico", "variante secolare", "sbalzo", "campo magnetico terrestre", "campo magnetico principale", "ampiezza dello scatto", "geomagnete variante secolare", "scatto del geomagnete", "nel cambiamento", "sv", "modifica del passo di ampiezza \"grande\".", "modifica del gradiente", "mf"]}
{"file_name": "S0045782513000479", "text": "Gli algoritmi riguardanti i campi di distanza risalgono all'equazione del livello impostato. Il metodo del level set \u00e8 stato presentato da Osher e Sethian [20] che hanno descritto la propagazione temporale delle interfacce in movimento mediante metodi numerici risolvendo l'equazione di Hamilton-Jacobi. Ci\u00f2 viene eseguito mediante uno schema alle differenze finite che lavora su una griglia rettangolare in due o tre dimensioni. \u00c8 possibile ottenere informazioni sui vettori normali e sulla curvatura. Il metodo della marcia veloce [21] fornisce un efficiente schema numerico di complessit\u00e0 nlogn per calcolare i valori di supporto sulla griglia. Si tratta di una reinterpretazione del processo di propagazione, cio\u00e8 il tempo in cui l'interfaccia passa un certo punto della griglia \u00e8 influenzato solo da quei punti della griglia vicini che sono stati precedentemente attraversati dall'interfaccia. Una panoramica sulla teoria dei metodi di level set e di marcia veloce e le loro applicazioni a problemi di varie aree \u00e8 fornita in [22,23], ad esempio compensazione della forma, calcolo delle distanze, sviluppo della fotolitografia, tempi di viaggio sismici, ecc. I campi di distanza sono un caso speciale dell'equazione del livello in cui il valore assoluto della velocit\u00e0 di avvezione \u00e8 1.", "keyphrases": ["campo di distanza", "livello impostato", "tempo di percorrenza sismica", "livello impostato equat", "schema numerico del nlogn complesso per calcolare il valore del supporto sulla griglia", "il tempo in cui l'interfaccia passa un certo punto della griglia \u00e8 influenzato solo dai punti della griglia vicini che sono passati precedentemente dall'interfaccia", "calcolare la distanza", "processo di propagazione", "nlogn complesso", "uguaglianza hamilton-jacobi", "metodo della marcia veloce", "griglia rettangolare in due o tre dimensioni", "schema di differenze finite", "si sviluppano fotolitografie", "marcia veloce", "metodo numerico", "metodo di impostazione del livello", "propagazione temporale", "L'algoritmo riguarda il campo delle distanze", "la zona", "teoria dell'insieme di livelli", "spostamento della forma"]}
{"file_name": "S0263822312000657", "text": "I materiali a classificazione funzionale (FGM), descritti in dettaglio da Suresh e Mortensen [1], sono un tipo di materiali compositi eterogenei che mostrano una variazione graduale nella frazione volumetrica dei loro costituenti da una superficie del materiale all'altra, con conseguente propriet\u00e0 che variano continuamente attraverso il materiale. L'idea di un materiale classificato in modo funzionale non \u00e8 nuova, infatti ci sono molti materiali naturali che presentano questa propriet\u00e0. Lo studio di ossa, conchiglie, legno di balsa e bamb\u00f9 mostra che sono tutti classificati con la massima resistenza all'esterno, nelle aree in cui \u00e8 richiesta la massima protezione. Tuttavia \u00e8 stato solo negli anni '80 in Giappone [2] che l'idea di un materiale classificato in modo funzionale \u00e8 stata attivamente ricercata al fine di ottenere progressi nei materiali resistenti al calore da utilizzare nei reattori aerospaziali e nucleari a fissione.", "keyphrases": ["reattore a fissione nucleare", "legno di balsa", "bamb\u00f9", "aerospaziale", "osso", "conchiglia", "fgm", "materiale resistente al calore", "studi di osso, conchiglia, balsa e bamb\u00f9", "materiali compositi eterogenei", "materiali del grado funzionale"]}
{"file_name": "S2212667814001348", "text": "Alcune equazioni d'onda non lineari sono pi\u00f9 difficili da studiare matematicamente, poich\u00e9 non esiste un metodo analitico generale per le loro soluzioni. La tecnica della Differenza Temporale Esponenziale (ETD) richiede fasi minime per ottenere la precisione richiesta, il che suggerisce una tecnica efficiente in termini di durata computazionale che garantisce notevoli caratteristiche di stabilit\u00e0 nella risoluzione di equazioni d'onda non lineari. Questo articolo risolve l'esempio diagonale dell'equazione di Kawahara tramite la tecnica ETD Runge-Kutta 4. L'implementazione di questa tecnica \u00e8 proposta da brevi programmi Matlab.", "keyphrases": ["calcola durata", "onda non lineare equat", "resolv onda non lineare equat", "ecc", "caratteristiche stabili su", "matematica investigativa", "risolvi l'esempio del diagramma di kawahara equat", "programma matlab", "etd runge-kutta 4 tecnica", "esponenti differenza temporale", "stadio minimo", "metodo dell'analista"]}
{"file_name": "S2212667812000780", "text": "Con lo sviluppo degli studenti sportivi normali in Cina, alcune idee di insegnamento e apprendimento che vedono l'apprendimento come un semplice processo di conoscenza sono diventate obsolete e inefficaci, quindi, al fine di migliorare la qualit\u00e0 dell'insegnamento e dell'apprendimento degli studenti sportivi normali in Cina, questo autore ha discusso alcuni fattori sulla promozione del livello di insegnamento e apprendimento per gli studenti normali dello sport, come il principio di implementazione, la progettazione del curriculum, la politica educativa e cos\u00ec via. Vengono discussi il significato dei risultati e le loro implicazioni per la ricerca futura.", "keyphrases": ["implementare il principio", "migliorare la qualit\u00e0 dell'insegnamento e dell'apprendimento nello sport per studenti normali", "Imparare", "progettazione del curriculum", "fattore di promozione del livello di insegnamento e apprendimento", "insegnare", "conoscenza", "ricerca futura", "educazione politica"]}
{"file_name": "S0377221716304258", "text": "I modelli a due stati sono spesso insufficienti per adattare tracce complesse, quindi studiamo anche l'adattamento approssimativo di grandi M3PP. Nel context di una singola classe, una limitazione nota degli MMPP \u00e8 l\u2019incapacit\u00e0 di adattare simultaneamente molti descrittori statistici a causa della non linearit\u00e0 delle loro equazioni sottostanti (Bodrog, Heindl, Horv\u00e1th e Telek, 2008; Heindl, Horv\u00e1th e Gross, 2006 ; Horvath & Telek, 2009). Ci\u00f2 ha portato alla definizione di diversi approcci per adattare tracce complesse componendo pi\u00f9 MMPP o MAP di piccole dimensioni utilizzando operatori Kronecker (Andersen & Nielsen, 1998; Casale, Zhang, & Smirni, 2010; Horv\u00e1th & Telek, 2002). Questi metodi utilizzano operatori di composizione per l'adattamento del momento, offrendo un diverso compromesso tra costo computazionale e accuratezza dell'adattamento rispetto ai metodi di adattamento basati sull'algoritmo EM (Breuer, 2002; Horv\u00e1th & Okamura, 2013; Klemm, Lindemann e Lohmann, 2003). . In particolare, l'operatore di sovrapposizione consente di descrivere una traccia mediante multiplexing statistico di pi\u00f9 MMPP, a scapito di una crescita esponenziale del numero di stati nel processo risultante (Sriram & Whitt, 1986). Questa esplosione dello spazio degli stati rappresenta un ostacolo per l\u2019applicazione di MMPP e MAP alla modellazione di sistemi reali; ad esempio rallenta notevolmente, o addirittura rende irrealizzabile, la valutazione numerica di modelli di code mediante metodi geometrici a matrice (Bini, Meini, Steff\u00e9, P\u00e9rez, & Houdt, 2012; P\u00e9rez, Velthoven, & Houdt, 2008).", "keyphrases": ["modello a due statistiche", "lo spazio statale esplode", "compos multipl mmpp o mappa di piccole dimensioni", "metodo della geometria delle matrici", "valore numerico del modello di coda", "sovrapposizione operat", "sottoli equat", "Kroneck opera", "mmpp e mappa", "opera composita", "algoritmo", "descrittore statalista", "studia l'adattamento approssimativo di larg m3pp", "multiplex statista di sever mmpp", "m3pp", "sistema reale modello", "mmpp", "metodo di adattamento"]}
{"file_name": "S004578251400334X", "text": "In questo articolo proponiamo un metodo che adotta un approccio diverso alla procedura di generazione sopra delineata e che aiuta ad affrontare il problema della generazione di mesh di ordine elevato per flussi con numeri di Reynolds elevati. Il metodo \u00e8 concettualmente semplice, economico da implementare e non richiede una fitta maglia lineare di strato limite. Si basa sull'uso di un'interpolazione isoparametrica [17] o, in generale, transfinita [18] in cui una mesh prismatica grossolana dello strato limite di ordine elevato \u00e8 suddivisa in prismi o tetraedri utilizzando la mappatura che definisce l'interpolazione grossolana alta- prismi dell'ordine. La procedura \u00e8 inoltre molto versatile in quanto permette di generare con facilit\u00e0 mesh con diverse distribuzioni di y+ ed inoltre la validit\u00e0 di tali mesh \u00e8 garantita se la mesh iniziale \u00e8 valida e lo spazio polinomiale \u00e8 scelto opportunamente.", "keyphrases": ["prisma di alto livello", "maglia iniziale", "suddiviso in prismi o tetraedri", "flusso dei numeri di Reynolds", "tetraedri", "maglia", "procedura generale", "isoparametro [17] o, in generale, un interpol transfinito", "genera mesh di alto livello per un flusso di numeri di Reynold elevato", "prisma", "Maglia prismatica a disposizione dei confini con struttura grossolana di alto livello", "spazio polinomiale", "maglia di alto livello", "dens rete lineare perimetrale"]}
{"file_name": "S0301010414003516", "text": "Array di TFT e circuiti sono stati fabbricati su substrati prepuliti, 5 cm \u00d7 5 cm, 125 \u03bcm di spessore di polietilene naftalato (PEN) (Dupont-Teijin). I dettagli completi delle nostre procedure di fabbricazione sotto vuoto sono stati forniti in pubblicazioni precedenti [17\u201319,23]. In breve, gli elettrodi di gate in alluminio e le tracce associate sono stati evaporati sotto vuoto sui substrati attraverso maschere d'ombra. Successivamente, i substrati sono stati fissati ad un tamburo di spalmatura raffreddato (Aerre Machines). Con il tamburo che ruotava a una velocit\u00e0 lineare di 25 m/min sotto vuoto, il vapore di monomero TPGDA evaporato flash che si condensava sui substrati veniva reticolato mediante esposizione, in situ, a un plasma. Le pellicole risultanti, lisce e prive di fori stenopeici, avevano tipicamente uno spessore compreso tra 500 nm e 1 \u03bcm con una costante dielettrica misurata che variava nell'intervallo 4-5. Per la fabbricazione del circuito, l'isolante \u00e8 stato modellato utilizzando maschere d'ombra per definire aree rettangolari separate da spazi di 1 mm per fungere da vie per le connessioni metalliche tra gli strati. I substrati sono stati quindi trasferiti in un evaporatore (Minispectros, Kurt Lesker) integrato in un vano portaoggetti di azoto per la deposizione sotto vuoto (2,4 nm/min) di DNTT sull'isolante. Senza esporre i substrati all'aria ambiente, lo strato di metallizzazione source/drain dell'oro \u00e8 stato depositato attraverso una maschera d'ombra nello stesso evaporatore.", "keyphrases": ["maschera d'ombra", "circuito", "vuoto", "substrato", "vano portaoggetti ad azoto", "tamburo", "polietilennaftale", "substrato di polietilennaftal (penna).", "evaporazione sotto vuoto", "elettrodo con cancello in alluminio", "tamburo del rivestimento in rete", "plasma", "flash-evaporatore tpgda monom vapore", "insul", "procedura di tessuto sottovuoto", "aria ambiente", "tessuto del circuito", "tft", "deposito sottovuoto", "traccia", "film", "connessione metallica inter-lay", "penna", "esposizione", "reticolazione", "evaporare", "strato metallico di sorgente/scarico dell'oro"]}
{"file_name": "S0021999114002587", "text": "I progettisti di dispositivi microfluidici hanno bisogno di strumenti computazionali che possano essere utilizzati per analizzare problemi che coinvolgono flussi di gas rarefatti in microgeometrie complesse. La simulazione numerica del flusso di gas attraverso tali geometrie \u00e8, tuttavia, estremamente impegnativa. La fluidodinamica continua convenzionale (CFD) diventa non valida o imprecisa quando la scala caratteristica della geometria (l'altezza del canale, h) si avvicina al percorso libero medio molecolare, \u03bb [1,2]. Quando \u03bb/h\u22730,1, l'errore nelle soluzioni ottenute dalla CFD pu\u00f2 essere significativo e dobbiamo considerare il fluido per quello che \u00e8: un insieme di particelle interagenti. Tuttavia, la spesa computazionale per simulare il flusso di un gas rarefatto in microgeometrie con rapporti di aspetto elevati (cio\u00e8 lunghe, rispetto alla loro sezione trasversale) utilizzando un metodo particellare, come il metodo Monte Carlo di simulazione diretta (DSMC) [2], pu\u00f2 essere proibitivo [3,4]. L'intensit\u00e0 computazionale del metodo delle particelle \u00e8 ancora maggiore quando si simulano dispositivi microfluidici a bassa velocit\u00e0 dove ci sono solo piccole deviazioni dall'equilibrio, caratterizzati da numeri di Mach estremamente bassi e gradienti di temperatura deboli.", "keyphrases": ["microgeometrie ad alto rapporto d'aspetto", "numero di Mach estremamente basso e gradiente di temperatura debole", "CFD", "dsmc", "lungo, riferiti alla loro sezione trasversale", "dispositivo microfluido", "numero simul", "analizza problemi che coinvolgono flussi rarefatti in microgeometri complessi", "diretto simul mont carlo", "convento fluidodinamico continuo", "flusso di un rarefi ga", "piccolo scostamento dall\u2019equilibrio", "flusso ga", "metodo delle particelle", "raccogliere di interagire particl", "flusso rarefi ga"]}
{"file_name": "S1875952116300209", "text": "Per verificare se i modelli tattili possono trasmettere o migliorare la musica d'atmosfera di un film, \u00e8 stato richiesto un corpus di filmati affettivi costituito da clip etichettati in base all'emozione trasmessa nella musica d'atmosfera. Le seguenti raccolte di database sono state esaminate come possibili fonti per il corpus: Emotional Movie Database (EMDB) [19] e Film Stim [20]. Tuttavia, questi sono stati scartati dopo la revisione in quanto non idonei. Lo scopo di questo studio \u00e8 quello di migliorare l'atmosfera nella colonna sonora del film e, nel caso delle clip nell'EMDB, non viene fornito alcun audio che ritenga le clip inadatte. Nel caso del database Film Stim, le clip sono in francese anzich\u00e9 in inglese e senza sottotitoli, anch'essi ritenuti inadeguati poich\u00e9 gli studi sono condotti con partecipanti di lingua inglese. Inoltre, la selezione di Film Stim si basa sul contenuto affettivo della narrazione poich\u00e9 nella maggior parte di essi non \u00e8 presente musica che sia inadatta a quanto discusso. Dalla nostra revisione delle raccolte di database disponibili, \u00e8 emerso che al momento non esiste un corpus standard di filmati affettivi in \u200b\u200bcui l'indicizzazione affettiva si riferisse alla partitura musicale del filmato.", "keyphrases": ["emo i database dei movimenti", "i database raccolgono", "emb", "testare se il modello tattile pu\u00f2 trasmettere o migliorare la musica d'atmosfera", "database di stimolazione cinematografica", "revisione della raccolta dei database di avvale", "selezionare la stimolazione del film", "partecipazione in inglese", "migliorare l'umore", "influiscono sul corpo dei filmati", "revisione", "stimolazione cinematografica"]}
{"file_name": "S0927025615006357", "text": "In questo articolo, il modello di plasticit\u00e0 cristallina, in combinazione con XFEM, \u00e8 stato applicato per studiare la deformazione ciclica e la crescita di cricche da fatica in una superlega a base di nichel LSHR (Low Solvus High Refractory) ad alta temperatura. Il primo obiettivo di questa ricerca era sviluppare e valutare un modello a elementi finiti basato su RVE con l'incorporazione di una microstruttura materiale realistica. Il secondo obiettivo di questo lavoro era determinare i parametri di un modello costitutivo di plasticit\u00e0 cristallina per descrivere il comportamento di deformazione ciclica del materiale utilizzando una subroutine del materiale definita dall'utente (UMAT) interfacciata con il pacchetto di elementi finiti ABAQUS. I parametri del modello sono stati calibrati da analisi approfondite agli elementi finiti per adattarsi ai dati di test monotonici, di rilassamento dello stress e ciclici. Il terzo obiettivo era prevedere la crescita delle cricche combinando la tecnica XFEM e la plasticit\u00e0 cristallina calibrata UMAT, per la quale la deformazione plastica accumulata \u00e8 stata utilizzata come criterio di frattura.", "keyphrases": ["sviluppare e valutare un modello agli elementi finiti rve-bas", "xfem", "basso solvu alto refrattari", "modello agli elementi finiti rve-bas", "superlega a base di nichel lshr", "calibro cristallo di plastica umat", "modello in plastica di cristallo", "tecnica xfem", "crescita delle crepe", "studi sulla deformazione ciclica e sulla crescita delle crepe a fatica", "lshr", "abaqu", "umat", "criterio di frattura", "analisi degli elementi finiti", "deformazione plastica", "determinare il parametro di un modello costituente cristallo-plastico", "modello costitutivo di plastica cristallina", "subroutine materiali definita dall'utente", "dati di test monotonici, stress relax e ciclici", "prevedere la crescita delle crepe", "deformare ciclicamente"]}
{"file_name": "S0022311515300295", "text": "Le leghe di zirconio sono comunemente utilizzate come rivestimento del combustibile per i reattori nucleari a fissione raffreddati ad acqua, principalmente a causa della loro bassa sezione trasversale dei neutroni, della buona resistenza alla corrosione durante le normali condizioni operative e della sufficiente resistenza meccanica [1]. Nonostante l\u2019elevata resistenza alla corrosione alle normali temperature di esercizio (circa 300 \u00b0C) [2], le leghe di Zr si ossidano molto rapidamente se esposte a temperature di alcune centinaia di gradi superiori. Si tratta di una reazione esotermica, che pu\u00f2 accelerare ulteriormente l'ossidazione e, a temperature superiori a 1000 \u00b0C, portare potenzialmente alla disintegrazione delle barre di combustibile, come evidenziato durante l'incidente nucleare di Fukushima Daiichi. Per questo motivo sono state avviate nuove attivit\u00e0 di ricerca in tutto il mondo per sviluppare carburanti tolleranti agli incidenti (ATF). Inoltre, gli ATF potrebbero anche fornire ulteriori miglioramenti nelle prestazioni di corrosione durante le normali condizioni operative consentendo lo sviluppo di gruppi di combustibile con un consumo molto elevato.", "keyphrases": ["gruppo carburante", "ossidis", "disintegrazione della barra di combustibile", "ossido", "sviluppo del gruppo carburante", "reattore a fissione nucleare raffreddato ad acqua", "carburante resistente agli acidi", "rivestito di carburante", "reazione esotermica", "lega zr", "migliorare le prestazioni della corrosione", "lega di zirconio", "atf", "sviluppare carburante resistente agli acidi", "barra di carburante"]}
{"file_name": "S0022311514009271", "text": "Le propriet\u00e0 strutturali sono ben riprodotte da tutti i modelli (Tabella 2), ma il miglioramento significativo del nostro potenziale risiede nelle costanti elastiche che riguardano il modo in cui il sistema risponde allo stress. Infatti, struttura ed elasticit\u00e0 sono parametri importanti per chiarire la stabilit\u00e0 dei bordi dei grani. Tutti i modelli potenziali prevedono correttamente la stabilit\u00e0 relativa delle energie del difetto. Il modello potenziale di Morelon ha funzionato meglio poich\u00e9 \u00e8 stato specificamente derivato per replicare le energie di formazione dei difetti, ma sottostima ampiamente il modulo di massa. Le energie calcolate con i modelli potenziali di Morl e Arima sono sovrastimate; questo \u00e8 uno svantaggio noto dell'utilizzo di modelli di ioni rigidi poich\u00e9 la polarizzabilit\u00e0 ionica non viene presa in considerazione. Per completezza riportiamo due modelli shell con i migliori risultati dati dal modello potenziale di Catlow. Il Morl, insieme al modello potenziale del guscio di Grimes, riproducono accuratamente l'energia di attivazione della migrazione dell'ossigeno (il percorso di migrazione era l'energia pi\u00f9 bassa e il meccanismo di diffusione pi\u00f9 favorevole osservato nell'UO2 in massa [1]). La principale carenza del potenziale Morl \u00e8 che le energie dei difetti cationici sono elevate, e quindi il numero di difetti cationici sar\u00e0 sottostimato. Tuttavia, questo non dovrebbe rappresentare un problema a meno che questo modello non venga applicato a processi come la crescita del grano in cui contribuisce la mobilit\u00e0 dei cationi.", "keyphrases": ["prevedere la stabilit\u00e0 rel dell'energia del difetto", "chiari confini del grano stabili", "uo2", "morl, insieme al modello grime shell potenti", "riprodurre l'energia attiva dell'ossigeno migrato", "modello ionico rigido", "percorso migratorio", "meccanica diffusa", "Modello Morelon Potenti", "catione", "morl e il modello arima potenti", "morl potente", "grano", "modello catlow potenti", "formato difetto replica energi", "modello a conchiglia", "ossigeno", "crescita del grano"]}
{"file_name": "S0022311511010014", "text": "La scoperta che sia i percorsi di migrazione dei posti vacanti che quelli dei difetti interstiziali sono confinati in regioni prive di Ga suggerisce cambiamenti nei tassi di ricombinazione delle coppie isolate di posti vacanti-interstiziali rispetto al Pu puro. Il grado in cui i tassi vengono influenzati dipende dalla distribuzione dei difetti residui dopo un evento a cascata, oltre alla concentrazione e all'ordinamento degli atomi di Ga. Se i posti vacanti e gli interstitial si separano notevolmente dopo la cascata di collisioni, \u00e8 probabile che i percorsi di ricombinazione si riducano e i tempi di recupero si allunghino. Ci\u00f2 \u00e8 fattibile per le cascate che hanno creato un nucleo ricco di posti vacanti circondato da interstiziali dispersi, come riscontrato per le cascate a bassa energia in Pu e PuGa [11,12]. Questo potrebbe anche essere il caso degli eventi di canalizzazione, dove gli atomi energetici viaggiano in profondit\u00e0 nel reticolo attraverso canali a bassa densit\u00e0 atomica.", "keyphrases": ["ga", "percorso migratorio difettoso", "cascata del collis", "atomo ga", "cascata a bassa energia in pu e puga", "evento del canale", "l'atomo energetico viaggia in profondit\u00e0 nel reticolo attraverso il canale della bassa densit\u00e0 di atomi", "evento a cascata"]}
{"file_name": "S2352179114200032", "text": "Sebbene il modello presentato sia sviluppato e testato pensando agli strati aC:H, non \u00e8 necessariamente limitato a questi. Inoltre, le uniche ipotesi sono le reazioni chimiche tra il gas e il solido che formano sostanze volatili, la perdita di queste sostanze volatili dal materiale e le due condizioni al contorno indicate dell'afflusso di gas su una singola superficie esterna e la possibilit\u00e0 di reazioni in tutta la massa. Porosit\u00e0 e quantit\u00e0 significative di gas sono state osservate non solo per il carbonio [12] ma anche per i co-depositi di berillio [25] e ci si pu\u00f2 aspettare per altri co-depositi formati nei dispositivi al plasma [1]. Pertanto, il TCR e la sua descrizione mediante il modello presentato possono essere applicabili a tutti i depositi. Se uno strato ha costituenti che non formano volatili con il gas reattivo, W e Be con O2, questi costituenti non possono essere rimossi dal TCR, poich\u00e9 non verranno rimossi dal deposito. Ci\u00f2 pu\u00f2 influenzare la rimozione di altri costituenti del deposito e l\u2019evoluzione temporale del processo pu\u00f2 cambiare. La nuova comprensione del TCR potrebbe, per la prima volta, consentire di applicare il metodo in modo controllato ai dispositivi per la fusione nucleare, risolvendo eventualmente il problema della ritenzione del trizio, legato soprattutto ai materiali a base di carbonio.", "keyphrases": ["reazione", "dispositivo al plasma", "deposito costitu", "ga inventori", "problema di ritenzione del trizio", "reazione chimica", "strato ac:h", "trizio", "materiali a base di carbonio", "carbonio", "costitu che non sono volatili con i reattivi ga", "afflusso ga", "unica superficie esterna", "poros", "ritenzione di trizio", "forma solida volatile", "dispositivo per la fusione nucleare", "ga", "w e sii con o2", "reattivo ga", "tcr", "co-deposito di berillio"]}
{"file_name": "S0009261415008362", "text": "Per qualsiasi metodo di dinamica quantistica, esistente o emergente, sono necessari parametri di riferimento affidabili per valutarne l'accuratezza. Un modello hamiltoniano che mostra una dinamica di tunneling attraverso un potenziale a doppio pozzo multidimensionale asimmetrico \u00e8 stato utilizzato come test dai metodi MP/SOFT [18] e CCS [19] menzionati sopra, e anche pi\u00f9 recentemente da un metodo di espansione dell'interazione di configurazione (CI) [ 20] e versione a due strati di CCS (2L-CCS). [21] L'Hamiltoniana consiste in una modalit\u00e0 di tunneling unidimensionale accoppiata a un bagno armonico (M\u22121) dimensionale, quindi \u00e8 un problema di bagno di sistema che presenta alcune somiglianze con il modello di tunneling di Caldeira-Leggett in un sistema dissipativo [22,23]. Tuttavia, questa hamiltoniana non \u00e8 dissipativa e i modi armonici hanno tutti la stessa frequenza. I modelli del bagno di sistema svolgono un ruolo importante in fisica, poich\u00e9 vengono utilizzati per descrivere la superconduttivit\u00e0 in una giunzione Josephson in un dispositivo di interfaccia quantistica superconduttore (SQUID) [24], per il quale il modello di Caldeira-Leggett fornisce una base teorica, e fenomeni magnetici e di conduttanza. nel regime di centrifugazione [25].", "keyphrases": ["metodo cc", "un hamiltoniano modello", "modello di tunnel caldeira-leggett", "segno di riferimento", "ci", "Bagno armonico (m\u22121)-dimensione", "calamaro", "regime di centrifuga", "fisica", "l'Hamiltoniano", "modalit\u00e0 armonia", "multidimensionale asimmetrico doppio pozzo potenti", "2l-cc", "mp/morbido", "Fenomeni magnetici e di conduzione", "problema del bagno di sistema", "modello caldeira-leggett", "Modalit\u00e0 tunnel monodimensionale", "configura il metodo interagisci (ci) espande", "dispositivo di interfaccia quantistica supercondotta", "modello sistema-bagno", "dinamica del tunnel", "configurare interagire", "metodo quantistico dinamico", "hamiltoniano", "versione a due voci delle cc", "superconduttore alla giunzione Josephson"]}
{"file_name": "S2212667814001245", "text": "La riduzione delle frasi \u00e8 uno degli approcci per il riepilogo del text che ha attratto molti ricercatori e studiosi nel campo dell'elaborazione del linguaggio naturale. In questo articolo presentiamo un metodo che genera la riduzione della frase e applica il riepilogo del text vietnamita utilizzando il modello della rete bayesiana. Il modello di rete bayesiano viene utilizzato per trovare la frase breve con la migliore verosimiglianza confrontando la differenza di probabilit\u00e0. I risultati sperimentali con 980 frasi mostrano che il nostro metodo \u00e8 davvero efficace nel generare una riduzione delle frasi comprensibile, leggibile e perfettamente grammaticale.", "keyphrases": ["processo linguistico naturale", "riepilogo del text in vietnamita", "gener frase ridotta", "980 frase", "modello di rete bayesiana", "sentenza ridotta", "frase breve con la migliore probabilit\u00e0", "riepilogo testuale", "compara differisce da probabile"]}
{"file_name": "S0039602899010869", "text": "Il contributo finale alla forza \u00e8 l'interazione di van der Waals. Comprende i seguenti contributi: (i) tra la punta macroscopica di Si di forma conica con la sfera di raggio R all'estremit\u00e0 [27] e il substrato semi-infinito; (ii) le forze di dispersione tra gli atomi del campione trattato atomisticamente; e (iii) l'interazione tra la parte macroscopica della punta e gli atomi del campione. Il primo contributo \u00e8 calcolato analiticamente [27]. Infatti, il contributo macroscopico alla forza di van der Waals \u00e8 lo stesso in ciascuno dei tre sistemi descritti di seguito, poich\u00e9 dipende solo dalla separazione punta-superficie, dal raggio macroscopico della sfera, dall\u2019angolo del cono e dalla costante di Hamaker del sistema [27 ]. Tutte queste quantit\u00e0 sono identiche in ogni sistema che esaminiamo, cos\u00ec che la forza di van der Waals agisce come una forza attrattiva di fondo indipendente dalle propriet\u00e0 microscopiche del sistema [8]. Si stima che la costante di Hamaker necessaria per il calcolo della forza macroscopica di van der Waals sia 0,5 eV [32].", "keyphrases": ["calcolo", "atomo campione", "substrato semiinfinito", "punta del macroscopio", "atomo", "macroscopio van der Waal forc", "parte macroscopica della punta", "van der Waal interagisce", "punta-superficie separ", "disperde la forza", "forza van der Waal"]}
{"file_name": "S221266781400149X", "text": "In questo articolo vengono discusse e analizzate le tecniche di beamforming adattivo per antenne intelligenti basate sui minimi quadrati medi (LMS), sull'inversione della matrice dei campioni (SMI), sui minimi quadrati ricorsivi (RLS) e sul metodo del gradiente coniugato (CGM). Le prestazioni del beamforming vengono studiate variando la spaziatura degli elementi e il numero di elementi della schiera di antenne per ciascun algoritmo. Questi quattro algoritmi vengono confrontati per il loro tasso di convergenza, beamforming e prestazioni di governo nullo (larghezza del fascio, profondit\u00e0 nulla e livello massimo dei lobi laterali).", "keyphrases": ["livello massimo dei lobi laterali", "lm", "forma del fascio", "larghezza del fascio", "metodo del gradiente coniugato", "ricorre il minimo quadrato", "algoritmo", "matrice campionaria inversa", "variare lo spazio degli elementi e il numero di elementi dell'array di antenne", "eseguire la forma del fascio", "discutere e analizzare", "cgm", "smi", "esecuzione di sterzo nulla", "tasso di convergenza", "quadrato meno mediocre", "antenna intelligente", "adattare la tecnica del beamform", "rl", "profondit\u00e0 nulla"]}
{"file_name": "S0032386109001712", "text": "Con il costante aumento delle prestazioni dei computer, le simulazioni in sistemi molto pi\u00f9 grandi sono diventate fattibili. Tuttavia, gli approcci completamente atomistici alla cristallizzazione dei polimeri richiedono una potenza di calcolo estremamente elevata anche nel caso di polimeri semplici, e la modellazione appropriata o la grana grossa del sistema sono indispensabili. Da una serie di lavori sullo sviluppo di modelli a grana grossa per polimeri, Mayer e Muller-Plathe hanno creato un modello di alcol polivinilico (PVA) per studiare la fase iniziale della cristallizzazione. Hanno studiato l'emergere dell'ordine cristallino dalla fusione isotropa mediante tempra rapida [51,52]. Sono riusciti a riprodurre molti processi elementari di nucleazione omogenea che hanno mostrato una buona corrispondenza con esperimenti e altre simulazioni, nella dipendenza dalla temperatura dello spessore della lamella, nella struttura della superficie della piega, ecc. Nel loro lavoro, hanno trascurato la forza a lungo raggio (attrazione di van der Waals) per accelerare il calcolo. Il loro modello ha il contributo energetico dovuto solo alle interazioni intracatena e la forza motrice dominante per la cristallizzazione \u00e8 entropica, il che sembra ignorare la forza motrice dominante per la cristallizzazione dei polimeri in senso convenzionale. Tuttavia, il loro lavoro ricorda la classica transizione solido-liquido nei sistemi di atomi sferici repulsivi [53] e pone un problema intrigante riguardo alla forza motrice intrinseca per la cristallizzazione dei polimeri.", "keyphrases": ["pva", "classico transito solido-liquido", "cristallo", "approccio completamente atomista", "simul", "cristallo polimerico", "grana grossa del sistema", "modello appropriato", "modello a grana grossa", "poligono semplice", "respingere l'atomo sferico", "lamella", "spegnimento rapido", "polim", "interagiscono intracatena", "solido", "cristallino", "fusione isotropa", "alcool polivinilico)", "liquido", "piegare la superficie", "nucleato omogeneo"]}
{"file_name": "S0370269304009268", "text": "Uno dei grandi successi del programma sperimentale portato avanti al LEP \u00e8 stato quello di porre un limite inferiore fermo alla massa di Higgs, mH>114 GeV [1], e allo stesso tempo, insieme alle informazioni provenienti da SLD, di fornire una forte prova indiretta che il bosone di Higgs, la particella ancora mancante del Modello Standard (SM), dovrebbe essere relativamente leggero con un\u2019alta probabilit\u00e0 che la sua massa sia inferiore a 200 GeV. La ricerca del bosone di Higgs \u00e8 uno degli obiettivi principali del Tevatron e del futuro Large Hadron Collider (LHC), che dovrebbero coprire tutte le regioni di massa di Higgs fino a 1 TeV. Nei collisori adronici il principale meccanismo di produzione del bosone \u00e8 la fusione del gluone [2], un processo la cui conoscenza \u00e8 fondamentale per porre limiti alla massa del bosone o, nel caso in cui il bosone venga scoperto, per confrontare la sezione d'urto misurata con il risultato SM . Per quanto riguarda i canali di decadimento dell\u2019Higgs, \u00e8 piuttosto difficile per un collisore di adroni accedere a parte dell\u2019intervallo di massa favorito dai risultati LEP, la cosiddetta regione di massa intermedia dell\u2019Higgs 114\u2272mH\u2272160 GeV, a causa dell\u2019ampio background QCD del modalit\u00e0 dominanti. In questa regione il raro decadimento H\u2192\u03b3\u03b3 \u00e8 l'alternativa pi\u00f9 interessante ai soliti canali di decadimento.", "keyphrases": ["l'accesso a parte della messa ha squillato il favore del risultato della lebbra", "collisione di adroni di grandi dimensioni", "tevatron", "imporre un limite inferiore fermo alla massa di Higg", "parte della messa fu favorevole al risultato della lebbra", "bosone di Higg", "h\u2192\u03b3\u03b3", "ciao", "abbraccia tutta la regione della massa higg fino a 1 tev", "modello standard", "decadimento di Higg", "massa higg", "sfondo qcd", "regione di massa higg intermedia", "sld", "principale meccanico del prodotto Higg", "(lhc)", "mh>114 gev", "confrontare la sezione trasversale misurata con il risultato sm", "particl", "canale di decadimento", "fusione dei gluoni", "114\u2272mh\u2272160 gev", "meccanico del prodotto higg", "decadimento raro", "la ricerca del bosone di Higg", "sm", "collisione di adroni", "porre un limite alla massa di Higg"]}
{"file_name": "S0370269304009086", "text": "Il modello ART \u00e8 un modello di trasporto adronico che include barioni come N, \u0394(1232), N\u2217(1440), N\u2217(1535), \u039b, \u03a3 e mesoni come \u03c0, \u03c1, \u03c9, \u03b7, K, K\u2217. Sia le collisioni elastiche che anelastiche tra la maggior parte di queste particelle sono incluse utilizzando i dati sperimentali delle collisioni adrone-adrone. Il modello ART ha avuto molto successo nello spiegare molte osservazioni sperimentali, incluso l'antiflusso di kaoni sorprendentemente grande [11,12] nelle collisioni di ioni pesanti alle energie AGS. Il modello ART permette anche di capire se la materia fortemente interagente formata in queste collisioni raggiunge o meno l'equilibrio chimico e/o termico. Nel presente studio, estendiamo il modello ART per includere perturbativamente la particella \u039e come negli studi per altre particelle rare utilizzando il modello di trasporto [6,13,14].", "keyphrases": ["collisione di ioni pesanti", "queste particl", "collisione adrone-adrone", "n,\u03b4(1232)", "\u03b7", "modello di trasporto degli adroni", "\u03be partic", "mesone", "collis", "K", "modello artistico", "\u03bb", "n\u2217(1440)", "k\u2217", "ag energi", "adrone", "modello di trasporto", "dati sperimentali dalla collisione adrone-adrone", "spiegare l'esperimento mani osservare", "estendere il modello artistico per includere la perturbazione della particella \u03be", "ione pesante", "\u03c0", "capire se le forme di materia che interagiscono forte in questi colli raggiungono o meno l'equilibrio chimico e/o termico", "\u03c9", "kaone", "n\u2217(1535)", "barione", "\u03c3", "\u03c1", "particella rara", "kaone antiflusso", "elast e inelast collis", "interagiscono fortemente con la materia"]}
{"file_name": "S0031920113001222", "text": "La tomografia sismica \u00e8 un potente strumento per indagare la struttura profonda sotto i vulcani. Con il recente rapido sviluppo delle reti sismiche provinciali cinesi (Zheng, 2009, 2010) e di alcuni sistemi sismici portatili (Hetland, 2004; Duan, 2009; Lei, 2012b) attorno ai vulcani, \u00e8 diventato possibile immaginare i dettagli 3-D struttura di velocit\u00e0 sotto alcuni di questi vulcani, dove le stazioni sismiche sono densamente distanziate. In questa panoramica, sintetizziamo i risultati delle immagini sismiche profonde del mantello superiore sotto i vulcani Changbaishan, Tengchong, Hainan e il vulcano Datong (Figura 1). Valutiamo anche i vantaggi delle tecniche tomografiche sismiche recentemente aggiornate per ricavare informazioni potenziali. Questo lavoro aggiorna una precedente revisione di Zhao e Liu (2010) su questo argomento, con una sintesi pi\u00f9 dettagliata di tutte le informazioni disponibili.", "keyphrases": ["indagando la struttura profonda sotto il vulcano", "immagine sismica profonda", "tecnica del tomografo sismico", "sintetizza il risultato dell'immagine sismica profonda del mantello superiore", "immagina il dettaglio della struttura veloc 3-d", "rete sismica provinciale", "array sismico portatile", "stazione sismica", "tomografia sismica", "Struttura veloce 3-d", "vantaggio del recente aggiornamento della tecnica del tomografo sismico", "changbaishan, tengchong, vulcano hainan e datong"]}
{"file_name": "S0032386109004996", "text": "L'SPM, e l'AFM in particolare, sono stati ampiamente applicati a problemi di cristallizzazione dei polimeri. La tecnica ha diversi punti di forza che la rendono ideale per tali studi. Si tratta di una tecnologia ad alta risoluzione, che risolve abitualmente caratteristiche inferiori a 10 nm [13,14] e quindi consente di osservare la scala di lunghezza fondamentale del cristallo lamellare del polimero, e il suo spessore. L'AFM non richiede colorazione o rivestimento metallico del campione, quindi la preparazione del campione \u00e8 relativamente semplice. Inoltre, non \u00e8 distruttivo in molte circostanze. Ci\u00f2 consente di ottenere immagini mentre si verifica un processo come la crescita o la fusione dei cristalli, fornendo dati risolti nel tempo con risoluzione lamellare o sub-lamellare [15\u201318]. \u00c8 questa caratteristica finale che offre molte delle possibilit\u00e0 pi\u00f9 interessanti dell'AFM per lo studio della cristallizzazione dei polimeri, poich\u00e9 ora \u00e8 possibile osservare la crescita dei cristalli, la fusione dei cristalli e le riorganizzazioni all'interno dei cristalli su scala lamellare, osservando come la struttura si evolve e le variazioni locali. le condizioni influenzano la cinetica. L'AFM ha un'ampia gamma di diverse modalit\u00e0 di misurazione e, con il numero sempre crescente di polimeri semicristallini funzionali disponibili ([19]), anche l'ampiezza degli esperimenti che possono essere eseguiti con una singola macchina \u00e8 una delle attrazioni della tecnica.", "keyphrases": ["cristallo", "crescita dei cristalli", "domanda in cristallo polimerico", "cristallo polimerico", "dati di risoluzione temporale", "fusione del cristallo", "riorganizzarsi all'interno del cristallo su scala lamellare", "tecnologia ad alta risoluzione", "sp", "polimero semicristallino", "macchia", "sciolto", "funzione risoluzione inferiore a 10 nm", "strato metallico", "polim", "cristallo lamellare polimerico", "afm", "studi polimero cristallo", "preparazione del campione"]}
{"file_name": "S0370269304008706", "text": "L'accordo tra i nuovi dati ed i calcoli con la funzione d'onda relativistica del deuterone non deve essere considerato casuale; a questo proposito vanno citati altri risultati. In precedenza \u00e8 stato dimostrato [15] che i calcoli nell'ambito della dinamica del fronte luminoso con la funzione d'onda del deuterone di Karmanov sono in buon accordo con i dati sperimentali sul parametro T20 della rottura del deuterone su bersagli H e C con l'emissione di protoni a 0 \u00b0 nella regione k da 0,4 a 0,8 GeV/c. Inoltre, all'interno dello stesso approccio, una descrizione qualitativa del comportamento della quantit\u00e0 di moto del parametro Ayy della reazione 9Be(d,p)X con una quantit\u00e0 di moto del deuterone di 4,5 GeV/c e un angolo del protone rilevato di 80 mr e una descrizione piuttosto buona di sono stati ottenuti i dati Ayy per la reazione 12C(d,p)X a 9 GeV/c e 85 mr [16].", "keyphrases": ["Funzione d'onda del deutone di Karmanov", "momento del deuterone", "dinamica del fronte luminoso", "ahi dati", "accordo tra i nuovi dati e il calcolo con la funzione d'onda relativista del deuterone", "descrizione qualitativa del comportamento della quantit\u00e0 di moto del parametro ayi della reazione 9be(d,p)x", "Funzione d'onda relativista del deuterone", "Parametro t20 della rottura del deuterone sui target h e c", "emissione di protoni a 0\u00b0 nella regione k da 0,4 a 0,8 gev/c", "Reazione 12c(d,p)x", "calcolo nell'ambito della dinamica del fronte luminoso con funzione d'onda del deuterone di Karmanov"]}
{"file_name": "S003238610900086X", "text": "Ci occupiamo dell'intensit\u00e0 diffusa da una miscela casuale di catene di PE deuterato/idrogenato. L'algoritmo da noi utilizzato per valutare i grafici di Kratky per insiemi di steli polimerici paralleli \u00e8 molto semplificato. Abbiamo verificato che fosse adeguato nell'intervallo di coordinate reciproche in esame [0<q(=4\u03c0sin\u03b8/\u03bb)\u22640,25\u00c5\u22121] confrontando i risultati con calcoli pi\u00f9 precisi. I centri di scattering sono identificati con pseudoatomi che si ripetono dopo una distanza costante di 1,27\u00c5 lungo linee rette coincidenti con gli assi dello stelo, su ciascuno stelo essendo posti 100 centri di scattering; si trascura la diffusione da parte degli atomi appartenenti alle pieghe della catena. Gli assi paralleli degli steli sono disposti secondo un'impostazione esagonale - un'approssimazione approssimativa della struttura monoclina e pseudo-esagonale del PE - e i centri di diffusione hanno le stesse coordinate assiali in tutti gli steli. Definendo un intero i che va da 1 al numero totale ns\u00b7100 dei centri di scattering, abbiamo (q<1) [9](1A)q2\u00b7I(q)=C\u00b7(bH\u2212bD)2\u2211i=1ns \u00b7100\u2211j=1ns\u00b71004\u03c0qsin(q\u00b7dij)dij;dij2=\u0394ij2+(zj\u2212zi)2;q=2\u03c0sin\u03b8\u03bbdove bH, bD sono rispettivamente le lunghezze di diffusione di idrogeno e deuterio, dij \u00e8 la distanza tra gli atomi di C, 2\u03b8 \u00e8 l'angolo di diffrazione e \u03bb la lunghezza d'onda. La coordinata i-esima dell'atomo C lungo l'asse dello stelo \u00e8 zi e \u0394ij \u00e8 la distanza tra gli assi dello stelo a cui appartengono gli atomi i e j. Per tutti i gambi abbiamo lo stesso insieme di coordinate zi. La somma nell'Eq. (1A) \u00e8 esteso a tutti i fusti del dominio cristallino, vedere Figg. 2 e 10 per esempi.", "keyphrases": ["calcolo", "stelo", "piega a catena", "deuter", "pe", "atomo", "ascia a stelo parallelo", "atomo c", "catena pe", "spargere", "cristallino", "idrogeno", "trama di Kratki", "deuterio", "stelo in polimero parallelo", "centro di dispersione", "ascia a stelo", "pseudo-atomo"]}
{"file_name": "S0301932214001499", "text": "In generale, i flussi del film liquido di rilevanza pratica sono turbolenti e, quindi, sono associati alla presenza di onde interfacciali a banda larga sulla superficie del film. Una comprensione approfondita dei profili caratteristici, delle scale e della dinamica di queste onde interfacciali \u00e8 di essenziale importanza per fare previsioni accurate e affidabili delle velocit\u00e0 di trasferimento di calore e massa (Mathie e Markides, 2013a; Mathie, 2013). Precedenti sforzi nel flusso anulare verso il basso si sono concentrati sulla misurazione spazio/temporale dello spessore del film liquido, seguita da analisi statistiche approfondite di questo spessore del film (Webb e Hewitt, 1975; Belt, 2010; Alekseenko, 2012; Zhao, 2013). Questi sforzi hanno contribuito ad una migliore comprensione della topologia interfacciale osservata nei flussi anulari discendenti e anche alla successiva proposta di una serie di correlazioni per la quantificazione dello spessore medio del film, delle ampiezze delle onde e dei tassi di trascinamento del liquido nella fase gassosa (Ambrosini , 1991; D'altra parte, \u00e8 stato pubblicato meno sulla distribuzione della velocit\u00e0 e sulla struttura del flusso all'interno dei film liquidi, sotto la superficie del film. Ci\u00f2 pu\u00f2 essere correlato alla relativa difficolt\u00e0 di queste misurazioni causata da: (i) lo spazio di misura estremamente ristretto, a causa del piccolo spessore dei film liquidi (nell'ordine e spesso inferiori al mm), (ii) lo spazio altamente disturbato e la natura intermittente dell'interfaccia gas-liquido, (iii) il trascinamento del gas all'interno della pellicola liquida e del liquido nel nucleo del gas, e (iv) le velocit\u00e0 relativamente elevate di entrambe le fasi gassosa e liquida.", "keyphrases": ["analisi statalistiche di questo film spesso", "film liquido spesso", "comprendere i profili caratteristici, la scala e la dinamica di queste interfacce d'onda", "distribuzione veloce", "topologia delle interfacce", "onda di interfaccia a banda larga", "spessore medio del film", "superficie della pellicola", "trascinamento di ga", "analisi statalistiche", "fase ga", "nucleo centrale", "alta velocit\u00e0", "quantit\u00e0 dello spessore medio del film, dell'ampiezza delle onde e della velocit\u00e0 di trascinamento del liquido", "ampiezza delle onde", "ga", "film", "interfaccia gas-liquido", "onda", "spessore del film liquido", "flusso anulare discendente", "pellicola liquida", "misura di spazio/tempo", "struttura del flusso all'interno del film liquido", "liquido", "onda di interfaccia", "flusso del film liquido"]}
{"file_name": "S0377025714001931", "text": "L'adesivit\u00e0 \u00e8 una propriet\u00e0 importante di un PSA in quanto quantifica la sua capacit\u00e0 di formare istantaneamente un legame quando viene messo a contatto con una superficie. L'adesione finale e la forza coesiva del legame sono influenzate da numerosi fattori tra cui le energie superficiali dell'adesivo e del substrato, il tempo di permanenza, la pressione di contatto, le propriet\u00e0 meccaniche dell'adesivo, nonch\u00e9 le condizioni ambientali come temperatura e umidit\u00e0 [8]. Pertanto, l'adesivit\u00e0 \u00e8 importante in molte applicazioni in cui \u00e8 richiesto un legame istantaneo, tuttavia \u00e8 altrettanto importante quando \u00e8 desiderabile una separazione \"pulita\" delle superfici inizialmente incollate. Sono stati ideati molti metodi diversi per misurare l'adesivit\u00e0, i quattro principali sono i test con palla rotolante, virata ad anello, stick rapido e test di virata con sonda [9]. Ciascuno presenta vantaggi e svantaggi e il metodo di prova specifico deve essere selezionato in base alla particolare applicazione.", "keyphrases": ["separazione \"pulita\".", "test", "p.s", "substrato", "virata", "virata ad anello", "aderisce", "superficie di adesione", "rotolare la palla", "bastone veloce", "puntina della sonda"]}
{"file_name": "S0022311513001165", "text": "Le nostre simulazioni confermano le osservazioni sperimentali secondo cui l\u2019erosione netta del W rappresenta solo una piccola frazione (nella nostra simulazione circa l\u20191%) dell\u2019erosione lorda del W. I flussi W stimati a monte, FWupstrem, sono in buon accordo con i valori osservati sperimentalmente \u2a7d1019m-2s-1 [16]. Inoltre questo valore non \u00e8 molto sensibile alla temperatura del plasma del divertore. A basse temperature l'energia degli ioni D e C che colpiscono le piastre del divertore \u00e8 troppo bassa per emettere una quantit\u00e0 sufficiente di W. Con l'aumentare dell'energia lo sputtering di W aumenta, ma aumenta anche il potenziale calo nel plasma del divertore. Di conseguenza, la maggior parte degli atomi di W vengono ionizzati in prossimit\u00e0 del divertore e ritornano alle piastre. Ci sono due effetti che portano alla pronta rideposizione osservata degli ioni W: il primo \u00e8 la ionizzazione \u201cvicino al divertore\u201d di W dovuta al basso potenziale di ionizzazione \u22127,86 eV (per confronto, i potenziali di ionizzazione per D e C sono 13,6 e 10,6 eV ), in secondo luogo, gli ioni W+n hanno un raggio di Larmor ampio \u223c2/nmm, quindi vengono ridepositati entro la distanza di un raggio di Larmor. \u00c8 importante notare che una frazione significativa di ioni W che sfuggono a questa pronta rideposizione vengono restituiti a causa dell'attrito con gli ioni principali.", "keyphrases": ["aumenta l'energia", "w sputacchiare", "simul", "w flusso", "w eros netto", "ioni d e c", "deviatore", "piatto", "w atomo", "ioniz", "grande raggio di larmor", "ritorno", "colpire la piastra del deviatore", "valore di osservazione dell'esperimento", "piastra deviatrice", "w ione", "D", "stima a monte w flusso", "attrito con lo ione principale", "quasi-divertore\u201d ioniz", "w", "ione w+n", "fwupstrem", "C", "osservare il rapido rideposito", "w eros grossolano", "plasma divergente"]}
{"file_name": "S025405841530136X", "text": "Da questo studio in cui una lega commerciale Al-12Si \u00e8 stata inoculata con diversi livelli di aggiunta di Nb+B per valutare la potenza di affinazione del grano dell'inoculazione di Nb+B si pu\u00f2 concludere che i composti intermetallici a base di Nb formati in situ sono potenti substrati di nucleazione eterogenei con elevata potenza per l'affinamento delle leghe di fusione Al-Si. La dimensione del grano dendritico primario \u03b1-Al varia con il livello di aggiunta di Nb e B. Inoltre, un significativo affinamento del grano su un ampio intervallo di velocit\u00e0 di raffreddamento si ottiene tramite una nucleazione eterogenea migliorata che rende la dimensione del grano del materiale meno sensibile alla velocit\u00e0 di raffreddamento. Gli inoculanti Nb+B sono caratterizzati da un certo sbiadimento che \u00e8 ancora accettabile dopo 4 ore di tempo di contatto. Inoltre, le leghe raffinate mediante inoculanti Nb+B possono essere riciclate ottenendo una struttura a grana fine con piccola aggiunta o nessuna ulteriore aggiunta di inoculanti dopo la prima aggiunta iniziale. In conclusione, l'inoculazione di Nb+B \u00e8 un candidato promettente per il perfezionamento della lega di Al fusa che potrebbe portare ad un loro pi\u00f9 ampio impiego nell'industria automobilistica con i conseguenti vantaggi intrinseci di componenti strutturali pi\u00f9 leggeri da un punto di vista ambientale.", "keyphrases": ["lega al-12si", "lega", "potenza della raffinazione del grano dell'inoculo nb+b", "grano", "raffinazione della lega fusa al-si", "n.b", "lega di alluminio fuso", "nb+b inocul", "raffinazione di leghe di alluminio pressofuso", "composto intermetallico a base nb", "Grano \u03b1-al dendritico", "dissolvenza", "potenziare il nucleato eterogeneo", "B", "substrato nucleato eterogeneo", "nb+b", "lega fusa al-si", "ampia gamma di tassi di interesse", "raffinazione del grano", "inoc", "componente strutturale pi\u00f9 leggero", "struttura a grana fine", "inoculo con livelli diversi di nb+b"]}
{"file_name": "S002002551630384X", "text": "Un primo tentativo di combinare insiemi e reti in un'unica visualizzazione si basava prima sul disegno di un diagramma di Eulero e poi sull'inserimento di un grafico al suo interno [30], tuttavia gli insiemi erano spesso visualizzati con curve contorte e difficili da seguire. Inoltre, \u00e8 stato possibile mostrare solo tipi limitati di dati impostati poich\u00e9 il sistema era limitato a diagrammi di Eulero ben formati. I grafici composti possono essere utilizzati per rappresentare tipi ristretti di dati di rete raggruppati [8]. I cluster di grafici sono visualizzati con scafi trasparenti da Santamaria e Theron [39]. Tuttavia, la tecnica rimuove i bordi dal grafico e non \u00e8 sufficientemente sofisticata per insiemi sovrapposti arbitrari. Itoh et al. [24] hanno proposto di sovrapporre glifi a forma di torta sui nodi di un grafico per codificare pi\u00f9 categorie. Ogni insieme \u00e8 quindi rappresentato utilizzando regioni disconnesse che sono collegate avendo lo stesso colore. Ci\u00f2 causa difficolt\u00e0 con i compiti che implicano la ricerca di relazioni tra insiemi come T1, T3 e T4 nella Sezione 5.3. Una classe correlata di tecniche visualizza il raggruppamento di informazioni su grafici utilizzando scafi convessi, come Vizster [22]. Tuttavia, non supportano la visualizzazione delle sovrapposizioni di set.", "keyphrases": ["visuale unica", "glifo", "scafo convesso", "scafo trasparente", "grappolo grafico", "combinare set e rete in un unico oggetto visivo", "trova la relazione tra il set", "t1, t3 e t4", "dati di rete", "il gruppo visivo informa sul grafico", "grafico composto", "diagramma di Eulero", "vizster"]}
{"file_name": "S0927025614007137", "text": "Gli adesivi strutturali sono sempre pi\u00f9 utilizzati per incollare componenti all'interno di strutture ingegneristiche portanti critiche come quelle aerospaziali e automobilistiche. Tipicamente questi adesivi sono a base di polimeri epossidici. Le resine epossidiche sono intrinsecamente fragili a causa della loro microstruttura omogenea e della natura altamente reticolata. Pertanto, molte ricerche si sono concentrate sul miglioramento della resistenza alla frattura dei polimeri epossidici incorporando una seconda fase minoritaria su scala nanometrica. Questi modificatori rientrano in una delle due categorie principali: additivi inorganici, silice [1,2], vetro [3], allumina [4], nano-argille [5] e nanotubi di carbonio [6,7] o particelle organiche, solitamente di gomma. . Gli additivi gommosi possono essere particelle di gomma nucleo-guscio [8\u201310] o possono formarsi durante la polimerizzazione tramite meccanismi di separazione di fase indotti dalla reazione [11,12]. \u00c8 noto che i meccanismi primari di dissipazione dell\u2019energia per le resine epossidiche rinforzate con gomma sono sia la crescita dei vuoti plastici che lo sviluppo di bande di taglio [13]. \u00c8 stato anche dimostrato che una combinazione degli additivi di cui sopra per creare un materiale ibrido pu\u00f2 fornire effetti di indurimento sinergici, nanotubi di carbonio e nanoparticelle di silice [14] o gomma con nanoparticelle di silice [15\u201317].", "keyphrases": ["si sviluppa una fascia di taglio", "allumina", "incorporare una seconda fase minore su scala nanometrica", "nano-argilla", "silice", "materia ibrida", "particelle di gomma", "nanoparticelle di silice", "crescita dei vuoti plastici", "aggiunta di gomma", "additivo inorganico", "nanotubo di carbonio", "resina epossidica rinforzante per gomma", "automot", "microstruttura", "bicchiere", "meccanismo di dissipazione dell'energia", "il carico critico sopporta la struttura del motore", "aerospaziale", "nanotubo di carbonio e nanoparticelle di silice", "aderisce", "effetto rinforzante sinergico", "cura", "frattura dura", "epossidico", "componente obbligazionario", "particella di gomma nucleo-rivestimento", "meccanismo di separazione della fase indotta dalla reazione", "gomma con nanoparticelle di silice", "polimero epossidico", "addizione", "la struttura aderisce", "migliorare la resistenza alla frattura del polimero epossidico", "organo"]}
{"file_name": "S0306437913000768", "text": "Modellare i processi di collaborazione \u00e8 un compito impegnativo. Gli approcci di modellizzazione esistenti non sono in grado di esprimere la natura imprevedibile e non di routine della collaborazione umana, che \u00e8 influenzata dal context sociale dei collaboratori coinvolti. Proponiamo un approccio di modellazione che considera i processi di collaborazione come l'evoluzione di una rete di documenti collaborativi insieme a una rete sociale di collaboratori. Il nostro approccio di modellazione, accompagnato da notazione grafica e formalizzazione, consente di catturare l'influenza di strutture sociali complesse formate da collaboratori e quindi facilita attivit\u00e0 come la scoperta di team socialmente coerenti, hub sociali o esperti imparziali. Dimostriamo l'applicabilit\u00e0 e l'espressivit\u00e0 del nostro approccio e della nostra notazione e ne discutiamo i punti di forza e di debolezza.", "keyphrases": ["influenza di una struttura sociale complessa", "processo di collaborazione modello", "evoluzione di una rete di collaborazione documentale insieme ad una rete sociale di collaborazione", "processo di collaborazione", "approccio modello", "collaborazione umana", "scoperta della coesione sociale del team", "notazione grafica e formale"]}
{"file_name": "S0021999113005603", "text": "Dopo che tutti i microelementi hanno raggiunto uno stato stazionario rilassato, le misurazioni vengono ottenute utilizzando una tecnica di media cumulativa per ridurre il rumore. Ogni microelemento \u00e8 diviso in contenitori orientati spazialmente nella direzione y per risolvere i profili di velocit\u00e0 e sforzo di taglio. La velocit\u00e0 in ciascun contenitore viene misurata utilizzando il metodo della media cumulativa (CAM) [24], mentre il campo tensore dello stress viene misurato utilizzando la relazione Irving-Kirkwood [25]. Viene eseguito un adattamento polinomiale dei minimi quadrati ai dati, che aiuta a ridurre ulteriormente il rumore. L'adattamento produce una funzione continua che evita problemi di stabilit\u00e0 derivanti dalla fornitura di dati altamente fluttuanti al risolutore macro. Un adattamento dei minimi quadrati viene applicato a un polinomio di ordine N per il profilo di velocit\u00e0 nella regione centrale e a un polinomio di ordine M per il profilo di velocit\u00e0 nella regione vincolata:(16)\u3008ui,core\u3009=\u2211k=1Nbk,iyi \u2032(N\u2212k),per 0\u2a7dyi\u2032\u2a7dhcore, e(17)\u3008ui,cs\u3009=\u2211k=1Mck,iyi\u2033(M\u2212k),per 0\u2a7dyi\u2033\u2a7dhcs, dove bk,i e ck,i sono i coefficienti dei polinomi utilizzati rispettivamente nella microregione centrale e nella regione vincolata. Una stima della nuova velocit\u00e0 di scorrimento uB per l'input della macro soluzione (6) viene presa direttamente dalla soluzione del microelemento della parete compressa (16), a yi\u2032=0.", "keyphrases": ["vestibilit\u00e0 minima quadrata", "risolvere il profilo velocit\u00e0 e sforzo di taglio", "problema stabile", "risolutore di macro", "Polinomi di ordine ennesimo", "nuova velocit\u00e0 di scorrimento", "tecnica cumulata media", "adattamento del polinomio del minimo quadrato", "fornisce dati altamente fluttuanti al risolutore macro", "campo tensore dello sforzo", "Camera", "diviso in contenitori spazialmente-ori", "profilo di sforzo di taglio", "veloc", "metodo della media cumulata", "comprimere parete micro-el solut", "relazione irving-kirkwood", "ridurre il rumore", "soluzione macro", "polinomio di ordine m", "polinomi", "funzione continua"]}
{"file_name": "S221266781400121X", "text": "Nel documento presentiamo una versione estesa dell'algoritmo di disambiguazione del senso di parola senza supervisione basato su grafici. L'algoritmo si basa sullo schema di attivazione dello spread applicato ai grafici costruiti dinamicamente sulla base delle parole del text e di un ampio wordnet. L'algoritmo, originariamente proposto per l'inglese e Princeton WordNet, \u00e8 stato adattato al polacco e plWordNet. \u00c8 stata proposta un'estensione basata sulla conoscenza acquisita dalla Measure of Semantic Relatedness derivata dal corpus. L'algoritmo esteso \u00e8 stato valutato rispetto al corpus disambiguato manualmente. Abbiamo osservato un miglioramento nel caso della disambiguazione eseguita per contesti di text pi\u00f9 brevi. Inoltre l'applicazione dell'algoritmo ha espresso un miglioramento nell'attivit\u00e0 di clustering dei documenti.", "keyphrases": ["disambigu", "si estende", "grande wordnet", "schema attivo diffuso", "manuale di disambigu corpo", "parola di text", "algoritmo", "costruito sulla base della parola di text e di una parola grande", "attivit\u00e0 del cluster di documenti", "misura del corpo derivato del semantico correlato", "estendere l'algoritmo", "polacco e plwordnet", "Algoritmo di disambiguit\u00e0 del senso della parola", "versione estesa dell'algoritmo graph-bas unsupervis word sens disambigu", "Wordnet inglese e Princeton"]}
{"file_name": "S0370157314001318", "text": "Nonostante l\u2019ubiquit\u00e0 dei sistemi dinamici dipendenti dal tempo in natura, \u00e8 stato svolto relativamente poco lavoro sull\u2019analisi delle serie temporali di tali sistemi. Matematicamente sono detti sistemi non autonomi, chiamati cos\u00ec perch\u00e9, a differenza dei sistemi autonomi, oltre ai punti dello spazio su cui vengono osservati sono influenzati anche dai punti del tempo. Recentemente c'\u00e8 stato molto lavoro sull'approccio diretto \"dal basso verso l'alto\" a questi sistemi, che include l'introduzione di una sottoclasse nota come sistemi cronotassici che sono in grado di modellare le frequenze stabili ma variabili nel tempo delle oscillazioni nei sistemi viventi [8, 9]. Al contrario, l\u2019analisi delle serie temporali di questi sistemi, denominata approccio inverso o \u201ctop-down\u201d, non \u00e8 stata studiata in dettaglio prima. Ci\u00f2 \u00e8 in parte dovuto al fatto che i sistemi non autonomi possono ancora essere analizzati allo stesso modo di altri tipi di sistemi sia in regime deterministico [10] che stocastico [11]. Tuttavia, oggi si sostiene che questo tipo di analisi sia insufficiente e che sia necessario un quadro analitico completamente nuovo per fornire un quadro pi\u00f9 utile di tali sistemi. Nel caso dei sistemi cronotassici sono gi\u00e0 stati sviluppati alcuni metodi per l'approccio inverso che si sono rivelati utili nell'analisi della variabilit\u00e0 della frequenza cardiaca [12]. Non \u00e8 stata per\u00f2 ancora affrontata una procedura generale e dedicata per l'analisi dei sistemi non autonomi.", "keyphrases": ["frequenza cardiaca variabile", "stocastico", "invers", "quadro analitico", "sistema non autonomo", "sistema dinamico dipendente dal tempo", "sistema vivo", "sistema autonomo", "analisi della serie temporale", "approccio \u201cdal basso verso l\u2019alto\u201d.", "'dall'alto al basso'", "determinista", "sistema della cronotassa", "analisi della serie temporale", "approccio inverso", "modellare la frequenza stabile ma variabile nel tempo"]}
{"file_name": "S0370269304009025", "text": "Una questione centrale dal punto di vista della fisica nucleare riguarda i cambiamenti nella distribuzione dei quark e degli antiquark di un protone legato. Poich\u00e9 \u00e8 necessario sviluppare un modello affidabile sia del protone libero che del legame dei nucleoni a partire dal livello dei quark [8], questo problema \u00e8 piuttosto complicato. Intendiamo riferire sulla nostra indagine su questo problema in lavori futuri. Per il momento, abbiamo scelto di illustrare le idee formali qui sviluppate applicandole a un modello giocattolo, vale a dire le distribuzioni di quark di materia quark simmetrica con isospin in cui ogni quark sente un potenziale scalare, \u2212Vsq, e un potenziale vettoriale, Vvq. Questa \u00e8 la premessa del modello Quark-Meson Coupling (QMC) [9] che \u00e8 stato utilizzato con successo per calcolare le propriet\u00e0 della materia nucleare e dei nuclei finiti [10,11]. Pi\u00f9 recentemente \u00e8 stato utilizzato anche per ricavare una forza nucleare efficace che \u00e8 molto simile alla forza Skyrme III ampiamente utilizzata [12]. (Tranne che nella QMC i quark sono confinati nella borsa del MIT, oltre a percepire i potenziali scalari e vettoriali del campo medio generati dai nucleoni circostanti.) Nell'approssimazione del campo medio, l'equazione di Dirac per il quark nella materia a quark infinita \u00e8 scritto come: (30)i\u03b3\u00b7\u2202\u2212m\u2212Vqs\u2212\u03b30Vqv\u03c8QMq(x)=0.", "keyphrases": ["distribuzione dei quark della materia dei quark con simmetria di isospin", "illustrare l'idea formale sviluppata qui applicandole ad un modello giocattolo", "(30)i\u03b3\u00b7\u2202\u2212m\u2212vqs\u2212\u03b30vqv\u03c8qmq(x)=0", "calcolo delle propriet\u00e0 della materia nucleare e dei nuclei finiti", "ogni quark percepisce un potenziale scalare, \u2212vsq, e un potenziale vettoriale, vvq", "qmc", "dirac equat per il quark nella materia dei quark infiniti", "effetto forza nucleare", "cambiamento nella distribuzione di quark e antiquark di un protone legato", "coppia quark-mesone", "sviluppare un modello affidabile sia del protone libero che del legame del nucleone partendo dal livello dei quark", "campo medio approssimativo"]}
{"file_name": "S2212671612000121", "text": "In this paper, three different approaches for implementing a quantum search algorithm by adiabatic evolution are shown. As expected, either one of them can provide a quadratic speed up as opposed to the classical search algorithm. This implies that adiabatic evolution based quantum computation gives more feasibilities than the quantum circuit model, although the equivalence between them has already been proven in the corresponding literature.", "keyphrases": ["three differ approach", "implement a quantum search algorithm by adiabat evolut", "quantum circuit model", "quantum search algorithm", "feasibl", "quantum comput", "quadrat speed up", "adiabat evolut", "classic search algorithm"]}
{"file_name": "S0377221716303873", "text": "The iron ore may be extracted from blocks of 25\u00d725\u00d712meter3 located at three consecutive mining benches of 12meter height. For this case study, ten equally probable scenarios of iron content, phosphorous, silica, aluminum and LOI are used to quantify the joint uncertainty in the characteristics of the iron ore deposit considered and are the input to the SSTPS formulation proposed in the previous section. The simulated scenarios available were provided and generated using the stochastic simulated technique detailed in Boucher and Dimitrakopoulos (2012). The area considered is bounded by the limits of the given volume of production in the long-term first year production schedule provided. Figure 4 shows 3 scenarios of iron ore content as well as the corresponding conventional and single estimated (average) representation of iron content (Fe2O3%) for the upper bench. In total, 734 blocks from 3525 to 21,150 tonnes, with Fe2O3 from 54.59% to 60.63%, P from 0.02% to 0.04%, SiO2 from 3.10% to 8.58%, Al2O3 from 0.53% to 1.88% and LOI from 8.75% to 11.75% are available.", "keyphrases": ["sio2", "silica", "fe2o3", "loi", "iron ore deposit", "scenario of iron ore content", "iron ore", "stochast simul techniqu", "p", "simul scenario", "aluminum", "phosphor", "iron", "iron content", "sstp formul", "734 block", "probabl scenario", "quantifi the joint uncertainti in the characterist of the iron ore deposit", "al2o3"]}
{"file_name": "S0963869515000572", "text": "Shear horizontal (SH) ultrasound waves are guided waves (they have propagation properties affected by the geometry of the propagation medium), with symmetric and anti-symmetric modes; phase and group speeds are dependent on frequency, sample thickness, and the bulk shear wave speed [11,12]. The properties of the different modes can be very useful, such as in thickness measurement [13], but in this case they are a complication. SH0 has a thickness independent speed, equal to the shear wave speed, and is non-dispersive (the phase and group speed are equal to the shear wave speed for all frequencies). The oscillation direction of SH ultrasound is in the plane of the surface where the wave was generated, and perpendicular to the propagation direction, as shown in Figure 1, with respect to a reference interface, which is typically a sample surface. Under certain conditions, such as over short propagation distances, SH waves can be treated as bulk waves.", "keyphrases": ["guid wave", "phase and group speed", "wave", "sh ultrasound", "oscil", "bulk shear wave speed", "shear wave speed", "bulk wave", "sh0", "propag", "shear horizont (sh) ultrasound wave", "sh wave"]}
{"file_name": "S0168365913001521", "text": "The mesoporous silica particles were prepared by the surfactant self-assembly method described previously [18,24]. Briefly, a homogeneous solution of the soluble silica precursor, tetraethylorthosilicate (TEOS; Sigma-Aldrich Corp., St. Louis, MO), and hydrochloric acid was mixed in ethanol and water. A surfactant, cetyltrimethylammonium bromide (CTAB; Sigma-Aldrich Corp., St. Louis, MO), with an initial concentration much less than the critical micelle concentration was added to lower the surface tension of the liquid mixture and act as the mesoporous structure-directing template. Aerosol solutions of soluble silica plus surfactant were then generated with nitrogen as a carrier atomizing gas using a commercially available atomizer (Model 9392A, TSI, Inc., St. Paul, MN). The aerosol droplets were solidified in a tube furnace at 400\u00b0C until dry. Once dried, a durapore membrane filter, kept at 80\u00b0C, was used to collect the particles. As a final step, the surfactant was removed at 400\u00b0C for 5h via calcination. The surface of the mesoporous silica core in these studies was chemically modified with 10wt.% or 15wt.% by aminopropyltriethoxysilane (APTES; Sigma-Aldrich Corp., St. Louis, MO) conducted identically as previously described [17] to create a positive surface charge to increase loading efficiency of negatively charged cargo. Further, Liu and colleagues report the colloidal stability of these protocells with lipid bilayers, excess amount of liposomes (50\u03bcg liposomes per 0.5mg silica were used [18]).", "keyphrases": ["atom ga", "solubl silica precursor", "aerosol solut", "tube furnac", "apt", "tetraethylorthosil", "aminopropyltriethoxysilan", "mesopor silica", "mesopor silica core", "solubl silica", "durapor membran filter", "ctab", "cetyltrimethylammonium bromid", "nitrogen", "water.", "calcin", "hydrochlor acid", "homogen solut", "surfact", "mesopor structure-direct templat", "ethanol", "liposom", "atom", "surfact self-assembl", "aerosol droplet", "protocel", "teo"]}
{"file_name": "S0378381215300297", "text": "The Statistical Associating Fluid Theory (SAFT) is a well-developed perturbation theory used to describe quantitatively the volumetric properties of fluids. The reader is referred to several reviews on the topic which describe the various stages of its development and the multiple versions available [50\u201353]. The fundamental difference between the versions is in the underlying intermolecular potential employed to describe the unbounded constituent particles. Hard spheres, square well fluids, LJ fluids, argon, alkanes have all been employed as reference fluids in the different incarnations of SAFT. For the purpose of this work we will center on a particular version of the SAFT EoS, i.e the SAFT-VR Mie recently proposed by Laffitte  [54] and expanded into a group contribution approach, SAFT-\u03b3, by Papaioannou  [55]. This particular version of SAFT provides a closed form EoS that describes the macroscopical properties of the Mie potential [56], also known as the (m,n) potential; a generalized form of the LJ potential (albeit predating it by decades). The Mie potential has the form(1)\u03d5(r)=C\u03b5\u03c3r\u03bbr\u2212\u03c3r\u03bbawhere C is an analytical function of the repulsive and attractive exponents, \u03bba and \u03bbr, respectively, \u03c3 is a parameter that defines the length scale and is loosely related to the average diameter of a Mie bead; \u025b defines the energy scale and corresponds to the minimum potential energy between two isolated beads; expressed here as a ratio to the Boltzmann constant, kB. The Mie function, as written above, deceivingly suggests that four parameters are needed to characterize the behaviour of an isotropic molecule, however the exponents \u03bba and \u03bbr are intimately related, and for fluid phase equilibria, one needs not consider them as independent parameters [57]. Accordingly, we choose herein to fix the attractive exponent to \u03bba=6 which would be expected to be representative of the dispersion scaling of most simple fluids and refer from here on to the repulsive parameter as \u03bb=\u03bbr. The potential simplifies to(2)\u03d5(r)=\u03bb\u03bb\u22126\u03bb66/(\u03bb\u22126)\u03b5\u03c3r\u03bb\u2212\u03c3r6", "keyphrases": ["argon", "hard sphere", "squar well fluid", "saft-\u03b3", "isotrop molecul", "lj potenti", "saft eo", "lj fluid", "perturb theori", "intermolecular potenti", "statist associ fluid theori", "fluid", "group contribut approach", "bead", "close form eo", "unbound constitu particl", "mie potenti", "saft-vr mie", "saft", "(m,n) potenti", "refer fluid", "simpl fluid", "alkan"]}
{"file_name": "S2212671612001497", "text": "Our country is rich of line galloping, there are many important galloping data failed to collect systematically and completely because there is no unified management platform. After the galloping occurrence in 2009\u20132010's winter the department of productive of the State Grid Corporation organized a lot of human to carry out the research of galloping information, this work is time\u2013consuming and inefficient. The State Grid Corporation has used the production management system (PMS) which is a powerful and easy to use. With the help of the system we can create a galloping database which can save resources and storage the galloping data. To build and put it into application of database can provide technical support for line galloping prevention and galloping research work.", "keyphrases": ["collect systemat and complet", "line gallop prevent", "gallop occurr", "pm", "applic of databas", "technic support", "unifi manag platform", "product manag system", "carri out the research of gallop information,", "gallop data", "gallop", "save resourc and storag the gallop data", "creat a gallop databas", "line gallop", "gallop research work"]}
{"file_name": "S0167931713005042", "text": "We used 2\u03bcm of ultra-nanocrystalline diamond (UNCD) grown by chemical vapour deposition (CVD) on a \u223c520\u03bcm silicon carrier wafer from Advanced Diamond Technologies Ltd. Detailed information about the material and the stamp fabrication can be found in our earlier paper [16]. The UNCD wafer was scribed into 1\u00d71cm2 samples and subjected to RCA cleaning (SC-1), followed by ultrasonic solvent cleaning. Nanofeature stamps were then created from the samples using conventional electron beam lithography (EBL) with negative tone electron sensitive resist, hydrogen silsesquioxane (HSQ). An Al discharge layer was required above the resist to prevent e-beam deflection due to charge build-up on the surface [17]. Several stamps were produced with this process and the pattern written varied in design but consisted of arrays of circular pillars. After EBL and HSQ development, the HSQ was used as an etch mask for RIE with a mixture of oxygen and argon gas. The etched diamond nanopillars were typically 225nm high. Figure 1 displays a scanning electron micrograph of some typical stamp features.", "keyphrases": ["prevent e-beam deflect due to charg build-up on the surfac", "vapour", "etch diamond nanopillar", "chemic vapour deposit", "etch mask", "ultrason solvent clean", "nanofeatur stamp were then creat from the sampl", "rie", "argon ga", "ultra-nanocrystallin diamond", "uncd wafer", "sever stamp were produc", "ebl and hsq development, t", "hydrogen silsesquioxan", "cvd", "ebl", "hsq", "rca clean", "scan electron micrograph", "circular pillar", "uncd", "al discharg layer", "convent electron beam lithographi", "oxygen", "neg tone electron sensit resist"]}
{"file_name": "S0370269304008421", "text": "The expression for Pc is also easily found in the same basis, where it becomes apparent that the dynamics of conversion in matter depends only on the relative orientation of the eigenstates of the vacuum and matter Hamiltonians. This allows to directly apply the known analytical solutions for Pc, and, upon rotating back, obtain a generalization of these results to the NSI case. For example, the answer for the infinite exponential profile [18,19] A\u221dexp(\u2212r/r0) becomes Pc=exp[\u03b3(1\u2212cos2\u03b8rel)/2]\u22121exp(\u03b3)\u22121, where \u03b3\u22614\u03c0r0\u0394=\u03c0r0\u0394m2/E\u03bd. We further observe that since \u03b3\u2aa21 the adiabaticity violation occurs only when |\u03b8\u2212\u03b1|\u2aa11 and \u03c6\u2243\u03c0/2, which is the analogue of the small-angle MSW [10,20] effect in the rotated basis. The \u201cresonant\u201d region in the Sun where level jumping can take place is narrow, defined by A\u2243\u0394 [21]. A neutrino produced at a lower density evolves adiabatically, while a neutrino produced at a higher density may undergo level crossing. The probability Pc in the latter case is given to a very good accuracy by the formula for the linear profile, with an appropriate gradient taken along the neutrino trajectory, (12)Pc\u2243\u0398(A\u2212\u0394)e\u2212\u03b3(cos2\u03b8rel+1)/2, where \u0398(x) is the step function, \u0398(x)=1 for x>0 and \u0398(x)=0 otherwise. We emphasize that our results differ from the similar ones given in [5,22] in three important respects: (i) they are valid for all, not just small values of \u03b1 (which is essential for our application), (ii) they include the angle \u03c6, and (iii) the argument of the \u0398 function does not contain cos2\u03b8, as follows from [21]. We stress that for large values of \u03b1 and \u03c6\u2243\u03c0/2 adiabaticity is violated for large values of\u00a0\u03b8.", "keyphrases": ["convers in matter", "analyt solut for pc", "gener of these result to the nsi case", "adiabat violat", "matter hamiltonian", "neutrino", "nsi", "vacuum", "pc", "rel orient of the eigenst"]}
{"file_name": "S2212667812000524", "text": "Digital libraries promise new societal benefits, especially for e-learning in digital or mobile times, starting with the elimination of the time and space constraints of traditional bricks-and-mortar libraries. The library and information professionals are required to acquire such knowledge and skills as the library is one of the highly IT influenced service profession. This paper gives an overview of current trends in digital library research consists of digital library characteristic, advantage, disadvantages and function. This paper also highlights on the impact of information technology on the traditional library.", "keyphrases": ["librari", "overview of current trend in digit librari research", "e-learn", "elimin of the time and space constraint", "bricks-and-mortar librari", "highlight on the impact of inform technolog", "acquir such knowledg and skill", "digit librari"]}
{"file_name": "S2212667813001068", "text": "It is difficult in directly predicting permeability from porosity in tight sandstones due to the poor relationship between core derived porosity and permeability that caused by the extreme heterogeneity. The classical SDR (Schlumberger Doll Research) and Timur-Coates models are all unusable because not enough core samples were drilled for lab NMR experimental measurements to calibrate the involved model parameters. Based on the classification scale method (CSM), after the target tight sandstones are classified into two types, the relationship between core porosity and permeability is established for every type of formations, and the corresponding permeability estimation models are established. Field examples show that the classification scale method is effective in estimating tight sandstone permeability.", "keyphrases": ["csm", "experiment measur", "calibr the involv model paramet", "schlumberg doll research", "classif scale method", "permeabl estim model", "permeabl", "sandston", "timur-co model", "poros", "sdr", "nmr", "field exampl", "calibr"]}
{"file_name": "S0167273813005298", "text": "At 200 \u2013 300\u00b0C: nuclear densities are localised in the tetrahedral volume roughly covering the 8c and 32f positions with \u201cbulges\u201d of nuclear densities pointing toward the 48i position, while at 400 and 500\u00b0C continuous nuclear densities forming a straight line along the <100> direction are found, indicative of oxide-ion diffusion pathway along that direction. In the literature, curved pathways along the <100> direction passing through the 48i site are generally observed in fluorite materials [20], the prevalence of curve pathway as opposed from straight pathway is explained by the repulsion between cation and anions, the curved pathway allowing the cation\u2013anion to maintain a reasonable distance. However, a straight pathway is observed for Y0.785Ta0.215O1.715 [23], as is the case for the present material. This suggests that Ta and Re cations might play a similar role in these systems.", "keyphrases": ["oxid", "ta and re cation", "ion", "anion", "oxide-ion diffus", "fluorit materi", "\u201cbulges\u201d", "cation", "present materi"]}
{"file_name": "S0032386114008428", "text": "Another choice was to graft the fluorinated groups on the copolymers with functional groups. Casazza et\u00a0al. [52] synthesized an acrylic terpolymer with pendent perfluoroether segments via grafting fluorinated groups into a poly(butyl methacrylate-co-hydroxyehtyl acrylate-co-ethyl acrylate) random copolymer through hexamethylene diisocyanate functionality. Malshe et\u00a0al. [53,54] studied the coating properties of fluorinated acrylic copolymers based on MMA, BA, and 2-hydroxyethyl methacrylate (HEMA). They partially esterified hydroxyl functionality of HEMA with tetrafluoro propanoic acid and cured the polymer with butylated melamine formaldehyde resin. Such methods were suited for the synthesis of copolymers containing complicated fluorinated groups or difficult to be provided directly by living polymerization.", "keyphrases": ["butyl methacrylate-co-hydroxyehtyl acrylate-co-ethyl acryl", "graft the fluorin group on the copolym with function group", "poli", "2-hydroxyethyl methacryl", "ba", "anoth choic", "graft fluorin group", "live polymer", "fluorin acryl copolym", "the coat properti of fluorin acryl copolym", "the polym with butyl melamin formaldehyd resin", "hema", "mma", "an acryl terpolym with pendent perfluoroeth segment", "copolym contain complic fluorin group", "copolym", "hexamethylen diisocyan function", "hydroxyl function of hema with tetrafluoro propano acid"]}
{"file_name": "S0045782513001473", "text": "In this paper, however, we prefer the simpler \u2018framed\u2019 cell employed by Hadjiconstantinou and Patera [16], where the shear stress is generated by constraining the velocity in a \u2018frame\u2019 rather than by modifying the shape of the box. The framed cell is periodic, but we cannot simply calculate the average stress in the whole box because the presence of an external buffer would produce spurious results. We need the local stress in the core region, but this complicates the Oij term in Eq. There are other methods to calculate the stress tensor such as the method of planes [32], the volume-average approach [26,14], or the method derived from the Schweitz virial relation [25], but, in general, we must choose between a complicated computational cell (i.e. Lees\u2013Edwards cell) and simplifying the calculation of the momentum flux, or a simple cell (i.e framed cell) and complicating the calculation of the momentum flux. The new method we propose here does not need the direct calculation of the flux, so it avoids this issue altogether: we can use the framed cell and, at the same time, avoid the calculation of the IK equation.", "keyphrases": ["calcul the stress tensor", "schweitz virial relat", "constrain the veloc", "method of plane", "complic comput cell", "frame cell", "framed\u2019 cell", "ik equat", "simpl cell", "volume-averag approach", "shear stress", "lees\u2013edward cell"]}
{"file_name": "S0377221716301357", "text": "As mentioned earlier, this paper represents ongoing efforts to efficiently address the stochastic MPSP. Future work may consider investigating whether the algorithm would be as successful or not in solving variants of the MPSP that include more operational constraints, such as variable cut-off grade, grade blending, and stockpiling, as it is in solving the \u201cclassical\u201d variant considered in this paper. Indeed, it is a general-purpose algorithm and should be applicable to any of these variants. Other research avenues include considering other strategies for updating the penalties within PH and other methods for solving the sub-problems. Finally, another important research direction is the development of other efficient solution approaches. Since it has been observed empirically that the problem formulation often achieves small integrality gaps, one approach could be to solve the linear relaxation of the problem using an efficient algorithm and then to use an LP-rounding procedure to get an integer solution.", "keyphrases": ["stockpil", "oper constraint", "stochast mpsp", "grade blend", "ph", "solv the linear relax", "variabl cut-off grade", "lp-round procedur", "general-purpos algorithm", "mpsp"]}
{"file_name": "S221450951530005X", "text": "An innovative sound wall system was developed in the University of Western Ontario, and was examined to serve as a vertical extension to the existing sound walls. The wall system (denoted as flexi-wall) consists of stay-in-place poly-blocks as formwork, light polyurethane foam (LPF) reinforced with steel rebars as structural cores and polyurea as a coating of the wall surfaces (Figure 1). Poly-blocks are interlocking light-weight blocks which are stacked up layer by layer and act as formwork for the LPF cores. The poly-block is 20\u00d720\u00d780cm3 and includes four cylindrical voids with 14cm diameter. It is made of molded low-density polyurethane and weighs approximately 1kg. The poly-blocks are fire-resistant blocks and have an excellent capability to absorb, mitigate and reflect a wide range of noises with unmatched frequency of reflective noise. Polyurea coating is an abrasion-resistant finishing layer, which is sprayed on the surfaces of the wall and sets within 2\u20133min. This layer also enhances the surface resistance of poly-blocks against stone impact, weathering, fire development, chemicals and penetration. LPF is an expanding liquid mixture which is injected into the poly-block voids and cures within 10min. Steel rebars are epoxied into holes drilled in the existing sound wall to connect the wall extension to its base.", "keyphrases": ["exist sound wall", "spray", "base", "structur core", "poly-block", "abrasion-resist finish layer", "fire-resist block", "expand liquid mixtur", "mitig", "lpf", "interlock light-weight block", "light polyurethan foam", "fire develop", "weather", "flexi-wal", "poly-block void", "coat", "surfac of the wall", "hole", "mold low-dens polyurethan", "stay-in-plac poly-block", "wall extens", "enhanc the surfac resist", "absorb", "wall surfac", "wall system", "lpf core", "cure", "penetr", "sound wall system", "layer", "stone impact", "reflect", "polyurea", "polyurea coat", "cylindr void", "chemic", "steel rebar"]}
{"file_name": "S1524070312000380", "text": "Isogeometric analysis (IGA) is a numerical simulation method which is directly based on the NURBS-based representation of CAD models. It exploits the tensor-product structure of 2- or 3-dimensional NURBS objects to parameterize the physical domain. Hence the physical domain is parameterized with respect to a rectangle or to a cube. Consequently, singularly parameterized NURBS surfaces and NURBS volumes are needed in order to represent non-quadrangular or non-hexahedral domains without splitting, thereby producing a very compact and convenient representation.The Galerkin projection introduces finite-dimensional spaces of test functions in the weak formulation of partial differential equations. In particular, the test functions used in isogeometric analysis are obtained by composing the inverse of the domain parameterization with the NURBS basis functions. In the case of singular parameterizations, however, some of the resulting test functions do not necessarily fulfill the required regularity properties. Consequently, numerical methods for the solution of partial differential equations cannot be applied properly.We discuss the regularity properties of the test functions. For one- and two-dimensional domains we consider several important classes of singularities of NURBS parameterizations. For specific cases we derive additional conditions which guarantee the regularity of the test functions. In addition we present a modification scheme for the discretized function space in case of insufficient regularity. It is also shown how these results can be applied for computational domains in higher dimensions that can be parameterized via sweeping.", "keyphrases": ["physic domain is parameter", "nurbs-bas represent", "discret function space", "galerkin project", "sweep", "split", "present a modif scheme", "nurb volum", "deriv addit condit which guarante the regular of the test function", "modif scheme", "iga", "isogeometr analysi", "numer simul method", "parameter", "cad model", "discuss the regular properti of the test function", "formul of partial differenti equat", "nurb object", "nurb", "numer method", "nurb basi function", "consid sever import class of singular of nurb parameter", "nurbs-bas represent of cad model", "nurb surfac"]}
{"file_name": "S0032386109005357", "text": "A hydroxyl-functionalized poly(butylene succinate) based polyester was prepared by conventional polycondensation of benzyl-protected dimethyl malonate and 1,4-butanediol (Scheme 2(a)) [24a]. Yao et\u00a0al reported on the direct polycondensation of l-lactic acid and citric acid with the formation of poly[(l-lactic acid)-co-(citric acid)], obtaining a polyester oligomer with both pendant carboxylic and hydroxyl groups [24b]. This PLCA oligomer was reacted with dihydroxylated PLLA as a macromonomer, yielding a PLCA\u2013PLLA multiblock copolymer as shown in Scheme 2(b). While lipases have been investigated for the ring-opening polymerization (ROP) of cyclic ester monomers [25,26], they have also been used for the preparation of polyesters by polycondensation reactions. The advantage of this technique is that these enzyme-catalyzed reactions proceed without protection of the pendant functional groups. In this field, hydroxyl-bearing polyesters have been synthesized by the copolymerization of divinyl adipate with various triols ( glycerol, 1,2,4-butanetriol) as represented in Scheme 2(c) [27] and by copolymerizations of 1,8-octanediol with adipic acid and several alditols [28]. Very recently, several \u03b1-hydroxy acids derived from amino acids were homo- and copolymerized with lactic acid by polycondensation in bulk without protected monomers (Scheme 2(d)) [29]. Biodegradable polyesters with various pendant groups were obtained, although the molecular weights remained low (1000\u20133000gmol\u22121).", "keyphrases": ["1,2,4-butanetriol", "amino acid", "dihydroxyl plla", "biodegrad polyest", "adip acid", "lipas", "poly[(l-lact acid)-co-(citr acid)]", "glycerol", "1,4-butanediol", "polyest oligom", "plca\u2013plla multiblock copolym", "l-lactic acid", "rop", "polycondens", "ring-open polymer", "hydroxyl-bear polyest", "alditol", "triol", "monom", "divinyl adip", "1,8-octanediol", "\u03b1-hydroxi acid", "lactic acid", "citric acid", "enzyme-catalyz", "polyest", "dimethyl malon", "copolymer", "cyclic ester monom", "plca oligom"]}
{"file_name": "S1364815216302705", "text": "The main objective of this manuscript is to present and discuss the application of SLAMM to the New York coast. Although the base analysis considers a range of different possible SLR scenarios, the effects of various sources of uncertainties such as input parameters and driving data are not accounted for. In addition, refined and site-specific data are often not available requiring the use of regional data collected from literature and professional judgement in order to run the model. To ignore the effects of these uncertainties on predictions may make interpretation of the results and subsequent decision making misleading since the likelihood and probabilities of predicted outcomes would be unknown. A unique capability of the current version of SLAMM is the ability to aggregate multiple types of input-data uncertainty to create outputs accompanied by probability statements and confidence intervals. Uncertainty in elevation data layers have been considered by several modeling groups to various extents (Gesch, 2009; Gilmer and Ferda\u00f1a, 2012; Schmid et\u00a0al., 2014). However, to the best of our knowledge, no other marsh migration model simultaneously accounts for the combined effects of uncertainty in spatial inputs (DEM, VDATUM, etc.) and parameter choices (accretion rates, tide ranges, etc.) This added feature of SLAMM allows results to be evaluated in terms of their likelihood of occurrence with respect to input-data and parameter uncertainties. Further, by assigning wide ranges of uncertainty when appropriate, it permits the production of meaningful projections in areas where high-quality local data are not available.", "keyphrases": ["slr", "paramet choic", "landcov project", "present and discuss the applic of slamm to the new york coast", "spatial input", "marsh migrat model", "accret rate", "tide rang", "high-qual local data", "dem", "vdatum", "slamm"]}
{"file_name": "S0301932213001985", "text": "In the current CLSVOF method, the normal vector is calculated directly by discretising the LS gradient using a finite difference scheme. By appropriately choosing one of three finite difference schemes (central, forward, or backward differencing), it has been demonstrated that thin liquid ligaments can be well resolved see Xiao (2012). Although a high order discretisation scheme ( 5th order WENO) has been found necessary for LS evolution in pure LS methods to reduce mass error, low order LS discretisation schemes (2nd order is used here) can produce accurate results when the LS equation is solved and constrained as indicated above in a CLSVOF method (see Xiao, 2012), since the VOF method maintains 2nd order accuracy. This is a further reason to adopt the CLSVOF method, which has been used for all the following simulations of liquid jet primary breakup.", "keyphrases": ["thin liquid ligament", "finit differ scheme", "liquid", "simul of liquid jet primari breakup", "reduc mass error", "clsvof method", "central, forward, or backward differenc", "ls method", "5th order weno", "high order discretis scheme", "ls", "vof method", "low order ls discretis scheme"]}
{"file_name": "S0370269304009293", "text": "An OPE of VQCD(r) was developed in [3]. In this and the next paragraph, we review the content of that paper relevant to our analysis. Within this framework, short-distance contributions are contained in the potentials, which are in fact the Wilson coefficients, while non-perturbative contributions are contained in the matrix elements that are organized in multipole expansion in r\u2192 at r\u226a\u039bQCD\u22121. The following relation was derived: (16)VQCD(r)=VS(r)+\u03b4EUS(r),(17)\u03b4EUS=\u2212ig2TFNC\u222b0\u221edte\u2212i\u0394V(r)t\u00d7\u3008r\u2192\u22c5E\u2192a(t)\u03c6adj(t,0)abr\u2192\u22c5E\u2192b(0)\u3009+O(r3). VS(r) denotes the singlet potential \u03b4EUS(r) denotes the non-perturbative contribution to the QCD potential, which starts at O(\u039bQCD3r2) in the multipole expansion. \u0394V(r)=VO(r)\u2212VS(r) denotes the difference between the octet and singlet potentials; see [3] for details. Intuitively VS(r) corresponds to VUV(r;\u03bcf) and \u03b4EUS(r) to VIR(r;\u03bcf). We adopt dimensional regularization in our analysis; we also refer to hard cutoff schemes when discussing conceptual aspects.", "keyphrases": ["ope", "qcd potenti", "multipol expans", "vqcd(r)", "dimension regular", "hard cutoff scheme"]}
{"file_name": "S2212667814000550", "text": "The low-carbon economic development has become the trend and orientation of regional economic development. As the residents of Heilongjiang province, their consumption is the most direct way to achieve the low-carbon lifestyle. Based on the research and discussion of the connotation of low-carbon consumption and its culture, behaviour, preferences and habits, it is concluded that the low-carbon consumption requires us to abide by the life-style of knowledge and culture. Therefore, it is obvious that the development of low-carbon economy is a complex and systematic project, involved the economic development mode, technological innovation mode, consumption values and changes of lifestyle.", "keyphrases": ["low-carbon economi", "region econom develop", "carbon", "low-carbon econom develop", "technolog innov", "develop of low-carbon economi", "econom develop", "low-carbon consumpt"]}
{"file_name": "S0301932215002037", "text": "There is also a lack of agreement as to what constitutes churn flow. It is fairly certainly a gas continuous flow. There is growing agreement that there are huge waves present and some of the liquid is carried as drops. Sekoguchi and Mori (1997) and Sawai et\u00a0al. (2004) using measurements from their multiple probes (92 over an axial length of 2.325\u00a0m) obtained time/axial position/void fraction information. From this they were able to identify huge wave from amongst disturbance waves and slugs. They classified individual structures as huge waves from their size together with the fact that their velocities depended significantly on the corresponding axial length. This was in contrast to disturbance waves where the velocity of individual waves only increased slightly with the axial extent of these waves. They also found that the frequency of huge waves first increased and then decrease with increasing gas superficial velocity. Similarly, their velocities were found to deviate from the line for slug flow velocities and pass through a maximum and then a minimum.", "keyphrases": ["ga", "slug", "time/axi position/void fraction inform", "wave", "frequenc of huge wave", "liquid", "ga superfici veloc", "churn flow", "probe", "churn", "huge wave", "slug flow veloc", "veloc of individu wave", "disturb wave", "ga continu flow", "identifi huge wave"]}
{"file_name": "S2214657115000155", "text": "MicroCT has been applied to AM parts in various forms. Some preliminary results demonstrating the visualization of defects including porosity in AM components were reported in [6]. In another study, the porosity structures in parts built with improper settings were investigated [7]. In this work, the average porosity ranged from 0.1\u20130.5%, and large pores were observed which followed the build direction and may be attributed to the electron beam raster and overlap pattern. This was followed by more recent reports of the porosity distribution as a function of build strategy for electron beam melted samples with average porosity < 0.2% [8]. In another study, similar porosity images from microCT were reported at levels above 0.2% average porosity [9,10]. Very recent work reports similar images and may indicate that the porosity structure depends on the build direction [11]. Other applications of the use of microCT to characterize AM parts include the comparison of the part to its design model [12] and the characterization of surface roughness of such parts [13]. In the present work, the aim is to demonstrate a specific type of defect present at very low average porosity levels below 0.01%, and which does not follow the build direction as in some other reported examples. We also demonstrate how this porosity structure changes after Hot Isostatic Pressing (HIP) treatment of the same sample.", "keyphrases": ["visual of defect", "not follow the build direct", "character am part", "veri low averag poros level", "poros distribut", "averag poros", "preliminari result", "demonstr a specif type of defect", "poros structur in part", "poros imag", "hot isostat press", "microct", "poros in am compon", "am part", "electron beam melt sampl", "poros structur chang", "comparison of the part to it design model", "build direct", "character of surfac rough", "electron beam raster and overlap pattern.", "recent report", "hip"]}
{"file_name": "S0927025614003322", "text": "A principle of high-throughput materials science is that one does not know a priori where the value of the data lies for any specific application. Trends and insights are deduced a posteriori. This requires efficient interfaces to interrogate available data on various levels. We have developed a simple WEB-based API to greatly improve the accessibility and utility of the AFLOWLIB database [14] to the scientific community. Through it, the client can access calculated physical properties (thermodynamic, crystallographic, or mechanical properties), as well as simulation provenance and runtime properties of the included systems. The data may be used directly (, to browse a class of materials with a desired property) or integrated into higher level work-flows. The interface also allows for the sharing of updates of data used in previous published works, , previously calculated alloy phase diagrams [19\u201331], thus the database can be expanded systematically.", "keyphrases": ["improv the access and util of the aflowlib databas", "effici interfac to interrog avail data on variou level", "simul proven", "higher level work-flow", "thermodynamic, crystallographic, or mechan properti", "share of updat of data", "physic properti", "interfac", "brows a class of materi with a desir properti", "high-throughput materi scienc", "runtim properti", "aflowlib databas", "alloy phase diagram", "web-bas api"]}
{"file_name": "S2212667814001166", "text": "Along with the expansion of computer-based climate simulations, efficient visualization and analysis of massive climate data are becoming more important than ever. In this paper, we try to explore the factors behide climate changes by combining window query and time-varying data mining techniques. With constant query time and acceptable storage cost, the algorithms presented support various queries on 3d time-varying datasets, such as average, min, and max value. A new time-varying data analysis algorithm is given, which is especially suitable for analyzing big data. All these algorithms have been implemented on and integrated into a visual analysis system, with tiled-LCD ultra-resolution display. Experimental results on several datasets from practical applications are presented.", "keyphrases": ["explor the factor behid climat chang", "analyz big data", "tiled-lcd ultra-resolut display", "visual and analysi of massiv climat data", "3d time-vari dataset", "algorithm", "combin window queri and time-vari data mine techniqu", "time-vari data analysi algorithm", "massiv climat data", "queri", "sever dataset from practic applic", "expans of computer-bas climat simul", "implement on and integr into a visual analysi system", "computer-bas climat simul"]}
{"file_name": "S0370269304009359", "text": "Table 1 lists 8 pairs of B decays. In fact, there are more decay pairs, since many of the particles in the final states can be observed as either pseudoscalar\u00a0(P) or vector\u00a0(V) mesons. Note that certain decays are written in terms of VV final states, while others are have PP\u00a0states. There are three reasons for this. First, some decays involve a final-state\u00a0\u03c00. However, experimentally it will be necessary to find the decay vertices of the final particles. This is virtually impossible for a\u00a0\u03c00, and so we always use a\u00a0\u03c10. Second, some pairs of decays are related by SU(3) in the SM only if an (ss\u00af) quark pair is used. However, there are no P's which are pure (ss\u00af). The mesons \u03b7 and \u03b7\u2032 have an (ss\u00af) component, but they also have significant (uu\u00af) and (dd\u00af) pieces. As a result the b\u00af\u2192s\u00af and b\u00af\u2192d\u00af decays are not really related by SU(3) in the SM if the final state involves an \u03b7 or\u00a0\u03b7\u2032. We therefore consider instead the vector meson \u03d5 which is essentially a pure (ss\u00af) quark state. Finally, we require that both B0 and B\u00af0 be able to decay to the final state. This cannot happen if the final state contains a single K0 (or K\u00af0) meson. However, it can occur if this final-state particle is an excited neutral kaon. In this case one decay involves K*0, while the other has K\u00af*0. Assuming that the vector meson is detected via its decay to \u03c8Ks\u03c00 (as in the measurement of sin2\u03b2 via Bd0(t)\u2192J/\u03c8K*), then both B0 and B\u00af0 can decay to the same final state.", "keyphrases": ["b decay", "\u03b7", "\u03c8ks\u03c00", "meson", "measur of sin2\u03b2", "final particl", "excit neutral kaon", "b0", "quark pair", "find the decay vertic", "decay", "decay pair", "quark", "k\u00af*0", "vector meson", "\u03d5", "quark state", "decay to the final state", "decay to \u03c8ks\u03c00", "final-st particl", "\u03b7\u2032", "k*0", "sm", "pair of decay", "b\u00af0"]}
{"file_name": "S0038092X11004129", "text": "Assuming a constant cell electrical conversion efficiency of 15%, a constant fraction of the incident solar radiation would be dissipated by the solar cell for each solar radiation intensity level. From Table 2, it can be seen that for the worst scenario when the ambient temperature was 50\u00b0C with natural convection only, the predicted cell electrical conversion efficiency would have reduced to approximately 8% rather than the 15% assumed. The energy dissipated as heat from the cell would thus be 7% higher. To correct for this effect the apparent insolation level should be modified using the following formula:(3)Iact=I\u00d70.850.85+d\u03b7where Iact is the actual incident solar radiation intensity, d\u03b7 is solar cell efficiency difference between the initially assumed 15% and final calculated cell efficiency based on measured cell temperature.", "keyphrases": ["predict cell electr convers effici", "solar radiat", "(3)iact=i\u00d70.850.85+d\u03b7", "cell electr convers", "natur convect", "appar insol level"]}
{"file_name": "S2352179114200056", "text": "Power and particle exhaust are crucial for the viability of any future fusion power plant concept. Heat in fusion reactors must be extracted through a wall and cannot be exhausted volumetrically, which limits the allowed power density in fusion reactors [1] and is a severe technical challenge in itself [2]. In addition, structural material changes resulting from neutron irradiation cause degradation in the heat exhaust capabilities of existing designs [3] and static surfaces can suffer severely from erosion due to impinging plasma particles [4,5]. It is concluded that conventional concepts and materials for plasma facing components (PFCs) reach their limits in terms of material lifetime and power exhaust at approximately 20MW/m2, which is presumably dramatically reduced to <10MW/m2 due to neutron damage in a D-T reactor [6] or even only half that value [7].", "keyphrases": ["structur materi", "neutron damag", "structur materi chang", "power and particl exhaust", "sever technic challeng", "pfc", "neutron", "neutron irradi", "imping plasma particl", "fusion power plant", "fusion reactor", "d-t reactor", "plasma face compon", "static surfac"]}
{"file_name": "S1574119211001544", "text": "As future work on the protocol, we would promote two items. Firstly, the two mobility models that we have considered in this work propose possible way to capture social context in the way nodes move in the physical space, yet still potentially allowing nodes to explore the geographical regions considered in its entirety. Further insights to the performance potential could be given through the assessment of the protocol with other mobilities that can extend the physical region of movement as well as impose potential restrictions on the nodes mobility, for example by forcing similar nodes to move within specifically defined areas. Secondly, the different forwarding modes introduced in Section\u00a0 3.3 express different levels of cooperation across the network. The push-community mode, for example, is a form of interest-community selfishness and assumes reciprocation in the nodes\u2019 behaviour. The vulnerability (resp resilience) of the protocol to different instances of node misbehaviours is a research item worth exploring.", "keyphrases": ["node mobil", "extend the physic region of movement", "forward mode", "impos potenti restrict", "push-commun mode", "node", "mobil model", "protocol", "perform potenti", "geograph region", "forc similar node to move within specif defin area", "physic space", "network"]}
{"file_name": "S0266352X16301550", "text": "To address the vertical displacement estimation of conventional pile groups subjected to mechanical loads, various numerical and analytical methods have been proposed. These methods include the finite element method [, 2,3], the boundary element method [, 4,5], the finite difference method [, 6], the interaction factor method [, 7,8\u201311], the equivalent pier and raft methods [, 12\u201314], and the settlement ratio method [, 15]. The finite element method, while providing the most rigorous and exhaustive representation of the pile group-related problem, is generally computationally expensive and considered mainly a research tool rather than a design tool. Conversely, the versatility of simplified (approximate) methods, such as the interaction factor approach that allows capturing the (, vertical) displacements of any general pile group by the analysis of the displacement interaction between two identical piles and by the use of the elastic principle of superposition of effects, makes them attractive as design tools because they allow for the use of expedient parametric studies under various design conditions.", "keyphrases": ["finit differ method", "vertic displac estim of convent pile group subject to mechan load", "elast principl of superposit of effect", "pile group-rel problem", "research tool", "analysi of the displac interact between two ident pile", "equival pier and raft method", "design tool", "expedi parametr studi", "interact factor method", "versatil of simplifi (approximate) method", "numer and analyt method", "captur the (e.g., vertical) displac of ani gener pile group", "settlement ratio method", "boundari element method", "interact factor approach", "finit element method"]}
{"file_name": "S0165212511000862", "text": "In this paper we construct such a physical model with a continuous distribution of relaxations. It is based on the phenomenological theory of relaxation processes which have a long history in physics literature and was recently summarized in a monograph in which references to other relevant publications can be found,\u00a0[24]; also see\u00a0[25]. The present work is confined to relaxation mechanisms which result from changes in normal stresses. More specifically, we are interested in the local mechanisms of irreversible energy loss caused by uniform compression or expansion of a medium for which all components remain unchanged, rather than the losses caused by friction between different layers of a medium which move with different velocities (for a more detailed discussion of this issue see\u00a0[26]). No attempt is made to model effects of shear viscosity and heat conduction beyond the conventional Navier\u2013Stokes approach, since this topic goes far beyond the scope of this paper.", "keyphrases": ["navier\u2013stok approach", "heat conduct", "continu distribut of relax", "relax mechan", "physic model", "shear viscos", "irrevers energi loss", "friction between differ layer of a medium", "relax process", "compress or expans of a medium", "local mechan of irrevers energi loss", "phenomenolog theori of relax process", "relax"]}
{"file_name": "S0045782512002599", "text": "Finite Element Tearing and Interconnecting (FETI) methods are a powerful approach to designing solvers for large-scale problems in computational mechanics. The numerical simulation problem is subdivided into a number of independent sub-problems, which are then coupled in appropriate ways. NURBS- (Non-Uniform Rational B-spline) based isogeometric analysis (IGA) applied to complex geometries requires to represent the computational domain as a collection of several NURBS geometries. Since there is a natural decomposition of the computational domain into several subdomains, NURBS-based IGA is particularly well suited for using FETI methods.This paper proposes the new IsogEometric Tearing and Interconnecting (IETI) method, which combines the advanced solver design of FETI with the exact geometry representation of IGA. We describe the IETI framework for two classes of simple model problems (Poisson and linearized elasticity) and discuss the coupling of the subdomains along interfaces (both for matching interfaces and for interfaces with T-joints, i.e hanging nodes). Special attention is paid to the construction of a suitable preconditioner for the iterative linear solver used for the interface problem. We report several computational experiments to demonstrate the performance of the proposed IETI method.", "keyphrases": ["sever subdomain", "simpl model problem", "poisson", "advanc solver design", "nurbs-bas iga", "construct of a suitabl precondition for the iter linear solver", "number of independ sub-problem", "numer simul problem", "isogeometr tear and interconnect", "ieti", "demonstr the perform of the propos ieti method", "finit element tear and interconnect", "iga", "isogeometr analysi", "solver for large-scal problem in comput mechan", "linear elast", "complex geometri", "ieti framework", "non-uniform ration b-spline", "comput domain as a collect of sever nurb geometri", "feti", "hang node", "interfac with t-joint", "feti method", "nurb", "exact geometri represent", "coupl of the subdomain along interfac"]}
{"file_name": "S0021999116303291", "text": "DPD was first proposed in order to recover the properties of isotropy (and Galilean invariance) that were broken in the so-called lattice-gas automata method [5]. In DPD, each body is regarded as a coarse-grained particle. These particles interact in a soft (and short-ranged) potential, allowing larger integration timesteps than would be possible in MD, while simultaneously decreasing the number of degrees of freedom required. As in Langevin dynamics, a thermostat consisting of well-balanced damping and stochastic terms is applied to each particle. However, unlike in Langevin dynamics, both terms are pairwise and the damping term is based on relative velocities, leading to the conservation of both the angular momentum and the linear momentum. The property of Galilean invariance (i.e., the dependence on the relative velocity) makes DPD a profile-unbiased thermostat (PUT) [6,7] by construction and thus it is an ideal thermostat for nonequilibrium molecular dynamics (NEMD) [8]. The momentum is expected to propagate locally (while global momentum is conserved) and thus the correct hydrodynamics is expected in DPD [8], as demonstrated previously in [9]. Due to the aforementioned properties, DPD has been widely used to recover thermodynamic, dynamical, and rheological properties of complex fluids, with applications in polymer solutions [10], colloidal suspensions [11], multiphase flows [12], and biological systems [13]. DPD has been compared with Langevin dynamics for out-of-equilibrium simulations of polymeric systems in [14], where as expected the correct dynamic fluctuations of the polymers were obtained with the former but not with the latter.", "keyphrases": ["thermostat", "nonequilibrium molecular dynam", "put", "isotropi", "nonequilibrium molecular dynam (nemd)", "dpd", "coarse-grain particl", "galilean invari", "biolog system", "nemd", "angular momentum", "colloid suspens", "dynam fluctuat", "particl", "polymer system", "langevin dynam", "profile-unbias thermostat", "complex fluid", "recov thermodynamic, dynamical, and rheolog properti", "md", "polym", "depend on the rel veloc", "multiphas flow", "lattice-ga automata", "linear momentum", "polym solut"]}
{"file_name": "S0378381215300674", "text": "The next phase of our current study is to use the parameters obtained from pure-component systems in a transferable manner to represent the corresponding mixtures. Mixtures of n-alkanes and H2O have been studied previously with SAFT-\u03b3 SW [82]. In general it is well known that the extreme nature of the phase separation [150] makes it challenging to model mixtures of H2O with non-polar compounds. Because of the large differences in the dielectric constant of the two phases as well as in the dipole moment of H2O and the hydrophobic molecules, it especially difficult to obtain phase-independent unlike interaction parameters [112] and thus to model simultaneously the equilibrium phases. In previous work [82], emphasis was placed on obtaining an accurate description of the alkane-rich phases (both liquid and vapour), while small absolute (but not relative) deviations for the aqueous phase composition were achieved. The systems of interest in our current work are typically aqueous mixtures containing a high proportion of H2O, alkylamine, and CO2. Consequently, in order to provide an improved overall description of the fluid-phase equilibria at the conditions of interest, refinements have been made to the unlike parameters presented in the previous study [129] relating to the interactions between H2O and the alkyl groups, CH3 and CH2, namely \u03f5CH3,H2O, \u03f5CH2,H2O and \u03bbCH3,H2O, \u03bbCH2,H2O.", "keyphrases": ["vapour", "aqueou mixtur", "\u03bbch3,h2o, \u03bbch2,h2o", "interact between h2o and the alkyl group", "hydrophob molecul", "alkylamin", "fluid", "descript of the alkane-rich phase", "fluid-phas equilibria", "h2o", "saft-\u03b3 sw", "co2", "ch3 and ch2", "pure-compon system", "non-polar compound", "alkyl group", "\u03f5ch3,h2o, \u03f5ch2,h2o", "mixtur of n-alkan and h2o", "liquid", "mixtur of h2o"]}
{"file_name": "S0963869514000863", "text": "EM sensors exploit the difference in magnetic properties, such as relative permeability, and electrical conductivity between samples with different microstructural phase balances. In ferromagnetic steels, the change in relative permeability has a significant effect. Previously, multi-frequency EM sensors have been shown to be able to measure austenite/ferrite fraction from 0% to 100% in model (HIPped austenitic/ferritc stainless steel powder) alloys [7,8]. The large difference in magnetic properties of ferrite (ferromagnetic) and austenite (paramagnetic) phases makes the change in signal large and hence relatively easy to measure. EM sensors have also measured the levels of decarburisation (variation in ferrite content with depth) in steel rod [9,10]. The approach adopted to relate the overall steel EM sensor signal to its microstructure has been to construct a finite element (FE) model for the microstructure (phase, region size and distribution). The EM properties of the individual phases are assigned to those regions to give the overall EM properties of the steel. Within the model the particular sensor geometry is included ( two-dimensional axisymmetric for a cylindrical sample and tubular sensor [10]) and the interaction with the steel and any external circuits predicted. In this way different microstructures and sensor designs can be compared.", "keyphrases": ["paramagnet", "decarburis", "ferromagnet", "austenit", "electr conduct", "differ in magnet properti", "tubular sensor", "em sensor signal", "particular sensor geometri", "finit element", "em sensor", "em properti of the individu phase", "cylindr sampl", "steel rod", "microstructur", "overal em properti", "steel", "extern circuit", "microstructur phase balanc", "fe", "stainless steel powder", "multi-frequ em sensor", "rel permeabl", "variat in ferrit content with depth", "ferrit", "sensor", "ferromagnet steel"]}
{"file_name": "S221267161200162X", "text": "A fuzzy-Hammerstein model predictive control method is proposed for a continuous stirred-tank reactor (CSTR). In this paper T-S fuzzy model is used to approximate the static nonlinear characteristics of Hammerstein model, and a linear autoregressive model is used to solve the results of optimal control. The designed nonlinear predictive controller using Hammerstein model make good use of the ability of universal approach nonlinear of T-S model, and divide the question of nonlinear predictive control into the nonlinear model recongnization and the question of linear predictive control. The application results of CSTR process show the proposed control method has good control performance compared to PID controller.", "keyphrases": ["univers approach nonlinear", "nonlinear model recongn", "linear autoregress mode", "hammerstein model", "fuzzy-hammerstein model predict control method", "control method", "optim control", "pid control", "t- fuzzi model", "cstr", "nonlinear predict control", "t- model", "fuzzy-hammerstein model", "linear predict control", "cstr process", "static nonlinear characterist of hammerstein model", "continu stirred-tank reactor"]}
{"file_name": "S0370269304007695", "text": "In summary, we have shown that one can describe the experimental data of the HERMES Collaboration for hadron attenuation on nuclei without invoking any changes in the fragmentation function due to gluon radiation. In our dynamical studies, that include the most relevant FSI, we employ only the \u2018free\u2019 fragmentation function on a nucleon and attribute the hadron attenuation to the deceleration of the produced (pre-)hadrons due to FSI in the surrounding medium. We find that in particular the z-dependence of RMh is very sensitive to the interaction cross section of leading prehadrons and can be used to determine \u03c3lead. The interaction of the leading prehadrons during the formation time could be interpreted as an in-medium change of the fragmentation function, which however could not be given in a closed form. The extracted average hadron formation times of \u03c4f\u22730.3\u00a0fm/c are compatible with the analysis of antiproton attenuation in p+A reactions at AGS energies [17]. In an upcoming work we will investigate in detail the spectra for different particle species (\u03c0\u00b1,K\u00b1,p,p\u0304) to examine, if the formation times of mesons and antibaryons are about equal. In addition we will improve our model to describe the primary photon\u2013nucleon reaction below the PYTHIA threshold of W\u2a7e4\u00a0GeV.", "keyphrases": ["nuclei", "gluon radiat", "photon", "meson", "hadron attenu", "particl speci", "\u03c0\u00b1", "determin \u03c3lead", "antiproton", "nucleon", "dynam studi", "k\u00b1", "fsi", "analysi of antiproton attenu", "describ the experiment data of the herm collabor for hadron attenu on nuclei", "detail the spectra for differ particl speci (\u03c0\u00b1,k\u00b1,p,p\u0304)", "rmh", "p", "\u2018free\u2019 fragment function", "hadron", "p\u0304", "antibaryon", "primari photon\u2013nucleon reaction", "fragment function", "in-medium chang of the fragment function", "surround medium", "improv our model to describ the primari photon\u2013nucleon reaction below the pythia threshold of w\u2a7e4 gev", "interact of the lead prehadron dure the format time", "hadron format", "produc (pre-)hadron", "lead prehadron", "p+a reaction", "examine, if the format time of meson and antibaryon are about equal", "the z-depend of rmh"]}
{"file_name": "S0370269304007798", "text": "States outside the constituent quark model have been hypothesized to exist almost since the introduction of color\u00a0[1\u20134]. Hybrid mesons, qq\u0304 states with an admixture of gluons, and glueballs, states with no quark content, rely on the self interaction property of gluons due to their color charge. Looking for glueballs would be the most obvious way to find evidence for states with constituent gluons; however, the search is hindered by the fact that these states may significantly mix with regular qq\u0304-mesons in the region where the lightest are predicted to occur. As such, they may not be observable as pure states and disentangling the observed spectra may be a very difficult task. Instead, hybrid mesons (qq\u0304gn) may be a better place to search for evidence of resonances outside the constituent quark model, especially since the lightest of theses states are predicted to have exotic quantum numbers of spin, parity, and charge conjugation, JPC, that is, combinations that are unattainable by regular qq\u0304-mesons.", "keyphrases": ["color charg", "quark", "find evid for state with constitu gluon", "constitu quark model", "jpc", "hybrid meson", "disentangl the observ spectra", "qq\u0304gn", "reson outsid the constitu quark model", "look for gluebal", "qq\u0304-meson", "gluebal", "gluon"]}
{"file_name": "S2212667814000070", "text": "This paper suggests a design of high quality real-time rotation face detection architecture for gesture recognition of smart TV. For high performance rotated face detection, the multiple-MCT(Modified Census Transform) architecture, which is robust against lighting change, was used. The Adaboost learning algorithm was used for creating optimized learning data. The proposed hardware structure was composed of Color Space Converter, Image Resizer, Noise Filter, Memory Controller Interface, Image Rotator, Image Scaler, MCT Generator, Candidate Detector, Confidence Switch, Confidence Mapper, Position Resizer, Data Grouper, Overlay Processor and Color Overlay Processer. As a result, suggested face detection device can conduct real-time processing at speed of at least 30 frames per second.", "keyphrases": ["rotat face detect architectur", "candid detector,", "data grouper", "design of high qualiti real-tim rotat face detect architectur for gestur recognit of smart tv", "color space convert", "gestur recognit", "confid switch", "creat optim learn data", "mct gener", "imag rotat", "confid mapp", "modifi censu transform", "face detect", "adaboost learn algorithm", "posit resizer,", "imag scaler", "hardwar structur", "color overlay process", "imag resizer,", "mct", "overlay processor", "real-tim process", "memori control interfac", "nois filter"]}
{"file_name": "S0010938X14002157", "text": "A surfactant is a surface active agent. In this work a surfactant term will be used for compounds which improve the dispersability of the CI in the acid (as emulsifiers providing dispersed emulsion \u2013 not separated) while wetting the surface of the metallic material [14,20,24]. However, surfactants can offer corrosion protection themselves. Some examples when the same compound was used as a surfactant or active corrosion inhibitor ingredient are given below. Typical surfactants in the oilfield services industry are alkylphenol ethoxylates,  nonylphenol ethoxylate (NPE) [14,15,30,106,107]. However, NPEs have been banned from use in the North Sea because of their toxicity. On the other hand, ethoxylated linear alcohols are more acceptable [20]. The quaternary ammonium salts and amines (when protonated) are the most used compounds of the cationic surfactants class, where the cation is the surface active specie. As the amines only function as a surfactant in the protonated state, they cannot be used at high pH. On the other hand, quaternary ammonium compounds, frequently abbreviated as \u201cquats\u201d, are not pH sensitive. Long-chain quaternary ammonium bromides were also reported to work as efficient CIs for steel materials [106]. A frequently employed surfactant was N-dodecylpyridinium bromide (DDPB) [9,60,61,108,109]. Anionic sulphates, anionic sulphonates, alkoxylated alkylphenol resins, and polyoxyethylene sorbitan oleates are also useful surfactants. Ali reported that a particularly useful surfactant is a blend of polyethylene glycol esters of fatty acids and ethoxylated alkylphenols [15]. Several examples of the surfactants used are given below in Section 5.6.", "keyphrases": ["compound which improv the dispers", "n-dodecylpyridinium bromid", "quaternari ammonium salt", "quat", "blend of polyethylen glycol ester of fatti acid and ethoxyl alkylphenol", "anion sulphat", "improv the dispers", "quaternari ammonium compound", "emulsifi", "proton state", "ci", "amin", "nonylphenol ethoxyl", "metal materi", "polyoxyethylen sorbitan oleat", "cation", "ethoxyl linear alcohol", "surfac activ speci", "ddpb", "amin (when protonated)", "npe", "alkoxyl alkylphenol resin", "acid", "cation surfact class", "corros protect", "surfact", "anion sulphon", "alkylphenol ethoxyl", "long-chain quaternari ammonium bromid", "surfact or activ corros inhibitor", "dispers emuls", "steel materi", "surfac activ agent"]}
{"file_name": "S0045782514004812", "text": "We shall establish the variational format in the space\u2013time domain S=def\u03a9\u00d7I, for given spatial domain \u03a9 and time domain I=(0,T), for a quite broad class of problems involving a first order time-derivative. In particular, the coupled problem of consolidation of geomaterials falls within this class. Another interesting application is the problem of dynamics, rewritten in first-order form, i.e through a Hamiltonian description. It is of considerable interest to note from the outset that, due to the forward transport of information in time, it is always possible to consider a set of finite time intervals, whereby the solution at the end of any such interval will act as the initial data for the next one. To this end, we introduce a partition 0=t0<t1<\u22ef<tN=T of the considered time domain I=(0,T) into time-intervals In=(tn\u22121,tn) of length \u0394tn=tn\u2212tn\u22121.11The abbreviated notation \u0394t=\u0394tn will be used henceforth for the current time step associated with In. Hence, we define space\u2013time slabs Sn=def\u03a9\u00d7In such that the space\u2013time domain can be given as S=def\u03a9\u00d7I=S1\u222aS2\u22ef\u222aSn.", "keyphrases": ["coupl problem of consolid of geomateri", "space\u2013tim domain", "problem of dynamics, rewritten in first-ord form", "hamiltonian descript", "sn=def\u03c9\u00d7in", "spatial domain \u03c9", "variat format in the space\u2013tim domain", "s=def\u03c9\u00d7i", "s=def\u03c9\u00d7i=s1\u222as2\u22ef\u222asn", "space\u2013tim slab", "time domain i=(0,t)", "first order time-deriv"]}
{"file_name": "S0370269302011838", "text": "First results from RHIC on charged multiplicities, evolution of multiplicities with centrality, particle ratios and transverse momentum distributions in central and minimum bias collisions, are analyzed in a string model which includes hard collisions, collectivity in the initial state considered as string fusion, and rescattering of the produced secondaries. Multiplicities and their evolution with centrality are successfully reproduced. Transverse momentum distributions in the model show a larger pT-tail than experimental data, disagreement which grows with increasing centrality. Discrepancies with particle ratios appear and are examined comparing with previous features of the model at SPS.First results from RHIC on charged multiplicities, evolution of multiplicities with centrality, particle ratios and transverse momentum distributions in central and minimum bias collisions, are analyzed in a string model which includes hard collisions, collectivity in the initial state considered as string fusion, and rescattering of the produced secondaries. Multiplicities and their evolution with centrality are successfully reproduced. Transverse momentum distributions in the model show a larger pT-tail than experimental data, disagreement which grows with increasing centrality. Discrepancies with particle ratios appear and are examined comparing with previous features of the model at SPS.", "keyphrases": ["charg multipl", "collect in the initi state", "evolut of multipl with central", "particl ratio", "particl", "discrep with particl ratio", "their evolut", "rescatt of the produc secondari", "hard collis", "string model", "multipl", "transvers momentum distribut"]}
{"file_name": "S092702561300760X", "text": "Due to the complex nature of the thermal spray process, modelling has been playing a key role in providing some key insights for process design and operations. The relationships among processing conditions, particle characteristics, and the resulting coating properties are nonlinear and might be difficult to be unravelled by the experimental studies alone ( [5\u20137]) Detailed information on the atomic level changes leading to changes observed at macroscale can appropriately be obtained by MD simulation and the effect of temperature and velocity can be determined more precisely. In this work, relatively simpler spray system of copper\u2013copper particle was simulated to obtain a better understanding of particle recrystallization and solidification, and deformation mechanics and topography of the impacting particles. Using state-of-the-art methods to examine the physical mechanisms involved in the impacting behavior and structure\u2013property relationship, it can be suggested that the consecutive layer deposition of particles can better be understood by understanding individual particle impacts. The particle\u2013surface interaction mechanism and its relation to Reynolds number can offer information on the quality of the coating through its response to shock heating. As a general practice, engineering components are thermally sprayed in a continuous multilayer mode with cooling; therefore there is an opportunity for developing richer theoretical models for single or multiple particle impact in conjunction with actual spraying tests, so as to identify cohesive and adhesive strength, hardness and residual stresses.", "keyphrases": ["md simul", "provid some key insight for process design and oper", "particle\u2013surfac interact mechan", "surfac", "engin compon", "process", "reynold number", "thermal spray", "understand individu particl impact", "develop richer theoret model for singl or multipl particl impact", "model", "coat", "spray test", "spray system", "atom level chang", "copper\u2013copp particl", "cool", "particl", "deform", "experiment studi", "shock heat", "thermal spray process", "md", "particl recrystal and solidif", "consecut layer deposit"]}
{"file_name": "S1574119215000796", "text": "The proposed multihop routing protocol, PHASeR, applies the technique of blind forwarding in a MWSN, which increases the reliability of data delivery through its inherent use of multiple routes. This approach requires a gradient metric to be continuously maintained, which is problematic in a dynamic topology. The literature commonly uses either flooding or location awareness, however flooding creates large amounts of overhead and location determination schemes can often be inaccurate, power hungry and create the issue of the dead end problem. PHASeR uses a novel method of gradient maintenance in a mobile network, which requires the proactive sharing of only local topology information. This is facilitated by a global TDMA (time division multiple access) MAC (medium access control) layer and further reduces the amount of overhead, which in turn will decrease packet latency. PHASeR is also set apart by its use of encapsulation, which allows data from multiple nodes to be transmitted in the same packet in order to handle high volumes of traffic. It utilises node cooperation to create a robust multipath routing solution. As such, the contribution of this paper is a cross-layer routing protocol for MWSNs that can handle the constant flow of data from sensors in highly mobile situations.", "keyphrases": ["gradient mainten", "gradient metric", "mobil network", "node", "multihop rout protocol", "phaser", "cross-lay rout protocol", "mwsn", "cross-lay rout protocol for mwsn", "node cooper", "medium access control", "packet latenc", "time divis multipl access", "sensor", "mac", "tdma", "encapsul"]}
{"file_name": "S1364815216303061", "text": "In representing wetland-river interactions involving GIWs, many models assume that the wetland can discharge into a river but cannot receive overbank flows from it. In such models, the volume of water (or water level elevation) in a wetland and its corresponding threshold value (predominantly controlled by outlet elevation) are the prime determinants of wetland outflow (Feng et\u00a0al., 2012; Hammer and Kadlec, 1986; Johnson et\u00a0al., 2010; Kadlec and Wallace, 2009; Powell et\u00a0al., 2008; Voldseth et\u00a0al., 2007; Wen et\u00a0al., 2013; Zhang and Mitsch, 2005). However, in regions characterised by widespread riparian wetlands that are hydraulically connected with adjacent rivers, wetland-river interaction is likely to be bidirectional. Such interactions should be quantified according to hydraulic principles involving relative river and wetland water level elevations as well as the properties of the connection between the two (Kouwen, 2013; Liu et\u00a0al., 2008; Min et\u00a0al., 2010; Nyarko, 2007; Restrepo et\u00a0al., 1998). In the WATFLOOD model, for instance, riparian wetland-river interaction is modelled using the principle of Dupuit-Forchheimer lateral/radial groundwater flow (Kouwen, 2013). Since exchange between riparian wetlands and rivers can occur over the surface and/or through the subsurface, Restrepo et\u00a0al. (1998) incorporated an equivalent transmissivity expression, obtained for wetland vegetation and the subsurface soil, into the Darcy flow equation of the MODFLOW model.", "keyphrases": ["subsurfac soil", "watflood", "interact should be quantifi accord to hydraul principl", "outlet elev", "repres wetland-riv interact involv giw", "properti of the connect between the two", "riparian wetland-riv interact is model", "equival transmiss express", "principl of dupuit-forchheim lateral/radi groundwat flow", "rel river and wetland water level elev", "modflow", "wetland veget", "darci flow equat"]}
{"file_name": "S2214657115000179", "text": "Aeroengine turbine disks often consist of paramagnetic, that means non-ferromagnetic Nickel based alloys. Sometimes, parasitic small ferromagnetic particles can be included in these disks that may decrease the mechanical stability. For this reason, in case of a suspicion disks are to be analysed with respect to ferromagnetic inclusions. These inclusions generate a magnetic density which can be measured by a flux gate magnetometer using the magnetic remanence method [1]. The detection principle of ferromagnetic impurities in non-magnetic metallic materials is based on their remanence. Before such a measurement can be carried out, the aeroengine turbine disks are premagnetised in axial direction. As ferromagnetic materials show the well-known hysteresis behaviour, those materials can be magnetised by a strong magnetic field which drives the magnetic material into saturation. When removing the magnetic field, the remanence is left. This remaining flux density is used to detect them in non-magnetic materials.", "keyphrases": ["paramagnet", "flux gate magnetomet", "non-ferromagnet nickel base alloy", "remov the magnet field", "strong magnet field", "ferromagnet inclus", "remain flux densiti", "magnet densiti", "magnet reman method", "measur", "parasit small ferromagnet particl", "aeroengin turbin disk", "decreas the mechan stabil", "premagnetis", "hysteresi behaviour", "detect principl of ferromagnet impur"]}
{"file_name": "S0370269304008780", "text": "In the NJL model studied here, we find no stable stars with either CFL or normal quark matter cores. This is the opposite of the prediction of Ref. [15] where it was argued that there is no 2SC phase in compact stars. Let us be more precise: performing a Taylor expansion in the strange quark mass, the authors of Ref. [15] found that in beta-equilibrated electrically and color neutral quark matter the 2SC phase is always less favored than the CFL phase or normal quark matter. From this observation they concluded that the 2SC phase is absent in compact stars. In contrast to this result, it was shown in Ref. [16] in the framework of the NJL model that neutral 2SC matter could be the most favored quark phase in a certain regime. However, the authors argued that this interval might disappear if the hadronic phase is included more properly. This is indeed what we found for parameter set RKH, while for parameter set HK the 2SC phase survives only in a tiny window. Nevertheless, if Nature chooses to be similar to this equation of state, it will be this tiny window which gives rise to hybrid stars, whereas the CFL phase would be never present in compact stars.", "keyphrases": ["njl model studi", "beta-equilibr electr", "cfl or normal quark matter core", "neutral 2sc matter", "quark phase", "stabl star", "compact star", "taylor expans", "njl model", "normal quark matter", "strang quark mass", "hadron phase", "color neutral quark matter", "hybrid star", "cfl phase", "2sc phase"]}
{"file_name": "S016793171300244X", "text": "Ever since the identification of the paramagnetic E\u2032 centre in SiO2 as an unpaired electron localised in an sp3 hybrid orbital of an Si atom backbonded to three oxygen atoms, a number of attempts has been made at explaining the optical and electronic properties of SiO2 in the presence of E\u2032 centres. The irradiation or hole injection induces trapping of positive charge in thin layers of a-SiO2 grown on silicon surfaces by thermal oxidation. This effect has been correlated with paramagnetic E\u2032 centre signals and led to the initial assignment of the neutral oxygen vacancy as the major hole trap in a-SiO2 [1\u20133]. In this model, originally proposed for E\u2032 centres in \u03b1-quartz, upon trapping a hole, one Si atom from the two Si atoms constituting the vacancy remains neutral and hosts the localised unpaired electron while its counterpart becomes positively charged. Although this model has initially been accepted widely for its simplicity, it fails to account for a number of observations, such as the positive charge trapping without generation of E\u2032 centres [4], the formation of high density of E\u2032 centres without the corresponding density of positive charge [5], and the absence of correlation between the decrease of the E\u2032 centre density and the density of positive charge upon post-irradiation electron injection in SiO2 [6].", "keyphrases": ["sio2", "thermal oxid", "e\u2032 centr in \u03b1-quartz", "posit charg", "paramagnet e\u2032 centr", "silicon surfac", "major hole trap", "a-sio2", "irradi", "si atom", "explain the optic and electron properti of sio2 in the presenc of e\u2032 centr", "post-irradi electron inject", "identif of the paramagnet e\u2032 centr in sio2", "oxygen atom", "unpair electron", "e\u2032 centr", "hole inject", "neutral oxygen vacanc", "high densiti of e\u2032 centr", "localis unpair electron", "sp3 hybrid orbit", "paramagnet e\u2032 centr signal", "trap of posit charg in thin layer of a-sio2 grown on silicon surfac", "posit charg trap"]}
{"file_name": "S107158191630074X", "text": "An obvious metric to measure the monitoring performance between the different conditions would be to compare how many clicks the users made in average for each condition. Furthermore of interest are the buffer values of the respective buffers at the time of the user's interaction with the simulation (, the input buffer of a certain machine at the time of refilling it). A relatively high average buffer value can  signify that the users do not trust that the respective mode of process monitoring conveys the need for interaction in time, leading the users to switching their attention to the process simulation in regular intervals, and performing interactions just in case. A low average buffer can, on the other hand, signify that the users rely on the respective conditions\u2019 ability to signal interaction needs. On the other hand, if  an input buffer had already been completely depleted at the time of intervention, this may signify that the respective condition has failed to inform the users in time. In many cases, participants used double clicks for their interactions, while a single click would have been sufficient, a fact that was perhaps not communicated clearly enough to the participants. Therefore, if several clicks were performed directly one after another, only the first click was taken into account.", "keyphrases": ["compar how mani click the user made in averag for each condit", "buffer", "input buffer", "simul"]}
{"file_name": "S0168365913008766", "text": "Immunopotentiators activate innate immunity directly (for example, cytokines) or through pattern-recognition receptors (PRRs, such as those for bacterial components). The Toll-like receptors (TLRs) are a family of PRRs that are an important link between innate and adaptive immunity. Some studies have shown that TLR ligands have adjuvant activity and enhance antigen-specific antibody and cell-mediated immune responses, especially when they are combined with delivery systems that promote their uptake and delivery into antigen-presenting cells [22\u201324]. For clinical studies, TLR9 is generally stimulated with synthetic oligodeoxynucleotides containing one or more unmethylated CpG dinucleotides. In humans, CpG has been used as an adjuvant for infectious disease vaccination [25,26] and in the development of cancer therapy [27]. In a mouse model, CpG has also been shown to induce T helper 1 (Th1) immune responses, which are characterized by the production of IFN-\u03b3 and the generation of IgG2a [28,29]. Moreover, a previous study had demonstrated that different liposomes with CpG ODN significantly increased Th1-biased cytokines and augmented cell mediated immune response [30].", "keyphrases": ["tlr9", "unmethyl cpg dinucleotid", "e develop of cancer therapi", "toll-lik receptor", "tlr ligand", "th1-bias cytokin", "pattern-recognit receptor", "mous model", "activ innat immun", "adjuv", "immunopotenti", "infecti diseas vaccin", "antigen-pres cell", "synthet oligodeoxynucleotid", "prr", "product of ifn-\u03b3 and the gener of igg2a", "tlr", "augment cell mediat immun respons", "cpg", "clinic studi", "liposom", "stimul", "induc t helper 1"]}
{"file_name": "S000926141500651X", "text": "Previous studies have shown that there are two main mechanisms for the development of radiation-induced DSBs [16,17]. For \u03b3-ray radiation, single step is the main process to cause DSBs (see Figure 3b), which is attributed to the generation of number of ROS upon the incident of individual photon of \u03b3-ray. Whereas photo-radiation causes DSBs through two step mechanism (Figure 3a) by reflecting that each single photon causes mostly single ROS and thus induces only single strand break. Then, when a second single strand break occurs where near the existing single strand break, DBS is caused, i.e., the two step mechanism. Summarizing the results and discussion we may conclude as that: (1) The significant protective effect of AA against photo-induced damage may reflect the effective diminish of ROS by AA. (2) For the \u03b3-ray induced DSB, the protective effect by AA is a little bit weaker than the case of photo irradiation. This may be due to the generation of numbers of ROS by single photon of \u03b3-ray. Surviving oxygen species against the diminishment effect by AA may cause DSBs. (3) As for the DSBs by ultrasound, damage is caused by the shockwave through the generation of cavitations [18]. Thus, the chemical effect of AA to diminish ROS is considered to be negligibly small for the protection of DSBs.", "keyphrases": ["develop of radiation-induc dsb", "shockwav", "singl strand break", "photon", "cavit", "photo", "ro", "\u03b3-ray induc dsb", "gener of number of ro", "dsb", "photo-radi", "two step mechan", "\u03b3-ray radiat", "photo irradi", "db", "strand", "ultrasound", "singl step", "photo-induc damag", "singl photon of \u03b3-ray", "diminish ro", "radiation-induc dsb", "aa", "photon of \u03b3-ray"]}
{"file_name": "S0032386109007423", "text": "In general, the ion exchange capacity (IEC) is closely related to the proton conductivity of PEMs because the acid functionalities, such as sulfonic acid groups, contribute to the proton conduction in a membrane. Beyond a certain sulfonation degree, PEMs tend to absorb too much water or are even soluble in water, which negatively affect their mechanical resistance and water resistance [17,18]. Therefore, the improvement of proton conductivity using aromatic polymers with moderately adjusted IEC values has been under intense investigation [19\u201323]. To achieve high proton conductivity with moderate IEC values, the formation of ion channel structures, which enable effective proton conduction, has been studied. In the course of these studies, an ideal morphology has been pursued by microphase separation of segmented block copolymers in which hydrophilic sulfonated polymer segments form an interconnected three-dimensional network responsible for efficient proton transport, while a complementary network of hydrophobic non-sulfonated segments imparts a reinforcing effect, preventing excessive swelling in water and enhancing the mechanical properties. An image of the ideal morphology for PEMs is shown in Figure\u00a02.", "keyphrases": ["effect proton conduct", "ion exchang capac", "segment block copolym", "prevent excess swell in water", "membran", "high proton conduct", "proton transport", "complementari network of hydrophob non-sulfon segment", "format of ion channel structur", "aromat polym", "proton", "sulfon acid group", "hydrophob non-sulfon segment", "improv of proton conduct use aromat polym with moder adjust iec valu", "water", "iec", "enhanc the mechan properti", "proton conduct", "ion channel structur", "interconnect three-dimension network", "hydrophil sulfon polym segment", "pem"]}
{"file_name": "S0011227515001216", "text": "Prior to assembling the miniature ADR, the mKCC MR heat switch could not be fully thermally characterised due to cryostat constraints. However, based on experiments and research conducted at MSSL on a range of tungsten heat switches, the thermal conductivity has been estimated. In Hills  [8], an equation is derived which allows the thermal conductivity (\u03ba) below 6K to be calculated as a function of magnetic field (B) and temperature (T) (see Eq. To estimate the performance of the mKCC heat switch, the parameters in Eq. (1) have been taken from the measured thermal conductivity of another MSSL heat switch with the same 1.5mm square cross section, a free path length of 43cm and a RRR of 20,000; it has been observed from experiments conducted at MSSL that there is little change in the thermal performance for tungsten heat switches with a RRR between 20,000 and 32,000 (subject of a future publication) and therefore the performance of the 20,000 RRR heat switch has been assumed to be a good approximation. Figure 5 gives the calculated thermal conductivity of the mKCC switch at 0, 1, 2 and 3T based on Eq. (1), where the constants b0, a1, a2, a3, a4 and n have the values 0.0328, 1.19\u00d710\u22124, 3.57\u00d710\u22126, 1.36, 0.000968 and 1.7 respectively. It should be noted that the calculated thermal conductivity of the mKCC switch presented in Figure 5 has been validated by comparing the experimental results of the miniature ADR with modelled predictions (this is discussed in Section 3.3). (1)\u03ba(T)=b0T2+1a1+a2T2T+Bna3T+a4T4", "keyphrases": ["20,000 rrr heat switch", "mssl heat switch", "mkcc mr heat switch", "cryostat constraint", "\u03ba", "b", "magnet field", "thermal conduct", "tungsten heat switch", "mkcc switch", "thermal characteris", "miniatur adr", "mkcc heat switch", "thermal perform", "assembl the miniatur adr"]}
{"file_name": "S0009261408017028", "text": "We use open and close aperture Z-scan experiments, in analogy to the saturation absorption work discussed earlier in water [8], to respectively measure the \u03b2 and n2 for a series of primary alcohols with the help of 1560nm femtosecond laser pulses, however, with the important inclusion of an optical-chopper. The vibrational combination states of the alcohols are coupled by the femtosecond laser pulses at 1560nm. These couplings result in the absorption of 1560nm and the excited molecules undergo relaxation through non-radiative processes, which gives rise to transient thermal effects. These transient thermal effects are related to the pure optical nonlinearity of the samples and can be measured as a change in their n2 values [14]. The transient thermal effects of individual pulses accumulate in case of high repetition-rate lasers to produce a cumulative thermal effect at longer timescales. We measure this cumulative thermal effect with the mode-mismatched two-color pump\u2013probe experiment.", "keyphrases": ["cumul thermal effect", "high repetition-r laser", "femtosecond laser puls at 1560nm", "1560nm femtosecond laser puls", "alcohol", "water", "primari alcohol", "molecul", "apertur z-scan experi", "optical-chopp", "pure optic nonlinear", "absorpt", "measur thi cumul thermal effect", "non-radi process", "transient thermal effect", "satur absorpt", "mode-mismatch two-color pump\u2013prob experi", "vibrat combin state"]}
{"file_name": "S0968432814000250", "text": "Volume EM can be performed using transmission or scanning electron microscopes. Each approach has its own strengths and weaknesses, and the choice is dependant on the required lateral (x, y) and axial (z) resolution, and the size of the structure of interest. Historically, transmission electron microscopy (TEM) was the tool of choice for ultrastructural examination of biomedical specimens at sub-nanometer resolution. However, for many cell biology studies structural resolution is actually limited by the deposition of heavy metals onto membranes during sample preparation. In addition, voxel dimensions may only need to be half that of the smallest expected feature of interest (Briggman and Bock, 2012). Advances in scanning electron microscopy (SEM) technology are now driving a paradigm shift in electron imaging. SEMs with field emission electron sources and high efficiency electron detectors can achieve lateral resolutions in the order of 3nm, allowing visualisation of structures such as synaptic vesicles and membranes (De Winter , 2009; Knott , 2008; Vihinen , 2013; Villinger , 2012), though resolving individual leaflets of membrane bilayers remains a challenge (Vihinen , 2013). The use of low beam energies also limits the interaction volume, enhancing axial resolution (Hennig and Denk, 2007). In this review, volume imaging in both transmission and scanning EMs will be explored, moving from traditional manual techniques, through to the latest systems where aspects of both sample preparation and imaging have been automated.", "keyphrases": ["volum em", "tem", "imag", "visualis of structur", "low beam energi", "synapt vesicl", "membran", "scan electron microscop", "tradit manual techniqu", "interact volum", "transmiss", "transmiss electron microscopi", "scan electron microscopi (sem) technolog", "heavi metal", "high effici electron detector", "membran bilay", "field emiss electron sourc", "latest system", "cell biolog studi", "scan electron microscopi", "electron imag", "resolv individu leaflet of membran bilay", "sem", "deposit of heavi metal", "volum imag", "enhanc axial resolut", "sampl prepar", "ultrastructur examin of biomed specimen", "transmiss and scan em"]}
{"file_name": "S0029549313003439", "text": "An essential part of nuclear reactor analysis is the prediction of the three-dimensional space-time kinetics of neutrons in a relatively large, finite, heterogeneous, three-dimensional reactor core. In a majority of safety analyses the prediction of reactor physics responses is performed using neutron diffusion theory applied to three-dimensional systems, with inputs usually derived from deterministic neutron transport solutions of two-dimensional lattice geometries. There has been increased activity related to uncertainty and sensitivity in reactor physics calculations, and the Organization for Economic Cooperation and Development \u2013 Nuclear Energy Agency (OECD-NEA) has sponsored an ongoing benchmark entitled \u201cUncertainty Analysis in Modelling\u201d (UAM) related to these efforts. The goal of this work is to offer a strategy for computing lattice sensitivities using the DRAGON lattice code and WIMS-D4 multi-group library. Results are presented with comparison to those from TSUNAMI, developed by Oak Ridge National Laboratories.", "keyphrases": ["neutron diffus theori appli to three-dimension system", "determinist neutron transport solut", "tsunami", "uncertainti analysi in model", "reactor physic calcul", "wims-d4 multi-group librari", "two-dimension lattic geometri", "reactor core", "nuclear reactor", "neutron", "predict of reactor physic respons", "predict of the three-dimension space-tim kinet of neutron", "reactor", "uam", "dragon lattic code", "safeti analys", "strategi for comput lattic sensit", "nuclear reactor analysi"]}
{"file_name": "S037026930301801X", "text": "The measurements presented here provide evidence for the existence of di-cluster structures in 10\u201312,14Be. Certainly, if the breakup process samples the overlap between the wavefunctions of the ground state and the excited states, the first-chance cluster breakup cross-sections, shown in Figure\u00a04(a), indicate that the xHe+A\u2212xHe cluster structure does not decrease over the mass range A=10, 12 and 14. Given also that the decay energy threshold increases with mass number, the present data may even indicate a slight increase in clustering. The breakup cross-sections also appear to demonstrate that these nuclei possess a stronger structural overlap with an \u03b1\u2013Xn\u2013\u03b1 configuration, although the reaction mechanics by which this final state is reached may be complex. That is to say that the dominant structural mode of the neutron rich isotopes may be identified with two alpha-particles plus valence neutrons. These comprehensive measurements of the neutron-removal and cluster breakup for the first time provide experimental data whereby the structure of the most neutron-rich Be isotopes can be modeled via their reactions.", "keyphrases": ["alpha-particl", "reaction mechan", "first-chanc cluster breakup cross-sect", "neutron rich isotop", "xhe+a\u2212xh cluster structur", "nuclei", "neutron-remov", "domin structur mode", "di-clust structur", "comprehens measur of the neutron-remov and cluster breakup", "neutron-rich be isotop", "cluster breakup", "valenc neutron", "decay energi", "breakup cross-sect", "wavefunct of the ground state and the excit state", "breakup process"]}
{"file_name": "S092702561300267X", "text": "In previous publications the present authors proposed a method to incorporate the thermodynamics of ternary alloys and liquid diffusion-governed solidification kinetics into a multiphase volume average solidification model [23,24]. Back diffusion was disregarded. A way to access the thermodynamic data ( Thermo-Calc [1]) through a tabulation and interpolation program ISAT (In Situ Adaptive Tabulation) was suggested. With the ISAT approach it is possible to perform an online call of the thermodynamic data and trace the formation of each individual solid phase (primary, peritectic, eutectic, etc.). As the number of calls of the thermodynamic data is equal to the product of the number of the discretized volume elements, the time steps and the calculation iterations per time step, the calculation becomes exhausting. Therefore, the current model is a modification of the previous model using a linearized phase diagram, and no online call of thermodynamic data is necessary. In addition, the model presented in this paper is extended to consider the back diffusion into the solid. With these modifications, the model can be used to perform casting process simulations with incorporated full diffusion-governed solidification kinetics for ternary alloys at a reasonable computation cost.", "keyphrases": ["incorpor the thermodynam of ternari alloy and liquid diffusion-govern solidif kinet into a multiphas volum averag solidif model", "onlin call of thermodynam data", "tabul and interpol program", "ternari alloy", "current model", "back diffus", "modif", "perform cast process simul with incorpor full diffusion-govern solidif kinet", "full diffusion-govern solidif kinet", "multiphas volum averag solidif model", "modif of the previou model use a linear phase diagram", "isat", "thermodynam data", "discret volum element", "in situ adapt tabul", "isat approach", "solid", "cast process simul", "extend to consid the back diffus into the solid", "liquid diffusion-govern solidif kinet"]}
{"file_name": "S0168874X1630049X", "text": "The crack band approach for producing mesh independent load\u2013displacement curves for fracture in plain concrete is based on the idea that the crack opening is transformed into inelastic strain by distributing it over an element length dependent zone [5]. This approach will only produce mesh independent load\u2013displacement curves, if the inelastic strain profiles in the finite element analysis are mesh size dependent. This requirement is an important difference to the nonlocal model which is designed to produce both mesh size independent load\u2013displacement curves and strain profiles. In CDPM2, the crack band approach is applied only to the tensile part of the damage algorithm by replacing the stress\u2013inelastic strain law shown in Figure 2(b) by a stress\u2013inelastic displacement law of the form(13)\u03c3=ftexp(\u2212\u03f5inhwft)if(\u03f5in>0)Here, wft is a crack opening threshold used to control the slope of the softening curve and h is the width of the crack-band, which in the present study is equal to the maximum dimension of the element along the principal direction of the strain tensor corresponding to the maximum tensile principal strain at the onset of damage. For the compressive part, a stress\u2013inelastic strain law was used to determine the compressive damage parameter, since it was reported in [14] for columns subjected to eccentric compression that inelastic strain profiles in compression do not exhibit a mesh dependence which would satisfy the assumptions of the crack-band approach. This approach of applying the crack-band approach only to the tensile part has already been successfully used in\u00a0Grassl  [16].", "keyphrases": ["crack-band approach", "(13)\u03c3=ftexp(\u2212\u03f5inhwft)if(\u03f5in>0)", "inelast strain profil", "tensil part", "stress\u2013inelast strain law", "crack band approach", "stress\u2013inelast displac law"]}
{"file_name": "S0021999115003423", "text": "The remainder of our discussion proceeds as follows. In Section 2 we briefly describe the problem of cell tracking and introduce our approach to cell tracking, which may be regarded as fitting a mathematical model to experimental image data sets. We present the geometric evolution law model we seek to fit, which is a simplification of recently developed models in the literature that show good agreement with experiments [8,10\u201312,4,13,9]. We finish Section 2 by reformulating our model into the phase field framework, which appears more suitable for the problem in hand, and we formulate the cell tracking problem as a PDE constrained optimisation problem. In Section 3 we propose an algorithm for the resolution of the PDE constrained optimisation problem and we discuss some practical aspects related to the implementation. In particular we note that the theoretical and computational framework may be applied directly to multi-cell image data sets and raw image data sets (of sufficient quality) without segmentation. In Section 4 we present some numerical examples for the case of 2d single and multi-cell image data sets. Finally in Section 5 we present some conclusions of our study and discuss future extensions and applications of the work.", "keyphrases": ["geometr evolut law model", "our model", "cell track problem", "introduc our approach to cell track", "theoret and comput framework", "algorithm", "experiment imag data set", "multi-cel imag data set", "phase field framework", "pde constrain optimis problem", "imag data set", "raw imag data set", "problem of cell track", "segment", "mathemat model"]}
{"file_name": "S1364815216302122", "text": "When we formulate the downscaling problem as a multi-objective optimization problem, we face, however, the following problems. Minimizing the sum of different objectives is problematic, since they may have different units and ranges. Even with an appropriate scaling procedure there is a risk of treating the objectives unequally or getting trapped in a local minimum. Firstly, we can never know, what is the minimum value of each objective that can be achieved by the regression. Thus, designing an appropriate scaling procedure is difficult and one would need to decide on the relative importance of the different objectives in advance. Secondly, adding multiple, conflicting objectives very likely results in a fitness function with multiple local minima, which makes optimization more difficult. To avoid these problems, we have implemented fitness calculation according to the Strength Pareto Evolutionary Algorithm (SPEA) by Zitzler and Thiele (1999), instead of using a single (weighted) fitness or cost function. Approaches for multi-objective optimization like SPEA are widely used in evolutionary computation. In SPEA the fitness calculation during the fitting procedure is based on an intercomparison of the different models. Further, a finite set of so called Pareto optimal models (downscaling rules) is returned.", "keyphrases": ["evolutionari comput", "fit calcul", "multi-object optim", "optim", "downscal rule", "pareto optim model", "use a singl (weighted) fit or cost function", "strength pareto evolutionari algorithm", "spea", "scale procedur", "regress"]}
{"file_name": "S0963869514001078", "text": "It is known that as the temperature of the sample rises, the Lorentz mechanism remains dominant until Tc of steel is reached (770\u00b0C for a low carbon steel), when the magnetostrictive mechanism becomes more efficient [15]. Previously this has been thought due to a thin ferromagnetic oxide layer on the sample surface, the surface being cooler than the bulk of the material [16,17]. This layer concentrates the magnetic field, increasing generation efficiency. Recent studies also show that rearrangement of the magnetic moments from ordered domains to a disordered state at a magnetic phase transition lowers the magnetostrictive constant. This ferromagnetic to paramagnetic transition is accompanied by large changes in the efficiency of electromagnetic ultrasound generation leading to the use of EMATs as a method of studying phase transitions in magnetic alloys [18].", "keyphrases": ["magnetostrict mechan", "lorentz mechan", "electromagnet ultrasound gener", "magnet alloy", "magnet field", "steel", "studi phase transit", "ferromagnet oxid", "low carbon steel", "magnet phase transit", "ferromagnet to paramagnet transit", "emat", "gener effici"]}
{"file_name": "S2212667812000949", "text": "By referring to many relevant data and essays, this paper aims at discussing and analyzing the importance of hip-push applied in walking race,based on the point of the view on sports biomechanics .With redard to the existing problems,the authors have made an objective analysis on the sports-biomechanics factors that can influence the race,hoping to provide a theoretical basis for the deep development and training of walking race.", "keyphrases": ["deep develop and train of walk race", "object analysi on the sports-biomechan factor", "theoret basi", "hip-push", "data and essay", "sport biomechan", "discuss and analyz the import of hip-push appli in walk race"]}
{"file_name": "S1010603013001809", "text": "The other methods for enhancement of photocatalytic activity are grafting co-catalysts. There are two kinds of co-catalysts in terms of its function: one is for separation of electrons and the other is for separation of holes. The former representative co-catalysts are Pt, Fe3+, and Cu2+ [9\u201312]. It was reported that Fe3+ and Cu2+ were grafted as amorphous oxide cluster [9,10], and reduced into Fe2+ and Cu+ by receiving one electron, respectively [11,12]. The reduced metal oxide cluster with reduced ions could return into the original state by giving more than one electron to molecular oxygen. The latter ones are CoOx, CoPi (CoPOx), IrOx, and RuOx which are used for water oxidation, among which CoPi is reported to be the most effective co-catalyst for water oxidation [13]. However, there were few reports concerning co-grafting effects on photocatalytic activity especially in gaseous phase. We expected that by co-grafting of both co-catalysts for separations of electrons and holes, photocatalytic activity in gaseous phase would be further enhanced. Moreover, complex of BiVO4 with the other materials of p-type semiconductor is also effective for enhancing photocatalytic activity.", "keyphrases": ["enhanc of photocatalyt activ", "copox", "electron", "fe3+", "water oxid", "photocatalyt activ", "reduc ion", "co-catalyst", "separ of electron", "hole", "ruox", "p-type semiconductor", "coox", "co-graft", "copi", "irox", "amorph oxid cluster", "cu+", "reduc metal oxid cluster", "separ of hole", "pt", "gaseou phase", "fe2+", "bivo4", "cu2+", "oxygen"]}
{"file_name": "S0375960113004568", "text": "The length effect is always important in nanodevices. So we investigate the length dependence of electronic transport properties in M3 by increasing the number of carbon unit cells in the scattering region. Here we present the transport results when the numbers of carbon unit cells in the scattering region are 10 and 12, which are called M4 and M5, respectively. The current\u2013voltage characteristics shown in Figure 8. We can see that the large rectifying ratio still can be observed irrespective of the length of heterojunctions. This is due to the fact that the electronic transport properties for M3 are mainly determined by the parity of the \u03c0 and \u03c0\u204e subbands of left and right electrodes. Thees results indicate that the lengths of the two parts in the scattering regions have no affects on the qualitative charge transport in M3.", "keyphrases": ["length depend of electron transport properti", "length effect", "current\u2013voltag characterist", "nanodevic", "qualit charg transport", "increas the number of carbon unit cell", "electron transport properti", "larg rectifi ratio", "\u03c0 and \u03c0\u204e subband", "carbon unit cell"]}
{"file_name": "S0301679X13003289", "text": "Nanoparticle Tracking Analysis (NTA) has been applied to characterising soot agglomerates of particles and compared with Transmission Electron Microscoscopy (TEM). Soot nanoparticles were extracted from used oil drawn from the sump of a light duty automotive diesel engine. The samples were prepared for analysis by diluting with heptane. Individual tracking of soot agglomerates allows for size distribution analysis. The size of soot was compared with length measurements of projected two-dimensional TEM images of agglomerates. Both the techniques show that soot-in-oil exists as agglomerates with average size of 120nm. NTA is able to measure particles in polydisperse solutions and reports the size and volume distribution of soot-in-oil aggregates; it has the advantages of being fast and relatively low cost if compared with TEM.Nanoparticle Tracking Analysis (NTA) has been applied to characterising soot agglomerates of particles and compared with Transmission Electron Microscoscopy (TEM). Soot nanoparticles were extracted from used oil drawn from the sump of a light duty automotive diesel engine. The samples were prepared for analysis by diluting with heptane. Individual tracking of soot agglomerates allows for size distribution analysis. The size of soot was compared with length measurements of projected two-dimensional TEM images of agglomerates. Both the techniques show that soot-in-oil exists as agglomerates with average size of 120nm. NTA is able to measure particles in polydisperse solutions and reports the size and volume distribution of soot-in-oil aggregates; it has the advantages of being fast and relatively low cost if compared with TEM.", "keyphrases": ["nta", "nanoparticl track analysi", "tem", "heptan", "agglomer", "soot agglomer", "size distribut analysi", "soot nanoparticl", "polydispers solut", "soot-in-oil aggreg", "transmiss electron microscoscopi"]}
{"file_name": "S0032386109007290", "text": "ELRs are particularly attractive for the synthesis of block copolymers that self-assemble into polymer nanostructures such as\u00a0micelles. The first work in this area involved an elastin-mimetic di-block copolymer containing VPGEG\u2013(IPGAG)4 and VPGFG\u2013(IPGVG)4 as the hydrophilic and hydrophobic blocks, respectively [49]. The resulting micelles were studied by dynamic light scattering (DLS) and DSC was used to measure the enthalpy of self-assembly. A tri-block copolymer was subsequently synthesized and the TEM images of this polymer showed that it formed spherical aggregates [50]. Other multivalent spherical micelles have been obtained from linear elastin-like AB di-block copolymers in the temperature range 37\u201342\u00b0C with the aim of targeting cancer cells [51]. Bidwell et\u00a0al have also exploited the ELRs for its ability to serve as macromolecular carriers for thermally targeted delivery of drugs. Attachment of doxorubicin to ELR-based system showed enhanced cytotoxicity in uterine sarcoma cells when aggregation was induced with hyperthermia [52].", "keyphrases": ["micel", "tri-block copolym", "linear elastin-lik ab di-block copolym", "doxorubicin", "tem imag", "macromolecular carrier", "cytotox", "self-assembl", "elastin-mimet di-block copolym", "target cancer cell", "vpgeg\u2013(ipgag)4", "uterin sarcoma cell", "multival spheric micel", "synthesi of block copolym", "vpgfg\u2013(ipgvg)4", "thermal target deliveri of drug", "hyperthermia", "elr", "aggreg", "elr-bas system", "dynam light scatter", "dl", "dsc", "polym", "polym nanostructur", "spheric aggreg", "hydrophil and hydrophob block", "block copolym"]}
{"file_name": "S0963869514000875", "text": "There are a number of avenues to explore for future work, in particular the use of other time\u2013frequency analysis methods. The STFT spectrogram was utilised here, as it is the simplest to implement. Whilst all of the echoes could be clearly resolved in both time and frequency, the spectrogram suffers from a fixed resolution, i.e an increase of time resolution necessarily leads to a decrease in frequency resolution. Other methods of time\u2013frequency analysis, such as discrete wavelet analysis, benefit from advantage of multi-resolution analysis, which offers improved temporal resolution of the high frequency components, and frequency resolution of the low frequency components [25,18,19]. Also, whilst the current work has utilised SH waves that are generated by EMATs, the physics that describes the pulsed array system is universal to other types of waves. Future work will include demonstrating this phenomenon with a number of other systems, for example using longitudinal ultrasonic waves or electromagnetic waves.", "keyphrases": ["longitudin ultrason wave", "multi-resolut analysi", "tempor resolut", "puls array system", "frequenc resolut", "low frequenc compon", "time resolut", "demonstr thi phenomenon with a number of other system", "use of other time\u2013frequ analysi method", "fix resolut", "stft spectrogram", "spectrogram", "discret wavelet analysi", "time\u2013frequ analysi", "electromagnet wave", "emat", "sh wave"]}
{"file_name": "S0165212515000931", "text": "We describe three ways to solve the reflection problem. The first way is very simple (Section\u00a0 4). We exploit the consequences of shifting the semi-infinite row by one period (to the right or left). In effect, we regard the semi-infinite row as two scatterers, one of which is another semi-infinite row. This idea goes back to a series of papers by Millar in the 1960s, starting with\u00a0 [2]. He used it for several two-dimensional grating problems. A similar approach was used for layered media by Shenderov\u00a0 [3]. In our one-dimensional context, we obtain a quadratic equation for R; we show how to select the correct solution. We remark that there has been much recent interest in related two-dimensional waveguide problems; see, for example,\u00a0 [4\u20136], where the shifting-by-one-period idea is again employed, leading to a quadratic equation for a certain operator.", "keyphrases": ["two-dimension grate problem", "layer media", "semi-infinit row", "quadrat equat", "shift the semi-infinit row", "shifting-by-one-period idea", "waveguid problem", "two scatter", "two-dimension waveguid problem", "reflect problem", "obtain a quadrat equat"]}
{"file_name": "S096386951400070X", "text": "This paper has highlighted a band of frequencies, outside the conventional operation range, and close to electrical resonance of an eddy current probe, where the magnitude of impedance SNR reaches a peak. The SNR of scans of three slots of varying depth were enhanced by a factor of up to 3.7, from the SNR measured at 1MHz. This is a result of a defect-decoupling resonance-shift effect and is referred to as the near electrical resonance signal enhancement (NERSE) phenomenon. NERSE frequency operation has significant potential for ECT inspection, and opens up a range of investigative possibilities. Within this investigation, only the magnitude of the electrical impedance has been analyzed. An immediate extension of this investigation will be to consider phase information, and determine whether a similar exploitable NERSE effect exists.", "keyphrases": ["electr imped", "snr", "highlight a band of frequenc", "near electr reson signal enhanc", "electr reson of an eddi current probe", "imped snr", "ners", "ect inspect", "defect-decoupl resonance-shift effect", "eddi current probe"]}
{"file_name": "S0021961413004321", "text": "The thermodynamics of copper-zinc alloys (brass) was subject of numerous investigations. Brass is characterised by an excess enthalpy and excess entropy of mixing, both of which are negative. The enthalpic data were measured by solution calorimetry , [1\u20133] and based on chemical potential data calculated from phase equilibrium experiments , [4\u20136], the excess entropy of mixing could be evaluated , [7\u20139]. This excess entropy contains both, the vibrational and the configurational parts. The excess vibrational entropy, defined as the deviation from the entropy of a mechanical mixture of the end members A and B (i.e., Smmechmix=XASmA+XBSmB), can be determined by measuring the low temperature heat capacity (5 to 300K) versus composition behaviour. The determination of the excess configurational entropy, i.e., the excess entropy coming from non-random atomic distributions and defects, is much more difficult. Here, neutron scattering investigations together with computer simulations are normally used. If, however, reliable data of the total excess entropy (from enthalpic and chemical potential data) are available, the measurement of the excess vibrational entropy enables the determination of the excess configurational entropy simply by subtraction. Since configurational and vibrational entropies may have different temperature dependencies, it is worthwhile to separate the entropic effects. This is one aim of this study. Another aim is to deliver experimental data so that first principles studies can test their models on a disordered alloy, whose structural details (short-range order) depend on temperature.", "keyphrases": ["subtract", "brass", "copper-zinc alloy", "smmechmix=xasma+xbsmb", "deliv experiment data", "determin of the excess configur entropi", "vibrat and the configur part", "reliabl data of the total excess entropi", "separ the entrop effect", "excess entropi of mix", "disord alloy", "comput simul", "enthalp data", "excess enthalpi and excess entropi of mix", "measur of the excess vibrat entropi", "excess configur entropi", "neutron scatter investig", "experiment data", "solut calorimetri", "thermodynam of copper-zinc alloy (brass)", "phase equilibrium experi", "enthalp and chemic potenti data", "chemic potenti data", "measur the low temperatur heat capac (5 to 300k) versu composit behaviour"]}
{"file_name": "S0167931711005120", "text": "A nanocomposite system consisting of a semiconducting matrix and embedded ferromagnetic nanostructures has been fabricated. The ferromagnetic characteristics as coercivity, remanence and magnetic anisotropy of the nanocomposite can be adjusted by the electrochemical parameters. Furthermore the spatial distribution of the metal structures within the pores can be varied which means that the magnetic interactions between the particles can be influenced. In the case of densely packed particles within the pores dipolar coupling between them occurs and results in quasi magnetic chains which offer a much larger magnetic anisotropy than non-interacting particles. By modifying the current density small Ni-particles (3\u20136nm) can be deposited. If the packing density of these particles is sufficiently close, Ni-tubes of a few nanometer in thickness are covering the pore walls. The presented nanocomposite is an interesting system for magnetic applications as magnetic sensor technology. Silicon as substrate renders this composite a good candidate for the integration in existing process technology.", "keyphrases": ["a semiconduct matrix and embed ferromagnet nanostructur", "small ni-particl (3\u20136nm)", "modifi the current densiti", "dens pack particl", "the electrochem paramet", "the ferromagnet characterist", "coercivity, reman and magnet anisotropi of the nanocomposit", "these particl", "the present nanocomposit", "a nanocomposit system", "distribut", "non-interact particl", "silicon", "ni-tub", "a much larger magnet anisotropi", "a good candid for the integr"]}
{"file_name": "S0305440314001927", "text": "Traditionally, archaeologists have recorded sites and artefacts via a combination of ordinary still photographs, 2D line drawings and occasional cross-sections. Given these constraints, the attractions of 3D models have been obvious for some time, with digital photogrammetry and laser scanners offering two well-known methods for data capture at close range ( Bates et\u00a0al., 2010; Hess and Robson, 2010). The highest specification laser scanners still boast better positional accuracy and greater true colour fidelity than SfM\u2013MVS methods (James and Robson, 2012), but the latter produce very good quality models nonetheless and have many unique selling points. Unlike traditional digital photogrammetry, little or no prior control of camera position is necessary, and unlike laser scanning, no major equipment costs or setup are involved. However, the key attraction of SfM\u2013MVS is that the required input can be taken by anyone with a digital camera and modest prior training about the required number and overlap of photographs. A whole series of traditional bottlenecks are thereby removed from the recording process and large numbers of archaeological landscapes, sites or artefacts can now be captured rapidly, in the field, in the laboratory or in the museum. Figure\u00a02a\u2013c shows examples of terracotta warrior models for which the level of surface detail is considerable.", "keyphrases": ["sfm\u2013mv method", "3d model", "record site and artefact", "digit photogrammetri", "archaeolog landscap", "terracotta warrior model", "data captur at close rang", "sfm\u2013mv", "tradit digit photogrammetri", "2d line draw", "laser scan", "control of camera posit", "artefact", "ordinari still photograph", "digit camera", "laser scanner", "record process", "occasion cross-sect", "prior train about the requir number and overlap of photograph", "site"]}
{"file_name": "S0927025612000249", "text": "The need for power generation industry to improve the thermal efficiency of power plant has led to the development of 9\u201312% Cr martensitic steels. The development of and research on P91 steels started since late 1970s and early 1990s, respectively [1]. The work has focussed on their creep strengths due to its intended application at high temperature. Recently, the introduction of more cyclic operation of power plant has introduced the possibility of fatigue problems. Bore cracking due to the effects of varying steam warming has been reported [2]. The temperature cycling causes thermal gradients between the inside and outside of components and this can cause cyclic stress levels to be of concerns. Recently, research on thermal\u2013mechanical analysis of P91 has been carried out including the characterisation of the cyclic behaviour of the material using the two-layer and unified visco-plasticity models [3,4].", "keyphrases": ["fatigu problem", "p91 steel", "temperatur cycl", "9\u201312% cr martensit steel", "two-lay and unifi visco-plast model", "power gener", "thermal\u2013mechan analysi of p91", "power plant", "p91", "steam warm", "develop of and research on p91 steel", "the materi", "characteris of the cyclic behaviour of the materi", "improv the thermal effici of power plant"]}
{"file_name": "S0003491613001516", "text": "Complex Langevin (CL) dynamics\u00a0 [1,2] provides an approach to circumvent the sign problem in numerical simulations of lattice field theories with a complex Boltzmann weight, since it does not rely on importance sampling. In recent years a number of stimulating results has been obtained in the context of nonzero chemical potential, in both lower and four-dimensional field theories with a severe sign problem in the thermodynamic limit\u00a0 [3\u20138] (for two recent reviews, see \u00a0Refs. However, as has been known since shortly after its inception, correct results are not guaranteed\u00a0 [11\u201316]. This calls for an improved understanding, relying on the combination of analytical and numerical insight. In the recent past, the important role played by the properties of the real and positive probability distribution in the complexified configuration space, which is effectively sampled during the Langevin process, has been clarified\u00a0 [17,18]. An important conclusion was that this distribution should be sufficiently localised in order for CL to yield valid results. Importantly, this insight has recently also led to promising results in nonabelian gauge theories, with the implementation of SL(N,C) gauge cooling\u00a0 [8,10].", "keyphrases": ["nonabelian gaug theori", "complex langevin", "lower and four-dimension field theori", "probabl distribut", "sign problem in the thermodynam limit", "sign problem", "complexifi configur space", "cl", "improv understanding, reli on the combin of analyt and numer insight", "langevin process", "numer simul of lattic field theori", "sl(n,c) gaug cool", "distribut", "nonzero chemic potenti"]}
{"file_name": "S2212667814000951", "text": "Design semantics is an integration of human mode of existence and view on culture and art, which means it is a unity of art and science. Design semantics is the annotation of form and the reflection of its symbolic meaning, which means it is an explanation of the deposited human cultural spirit. Chinese art stresses Expression, Force and Qi. In China, people advocate \u201cto learn from nature\u201d, \u201cto look up to observe the sun, the moon and stars, and look down to observe the surroundings\u201d, and take \u201cNature and Man in One\u201d as the highest state of spirit. Design semantics is expressed in space environment design through a symbiotic philosophical view that natural and artificial forms are complementary and interactive. This form of design leads humans back to a better state of living, i.e. Nature and Man in One.", "keyphrases": ["design semant", "annot of form and the reflect of it symbol mean", "explan of the deposit human cultur spirit", "integr of human mode of exist and view on cultur and art", "to learn from natur", "natur and artifici form", "uniti of art and scienc", "space environ design", "observ the surround"]}
{"file_name": "S0167931713002487", "text": "Ge (100) wafers (n- and p-type) were cleaned in ultra high vacuum (<10\u22126mbar) at 500\u00b0C and 600\u00b0C for 10min to evaporate any native oxide and so achieve an oxide free surface. Subsequently, wafers were exposed to an Al flux for a range of times to deposit ultrathin Al layers. The samples were then oxidized at ambient temperatures in the MBE load lock to produce Al2O3 layers. The samples were transferred within 1min to an Oxford Instruments OpAL reactor and thin films of HfO2 were deposited on the Al2O3 using atomic layer deposition (ALD). The HfO2 depositions used a [(CpMe)2HfOMeMe] precursor coupled with an O2 plasma as the oxidizing species. Between 30 and 130 ALD cycles were used to grow HfO2 thicknesses from 1.6 to 7nm at 250\u00b0C. For electrical measurements, circular gold contacts of area 1.96\u00d710\u22123cm2 were deposited onto the films to form MOS gate electrodes and Al was deposited on the back of the Ge wafers to provide an ohmic contact. After preliminary measurements, the samples were annealed in forming gas (FGA) at 350\u00b0C for 30min. The oxide leakage current was measured using a Keithley 230B voltage source and Keithley 617B electrometer. The HP 4192A low frequency (LF) impedance analyzer at small signal frequencies between 100Hz to 1MHz was used to perform high frequency capacitance\u2013voltage (HF CV) measurements.", "keyphrases": ["clean in ultra high vacuum", "electr measur", "oxid leakag current", "evapor ani nativ oxid", "oxid", "al", "thin film of hfo2", "keithley 230b voltag sourc", "measur", "ge wafer", "ultra high vacuum", "fga", "anneal in form ga", "o2 plasma", "hp 4192a low frequenc (lf) imped analyz", "mo gate electrod", "n- and p-type", "ohmic contact", "mbe load lock", "grow hfo2 thick", "to perform high frequenc capacitance\u2013voltag (hf cv) measur", "oxford instrument opal reactor", "oxid free surfac", "high frequenc capacitance\u2013voltag (hf cv) measur", "sampl", "produc al2o3 layer", "oxid speci", "keithley 617b electromet", "wafer", "al flux", "film", "hfo2", "[(cpme)2hfomeme] precursor", "circular gold contact", "hfo2 deposit", "al2o3 layer", "ge (100) wafer", "ald", "nativ oxid", "form ga", "ultrathin al layer", "al2o3", "atom layer deposit"]}
{"file_name": "S0168365913002848", "text": "Mice bearing the orthotopic model were treated starting from day 21 after NB cell implant; mice with the pseudo-metastatic model received the first treatment 4h after NB cell injection. These therapeutic schedules were designed to test the effects of our targeted formulations against both established and pseudo-metastatic preclinical models of human NB, as described [16,19]. Animals were treated i.v once a week for 3 weeks with untargeted (SL[DXR]) or peptide-targeted SL[DXR] (5mg/kg). Scrambled peptide-functionalized liposomes were used as a control, and in every experiment a group of control mice received HEPES-buffered saline. Survival times were used as the main criterion for determining treatment efficacy. In the orthotopic model, time-dependent anti-tumor activity was also evaluated by bioluminescence imaging (BLI) and X-ray analyses. For this purpose, the GI-LI-N cell line was infected with a retrovirus expressing the firefly luciferase gene, as previously reported [17]; luciferase activity of retrovirally-transduced cells was visualized in vivo by BLI (IVIS Caliper Life Sciences, Hopkinton, MA) after a 10min incubation with 150\u03bcg/mL of d-luciferin (Caliper Life Sciences), as described [17]. X-ray analysis was superimposed to the luminescence for a better visualization of the tumors.", "keyphrases": ["these therapeut schedul", "preclin model", "visual", "untarget", "mice bear the orthotop model", "test the effect", "luciferas activ", "anim", "hepes-buff salin", "scrambl peptide-function liposom", "surviv time", "determin treatment efficaci", "infect", "sl[dxr]", "mice with the pseudo-metastat model", "the gi-li-n cell line", "retrovirally-transduc cell", "peptide-target sl[dxr]", "our target formul", "d-luciferin", "orthotop model", "time-depend anti-tumor activ"]}
{"file_name": "S0142061516308079", "text": "The above discussion summarizes the state of the art related to impacts and interpretations of communication latency between RT simulators. However, research is focused primarily on the effect of the data loss during the communication and how to mitigate it [34]. In the thermo-electric co-simulation example in [35], the time constant is larger in the thermal simulation than that of power system simulation. Thus the communication latency will not significantly affect the accuracy of co-simulation. In [36], the co-simulation is performed using resources at the same location without synthetically introduced delays, which means the communication latency between RT simulators is ignored. In [37], the authors have mentioned the communication latency as an important factor in the distributed simulation and that its effect on simulation stability will be studied as future work. An in-depth research about the role of communication latency and mitigation measure for geographically distributed RT simulations is identified as a technical gap and addressed in this paper.", "keyphrases": ["distribut simul", "co-simul", "rt simul", "thermo-electr co-simul", "role of commun latenc", "commun latenc"]}
{"file_name": "S2212667814000987", "text": "In this paper we consider problems of creating and introducing intelligent management systems as one of the most important mechanism of increasing energy efficiency in industry. Operating principles of intelligent electric power distribution systems developed in MSTU \u00abSTANKIN\u00bb for AC and DC grids on industrial plants are described. Essential devices composing the systems are considered, their technical characteristics are described. Experimental results are presented.In this paper we consider problems of creating and introducing intelligent management systems as one of the most important mechanism of increasing energy efficiency in industry. Operating principles of intelligent electric power distribution systems developed in MSTU \u00abSTANKIN\u00bb for AC and DC grids on industrial plants are described. Essential devices composing the systems are considered, their technical characteristics are described. Experimental results are presented.", "keyphrases": ["devic compos the system", "mstu \u00abstankin\u00bb", "intellig manag system", "devic compos the system are consid", "intellig electr power distribut system", "problem of creat and introduc intellig manag system", "technic characterist are describ", "ac and dc grid", "creat and introduc intellig manag system", "increas energi effici", "ntellig manag system"]}
{"file_name": "S0301010415002189", "text": "The sodium trimer has a long history of theoretical and experimental studies. A pioneering theoretical paper of Martin and Davidson published in 1978 showed that the obtuse isosceles geometry is lower in energy than the linear conformation [6]. Several extended PES scans of Na3 and other alkali trimers followed this initial study, employing DFT [7], complete active space SCF [8], or a configuration interaction approach based on valence bond wave functions [9]. Recently, the applicability of density functional theory (DFT) to JT-distorted systems has also been tested for Na3 [10], and the B-X transition has been revisited as well, applying state-averaged multi-reference configuration interaction with a large active space in order to derive more accurate non-adiabatic coupling terms for an improved interpretation of photoabsorption spectra [11\u201313].", "keyphrases": ["sodium trimer", "obtus isoscel geometri", "valenc bond wave function", "b-x transit", "configur interact approach", "densiti function theori", "linear conform", "photoabsorpt spectra", "pe scan", "deriv more accur non-adiabat coupl term", "dft", "na3", "complet activ space scf", "state-averag multi-refer configur interact", "jt-distort system", "alkali trimer"]}
{"file_name": "S0301010415300355", "text": "Alternatively to H-atom photodetachment from the intermediate radicals, the latter may serve as reducing agents. Evidence has been reported in recent years that the pyridinyl radical (PyH) is an exceptionally strong reducing agent which can even reduce CO2 to formaldehyde, formic acid or methanol with suitable catalyzers [27\u201329], albeit the mechanisms of these reactions are currently poorly understood [30\u201332]. The theoretically predicted dissociation thresholds of the AcH, AOH and BAH radicals are about 2.7eV, 2.5eV and 3.0eV, respectively (see Figure 4), while the predicted dissociation threshold of the pyridinyl radical is much lower, about 1.7eV [1]. Pyridinyl is thus a significantly stronger reductant than acridinyl and related radicals. It is therefore not expected that the latter will be able to reduce carbon dioxide in dark reactions.", "keyphrases": ["pyridinyl", "intermedi radic", "acridinyl", "formic acid", "pyridinyl radic", "radic", "reduct", "catalyz", "methanol", "co2", "ach, aoh and bah radic", "formaldehyd", "pyh", "reduc carbon dioxid in dark reaction", "carbon dioxid", "h-atom photodetach", "reduc agent"]}
{"file_name": "S0370269303015478", "text": "Since perturbative expansion is used, it is impossible to find the exact bounds; instead, one can derive tree-level unitarity bounds or loop-improved unitarity bounds. In this study, we will use unitarity bounds coming from a tree-level analysis\u00a0[20]. This tree level analysis is derived with the help of the equivalence theorem [21], which itself is a high-energy approximation where it is assumed that the energy scale is much larger than the Z0 and W\u00b1 gauge-boson masses. We will consider here this \u201chigh-energy\u201d hypothesis that both the equivalence theorem and the decoupling regime are well settled, but in such a way that the unitarity constraint is also fulfilled. Our purpose is to investigate the quantum effects in the decays of the light CP-even Higgs boson h0, especially looking for sizeable differences with respect to the SM in the decoupling regime.", "keyphrases": ["high-energi approxim", "unitar bound", "unitar constraint", "equival theorem", "investig the quantum effect in the decay of the light cp-even higg boson h0", "perturb expans", "higg boson", "loop-improv unitar bound", "decoupl regim", "exact bound", "gauge-boson mass", "tree level analysi", "tree-level unitar bound", "tree-level analysi", "quantum effect", "look for sizeabl differ with respect to the sm in the decoupl regim", "decay of the light cp-even higg boson h0", "h0", "sm"]}
{"file_name": "S0032386109005485", "text": "Inverse miniemulsion polymerization is a water-in-oil (W/O) heterogeneous polymerization process that forms kinetically stable macroemulsions at, below, or around the critical micellar concentration (CMC). This process contains aqueous droplets (including water-soluble monomers) stably dispersed, with the aid of oil-soluble surfactants, in a continuous organic medium. Stable inverse miniemulsions are formed under high shear by either a homogenizer or a high speed mechanical stirrer. Oil-soluble nonionic surfactants with hydrophilic-lipophilic balance (HLB) value around 4 are used to implement colloidal stability of the resulting inverse emulsion. Upon addition of radical initiators, polymerization occurs within the aqueous droplets producing colloidal particles (Figure\u00a02) [83]. Several reports have demonstrated the preparation of stable particles of hydrophilic and water-soluble polymers [86\u201389], polyaniline nanoparticles [90], and organic\u2013inorganic hybrid particles [91\u201393]. This method also allows for the preparation of crosslinked microgels in the presence of difunctional crosslinkers [27,94\u2013100]. In addition, CRP techniques including ATRP [78,79,82,101,102] and RAFT [103] in inverse miniemulsion have been explored to prepare well-defined nanoparticles and nanogels.", "keyphrases": ["water-solubl monom", "oil-solubl nonion surfact", "cmc", "organic\u2013inorgan hybrid particl", "raft", "atrp", "invers miniemuls polymer", "polymer", "difunct crosslink", "crp techniqu", "high speed mechan stirrer", "homogen", "aqueou droplet", "invers emuls", "w/o", "heterogen polymer process", "implement colloid stabil of the result invers emuls", "water-in-oil", "organ medium", "polyanilin nanoparticl", "crosslink microgel", "kinet stabl macroemuls", "nanogel", "prepar of crosslink microgel in the presenc of difunct crosslink", "colloid particl", "invers miniemuls", "critic micellar concentr", "stabl invers miniemuls", "stabl particl of hydrophil and water-solubl polym", "nanoparticl", "oil-solubl surfact", "radic initi"]}
{"file_name": "S221450951400014X", "text": "This figure demonstrates that changes in the measure of bitumen content create sizable differences in the stiffness modulus of asphaltic samples that include waste glass cullet. As the percentage of glass increases, the measure of the stiffness modulus of modified asphalt increases too. But with pass of optimum measure of glass the stiffness modulus of asphaltic samples decrease. This trend in total of percentages of bitumen content is existing. Due to that waste glass cullet has no suction; the trend does not extend to measuring the stiffness modulus of asphaltic samples including waste glass cullet with different percentage of bitumen content. Glass particles do not absorb any bituminous material, so it is necessary to decrease the bitumen content with the addition of glass cullet. According to Figure 2 and the results of the Marshall tests, the optimum bitumen measures decrease significantly in samples that include higher percentages of waste glass cullet. As the percentage of optimum bitumen content is 1% more in samples without waste glass cullet in comparison with saphaltic samples that include 20% waste glass cullet. The stiffness modulus of asphaltic samples that include waste glass cullet increased due to additional interlocking between the aggregate and the angularity of particles of glass cullet content. The increase in the intrusive friction angle because of the glass particles\u2019 increased angularity is the main reason for the addition of the stiffness modulus of asphaltic samples that include waste glass cullet. But as the percentage of glass content reaches greater than 15%, the particles\u2019 abundance cause slip these particles on together. The stiffness modulus of samples decreases as the percentage of glass cullet increases. The variations in the stiffness modulus of asphaltic samples that include different percentages of waste glass cullet at different temperature are shown in Figure 3.", "keyphrases": ["glass", "modifi asphalt", "bitumen", "differ in the stiff modulu of asphalt sampl", "marshal test", "saphalt sampl", "glass cullet", "particl", "glass particl", "bitumin materi", "interlock", "asphalt sampl", "glass particles\u2019", "stiff modulu", "wast glass cullet", "chang in the measur of bitumen content"]}
{"file_name": "S0021999115008256", "text": "This section is devoted to the discretization of the advection\u2013diffusion equation and to the analysis of dispersion and diffusion eigencurves for different polynomial orders. The spectral/hp continuous Galerkin method considered closely resembles the formulation presented in [7]. Sec. 2.1 describes in detail the derivation of the semi-discrete advection\u2013diffusion problem as applied to wave-like solutions, from which the relevant eigencurves can be obtained. The inviscid case (linear advection) is then addressed in Sec. 2.2, where the role of primary and secondary eigencurves is discussed from the perspective introduced in [9]. The viscous case is subsequently considered in Sec. 2.3, where eigencurves are shown to feature irregular oscillations for problems strongly dominated by either convection or diffusion.", "keyphrases": ["wave-lik solut", "deriv of the semi-discret advection\u2013diffus problem", "linear advect", "discret of the advection\u2013diffus equat", "dispers and diffus eigencurv", "galerkin method", "viscou case", "inviscid case"]}
{"file_name": "S0022311515002470", "text": "To conclude, the electrochemical reduction of uranium dioxide to uranium metal has been studied in a lithium chloride\u2013potassium chloride eutectic molten salt at 450\u00b0C. Both electrochemical and synchrotron X-ray techniques have been utilised to deduce the electrochemical reduction potential, mechanism and reduction pathway. The electrochemical reduction potential of the UO2|U couple is dependent on the activity of oxide ions existing within the melt. The electrochemical reduction of uranium dioxide to uranium metal seems to occur in a single, 4-electron-step, process; indicated by a single reduction peak (C1) in the cyclic voltammograms and also by the exclusion of any other phases in the EDXD data. The electrochemical reduction may be impeded by an increase in oxo-acidity of the molten salt. That is, O2\u2212 ions that are liberated by the electroreduction may not react at the counter electrode and, thus, not be removed from the molten salt. This could be due to the electrode geometry and/or the inherent microstructure of the working electrode: a high tortuosity, for example, would impede the diffusion of O2\u2212 ions out of the working electrode. This could then cause an increase in the activity of oxide ions existing within the melt and hence inhibit the electrochemical reduction \u2013 exploration of the microstructure of working electrodes will be the focus of future work.", "keyphrases": ["4-electron-step", "uranium metal", "edxd data", "counter electrod", "electron", "synchrotron x-ray", "electrochem reduct of uranium dioxid", "molten salt", "electrochem", "oxid ion", "cyclic voltammogram", "uo2|u coupl", "o2\u2212 ion", "uranium dioxid", "electrochem reduct", "melt", "lithium chloride\u2013potassium chlorid eutect molten salt", "explor of the microstructur of work electrod", "deduc the electrochem reduct potential, mechan and reduct pathway", "electrod", "electroreduct"]}
{"file_name": "S0009261415002730", "text": "Both methods of structure solution reveal a bent conformation of the central terthiophene units of the DOTT molecule as is clearly visible in all three cases in Figure 5. However, there is a fundamental difference in the conformation of the octyl side chains. Whilst for the single crystal phase at T=100K linearly extended chains are observed (Figure 5B), a defined rotation of the octyl chains relative to the terthiophene unit is found for the three thin film phases (Figure 5A). The rotation angle of about \u00b170\u00b0 results from a twist of the first CC single bond at the link between the terthiophene unit and the octyl chain (see arrows Figure 5A). Two features of this rotated conformation are interesting. First, a molecule with rotated side chains represents the equilibrium state of an isolated single DOTT molecule as obtained by combined MD and VASP calculations [33]. Second, the rotated conformation of the octyl chains allows a dense packing of the octyl side chains for both molecules. Interestingly, the single crystal structure at room temperature shows the twisted as well as the linear conformation of the octyl side chains within one molecule (Figure 5C).", "keyphrases": ["central terthiophen unit", "thin film", "linearli extend chain", "defin rotat of the octyl chain", "rotat side chain", "crystal structur", "structur solut", "octyl chain", "octyl side chain", "dens pack", "twist of the first cc singl bond", "terthiophen unit", "bent conform", "combin md and vasp calcul", "dott molecul"]}
{"file_name": "S1570870516301822", "text": "MWSN routing protocols generally take influence from both WSN and mobile ad hoc network (MANET) routing protocols, which all share common limitations, such as bandwidth, power and cost. WSNs often share the same aim as MWSNs, in that they wish to route data from many sensors to a single sink. However, WSNs are normally considered to be static and so the associated routing protocols are often unable to cope in a mobile scenario [10]. Alternatively, MANET protocols are designed to be able to cope with the mobility of nodes, however they aim to allow end-to-end communication to occur between any two nodes [2]. This extra functionality is often not required by MWSNs and so the additional overhead is unnecessary. Combined with the high packet delivery ratios and low delays that are demanded by emerging applications, the ideal routing solution for a MWSN is one that can handle the mobility of nodes and allows data to be forwarded from the sensors to the sink in a reliable and timely manner. This set of requirements make the problem of routing in a MWSN a unique challenge, which will require new specifically designed solutions. For this reason there have been many routing protocols designed for MWSNs. As such, this section will give an overview of the current literature, which highlights the different techniques and commonly used protocols in MWSN routing.", "keyphrases": ["mobil ad hoc network", "manet", "wsn", "rout protocol", "mwsn", "mwsn rout protocol", "manet protocol", "mwsn rout", "sensor", "rout data", "rout in a mwsn"]}
{"file_name": "S221267161200176X", "text": "Modeling or approximating high dimensional, computationally-expensive problems faces an exponentially increasing difficulty, the \u201ccurse of dimensionality\u201d. This paper proposes a new form of high dimensional model representation (HDMR) by utilizing the support vector regression (SVR), termed as adaptive SVR-HMDR, to conquer this dilemma. The proposed model could reveal explicit correlations among different input variables of the underlying function which is unknown or expensive for computation. Taking advantage of HDMR's hierarchical structure, it could alleviate the exponential increasing difficulty, and gain satisfying accuracy with small set of samples by SVR. Numerical examples of different dimensionality are given to illustrate the principle, procedure and performance of SVR-HDMR.", "keyphrases": ["support vector regress", "comput", "illustr the principle, procedur and perform", "approxim", "explicit correl", "model or approxim high dimensional, computationally-expens problem", "adapt svr-hmdr", "curs of dimension", "svr", "svr-hdmr", "high dimension model represent", "hdmr", "conquer thi dilemma", "model", "allevi the exponenti increas difficulti", "new form of high dimension model represent", "input variabl"]}
{"file_name": "S0079642514000784", "text": "Gas sorption, storage and separation in carbon materials are mainly based on physisorption on the surfaces and particularly depend on the electrostatic and dispersion (i.e., vdW) interactions. The former can be tuned by introducing charge variations in the material, and the latter by chemical substitution. The strength of the interaction is determined by the surface characteristics of the adsorbent and the properties of targeted adsorbate molecule, including but not limited to the size and shape of the adsorbate molecule along with its polarizability, magnetic susceptibility, permanent dipole moment, and quadrupole moment. Li  summarise the adsorption-related physical parameters of many gas or vapour adsorbates, and herein Table 1 we show a few of those of interest, H2, N2, CO, CO2, CH4, NH3, SO2 and H2S [90]. For instance, an adsorbent with a high specific surface area is a good candidate for adsorption of a molecule with high polarizability but no polarity. Adsorbents with highly polarised surfaces are good for adsorbate molecules with a high dipole moment. The adsorbents with high electric field gradient surfaces are found to be ideal for the high quadrupole moment adsorbate molecules [91]. Normally, the binding or adsorption strength with a carbon nanostructure is relatively low for H2 and N2; intermediate for CO, CH4 and CO2; and relatively high for H2S, NH3 and H2O. Thus, surface modifications, such as doping, functionalization and improving the pore structure and specific surface area of nanocarbons, are important to enhance gas adsorption. For this purpose, graphene offers a great scope for tailor-made carbonaceous adsorbents.", "keyphrases": ["so2", "adsorb", "improv the pore structur and specif surfac area of nanocarbon", "ga or vapour adsorb", "ga sorption, storag and separ", "enhanc ga adsorpt", "ch4", "introduc charg variat in the materi", "carbon materi", "co", "chemic substitut", "adsorb molecul", "h2o", "molecul", "function", "surfac modif", "h2", "co2", "physisorpt", "high quadrupol moment adsorb molecul", "n2", "nanocarbon", "electrostat and dispers (i.e., vdw) interact", "nh3", "carbonac adsorb", "graphen", "dope"]}
{"file_name": "S0305054816300867", "text": "The scheduling process we adopt matches a multiple stage stochastic programming approach. Standard two-stage stochastic programs with linear or convex functions are often solved using the L-shaped method or Bender's decomposition [44,6,7]. However, our recourse decision (scheduled cancellations) is still anticipative to further uncertainty, namely the second shift surgery durations, unavailability and cancellations. As such, the decision problem can be viewed as a three-stage recourse model [5,6]. Solving the scheduling problem is further complicated because the recourse function is integer. Laporte and Louveaux [26] propose modified L-shaped decomposition with adjusted optimal cuts for two stage stochastic program with integer recourse. Angulo  [1] alternately generate optimal cuts of the linear sub-problem and the integer sub-problem, which improves the practical convergence (see also [15,8]). We follow a sample average approximation approach (SAA) which uses this framework. Moreover, we prove and exploit a specific relationship between the first-stage realization and the optimal number of scheduled cancellations to speed up the computation of integer cuts. We use Jensen's inequality [17] to upper bound\u00a0the minus\u00a0second (and third) stage cost, a technique that was proposed by Batun  [3].", "keyphrases": ["linear or convex function", "first-stag realiz", "two stage stochast program", "sampl averag approxim approach", "schedul cancel", "upper bound the minu second (and third) stage cost", "linear sub-problem", "schedul process", "decis problem", "integ recours", "modifi l-shape decomposit", "three-stag recours model", "multipl stage stochast program approach", "recours function", "gener optim cut of the linear sub-problem and the integ sub-problem", "two-stag stochast program", "integ sub-problem", "bender' decomposit", "saa", "l-shape method", "jensen' inequ", "schedul problem", "recours decis", "integ cut"]}
{"file_name": "S0032386109003991", "text": "A living polymerization is a reaction without transfer and termination reactions that can proceed up to complete monomer conversion. In addition, when initiation is quantitative and fast compared to the propagation reaction, polymers with precisely controlled chain length and narrow molar mass distribution can be obtained. In the case of an industrial styrene polymerization this would permit to avoid any specific washing or degassing steps, which are necessary in the radical process to remove residual monomer and low molar mass oligomers. Since head-to-head defects along the chains are absent, anionic polystyrene would exhibit also a better thermal stability than radical one. Therefore, production of anionic polystyrene (PS) would be of interest if the conditions required to control the polymerization could be adapted to the market and be able to compete economically with industrial radical processes. The use of organic solvents and of expensive alkyllithium initiators, as well as the relatively low reaction temperatures required, was some important limitation to overcome. The possibilities to achieve a quantitative living-like anionic polymerization of styrene in the absence of solvent and at elevated temperature, using inexpensive initiating systems, were the main targets identified to tremendously decrease the cost of the anionic process. This implied at first to control the reactivity and stability of initiating and propagating active species in such unusual operating conditions.", "keyphrases": ["(p", "organ solvent", "reaction", "propag activ speci", "monom convers", "termin", "polym", "product of anion polystyren (ps)", "wash", "low molar mass oligom", "anion polymer of styren", "alkyllithium initi", "industri styren polymer", "degass", "anion polystyren", "propag", "polymer", "solvent"]}
{"file_name": "S1010603009002676", "text": "In this paper, we present our experimental observations on how solvents can vary the TPA and TPF properties of fluorescent rhodamine (Rh) dyes Rh6G, RhB and Rh101. Rhodamines are well-known xanthenes dyes, which have been extensively used for many widespread applications in single-molecule detection [24], DNA-sequence determination [25], fluorescence labelling [26], etc due to their strong fluorescence over the visible spectral region. Molecular geometries of rhodamine dyes are well-known [27,28] and indicate that all the structures are non-centrosymmetric. In general, for centrosymmetric molecules, TPA is forbidden when tuned to the transitions at one-half of the excitation frequencies. However, for non-centrosymmetric molecules due to symmetry relaxations, the single-photon absorption (SPA) peaks and TPA peaks may coincide. So we set our primary aim to find the effect of solvent polarity on the correlation of SPA and TPA peaks for all the dyes.", "keyphrases": ["spa", "symmetri relax", "non-centrosymmetr molecul", "dna-sequ determin", "experiment observ on how solvent can vari the tpa and tpf properti of fluoresc rhodamin (rh) dye", "single-photon absorpt", "rh101", "tpa", "centrosymmetr molecul", "rhodamin dye", "rhodamin", "xanthen dye", "fluoresc", "tpf", "fluoresc rhodamin (rh) dye", "rh6g", "rhb", "single-molecul detect", "tpa peak", "fluoresc rhodamin", "single-photon absorpt (spa) peak", "fluoresc label", "rh", "dye"]}
{"file_name": "S0003491615001839", "text": "This work shows how our approach based on the combination of Statistical Mechanics and nonlinear PDEs theory provides us with a novel and powerful tool to tackle phase transitions. This method leads to solution of perhaps the most known test-case that exhibits a first order phase transition (semi-heuristically described) such as the van der Waals model. In particular we have obtained the first global mean field partition function (Eq. (9)), for a system of finite number of particles. The partition function is a solution to the Klein\u2013Gordon equation, reproduces the van der Waals isotherms away from the critical region and, in the thermodynamic limit N\u2192\u221e automatically encodes the Maxwell equal areas rule. The approach hereby presented is of remarkable simplicity, has been successfully applied to spin\u00a0 [17\u201319,14,16] and macroscopic thermodynamic systems\u00a0 [20,15] and can be further extended to include the larger class of models admitting partition functions of the form (4) to be used to extend to the critical region general equations of state of the form (7) including a class virial expansions.", "keyphrases": ["thermodynam limit n\u2192\u221e", "spin", "nonlinear pde theori", "maxwel equal area rule", "macroscop thermodynam system", "partit function of the form", "class virial expans", "phase transit", "van der waal model", "field partit function", "van der waal isotherm", "partit function", "gener equat of state of the form", "klein\u2013gordon equat", "first order phase transit", "statist mechan"]}
{"file_name": "S0003491615001505", "text": "The next important step might be the derivation of the Dirac equation. The Creutz model\u00a0 [32] suggests that we should consider incorporating into the logical inference treatment, the additional knowledge that one has objects hopping on a lattice instead of particles moving in a space-time continuum. Recall that up to Section\u00a0 2.4, the description of the measurement scenario, robustness etc is explicitly discrete. In Section\u00a0 2.4, the continuum limit was taken only because our aim was to derive the Pauli equation, which is formulated in continuum space-time. Of course, the description of the motion of the particle in Section\u00a0 2.6 is entirely within a continuum description but there is no fundamental obstacle to replace this treatment by a proper treatment of objects hopping on a lattice. Therefore it seems plausible that the logical inference approach can be extended to describe massless spin-1/2 particles moving in continuum space-time by considering the continuum limit of the corresponding lattice model. An in-depth, general treatment of this problem is beyond the scope of the present paper and we therefore leave this interesting problem for future research.", "keyphrases": ["object", "pauli equat", "particl move in a space-tim continuum", "the creutz model", "continuum space-tim", "lattic model", "object hop on a lattic instead of particl", "dirac equat", "motion of the particl", "massless spin-1/2 particl", "lattic", "measur scenario", "futur research"]}
{"file_name": "S0377025713001031", "text": "Flow-induced deformations can lead to irreversible changes in the structure of a polymeric fluid; if the rate of extension far exceeds the rate of relaxation, then the polymer chain can be broken. Mechanical degradation of polymers in extensional flow has long been recognised [30] and leads to a reduction in the average molecular weight. A-Alamry  [1] have recently reported evidence of flow-induced polymer degradation in DoD jetting. Central scission is observed for polystyrene in a number of good solvents under certain jetting conditions for a bounded range of molecular weights. Since only those molecules that are fully extended can be fractured at the centre of the polymer chain [29], in this paper we investigate whether flow-induced central scission is possible under the conditions of DoD jetting.", "keyphrases": ["reduct in the averag molecular weight", "polymer fluid", "dod jet", "polym", "flow-induc central scission", "central scission", "polystyren"]}
{"file_name": "S0045782512003234", "text": "An attempt of a quite comprehensive answer to this question is made hereafter, within the following structure of the remaining paper: first, we introduce the mathematical systems biology of bone, starting from the work of Pivonka  [25,26], and extending it to mechanoregulatory feedback control (Section 2). Then, we introduce a continuum micromechanics representation adopted from Hellmich  [30], in order to scale elasticity and strains from the level of the extravascular bone matrix to that of cortical bone1In this paper, we restrict ourselves to cortical bone, due to its major importance in providing sufficient load-carrying capacity. However, extension of the coupled approach proposed here to trabecular bone is straightforward; it merely requires recalibration of underlying parameters.1 and vice versa (Section 3). The micromechanics formulation is fed with composition quantities derived from the systems biology approach, which, in turn, is provided with mechanical stimuli gained from the micromechanics model. We then apply the coupled approach to biochemical and mechanical conditions typical for postmenopausal osteoporosis (Section 4) and microgravity exposure (Section 5), and discuss key sensitivity features (Section 6). After emphasizing the potentials and limitations of the presented approach (Section 7), we conclude the paper in (Section 8).", "keyphrases": ["coupl approach", "continuum micromechan represent", "recalibr of underli paramet", "scale elast and strain from the level of the extravascular bone matrix to that of cortic bone", "micromechan model", "potenti and limit of the present approach", "system biolog approach", "cortic bone", "mechan stimuli", "mathemat system biolog of bone", "mechanoregulatori feedback control", "composit quantiti", "provid suffici load-carri capac", "trabecular bone", "biochem and mechan condit", "micromechan formul"]}
{"file_name": "S0003491615000433", "text": "Nuclear theory devoted major efforts since 4 decades to describe thermalization in nuclear reactions, predominantly using semi-classical methods\u00a0 [13,14,10], in line with similar problems in quantum liquids\u00a0 [15,16]. There were attempts to develop improved molecular dynamics methods combining quantum features with a semi classical treatment of dynamical correlations\u00a0 [17,18]. Still, no clear-cut quantum approach is readily available yet, in spite of numerous formal attempts [19,20,10]. The field of clusters and nano structures is far younger but fast developing in relation to the ongoing developments of lasers and imaging techniques. Semiclassical approaches were also considered in the field to include some dynamical corrections\u00a0 [21,22] and could qualitatively describe dynamical processes. But such approaches are bound to simple metals with sufficiently delocalized wave functions, and thus smooth potentials justifying semiclassical approximations. The case of organic systems, in particular the much celebrated C60 \u00a0 [4,23], cannot be treated this way. Semi classical, and even classical approaches, can be used at very high excitations such as delivered by very intense laser pulses\u00a0 [2]. In such cases the system is blown up and details of its quantum mechanical features do not matter anymore. But for less violent scenarios, quantum shell effects cannot be ignored.", "keyphrases": ["organ system", "improv molecular dynam method", "quantum liquid", "nuclear theori", "thermal", "laser", "combin quantum featur", "qualit describ dynam processes.", "quantum shell effect", "quantum mechan featur", "semi classic treatment of dynam correl", "quantum approach", "veri intens laser puls", "imag techniqu", "nuclear reaction", "field of cluster and nano structur", "semi-class method", "simpl metal", "simpl metal with suffici deloc wave function", "c60"]}
{"file_name": "S0098300413002124", "text": "In this section, we use the terrain data processing as an example to describe the geodetic data transformation method. Since Google Maps/Earth server only gives the terrain data in graphical display, we have to get terrain digital data from other sources. The fine-resolution (3\u2033 or finer) terrain data bases such as SRTM (Shuttle Radar Topographical Mission) or USGS's DEM (Digital Elevation Model) data are necessary. Moreover, since 3DWF is used to model the fine-scale (meters up to 100m) atmospheric flow, it needs fine resolution terrain data. In this project, we use the terrain elevation data set from SRTM (Farr  2007) with 3-arcsecond (~90m resolution at the equator) resolution. The data covers the land area, nearly global from 56S to 60N latitudes. We use the processed version 4 SRTM data set as described in Gamache (2005) in which some of the missing data holes were filled. The original data is organized in WGS84 (World Geodetic System 84) geodetic coordinate system. When the data are applied to the 3DWF model, they are transformed to the local East, North and Up (ENU) coordinate (see Figure 3). Since the 3DWF is a fine scale wind model and its entire model domain is not intended to be larger than 20\u00d720km, this Cartesian coordinate system is a good choice with very little distortion due to the curvature of the Earth's surface. The transformation from the WGS84 data to the ENU coordinate is performed as follows (Fukushima, 2006; Featherstone and Claessens, 2008).", "keyphrases": ["fine-resolut (3\u2033 or finer) terrain data base", "fine-scal (meter up to 100m) atmospher flow", "shuttl radar topograph mission", "terrain data process", "wgs84", "enu", "east, north and up", "describ the geodet data transform method", "3dwf", "srtm", "terrain digit data", "world geodet system 84", "digit elev model", "dem", "cartesian coordin system"]}
{"file_name": "S221266781300018X", "text": "Amodel are proposed for modeling data-centric Web services which are powered by relational databases and interact with users according to logical formulas specifying input constraints, control-flow constraints and state/output/action rules. The Linear Temporal First-Order Logic (LTL-FO) formulas over inputs, states, outputs and actions are used to express the properties to be verified.We have proven that automatic verification of LTL-FO properties of data-centric Web services under input-bounded constraints is decidable by reducing Web services to data-centric Web applications. Thus, we can verify Web service specifications using existing verifier designed for Web applications.", "keyphrases": ["interact with user", "verifi web servic specif", "relat databas", "ltl-fo", "data-centr web servic", "control-flow constraint", "linear tempor first-ord logic", "data-centr web applic", "logic formula", "state/output/act rule", "web applic", "reduc web servic to data-centr web applic", "model data-centr web servic"]}
{"file_name": "S0022311514007119", "text": "In the calculations for the formation energy, the box size is set to 30a0\u00d730a0\u00d730a0, where a0 is the bcc Fe lattice parameter. For all calculations periodic boundary conditions and constant volume are used. The Monte Carlo algorithm used to determine the lowest energy configuration of the cluster [28] is organised as follows. First, the energetics of voids without helium are investigated. A vacancy is introduced into the simulation cell and the system is minimised using a conjugate gradient algorithm, yielding a single vacancy formation energy Evac of 1.72eV. Next, the atom with the highest potential energy is removed from the system and again the system is minimised. This scheme is iteratively continued to create voids up to the number of target vacancies and the formation energy of each is calculated. Next, helium atoms are introduced to the vacancies. The total system energy is measured and recorded. At this point, a Metropolis MC scheme [29] is used to find the low energy configurations. Every helium in the system is randomly displaced from its site up to a maximum of rmax (4.5\u00c5, the cut off distance for He\u2013He interactions) in each of the x, y and z directions and then minimised using the conjugate gradient algorithm. Each bubble is continued for a minimum of 10,000 steps. After that, the searches will be terminated if the system energy does not drop within a further 10 steps. A schematic of this iterative process is shown in Figure 1.", "keyphrases": ["mont carlo algorithm", "total system energi", "singl vacanc format energi", "void without helium", "evac", "helium atom", "box", "simul cell", "low energi configur", "format energi", "metropoli mc scheme", "helium", "iter process", "he", "minimis", "fe lattic", "he\u2013h interact", "determin the lowest energi configur", "conjug gradient algorithm"]}
{"file_name": "S0029549314002854", "text": "The pipes under pressure in the RCS or connected to RCS are usually made of austenitic or austenitic & ferritic stainless steel. Most connections are welded. The pipes may be exposed to various degradation phenomena (diverse hazards, mechanical fatigue, thermal fatigue, stress corrosion, etc.). Event screening in the databases showed a total of 116 events (33 related to cracks and 83 to leaks). Three main causes for failure were identified, namely, fatigue, corrosion and the presence of manufacturing defects. Human factor induced defects proved to have little impact \u2013 less than 10% of the cases could be attributed to operation errors. Fatigue was found being induced by several factors: excessive vibration, pressure shocks and the thermal regime of operating the pipe, as well as by combinations of these factors. Corrosion was induced, in most of the cases, by a non-appropriate choice of alloys while not taking into account the chemical parameters of the fluid inside pipes. Manufacturing defects mostly dealt with welding related problems and deviation from the design documentation during post-weld heat treatment.", "keyphrases": ["alloy", "event screen", "pipe", "austenit or austenit & ferrit stainless steel", "rc", "fluid"]}
{"file_name": "S0010938X12002508", "text": "The study outlines a trial of transient response analysis on full-scale motorway bridge structures to obtain information concerning the steel\u2013concrete interface and is part of a larger study to assess the long-term sustained benefits offered by Impressed Current Cathodic Protection (ICCP) after the interruption of the protective current [1]. These structures had previously been protected for 5\u201316years by an ICCP system prior to the start of the study. The protective current was interrupted, in order to assess the long-term benefits provided by ICCP after it has been turned off. This paper develops and examines a simplified approach for the on-site use of transient response analysis and discusses the potential advantages of the technique as a tool for the assessment of the corrosion condition of steel in reinforced concrete structures.", "keyphrases": ["iccp", "protect current wa interrupt", "assess the long-term benefit", "motorway bridg structur", "long-term sustain benefit", "discuss the potenti advantag", "reinforc concret structur", "steel\u2013concret interfac", "assess of the corros condit", "interrupt of the protect current", "transient respons analysi", "develop and examin a simplifi approach", "iccp system", "impress current cathod protect", "steel"]}
{"file_name": "S2212667814001208", "text": "Improving as well as evaluating the performance of High Performance Computing (HPC) applications by migrating them to Cloud environments are widely considered as critical issues in the field of high performance and Cloud computing. However, poor network performance, heterogeneous and dynamic environments are some series of pitfalls for execution of HPC applications in Cloud. This paper proposes a new approach to improve the performance and scalability of HPC applications on Amazon's HPC Cloud. The evidence from our approach points a significant improvement in speed up and scale up with the response rate of more than 20 percent parallel ef\ufb01ciency on the Cloud in comparison to dedicated HPC cluster. We state that the EC2 Cloud system is a feasible platform for deploying on-demand, small sized HPC applications.", "keyphrases": ["scale up", "deploy on-demand, small size hpc applic", "respons rate", "improv as well as evalu the perform", "ec2 cloud system", "hpc applic", "cloud", "amazon' hpc cloud", "hpc", "speed up", "propos a new approach to improv the perform and scalabl of hpc applic", "execut of hpc applic in cloud", "poor network perform", "cloud environ", "hpc cluster", "parallel ef\ufb01cienc", "high perform and cloud comput", "migrat them to cloud environ", "heterogen and dynam environ", "high perform comput"]}
{"file_name": "S0370269304009062", "text": "The microwave background is not the only universal photon field that has to be taken in consideration. Especially interesting is the isotropic infrared and optical background (IRB). The number density of IRB is smaller than that of MBR by more that two orders of magnitude. On the other hand, protons of lower energy can interact on the IRB, and the smaller number density has to be weighted with the higher flux of interacting protons. The present Universe is optically thin to 1019\u00a0eV and lower energy protons, but even at low redshifts the proton interaction rate quickly increases. This is different from the interactions on MBR, where the interacting protons quickly lose their energy even at z=0. The cosmological evolution of UHECR injection is thus of major importance for the contribution of such interactions to the flux of cosmogenic neutrinos.", "keyphrases": ["cosmolog evolut of uhecr inject", "lower energi proton", "irb", "isotrop infrar and optic background", "present univers", "the smaller number densiti ha to be weight with the higher flux of interact proton", "microwav background", "interact on mbr", "flux of cosmogen neutrino", "proton interact rate", "univers photon field", "mbr", "quickli lose their energi even at z=0", "proton", "interact proton", "taken in consider"]}
{"file_name": "S0888613X16301062", "text": "The first step of PB, the enumeration of the conditional sample space through abductive logic programming, could be compared to \u201clogical inference\u201d in ProbLog [9]. While both languages aim to generate a propositional formula and compile it into a decision diagram, \u201clogical inference\u201d in PB is based on abductive logic programming, while ProbLog grounds the relevant parts of the probabilistic program. Moreover, in PB compilation of the boolean formulas is performed using (RO)BDDs, while ProbLog can use a wider range of decision diagrams,  sentential decision diagrams (SDD), deterministic, decomposable negation normal form (d-DNNF). These differences reflect the different aims of the two PPLs: ProbLog focuses on models where \u201clogical inference\u201d needs to be efficient, and the resulting representation, the decision diagrams, need to be compact, while PB focuses on models where \u201clogical inference\u201d is typically easy, however it must be applied repeatedly, according to the nature and the number of the observations. However, in future work, PB could benefit from the use of more compact decision diagrams.", "keyphrases": ["logic infer", "(ro)bdd", "\u201clogic inference\u201d in pb", "enumer of the condit sampl space", "pb compil", "sdd", "d-dnnf", "use of more compact decis diagram", "problog", "decis diagram", "\u201clogic inference\u201d", "ppl", "pb", "sententi decis diagram", "deterministic, decompos negat normal form"]}
{"file_name": "S0038092X15003059", "text": "In addition, the prediction of solar cell\u2019s temperature is very important for the electrical characterisation of CPV modules. Rodrigo  (2014) reviewed various methods for the calculation of the cell temperature in High Concentrator PV (HCPV) modules. The methods were categorised based on: (1) heat sink temperature, (2) electrical parameters and (3) atmospheric parameters. The first two categories are based on direct measurements of CPV modules in indoor or outdoor experimental setups and presented the highest degree of accuracy (Root Mean Square Error (RMSE) 1.7\u20132.5K). Most of the methods reviewed by Rodrigo  (2014) calculate the cell temperature at open-circuit conditions. Methods that predict the cell temperature at maximum power point (MPP) operation offer a more realistic approach since they include the electrical energy generation of the solar cells (i.e real operating conditions); Yandt  (2012) described a method predicting the cell temperature at MPP based on electrical parameters and Fern\u00e1ndez  (2014b) based on heat sink temperature with absolute RMSE 0.55\u20131.44K. Fern\u00e1ndez  (2014a) also proposed an artificial neural network model to estimate the cell temperature based on atmospheric parameters and an open-circuit voltage model based on electrical parameters (Fernandez , 2013a) offering good accuracy (RMSE 3.2K and 2.5K respectively (Rodrigo , 2014)). The main disadvantage of the aforementioned methods is that an experimental setup is required to obtain the parameters used for the cell temperature calculation.", "keyphrases": ["predict of solar cell\u2019 temperatur", "predict the cell temperatur at mpp", "calcul the cell temperatur", "cell", "high concentr pv", "cell temperatur calcul", "calcul of the cell temperatur", "cpv", "hcpv", "mpp", "artifici neural network model", "maximum power point", "open-circuit voltag model", "open-circuit condit", "estim the cell temperatur", "solar cell", "electr energi gener"]}
{"file_name": "S0032386109010386", "text": "From a general point of view, polymerization techniques can be divided into two types of chemical reactions: step-growth polymerization and free radical polymerization. Step-growth polymerization is widely used for synthesis of polyesters, polyamide and epoxies while the synthesis of polyacrylics requires the use of free radical polymerization. These polymerization reactions can be performed either in bulk or in solution or in dispersed media. Heterophase polymerizations (i.e emulsion, dispersion and miniemulsion polymerizations) present the advantage of easier removal of the resulting product from the reactor compared to bulk polymerization thanks to the low viscosity of the reaction medium. Polymerization in solution also induces lower viscosity but also lower reaction rates due to dilution of the reactants and higher cost and environmental impact due to the use of organic solvents. These problems are solved in the case of heterophase polymerizations where the reactants are confined inside droplets (no dilution effect) and water is used as medium. The use of surfactant molecules are usually needed for the stabilization of the monomer droplet and subsequent polymer particles in the water phase.", "keyphrases": ["reaction", "reaction medium", "synthesi of polyacryl", "emuls", "polyamid", "surfact molecul", "reactor", "reactant", "polymer", "monom droplet", "solut", "chemic reaction", "bulk polymer", "dilut", "polym particl", "stabil of the monom droplet", "dilut effect", "dispers", "dispers media", "bulk", "step-growth polymer", "remov of the result product", "water", "organ solvent", "droplet", "polymer techniqu", "free radic polymer", "polyest", "heterophas polymer", "synthesi of polyest", "epoxi", "miniemuls polymer", "polyacryl", "polymer reaction"]}
{"file_name": "S2212667813000610", "text": "The most important goal of the software industry is to produce successful product. During the process of production several times the product fails due to lack of proper management. This paper is exploring the role of software engineering courses in computer engineering related branches and then reasons why software developers lack project management in proper software management trainings. Our findings reflect that in majority of computer related branches like computer science, computer engineering, information system engineering there is no place for software project management course. Our findings are based on a survey of course curriculums of computer engineering, computer science and information system engineering courses taught in Turkish universities.", "keyphrases": ["product", "manag", "comput engin", "softwar manag", "softwar industri", "project manag", "role of softwar engin cours", "softwar project manag cours", "softwar project manag", "product fail", "proper softwar manag train", "survey of cours curriculum", "comput scienc and inform system engin", "produc success product"]}
{"file_name": "S004578251300176X", "text": "Powder metallurgy is a versatile technology for the manufacturing of components to (near) net-shape with high product quality. For a hardmetal (such as WC-Co) cold compaction of the powder to a \u201cgreen body\u201d is followed by liquid-phase sintering from the subsequent heating. This means that the binder metal Co is heated to melt in order to obtain sufficient mobility via capillary action, i.e., via surface traction, stemming from stored surface energy. The resulting flow causes gradual filling of the pore space and brings about a macroscopic shrinkage of the particle compact until a completely dense state is obtained, at least ideally. To model and quantitatively simulate the sintering process is a challenging task. The goal is to (i) estimate the final resulting quality (i.e., in terms of porosity) and (ii) to predict the final net shape and size of the sintered component.", "keyphrases": ["macroscop shrinkag", "to predict the final net shape and size", "green bodi", "powder metallurgi", "obtain suffici mobil via capillari action", "sinter compon", "sinter process", "wc-co", "surfac traction", "powder", "technolog for the manufactur of compon to (near) net-shap", "co", "gradual fill of the pore", "hardmet", "particl", "poros", "dens state", "heat", "co is heat", "model and quantit simul the sinter process", "liquid-phas sinter", "estim the final result qualiti"]}
{"file_name": "S0167273812003025", "text": "In conclusion, a new approach to the \u201cgrind-free\u201d nanoprecursor route to direct combinatorial solid state synthesis of several \u201cdifficult to make\u201d and hitherto unknown phase-pure heterometallic Ruddlesden Popper type La4Ni3\u2212xFexO10 materials has been described. The new approach used a high-throughput reactor and robotic automation (RAMSI) to rapidly synthesise a range of nanoparticle co-precipitate precursors in cloned libraries at a rate of 7.5 samples an hour. Each library could then be heat-treated at a different temperature and an initial powder XRD screen was used to locate and approximate phase boundary. A more focussed second synthesis and XRD characterisation of selected larger heat-treated powders was then performed to reconfirm the locations of the phase boundaries with the highest dopant level being achieved for La4Ni2FeO10 which is significantly greater Fe doping than has been achieved by anyone previously (despite several notable efforts). EXAFS data suggested that Fe3+ was located onto Ni sites in all cases and did not exist as a separate iron oxide phase.", "keyphrases": ["heat-treat powder", "ni", "new approach to the \u201cgrind-free\u201d nanoprecursor rout to direct combinatori solid state synthesi", "direct combinatori solid state synthesi", "nanoparticl co-precipit precursor", "la4ni2feo10", "fe3+", "phase-pur heterometal ruddlesden popper type la4ni3\u2212xfexo10 materi", "locat and approxim phase boundari", "synthesis a rang of nanoparticl co-precipit precursor", "fe", "iron oxid", "exaf data", "\u201cgrind-free\u201d nanoprecursor rout", "powder xrd screen", "robot autom", "synthesi and xrd characteris", "high-throughput reactor", "heat-treat", "ramsi", "rate of 7.5 sampl an hour"]}
{"file_name": "S0377025714002213", "text": "The first of these systems, a biopolymer gel, involves the thermoreversible gelation of aqueous gelatin solutions to form a physical gel, whereas the other systems considered herein involve the formation of chemical gels featuring permanent cross-linked branching networks. The second system is a commercial silicone dielectric gel (SDG) which is used in the production of electronic products created by industrial printing processes. The third experimental system is a fibrin gel formed by the thrombin-induced polymerisation of fibrinogen molecules. The gel network product in the latter case forms the principal microstructural component of a blood clot [8]. The latter case is particularly interesting as the critical-gel which is established at the GP serves as a \u2018template\u2019 for the ensuing development of microstructure and associated rheological properties in the post-GP phase of fibrin clot evolution [9].", "keyphrases": ["sdg", "biopolym gel", "fibrin clot", "product of electron product", "blood clot", "cross-link branch network", "microstructur compon", "gel network product", "fibrin gel", "critical-gel", "thrombin-induc polymeris", "thermorevers gelat", "fibrinogen molecul", "commerci silicon dielectr gel", "\u2018template\u2019 for the ensu develop of microstructur and associ rheolog properti", "gp"]}
{"file_name": "S2212667814001361", "text": "Contractor selection for a project is an important decision, one for the project time and cost, next for the quality obtained by the project. Although the project managers can easily determine the project time and cost, the quality is usually undefined especially for un-experienced managers. With a learnable property, an approach is first introduced in this paper to quantify the quality obtained for a gas well drilling project. Then, based on these three objectives (time, cost, and quality), a contractor selection problem is converted to an optimization problem. Next, the NSGA-II algorithm is utilized for solution. At the end, a sensitivity analysis is performed to select the parameters of the algorithm.", "keyphrases": ["sensit analysi", "ga well drill project", "object", "project time and cost", "qualiti", "(time", "learnabl properti", "contractor select", "un-experienc manag", "determin the project time and cost", "project manag", "quantifi the qualiti obtain for a ga well drill project", "contractor select problem", "nsga-ii algorithm", "optim problem", "cost"]}
{"file_name": "S1566253516300069", "text": "The above discussion also lays bare the difference of perspectives between the fusion of hard constraints and knowledge-base merging: the idea of Konieczny and Pino-Perez is to explain the fusion of plain epistemic states, understood as a set of plausible worlds, by the existence of underlying partial orderings or numerical plausibility degrees (obtained by distances), based on axioms that only use plausible sets attached to these orderings. In [67] the same authors use both hard (integrity) constraints and belief sets referring to plausible worlds, and try to extend both the AGM revision and knowledge-based merging. However, they do not envisage the merging of integrity constraints discussed in the previous section. The belief revision and merging literature takes an external point of view on cognitive processes under study. The underlying ordered structures are here a consequence of the merging postulates, but they do not appear explicitly in the axioms and they are not observable from the outside. On the contrary, our approach is to construct fusion rules that only rely on what is explicitly supplied by sources. In the sequel we consider the counterpart of our fusion postulates for ranked models, that can be expressed by means of total orders of possible worlds or by their encodings on a plausibility scale.", "keyphrases": ["belief set", "fusion of plain epistem state", "agm revis", "construct fusion rule", "order structur", "numer plausibl degre", "partial order", "belief revis and merg", "knowledge-bas merg", "rank model", "hard (integrity) constraint", "hard constraint", "merg of integr constraint"]}
{"file_name": "S0168365913003295", "text": "A limitation of the pharmacyte approach is the one-time nature of the intervention: ACT T-cells can only be loaded once with a cargo of adjuvant drug prior to transfer, and the duration of stimulation is inherently limited by expansion of the cell population in vivo, since cell-bound particles are diluted with each cell division. We hypothesized that a strategy to target supporting drugs to T-cells with nanoparticle drug carriers directly in vivo would enable transferred lymphocytes to be repeatedly stimulated with supporting adjuvant drugs, and thereby provide continuous supporting signals over the prolonged durations that might be necessary for elimination of large tumor burdens. Such \u201cre-arming\u201d of T-cells with supporting drugs could be achieved by repeated administration of targeted particles, allowing adoptively-transferred T-cells to be restimulated multiple times directly in vivo, while the use of internalizing targeting ligands would minimize the likelihood of immune responses against the nanoparticle carrier. To our knowledge, only two prior studies have attempted to target nanoparticles to T-cells in vivo [17,18]. In both of these studies, particles were targeted to T-cells via peptide-MHC ligands that bind to specific T-cell receptors. However, peptide-MHC-functionalized nanoparticles have recently been shown to deliver an anergizing/tolerizing signal to T-cells [18,19] \u2014 which is ideal for treating graft rejection or autoimmunity, but runs counter to the goals of cancer immunotherapy.", "keyphrases": ["expans of the cell popul in vivo", "cell", "cancer immunotherapi", "adoptively-transf t-cell", "peptide-mhc ligand", "support adjuv drug", "t-cell receptor", "nanoparticl carrier", "transfer lymphocyt", "adjuv drug", "elimin of larg tumor burden", "cell divis", "nanoparticl drug carrier", "\u201cre-arming\u201d of t-cell with support drug", "act t-cell", "support drug", "treat graft reject or autoimmun", "pharmacyt approach", "target particl", "intern target ligand", "t-cell", "stimul", "administr of target particl", "cell-bound particl", "nanoparticl", "peptide-mhc-function nanoparticl"]}
{"file_name": "S0167931713006904", "text": "Copper electro-chemical deposition (ECD) of through silicon via (TSV) is a key challenge of 3D integration. This paper presents a numerical modeling of TSV filling concerning the influence of the accelerator and the suppressor. The diffusion\u2013adsorption model was used in the simulation and effects of the additives were incorporated in the model. The boundary conditions were derived from a set of experimental Tafel curves with different concentrations of additives, which provided a quick and accurate way for copper ECD process prediction without complicated surface kinetic parameters fitting. The level set method (LSM) was employed to track the copper and electrolyte interface. The simulation results were in good agreement with the experiments. For a given feature size, the current density for superfilling could be predicted, which provided a guideline for ECD process optimization.", "keyphrases": ["copper electro-chem deposit", "simul", "acceler and the suppressor.", "3d integr", "superfil", "copper ecd process predict", "lsm", "through silicon via", "simul and effect of the addit", "tsv", "ecd process optim", "numer model of tsv fill", "diffusion\u2013adsorpt model", "tsv fill", "level set method", "ecd", "copper electro-chem deposit (ecd) of through silicon via (tsv)", "addit", "track the copper and electrolyt interfac", "set of experiment tafel curv"]}
{"file_name": "S0021999115001412", "text": "Inspired by energy-fueled phenomena such as cortical cytoskeleton flows [46,45,32] during biological morphogenesis, the theory of active polar viscous gels has been developed [37,33]. The theory models the continuum, macroscopic mechanics of a collection of uniaxial active agents, embedded in a viscous bulk medium, in which internal stresses are induced due to dissipation of energy [41,58]. The energy-consuming uniaxial polar agents constituting the gel are modeled as unit vectors. The average of unit vectors in a small local volume at each point defines the macroscopic directionality of the agents and is described by a polarization field. The polarization field is governed by an equation of motion accounting for energy consumption and for the strain rate in the fluid. The relationship between the strain rate and the stress in the fluid is provided by a constitutive equation that accounts for anisotropic, polar agents and consumption of energy. These equations, along with conservation of momentum, provide a continuum hydrodynamic description modeling active polar viscous gels as an energy consuming, anisotropic, non-Newtonian fluid [37,33,32,41]. The resulting partial differential equations governing the hydrodynamics of active polar viscous gels are, however, in general analytically intractable.", "keyphrases": ["theori of activ polar viscou gel", "uniaxi activ agent", "equat of motion", "cortic cytoskeleton flow", "constitut equat", "energi consuming, anisotropic, non-newtonian fluid", "continuum hydrodynam descript", "model the continuum, macroscop mechan", "polar field", "uniaxi polar agent", "viscou bulk medium", "gel", "activ polar viscou gel", "polar viscou gel", "these equations, along with conserv of momentum", "fluid", "biolog morphogenesi"]}
{"file_name": "S0925838814009669", "text": "SPS has been utilized in several studies to retain the nanostructure of aluminum alloy powders during consolidation. Ye  investigated the effect of processing of cryomilled Al 5083 powder via SPS [13]. X-ray Diffraction (XRD) grain size calculations before and after SPS showed that the average grain size of the alloy only increased from 25nm to 50nm (from powder to bulk state). Subsequently, the hardness values obtained through nanoindentation for specimens of AA5083 produced via SPS were highly improved in comparison to conventional sintering methods were grain coarsening takes place on a larger scale. In another study the combination of cryomilling and SPS of AA-5356/B4C nanocomposites powder was found to largely improve the microhardness and flexural strengths of the bulk nanocomposite. Rana  [14] investigated the effect of SPS on mechanically milled AA6061 (Al\u2013Mg\u2013Si) micro-alloy powder. The average grain size after 20h of milling was \u223c35nm and increased to only \u223c85nm after processing with SPS at 500\u00b0C. Microhardness and compressive tests were carried out on the consolidated near full density specimens of both unmilled and milled powders and the results showed significant increase in both hardness and compressive strengths for the milled nanocrystalline powders as a result of the very fine grain size.", "keyphrases": ["cryomil", "investig the effect of process of cryomil al 5083 powder", "alloy", "process of cryomil al 5083 powder", "mill nanocrystallin powder", "mechan mill aa6061", "x-ray diffract (xrd) grain size calcul", "investig the effect of sp on mechan mill aa6061 (al\u2013mg\u2013si) micro-alloy powder", "bulk nanocomposit", "x-ray diffract", "combin of cryomil and sp of aa-5356/b4c nanocomposit powder", "retain the nanostructur of aluminum alloy powder dure consolid", "aa5083", "aluminum alloy powder", "sp", "aa-5356/b4c nanocomposit powder", "cryomil al 5083 powder", "xrd", "unmil and mill powder", "nanoindent", "al\u2013mg\u2013si", "nanostructur of aluminum alloy powder", "mechan mill aa6061 (al\u2013mg\u2013si) micro-alloy powder", "consolid"]}
{"file_name": "S0370269304009220", "text": "There exist some interesting cases where the deformation structure becomes simple. One is the limit to the N=1/2 superspace [5], where the action should reduce to N=1/2 super-Yang\u2013Mills theory with adjoint matter. Another interesting case is the singlet deformation [10,11], where the deformation parameters belongs to the singlet representation of the R-symmetry group SU(2)R. In this Letter, we will study N=2 supersymmetric U(1) gauge theory in the harmonic superspace with singlet deformation. In this case, the gauge and supersymmetry transformations get correction linear in the deformation parameter. Therefore we can easily perform the field redefinition such that the component fields transform canonically under the gauge transformation. In the case of N=1/2 super-Yang\u2013Mills theory, such field redefinition is also possible [5]. But in this case the component fields do not transform canonically under the deformed supersymmtery transformation. In the singlet case, we will show that there is a field redefinition such that the redefined fields also transform canonically under the deformed supersymmetry. We will construct a deformed Lagrangian which is invariant under both the gauge and supersymmetry transformations. We find that the deformed Lagrangian is characterized by a single function of an antiholomorphic scalar field.", "keyphrases": ["deform structur", "compon field", "singlet case", "n=1/2 super-yang\u2013mil theori with adjoint matter", "gaug transform", "n=1/2 super-yang\u2013mil theori", "gaug and supersymmetri transform", "singl function", "su(2)r", "n=2 supersymmetr u(1) gaug theori", "singlet deform", "n=1/2 superspac", "correct linear", "deform lagrangian", "transform canon under the deform supersymmetri", "the gaug and supersymmetri transform", "r-symmetri group", "harmon superspac", "field redefinit", "deform supersymmteri transform", "antiholomorph scalar field", "singlet represent", "deform paramet", "deform supersymmetri"]}
{"file_name": "S0009261413004612", "text": "The control of the RP re-encounter probability finds a direct application to improve the performance of chemical devices. Here, we show how a simple-to-implement control scheme highly enhances the sensitivity of a model chemical magnetometer by up to two orders of magnitude. The basic idea behind a chemical magnetometer is that, since a change in the magnetic field modifies the amount of singlet products, one can reverse the reasoning and measure the chemical yield to estimate B. Intuitively, the magnetic sensitivity is high when a small change in the magnetic field intensity produces large effects on the singlet yield. Formally, it is defined as:(2)\u039bs(B)\u2261\u2202\u03a6s(B)\u2202B=\u222b0\u221epre(t)gs(B,t)dt,with gs(B,t)\u2261\u2202fs(B,t)\u2202B being the instantaneous magnetic sensitivity. The functional form of fs(B,t)=S\u03c1el(t)S strongly depends on the specific realization of the radical pair, in particular on the number of the surrounding nuclear spins. Here, we consider a radical pair in which the first electron spin is devoid of hyperfine interactions, while the second electron spin interacts isotropically with one spin-1 nucleus,  nitrogen. In the context of the chemical compass (i.e when the task is determining the magnetic field direction through anisotropic hyperfine interactions), an analogous configuration (with only one spin-1/2 nucleus) has been proposed [3], and numerically characterized [8], as being optimal: Additional nuclear spins would perturb the intuitive \u2018reference and probe\u2019 picture. The Hamiltonian then simplifies to H=-\u03b3eB(S1(z)+S2(z))+|\u03b3e|\u03b1S\u21922\u00b7I\u2192, where \u03b1 is the isotropic hyperfine coupling.", "keyphrases": ["rp re-encount probabl", "chemic compass", "magnet field direct", "h=-\u03b3eb(s1(z)+s2(z))+|\u03b3e|\u03b1s\u21922\u00b7i\u2192", "hyperfin interact", "singlet product", "magnet field intens", "chemic yield", "spin-1/2 nucleu", "anisotrop hyperfin interact", "magnet sensit", "improv the perform of chemic devic", "control scheme", "nuclear spin", "nitrogen", "singlet yield", "b", "spin-1 nucleu", "isotrop hyperfin coupl", "\u03b1", "instantan magnet sensit", "determin the magnet field direct through anisotrop hyperfin interact", "electron spin", "model chemic magnetomet", "chemic devic", "chemic magnetomet", "magnet field", "gs(b,t)\u2261\u2202fs(b,t)\u2202b", "realiz of the radic pair", "(2)\u03bbs(b)\u2261\u2202\u03c6s(b)\u2202b=\u222b0\u221epre(t)gs(b,t)dt", "analog configur"]}
{"file_name": "S0045782515001899", "text": "In recent years, the Discontinuous Galerkin (DG) method has emerged as a more thorough alternative for locally solving conservation laws of the shallow water equations with higher accuracy\u00a0 [21\u201327]. The DG method further involves finite element weak formulation to\u2013inherently from conservation principles\u2013shape a piecewise-polynomial solution over each local discrete cell, via local basis functions. On this basis, the DG polynomial accuracy is spanned by a set of coefficients, describing accuracy information, which are all locally evolved in time from conservation principles at the discrete level, with an arbitrary order of accuracy. A DG-based shallow water model appeals in providing higher quality solutions on very coarse meshes than a traditional finite volume counterpart, but is comparatively expensive to run and imposes a more restrictive stability condition for the CFL number\u00a0 [28,29].", "keyphrases": ["shallow water equat", "cfl number", "solv conserv law of the shallow water equat", "shape a piecewise-polynomi solut over each local discret cell", "dg-base shallow water model", "dg method", "local basi function", "finit element weak formul", "discontinu galerkin", "dg polynomi accuraci", "dg", "conserv principl", "veri coars mesh"]}
{"file_name": "S2212667812000883", "text": "The 21st century in the face of an aging population trend, the health status of the elderly is a hot issue of social concern, therefore, to explore the health status of the Chinese population aging and the elderly, elderly fitness exercise Misunderstanding study and formulate measures and methods of fitness of the elderly, promoting elderly fitness training towards a healthy, scientific direction, to promote a nationwide fitness activities carried out in order to achieve the exercise of scientific fitness of older persons.", "keyphrases": ["exercis of scientif fit", "explor the health statu", "promot a nationwid fit activ", "age popul trend", "formul measur and method of fit", "elderli fit train"]}
{"file_name": "S2212667814000732", "text": "The retrospective assessment of environmental carrying capacity aims to obtain the historical development situation of reclamation domain, it's an essential tool for improving the managed level and guiding the environmental management of reclamation. In this paper, a synthetic assessment method based on cloud theory is applied to evaluate the single factor and multiple factors environmental carrying capacity in Caofeidian marine district, Tangshan Bay, China. With the field data of five assessment indexes in recent six years, the assessment results are obtained which show that the marine reclamation has a certain impact for the marine environment.", "keyphrases": ["environment carri capac", "retrospect assess of environment carri capac", "synthet assess method", "field data", "improv the manag level", "marin reclam", "environment manag of reclam", "synthet assess method base on cloud theori is appli", "obtain the histor develop situat of reclam domain", "cloud theori", "guid the environment manag of reclam"]}
{"file_name": "S0167931712002936", "text": "A 3D finite element based (FEM) COMSOL capacitance analysis is combined with Monte Carlo single-electron circuit simulations to model device operations during single electron detection. The 3D structural data (Figure 1b) of the nanoscale DQD pair and multiple gate electrodes are precisely input into COMSOL\u2019s FEM-based electrostatics simulator. Capacitances between different device components are then extracted and fed into the well-tested single electron circuit simulator SETSPICE [11], based on the orthodox theory of single electron tunnelling [12]. For our target d1 of 60nm, simulation results (Figure 1c) showed that as we sweep the voltage applied on gate G1, VG1, single electron tunnelling into the turnstile\u2019s two QDs should generate shifts in the electrometer current, IDS, of tens of pA. This is well within the charge sensitivity of DQD electrometer [6] and consistent to the same order of magnitude with previous work in single electron detection [13]. In addition, the gate to QD capacitive coupling appear to be sufficient for the control of QD occupations down to the single electron limit, allowing for future manipulation of single electron spins in qubit research.", "keyphrases": ["multipl gate electrod", "gate", "dqd electromet", "nanoscal dqd pair", "simul", "orthodox theori", "singl electron tunnel", "comsol\u2019 fem-bas electrostat simul", "gate g1", "target d1", "3d finit element base (fem) comsol capacit analysi", "3d structur data", "electromet current", "manipul of singl electron spin", "singl electron detect", "vg1", "qubit research", "shift in the electromet current", "id", "model devic oper dure singl electron detect", "turnstile\u2019 two qd", "setspic", "qd capacit coupl", "devic compon", "well-test singl electron circuit simul", "control of qd occup", "mont carlo single-electron circuit simul", "singl electron spin"]}
{"file_name": "S0021999115008372", "text": "The need to represent scale interactions in weather and climate prediction models has, for many decades, motivated research into the use of adaptive meshes [3,34,38]. R-adaptivity \u2013 mesh redistribution \u2013 involves deforming a mesh in order to vary local resolution and was first considered for atmospheric modelling more than twenty years ago by Dietachmayer and Droegemeier [14]. It is an attractive form of adaptivity since it does not involve altering the mesh connectivity, does not create load balancing problems because points are never created or destroyed, does not require mapping of solutions between meshes [26], does not lead to sudden changes in resolution and can be retro-fitted into existing models. Variational methods exist which attempt to control resolution in different directions for r-adaptive meshes ( [23,25]). Alternatively, the solution of the Monge\u2013Amp\u00e8re equation to generate an optimally transported (OT) mesh based on a scalar valued monitor function is a useful form of r-adaptive mesh generation because it generates a mesh equidistributed with respect to a monitor function and does not lead to mesh tangling [7]. We will see that the optimal transport problem on the sphere leads to a slightly different equation of Monge\u2013Amp\u00e8re type, which has not before been solved numerically on the surface of a sphere, which would be necessary for weather and climate prediction using r-adaptivity.", "keyphrases": ["adapt mesh", "map of solut between mesh", "deform a mesh", "adapt", "sphere", "atmospher model", "repres scale interact", "alter the mesh connect", "r-adapt mesh", "control resolut in differ direct for r-adapt mesh", "mesh", "weather and climat predict model", "r-adapt mesh gener", "weather and climat predict", "mesh tangl", "r-adapt", "optim transport problem on the sphere", "scalar valu monitor function", "optim transport (ot) mesh", "monge\u2013amp\u00e8r equat", "monge\u2013amp\u00e8r", "mesh redistribut", "monitor function", "variat method"]}
{"file_name": "S2212667814000884", "text": "Many models have been propounded for forecasting lightning. Though majority of the model had shown accuracy, the response time in detecting natural phenomenon is quite low. In this model, we used the mathematical experimentation of the micro scale plasmas to develop the macro scale atmospheric plasma which we believe is a major influence of lightning. The Schr\u00f6dinger-electrostatic algorithm was propounded to further increase both the accuracy and alacrity of detecting natural phenomena. According to our theoretical experimentation, the air density plays a major role in lightning forecast. Our guess was verified using the Davis Weather Station to track the air density both in the upper and lower atmosphere. The air density in the upper atmosphere showed prospect as a vital factor for lightning forecast.", "keyphrases": ["mathemat experiment", "air", "forecast lightn", "lightn", "upper atmospher", "macro scale atmospher plasma", "detect natur phenomena.", "micro scale plasma", "theoret experiment", "track the air densiti", "model", "natur phenomenon", "schr\u00f6dinger-electrostat algorithm", "davi weather station"]}
{"file_name": "S2212667812000895", "text": "Faced with deficient ability of autonomic learning among learners and low emotional involvement in current web-based instructional environment, here we propose a construct model that is based on inter-subjectivity fusing cognition with emotion to make up for these shortages. Further more, we\u2019ve put the construct model into practice through the online teaching reformation of the quality course apparel production and management.", "keyphrases": ["onlin teach reform", "propos a construct model", "web-bas instruct environ", "autonom learn", "low emot involv", "construct model", "fuse cognit with emot"]}
{"file_name": "S0167273814004548", "text": "Two different micro-contact set-ups were used in the experiments. The asymmetrically heated measurement set-up (Figure\u00a02a) allows to change the contacted electrode within seconds and thereby to gain statistical information over a large number of different microelectrodes on one and the same sample in a relatively short time. It also enables monitoring of optical changes during the measurement in real time. However, the asymmetrical heating from the bottom side and local cooling ( by convection, radiation, and the contacting tip acting as a heat sink) is known to cause temperature gradients within the sample [11]. Such temperature gradients are responsible for thermo-voltages, which can lead to measurement artifacts in electrochemical experiments [24]. Moreover, in this set-up temperature cycles can hardly be performed on single microelectrodes but require subsequent contacting and de-contacting of different microelectrodes.", "keyphrases": ["contact tip", "chang the contact electrod", "asymmetr heat", "temperatur cycl", "microelectrod", "heat sink", "convect", "gain statist inform", "temperatur gradient", "electrochem experi", "radiat", "contact and de-contact of differ microelectrod", "electrod", "micro-contact set-up", "asymmetr heat measur set-up", "local cool", "monitor of optic chang"]}
{"file_name": "S221450951400031X", "text": "This phase was completed in 2005. Previous contracts had been procured with the contractor providing the detailed design. For this system the design was undertaken by Mott MacDonald. It was developed by looking at the systems installed previously and calculating what was actually required to achieve cathodic protection of the piers. This resulted in a significant reduction in the number of zones and monitoring probes. The varying amounts of steelwork in the beams had previously lead to up to 5 zones per beam, with multiple layers of mesh to achieve the design current density. On review of the data the operating current density was similar in all zones and so this was reduced to a single zone per beam. The encapsulation was susceptible to ASR and contained post tensioning and so it was decided to use a galvanic system based on Galvashield CC anodes from Fosroc. Our design did not include an option to allow depolarization of the galvanic system, but the contractor supplied one, such that the anodes could be remotely disconnected. The control unit was from Electrotech CP and operated via a broadband connection provided by the contractor.", "keyphrases": ["asr", "data", "encapsul", "galvan system", "detail design", "vari amount of steelwork", "galvashield cc anod", "depolar of the galvan system", "signific reduct in the number of zone and monitor probe", "system instal previous", "broadband connect", "look at the system instal previous and calcul", "cathod protect of the pier", "multipl layer of mesh"]}
{"file_name": "S2214509515300103", "text": "Another important reason for the damages incurred by the RC buildings is workmanship defects. It is understood that granulometry of the handmade concretes was not in compliance with the standards since the aggregate utilized in them was not sieved. Also the compaction process was not properly implemented in general in the installment of concrete in RC buildings. This situation resulted in the concrete to exhibit an excessively porous structure. The most fundamental rules of thumb of construction, namely concrete cover, was not taken care of in formwork workmanship. Faults in the connections of stirrups to the longitudinal bars, unstaggered formation of stirrup hooks in beams and columns, the perpendicular angles of the hooks, inadequately anchorage lengths of the stirrup hooks and longitudinal bars, and the use of cold joints were the other frequently encountered workmanship defects (Figs.", "keyphrases": ["unstagg format of stirrup", "concret", "beam", "fault in the connect of stirrup", "granulometri of the handmad concret", "stirrup hook", "use of cold joint", "concret cover", "workmanship defect", "compact process", "hook", "longitudin bar", "column", "inadequ anchorag length", "instal of concret", "perpendicular angl"]}
{"file_name": "S088523081530036X", "text": "Note that the presented architecture works at the frame level, meaning that each single frame (plus its corresponding context) is fed-forward through the network, obtaining a class posterior probability for all of the target languages. This fact makes the DNNs particularly suitable for real-time applications because, unlike other approaches (i.e i-vectors), we can potentially make a decision about the language at each new frame. Indeed, at each frame, we can combine the evidence from past frames to get a single similarity score between the test utterance and the targetlanguages. A simple way of doing this combination is to assume that frames are independent and multiply the posterior estimates of the last layer. The score sl for language l of a given test utterance is computed by multiplying the output probabilities pl obtained for all of its frames; or equivalently, accumulating the logs as:(6)sl=1N\u2211t=1Nlogp(Ll|xt\u200b,\u2009\u03b8)where p(Ll|xt\u200b,\u2009\u03b8) represents the class probability output for the language l corresponding to the input example at time t, xt by using the DNN defined by parameters \u03b8.", "keyphrases": ["evid from past frame", "combin the evid from past frame", "other approach", "multipli the output probabl pl obtain for all of it frame", "dnn", "accumul the log as:(6)sl=1n\u2211t=1nlogp(ll|xt\u200b, \u03b8)", "assum that frame are independ and multipli the posterior estim of the last layer", "test utter", "i-vector", "target languag"]}
{"file_name": "S1359646214000165", "text": "The first-principles calculations are performed using the Cambridge Serial Total Energy Package (CASTEP) [21] which implements the plane-wave pseudopotential DFT method. The exchange correlation functional is approximated using the generalized gradient approximation (PBE-GGA) [22], and the electron\u2013ion interactions are described by Vanderbilt-type ultrasoft pseudopotentials [23]. The plane wave basis set is truncated at a cutoff of 400eV, and the Brillouin-zone sampling was performed using the Monkhorst-Pack scheme with a k-point spacing in reciprocal space of 0.04\u00c5\u22121. Tests show that these computational parameters give results that are sufficiently accurate for present purposes. The ferromagnetism of nickel is accounted for by performing all calculations using spin polarization, starting at a ferromagnetic initial configuration and relaxing towards its ground state. However, for all compositions considered, the ground state electronic structure of each alloy is found to exhibit only very weak ferromagnetism, and the effect is not thought to influence their phase stability. Table 1 shows the calculated equilibrium lattice constants of the \u03b7 phase at various Ti concentrations, using partially ordered \u03b7P structures. The change in lattice constant upon Ti alloying is relatively small, but can be related to the \u223c10% larger covalent radius of Ti. The calculated lattice constants are in good agreement with the experimental values, which relate to an alloy with a Al/Ti ratio of \u223c2.75.", "keyphrases": ["cambridg serial total energi packag", "ferromagnet", "electron\u2013ion interact", "alloy", "k-point space", "electron", "al", "pbe-gga", "exchang correl function", "brillouin-zon sampl", "castep", "ion", "gener gradient approxim", "nickel", "plane wave", "first-principl calcul", "vanderbilt-typ ultrasoft pseudopotenti", "plane-wav pseudopotenti dft method", "ti alloy", "monkhorst-pack scheme", "\u03b7p structur", "ti", "spin polar"]}
{"file_name": "S002199911200068X", "text": "Myocardial electrical propagation can be simulated using the monodomain or bidomain PDEs [5,6]. Due to its capacity to represent complex geometries with ease, approximations are often obtained using the finite element method (FEM) to discretise the PDEs in space on realistic cardiac geometry meshes; this results in very large (up to forty-million degrees of freedom (DOF) for human heart geometries) systems of linear equations which must be solved many thousands of times over the course of even a short simulation. Thus, they are extremely computationally demanding, presenting taxing problems even to high-end supercomputing resources. This computational demand means that effort has been invested in developing efficient solution techniques, including work on preconditioning, parallelisation and adaptivity in space and time [7\u201312]. In this study, we investigate the potential of reducing the number of DOF by using a high-order polynomial FEM [13\u201315] to approximate the monodomain PDE in space, with the goal of significantly improving simulation efficiency over the piecewise-linear FEM approach commonly used in the field [16\u201319]. For schemes where the polynomial degree p of the elements is adjusted according to the error in the approximation, this is known as the finite element p-version. In the work presented here, we work with schemes which keep p fixed.", "keyphrases": ["finit element p-version", "simul", "high-end supercomput resourc", "geometri", "investig the potenti of reduc the number of dof", "high-ord polynomi fem", "system of linear equat", "finit element method", "cardiac geometri mesh", "myocardi electr propag", "fem", "adapt in space and time", "simul effici", "monodomain pde", "significantli improv simul effici", "monodomain or bidomain pde", "precondit", "parallelis", "human heart geometri", "pde", "piecewise-linear fem", "develop effici solut techniqu"]}
{"file_name": "S0032386110001667", "text": "Note that the quantitative introduction of a reactive functionality into the polymer chain end can be easily achieved by adopting the living ROMP technique especially using the Schrock type molybdenum alkylidene initiator [7,12,21,61\u201365]. The exclusive preparation of end-functionalized ring-opened polymers (realized by a living polymerization with quantitative initiation) can be applied not only to prepare block copolymers (ABCs) coupled with another living polymerization techniques [66], but also for preparation of macromonomers, as described below. In contrast, the initiation efficiency is not always perfect as seen in the molybdenum alkylidene initiators, because dissociation of ligand (PR3 etc.) should be required to generate the catalytically active species in the ROMP with the ruthenium carbene catalysts (Scheme 2) [67\u201369]. An equilibrium between coordination and dissociation of PR3 should be present even in the propagation process, and replacement of halogen with the other anionic ligand (and/or replacement of PR3 with the other neutral donor ligands/substrates) can also be considered as the probable side reactions. Importance of using the molybdenum catalysts should be thus emphasized for their precise preparations, although the initiators are highly sensitive to moisture and both monomers and solvent have to be thus strictly purified to avoid the catalyst decomposition (deactivation).", "keyphrases": ["prepar of end-function ring-open polym", "ruthenium carben catalyst", "ligand", "deactiv", "gener the catalyt activ speci in the romp", "prepar of macromonom", "schrock type molybdenum alkyliden initi", "pr3", "polym chain end", "catalyst", "dissoci", "decomposit", "propag process", "ring-open polym", "macromonom", "live polymer techniqu", "live romp techniqu", "halogen", "monom", "anion ligand", "quantit introduct of a reactiv function into the polym chain end", "abc", "live polymer with quantit initi", "solvent", "molybdenum catalyst", "neutral donor ligands/substr", "block copolym", "molybdenum alkyliden initi", "coordin", "romp"]}
{"file_name": "S037026930400680X", "text": "Certainly therefore the see-saw mechanism is an attractive explanation of why the light neutrino masses are so small. However, it is not without its faults. In particular, there is a tension between the strongly hierarchical nature of the observed Yukawa couplings in the quark and charged lepton sectors, and the essentially hierarchy-free masses implied by the \u0394m2's. Moreover, both the \u03b812 and \u03b823 mixing angles are large while the angle\u00a0\u03b813 is small which is in sharp contrast with the corresponding mixings in the quark sector which are all small. These problems can be solved in specific models, for example, the \u0394m2 values can be fitted by taking the spectrum of rhd neutrino masses to be hierarchical in such a way as to almost compensate for the hierarchical neutrino Yukawa couplings. But this has the price of introducing a wide range of rhd neutrino masses MR\u223c1010\u20131015 which then require explanation.", "keyphrases": ["light neutrino mass", "yukawa coupl", "charg lepton sector", "quark", "rhd neutrino mass", "yukawa coupl in the quark and charg lepton sector", "mr\u223c1010\u20131015", "\u03b4m2 valu can be fit by take the spectrum of rhd neutrino mass", "see-saw mechan", "hierarchy-fre mass impli by the \u03b4m2'", "\u03b812 and \u03b823 mix angl", "hierarch neutrino yukawa coupl", "the angl \u03b813", "quark sector"]}
{"file_name": "S0022311515301653", "text": "Uranium carbide was traditionally used as fuel kernel for the US version of pebble bed reactors as opposed to the German version based on uranium dioxide. For the Generation IV nuclear systems, mixed uranium\u2013plutonium carbides (U, Pu) C constitute the primary option for the gas fast reactors (GFR) and UCO is the first candidate for the very high temperature reactor (VHTR). In the former case the fuel high actinide density and thermal conductivity are exploited in view of high burnup performance. In the latter, UCO is a good compromise between oxides and carbides both in terms of thermal conductivity and fissile density. However, in the American VHTR design, the fuel is a 3:1 ratio of UO2:UC2 for one essential reason, well explained by Olander [2] in a recent publication. During burnup, pure UO2 fuel tends to oxidize to UO2+x. UO2+x reacts with the pyrocarbon coating layer according to the equilibrium:(1)UO2+x\u00a0+\u00a0xC\u00a0\u2192\u00a0UO2\u00a0+\u00a0xCO", "keyphrases": ["gener iv nuclear system", "gfr", "oxid", "uo2", "(u, pu) c", "veri high temperatur reactor", "uco", "burnup", "uranium carbid", "fuel kernel", "uo2 fuel", "uranium dioxid", "pebbl bed reactor", "uc2", "xc", "xco", "ga fast reactor", "actinid", "mix uranium\u2013plutonium carbid", "carbid", "uo2+x", "pyrocarbon coat layer", "fuel", "vhtr"]}
{"file_name": "S0370269304007634", "text": "I also could not resist mentioning another wild speculation [10]. Many years ago, inspired by the almost exact correspondence between Einstein's post-Newtonian equations of gravity and Maxwell's equations of motion I proposed the gravitipole in analogy with Dirac's magnetic monopole. After Dirac there was considerable debate on how a field theory of magnetic monopoles may be formulated. Eventually, 't Hooft and Polyakov showed that the magnetic monopole exists as an extended solution in certain non-abelian gauge theories. Most theorists now believe that electromagnetism is merely a piece of a grand unified theory and that magnetic monopoles exist. Might it not turn out that Einstein's theory is but a piece of a bigger theory and that gravitipoles exist? In grand unified theory the electromagnetic field is a component of a multiplet. Could it be that the gravitational field also somehow carries an internal index and that the field we observe is just a component of a multiplet? Throwing caution to the wind, I also asked in [10] if the gravitipole and the graviton might not form a representation under some dual group just as the magnetic monopole and the photon form a triplet under the dual group of Montonen and Olive\u00a0[11].", "keyphrases": ["gravit field", "einstein' post-newtonian equat of graviti", "dirac' magnet monopol", "photon", "electromagnet", "electromagnet field", "gravitipol", "graviton", "field theori of magnet monopol", "maxwell' equat of motion", "non-abelian gaug theori", "magnet monopol"]}
{"file_name": "S0021999115003459", "text": "The boundary element method (BEM) has clear advantages when applied to shape optimisation of high-voltage devices, see [4\u20138] for an introduction to BEM. First of all, BEM relies only on a surface discretisation so that there is no need to maintain an analysis-suitable volume discretisation during the shape optimisation process. Moreover, BEM is ideal for solving problems in unbounded domains that occur in electrostatic field analysis. In gradient-based shape optimisation the shape derivative of the cost functional with respect to geometry perturbations is needed [9\u201311]. To this purpose, we use the adjoint approach and solve the primary and the adjoint boundary value problems with BEM. The associated linear systems of equations are dense and an acceleration technique, such as the fast multipole method [12,13], is necessary for their efficient solution. For some recent applications of fast BEM in shape optimisation and Bernoulli-type free-boundary problems we refer to [14\u201316].", "keyphrases": ["adjoint approach", "shape optimis", "shape optimis of high-voltag devic", "primari and the adjoint boundari valu problem", "bernoulli-typ free-boundari problem", "shape deriv", "fast multipol method", "solv problem in unbound domain", "fast bem in shape optimis", "boundari element method", "electrostat field analysi", "surfac discretis", "bem", "gradient-bas shape optimis"]}
{"file_name": "S0167931712003012", "text": "We evaluated three spin-on carbon hardmasks from Irresistible Materials [12]. The spin-on carbon compositions were dissolved in a suitable solvent such as chloroform or anisole with a concentration in the range 5\u201350g/l. In this report, film thickness measurements were made for IM-HM11-01 and IM-HM11-02 films, whilst IM-HM11-03 was used for etching; further investigations to compare the performance of the different compositions across tasks are underway. Films of the SoC were prepared by spin coating on hydrogen-terminated silicon substrates with a speed varying between 800 and 2000 RPM for 60s. After spin coating the film was baked for 2min at temperatures of up to 330\u00b0C. In order to enable further processing, the SoC should be rendered insoluble in typical solvents for resist and spin-on-hardmask to enable further processing. The elution behavior of films of IM-HM11-01 and IM-HM11-02 for thicknesses between 30 and 325nm was tested as a function of the baking temperature. Figure 1 shows the normalized film thickness of two formulations of the SoC (IM-HM11-01 and IM-HM11-02), before and after dipping in monochlorobenzene (MCB):IPA 1:1 solution. Prior to baking the thickness of IM-HM11-01 was \u223c320nm, and the thickness of IM-HM11-02 was \u223c250nm. For temperatures above 190\u00b0C the IM-HM11-02 film was rendered insoluble, whilst a temperature of 260\u00b0C was required to achieve the same for IM-HM11-01. Film thickness did not affect the elution results.", "keyphrases": ["ake for 2min at temperatur of up to 330\u00b0c", "befor and after dip", "mcb", "monochlorobenzen", "bake", "soc (", "etch", "compar the perform of the differ composit across task", "soc", "spin-on-hardmask", "evalu three spin-on carbon hardmask from irresist materi", "chloroform", "hydrogen-termin silicon substrat", "film of the soc", "im-hm11-02", "im-hm11-01", "three spin-on carbon hardmask", "im-hm11-03", "im-hm11-02 film", "film", "solvent", "spin coat", "elut behavior", "anisol", "film thick measur", "im-hm11-01 and im-hm11-02", "spin-on carbon composit"]}
{"file_name": "S0370269304005829", "text": "Let us now consider the case of a beta-beam source. Similarly to the case of a static tritium source, an advantage of the beta-beams is that the neutrino fluxes can be very accurately calculated. Figure\u00a03 shows the electron\u2013neutrino scattering events in the range of 0.1\u00a0MeV to 1\u00a0MeV and 1\u00a0keV to 10\u00a0keV, respectively. (In Figure\u00a03(b) we have rounded to the nearest integer number of counts.) The shape of the flux-averaged cross sections is very similar to the reactor case as reflected in the event rates shown in the figures. As can be seen, by measuring electron recoils in the keV range with a beta-beam source one could, with a sufficiently strong source, have a very clear signature for a neutrino magnetic moment of 5\u00d710\u221211\u03bcB. These figures are for Helium-6 ions, however, similar results can be obtained using neutrinos from 18Ne. The results shown are obtained for an intensity of 1015\u00a0\u03bd/s (i.e., 1015\u00a0\u00a0ions/s). If there is no magnetic moment, this intensity will produce about 170 events in the 0.1 MeV to 1 MeV range per year and 3 events in the 1 keV to 10 keV range per year. These numbers increase to 210 and 55, respectively, in the case of a magnetic moment of 5\u00d710\u221211\u03bcB.", "keyphrases": ["electron recoil", "electron\u2013neutrino scatter", "neutrino magnet moment", "reactor case", "electron", "neutrino", "neutrino flux", "static tritium sourc", "beta-beam", "helium-6 ion", "beta-beam sourc"]}
{"file_name": "S0301932213000487", "text": "As already discussed, in dilute flows the choice between the hard sphere and soft sphere models largely depends on the computational time spent to solve the particle equation of motion. For very dilute flows, the hard sphere model is the most natural choice. However, when the collisions can no longer be assumed as binary and instantaneous, the soft sphere model is the only realistic option. It is interesting to know whether the choice of the collision model affects the statistics. Figure 14 compares the mean velocity obtained from both models with the experimental data. The same comparison is performed for the smooth walls. The differences between the hard and soft sphere models for the smooth walls are almost negligible. However, the differences between the hard and soft sphere models for the rough walls are minor. This is because the rough wall treatment in the soft sphere implementation adds extra virtual walls during the collision of a particle with a wall, which is a more realistic representation of a rough wall compared to the hard sphere rough wall treatment where one random wall is considered. This is because, a soft sphere collision is not instantaneous and occurs over a finite amount of time. Similarly, the same effects are observed on the fluid statistics. However, Figure 15, which compares the particle velocity fluctuations, shows that the differences are somewhat larger. Additionally, the differences in both particle mean and RMS velocity profiles are because the hard sphere collisions are unfortunately heavily dependent on the tangential coefficient of restitution (\u03c8); the effects by varying this quantity are shown in Figs. 16 and 17.", "keyphrases": ["hard sphere and soft sphere model", "hard sphere collis", "soft sphere model", "hard and soft sphere model", "wall", "rough wall treatment", "soft sphere implement", "virtual wall", "fluid", "particl", "hard sphere model", "random wall", "collis model", "hard sphere rough wall treatment", "smooth wall", "soft sphere collis", "rough wall", "solv the particl equat of motion", "dilut flow"]}
{"file_name": "S0022311515303640", "text": "Ferritic and martensitic steels are candidate materials for use in nuclear reactors [1,2]. The transmutation-created inert gas, especially He, plays an important role in the microstructural evolution of these steels under neutron irradiation. In a previous paper [3] the mechanisms by which He in a perfect body-centred-cubic (bcc) Fe lattice, can agglomerate into bubbles was discussed. It was shown that small He interstitial clusters are highly mobile but become effectively pinned with the emission of Fe interstitials when the clusters contain 5 or more He atoms. Small bubbles up to around 1.5\u00a0nm in diameter can easily form at room temperature from such seed points but larger bubbles are more difficult to form by diffusion alone due to the induced strain in the bcc lattice which increases the energy barriers for diffusion towards the bubbles whilst reducing them in a direction away from the bubbles. Subsequent bubble enlargement can then only occur either through increased temperature or by radiation induced mechanisms which increase the number of vacancies in the bubble and reduce the lattice strain. Emission of interracial loops from such a bubble was not observed in molecular dynamics simulations.", "keyphrases": ["body-centred-cub", "diffus", "induc strain", "he interstiti cluster", "fe interstiti", "transmutation-cr inert ga", "bcc lattic", "lattic strain", "ferrit and martensit steel", "mechan by which he in a perfect body-centred-cub (bcc) fe lattice, can agglomer into bubbl", "molecular dynam simul", "emiss of interraci loop", "bubbl enlarg", "steel", "reduc the lattic strain", "he", "bubbl", "neutron irradi", "nuclear reactor", "bcc", "fe lattic", "he atom", "radiat induc mechan", "microstructur evolut of these steel under neutron irradi"]}
{"file_name": "S1877750315000460", "text": "FabHemeLB is a Python tool which helps automate the construction and management of ensemble simulation workflows. FabHemeLB is an extended version of FabSim [27] configured to handle HemeLB operations. Both FabSim and FabHemeLB help to automate application deployment, execution and data analysis on remote resources. FabHemeLB can be used to compile and build HemeLB on any remote resource, to reuse machine-specific configurations, and to organize and curate simulation data. It can also submit HemeLB jobs to a remote resource specifying the number of cores and the wall clock time limit for completing a simulation. The tool is also able to monitor the queue status on remote resources, fetch results of completed jobs, and can conveniently combine functionalities into single one-line commands. In general, the FabHemeLB commands have the following structure:", "keyphrases": ["fetch result of complet job", "execut", "autom applic deployment, execut and data analysi on remot resourc", "python tool", "fabhemelb", "monitor the queue statu on remot resourc", "simul data", "simul", "autom the construct and manag of ensembl simul workflow", "deploy", "hemelb", "organ and curat simul data", "combin function into singl one-lin command", "fabsim", "data analysi"]}
{"file_name": "S0370269304009116", "text": "We prove the uniqueness of the supersymmetric Salam\u2013Sezgin (Minkowski)4\u00d7S2 ground state among all non-singular solutions with a four-dimensional Poincar\u00e9, de\u00a0Sitter or anti-de\u00a0Sitter symmetry. We construct the most general solutions with an axial symmetry in the two-dimensional internal space, and show that included amongst these is a family that is non-singular away from a conical defect at one pole of a distorted 2-sphere. These solutions admit the interpretation of 3-branes with negative tension.", "keyphrases": ["de sitter or anti-d sitter symmetri", "construct the most gener solut", "non-singular solut with a four-dimension poincar\u00e9", "prove the uniqu", "3-brane with neg tension", "axial symmetri in the two-dimension intern space,", "interpret of 3-brane with neg tension", "non-singular away from a conic defect"]}
{"file_name": "S0927025614006181", "text": "The Discrete Element Method applied to spheres is well established as a reasonably realistic tool, in a wide range of engineering disciplines, for modelling packing and flow of granular materials; Asmar  [8] describes the fundamentals of this method as applied by code developed in-house at Nottingham; since these are widely documented the details are not reproduced here, simply a summary. It applies an explicit time stepping approach to numerically integrate the translational and rotational motion of each particle from the resulting forces and moments acting on them at each timestep. The inter-particle and particle wall contacts are modelled using the linear spring\u2013dashpot\u2013slider analogy. Contact forces are modelled in the normal and tangential directions with respect to the line connecting the particles centres. Particle elastic stiffness is set so sphere \u201coverlap\u201d is not significant and moderate contact damping is applied. Particle cohesion can also be modelled but is assumed to be negligible in the current study. The translational and rotational motion of each particle is modelled using a half step leap-frog Verlet numerical integration scheme to update particle positions and velocities. Near-neighbour lists are used to increase the computational efficiency of determining particle contacts and a zoning method is used each time the list is composed; that is the system is divided into cubic regions, each particle centre is within one zone, and potential contacting particles are within the same or next-door neighbour zones. Full details are given in Asmar  [8].", "keyphrases": ["translat and rotat motion", "particl contact", "granular materi", "contact particl", "discret element method", "particl posit", "sphere", "inter-particl and particl wall contact", "contact damp", "half step leap-frog verlet numer integr scheme", "explicit time step approach", "zone method", "particl centr", "particl elast stiff", "near-neighbour list", "moment", "model pack and flow of granular materi", "linear spring\u2013dashpot\u2013slid analog", "particl", "sphere \u201coverlap\u201d", "forc", "numer integr", "particl cohes", "particl elast", "veloc", "contact forc"]}
{"file_name": "S0370269303017222", "text": "In the bag model and in linear or harmonic oscillator confining potentials, the first excited S-state lies above the lowest P-state, making the predicted Roper mass heavier than the lightest negative parity baryon mass. Pairwise spin-dependent interactions must reverse the level ordering. As mentioned earlier, color-spin interactions fail in this regard\u00a0[29], while flavor-spin interactions produce the desired effect. Since the q3 color wave function is antisymmetric, the flavor-spin-orbital wave function is totally symmetric. For all quarks in an S-state, the flavor-spin wave function is totally symmetric all by itself and leads to the most attractive flavor-spin interaction. If one quark is in a P-state, the orbital wave function is mixed symmetry and so is the flavor-spin wave function, and the flavor-spin interaction is a less attractive. In the SU(3)F symmetric case, Eq. (1), one obtains mass splittings (2)\u0394M\u03c7=\u221214C\u03c7,N(939),N\u2217(1440),\u22124C\u03c7,\u0394(1232),\u22122C\u03c7,N\u2217(1535). Here we have approximated the N\u2217(1535) as a state with total quark spin-1/2.", "keyphrases": ["color-spin interact", "quark", "bag model", "orbit wave function", "flavor-spin interact", "pairwis spin-depend interact", "flavor-spin-orbit wave function", "level order", "oscil confin potenti", "q3 color wave function", "flavor-spin wave function", "quark spin", "mass split"]}
{"file_name": "S0375960113010839", "text": "The goal of the glued trees (GT) algorithm for quantum search is the following: beginning from the left-most vertex of a given GT graph, traverse the graph and reach the right-most vertex, referred to as the target vertex. Childs  [1] use this algorithm to show quantum walk search to be fundamentally more effective than classical random walk search by presenting a class of graphs (the GT graphs) that force classical random walks to make exponentially many queries to an oracle encoding the structure of the graph, but that are traversable by quantum walks with a polynomial number of queries to such an oracle. In order to study the robustness of the algorithm to the detrimental effects of decoherence, we shall determine how effectively it achieves its goal when subjected to an increasing degree of phase damping noise. For this reason, we will focus on the probability that the walker is on the target vertex at the end of the walk. We thus consider GT graphs such as the one illustrated in Figure 1(b), i.e consisting of n layers before the gluing stage, and thus labelled as G\u2032n.", "keyphrases": ["glu stage", "increas degre of phase damp nois", "quantum walk search", "gt graph", "quantum search", "classic random walk search", "class of graph", "classic random walk", "glu tree", "graph", "gt"]}
{"file_name": "S0029549314002970", "text": "The design, and the temperature reached in the sample holders, guarantees that the Na remains liquid during operation to improve the heating transfer and avoiding solid formation (too cold working temperature) or sodium boiling (too hot working temperature). The temperature above and just below the Na surface will be monitored by six dedicated thermocouples. In order to prevent oxidation of the Na, the plenum of the 1st containment is filled with high-purity He at 0.1MPa, sealed after final assembly and kept closed during in-pile operation (no gas circulation in the 1st containment). The heat generated by fission and gamma absorption in the materials will be radially dissipated through the Na bath, the structural materials and the gas gaps by conduction and radiation to the downstream primary coolant of the TRIO wet channel.", "keyphrases": ["ga", "na", "solid format", "na bath", "oxid", "sampl holder", "improv the heat transfer", "ga circul", "sodium", "na surfac", "high-pur he", "trio wet channel", "fission and gamma absorpt", "sodium boil", "monitor by six dedic thermocoupl"]}
{"file_name": "S0370269304006768", "text": "In our study we illustrate the properties of gauge invariant extensions of local functionals. We aim at clarifying, via specific examples, the relation between a functional which is local in a particular gauge (but not necessarily gauge invariant), and its gauge invariant extension (which is not necessarily local). We show that the non-localities found are not perturbatively local because they cannot be expressed in terms of an infinite derivative expansion. We believe that the implications of this observation have not been clearly emphasised in the literature, as attested by the absence of any debate about it in recent works. It is precisely these dangerous infrared modes that make it hard to define a gauge independent renormalisation for the gauge invariant extensions of local functionals. This observation supports the remark in [2] that the expectation value receives important contributions from both large and small distances. Our arguments on renormalisability are based on the notion of renormalisation in the modern sense [8] which relies on BRST cohomology theorems. The BRST terminology will therefore be frequently used here, even though it is not always necessary.", "keyphrases": ["notion of renormalis", "it gaug invari extens", "gaug independ renormalis", "invari extens of local function", "brst terminolog", "brst cohomolog theorem", "non-loc found", "nfinit deriv expans", "expect valu", "renormalis", "function which is local in a particular gaug", "infrar mode", "gaug invari extens of local function"]}
{"file_name": "S0370269304009104", "text": "Though, in this Letter we have constructed the Born\u2013Infeld black holes in the presence of a cosmological constant and discussed their thermodynamical properties, many issues however still remain to be investigated. We know that Reissner\u2013Nordstr\u00f6m AdS black holes undergo Hawking\u2013Page phase transition. This transition gets modified as we include Born\u2013Infeld corrections into account. We hope to carry out a detail study on this issue in the future. Furthermore, in the context of brane world cosmology, it was found that a brane moving in a Reissner\u2013Nordstr\u00f6m AdS background generates non-singular cosmology\u00a0[14]. However, as shown in\u00a0[15], the brane always crosses the inner horizon of the bulk geometry, creating an instability. It would be interesting to study cosmology on the brane when it is moving in the charged black hole backgrounds that we have constructed. Note that since these charged holes does not have inner horizon for certain range of parameters, we may generate non-singular cosmology without creating the instabilities that we have just mentioned.", "keyphrases": ["reissner\u2013nordstr\u00f6m ad black hole", "cosmolog", "studi cosmolog on the brane when it is move in the charg black hole background", "charg black hole", "born\u2013infeld black hole", "discuss their thermodynam properti", "non-singular cosmolog", "brane world cosmolog", "hawking\u2013pag phase transit", "construct the born\u2013infeld black hole in the presenc of a cosmolog constant", "gener non-singular cosmolog without creat the instabl", "born\u2013infeld correct", "charg hole", "cross the inner horizon of the bulk geometri", "reissner\u2013nordstr\u00f6m ad background", "brane", "instabl"]}
{"file_name": "S0370269304007439", "text": "In contrast to the H particle, the situation for the \u0398+ baryon is very promising. Thus, in this Letter we explore the formation of the \u0398+-baryon within a new approach called parton-based Gribov\u2013Regge theory. It is realized in the Monte Carlo program NEXUS 3.97 [22,23]. In this model high energy hadronic and nuclear collisions are treated within a self-consistent quantum mechanical multiple scattering formalism. Elementary interactions, happening in parallel, correspond to underlying microscopic (predominantly soft) parton cascades and are described effectively as phenomenological soft pomeron exchanges. A pomeron can be seen as layers of a (soft) parton ladder, which is attached to projectile and target nucleons via leg partons. At high energies one accounts also for the contribution of perturbative (high pt) partons described by a so-called \u201csemihard pomeron\u201d\u2014a piece of the QCD parton ladder sandwiched between two soft pomerons which are connected to the projectile and to the target in the usual way. The spectator partons of both projectile and target nucleons, left after pomeron emissions, form nucleon remnants. The legs of the pomerons form color singlets, such as q\u2013q\u0304, q\u2013qq or q\u0304\u2013q\u0304q\u0304. The probability of q\u2013qq and q\u0304\u2013q\u0304q\u0304 is controlled by the parameter\u00a0Pqq and is fixed by the experimental yields on (multi-)strange baryons [23].", "keyphrases": ["mont carlo program", "perturb (high pt) parton", "projectil and target nucleon", "\u03b8+ baryon", "parton-bas gribov\u2013regg theori", "microscop (predominantli soft) parton cascad", "nexu 3.97", "elementari interact", "phenomenolog soft pomeron exchang", "q\u2013q\u0304", "pomeron emiss", "self-consist quantum mechan multipl scatter formal", "pomeron", "the format of the \u03b8+-baryon", "spectat parton", "fix by the experiment yield on (multi-)strang baryon", "high energi hadron and nuclear collis", "leg parton", "q\u0304\u2013q\u0304q\u0304", "q\u2013qq", "(soft) parton ladder", "nucleon remnant", "color singlet", "\u201csemihard pomeron\u201d", "(multi-)strang baryon", "piec of the qcd parton ladder sandwich between two soft pomeron which are connect to the projectil and to the target in the usual way"]}
{"file_name": "S0098300414002532", "text": "The threshold values for removing large caters were determined by examining the craters within the study area, referencing previous studies (Molloy and Stepinski, 2007), and some trial and error. After the parameter values are determined, the rest of the process is automated. However, we do anticipate some minimum manual editing may be needed in some complicated terrains when apply it to all of Mars. To minimize the distortion resulted from map projection on global datasets, we will choose an equal area projection by evaluating the options suggested in Steinwand  (1995) or conduct geodesic area calculation using software such as \u201cTools for Graphics and Shapes\u201d (http://www.jennessent.com/arcgis/shapes_graphics.htm)Although post-formational modification to the valleys may be minimum (Williams and Phillips, 2001), there may nonetheless be modifications such as eolian fill and mass wasting (, Grant , 2008). Thus the volume estimates derived with PBTH method represents a lower bound. Comparing the estimates from MOLA and HRSC data reveals that MOLA estimate is about 91% of HRSC value. However, MOLA has global coverage whereas HRSC does not. Therefore, for areas where there is only MOLA coverage, the estimate may be scaled upward by 1.1 times. The algorithm has been tested on DEMs with various resolutions (2 m for simulated DEM, 75m for HRSC, and 463m for MOLA). It can certainly be applied to higher resolution DEMs for Mars when they become available, but the threshold values will need to be adjusted.", "keyphrases": ["hrsc", "dem", "the threshold valu for remov larg cater were determin", "tool for graphic and shape", "pbth method", "manual edit", "mola"]}
{"file_name": "S0377025715000051", "text": "A convenient and widely reported technique for detection of the GP involves measurements of the complex shear modulus, G\u2217, over a range of frequencies, \u03c9, in oscillatory shear. At the GP the elastic and viscous components of the complex modulus, G\u2032 and G\u2033, respectively scale in oscillatory frequency, \u03c9, as G\u2032(\u03c9)\u223cG\u2033(\u03c9)\u223c\u03c9\u03b1 where \u03b1 is termed the stress relaxation exponent [15]. Thus, the GP may be identified as the instant where the G\u2032 and G\u2033 scale in frequency according to identical power laws [15], behaviour corresponding to attainment of a frequency independent phase angle, \u03b4(=atan(G\u2033/G\u2032)). GP measurements may involve \u2018frequency sweeps\u2019 with repeated consecutive application of a set of small amplitude oscillatory shear, SAOS, waveforms [15,16], or by Fourier Transform Mechanical Spectroscopy, FTMS, in which G\u2217(\u03c9) is found by simultaneous application of several harmonic frequencies in a composite waveform and its subsequent Fourier analysis [17,18]. Frequency sweeps are limited to relatively slow gelation processes due to sample mutation and interpolation errors [9,19,20]. FTMS may overcome these limitations, but is unsuitable for markedly strain sensitive materials, such as fibrin gels, due to the strain amplitude of the composite waveform exceeding the linear viscoelastic range (LVR) [9].", "keyphrases": ["sao", "applic of sever harmon frequenc", "small amplitud oscillatori shear", "fourier analysi", "markedli strain sensit materi", "gp measur", "gelat process", "composit waveform", "ftm", "fibrin gel", "detect of the gp", "fourier transform mechan spectroscopi", "waveform", "measur of the complex shear modulu", "frequenc sweep"]}
{"file_name": "S1877750311000676", "text": "One way to enforce this ratio is to use a probabilistic, \u2018roulette wheel\u2019 style lane selection policy. VISSIM, along with most simulation toolkits, offers methods to specify probabilistic routing whereby a defined percentage of vehicles are sent down unique routes. This is a piecewise technique that can be reapplied at various locations around a simulation. While these methods are attractive from a calibration perspective as exact representations of existing statistics can be ensured, the process is an unrealistic one as it assumes that drivers make probabilistic decisions at precise locations. So in this case when a vehicle arrives at a point prior to the weighbridges it is allocated one of the lanes based on the respective probabilities. It turns out that this method leads to significant variations in trip times depending on the initial random number seed, this can be seen in a graphic of the key areas of the simulation for the 2 different runs (Figure 7). One of the benefits of graphical microsimulation is that the 2D and 3D simulations help the researcher to visualise a new scheme and its potential benefits but also to highlight unrealistic behaviour. Figure 7 shows the congestion at the decision point for 2 different runs. Using probabilistic routing to enforce correct routing percentages is a clear case of overcalibration affecting simulation brittleness.", "keyphrases": ["piecewis techniqu", "driver", "vissim", "probabilistic, \u2018roulett wheel\u2019 style", "weighbridg", "lane select polici", "simul", "vehicl", "2d and 3d simul", "graphic microsimul", "probabilist rout", "simul toolkit"]}
{"file_name": "S0370269304008858", "text": "The reason to investigate the BFKL and DGLAP equations in the case of supersymmetric theories is based on a common belief, that the high symmetry may significantly simplify the structure of these equations. Indeed, it was found in the leading logarithmic approximation (LLA)\u00a0[10], that the so-called quasi-partonic operators in N=1 SYM are unified in supermultiplets with anomalous dimensions obtained from universal anomalous dimensions \u03b3uni(j) by shifting its arguments by an integer number. Further, the anomalous dimension matrices for twist-2 operators are fixed by the superconformal invariance\u00a0[10]. Calculations in the maximally extended N=4 SYM, where the coupling constant is not renormalized, give even more remarkable results. Namely, it turns out, that here all twist-2 operators enter in the same multiplet, their anomalous dimension matrix is fixed completely by the super-conformal invariance and its universal anomalous dimension in LLA is proportional to \u03a8(j\u22121)\u2212\u03a8(1), which means, that the evolution equations for the matrix elements of quasi-partonic operators in the multicolor limit Nc\u2192\u221e are equivalent to the Schr\u00f6dinger equation for an integrable Heisenberg spin model\u00a0[11,12]. In QCD the integrability remains only in a small sector of the quasi-partonic operators\u00a0[13]. In the case of N=4 SYM the equations for other sets of operators are also integrable\u00a0[14\u201316]. Evolution equations for quasi-partonic operators are written in an explicitly super-conformal form in Ref.", "keyphrases": ["evolut equat for the matrix element of quasi-parton oper in the multicolor limit nc\u2192\u221e", "twist-2 oper", "n=4 sym", "anomal dimens obtain from univers anomal dimens \u03b3uni(j) by shift it argument by an integ number", "high symmetri may significantli simplifi the structur of these equat", "super-conform invari", "evolut equat for quasi-parton oper", "lla", "fix by the superconform invari", "investig the bfkl and dglap equat in the case of supersymmetr theori", "anomal dimens matrix", "anomal dimens matric for twist-2 oper", "lead logarithm approxim", "calcul in the maxim extend n=4 sym, where the coupl constant is not renorm"]}
{"file_name": "S030439911200040X", "text": "Some methods use 1D radial profiles obtained from circular averaging of 2D experimental PSD [4,8,11] or by elliptical averaging [17]. An inadequacy of circular averaging is that it neglects astigmatism. Astigmatism distorts the circular shape of the Thon rings and thus decreases their modulation depth in the obtained 1D profile. A few algorithms that consider astigmatism involve concepts such as dividing the PSD into sectors where Thon rings are approximated by circular arcs [15,21], applying Canny edge detection to find the rings [17] prior to elliptical averaging, determining the relationship between the 1D circular averages with and without astigmatism [22], or using a brute-force scan of a database containing precalculated patterns as in ATLAS [23]. Some other approaches for estimating CTF parameters do a fully 2D PSD optimization [12,14,18,20] but they usually regulate and fit numerous parameters by an extensive search that does not guarantee convergence. Furthermore, only a few schemes that were developed for defocus estimation provide an error analysis [23,24].", "keyphrases": ["ellipt averag", "psd", "2d experiment psd", "thon ring", "ctf", "astigmat", "atla", "1d profil", "1d radial profil", "2d psd optim", "canni edg detect", "circular averag"]}
{"file_name": "S2212671612001709", "text": "An algorithm of multi-axis NC tool-path generation for subdivision surfaces is proposed. The algorithm includes two steps: model building and tool path generation. In the section of model building, in order to obtain the deformed surface, the deformation vector is computed which is associated with the curvature and the slope of cutter location surface. In the procedure of tool path generation, the slicing procedure is adopted to get the CL points. In addition, the inversely converted method is used. The method is tested by some examples with actual machining. The results show that the method can effectively reduce the error of the scallop height for subdivision surface and obtain the better shape and quality. In addition, the computational complexity and is scalable and robust.", "keyphrases": ["tool path gener", "curvatur and the slope of cutter locat surfac", "test by some exampl with actual machin", "algorithm of multi-axi nc tool-path gener for subdivis surfac", "invers convert method", "cl point", "subdivis surfac", "obtain the deform surfac", "algorithm", "scallop height", "some exampl with actual machin", "slice procedur", "cutter locat surfac", "model build", "deform vector is comput", "deform vector", "algorithm of multi-axi nc tool-path gener"]}
{"file_name": "S0010938X14000420", "text": "One surface was then polished and cleaned using a protocol designed to eliminate as much preparation-related contamination as possible. This is as follows: The lead surface was polished by hand using a damp abrasive disc (BuehlerMet II \u00ae) to remove visible surface defects and to expose a fresh metal surface. Coupons were then polished using a sequence of diamond polishes with decreasing particle sizes (6\u03bcm, 3\u03bcm, 1\u03bcm Buehler MetaDi \u00ae polycrystalline diamond suspension). A polishing cloth (Buehler MicroCloth \u00ae) was saturated with the appropriate diamond suspension. A custom-made jig fitted to an automatic polisher (Buehler Minimet \u00ae 1000) was used to hold the coupons in place during automated polishing. Coupons were polished for 15min using each diamond suspension followed by rinsing with 2-propanol (99.5%, reagent grade) and cleaning in 2-propanol for 5min in an ultrasonic bath. After polishing with the 1\u03bcm diamond suspension, the coupons were ultrasonically cleaned in 2-propanol for 3\u00d75min, with fresh propanol for each cleaning cycle. Polished coupons were stored in 2-propanol until required.", "keyphrases": ["diamond suspens", "custom-mad jig", "metal surfac", "diamond", "polish cloth", "polycrystallin diamond", "propanol", "2-propanol", "ultrason bath", "clean", "coupon", "surfac", "polish", "damp abras disc", "diamond polish", "autom polish"]}
{"file_name": "S0045782513000546", "text": "In this article we consider an extension to the equations of poroelasticity by modelling the flow of a slightly compressible single phase fluid in a viscoelastic porous medium. The constitutive equations therefore allow for the presence of viscoelastic relaxation effects in the porous media (but not the fluid). Fully discrete numerical schemes are derived based on a lagged and non-lagged backward Euler time stepping method applied to a mixed and Galerkin finite element spatial discretization. We show that the lagged scheme is unconditionally stable and give an optimal a priori error bound for it. Furthermore, this scheme is practical and useful in the sense that it can be easily implemented in existing poroelasticity software because the coupling between the viscous stresses and pressures and the elasticity and flow equations is \u2018lagged\u2019 by one time step. The required additional coding therefore takes the form of extra \u2018right hand side loads\u2019 together with some updating subroutines for the viscoelastic internal variables, but the solver and assembly engines remain intact. This idea of lagging has been used before for nonlinearly viscoelastic diffusion problems in [3,24] but, of course, is not new. Lagging in numerical schemes is discussed more widely by Lowrie in [14].", "keyphrases": ["fulli discret numer scheme", "flow equat", "constitut equat", "singl phase fluid", "viscoelast relax effect", "viscoelast porou medium", "coupl", "model the flow of a slightli compress singl phase fluid in a viscoelast porou medium", "nonlinearli viscoelast diffus problem", "lag and non-lag backward euler time step method", "numer scheme", "porou media", "mix and galerkin finit element spatial discret", "updat subroutin", "assembl engin", "fluid", "extens to the equat of poroelast"]}
{"file_name": "S0168365913004975", "text": "The \u03b1-\u03c9-aminohexylcarbamate derivative of cyanocobalamin was prepared using a method described previously [18]. Briefly, solid CDI (260mg, 0.32mmol) was added to cyanocobalamin (1.0g, 0.148mmol) previously dissolved in anhydrous dimethyl sulfoxide. The mixture was stirred for up to 2h at 30\u00b0C, followed by the addition of dry 1,6-hexanediamine (314mg, 0.54mmol) and stirring of the mixture at room temperature over 24h. The mixture was poured into ethyl acetate (30ml) and left to stand. Following centrifugation and decanting of the supernatant, the residue was sonicated for 5min in acetone (50ml). The resulting precipitate was filtered and the solid washed in acetone. The crude product was purified by silica column chromatography (45% v/v 2-propanol, 30% v/v n-butanol, 2% v/v ammonia and 25% v/v water) followed by lyophilisation.", "keyphrases": ["butanol", "supernat", "ethyl acet", "lyophilis", "silica column chromatographi", "ammonia", "centrifug", "residu", "water", "dri 1,6-hexanediamin", "anhydr dimethyl sulfoxid", "precipit", "\u03b1-\u03c9-aminohexylcarbam deriv of cyanocobalamin", "aceton", "crude product", "propanol", "solid", "decant", "cyanocobalamin", "solid cdi"]}
{"file_name": "S002199911300346X", "text": "Contact methods have been developed and used in Lagrangian staggered-grid hydrodynamic (SGH) calculations for many years. Early examples of contact methods are discussed in Wilkins [37] and Cherry  [7]. Hallquist  [17] provides an overview of multiple contact algorithms used in various Lagrangian SGH codes dating back to HEMP [37]. Of particular interest, Hallquist  [17] describes the contact surface scheme used in TOODY [31] and later implemented in DYNA2D [36]. The contact method of TOODY uses a master\u2013slave approach. The goal of this approach is to treat the nodes on the contact surface in a manner similar to an internal node. The physical properties of the slave surface are interpolated to a ghost mesh (termed phony elements in [17]) that overlays the slave zones. The physical properties are interpolated from the slave surface to the ghost zones using surface area weights. The surface area weights are equal to the ratio of the ghost zone surface area to the surface area of the master surface. The contact surface method for nodal-based Lagrangian cell-centered hydrodynamics (CCH) presented in this paper will use surface area weights similar in concept to those in TOODY. Following the area fraction approach of TOODY may seem retrospective; however, using surface area weights naturally extends to the new CCH methods that solve a Riemann-like problem at the node of a zone [10,24,25,3].", "keyphrases": ["cell-cent hydrodynam", "slave zone", "ghost zone surfac area", "dyna2d", "node", "phoni element", "cch method", "contact algorithm", "toodi", "solv a riemann-lik problem at the node of a zone", "contact method", "master surfac", "staggered-grid hydrodynam", "cch", "surfac area", "contact surfac", "sgh", "contact surfac scheme", "area fraction approach", "slave surfac", "intern node", "ghost zone", "hemp", "ghost mesh", "master\u2013slav approach", "contact surfac method", "lagrangian sgh", "nodal-bas lagrangian cell-cent hydrodynam"]}
{"file_name": "S0022311514006849", "text": "The early theoretical work of Catlow assessed a number of Willis type clusters and found them all to be stable using potential-based methods [6]. More recently \u201csplit interstitial\u201d type clusters (Figure 1) have emerged from computational studies as stable species following the potential based investigation of Govers  which found the 2:2:2 cluster in a UO2 supercell relaxed to a split di-interstitial [13] (Figure 1(b)); a single VO with three Oi displaced approximately 1.6\u00c5 in \u3008111\u3009 directions from the VO. This result was later confirmed by the LSDA+U calculations of Geng  [7]. The family of split interstitial clusters was extended to include tri-interstitials [8] (a di-interstitial with the fourth Oi site occupied) and quad-interstitials [9] (two di-interstitials on adjacent sites, giving a total of two VO and six Oi) (Figure 1(d)). Following this Andersson  postulated a model for U4O9 based on a UO2 supercell containing multiple split quad-interstitial clusters; following the prediction of their LSDA+U calculations that the quad-interstitial is more stable than its cuboctahedral counterpart [12].", "keyphrases": ["model for u4o9", "potential-bas method", "split interstitial\u201d type cluster", "two di-interstiti on adjac site", "vo", "willi type cluster", "di-interstiti", "oi", "potenti base investig", "a singl vo with three oi", "quad-interstiti", "uo2 supercel", "di-interstiti with the fourth oi site occupi", "split interstiti cluster", "multipl split quad-interstiti cluster", "cuboctahedr", "tri-interstiti", "lsda+u"]}
{"file_name": "S0021999113004555", "text": "Three Runge\u2013Kutta IMEX schemes were tested by Ullrich and Jablonowski [23] for the HEVI solution of the equations governing atmospheric motion. They tested the ARS(2,3,2) scheme of Ascher  [1] and also suggested the less computationally expensive but nearly as accurate Strang carryover scheme. This involves Strang splitting but the first implicit stage is cleverly re-used from the final implicit stage of the previous time-step and so there is only one implicit solution per time-step. Another novel approach taken by Ullrich and Jablonowski [23] is to use a Rosenbrock solution in order to treat all of the vertical terms implicitly rather than just the terms involved in wave propagation. A Rosenbrock solution is one iteration of a Newton solver. This circumvents the time-step restriction associated with vertical advection at the cost of slowing the vertical advection.", "keyphrases": ["runge\u2013kutta imex scheme", "ars(2,3,2) scheme", "atmospher motion", "time-step restrict", "vertic advect", "one iter of a newton solver", "wave propag", "rosenbrock solut", "slow the vertic advect", "newton solver", "hevi solut", "strang split", "strang carryov scheme"]}
{"file_name": "S0168365913009589", "text": "Ultrasound (US) can initiate the release of drugs from liposomes via an event called inertial cavitation, whereby the rarefactional phase of an ultrasound wave causes the expansion of a gas bubble followed by a violent collapse due to the inertia of the surrounding media. This collapse creates shock waves which can disrupt the stability of co-localised liposomal drug carriers. To date, studies have concentrated on the use of low frequency or high intensity US to generate gas bubbles in situ, and most recently such parameters have been used to achieve a variable level of triggered drug release following an intratumoral injection of liposomes [14]. However, concerns persist over the damage to non-target tissue that such US exposure parameters may cause and whether ultimately they will be widely clinically applicable. An alternative strategy is to utilise high-frequency US pulses at pressures in the diagnostic range in the presence of pre-existing gas bubbles. This provides an inertial cavitation stimulus for drug release using safe, clinically achievable US exposure conditions and approved US contrast agents [15]. Indeed, in the context of improving the delivery of therapeutics such as oncolytic viruses, this approach has already shown great promise [16]. A further advantage of this approach is that US-induced cavitation events produce distinct acoustic emissions that can be recorded and characterised providing non-invasive feedback, a feature which has proven useful in ablative US applications [17\u201319].", "keyphrases": ["liposom", "inerti cavit", "ultrasound", "us contrast agent", "us", "us-induc cavit", "oncolyt virus", "intratumor inject", "ga bubbl"]}
{"file_name": "S0301010414003115", "text": "The optimised structure at the B3LYP/aug-cc-pVTZ level was then used to perform calculations of the lowest electronic singlet excited states with the coupled cluster linear response (LR) coupled cluster hierarchy CCS, CC2, CCSD and CC3, along with perturbative corrected methods CIS(D) and CCSDR(3). The correlated response methods were performed with an all-electron atomic natural orbital (ANO) basis set contracted to 6s5p4d3f1g on manganese, [47] together with the cc-pVTZ basis set on the oxygen atoms. The all-electron correlated calculations invoked a 13 orbital frozen core (O 1s, Mn 1s2s2p3s3p). Trial calculations correlating these orbitals only had a minor effect on excitation energies. For comparison the EOM-CCSD method with the cc-pVTZ basis on all atoms was tested to compare with LR-CCSD. These formally give exactly the same excitation energies, although the transition moments are more accurate for LR-CCSD. Abelian symmetry (D2) was used in all correlated excited state calculations.", "keyphrases": ["o", "lowest electron singlet", "linear respons", "cc3", "b3lyp/aug-cc-pvtz", "cc-pvtz", "lr", "excit state calcul", "ccsd", "transit moment", "cc2", "mn", "all-electron correl calcul", "perturb correct method", "cc", "cis(d)", "d2", "eom-ccsd method", "manganes", "coupl cluster hierarchi", "ccsdr(3)", "ano", "atom natur orbit", "6s5p4d3f1g", "optimis structur", "lr-ccsd", "excit energi", "abelian symmetri", "correl respons method", "oxygen"]}
{"file_name": "S0038092X15001681", "text": "For the reverse current analysis, for both scenarios (shading and short circuits) were tested on two systems, one system using standard silicon modules and another system using high efficiency modules. For the standard silicon system, a power of 50kWp was considered, with a system composed by 10 strings of 24 modules per string and an approximate system Voc of 864 [VDC]. For the high efficiency system, a power of 40kWp was considered, with a system composed by 10 strings of 18 modules per string and an approximate system Voc of 873 [VDC]. Figure 5(a) shows the reverse current present in one string when different numbers of modules in the string are shaded by 90%. Figure 5(b) shows the reverse current present in one string when different numbers of modules of the string are short-circuited. For both figures the continuous lines are for the standard silicon system and the dashed lines are for the high efficiency system.", "keyphrases": ["system", "vdc", "voc of 873", "voc of 864", "high effici modul", "high effici system", "10 string of 24 modul per string", "standard silicon modul", "standard silicon system", "10 string of 18 modul per string", "differ number of modul of the string are short-circuit", "revers current analysi", "revers current"]}
{"file_name": "S0370269304006161", "text": "Absorption events through the charged current reactions (2)\u03bde+40Ar\u2192e\u2212+40K\u2217and\u03bd\u0304e+40Ar\u2192e++40Cl\u2217. There is some uncertainty in predicting e\u2212(e+) event rates for these processes which arise due to the nuclear model dependencies of the absorption cross section and the treatment of the Coulomb distortion of electron (positron) in the field of the residual nucleus. The nuclear absorption cross section for the charged current neutrino reactions in 40Ar relevant to supernova neutrino energies was first calculated by Raghavan\u00a0[10] and Bahcall \u00a0[11] for Fermi transitions leading to isobaric analogue state (IAS) at 4.38\u00a0MeV in 40K\u2217. Later Ormand \u00a0[12] used a shell model to calculate the Fermi and Gamow\u2013Teller transitions. In these calculations Fermi function F(Z,Ee) was used to take into account the Coulomb effects. In a recent paper Bueno \u00a0[13] make use of a calculation by Martinez-Pinedo \u00a0[14] who use a shell model for Fermi and Gamow\u2013Teller transitions and a continuum random phase approximation (CRPA) for forbidden transitions to calculate the absorption cross sections. In this calculation the Coulomb distortion of the produced electron is treated with a hybrid model where a Fermi function is used for lower electron energies and modified effective momentum approximation (MEMA) for higher electron energies\u00a0[14\u201317]. In a recent work Bhattacharya \u00a0[18] have measured the Fermi and Gamow\u2013Teller transition strengths leading to excited states up to 6\u00a0MeV in 40K\u2217 and obtained the neutrino absorption cross section for supernova neutrinos in 40Ar.", "keyphrases": ["absorpt event through the charg current reaction", "neutrino absorpt cross section", "treatment of the coulomb distort", "electron", "isobar analogu state", "nuclear absorpt cross section for the charg current neutrino reaction", "ia", "supernova neutrino energi", "shell model", "4.38 mev in 40k", "crpa", "shell model for fermi and gamow\u2013tel transit", "residu nucleu", "continuum random phase approxim", "the absorpt cross section", "modifi effect momentum approxim", "mema", "coulomb effect", "calcul by martinez-pinedo et al.", "fermi and gamow\u2013tel transit strength", "positron", "the fermi and gamow\u2013tel transit", "nuclear model depend", "predict e\u2212(e+) event rate"]}
{"file_name": "S2212667812000822", "text": "It has been more than a century since the emergence of the lettered words. After that, with the development of economy and culture, the increase of international contacts and communication between China and foreign countries, lettered words have been appearing more frequently. Lettered words have become an indispensable part of Chinese vocabulary, such as WTO, Ka la OK and MP3. As a new phenomenon in the vocabulary system of the modern Chinese, the lettered words draws a lot of academic attention. Ecolinguistics is a new branch of linguistic, which combine the linguistic with the ecology. This paper is trying to analyze the lettered words from the perspective of Ecolinguistics. This paper will discuss the reasons of appearing the lettered words and the influence may give to modern Chinese form the ecolinguistic view.", "keyphrases": ["analyz the letter word from the perspect of ecolinguist", "wto", "mp3", "ecolinguist", "letter word", "chines vocabulari", "discuss the reason of appear the letter word", "commun", "ka la ok", "vocabulari system", "develop of economi and cultur", "combin the linguist with the ecolog", "branch of linguist"]}
{"file_name": "S0370269304007816", "text": "We define a new multispecies model of Calogero type in D dimensions with harmonic, two-body and three-body interactions. Using the underlying conformal SU(1,1) algebra, we indicate how to find the complete set of the states in Bargmann\u2013Fock space. There are towers of states, with equidistant energy spectra in each tower. We explicitely construct all polynomial eigenstates, namely the center-of-mass states and global dilatation modes, and find their corresponding eigenenergies. We also construct ladder operators for these global collective states. Analysing corresponding Fock space, we detect the universal critical point at which the model exhibits singular behavior. The above results are universal for all systems with underlying conformal SU(1,1) symmetry.We define a new multispecies model of Calogero type in D dimensions with harmonic, two-body and three-body interactions. Using the underlying conformal SU(1,1) algebra, we indicate how to find the complete set of the states in Bargmann\u2013Fock space. There are towers of states, with equidistant energy spectra in each tower. We explicitely construct all polynomial eigenstates, namely the center-of-mass states and global dilatation modes, and find their corresponding eigenenergies. We also construct ladder operators for these global collective states. Analysing corresponding Fock space, we detect the universal critical point at which the model exhibits singular behavior. The above results are universal for all systems with underlying conformal SU(1,1) symmetry.", "keyphrases": ["conform su(1,1) algebra", "analys correspond fock space", "construct all polynomi eigenst", "multispeci model", "defin a new multispeci model of calogero type in d dimens", "construct ladder oper", "harmonic, two-bodi and three-bodi interact", "equidist energi spectra", "find their correspond eigenenergi"]}
{"file_name": "S0885230816300043", "text": "The final set of experiments involved an adaptive retraining of the GMM\u2013HMM parameters following the aNAT procedure. This new model only provided an improvement of 0.3%, similar to using the aCMLLR transforms on the baseline GMM\u2013HMM model. However, training show-based aCMLLR transforms on top of the adaptively trained model boosted the improvement to 0.8% absolute. This showed how adaptive training provided a better flexibility of the model to adapt to specific background conditions existing in each show. Finally, the factorisation approach using MLLR speaker transforms on top of the aNAT model and show-based aCMLLR transforms was tested. This only increased the improvement to 0.9% absolute (2.9% relative), which reflects the difficulty of performing accurate speaker clustering in this task and how this actually hampers speaker adaptation.", "keyphrases": ["anat model", "adapt retrain of the gmm\u2013hmm paramet", "train show-bas acmllr transform", "speaker adapt", "anat procedur", "speaker cluster", "gmm\u2013hmm model", "adapt train", "factoris approach use mllr speaker transform", "acmllr transform"]}
{"file_name": "S0022311515301963", "text": "Following fission, noble gas atoms will be distributed in the fuel matrix initially accommodated at point defects trap sites, generally thought to be Schottky trivacancy defects [4,5,31]. Diffusion to either bubbles or grain boundaries is then facilitated by associating a further uranium vacancy defect for the gas atom to \u2018hop\u2019 into, with the original vacancy then able to loop around to ensure continued diffusion. The rate determining step in the process is not the migration of the Xe itself but rather the rearrangement of the VU defect to facilitate net Xe diffusion [6\u20138]. Activation energies for the overall process depend on the availability of the defect trap sites, which in turn depends on the crystal stoichiometry. For Xe diffusion in UO2\u2212x, UO2 and UO2+x the activation energies calculated using DFT are 7.04\u201312.92\u00a0eV, 4.15\u20137.88\u00a0eV and 1.38\u20134.07\u00a0eV with the ranges reflecting the way the calculations were performed depending on the charge states of the defects involved and the presence of a Jahn\u2013Teller distortion [7]. Activation energies calculated using empirical pair potentials can vary strongly depending on the choice of potential. Govers et\u00a0al examined three different potentials for UO2 (those of Basak [9], Jackson [10] and Morelon [11]) coupled with different parameterisations for the U\u2013Xe and O\u2013Xe interactions from Geng [12] and Nicoll [13] and recommend values of 6.5\u00a0eV, 4.5\u00a0eV and 2.4\u00a0eV [6] for the different stoichiometric regimes in very good agreement with the experimental values of 6.0\u00a0eV, 3.9\u00a0eV and 1.7\u00a0eV respectively [14].", "keyphrases": ["xe", "charg", "crystal", "point defect trap site", "o\u2013x", "vu defect", "fission", "uo2", "\u2018hop\u2019 into", "diffus", "activ", "migrat", "grain boundari", "vu", "defect trap site", "dft", "uo2\u2212x", "u\u2013x", "jahn\u2013tel distort", "bubbl", "ga atom", "nobl ga atom", "uranium", "potenti", "crystal stoichiometri", "fuel matrix", "uo2+x", "schottki trivac defect", "empir pair potenti", "loop around", "rearrang", "xe diffus"]}
{"file_name": "S0098300412001793", "text": "MINERAL (MINeral ERror AnaLysis) is a new MATLAB\u00ae based program that provides mineral formula recalculations combined with the associated propagation of the analytical uncertainties. Methods are based on the work of Giamarita and Day (1990). However, additional features have been added to provide users with greater flexibility in data reporting. Many programs exist to recalculate wt% data into formula unit cations. Some generalized programs can be used to recalculate the formula of multiple minerals  CALCMIN (Brandelik, 2009) and HYPER-FORM (De Bjerg , 1992). Other programs are mineral specific  AMPH CLASS (Esawi, 2004) and PROBE AMPH (Tindle and Webb, 1994) for the recalculation of amphibole analyses; ILMAT (Lepage, 2003) for the recalculation of magnetite and ilmenite; and PX-NOM (Sturm, 2002) for the recalculation of pyroxene analyses. MINERAL provides a rapid method for the recalculation of multiple common minerals. However, its strength lies in the fact that is the first tool to incorporate the associated uncertainty propagation calculations. As these are performed concurrently with the standard recalculations, no additional time is needed to perform uncertainty propagation. While an understanding of the underlying calculations is strongly recommended, MINERAL is designed to allow users with little or no experience operating MATLAB\u00ae and/or performing mineral formula recalculations and uncertainty propagation to undertake both with ease.", "keyphrases": ["probe amph", "miner (miner error analysis)", "recalcul of magnetit and ilmenit", "some gener program", "allow user with littl or no experi oper matlab\u00ae and/or perform miner formula recalcul and uncertainti propag to undertak both with eas", "method", "hyper-form", "to provid user with greater flexibl in data report", "recalcul of amphibol analys", "a new matlab\u00ae base program", "px-nom", "ilmat", "provid miner formula recalcul combin with the associ propag of the analyt uncertainti", "recalcul of multipl common miner", "amph class", "recalcul of pyroxen analys", "incorpor the associ uncertainti propag calculations.", "calcmin", "miner", "recalcul the formula of multipl miner"]}
{"file_name": "S2212667813000774", "text": "Evolutionary Algorithms are the stochastic optimization methods, simulating the behavior of natural evolution. These algorithms are basically population based search procedures efficiently dealing with complex search spaces having robust and powerful search mechanism. EAs are highly applicable in multiobjective optimization problem which are having conflicting objectives. This paper reviews the work carried out for diversity and convergence issues in EMO.", "keyphrases": ["natur evolut", "stochast optim method", "ea", "search mechan", "evolutionari algorithm", "optim problem", "review the work carri out for divers and converg issu in emo", "emo", "popul base search procedur"]}
{"file_name": "S0045782512000266", "text": "In this work, a numerical strategy for designing an optimal maintenance scheduling for a structure, accounting explicitly for the effects of uncertainty is suggested. This contribution, which can be regarded as an extension of the methods developed in [23], presents several novel aspects over similar approaches proposed in the literature. Firstly, the initiation and propagation of fatigue crack is modeled efficiently by means of cohesive zone elements [24\u201326]. The application of this class of elements allows modeling the crack initiation and propagation within a unified framework. It should be noted that cohesive zone elements have already been used for uncertainty quantification of the crack propagation phenomenon [27,28]. However its application within the context of maintenance scheduling constitutes a novelty. The second innovative aspect of this contribution refers to the assessment of the reliability sensitivity with respect to the variables that define the maintenance scheduling. The estimation of this sensitivity, which is required in order to determine the optimal maintenance schedule within the proposed framework, can be quite demanding as the model characterizing repair of a cracked structure leads to a discontinuous performance function associated with the failure probability. A new approach for modeling this function is proposed herein. The continuous and discontinuous parts respectively of the function are considered separately to estimate accurately the gradients of the failure events.", "keyphrases": ["model character repair of a crack structur", "assess of the reliabl sensit with respect to the variabl that defin the mainten schedul", "model the crack initi and propag within a unifi framework", "optim mainten schedul within the propos framework", "cohes zone element", "optim mainten schedul for a structur", "mainten schedul", "estim of thi sensit", "numer strategi", "discontinu perform function associ with the failur probabl", "unifi framework", "continu and discontinu part", "uncertainti quantif of the crack propag phenomenon", "initi and propag of fatigu crack", "estim accur the gradient of the failur event", "account explicitli for the effect of uncertainti", "class of element"]}
{"file_name": "S0168365912006207", "text": "Unlike conventional materials used in nerve tissue engineering, PAs can be directly injected in vivo into models and spontaneously self-assemble into nanofibers in aqueous solutions. Furthermore, PAs can function as biomimetic materials exemplified by collagen-mimetic PAs [92]. Conventional materials often rely on electrospinning as a manufacturing method to achieve fiber-like structures suitable for use in nerve regeneration. The self-assembly nature of PAs allows them to circumvent costly manufacturing methods. However, in contrast to conventional manufacturing methods like electrospinning where quality and batch-to-batch variability can be tightly controlled, merely relying on self-assembly as a method of large-scale commercial production is still an experimental concept. Perhaps the next step would be to carefully compare and contrast the robustness of self-assemled PAs to electrospun nanofibers. Given that the constituent elements in PAs and external factors like pH can affect its structural assembly, parameters must be finely tuned and optimized in order for PA nanofibers to be used as a full-fledged commercialized medical product [93].", "keyphrases": ["compar and contrast", "costli manufactur method", "large-scal commerci product", "self-assembl", "collagen-mimet pa", "pa", "achiev fiber-lik structur", "tune and optim", "inject in vivo into model and spontan self-assembl into nanofib in aqueou solut", "biomimet materi", "a full-fledg commerci medic product", "electrospin", "convent manufactur method", "robust of self-asseml pa to electrospun nanofib", "a manufactur method", "pa nanofib"]}
{"file_name": "S2212671612002351", "text": "In this paper, a novel position estimation method of prism was proposed for single-lens stereovision system. The prism with multi faces was considered as a single optical system composed of some refractive planes. A transformation matrix which can express the relationship between an object point and its image by the refraction of prism was derived based on geometrical optics, and a mathematical model was introduced which can denote the position of prism with arbitrary faces only by 7 parameters. This model can extend the application of single-lens stereovision system using prism to a more widely area. Experimentation results are presented to prove the effectiveness and robustness of our proposed model.", "keyphrases": ["refract of prism", "posit estim method", "transform matrix", "mathemat model", "extend the applic of single-len stereovis system", "geometr optic", "imag", "object point", "singl optic system", "single-len stereovis system", "prism", "robust", "effect", "express the relationship", "refract plane"]}
{"file_name": "S0370269304009177", "text": "In the brane system appearing in string/D-brane theory, the stableness is the most important requirement. We find some stable brane configurations in the SUSY bulk-boundary theory. We systematically solve the singular field equation using a general mathematical result about the free-wave solution in S1/Z2-space. The two scalars, the extra-component of the bulk-vector (A5) and the bulk-scalar (\u03a6), constitute the solutions. Their different roles are clarified. The importance of the \u201cparallel\u201d configuration is disclosed. The boundary condition (of A5) and the boundary matter fields are two important elements for making the localized configuration. Among all solutions, the solution (c1=\u22121, c2=\u22121) is expected to be the thin-wall limit of a kink solution. We present a bulk Higgs model corresponding to the non-singular solution. The model is expected to give a non-singular and stable brane solution in the SUSY bulk-boundary theory.", "keyphrases": ["\u03c6", "boundari condit", "bulk higg model", "string/d-bran theori", "kink solut", "solut", "non-singular and stabl brane solut", "bulk-scalar", "stabl brane configur", "brane system", "thin-wal limit", "solv the singular field equat", "differ role are clarifi", "non-singular solut", "extra-compon of the bulk-vector", "a5", "susi bulk-boundari theori", "c1=\u22121, c2=\u22121", "gener mathemat result about the free-wav solut", "stabl"]}
{"file_name": "S0377025714000317", "text": "Denier and Hewitt [12] have shown that bounded solutions to 9a, 9b and 9c subject to (10a) and (10b) exist only in the shear-thinning case for n>12. In the shear-thickening case they have shown that solutions become non-differentiable at some critical location \u03b7c, and although it transpires that this singularity can be regularised entirely within the context of the power-law model, we will not consider such flows here. Thus in this study we will consider flows with power-law index in the range 12<n\u2a7d1. They have also shown that for 12<n<1 to ensure the correct algebraic decay in the numerical solutions one must apply the Robin condition(11)(u\u00af\u2032,v\u00af\u2032)=n\u03b7(n-1)(u\u00af,v\u00af)as\u03b7\u2192\u221e,at some suitably large value of \u03b7=\u03b7\u221e\u226b1. In the Newtonian case this relationship becomes singular, this is due to the fact that when n=1 the functions u\u00af and v\u00af decay exponentially. Cochran [13] showed that in this case(12)(u\u00af\u2032,v\u00af\u2032)=w\u00af\u221e(u\u00af,v\u00af)as\u03b7\u2192\u221e,where w\u221e=-2\u222b0\u221eu\u00afd\u03b7.", "keyphrases": ["solut", "correct algebra decay", "flow", "singular", "power-law model", "robin condition(11)", "shear-thicken"]}
{"file_name": "S0377025715000993", "text": "Equilibrium surface tension was measured at 21\u00b0C with a SITA pro line t-15 bubble tensiometer. Rheological measurements were performed with an ARES rheometer at shear rates up to 15s\u22121 and with a piezo axial vibrator [21] (PAV) at frequencies up to 6kHz. Table 1 shows the measured values of viscosity (the real component \u03b7\u2032 of complex viscosity) at 1s\u22121 and 4000s\u22121 and of surface tension for the solutions with and without the surfactant mixture. For the most concentrated (1.1wt%) solution, viscosity fell from >60mPas at low shear rate to about 4mPas at the highest shear rates. The PEDOT:PSS fluids also exhibited elasticity that steadily reduced with increasing frequency [4]. All the aqueous PEDOT:PSS solutions shear-thinned significantly, but the presence of surfactants did not affect the trends in the rheological behaviour, particularly at the higher frequencies (10\u20134000s\u22121).", "keyphrases": ["pedot:pss fluid", "pedot:pss solut", "rheolog measur", "pav", "sita pro line t-15 bubbl tensiomet", "valu of viscos", "are rheomet", "piezo axial vibrat", "most concentr (1.1wt%) solut", "equilibrium surfac tension", "surfac tension"]}
{"file_name": "S0010938X1500195X", "text": "Poor oxidation behavior is the major barrier to the increased use of Ti-based alloys in high-temperature structural applications. The demand to increase the service temperature of these alloys beyond 550\u00b0C (the typical temperature limit) requires careful study to understand the role that composition has on the oxidation behavior of Ti-based alloys [1\u20133]. The attempt to overcome this limitation in Ti-based alloys has led to the production of alloys with substantially improved oxidation resistance such as \u03b2-21S and also development of coatings and pre-oxidation techniques [1,4\u20136]. While it is tempting to extrapolate the oxidation behavior ( oxidation rate law, depth of oxygen ingress and scale thickness) observed for a limited number of compositions under a certain oxidation condition to a broader compositional range, there are numerous examples in the literature where deviations from the expected relations are observed [7,8].", "keyphrases": ["understand the role that composit ha on the oxid behavior of ti-bas alloy", "alloy", "oxid", "develop of coat and pre-oxid techniqu", "pre-oxid techniqu", "\u03b2-21", "alloy with substanti improv oxid resist", "ti-bas alloy", "coat", "oxygen"]}
{"file_name": "S0022311515300477", "text": "In all these studies, the association between the transition and lateral cracking in the oxide layer depicts some interaction between the mechanical behaviour of the system, and its corrosion kinetics, but does not provide a clear understanding of the morphology of the metal:oxide interface during the corrosion process, at the nanometre level. Understanding why this transition behaviour happens is critical when modelling the rate of growth of oxide, and therefore to the lifetime prediction of Zr clads, and ultimately to the safety of nuclear power reactors. No model will be complete without a nanoscale understanding of what is going on during oxidation. Thus, it is essential that the oxide scale and the top layers of the metal are studied at nanometre resolution to reveal the detailed structural and chemical changes associated with diffusion of oxygen and the resulting oxidation of the metal. Whilst a number of techniques have been employed for this purpose, it is clear that various techniques within transmission electron microscopy (TEM) will be among the most versatile and informative for this purpose, although additional information can be added by techniques such as atom probe tomography.", "keyphrases": ["the metal", "understand of what is go on dure oxid", "diffus of oxygen", "tem", "oxid", "understand of the morpholog of the metal:oxid interfac", "model the rate of growth of oxid", "oxid scale", "nuclear power reactor", "oxid layer", "transmiss electron microscopi", "understand whi thi transit behaviour happen", "corros process", "atom probe tomographi", "zr clad", "oxid of the metal", "structur and chemic chang", "top layer of the metal", "metal:oxid interfac", "oxygen"]}
{"file_name": "S0263822312001468", "text": "Recently together with structural efficiency, passenger safety is also an important issue in application of material to transportation industries. Hence, the crashworthiness parameters are introducing to predict the capability of structure to prevent the massive damage and protect the passenger in the event of a crash. Crashworthiness parameters for various thin-walled tubes made from metal or fibre/resin composites in different geometries have been studied. A critical difference of tubular composites failure modes compared with metallic is the brittle collapse. In addition, in composites, tubular failure modes are involved with micro-cracking development, delamination, fibre breakage, etc., instead of plastic deformation. Implementation of composite materials in the field of crashworthiness is attributed to Hull, who in 80s and 90s of the last century studied extensively the crushing behaviour of fibre reinforced composite material. He found that the composite materials absorbed high energy in the face of the fracture surface energy mechanism rather than plastic deformation as observed for metals [1]. This observation has inspired others to further investigation about crashworthiness characteristics of composite materials. Studies have examined the axial crushing behaviour of fibre-reinforced tubes [2], fibreglass tubes [3,4], PVC tubes [5] and carbon fibre reinforced plastic (CFRP) tubes [6].", "keyphrases": ["fibre-reinforc tube", "carbon fibr reinforc plastic (cfrp) tube", "composit materi", "structur effici", "axial crush behaviour", "transport industri", "tubular failur mode", "crashworthi paramet", "prevent the massiv damag", "tubular composit failur", "protect the passeng", "fractur surfac energi", "brittl collaps", "micro-crack develop", "delamin", "fibr reinforc composit materi", "cfrp", "pvc tube", "crush behaviour", "fibreglass tube", "fibre/resin composit", "metal", "passeng safeti", "fibr breakag", "plastic deform", "implement of composit materi", "carbon fibr reinforc plastic", "crashworthi characterist", "composit"]}
{"file_name": "S0021999115003939", "text": "The extrapolation of the upwind value required for TVD differencing is a particular hurdle for the application on unstructured meshes. As discussed in Section 3.2, two methods to extrapolate the value at the virtual upwind node, using data readily available on unstructured meshes, are considered. Given how the virtual upwind node is incorporated in the gradient ratio rf, the extrapolation method of Darwish and Moukalled [13] is referred to as implicit extrapolation and the method introduced by Ubbink and Issa [12] as explicit extrapolation. Both methods precisely reconstruct the upwind value for equidistant, rectilinear meshes but fail to do so on non-equidistant or non-rectilinear meshes, as discussed in Section 3.2. Using the explicit extrapolation method this issue can be rectified by imposing appropriate limits on the extrapolated upwind value.", "keyphrases": ["darwish and moukal", "virtual upwind node is incorpor in the gradient ratio rf", "equidistant, rectilinear mesh", "tvd differenc", "extrapol of the upwind valu", "non-equidist", "data readili avail on unstructur mesh", "implicit extrapol", "method introduc by ubbink and issa", "unstructur mesh", "non-rectilinear mesh", "explicit extrapol"]}
{"file_name": "S0032386110001254", "text": "Despite the loss of directed, self-complementary hydrogen bonding through alkylation of the imidazole ring, electrostatic aggregation of imidazolium salts is a tunable, self-assembly process, which is instrumental to several applications. Imidazolium salts are used to extract metal ions from aqueous solutions and coat metal nanoparticles [15], dissolve carbohydrates [16], and create polyelectrolyte brushes on surfaces [17]. For example, atom transfer radical\u00a0polymerization (ATRP) was used to graft poly(1-ethyl 3-(2-methacryloyloxy ethyl) imidazolium chloride) brushes onto gold surfaces [17]. One of the imidazolium salt\u2019s most promising attributes is its antimicrobial action [12,18] and molecular self-assembly into liquid crystals [19,20]. 1-Alkyl-3-methylimidazolium chlorides and bromides, 1-alkyl-2-methyl-3-hydroxyethylimidazolium chlorides, and N-alkyl-N-hydroxyethylpyrrolidinonium, for example, all exhibit strong biocidal activity [18]. Hydrogels form from polymerized methylimidazolium-based ionic liquids with acryloyl groups; the polymer self-assembles into organized lamellae with unique swelling properties, leading to bioactive applications [19]. Other bioactive applications for imidazolium salts include antiarrhythmics [21], anti-metastic agents [22,23], and imidazolium-based steroids [24]. Separation applications include efficient absorption of CO2 [25]. Imidazolium salts enhance vesicle formation as imidazolium surfactants [26], and they also find application in polymeric actuators [27].", "keyphrases": ["anti-metast agent", "effici absorpt of co2", "imidazolium-bas steroid", "aqueou solut", "atrp", "metal ion", "n-alkyl-n-hydroxyethylpyrrolidinonium", "separ applic", "carbohydr", "imidazolium surfact", "vesicl format", "atom transfer radic polymer", "1-alkyl-2-methyl-3-hydroxyethylimidazolium chlorid", "hydrogel form", "metal nanoparticl", "poly(1-ethyl 3-(2-methacryloyloxi ethyl) imidazolium chlorid", "co2", "bioactiv applic", "gold surfac", "acryloyl group", "hydrogen bond", "electrostat aggreg", "polyelectrolyt brush", "imidazolium salt", "organ lamella", "polym", "alkyl", "1-alkyl-3-methylimidazolium chlorid", "polymer actuat", "polymer methylimidazolium-bas ionic liquid", "bromid", "antimicrobi action", "liquid crystal", "biocid activ", "antiarrhythm"]}
{"file_name": "S0370269302012492", "text": "In this section we wish to calculate the cross section for the absorption of massless scalars by the self-dual string in the world volume of the M-theory five-brane. We will adopt an entirely world volume approach similar to that of\u00a0[21\u201323]. We begin by writing the equation satisfied by the s-wave with energy \u03c9, \u03c6(r,t)=\u03c6(r)ei\u03c9t, of the linear fluctuations of the four overall transverse scalars about the self-dual string, (it is known that there are problems when one considers higher angular momentum modes [23], one must take care with the validity of the linearized approximation, this is discussed in [13]): (15)\u03c1\u22123dd\u03c1\u03c13dd\u03c1+1+R6\u03c96\u03c16\u03c6(\u03c1)=0, where \u03c1=r\u03c9, R=Q1/3\u2113p. Note, as pointed out by\u00a0[11] world volume solitons have a much sharper potential than the Coulomb type potential typical of brane solutions in supergravity; thus this scattering is different to that of the string in six-dimensional supergravity. Nevertheless, for small \u03c9R one may solve this problem by matching an approximate solution in the inner region to an approximate solution in the outer region; this follows closely the supergravity calculation\u00a0[24].", "keyphrases": ["m-theori five-bran", "entir world volum approach", "approxim solut", "small \u03c9r", "massless scalar", "supergrav calcul", "s-wave", "calcul the cross section for the absorpt of massless scalar", "linear approxim", "linear fluctuat", "brane solut", "higher angular momentum mode", "self-dual string", "world volum soliton"]}
{"file_name": "S0166218X14003011", "text": "We study sequences of optimal walks of a growing length in weighted digraphs, or equivalently, sequences of entries of max-algebraic matrix powers with growing exponents. It is known that these sequences are eventually periodic when the digraphs are strongly connected. The transient of such periodicity depends, in general, both on the size of digraph and on the magnitude of the weights. In this paper, we show that some bounds on the indices of periodicity of (unweighted) digraphs, such as the bounds of Wielandt, Dulmage\u2013Mendelsohn, Schwarz, Kim and Gregory\u2013Kirkland\u2013Pullman, apply to the weights of optimal walks when one of their ends is a critical node.", "keyphrases": ["sequenc of entri of max-algebra matrix power with grow expon", "sequenc of optim walk of a grow length in weight digraph", "digraph are strongli connect", "digraph", "(unweighted) digraph"]}
{"file_name": "S0045782511003823", "text": "In the present work we use the mortar finite element method for the coupling of nonconforming discretized sub-domains in the framework of nonlinear elasticity. The mortar method has been shown to preserve optimal convergence rates (see Laursen (2002) [25] for details) and is variationally consistent. We show that the method can be applied to isogeometric analysis with little effort, once the framework of NURBS based shape functions has been implemented. Furthermore, a specific coordinate augmentation technique allows the design of an energy\u2013momentum scheme for the constrained mechanical system under consideration. The excellent performance of the redesigned mortar method as well as the energy\u2013momentum scheme is illustrated in representative numerical examples.In the present work we use the mortar finite element method for the coupling of nonconforming discretized sub-domains in the framework of nonlinear elasticity. The mortar method has been shown to preserve optimal convergence rates (see Laursen (2002) [25] for details) and is variationally consistent. We show that the method can be applied to isogeometric analysis with little effort, once the framework of NURBS based shape functions has been implemented. Furthermore, a specific coordinate augmentation technique allows the design of an energy\u2013momentum scheme for the constrained mechanical system under consideration. The excellent performance of the redesigned mortar method as well as the energy\u2013momentum scheme is illustrated in representative numerical examples.", "keyphrases": ["mortar method", "framework of nurb base shape function", "optim converg rate", "mortar finit element method", "coupl of nonconform discret sub-domain in the framework of nonlinear elast", "mortar finit element", "constrain mechan system", "mechan system", "isogeometr analysi", "energy\u2013momentum scheme", "converg rate", "coordin augment techniqu"]}
{"file_name": "S0010938X12001163", "text": "In situ oxidation, experiments were carried out using 3mm diameter discs with one surface ground and polished to a 1\u03bcm diamond finish. The 3mm discs were then oxidised in a Philips XL-30 FEG ESEM with a hot stage attachment. The oxidising atmosphere used was laboratory air at a pressure of 266Pa. During the experiment, the sample was observed and imaged using a primary beam energy of 20kV and an Everhart\u2013Thornley secondary electron detector. The sample was heated at a rate of 100\u00b0C/min to a temperature of 700\u00b0C and held at this temperature for 8min to stabilise the stage and the microscope. The sample was then heated to a final temperature of 900\u00b0C at the same heating rate. The total time of exposure of the sample was 120min before cooling to room temperature by turning off the heating coils. The samples were then examined in the LEO 1530VP FEGSEM with chemical information gathered using EDS. Cross-sections and Transmission Electron Microscope (TEM) samples were produced using a dual beam FEI Nova Nanolab 600 for Focused Ion Beam (FIB) milling perpendicular to the phase boundaries to determine their influence on the oxide development and imaged using a Jeol 2000FX W-filament TEM. EDS maps of the TEM samples were collected using the Nanolab 600 with a Scanning TEM (STEM) detector and an EDAX Genesis EDS system at an accelerating voltage of 30kV.", "keyphrases": ["3mm diamet disc", "leo 1530vp fegsem", "tem", "oxid", "oxid develop", "jeol 2000fx w-filament tem", "fib", "transmiss electron microscop", "acceler voltag of 30kv", "edax genesi ed system", "oxidis", "dual beam fei nova nanolab 600", "scan tem (stem) detector", "nanolab 600", "heat coil", "ground and polish", "tem sampl", "heat to a final temperatur of 900\u00b0c", "scan tem", "stem", "stabilis the stage and the microscop", "heat", "philip xl-30 feg esem", "focus ion beam", "ed", "in situ oxid", "hot stage attach"]}
{"file_name": "S0370269304009979", "text": "On the other hand, the other local fields except the gravitational field are not always localized on the brane even in the warped geometry. Indeed, in the Randall\u2013Sundrum model in five dimensions\u00a0[2], the following facts are well known: spin\u00a00 field is localized on a brane with positive tension which also localizes the graviton while the spin 1/2 and 3/2 fields are localized not on a brane with positive tension but on a brane with negative tension\u00a0[6]. Spin\u00a01 field is not localized neither on a brane with positive tension nor on a brane with negative tension\u00a0[7]. In six space\u2013time dimensions, the spin\u00a01 gauge field is also localized on the brane\u00a0[8]. Thus, in order to fulfill the localization of Standard Model particles on a brane with positive tension, it seems that some additional interactions except the gravitational interaction must be also introduced in the bulk. There is a lot of papers devoted to the different localization mechanisms of the bulk fields in various brane world models.", "keyphrases": ["local on the brane", "warp geometri", "brane world model", "five dimens", "local", "neg tension", "randall\u2013sundrum model", "local mechan", "six space\u2013tim dimens", "standard model", "local the graviton", "introduc in the bulk", "posit tension", "spin 0 field is local on a brane"]}
{"file_name": "S2212671612000686", "text": "This paper make the explained variables our financial stress index consist of the synchronous variables financial systemic risk, and make the explanatory variables the macroeconomic variable, currency credit variable, asset price variable and the macroeconomic variable of correlative economic powers, then use stepwise regression method to establish the financial systemic risk best predict equation, thus set up the reasonable and practical financial systemic risk early-warning index system; besides, use the best prediction equations predicts the financial systemic risk status in 2011. The predicted results show that Chinese financial systemic risk is on the rise in the first three quarters and higher than the peak of 2008; financial systemic risk start to decline since the fourth quarter.", "keyphrases": ["stepwis regress method", "financi system risk best predict equat", "macroeconom variabl of correl econom power", "macroeconom variabl", "financi stress index", "establish the financi system risk best predict equat", "currenc credit variabl", "financi system risk early-warn index system", "asset price variabl", "synchron variabl financi system risk", "best predict equat", "set up the reason and practic financi system risk early-warn index system"]}
{"file_name": "S0370269304009037", "text": "Within a coalescence approach as successfully applied earlier in the light-quark sector, we have evaluated transverse-momentum dependencies of charmed hadrons in central heavy-ion reactions at RHIC. For the charm-quark distributions at hadronization we have considered two limiting scenarios, i.e., no reinteractions (using spectra from PYTHIA) and complete thermalization with transverse flow of the bulk matter. The resulting J/\u03c8 (mT-)spectra differ in slope by up to a factor of\u00a02 (harder for pQCD c-quarks), and the integrated yield is about a factor of\u00a03 larger in the thermal case. For D-mesons, we found that the difference in the slope parameters of the pT-spectra in the two scenarios is less pronounced, but their elliptic flow is about a factor of\u00a02 larger for pT\u2a7e1.5\u00a0GeV in the thermalized case. The elliptic flow pattern of D-mesons was found to be essentially preserved in the single-electron decay spectra, rendering the latter a very promising observable to address the strength of charm reinteractions in the QGP. The present study can be straightforwardly generalized to charmed baryons (\u039bc), which may serve as a complimentary probe for charm-quark reinteractions in the QGP.", "keyphrases": ["differ in the slope paramet", "d-meson", "coalesc approach", "ellipt flow pattern", "single-electron decay spectra", "charm hadron", "hadron", "transvers flow", "spectra", "quark", "complimentari probe", "evalu transverse-momentum depend", "charm-quark reinteract", "pqcd c-quark", "central heavy-ion reaction", "ellipt flow", "pt-spectra", "charm reinteract", "baryon", "qgp", "integr yield", "complet thermal", "light-quark sector", "charm-quark distribut"]}
{"file_name": "S2212667814000756", "text": "This study is focused on the water-gas shift reaction (WGSR), occurring in the chemical kinetics equipment, which is used to increase hydrogen recovery from industrial processes. The research deals with comparing hydrogen recovery with the use of three different catalysts. The amount of the produced hydrogen depends considerably on the reaction state and the catalyst composition. To improve the course of the reaction, natural catalysts \u2013 calcite, coal char (unburned residues from coal) and modified olivine \u2013 are added to the gasification process and heated to the process temperature of 800, 850 and 900oC.", "keyphrases": ["ga", "coal char", "industri process", "calcit", "heat", "reaction", "unburn residu from coal", "water-ga shift reaction", "wgsr", "catalyst", "hydrogen", "modifi olivin", "natur catalyst", "water", "hydrogen recoveri", "gasif process", "chemic kinet equip"]}
{"file_name": "S221266781200007X", "text": "In this paper, the design of a varnish plant at Crocodile Matchet Limited, Tema, Ghana was considered and modification made to eliminate blooming and rusting of its product at the final processing plant when there is high moisture content in the atmosphere. The proposed design included pipelines or ductsand hot air receiving chambers for the Varnish Plant.Heat from the exhaust gas which would have otherwise, gone wasted, was utilised by redesigning the varnish plant and this yielded 6.74kW of heat energy which was transferred into the air chambers to aid the drying ofmatchets at the hardening plant. Consequently, the absorption of the moisture on the steel and the dryness of the product were improved. Further studies were done to ensure constant supply of hot air into the air chambers.", "keyphrases": ["varnish plant", "modif made to elimin bloom and rust", "process plant", "bloom", "air chamber", "absorpt of the moistur", "redesign the varnish plant", "pipelin", "transfer into the air chamber", "harden plant", "constant suppli of hot air into the air chamber", "dri ofmatchet", "steel", "heat energi", "exhaust ga", "design of a varnish plant", "rust", "further studi", "ductsand hot air receiv chamber"]}
{"file_name": "S0393044012000198", "text": "RemarkThe purely radiative spacetimes used as reference solutions in our analysis are not perturbations of the Minkowski spacetime. A way of seeing this is to consider the Newman\u2013Penrose constants of the spacetime. The Newman\u2013Penrose constants are a set of absolutely conserved quantities defined as integrals of certain components of the Weyl tensor and the Maxwell fields over cuts of null infinity\u2014see\u00a0[19\u201321] for the Einstein\u2013Maxwell case. In\u00a0[22] it has been shown that the value of the Newman\u2013Penrose constants for a vacuum radiative spacetime coincides with the value of the rescaled Weyl spinor at i+\u2014this result can be extended to the electrovacuum case using the methods of this article. For the radiative spacetimes arising from the construction of\u00a0[17] it can be seen that the value of the Weyl spinor at i+ is essentially the mass quadrupole of the seed static spacetime. It follows, that the Newman\u2013Penrose constants of the radiative spacetime can take arbitrary values. On the other hand, for the Minkowski spacetime, the Newman\u2013Penrose constants are exactly zero, and those of perturbations thereof will be small. Thus, in this precise sense, our radiative spacetimes are, generically, not perturbations of the Minkowski spacetime, unless all the Newman\u2013Penrose constants vanish.", "keyphrases": ["vacuum radi spacetim", "radi spacetim", "refer solut", "newman\u2013penros constant", "weyl tensor", "maxwel field", "minkowski spacetim"]}
{"file_name": "S0888327016300048", "text": "The research work in this paper elaborates on the theoretical effectiveness of the proposed method based on the multivariate EMD. It also clearly indicates through numerical simulations and applications to bearing monitoring that the expansion from standard EMD to multivariate EMD is a successful exploration. Using multiple sensors to collect signal from different locations of the machine and using the multivariate EMD to analyze multivariate signal can contribute to comprehensively collect all the frequency components related to any bearing fault, and is beneficial to extract fault information, especially for early weak fault characteristics. Both the characteristic frequencies of simulated signal and the fault frequencies of practical rolling bearing signal can be extracted from the same order of IMF groups, thus showing that multivariate EMD is an effective signal decomposition algorithm and can be competently applied to fault diagnosis of rolling bearings when combined with a multiscale reduction method and fault correlation factor analysis. In signal acquisition and processing, given the circumstance that there is a trend toward the use of multiple sensors, multivariate EMD appears to be very useful and meaningful as a kind of multivariate data processing algorithm. By analyzing the simulated signal and two different practical multivariate signals, the results demonstrate the significance of the proposed method in the field of fault diagnosis of rolling bearing.", "keyphrases": ["multiscal reduct method", "signal decomposit algorithm", "fault diagnosi of roll bear", "simul signal", "bear monitor", "applic to bear monitor", "fault correl factor analysi", "frequenc compon", "multivari signal", "elabor on the theoret effect of the propos method base on the multivari emd", "expans from standard emd to multivari emd", "multivari data process algorithm", "signal acquisit and process", "extract fault inform", "practic multivari signal", "practic roll bear signal", "standard emd", "roll bear", "multivari emd", "numer simul", "sensor", "fault diagnosi"]}
{"file_name": "S0009261412013838", "text": "Experimental studies of the dynamics of individual carbon atoms in graphene have been empowered by the recent progress in aberration-corrected transmission electron microscopy (AC-TEM) capable of sub-\u00c5ngstrom resolution. The examples include AC-TEM observations of the formation and annealing of Stone\u2013Wales defects [1], edge reconstruction [2,3] and formation of a large hole in graphene sheet from a single vacancy defect [3]. The AC-TEM has been also exploited in visualization in real time of the process of self-assembly of graphene nanoribbons from molecular precursors [4,5] and formation of nanometre size hollow protrusion on the nanotube sidewall [6]. Based on AC-TEM observations of transformation of small finite graphene flake into fullerene, a new \u2018top-down\u2019 mechanism for the formation of fullerene under the electron beam radiation has been proposed [7]. The critical step in the proposed \u2018top-down\u2019 mechanism of the fullerene formation is creation of vacancies in small graphene flake as a result of knock-on damage by electrons of the imaging electron beam (e-beam). The subsequent formation of pentagons at the vacancy sites near the edge reduces the number of dangling bonds and triggers the curving process of graphene flake into a closed fullerene structure [7]. Thus, dynamic behaviour of vacancies near graphene edge plays a crucial role in explaining mechanisms of the e-beam assisted self-assembly and structural transformations in graphene-like structures.", "keyphrases": ["ac-tem", "graphen nanoribbon", "subsequ format of pentagon", "edg reconstruct", "knock-on damag by electron of the imag electron beam (e-beam)", "creation of vacanc in small graphen flake", "e-beam assist self-assembl", "format of nanometr size hollow protrus on the nanotub sidewal", "small finit graphen flake", "format of a larg hole in graphen sheet from a singl vacanc defect", "structur transform in graphene-lik structur", "ac-tem observ of the format and anneal of stone\u2013wal defect", "ac-tem observ", "molecular precursor", "fulleren", "nanotub sidewal", "aberration-correct transmiss electron microscopi", "sub-\u00e5ngstrom resolut", "\u2018top-down\u2019 mechan for the format of fulleren", "propos \u2018top-down\u2019 mechan of the fulleren format", "graphen sheet", "graphen", "carbon atom", "graphene-lik structur", "process of self-assembl of graphen nanoribbon", "format of fulleren"]}
{"file_name": "S0957417416301786", "text": "These results demonstrate that SW-SVR predicts complicated micrometeorological data with the best prediction performance and the lowest computational complexity compared with standard algorithms. In particular, we found that dynamic aggregation of models built from very little extracted data by D-SDC is effective for compatibility of high prediction performance and low computational complexity. However, there are problems to be solved in SW-SVR. Firstly, the prediction performance of SW-SVR sometimes deteriorates despite an increase of training data. In particular, this problem occurred under the conditions that prediction horizons are 6 h as shown in Figure 3. This is because data extracted by D-SDC involves unnecessary training data for highly accurate prediction. If D-SDC extracts the same data as the extracted data when training periods are shorter, the prediction performance of SW-SVR never deteriorates due to an increase of training data. Therefore, we must review both feature mapping and algorithms of D-SDC so as to avoid extracting unnecessary training data. Meanwhile, SW-SVR is based on a combination of several algorithms: kernel approximation, PLS regression, k-means, D-SDC, and linear SVR. Moreover, each algorithm has several parameters. Therefore, SW-SVR has more varied parameters, and it takes more time to tune the parameters. In this experiment, we used a grid search roughly so as to decide the parameters in a certain time. However, there is still room for improvement in the prediction performance by using other approaches such as a genetic algorithm instead of a grid search (Huang & Wang, 2006).", "keyphrases": ["combin of sever algorithm", "pl regress", "dynam aggreg of model", "grid search", "d-sdc", "tune the paramet", "k-mean", "genet algorithm", "linear svr", "standard algorithm", "micrometeorolog data", "kernel approxim", "sw-svr", "train data"]}
{"file_name": "S221266781300083X", "text": "In this paper, coordination problem of agricultural products supply chain with stochastic yield is studied based on prices compensation strategy. The agricultural producing is influenced by the natural conditions, and the yield is uncertain. While agricultural products is rigid demand goods, the fluctuations of yield cause greater volatility of prices. The two- echelon supply chain with one supplier and one retailor is studied, and the mathematical model is constructed. The model showed that prices compensation strategy is Pareto improvement for agricultural products supply chain with stochastic yield, and it also incentive agricultural products supplier to rise the production plan and balance the profit allocation of supply chain.", "keyphrases": ["coordin problem of agricultur product suppli chain", "price compens strategi", "fluctuat of yield", "two- echelon suppli chain", "agricultur product suppli chain", "stochast yield", "coordin problem", "agricultur produc", "mathemat model is construct", "profit alloc", "product plan", "agricultur product", "mathemat model", "yield", "suppli chain"]}
{"file_name": "S0098300413002951", "text": "Hitherto, the investigation of fossil-orientation was only used for the topmost surface of fossil mass occurrences, deposited directly on the sea floor. Due to the fast development of virtual methods (, macro-CT, \u00b5-CT, nano-CT, etc.) it became possible, to investigate the interior orientation of such fossil mass occurrences in three-dimensional detail. Although, a series of paleontological studies deal with 3D-visualization of fossil-elements, no mass occurrence has previously been reconstructed three dimensionally for investigating their interior orientation. This study illustrates an interdisciplinary approach of virtual reconstruction, analyses and interpretation of the interior orientation of an ammonoid mass occurrence. The method established herein produces clear and consistent results using planispirally coiled ammonoid shells \u2013 fossils, that so far would have been used only with caution for depositional interpretations. This method can be applied to any kind of fossil mass occurrence, or even other abundant organic elements and particles, to examine their orientation and depositional conditions to conclude on their paleoenvironment, particularly on paleocurrents.", "keyphrases": ["investig their interior orient", "ossil mass occurr", "virtual reconstruct", "planispir coil ammonoid shell", "other abund organ element", "deposit interpret", "analys and interpret of the interior orient", "investig of fossil-orient", "macro-ct", "particl", "3d-visual", "fossil mass occurr", "nano-ct", "ammonoid mass occurr", "fossil-el", "\u00b5-ct", "virtual method"]}
{"file_name": "S0021999113006955", "text": "The test cases confirm that the high-order discretisation retains exponential convergence properties with increasing geometric and expansion polynomial order if both the solution and true surface are smooth. Errors are found to saturate when the geometric errors, due to the parametrisation of the surface elements, begin to dominate the temporal and spatial discretisation errors. For the smooth solutions considered as test cases, the results show that this dominance of geometric errors quickly limits the effectiveness of further increases in the number of degrees of freedom, either through mesh refinement or higher solution polynomial orders. Increasing the order of the geometry parametrisation reduces the geometric error. The analytic test cases presented here use a coarse curvilinear mesh; for applications, meshes are typically more refined in order to capture features in the solution and so will better capture the geometry and consequently reduce this lower bound on the solution error. If the solution is not smooth, we do not expect to see rapid convergence. In the case that the solution is smooth, but the true surface is not, then exponential convergence with P and Pg can only be achieved if, and only if, the discontinuities are aligned with element boundaries. However, if discontinuities lie within an element, convergence will be limited by the geometric approximation, since the true surface cannot be captured. In the cardiac problem, we consider both the true surface and solution to be smooth.", "keyphrases": ["smooth solut", "coars curvilinear mesh", "higher solut polynomi order", "geometr error", "element boundari", "element", "captur featur in the solut", "mesh refin", "reduc thi lower bound", "solut", "pg", "true surfac", "exponenti converg", "mesh", "p", "captur the geometri", "parametris of the surfac element", "geometri parametris", "geometr approxim", "high-ord discretis", "surfac element", "cardiac problem", "exponenti converg properti", "analyt test case", "discontinu are align with element boundari"]}
{"file_name": "S0021999115008153", "text": "As discussed above, proper inclusion of these interactions requires segment synchronization after every iteration. In order to minimize simulation errors due to incorrect values of the interactions potential, segments are synchronized after every iteration. Although relatively long communication times between remote processors may hinder this process in typical parallel computers, this is not the case for GPGPU architectures. Still, full recalculation of the interaction potential after each iteration is time consuming. Instead, the algorithm corrects the current potential by adding dipole contributions for every nearby charge that hopped during the previous iteration. Full updates of the interaction potential are only required for the grid points that are related to charges that hopped during the last iteration. Accumulative rounding errors that arise due to repetitive addition and subtraction are solve this by rounding all interaction potentials to a uniformly spaced range of floating point numbers.", "keyphrases": ["ad dipol contribut", "recalcul of the interact potenti", "minim simul error", "segment are synchron after everi iter", "segment synchron after everi iter", "algorithm", "correct the current potenti", "processor", "parallel comput", "interact potenti", "gpgpu architectur", "proper inclus of these interact"]}
{"file_name": "S0370269304006720", "text": "Classical, two-dimensional sigma models on compact symmetric spaces G/H are integrable by virtue of conserved quantities which can arise as integrals of local or non-local functions of the underlying fields (the accounts in [1\u20135] contain references to the extensive literature). Since these models are asymptotically free and strongly coupled in the infrared, their quantum properties are not straightforward to determine. Nevertheless, following L\u00fcscher [6], Abdalla, Forger and Gomes showed [7] that, in a G/H sigma model with H simple,11Here, and throughout this Letter, we shall use \u2018simple\u2019 to mean that the corresponding Lie algebra has no non-trivial ideals. Hence U(1) is simple in our terminology, in addition to the usual non-Abelian simple groups of the Cartan\u2013Killing classification [13] the first conserved non-local charge survives quantization (after an appropriate renormalization [6\u20138]), which suffices to ensure quantum integrability of the theory. By contrast, calculations using the 1/N expansion reveal anomalies that spoil the conservation of the quantum non-local charges in the CPN\u22121=SU(N)/SU(N\u22121)\u00d7U(1) models for N>2, and in the wider class of theories based on the complex Grassmannians SU(N)/SU(n)\u00d7SU(N\u2212n)\u00d7U(1) for N>n>1 [9].", "keyphrases": ["quantum integr", "quantiz", "cpn\u22121=su(n)/su(n\u22121)\u00d7u(1) model for n>2", "two-dimension sigma model on compact symmetr space g/h", "correspond lie algebra ha no non-trivi ideal", "integr of local or non-loc function", "calcul use the 1/n expans", "renorm", "complex grassmannian su(n)/su(n)\u00d7su(n\u2212n)\u00d7u(1) for n>n>1", "simpl", "conserv of the quantum non-loc charg", "g/h sigma model with h simpl"]}
{"file_name": "S0370269304009165", "text": "There are many possible applications for this mechanism. In this Letter, we have concentrated on its contribution to leptogenesis and baryogenesis. Our calculation is applicable in the phase when the fields are rolling. This rolling phase will start when the Hubble constant drops to a value comparable to the mass of the scalar fields. It is at this time in the cosmological evolution that CP violation is most efficient. After the fields have relaxed to their vacuum values, our CP violation mechanism turns off. We plan to discuss more details, in particular applications to concrete baryogenesis models, in a future publication [20]. Note that string cosmology and brane world scenarios may provide natural settings for the origin of the scalar fields required for our mechanism ( see Ref. [30] for a recent paper on how scalar fields from brane world scenarios can play a new role in spontaneous baryogenesis).", "keyphrases": ["cp violat", "brane world scenario", "concret baryogenesi model", "it contribut to leptogenesi and baryogenesi", "applic to concret baryogenesi model", "roll phase", "applic for thi mechan", "cp violat mechan", "spontan baryogenesi", "scalar field", "in the phase when the field are roll", "field have relax to their vacuum valu", "hubbl constant drop to a valu compar to the mass of the scalar field", "string cosmolog", "brane", "cosmolog evolut", "our mechan", "how scalar field from brane world scenario can play a new role in spontan baryogenesi"]}
{"file_name": "S0370269304007749", "text": "The charmonium production has long been considered as a good process for investigating both perturbative and nonperturbative properties of quantum chromodynamics (QCD), because of the relatively large difference between the scale at which the charm\u2013quark pair is produced at the parton level and the scale at which it evolves into a quarkonium. In particular, comparing to hadron colliders, e+e\u2212 colliders, provide a cleaner environment to study the charmonium productions and decays. However, some puzzles arise from the recent measurements on the prompt J/\u03c8 productions at BaBar and Belle\u00a0[1\u20133]. For the inclusive J/\u03c8 productions, the cross section is much larger than the predictions of nonrelativistic quantum chromodynamics (NRQCD)\u00a0[4]; there is also an over-abundance of the four-charm\u2013quark processes including the exclusive J/\u03c8 and charmonium productions; there is no apparent signal in the hard J/\u03c8 spectrum which has been predicted by the J/\u03c8gg production mode as well as the color-octet mechanism in NRQCD. To provide plausible solutions and explanations for these conflicts, theorists have studied the possibilities of the contribution from two-virtual-photon mediate processes\u00a0[5], large higher-order QCD corrections\u00a0[6,7], collinear suppression at the end-point region of the J/\u03c8 momentum\u00a0[7,8], contribution from the J/\u03c8-glueball associated production\u00a0[9] and contribution from a very light scalar boson\u00a0[10].", "keyphrases": ["babar", "contribut from the j/\u03c8-gluebal associ product", "j/\u03c8gg product mode", "possibl of the contribut from two-virtual-photon mediat process", "color-octet mechan in nrqcd", "recent measur on the prompt j/\u03c8", "nrqcd", "four-charm\u2013quark process", "exclus j/\u03c8 and charmonium product", "contribut from a veri light scalar boson", "quantum chromodynam", "investig both perturb and nonperturb properti of quantum chromodynam (qcd", "inclus j/\u03c8 product", "e+e\u2212 collid", "charmonium product", "collinear suppress at the end-point region of the j/\u03c8 momentum", "larg higher-ord qcd correct", "qcd", "studi the charmonium product and decay", "bell", "nonrelativist quantum chromodynam"]}
{"file_name": "S2212667812000664", "text": "According to the shortcomings of long time and big errors about the moving plate recognition system, we present the moving plate recognition algorithm based on principal component analysis(PCA) color extraction. On the basis of the analysis of moving plate recognition system's basic principles, it introduces the basic principles and calculation steps about PCA extraction algorithm, and discusses the feasibility of applying the algorithm to PRS in the paper. The experimental results show that the algorithm has the advantages of faster speed and higher accuracy of recognition. The algorithm provides a new thought for the research on the moving plate recognition algorithm.", "keyphrases": ["analysi of move plate recognit system' basic principl", "appli the algorithm to pr", "move plate recognit", "color extraction.", "recognit", "pca extract algorithm", "pca", "move plate recognit system", "princip compon analysi", "move plate recognit algorithm", "research on the move plate recognit algorithm", "pr"]}
{"file_name": "S2212671612000716", "text": "Based on the description model of object-orientation-based direction relation in two-dimensional space, the description mode of object-orientation-based direction relation in three-dimensional space is proposed. The basic idea is that the actual direction region is modeled as an open shape. The computation related to the world boundary of spatial direction region is eliminated, and the processing of the direction predicates is converted into the processing of topological operations between open shapes and closed geometry objects. The algorithms of topological operations between open shapes and closed geometry objects are presented and the theoretical proof for the correctness and completeness of the algorithms is performed.", "keyphrases": ["process of the direct predic", "descript mode of object-orientation-bas direct relat in three-dimension space is propos", "spatial direct region", "theoret proof for the correct and complet of the algorithm", "comput", "world boundari", "direct region", "geometri object", "algorithm", "two-dimension space", "descript mode", "open shape", "descript model", "object-orientation-bas direct relat", "process of topolog oper", "algorithm of topolog oper"]}
{"file_name": "S0029549314001551", "text": "An increase of neutron leakage from the core region can be achieved through modifications in the core geometry (usually by adopting a pan-cake geometry of the active core region at the expense of the general neutron economy). Extensive studies determined a set of core design modifications that optimised the total sodium void reactivity (becoming less positive). Among the most efficient design solutions identified is an enlarged sodium plenum above the active core region in combination with an absorber layer above the sodium plenum (to reduce neutron backscattering from the reflector region above the plenum). Figure 19 shows the combined effect of different upper plenum thicknesses of the absorber and boron layers. It can be observed that the sequential increase of the layer's thickness converge to an asymptotic value of reactivity reduction slightly over 800pcm. The pair of values selected was 60cm for the sodium plenum and 30cm for the boron layer. These modifications implied a considerable increase in the sub-assembly length that was compensated by reducing the upper axial reflector width (Sun , 2013).", "keyphrases": ["enlarg sodium plenum", "reduc neutron backscatt", "modif in the core geometri", "axial reflector", "reduc neutron backscatt from the reflector region abov the plenum", "pan-cak geometri of the activ core region", "plenum", "reduc the upper axial reflector width", "sodium plenum", "neutron", "sodium", "core", "absorb and boron layer", "neutron leakag", "absorb layer", "upper plenum", "core design modif that optimis the total sodium void reactiv", "increas of the layer' thick", "design solut", "increas in the sub-assembl length", "core region", "boron layer", "reactiv reduct"]}
{"file_name": "S0370269304009608", "text": "It should be noted that BEBC\u00a0[21] and NOMAD\u00a0[20] observed a discrepancy between experimental \u03c1 rates and those estimated with JETSET\u00a0[16]. NOMAD\u00a0[20] proposed to retune some of the parameters used within JETSET to obtain better agreement. Therefore, for the purpose of this analysis events were simulated both with the default setting and with the setting proposed by NOMAD of key JETSET parameters, taking an average between them as a result and half a difference as a systematic error. We used experimental rates of light neutral mesons and resonances where available (Table\u00a01) for normalization purposes. The uncertainty introduced by the JETSET parameter settings (which amounts to 20% at most) affects only the production of the \u03b7\u2032 and \u03d5 for which no experimental data are available. This uncertainty is reflected in the error quoted in the table. However, since the contribution from \u03b7\u2032 and \u03d5 is small, the overall effect is less important.", "keyphrases": ["experiment data", "jetset", "observ a discrep", "event were simul", "bebc", "retun some of the paramet", "set propos by nomad", "half a differ as a systemat error", "paramet set", "reson", "nomad", "analysi", "default set", "light neutral meson", "take an averag between them", "obtain better agreement", "normal"]}
{"file_name": "S0009261409006666", "text": "We have presented spectrally resolved femtosecond three-pulse photon echo measurements on Zn(II)\u2013OEP, Ni(II)\u2013OEP and Co(II)\u2013OEP. Increased degree of freedom in scans of time delays allows one to separate and extract specific type of spectroscopic information in complex molecules by studying spectral and temporal evolution of the photon echo signals. By varying the population times, population relaxation dynamics and inhomogeneous broadening is revealed in the photon echo spectra. Time-integrated photon echo signals show two different timescales. The electronic relaxation timescale is found to be sub 50fs whereas the timescale for intramolecular vibrational relaxation, occurring in Q00 band, was found to be over a picosecond for Co(II)\u2013OEP and Ni(II)\u2013OEP and within a picosecond for Zn(II)\u2013OEP.", "keyphrases": ["spectral resolv femtosecond three-puls photon echo measur", "spectral and tempor evolut of the photon echo signal", "within a picosecond for zn(ii)\u2013oep", "complex molecul", "vari the popul time", "zn(ii)\u2013oep", "photon echo spectra", "electron relax timescal", "sub 50f", "timescal", "ni(ii)\u2013oep", "inhomogen broaden", "popul time", "popul relax dynam", "time-integr photon echo signal", "increas degre of freedom", "photon echo signal", "separ and extract specif type of spectroscop inform", "co(ii)\u2013oep", "q00 band", "intramolecular vibrat relax"]}
{"file_name": "S2212667814000124", "text": "Based on expectation-maximization algorithm, parameter estimation was proposed for data-driven nonlinear models in this work. On this basis, particle filters were used to approximately calculate integrals, deriving EM algorithm based on particle filter. And the effectiveness of using the proposed algorithm for the soft sensor of COx content in tail gas of PX oxidation side reactions was verified through simulation results.", "keyphrases": ["px", "cox", "particl filter", "data-driven nonlinear model", "simul", "paramet estim", "em algorithm", "soft sensor", "expectation-maxim algorithm", "tail ga", "px oxid"]}
{"file_name": "S0370269302014880", "text": "Production of charmonium states J/\u03c8 and \u03c8\u2032 in nucleus\u2013nucleus collisions has been studied at CERN SPS over the previous 15 years by the NA38 and NA50 Collaborations. This experimental program was mainly motivated by the suggestion [1] to use the J/\u03c8 as a probe of the state of matter created at the early stage of the collision. The original picture [1] (see also [2] for a modern review) assumes that charmonia are created exclusively at the initial stage of the reaction in primary nucleon\u2013nucleon collisions. During the subsequent evolution of the system, the number of hidden charm mesons is reduced because of: (a)\u00a0absorption of pre-resonance charmonium states by nuclear nucleons (normal nuclear suppression), (b)\u00a0interactions of charmonia with secondary hadrons (comovers), (c)\u00a0dissociation of cc\u0304 bound states in deconfined medium (anomalous suppression). It was found [3] that J/\u03c8 suppression with respect to Drell\u2013Yan muon pairs measured in proton\u2013nucleus and nucleus\u2013nucleus collisions with light projectiles can be explained by the so-called \u201cnormal\u201d (due to sweeping nucleons) nuclear suppression alone. In contrast, the NA50 experiment with a heavy projectile and target (Pb+Pb) revealed essentially stronger J/\u03c8 suppression for central collisions [4\u20137]. This anomalous J/\u03c8 suppression was attributed to formation of quark\u2013gluon plasma (QGP) [7], but a comover scenario cannot be excluded [8].", "keyphrases": ["format of quark\u2013gluon plasma", "heavi projectil and target", "drell\u2013yan muon pair", "hidden charm meson", "dissoci of cc\u0304 bound state in deconfin medium", "pb+pb", "normal nuclear suppress", "nucleon", "charmonium", "na50 experi", "charmonia", "comov scenario", "\u03c8\u2032", "light projectil", "hadron", "nuclear nucleon", "cc\u0304", "proton\u2013nucleu", "nucleus\u2013nucleu collis", "use the j/\u03c8 as a probe of the state of matter creat at the earli stage of the collis", "experiment program", "product of charmonium state j/\u03c8 and \u03c8\u2032 in nucleus\u2013nucleu collis", "absorpt of pre-reson charmonium state by nuclear nucleon", "interact of charmonia with secondari hadron", "origin pictur", "j/\u03c8", "nuclear suppress", "sweep nucleon", "nucleu", "primari nucleon\u2013nucleon collis", "subsequ evolut of the system,", "qgp", "charmonium state", "anomal suppress", "j/\u03c8 suppress", "central collis", "quark\u2013gluon plasma", "comov"]}
{"file_name": "S221267161400105X", "text": "In this paper a comparison between two popular feature extraction methods is presented. Scale-invariant feature transform (or SIFT) is the first method. The Speeded up robust features (or SURF) is presented as second. These two methods are tested on set of depth maps. Ten defined gestures of left hand are in these depth maps. The Microsoft Kinect camera is used for capturing the images [1]. The Support vector machine (or SVM) is used as classification method. The results are accuracy of SVM prediction on selected images.In this paper a comparison between two popular feature extraction methods is presented. Scale-invariant feature transform (or SIFT) is the first method. The Speeded up robust features (or SURF) is presented as second. These two methods are tested on set of depth maps. Ten defined gestures of left hand are in these depth maps. The Microsoft Kinect camera is used for capturing the images [1]. The Support vector machine (or SVM) is used as classification method. The results are accuracy of SVM prediction on selected images.", "keyphrases": ["featur extract", "comparison between two popular featur extract method", "surf", "depth map", "svm", "scale-invari featur transform", "classif", "microsoft kinect camera", "sift", "support vector machin", "speed up robust featur", "classif method"]}
{"file_name": "S0032386108009397", "text": "The viscoelastic behavior of elastomers containing small amounts of unattached chains has been investigated to characterize the dynamics of the polymer chains trapped in fixed networks [66\u201368]. Polymer chains trapped in fixed networks constitute a simpler system for the study of the polymer chain dynamics than the corresponding uncrosslinked polymer melts. This is because the complicated effect of the motion of the surrounding chains on the dynamics of the probe chain \u2013 called \u201cconstraint release\u201d [69] \u2013 is absent in the fixed network systems. Most of the earlier studies employed randomly crosslinked elastomers as host networks. In this case, precise control of the mesh size of the host networks is not possible, and the mesh size has a broad distribution. The end-linking systems give the host networks a more uniform mesh size, and they can control the mesh size by the size of the precursor chains. We investigated the dynamic viscoelasticity of end-linked PDMS elastomers containing unattached linear PDMS as functions of the size of the unattached chains (Mg) and the network mesh (Mx) (Figure\u00a09a) [70]. We employed two types of host networks with Mx>Me and Mx<Me where Me (\u224810,000 for PDMS) is the molecular mass between adjacent entanglements in the molten state. The Mx>Me and Mx<Me networks (designated as NL and NS, respectively) were designed by end-linking the long (Mn=84,000) and short precursor chains (Mn=4,550), respectively. The mesh of the NL networks is dominated by trapped entanglements, while that of the NS network is governed by chemical cross-links.", "keyphrases": ["nl", "elastom", "pdm", "viscoelast behavior", "mx>me", "control of the mesh size", "mesh", "character the dynam of the polym chain", "ns", "polym melt", "mg", "constraint releas", "unattach chain", "precursor chain", "mx", "probe chain", "chemic cross-links.", "polym chain", "pdm elastom", "mx<me", "network mesh", "crosslink elastom"]}
{"file_name": "S0370269301015222", "text": "Recent astronomical observations of high redshift type Ia supernovae performed by two groups [1\u20133] as well as the power spectrum of the cosmic microwave background radiation obtained by the BOOMERANG [4] and MAXIMA-1 [5] experiments seem to indicate that at present the Universe is in a state of accelerated expansion. If one analyzes these data within the Friedmann\u2013Robertson\u2013Walker (FRW) standard model of cosmology their most natural interpretation is that the Universe is spatially flat and that the (baryonic plus dark) matter density \u03c1 is about one third of the critical density \u03c1crit. Most interestingly, the dominant contribution to the energy density is provided by the cosmological constant \u039b. The vacuum energy density (1.1)\u03c1\u039b\u2261\u039b/(8\u03c0G) is about twice as large as \u03c1, i.e., about two thirds of the critical density. With \u03a9M\u2261\u03c1/\u03c1crit, \u03a9\u039b\u2261\u03c1\u039b/\u03c1crit and \u03a9tot\u2261\u03a9M+\u03a9\u039b: (1.2)\u03a9M\u22481/3,\u03a9\u039b\u22482/3,\u03a9tot\u22481. This implies that the deceleration parameter q is approximately \u22121/2. While originally the cosmological constant problem [6] was related to the question why \u039b is so unnaturally small, the discovery of the important role played by \u03c1\u039b has shifted the emphasis toward the \u201ccoincidence problem\u201d, the question why \u03c1 and \u03c1\u039b happen to be of the same order of magnitude precisely at this very moment [7].", "keyphrases": ["deceler paramet", "\u03c1crit", "whi \u03c1 and \u03c1\u03bb happen to be of the same order of magnitud precis at thi veri moment", "power spectrum of the cosmic microwav background radiat", "\u03c1\u03bb\u2261\u03bb/(8\u03c0g)", "friedmann\u2013robertson\u2013walk (frw) standard model", "boomerang", "\u03bb", "\u03c1\u03bb", "high redshift type ia supernova", "matter densiti", "maxima-1", "q", "cosmolog constant", "astronom observ", "coincid problem", "vacuum energi densiti", "cosmolog", "\u03c1", "cosmolog constant problem", "question whi \u03bb is so unnatur small", "critic densiti"]}
{"file_name": "S1877750315000575", "text": "There are some relevant studies on information dissemination in transportation systems using simulations. One category of studies look at how either local information (only about the neighbours) or global information (about the entire network) affects the global network performance. Our approach is different in the sense that we investigate the impact of information on the global network performance depending on the fraction of people that receive information. We analyse what is the effect of real time information dissemination and explain why this effect appears. Information is disseminated in real time and contains global details about how congested the roads are. This approach is important as it gives insights on the impact that massive use of real-time information can have on traffic. This can be useful for building more intelligent traffic control mechanisms where information is a steering tool.", "keyphrases": ["massiv use of real-tim inform", "build more intellig traffic control mechan", "inform dissemin in transport system", "simul", "analys what is the effect of real time inform dissemin", "investig the impact of inform on the global network perform"]}
{"file_name": "S0045782512002678", "text": "To the best of authors\u2019 knowledge, so far there are only very few papers [12,13,16,29] which address the performance of linear algebra solvers. In Ref. [16], the authors study the performance of direct solvers which are clearly not suitable for large problems, specially in three-dimensions. In Ref. [29], the tearing and interconnecting approach of finite element methods is used in the context of isogeometric analysis, and the numerical tests (in absence of any theoretical study) suggest almost optimal (with a logarithmic factor) convergence rates of the proposed isogeometric tearing and interconnecting method. The only paper which provides rigorous theoretical study, supported by extensive numerical examples, is by Beirao  [12] where the authors discuss the overlapping Schwarz methods. The same authors have also proposed BDDC preconditioners for isogeometric analysis in [13].", "keyphrases": ["isogeometr tear and interconnect method", "perform of linear algebra solver", "extens numer exampl", "schwarz method", "larg problem", "numer test", "tear and interconnect approach of finit element method", "rigor theoret studi", "isogeometr analysi", "theoret studi", "perform of direct solver", "bddc precondition"]}
{"file_name": "S2214657115000052", "text": "The exponential relationships reported in the plots may be used to convert the dielectric values to air void values as prescribed in previous studies [1\u20133]. The AC pavement composite permittivity reduces, along with the reflection coefficient, as the volumetric proportion of air increases as compared to the remaining components. However, the method relies on an empirical fit, determined on a case-by-case basis, since the permittivity of the remaining components depends on the mix design (aggregate type, binder content, etc.). Long term studies in Finland concluded that this empirical fit is an exponential relationship [1]. The exponential fits, using a sufficient amount of cores, can be used to map the air void content variation in a similar manner to the dielectric maps shown in Figure 4. Only 4 cores were feasible due to various factors involved with testing the final lift of an in-service pavement. More cores are needed for more stable exponential coefficients, although the limited cores show that the predicted relationships are similar for the measured dielectric range in this case-study. Since both regressions predict air void content at a maximum difference of 0.56%, which is within the uncertainty of the core measurement precision of 0.7%, use of either the initial or repeat run regression predictions are appropriate.", "keyphrases": ["test the final lift", "core measur precis", "mix design", "convert the dielectr valu to air void valu", "air void content", "long term studi in finland", "more stabl exponenti coeffici", "predict relationship", "initi or repeat run regress predict", "suffici amount of core", "dielectr map", "measur dielectr rang", "volumetr proport of air", "map the air void content variat", "exponenti relationship", "ac pavement composit permitt", "regress"]}
{"file_name": "S0022311514006722", "text": "Zirconium alloys are used as fuel cladding in pressurised and boiling water nuclear reactors. As such these materials are exposed to a large number of environmental factors that will promote degradation mechanisms such as oxidation. At high burn-ups, i.e extended service life, oxidation and the associated hydrogen pick-up can be a limiting factor in terms of fuel efficiency and safety. The oxidation kinetics for many zirconium alloys are cyclical, demonstrating a series of approximately cubic kinetic curves separated by transitions [1\u20135]. These transitions are typified by a breakdown in the protective character of the oxide and are potentially linked to a number of mechanical issues. Understanding how these issues influence oxidation is a key to developing a full mechanistic understanding of the corrosion process.", "keyphrases": ["degrad mechan", "understand how these issu influenc oxid", "corros process", "oxid", "develop a full mechanist understand of the corros process", "nuclear reactor", "zirconium alloy", "hydrogen pick-up", "fuel"]}
{"file_name": "S0010938X15301268", "text": "Figure 9 displays the growth of two of the main corrosion products that develop or form on the surface of Cu40Zn with time, hydrozincite (Figure 9a) and Cu2O (Figure 9b). It should be remembered that both phases were present already from start of the exposure. The data is presented in absorbance units and allows comparisons to be made of the amounts of each species between the two Cu40Zn surfaces investigated, DP and HZ7. The tendency is very clear that the formation rates of both hydrozincite and cuprite are quite suppressed for Cu40Zn with preformed hydrozincite (HZ7) compared to the diamond polished surface (DP). In summary, without being able to consider the formation of simonkolleite, it can be concluded that an increased surface coverage of hydrozincite reduces the initial spreading ability of the NaCl-containing droplets and thereby lowers the overall formation rate of hydrozincite and cuprite.", "keyphrases": ["hydrozincit", "format rate", "diamond polish surfac", "cuprit", "hz7", "nacl-contain droplet", "absorb unit", "cu2o", "corros product", "format of simonkolleit", "dp", "initi spread", "comparison to be made of the amount of each speci between the two cu40zn surfac investig", "simonkolleit", "cu40zn"]}
{"file_name": "S0301679X14000449", "text": "Figure 11 shows the wear-mode map of RH ceramics, in which the early-stage friction coefficients and the surface roughness of the pure surface were chosen. The value of the fracture toughness of RH ceramics was calculated based on the reference data in other literature [22]. The Sc of RH ceramics was smaller than Sc,critical under all tested conditions during the initial stage of friction. Thus, the initial wear mode of RH ceramics was powder formation or plowing. In addition, powder formation and plowing can be distinguished using a dimensionless parameter (Sc\u204e) and a critical parameter (Sc,critical\u204e). (3)Sc\u204e=HvRmaxKIc(4)Sc,critical\u204e=51+10\u03bcwhere Hv is the Vickers hardness of RH ceramics [Pa]. The initial wear mode of RH ceramics was determined as powder formation under all tested conditions, as demonstrated in Figure 12(a). Furthermore, the wear-mode map at 2\u00d7104 cycles was constructed, as shown in Figure 12(b). In the map, all plots moved near the transition curve to plowing. In particular, the plots for RH ceramics sliding against stainless steel or Al2O3 balls were nearer than SiC or Si3N4 balls. Therefore, RH ceramics sliding against SiC and Si3N4 balls showed relatively higher wear than the other counterpart materials. Nevertheless, these results from the wear-mode maps indicated that the wear mode of RH ceramics was powder formation accompanied with microcracks under all tested conditions in this study, resulting in low wear (<5\u00d710\u22129mm2/N). Indeed, the observation of the worn surfaces revealed that the catastrophic wear of RH ceramics accompanied by large brittle fracture was prevented overall, as shown in Figure 13.", "keyphrases": ["wear-mod map", "sc,critical\u204e", "critic paramet", "powder format", "plow", "al2o3 ball", "sc\u204e", "sic and si3n4 ball", "sic or si3n4 ball", "stainless steel", "sc\u204e=hvrmaxkic(4)sc,critical\u204e=51+10\u03bc", "vicker hard", "dimensionless paramet"]}
{"file_name": "S0370269304009141", "text": "Longitudinal beam and target single-spin asymmetries have been at the center of the attention lately, since they have been measured by the HERMES and CLAS experimental Collaborations\u00a0[1\u20134] and more measurements are planned. They were originally believed to be signals of the so-called T-odd fragmentation functions\u00a0[5], in particular, of the Collins function\u00a0[6\u201312]. However, both types of asymmetry can receive contributions also from T-odd distribution functions\u00a0[13\u201316], a fact that has often been neglected in analyses. An exhaustive treatment of the contributions of T-odd distribution functions has not been carried out completely so far, especially up to subleading order in an expansion in\u00a01/Q, Q2 being the virtuality of the incident photon and the only hard scale of the process, and including quark mass corrections. It is the purpose of the present work to describe the longitudinal beam and target spin asymmetries in a complete way in terms of leading and subleading twist distribution and fragmentation functions. We consider both single-particle inclusive DIS, e+p\u2192e\u2032+h+X, and single-jet inclusive DIS, e+p\u2192e\u2032+jet+X. We assume factorization holds for these processes, even though at present there is no factorization proof for observables containing subleading-twist transverse-momentum dependent functions (only recently proofs for the leading-twist case have been presented in Refs.", "keyphrases": ["single-particl inclus di", "t-odd distribut function", "e+p\u2192e\u2032+h+x", "collin function", "sublead order in an expans in 1/q", "exhaust treatment of the contribut of t-odd distribut function", "subleading-twist transverse-momentum depend function", "quark mass correct", "single-jet inclus di", "quark", "e+p\u2192e\u2032+jet+x", "fragment function", "twist distribut", "proof for the leading-twist case", "incid photon", "longitudin beam and target single-spin asymmetri", "t-odd fragment function", "factor proof for observ contain subleading-twist transverse-momentum depend function", "herm and cla experiment collabor", "describ the longitudin beam and target spin asymmetri", "factor", "receiv contribut also from t-odd distribut function"]}
{"file_name": "S0375960113006725", "text": "Observations show that in the same area with dimensions of a few tenths of a parsec could be many sources, some of which only emits OH lines, and some \u2013 only lines H2O. The only known in physics the emission mechanism that can give tremendous power within a narrow range of the spectrum, is coherent (i.e the same phase and direction) light lasers, which are called optical lasers, and radio-masers. Cosmic maser radio sources emitting in the lines of the molecules have an extremely high brightness temperature radiation Tb. In the molecules of methanol masers (CH3OH) Tb value can reach 109\u00a0K, with masers hydroxyl molecules (OH) 6\u00d71012\u00a0K. The typical size of the maser clusters is about 1014\u20131015\u00a0m and the neutron star radius is of the order of 10 km. Thus, the radiation dilution coefficient is equaled approximately (2.5\u00d710\u221223)\u2013(2.5\u00d710\u221221) and, therefore, \u03bcB2B2/4(h\u03bd)2\u223c(2.4\u00d710\u22125)\u2013(2.4\u00d710\u22127) for the hydrogen line 21 cm and of the order 10\u22125\u201310\u22127 for the OH 18 cm line or the same order as Eq.", "keyphrases": ["maser hydroxyl molecul", "observ", "hydrogen line", "emiss mechan", "cosmic maser radio sourc", "h2o", "optic laser", "radiat dilut coeffici", "oh line", "maser cluster", "light laser", "neutron star", "methanol maser", "ch3oh", "radio-mas", "oh"]}
{"file_name": "S0370269304009189", "text": "The spins and parities of \u0398+ and \u039e\u2212\u2212 are not yet known experimentally. In this new wave of pentaquark research, most theoretical papers take the spin equal to\u00a01/2. The parity is more controversial. In chiral soliton or Skyrme models the parity is positive\u00a0[4]. In constituent quark models it is usually positive. In the present approach, the parity of the pentaquark is given by P=(\u2212)\u2113+1, where \u2113 is the angular momentum associated with the relative coordinates of the q4 subsystem. We analyze the case where the subsystem of four light quarks is in a state of orbital symmetry [31]O and carries an angular momentum \u2113=1. Although the kinetic energy of such a state is higher than that of the totally symmetric [4]O state, the [31]O symmetry is the most favourable both for the flavour\u2013spin interaction\u00a0[12] and the colour\u2013spin interaction\u00a0[13]. In the first case the statement is confirmed by the comparison between the realistic calculations for positive parity [12] and negative parity\u00a0[14], based on the same quark model\u00a0[15]. In Ref. [12] the antiquark was heavy, c or b, and accordingly the interaction between light quarks and the heavy antiquark was neglected, consistent with the heavy quark limit. In Ref. [16] an attractive spin\u2013spin interaction between s\u0304 and the light quarks was incorporated and shown that a stable or narrow positive parity uudds\u0304 pentaquark can be accommodated within such a model. This interaction has a form that corresponds to \u03b7 meson exchange [17] and its role is to lower the energy of the whole system.", "keyphrases": ["\u2113", "chiral soliton", "spin and pariti of \u03b8+ and \u03be\u2212\u2212", "\u03be\u2212\u2212", "heavi antiquark", "quark model", "lower the energi of the whole system", "kinet energi", "subsystem of four light quark is in a state of orbit symmetri", "\u03b7 meson exchang", "comparison between the realist calcul for posit pariti [12] and neg pariti [14], base on the same quark model [15]", "pariti of the pentaquark", "spin\u2013spin interact", "total symmetr [4]o state", "interact between light quark and the heavi antiquark wa neglected, consist with the heavi quark limit", "o symmetri", "\u03b7 meson", "colour\u2013spin interact", "\u03b8+", "flavour\u2013spin interact", "s\u0304", "quark", "uudds\u0304 pentaquark", "new wave of pentaquark research", "skyrm model", "antiquark", "take the spin equal to 1/2", "constitu quark model", "heavi quark", "pentaquark", "angular momentum associ with the rel coordin of the q4 subsystem", "light quark", "p=(\u2212)\u2113+1"]}
{"file_name": "S0257897213003563", "text": "According to the ellipsometric spectra, optical constants and other physical parameters can be extracted by an appropriate fitting model. In order to estimate the optical constants/dielectric functions of Ni-doped TiO2 films, a three-phase layered system (air/film/substrate) [15] was utilized to study the ellipsometric spectra. TiO2 belongs to the wide band gap semiconductors. Considering the contribution of the M0 type critical point with the lowest three dimensions, its dielectric function can be calculated by Adachi's model [15,22,23]: \u03b5(\u0395)=\u03b5\u221e+{A0[2\u2212(1+\u03c70)1/2\u2212(1\u2212\u03c70)1/2]}/(EOBG2/3\u03c702). In the model, E is the incident photon energy, \u03b5\u221e is the high-frequency dielectric constant, \u03c70=(E+i\u0393), EOBG is the optical gap energy, and A0 and \u0393 are the strength and broadening parameters of the EOBG transition, respectively. As an example, the experimental SE of the film TN1 at an incident angle 70\u00b0 by dot scatter is shown in Figure\u00a04. The Fabry\u2013P\u00e9rot interference oscillations due to multiple reflections within the film have been found in the photon energy from 1.5eV to 3.5eV (354nm\u2013826nm), which indicates that the films are transparent in this region. Note that a good agreement of the experimental and calculated spectra is attained in the whole measured photon energy range. The fitting thickness for film TN2 is 159nm, which is very near to the value obtained by SEM (see Figure\u00a01(b)).", "keyphrases": ["air/film/substr", "fabry\u2013p\u00e9rot interfer", "adachi' model", "e", "incid photon energi", "\u03b5\u221e", "a0 and \u03b3", "\u03b5(\u03b5)=\u03b5\u221e+{a0[2\u2212(1+\u03c70)1/2\u2212(1\u2212\u03c70)1/2]}/(eobg2/3\u03c702)", "high-frequ dielectr constant", "strength and broaden paramet", "se", "ellipsometr spectra", "semiconductor", "\u03c70=(e+i\u03b3)", "sem", "optic constants/dielectr", "eobg", "ni-dop tio2 film", "optic constant", "three-phas layer system"]}
{"file_name": "S0370269304008809", "text": "The most ambitious goal may be stated as the one of detecting the location of, say, one missing level on an otherwise complete sequence. Dyson, in a recent review [7], uses information theory concepts and argues that correlations in a sequence may provide the necessary redundancy from which error correcting codes can be constructed. At one extreme where no correlations and therefore no redundancy are present (Poissonian sequence), there is no possibility of detecting one missing level. At the other extreme, a sequence of equally spaced levels (picket fence), there is a maximum redundancy and a missed level can be obviously detected as a hole in the spectrum. Eigenvalues of random matrices, which exhibit characteristic correlations, correspond to an intermediate situation between these two extremes. The attempts to locate in the last case a single missed level have remained unsuccessful so far. However, it should be mentioned that for two-dimensional chaotic systems where, besides correlations of the order of one mean spacing as described by random matrices, the presence and the role of long range correlations governed by the shortest periodic orbits and reflected in Weyl's law describing the average spectral density, is well understood. It is then possible to approximately locate, from the study of spectral fluctuations, a single missed level\u00a0[8].", "keyphrases": ["poissonian sequenc", "locat in the last case a singl miss level", "error correct code can be construct", "no correl and therefor no redund are present", "picket fenc", "correl in a sequenc", "detect the locat of, say, one miss level on an otherwis complet sequenc", "studi of spectral fluctuat", "two-dimension chaotic system", "weyl' law describ the averag spectral densiti", "miss level can be obvious detect as a hole in the spectrum", "a singl miss level", "approxim locat", "detect one miss level", "sequenc of equal space level", "inform theori concept"]}
{"file_name": "S0022311514005480", "text": "The second stress state is a tri-axial tensile stress designed to represent the zone ahead of an advancing crack tip. Micro-scale lateral cracks have been observed in the oxide layer, and appear to form very close to or at the metal\u2013oxide interface (Figure 1). Finite element analysis by Parise  indicated that these cracks form as a result of localised tensile stresses above peaks in the metal\u2013oxide interface roughness [31]. These cracks are considered separate to any nano-scale cracks that might result from the tetragonal to monoclinic phase transformation. An assumption is made here that whether the micro-scale lateral cracks form via fracture of the oxide or by de-bonding at the interface a triaxial tensile stress state will still be present. In manufactured partially stabilised zirconia cracks would be expected to destabilise the tetragonal phase. This is simulated by applying tensile stress in direction 1, 2 and 3. As this the maximum stress at the crack tip is not known, the applied tensile stresses cover a range from 0.1GPa up to a maximum stress value of 2.2GPa as it is approximately equal to three times the fracture strength of bulk fracture strength for manufactured stabilized zirconia [34]. For the biaxial compressive and triaxial tensile stress states it is the trends in behaviour rather than the absolute values that are considered of greatest importance for this work.", "keyphrases": ["triaxial tensil stress", "second stress state", "oxid", "tetragon to monoclin phase transform", "advanc crack tip", "fractur", "metal\u2013oxid interfac", "tetragon phase", "oxid layer", "crack", "finit element analysi", "de-bond", "localis tensil stress", "manufactur stabil zirconia", "manufactur partial stabilis zirconia", "simul by appli tensil stress in direct 1, 2 and 3", "maximum stress", "appli tensil stress", "biaxial compress and triaxial tensil stress state", "tri-axi tensil stress"]}
{"file_name": "S037026930400721X", "text": "In the supersymmetric case, such a small coupling for quartic interaction cannot be realized if the potential is lifted by the gauge D-term interactions, since, if so, the coupling constant \u03bb becomes of the order O(g2) where g is the gauge coupling constant in the standard model. Therefore, we focus our attention on the D-flat directions. For D-flat directions, we have to be more careful since behaviors of the potential depend on which flat direction we consider. In the MSSM, Yukawa interactions exist in the superpotential to generate the fermion masses. Such Yukawa interactions lift some of the D-flat directions. In addition, we can also find several D-flat directions which are not affected by the Yukawa interactions associated with the fermion masses; without R-parity violation, such D-flat directions are only lifted by the effects of supersymmetry breaking.33Here, we assume that coefficients of non-renormalizable terms are suppressed enough to be neglected. This may be explained by the R-symmetry, assigning R-charge 23 to each MSSM chiral superfields. (See Ref. [6] for the details.)", "keyphrases": ["r-symmetri", "gaug coupl constant", "gaug d-term interact", "yukawa interact", "small coupl", "standard model", "small coupl for quartic interact", "behavior of the potenti", "coeffici of non-renormaliz term", "r-charg 23", "the coupl constant \u03bb", "mssm chiral superfield", "d-flat direct"]}
{"file_name": "S2212671612001783", "text": "Metal\u2013intermetallic laminated (MIL) composites are fabricated upon reaction sintering of titanium and aluminum foils of various thicknesses. The intermetallic phase of Al3Ti forming during the above processing gives high hardness and stiffness to the composite, while unreacted titanium provides the necessary high strength and ductility. Some results of studies of microstructure and some mechanical properties of layered composites are presented on the example of Ti-Al system. Static and dynamic tests results are discussed for the case when the intermetallic reaction was interrupted in the course of intermetallic sintering and also for the case when it was completed.", "keyphrases": ["intermetal phase", "metal\u2013intermetal lamin", "mil", "fabric upon reaction sinter", "process", "intermetal sinter", "reaction sinter", "intermetal reaction", "present on the exampl of ti-al system", "layer composit", "titanium and aluminum foil", "al3ti form", "ti-al system", "al3ti", "static and dynam test result are discuss", "unreact titanium", "studi of microstructur", "static and dynam test", "interrupt", "composit"]}
{"file_name": "S0370269304007208", "text": "It is well known that one of the long standing problems in physics is understanding the confinement physics from first principles. Hence the challenge is to develop analytical approaches which provide valuable insight and theoretical guidance. According to this viewpoint, an effective theory in which confining potentials are obtained as a consequence of spontaneous symmetry breaking of scale invariance has been developed\u00a0[1]. In particular, it was shown that a such theory relies on a scale-invariant Lagrangian of the type\u00a0[2] (1)L=14w2\u221212w\u2212F\u03bc\u03bdaFa\u03bc\u03bd, where F\u03bc\u03bda=\u2202\u03bcA\u03bda\u2212\u2202\u03bdA\u03bca+gfabcA\u03bcbA\u03bdc, and w is not a fundamental field but rather is a function of 4-index field strength, that is, (2)w=\u03b5\u03bc\u03bd\u03b1\u03b2\u2202\u03bcA\u03bd\u03b1\u03b2. The A\u03bd\u03b1\u03b2 equation of motion leads to (3)\u03b5\u03bc\u03bd\u03b1\u03b2\u2202\u03b2w\u2212\u2212F\u03b3\u03b4aFa\u03b3\u03b4=0, which is then integrated to (4)w=\u2212F\u03bc\u03bdaFa\u03bc\u03bd+M. It is easy to verify that the Aa\u03bc equation of motion leads us to (5)\u2207\u03bcFa\u03bc\u03bd+MFa\u03bc\u03bd\u2212F\u03b1\u03b2bFb\u03b1\u03b2=0. It is worth stressing at this stage that the above equation can be obtained from the effective Lagrangian (6)Leff=\u221214F\u03bc\u03bdaFa\u03bc\u03bd+M2\u2212F\u03bc\u03bdaFa\u03bc\u03bd. Spherically symmetric solutions of Eq. (5) display, even in the Abelian case, a Coulomb piece and a confining part. Also, the quantum theory calculation of the static energy between two charges displays the same behavior\u00a0[1]. It is well known that the square root part describes string like solutions\u00a0[3,4].", "keyphrases": ["(2)w=\u03b5\u03bc\u03bd\u03b1\u03b2\u2202\u03bca\u03bd\u03b1\u03b2", "spheric symmetr solut", "a\u03bd\u03b1\u03b2 equat of motion lead", "string like solut", "understand the confin physic from first principl", "the effect lagrangian", "\u03b5\u03bc\u03bd\u03b1\u03b2\u2202\u03b2w\u2212\u2212f\u03b3\u03b4afa\u03b3\u03b4=0", "confin part", "leff=\u221214f\u03bc\u03bdafa\u03bc\u03bd+m2\u2212f\u03bc\u03bdafa\u03bc\u03bd", "coulomb piec", "aa\u03bc equat of motion", "quantum theori calcul of the static energi between two charg", "function of 4-index field strength", "spontan symmetri break of scale invari", "scale-invari lagrangian", "integr to (4)w=\u2212f\u03bc\u03bdafa\u03bc\u03bd+m", "develop analyt approach"]}
{"file_name": "S0378381215301291", "text": "Recently, fundamental (thermophysical property) research on ionic clathrate hydrates has experienced remarkable growth, particularly over the last ten years [21\u201330]. Previously, beginning with the first paper on unusual hydrates of tetrabutylammonium salts in 1940 [31], a number of studies could be found on ionic clathrate hydrates (hereafter, semiclathrate hydrates) [32\u201335] before the unified terminology semiclathrate hydrate was generally accepted. Semiclathrate hydrates have been attracting increased attention because of their promising applications as phase change materials for refrigeration systems and in gas capture and storage [36\u201341]. In addition, there is interesting speculation that semiclathrate hydrate may be regarded as a representative substance for the study of thermal conductivity in clathrate hydrate in general. This is because: (1) it can reduce characterization problems as a solid sample, since semiclathrate hydrate is formed around ambient temperature under atmospheric pressure and is easy to handle; (2) accurately measuring the thermal conductivity of semiclathrate hydrates, which have many similarities to clathrate hydrates, may make possible a deeper understanding of the unique (anomalous) behavior of the thermal conductivity of clathrate hydrates; and (3) currently, there are no experimental studies on the thermal conductivity of semiclathrate hydrates.", "keyphrases": ["semiclathr hydrat", "ionic clathrat hydrat", "unusu hydrat of tetrabutylammonium salt", "phase chang materi for refriger system", "thermal conduct", "measur the thermal conduct", "studi of thermal conduct", "clathrat hydrat", "ga captur and storag"]}
{"file_name": "S2212671612002302", "text": "Monitoring the wear condition of the tramway superstructure is one of the key points to guarantee an adequate safety level of the light rail transport system. The purpose of this paper is to suggest a new non-conventionalprocedure for measuring the transverse profile of rails in operation by means of image-processing technique. This methodological approach is based on the \u201cinformation\u201d contained in high-resolution photographic images of tracks and on specific algorithms which allow to obtain the exact geometric profile of the rails and therefore to measure the state of the rail-head extrados wear.", "keyphrases": ["light rail transport system", "high-resolut photograph imag", "safeti level", "tramway superstructur", "wear condit", "new non-conventionalprocedur", "specif algorithm", "information\u201d", "rail", "monitor the wear condit", "transvers profil", "track", "image-process techniqu"]}
{"file_name": "S030193221400144X", "text": "In the present work, a LIF technique is applied for investigation of gas-sheared film flow in horizontal rectangular duct. The technique makes it possible to perform field measurements of local film thickness, resolved in both space and time, similar to the work of Alekseenko  (2009). The flat shape and large transverse size of the duct allow us to resolve the film thickness in transverse coordinate as well. Alekseenko  (2012) attempted to do this in annular downward flow, but, for technical reasons, the sampling frequency was not high enough in their experiments. More recently Alekseenko  (2014a) showed that the LIF technique can also detect entrained droplets. The technique allows the simultaneous study of three-dimensional wavy structures and liquid entrainment, and can improve understanding of the entrainment phenomenon.", "keyphrases": ["film", "liquid entrain", "duct", "detect entrain droplet", "resolv the film thick", "three-dimension wavi structur", "film flow", "sampl frequenc", "field measur of local film thick", "improv understand of the entrain phenomenon", "lif techniqu", "annular downward flow", "gas-shear film flow"]}
{"file_name": "S0377025714000135", "text": "This conclusion is a consequence of the high jet speeds and small nozzle diameters in combination with the relatively high viscosity solvent and modest molecular weights of the polystyrene, which results in high Weissenberg numbers and moderate values of the extensibility, L studied here. As discussed in earlier papers [3,6], other jetting fluid combinations, such as those of de Gans  [4], lie in a different jetting regime where full extension does not occur and relaxation time controls the viscoelastic behaviour. Consequently inkjet fluid assessment methods need to provide a full characterisation including both linear and nonlinear viscoelastic properties. This complexity suggests assessments of inkjet fluids might have to include jetting from sets of DoD print head devices with different sensitivities to all the various VE parameters [37], rather than reliance on testing without jetting. This was not the expected outcome from the present work but does echo the very pragmatic viewpoint expressed as a \u201cmap of misery\u201d by Clasen  [38] and may provide a way forward for future R&D strategies towards ink testing.", "keyphrases": ["jet fluid combin", "dod print head devic", "inkjet fluid", "jet", "provid a full characteris includ both linear and nonlinear viscoelast properti", "\u201cmap of misery\u201d", "inkjet fluid assess method", "ink test", "polystyren"]}
{"file_name": "S0370269304009013", "text": "Several methods based on dynamical assumptions were suggested for determination of the P-parity of the \u0398+ [13]. According to a general theorem [14], in order to determine the parity of one particle in a binary reaction one has to know polarizations at least of two fermions participating in this reaction. Model independent methods for determination of the P-parity of the \u0398+ were suggested recently in Refs. [15,16] for pp-collision, and in Ref. [17] for photoproduction of the \u0398+. The method of Refs. [15,16], based on the assumption that the spin of the \u0398+ equals 12, suggests to measure the spin\u2013spin correlation parameter in the reaction p\u2192p\u2192\u2192\u03a3+\u0398+ near the threshold. We generalize here this method for an arbitrary spin of the \u0398+ and both isospins T=0 and T=1 of the NN channel of the NN\u2192Y\u0398+ reaction. Furthermore, we consider a polarization transfer from a nucleon to the hyperon Y in this reaction. Our consideration is model independent, since it is based only on conservation of the P-parity, total angular momentum and isospin in the reaction and the generalized Pauli principle for nucleons.", "keyphrases": ["reaction", "polar transfer", "the hyperon y", "binari reaction", "total angular momentum", "nucleon", "pp-collis", "isospin", "determin the pariti", "measur the spin\u2013spin correl paramet", "determin of the p-pariti", "fermion", "particl", "model independ method", "photoproduct", "gener theorem", "conserv of the p-pariti", "thi reaction"]}
{"file_name": "S1071581916300854", "text": "We have developed a systematic, quantified understanding of a specific problem: the design of mobile-friendly unique identifiers. But our results also apply to the design of other text-based services. There has been a trend toward bespoke and adaptive keyboards (, Dunlop and Levine, 2012; Karrenbauer and Oulasvirta, 2014; Leiva , 2015; Wiseman , 2013). More often than not, though, input devices are a fixed constraint in the design of a service. Most users are typing on the keyboard that came with their phone. Those keyboards have advantages, limitations and quirks. The mode-switching that most touchscreen keyboards require to reach numbers and capital letters is at the root of design improvements we propose in this paper. When designing services, it is vital to be aware of the fixed constraints of a system and to then focus on the aspects of a service's design that can be controlled. Making changes to input data in this way is a cheap, quick and easy way to improve user experience.", "keyphrases": ["bespok and adapt keyboard", "design of mobile-friendli uniqu identifi", "design of a servic", "design of other text-bas servic", "mode-switch", "input devic", "design servic"]}
{"file_name": "S0375960113004908", "text": "Topological insulators (TIs) are promising candidates of spintronics materials because of their robust helical surface states and the extremely strong spin\u2013orbit interaction [1\u20133]. Initially, binary chalcogenides Bi2Te3, Sb2Te3 and Bi2Se3 have been identified as three-dimensional TIs by surface sensitive probes such as angle resolved photoemission spectroscopy and scanning tunneling microscopy/spectroscopy. Later, ternary chalcogenide (BixSb1\u2212x)2Te3 [4,5], which has similar tetradymite structure to the parent compounds Bi2Te3 and Sb2Te3, was predicted by ab initio calculations and confirmed by ARPES measurements as a tunable topological insulator whose Fermi energy and carrier density can be adjusted via changing the Bi/Sb composition ratio with stable topological surface state for the entire composition range. Combined with magnetism or superconductivity, TIs have attracted great attention due to the rich variety of new physics and applications. The ferromagnetism in several transition metal (TM) doped TIs, which breaks the time-reversal symmetry, has been reported [6\u201313]. Ferromagnetism in TIs is important because the combination of magnetism with TIs makes a good platform to study fundamental physical phenomena, such as the quantum anomalous Hall effect [14\u201317], Majorana fermions [18], image magnetic monopole effect [19], and topological contributions to the Faraday and Kerr magneto-optical effect [20].", "keyphrases": ["ferromagnet", "superconduct", "bi2se3", "fundament physic phenomena", "spintron materi", "topolog insul", "sb2te3", "surfac sensit probe", "ternari chalcogenid", "arp measur", "faraday and kerr magneto-opt effect", "spin\u2013orbit interact", "magnet", "tm", "majorana fermion", "(bixsb1\u2212x)2te3", "ab initio calcul", "chang the bi/sb composit ratio", "imag magnet monopol effect", "transit metal", "angl resolv photoemiss spectroscopi", "bi2te3", "binari chalcogenid", "ti", "scan tunnel microscopy/spectroscopi", "hall effect"]}
{"file_name": "S0370269304008998", "text": "Including the\u00a0O(\u03b1s) corrections, all the operators listed in\u00a0(9) and\u00a0(10) have to be included. A\u00a0convenient framework to carry out these calculations is the QCD factorization framework\u00a0[14] which allows to express the hadronic matrix elements in the schematic form: (11)\u3008V\u03b3|Oi|B\u3009=FB\u2192VTiI+\u222bdk+2\u03c0\u222b01du\u03c6B,+(k+)TiII(k+,u)\u03c6V\u22a5(u), where FB\u2192V are the transition form factors defined through the matrix elements of the operator\u00a0O7, \u03c6B,+(k+) is the leading-twist B-meson wave-function with k+ being a light-cone component of the spectator quark momentum, \u03c6\u22a5V(u) is the leading-twist light-cone distribution amplitude (LCDA) of the transversely-polarized vector meson\u00a0V, and\u00a0u is the fractional momentum of the vector meson carried by one of the two partons. The quantities\u00a0TiI and\u00a0TiII are the hard-perturbative kernels calculated to order\u00a0\u03b1s, with the latter containing the so-called hard-spectator contributions. The factorization formula\u00a0(11) holds in the heavy quark limit, i.e., to order\u00a0\u039bQCD/MB. This factorization framework has been used to calculate the branching fractions and related quantities for the decays B\u2192K\u2217\u03b3\u00a0[15\u201317] and B\u2192\u03c1\u03b3\u00a0[15,17]. The isospin violation in the B\u2192K\u2217\u03b3 decays in this framework have also been studied\u00a0[18]. (For applications to B\u2192K\u2217\u03b3\u2217, see Refs.\u00a0[16,19,20].) Very recently, the hard-spectator contribution arising from the chromomagnetic operator\u00a0O8 have also been calculated in next-to-next-to-leading order (NNLO) in \u03b1s showing that the spectator interactions factorize in the heavy quark limit\u00a0[21]. However, the numerical effect of the resummed NNLO contributions is marginal and we shall not include this in our update.", "keyphrases": ["leading-twist light-con distribut amplitud", "the factor formula", "express the hadron matrix element in the schemat form:", "oper list in (9) and (10) have to be includ", "fb\u2192v", "\u3008v\u03b3|oi|b\u3009=fb\u2192vtii+\u222bdk+2\u03c0\u222b01du\u03c6b,+(k+)tiii(k+,u)\u03c6v\u22a5(u)", "nnlo", "fraction momentum of the vector meson carri by one of the two parton", "+(k+)", "transit form factor defin through the matrix element of the oper o7, \u03c6b", "u", "lcda", "spectat interact", "thi factor framework", "\u03c6\u22a5v(u", "isospin violat in the b\u2192k\u2217\u03b3 decay", "hard-spect contribut aris from the chromomagnet oper o8", "schemat form", "qcd factor framework", "heavi quark", "next-to-next-to-lead ord", "leading-twist b-meson wave-funct with k+ be a light-con compon of the spectat quark momentum"]}
{"file_name": "S0167931713002438", "text": "There have been suggestions that electrons can be trapped in the bulk and at surfaces of silica [15] but new models of electron trapping centres started to appear only recently. It has been suggested by Bersuker , who used molecular models, that electrons can be trapped by Si\u2013O bonds in a-SiO2 leading to their weakening and thus facilitating Si\u2013O bond dissociation [16]. Further calculations by Camellone  have shown that electrons can spontaneously trap in non-defective continuum random network model of a-SiO2 [17]. Recent calculations have also demonstrated that the two dominant neutral paramagnetic defects at surfaces of a-SiO2, the non-bridging oxygen centre and the silicon dangling bond, are deep electron traps and can form the corresponding negatively charged defects [18]. However, these theoretical predictions have not yet been confirmed experimentally, emphasising the challenges for identifying defect centres.", "keyphrases": ["silica", "si\u2013o bond dissoci", "neutral paramagnet defect", "electron", "a-sio2 lead", "molecular model", "trap in the bulk and at surfac of silica", "identifi defect centr", "a-sio2", "spontan trap", "non-defect continuum random network model", "surfac of a-sio2", "neg charg defect", "deep electron trap", "si\u2013o bond", "weaken", "bulk", "silicon dangl bond", "trap", "non-bridg oxygen centr", "electron trap centr"]}
{"file_name": "S0379711213001653", "text": "With development of performance-based design, some studies have been conducted on fire risk analysis in buildings from different perspectives and levels. Models such as FiRECAM [11,12] and FiERAsystem [13] were used to calculate the expected life risk. In other studies probabilistic methods have been used to assess levels of people safety in buildings [14]. Quantitative risk analysis approaches have also been used to quantify the risk to occupants using stochastic factors [15]. However, studies to date have largely been concerned with various aspects of fire risk analysis and there has been little in the way of development of systematic theoretical methods for analyzing fire risk in buildings in terms of fire risk management. Existing fire risk management involves the identification of alternative fire safety design options [16,17], the ongoing inspection, maintenance of fire protection systems [18] and evacuation training and drills [19]. In this study, basic process of fire risk analysis in building is described, and a fire risk analysis model based on scenario clusters is established with consideration of the characteristics of fire dynamics and occupants' behavior. The number of deaths and directive property loss are selected as fire risk indices and the average fire risk of residential buildings is quantitatively analyzed, so that appropriate fire risk management measures can be adopted.", "keyphrases": ["evacu train and drill", "averag fire risk", "fierasystem", "mainten of fire protect system", "number of death and direct properti loss", "ongo inspect", "aspect of fire risk analysi", "stochast factor", "quantit risk analysi approach", "systemat theoret method", "basic process of fire risk analysi", "firecam", "identif of altern fire safeti design option", "model", "performance-bas design", "probabilist method"]}
{"file_name": "S037596011300741X", "text": "In exploring the WKB limit of quantum theory, Bohm [2] was the first to notice that although one starts with all the ambiguities about the nature of a quantum system, the first order approximation fits the ordinary classical ontology. By that we mean that the real part of the Schr\u00f6dinger equation under polar decomposition of the wave function becomes the classical Hamilton\u2013Jacobi equation in the limit where terms involving \u210f are neglected. In contrast to this approach, in this Letter we show that the classical trajectories arise from a short-time quantum propagator when terms of O(\u0394t2) can be neglected. This fact was actually already observed by Holland some twenty years ago: In page 269 of his book [6] infinitesimal time intervals are considered whose sequence constructs a finite path. It is shown that along each segment the motion is classical (negligible quantum potential), and that it follows that the quantum path may be decomposed into a sequence of segments along each of which the classical action is a minimum. The novel contribution of the present Letter is an improved proof of Holland\u02bcs result using an improved version of the propagator due to Makri and Miller [9,10]. (See also de Gosson [3] for a further discussion.)", "keyphrases": ["wkb limit of quantum theori", "hamilton\u2013jacobi equat", "infinitesim time interv", "schr\u00f6dinger equat under polar decomposit of the wave function", "propag", "short-tim quantum propag"]}
{"file_name": "S2212671612000741", "text": "A sentence alignment model based on combined clues and Kernel Extensional Matrix Matching (KEMM) method is proposed. In this model, a similarity matrix for sentence aligning is formed by the similarities of bilingual sentences calculated by the combined clues, such as lexicon, morphology, length and special symbols, etc. ; then this similarity matrix is used to construct a select matrix for sentence aligning; finally, obtains the sentence alignments by KEMM. Experimental results illustrated that our model outperforms over the Gale's system on handling any types of sentence alignments, with 30% total sentence alignment error rate decreasing.A sentence alignment model based on combined clues and Kernel Extensional Matrix Matching (KEMM) method is proposed. In this model, a similarity matrix for sentence aligning is formed by the similarities of bilingual sentences calculated by the combined clues, such as lexicon, morphology, length and special symbols, etc. ; then this similarity matrix is used to construct a select matrix for sentence aligning; finally, obtains the sentence alignments by KEMM. Experimental results illustrated that our model outperforms over the Gale's system on handling any types of sentence alignments, with 30% total sentence alignment error rate decreasing.", "keyphrases": ["gale' system", "construct a select matrix", "kemm", "similar matrix", "kernel extension matrix match", "sentenc align"]}
{"file_name": "S0010938X15301189", "text": "Failure of structural components is a major concern in the nuclear power industry and represents not only a safety issue, but also a hazard to economic performance. Stress corrosion cracking (SCC), and especially intergranular stress corrosion cracking (IGSCC), have proved to be a significant potential cause of failures in the nuclear industry in materials such as Alloy 600 (74% Ni, 16% Cr and 8% Fe) and stainless steels, especially in Pressurised Water Reactors (PWR) [1\u20135]. Stress corrosion cracking in pressurized water reactors (PWSCC) occurs in Alloy 600 in safety critical components, such as steam generator tubes, heater sleeves, pressurized instrument penetrations and control rod drive mechanisms [2,6,7]. Understanding the mechanisms that control SCC in this alloy will allow for continued extensions of life in current plant as well as safer designs of future nuclear reactors.", "keyphrases": ["pressur water reactor", "intergranular stress corros crack", "alloy", "safeti critic compon", "plant", "pressur instrument penetr", "pwscc", "stainless steel", "heater sleev", "structur compon", "74% ni, 16% cr and 8% fe", "control rod drive mechan", "pwr", "scc", "failur of structur compon", "alloy 600", "safer design of futur nuclear reactor", "nuclear reactor", "igscc", "steam gener tube", "stress corros crack", "pressuris water reactor"]}
